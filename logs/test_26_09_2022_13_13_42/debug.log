2022-09-26 13:13:42,642 [INFO] Running on device: cpu
2022-09-26 13:13:42,642 [INFO] Log dir: logs/test_26_09_2022_13_13_42
2022-09-26 13:13:42,643 [INFO] Running problem with 20 sensors 10 targets: (checkpoint: None, seed : 123, config: configs/test.yml)
2022-09-26 13:13:42,672 [INFO] Generating training dataset
2022-09-26 13:13:48,209 [INFO] Generating validation dataset
2022-09-26 13:13:51,788 [INFO] Begin training phase
2022-09-26 13:13:51,789 [INFO] Start epoch 0
2022-09-26 13:16:22,520 [INFO] 	Batch 99/1500, mean_policy_losses: 756.432, mean_net_lifetime: 3010.3726, mean_mc_travel_dist: 1992.1619, mean_rewards: 160.2219, total_rewards: 1094.2974, mean_steps: 17.6800, mean_ecr: 0.0390 mean_entropies: 2.9977, took: 150.7292s
2022-09-26 13:18:22,337 [INFO] 	Batch 199/1500, mean_policy_losses: 482.038, mean_net_lifetime: 2785.2581, mean_mc_travel_dist: 1901.4567, mean_rewards: 161.6711, total_rewards: 961.7005, mean_steps: 16.1100, mean_ecr: 0.0402 mean_entropies: 2.9949, took: 119.8166s
2022-09-26 13:21:08,945 [INFO] 	Batch 299/1500, mean_policy_losses: 283.348, mean_net_lifetime: 3165.3401, mean_mc_travel_dist: 2069.5208, mean_rewards: 163.7367, total_rewards: 1165.1469, mean_steps: 18.0900, mean_ecr: 0.0402 mean_entropies: 2.9896, took: 166.6083s
2022-09-26 13:23:38,971 [INFO] 	Batch 399/1500, mean_policy_losses: 123.281, mean_net_lifetime: 2788.8106, mean_mc_travel_dist: 1948.0910, mean_rewards: 156.1101, total_rewards: 921.4672, mean_steps: 16.6800, mean_ecr: 0.0397 mean_entropies: 2.9857, took: 150.0265s
2022-09-26 13:25:56,780 [INFO] 	Batch 499/1500, mean_policy_losses: 182.296, mean_net_lifetime: 2837.9143, mean_mc_travel_dist: 1878.9865, mean_rewards: 156.7755, total_rewards: 1039.8028, mean_steps: 16.7600, mean_ecr: 0.0406 mean_entropies: 2.9792, took: 137.8085s
2022-09-26 13:28:28,756 [INFO] 	Batch 599/1500, mean_policy_losses: 180.174, mean_net_lifetime: 2970.0503, mean_mc_travel_dist: 1953.2367, mean_rewards: 155.2454, total_rewards: 1096.6016, mean_steps: 17.6500, mean_ecr: 0.0405 mean_entropies: 2.9757, took: 151.9758s
2022-09-26 13:31:14,798 [INFO] 	Batch 699/1500, mean_policy_losses: 120.963, mean_net_lifetime: 3039.8912, mean_mc_travel_dist: 2024.6832, mean_rewards: 155.8860, total_rewards: 1089.7611, mean_steps: 18.0800, mean_ecr: 0.0407 mean_entropies: 2.9709, took: 166.0423s
2022-09-26 13:34:17,414 [INFO] 	Batch 799/1500, mean_policy_losses: 187.737, mean_net_lifetime: 3344.8728, mean_mc_travel_dist: 2173.5692, mean_rewards: 158.8542, total_rewards: 1247.2162, mean_steps: 19.8700, mean_ecr: 0.0395 mean_entropies: 2.9648, took: 182.6148s
2022-09-26 13:36:58,489 [INFO] 	Batch 899/1500, mean_policy_losses: 43.048, mean_net_lifetime: 3007.9482, mean_mc_travel_dist: 1968.7373, mean_rewards: 160.2506, total_rewards: 1118.1672, mean_steps: 17.5600, mean_ecr: 0.0401 mean_entropies: 2.9577, took: 161.0763s
2022-09-26 13:39:30,621 [INFO] 	Batch 999/1500, mean_policy_losses: -7.049, mean_net_lifetime: 2621.4630, mean_mc_travel_dist: 1783.6747, mean_rewards: 154.0046, total_rewards: 889.7261, mean_steps: 16.1100, mean_ecr: 0.0418 mean_entropies: 2.9500, took: 152.1317s
2022-09-26 13:42:21,903 [INFO] 	Batch 1099/1500, mean_policy_losses: 149.980, mean_net_lifetime: 3073.3671, mean_mc_travel_dist: 1995.2316, mean_rewards: 156.3600, total_rewards: 1136.1483, mean_steps: 18.2500, mean_ecr: 0.0395 mean_entropies: 2.9438, took: 171.2811s
2022-09-26 13:45:11,825 [INFO] 	Batch 1199/1500, mean_policy_losses: 101.530, mean_net_lifetime: 2973.4431, mean_mc_travel_dist: 1897.8148, mean_rewards: 157.0887, total_rewards: 1146.0898, mean_steps: 17.4000, mean_ecr: 0.0421 mean_entropies: 2.9313, took: 169.9228s
2022-09-26 13:48:11,335 [INFO] 	Batch 1299/1500, mean_policy_losses: 107.715, mean_net_lifetime: 3139.2947, mean_mc_travel_dist: 2069.3255, mean_rewards: 151.5253, total_rewards: 1141.2990, mean_steps: 19.3400, mean_ecr: 0.0388 mean_entropies: 2.9222, took: 179.5091s
2022-09-26 13:51:08,080 [INFO] 	Batch 1399/1500, mean_policy_losses: 88.631, mean_net_lifetime: 2934.1303, mean_mc_travel_dist: 1896.2789, mean_rewards: 151.2205, total_rewards: 1102.3864, mean_steps: 17.8100, mean_ecr: 0.0421 mean_entropies: 2.9063, took: 176.7460s
2022-09-26 13:54:18,740 [INFO] 	Batch 1499/1500, mean_policy_losses: 217.100, mean_net_lifetime: 3497.1884, mean_mc_travel_dist: 2156.3647, mean_rewards: 155.2551, total_rewards: 1406.1845, mean_steps: 21.0200, mean_ecr: 0.0384 mean_entropies: 2.9058, took: 190.6606s
2022-09-26 14:17:12,723 [INFO] Epoch 0: mean_policy_losses: 201.148, mean_net_lifetime: 3012.6230, mean_mc_travel_dist: 1980.6089, mean_entropies: 2.9584, m_net_lifetime_valid: 2629.0723, took: 3800.9334s, (151.6843 / 100 batches)

2022-09-26 14:17:12,724 [INFO] Start epoch 1
2022-09-26 14:20:00,560 [INFO] 	Batch 99/1500, mean_policy_losses: 66.826, mean_net_lifetime: 3087.5784, mean_mc_travel_dist: 1971.2824, mean_rewards: 155.1592, total_rewards: 1176.3034, mean_steps: 18.5900, mean_ecr: 0.0396 mean_entropies: 2.8924, took: 167.8341s
2022-09-26 14:22:54,171 [INFO] 	Batch 199/1500, mean_policy_losses: 110.245, mean_net_lifetime: 3101.4713, mean_mc_travel_dist: 1983.8189, mean_rewards: 154.5075, total_rewards: 1178.3079, mean_steps: 18.7400, mean_ecr: 0.0405 mean_entropies: 2.8822, took: 173.6115s
2022-09-26 14:25:54,309 [INFO] 	Batch 299/1500, mean_policy_losses: 158.052, mean_net_lifetime: 3369.2593, mean_mc_travel_dist: 2075.1333, mean_rewards: 154.6961, total_rewards: 1361.0942, mean_steps: 20.0500, mean_ecr: 0.0399 mean_entropies: 2.8755, took: 180.1365s
2022-09-26 14:28:55,300 [INFO] 	Batch 399/1500, mean_policy_losses: 16.441, mean_net_lifetime: 3136.6624, mean_mc_travel_dist: 1988.0281, mean_rewards: 150.7122, total_rewards: 1207.6139, mean_steps: 19.5100, mean_ecr: 0.0397 mean_entropies: 2.8574, took: 180.9922s
2022-09-26 14:32:05,021 [INFO] 	Batch 499/1500, mean_policy_losses: 146.112, mean_net_lifetime: 3081.9041, mean_mc_travel_dist: 1942.7071, mean_rewards: 152.6825, total_rewards: 1210.9682, mean_steps: 19.0000, mean_ecr: 0.0413 mean_entropies: 2.8518, took: 189.7207s
2022-09-26 14:34:58,668 [INFO] 	Batch 599/1500, mean_policy_losses: 78.078, mean_net_lifetime: 3136.5108, mean_mc_travel_dist: 1928.8913, mean_rewards: 152.0481, total_rewards: 1271.5643, mean_steps: 19.3500, mean_ecr: 0.0415 mean_entropies: 2.8270, took: 173.6475s
2022-09-26 14:38:15,876 [INFO] 	Batch 699/1500, mean_policy_losses: 88.167, mean_net_lifetime: 3556.0132, mean_mc_travel_dist: 2177.4238, mean_rewards: 151.9256, total_rewards: 1440.9700, mean_steps: 21.7700, mean_ecr: 0.0384 mean_entropies: 2.8378, took: 197.2073s
2022-09-26 14:41:21,220 [INFO] 	Batch 799/1500, mean_policy_losses: -89.532, mean_net_lifetime: 3116.3184, mean_mc_travel_dist: 2006.2408, mean_rewards: 150.0407, total_rewards: 1180.4314, mean_steps: 19.7500, mean_ecr: 0.0401 mean_entropies: 2.8421, took: 185.3446s
2022-09-26 14:43:42,427 [INFO] 	Batch 899/1500, mean_policy_losses: 43.885, mean_net_lifetime: 3135.4796, mean_mc_travel_dist: 1968.2290, mean_rewards: 151.7003, total_rewards: 1225.7745, mean_steps: 19.5900, mean_ecr: 0.0413 mean_entropies: 2.8118, took: 141.2076s
2022-09-26 14:46:04,415 [INFO] 	Batch 999/1500, mean_policy_losses: 133.783, mean_net_lifetime: 3493.4462, mean_mc_travel_dist: 2136.8569, mean_rewards: 152.4240, total_rewards: 1413.2155, mean_steps: 21.2300, mean_ecr: 0.0396 mean_entropies: 2.8106, took: 141.9873s
2022-09-26 14:48:24,344 [INFO] 	Batch 1099/1500, mean_policy_losses: 91.768, mean_net_lifetime: 3334.4511, mean_mc_travel_dist: 2023.6155, mean_rewards: 148.2151, total_rewards: 1369.1519, mean_steps: 21.0500, mean_ecr: 0.0408 mean_entropies: 2.8112, took: 139.9292s
2022-09-26 14:50:39,049 [INFO] 	Batch 1199/1500, mean_policy_losses: -14.662, mean_net_lifetime: 3236.9440, mean_mc_travel_dist: 2003.2277, mean_rewards: 148.4031, total_rewards: 1291.1997, mean_steps: 20.6500, mean_ecr: 0.0388 mean_entropies: 2.7922, took: 134.7053s
2022-09-26 14:53:05,240 [INFO] 	Batch 1299/1500, mean_policy_losses: 98.404, mean_net_lifetime: 3471.0373, mean_mc_travel_dist: 2163.6070, mean_rewards: 152.0691, total_rewards: 1365.2982, mean_steps: 21.9100, mean_ecr: 0.0392 mean_entropies: 2.7760, took: 146.1899s
2022-09-26 14:55:16,337 [INFO] 	Batch 1399/1500, mean_policy_losses: 15.696, mean_net_lifetime: 3176.2474, mean_mc_travel_dist: 1970.7552, mean_rewards: 150.4127, total_rewards: 1272.9849, mean_steps: 19.9400, mean_ecr: 0.0413 mean_entropies: 2.7751, took: 131.0973s
2022-09-26 14:57:28,879 [INFO] 	Batch 1499/1500, mean_policy_losses: 77.749, mean_net_lifetime: 3140.2400, mean_mc_travel_dist: 1940.1101, mean_rewards: 150.6287, total_rewards: 1254.1134, mean_steps: 19.8900, mean_ecr: 0.0405 mean_entropies: 2.7749, took: 132.5420s
2022-09-26 15:14:23,830 [INFO] Epoch 1: mean_policy_losses: 68.067, mean_net_lifetime: 3238.2376, mean_mc_travel_dist: 2018.6618, mean_entropies: 2.8279, m_net_lifetime_valid: 2702.5112, took: 3431.1061s, (151.0096 / 100 batches)

2022-09-26 15:14:23,832 [INFO] Start epoch 2
2022-09-26 15:16:40,363 [INFO] 	Batch 99/1500, mean_policy_losses: 157.492, mean_net_lifetime: 3462.5839, mean_mc_travel_dist: 2056.9527, mean_rewards: 152.3095, total_rewards: 1466.2560, mean_steps: 21.6400, mean_ecr: 0.0405 mean_entropies: 2.7756, took: 136.5296s
2022-09-26 15:19:07,560 [INFO] 	Batch 199/1500, mean_policy_losses: 96.955, mean_net_lifetime: 3575.4548, mean_mc_travel_dist: 2172.9332, mean_rewards: 150.6759, total_rewards: 1455.7406, mean_steps: 22.5800, mean_ecr: 0.0393 mean_entropies: 2.7944, took: 147.1966s
2022-09-26 15:21:33,749 [INFO] 	Batch 299/1500, mean_policy_losses: -25.730, mean_net_lifetime: 3471.1975, mean_mc_travel_dist: 2150.4239, mean_rewards: 144.7701, total_rewards: 1383.9454, mean_steps: 22.4600, mean_ecr: 0.0394 mean_entropies: 2.7495, took: 146.1891s
2022-09-26 15:24:04,916 [INFO] 	Batch 399/1500, mean_policy_losses: 56.172, mean_net_lifetime: 3355.9458, mean_mc_travel_dist: 2058.6500, mean_rewards: 144.5312, total_rewards: 1353.3937, mean_steps: 22.0600, mean_ecr: 0.0393 mean_entropies: 2.7599, took: 151.1660s
2022-09-26 15:26:19,440 [INFO] 	Batch 499/1500, mean_policy_losses: 113.471, mean_net_lifetime: 3263.6617, mean_mc_travel_dist: 1944.1147, mean_rewards: 152.0777, total_rewards: 1382.6002, mean_steps: 20.1700, mean_ecr: 0.0407 mean_entropies: 2.7483, took: 134.5254s
2022-09-26 15:28:31,946 [INFO] 	Batch 599/1500, mean_policy_losses: 22.150, mean_net_lifetime: 3102.6250, mean_mc_travel_dist: 1938.6718, mean_rewards: 149.6404, total_rewards: 1218.4778, mean_steps: 19.3400, mean_ecr: 0.0397 mean_entropies: 2.7342, took: 132.5054s
2022-09-26 15:31:15,498 [INFO] 	Batch 699/1500, mean_policy_losses: 51.300, mean_net_lifetime: 3229.3090, mean_mc_travel_dist: 1919.6566, mean_rewards: 146.3270, total_rewards: 1364.9176, mean_steps: 20.8600, mean_ecr: 0.0409 mean_entropies: 2.7276, took: 163.5530s
2022-09-26 15:33:38,950 [INFO] 	Batch 799/1500, mean_policy_losses: 99.405, mean_net_lifetime: 3090.6857, mean_mc_travel_dist: 1917.8125, mean_rewards: 149.9385, total_rewards: 1224.1664, mean_steps: 19.7900, mean_ecr: 0.0401 mean_entropies: 2.7325, took: 143.4520s
2022-09-26 15:35:50,705 [INFO] 	Batch 899/1500, mean_policy_losses: 115.550, mean_net_lifetime: 3268.0341, mean_mc_travel_dist: 1943.9312, mean_rewards: 149.1846, total_rewards: 1380.8155, mean_steps: 20.6500, mean_ecr: 0.0407 mean_entropies: 2.7148, took: 131.7546s
2022-09-26 15:37:58,788 [INFO] 	Batch 999/1500, mean_policy_losses: 128.222, mean_net_lifetime: 3280.2717, mean_mc_travel_dist: 1931.8442, mean_rewards: 150.0914, total_rewards: 1410.1804, mean_steps: 20.7800, mean_ecr: 0.0408 mean_entropies: 2.7302, took: 128.0835s
2022-09-26 15:40:25,161 [INFO] 	Batch 1099/1500, mean_policy_losses: 112.578, mean_net_lifetime: 3758.7729, mean_mc_travel_dist: 2193.1527, mean_rewards: 146.1132, total_rewards: 1621.1195, mean_steps: 24.3700, mean_ecr: 0.0389 mean_entropies: 2.7367, took: 146.3720s
2022-09-26 15:42:25,147 [INFO] 	Batch 1199/1500, mean_policy_losses: -47.032, mean_net_lifetime: 3119.4264, mean_mc_travel_dist: 1843.7383, mean_rewards: 148.6800, total_rewards: 1333.7418, mean_steps: 19.7500, mean_ecr: 0.0412 mean_entropies: 2.7370, took: 119.9855s
2022-09-26 15:44:36,317 [INFO] 	Batch 1299/1500, mean_policy_losses: 1.971, mean_net_lifetime: 3334.3668, mean_mc_travel_dist: 2028.2866, mean_rewards: 147.7365, total_rewards: 1372.3555, mean_steps: 21.1600, mean_ecr: 0.0398 mean_entropies: 2.7373, took: 131.1708s
2022-09-26 15:47:01,072 [INFO] 	Batch 1399/1500, mean_policy_losses: -2.287, mean_net_lifetime: 3190.9050, mean_mc_travel_dist: 1967.8934, mean_rewards: 144.5086, total_rewards: 1277.8338, mean_steps: 21.1800, mean_ecr: 0.0397 mean_entropies: 2.6816, took: 144.7548s
2022-09-26 15:49:26,140 [INFO] 	Batch 1499/1500, mean_policy_losses: 150.750, mean_net_lifetime: 3492.8828, mean_mc_travel_dist: 2004.7668, mean_rewards: 152.2052, total_rewards: 1528.6374, mean_steps: 22.2000, mean_ecr: 0.0406 mean_entropies: 2.6837, took: 145.0681s
2022-09-26 16:06:07,756 [INFO] Epoch 2: mean_policy_losses: 68.731, mean_net_lifetime: 3333.0749, mean_mc_travel_dist: 2004.8552, mean_entropies: 2.7362, m_net_lifetime_valid: 2759.1149, took: 3103.9241s, (131.3942 / 100 batches)

2022-09-26 16:06:07,757 [INFO] Start epoch 3
2022-09-26 16:08:38,608 [INFO] 	Batch 99/1500, mean_policy_losses: -21.164, mean_net_lifetime: 3382.9089, mean_mc_travel_dist: 2036.4144, mean_rewards: 144.1249, total_rewards: 1404.0960, mean_steps: 22.3300, mean_ecr: 0.0396 mean_entropies: 2.6791, took: 150.8486s
2022-09-26 16:10:53,511 [INFO] 	Batch 199/1500, mean_policy_losses: 63.144, mean_net_lifetime: 3328.5517, mean_mc_travel_dist: 2024.6237, mean_rewards: 147.2154, total_rewards: 1367.2430, mean_steps: 21.8300, mean_ecr: 0.0393 mean_entropies: 2.6547, took: 134.9028s
2022-09-26 16:13:08,570 [INFO] 	Batch 299/1500, mean_policy_losses: -5.550, mean_net_lifetime: 3353.9525, mean_mc_travel_dist: 2030.2576, mean_rewards: 148.2655, total_rewards: 1379.7338, mean_steps: 21.9400, mean_ecr: 0.0403 mean_entropies: 2.6999, took: 135.0584s
2022-09-26 16:15:43,644 [INFO] 	Batch 399/1500, mean_policy_losses: 19.553, mean_net_lifetime: 3571.4058, mean_mc_travel_dist: 2091.6308, mean_rewards: 144.6498, total_rewards: 1535.9101, mean_steps: 23.4300, mean_ecr: 0.0390 mean_entropies: 2.6875, took: 155.0737s
2022-09-26 16:18:09,848 [INFO] 	Batch 499/1500, mean_policy_losses: -58.634, mean_net_lifetime: 3015.7303, mean_mc_travel_dist: 1828.2830, mean_rewards: 145.2305, total_rewards: 1238.1922, mean_steps: 19.6600, mean_ecr: 0.0423 mean_entropies: 2.6348, took: 146.2047s
2022-09-26 16:20:38,439 [INFO] 	Batch 599/1500, mean_policy_losses: 139.430, mean_net_lifetime: 3343.4804, mean_mc_travel_dist: 1939.4681, mean_rewards: 144.5341, total_rewards: 1460.6116, mean_steps: 22.2500, mean_ecr: 0.0404 mean_entropies: 2.6450, took: 148.5914s
2022-09-26 16:23:30,402 [INFO] 	Batch 699/1500, mean_policy_losses: 45.742, mean_net_lifetime: 3191.2488, mean_mc_travel_dist: 1850.4448, mean_rewards: 146.5191, total_rewards: 1384.4955, mean_steps: 20.9400, mean_ecr: 0.0422 mean_entropies: 2.6372, took: 171.9626s
2022-09-26 16:26:35,056 [INFO] 	Batch 799/1500, mean_policy_losses: -22.250, mean_net_lifetime: 3475.5909, mean_mc_travel_dist: 2040.7648, mean_rewards: 143.1944, total_rewards: 1486.9406, mean_steps: 23.0400, mean_ecr: 0.0390 mean_entropies: 2.6291, took: 184.6549s
2022-09-26 16:30:08,517 [INFO] 	Batch 899/1500, mean_policy_losses: 100.676, mean_net_lifetime: 4124.2886, mean_mc_travel_dist: 2298.7091, mean_rewards: 148.3829, total_rewards: 1871.2286, mean_steps: 27.0200, mean_ecr: 0.0386 mean_entropies: 2.6173, took: 213.4603s
2022-09-26 16:33:16,345 [INFO] 	Batch 999/1500, mean_policy_losses: -139.130, mean_net_lifetime: 3205.4686, mean_mc_travel_dist: 1859.3335, mean_rewards: 140.8611, total_rewards: 1381.1063, mean_steps: 22.0900, mean_ecr: 0.0402 mean_entropies: 2.5973, took: 187.8277s
2022-09-26 16:36:16,927 [INFO] 	Batch 1099/1500, mean_policy_losses: -55.302, mean_net_lifetime: 3122.6011, mean_mc_travel_dist: 1841.4785, mean_rewards: 141.0879, total_rewards: 1316.6034, mean_steps: 21.3300, mean_ecr: 0.0412 mean_entropies: 2.6206, took: 180.5822s
2022-09-26 16:39:10,324 [INFO] 	Batch 1199/1500, mean_policy_losses: 80.401, mean_net_lifetime: 3264.8243, mean_mc_travel_dist: 1913.5600, mean_rewards: 144.3403, total_rewards: 1408.7685, mean_steps: 21.5000, mean_ecr: 0.0400 mean_entropies: 2.6224, took: 173.3938s

2022-10-09 17:46:02,983 [INFO] Running on device: cuda
2022-10-09 17:46:02,983 [INFO] Log dir: logs/test2_09_10_2022_17_46_02
2022-10-09 17:46:02,984 [INFO] Running problem with 20 sensors 10 targets: (checkpoint: None, seed : 123, config: configs/test2.yml)
2022-10-09 17:48:08,375 [INFO] 	Process 6 - batch 99: mean_policy_losses: 49.695, mean_net_lifetime: 1095.3460, mean_mc_travel_dist: 918.3539, mean_rewards: 150.8463, total_rewards: 271.0175, mean_steps: 6.5000, mean_ecr: 0.0564 mean_entropies: 2.9961, took: 93.0908s
2022-10-09 17:49:01,932 [INFO] 	Process 4 - batch 99: mean_policy_losses: 426.215, mean_net_lifetime: 2151.5910, mean_mc_travel_dist: 1427.8376, mean_rewards: 171.4884, total_rewards: 782.1626, mean_steps: 11.6900, mean_ecr: 0.0522 mean_entropies: 2.9862, took: 147.0111s
2022-10-09 17:49:10,038 [INFO] 	Process 7 - batch 99: mean_policy_losses: 304.724, mean_net_lifetime: 2248.6960, mean_mc_travel_dist: 1594.2410, mean_rewards: 167.0966, total_rewards: 721.0450, mean_steps: 12.5800, mean_ecr: 0.0439 mean_entropies: 2.9848, took: 155.1733s
2022-10-09 17:49:34,145 [INFO] 	Process 6 - batch 199: mean_policy_losses: -455.906, mean_net_lifetime: 1078.4779, mean_mc_travel_dist: 902.9727, mean_rewards: 149.4945, total_rewards: 262.7507, mean_steps: 6.4000, mean_ecr: 0.0559 mean_entropies: 2.9751, took: 85.7709s
2022-10-09 17:49:45,484 [INFO] 	Process 3 - batch 99: mean_policy_losses: 534.801, mean_net_lifetime: 2819.3171, mean_mc_travel_dist: 1822.7021, mean_rewards: 172.4956, total_rewards: 1066.2253, mean_steps: 15.4100, mean_ecr: 0.0484 mean_entropies: 2.9807, took: 189.9991s
2022-10-09 17:49:48,858 [INFO] 	Process 2 - batch 99: mean_policy_losses: 477.103, mean_net_lifetime: 2909.4710, mean_mc_travel_dist: 1943.6095, mean_rewards: 170.4390, total_rewards: 1029.0803, mean_steps: 16.1500, mean_ecr: 0.0413 mean_entropies: 2.9779, took: 194.1451s
2022-10-09 17:49:54,978 [INFO] 	Process 5 - batch 99: mean_policy_losses: 174.431, mean_net_lifetime: 2624.8829, mean_mc_travel_dist: 1973.2979, mean_rewards: 147.0660, total_rewards: 735.9999, mean_steps: 16.8100, mean_ecr: 0.0309 mean_entropies: 2.9805, took: 200.1521s
2022-10-09 17:50:24,430 [INFO] 	Process 1 - batch 99: mean_policy_losses: 725.466, mean_net_lifetime: 3702.3026, mean_mc_travel_dist: 2285.1548, mean_rewards: 178.6498, total_rewards: 1484.9438, mean_steps: 19.7500, mean_ecr: 0.0404 mean_entropies: 2.9744, took: 229.6292s
2022-10-09 17:50:56,633 [INFO] 	Process 6 - batch 299: mean_policy_losses: -372.718, mean_net_lifetime: 1087.5241, mean_mc_travel_dist: 907.1042, mean_rewards: 150.3364, total_rewards: 275.7036, mean_steps: 6.5000, mean_ecr: 0.0563 mean_entropies: 2.9668, took: 82.4875s
2022-10-09 17:51:28,019 [INFO] 	Process 4 - batch 199: mean_policy_losses: 248.461, mean_net_lifetime: 2217.3384, mean_mc_travel_dist: 1448.9538, mean_rewards: 173.6289, total_rewards: 828.3612, mean_steps: 11.8900, mean_ecr: 0.0521 mean_entropies: 2.9634, took: 146.0865s
2022-10-09 17:51:43,555 [INFO] 	Process 7 - batch 199: mean_policy_losses: 48.255, mean_net_lifetime: 2209.5547, mean_mc_travel_dist: 1591.9061, mean_rewards: 161.8017, total_rewards: 691.5960, mean_steps: 12.7800, mean_ecr: 0.0440 mean_entropies: 2.9559, took: 153.5173s
2022-10-09 17:52:37,628 [INFO] 	Process 6 - batch 399: mean_policy_losses: -444.899, mean_net_lifetime: 1101.3335, mean_mc_travel_dist: 905.9143, mean_rewards: 149.7501, total_rewards: 277.9755, mean_steps: 6.6200, mean_ecr: 0.0562 mean_entropies: 2.9460, took: 100.9953s
2022-10-09 17:53:02,257 [INFO] 	Process 3 - batch 199: mean_policy_losses: 480.822, mean_net_lifetime: 3016.2010, mean_mc_travel_dist: 1868.5229, mean_rewards: 178.4948, total_rewards: 1201.9371, mean_steps: 15.8700, mean_ecr: 0.0478 mean_entropies: 2.9573, took: 196.7738s
2022-10-09 17:53:08,149 [INFO] 	Process 2 - batch 199: mean_policy_losses: 301.895, mean_net_lifetime: 2885.3280, mean_mc_travel_dist: 1922.7768, mean_rewards: 168.0305, total_rewards: 1029.8404, mean_steps: 16.2600, mean_ecr: 0.0415 mean_entropies: 2.9543, took: 199.2912s
2022-10-09 17:53:38,206 [INFO] 	Process 5 - batch 199: mean_policy_losses: 67.958, mean_net_lifetime: 2812.1516, mean_mc_travel_dist: 2056.1589, mean_rewards: 146.2165, total_rewards: 848.3685, mean_steps: 18.2300, mean_ecr: 0.0308 mean_entropies: 2.9611, took: 223.2273s
2022-10-09 17:54:14,350 [INFO] 	Process 6 - batch 499: mean_policy_losses: -425.939, mean_net_lifetime: 1171.5151, mean_mc_travel_dist: 923.8771, mean_rewards: 155.5855, total_rewards: 332.1421, mean_steps: 6.6400, mean_ecr: 0.0561 mean_entropies: 2.9048, took: 96.7222s
2022-10-09 17:54:14,392 [INFO] 	Process 4 - batch 299: mean_policy_losses: 240.032, mean_net_lifetime: 2314.6567, mean_mc_travel_dist: 1461.1591, mean_rewards: 173.7406, total_rewards: 908.2784, mean_steps: 12.3900, mean_ecr: 0.0522 mean_entropies: 2.9304, took: 166.3739s
2022-10-09 17:54:58,324 [INFO] 	Process 7 - batch 299: mean_policy_losses: 127.541, mean_net_lifetime: 2500.1481, mean_mc_travel_dist: 1696.8474, mean_rewards: 158.8723, total_rewards: 883.0294, mean_steps: 14.8400, mean_ecr: 0.0438 mean_entropies: 2.8961, took: 194.7606s
2022-10-09 17:55:03,458 [INFO] 	Process 1 - batch 199: mean_policy_losses: 729.947, mean_net_lifetime: 4153.4972, mean_mc_travel_dist: 2398.8700, mean_rewards: 178.9553, total_rewards: 1809.4988, mean_steps: 22.1500, mean_ecr: 0.0403 mean_entropies: 2.9177, took: 279.0277s
2022-10-09 17:55:51,688 [INFO] 	Process 6 - batch 599: mean_policy_losses: -451.491, mean_net_lifetime: 1140.9277, mean_mc_travel_dist: 920.7363, mean_rewards: 153.6781, total_rewards: 306.9357, mean_steps: 6.5500, mean_ecr: 0.0560 mean_entropies: 2.8495, took: 97.3345s
2022-10-09 17:56:30,900 [INFO] 	Process 3 - batch 299: mean_policy_losses: 488.566, mean_net_lifetime: 3060.6818, mean_mc_travel_dist: 1850.0130, mean_rewards: 180.5254, total_rewards: 1269.5352, mean_steps: 15.9700, mean_ecr: 0.0477 mean_entropies: 2.9017, took: 208.6423s
2022-10-09 17:56:44,394 [INFO] 	Process 2 - batch 299: mean_policy_losses: 273.804, mean_net_lifetime: 2975.0711, mean_mc_travel_dist: 1926.5651, mean_rewards: 162.9434, total_rewards: 1106.0011, mean_steps: 17.3400, mean_ecr: 0.0415 mean_entropies: 2.9033, took: 216.2455s
2022-10-09 17:57:03,207 [INFO] 	Process 4 - batch 399: mean_policy_losses: 265.355, mean_net_lifetime: 2391.0939, mean_mc_travel_dist: 1473.1519, mean_rewards: 169.1948, total_rewards: 972.1849, mean_steps: 13.2300, mean_ecr: 0.0520 mean_entropies: 2.8609, took: 168.8144s
2022-10-09 17:57:22,962 [INFO] 	Process 6 - batch 699: mean_policy_losses: -441.965, mean_net_lifetime: 1164.7888, mean_mc_travel_dist: 898.8849, mean_rewards: 153.7467, total_rewards: 342.8479, mean_steps: 6.7600, mean_ecr: 0.0556 mean_entropies: 2.7745, took: 91.2775s
2022-10-09 17:57:34,763 [INFO] 	Process 5 - batch 299: mean_policy_losses: -17.261, mean_net_lifetime: 2846.5308, mean_mc_travel_dist: 2092.9186, mean_rewards: 139.8831, total_rewards: 823.1420, mean_steps: 19.1800, mean_ecr: 0.0307 mean_entropies: 2.9211, took: 236.5578s
2022-10-09 17:58:25,842 [INFO] 	Process 7 - batch 399: mean_policy_losses: 181.887, mean_net_lifetime: 2732.7619, mean_mc_travel_dist: 1721.6342, mean_rewards: 149.8448, total_rewards: 1083.1463, mean_steps: 17.3500, mean_ecr: 0.0437 mean_entropies: 2.7724, took: 207.5268s
2022-10-09 17:59:00,787 [INFO] 	Process 6 - batch 799: mean_policy_losses: -398.959, mean_net_lifetime: 1177.2213, mean_mc_travel_dist: 895.9185, mean_rewards: 150.3776, total_rewards: 363.5743, mean_steps: 7.0000, mean_ecr: 0.0555 mean_entropies: 2.7121, took: 97.8245s
2022-10-09 17:59:52,332 [INFO] 	Process 4 - batch 499: mean_policy_losses: 241.290, mean_net_lifetime: 2418.9692, mean_mc_travel_dist: 1448.6525, mean_rewards: 166.3832, total_rewards: 1013.0835, mean_steps: 13.6600, mean_ecr: 0.0529 mean_entropies: 2.7652, took: 169.1255s
2022-10-09 17:59:57,254 [INFO] 	Process 1 - batch 299: mean_policy_losses: 776.466, mean_net_lifetime: 4501.4696, mean_mc_travel_dist: 2438.6856, mean_rewards: 177.4681, total_rewards: 2105.2396, mean_steps: 24.3300, mean_ecr: 0.0402 mean_entropies: 2.7876, took: 293.7962s
2022-10-09 17:59:57,980 [INFO] 	Process 3 - batch 399: mean_policy_losses: 472.027, mean_net_lifetime: 3139.0491, mean_mc_travel_dist: 1831.0207, mean_rewards: 176.7364, total_rewards: 1367.3686, mean_steps: 16.8200, mean_ecr: 0.0476 mean_entropies: 2.8106, took: 207.0805s
2022-10-09 18:00:21,675 [INFO] 	Process 2 - batch 399: mean_policy_losses: 249.502, mean_net_lifetime: 2962.6897, mean_mc_travel_dist: 1865.7179, mean_rewards: 156.4094, total_rewards: 1159.6182, mean_steps: 18.1000, mean_ecr: 0.0417 mean_entropies: 2.8248, took: 217.2795s
2022-10-09 18:00:40,735 [INFO] 	Process 6 - batch 899: mean_policy_losses: -457.737, mean_net_lifetime: 1197.9783, mean_mc_travel_dist: 902.1007, mean_rewards: 151.1292, total_rewards: 363.1216, mean_steps: 7.0600, mean_ecr: 0.0556 mean_entropies: 2.5932, took: 99.9482s
2022-10-09 18:02:00,255 [INFO] 	Process 5 - batch 399: mean_policy_losses: 16.230, mean_net_lifetime: 3214.1627, mean_mc_travel_dist: 2266.7598, mean_rewards: 141.9900, total_rewards: 1015.1680, mean_steps: 21.5100, mean_ecr: 0.0305 mean_entropies: 2.8781, took: 265.4925s
2022-10-09 18:02:24,906 [INFO] 	Process 6 - batch 999: mean_policy_losses: -601.203, mean_net_lifetime: 1154.0831, mean_mc_travel_dist: 896.1643, mean_rewards: 144.4296, total_rewards: 327.1052, mean_steps: 7.2500, mean_ecr: 0.0558 mean_entropies: 2.5437, took: 104.1713s
2022-10-09 18:02:35,277 [INFO] 	Process 7 - batch 499: mean_policy_losses: 234.027, mean_net_lifetime: 3089.4904, mean_mc_travel_dist: 1743.7309, mean_rewards: 145.5044, total_rewards: 1393.8410, mean_steps: 20.5000, mean_ecr: 0.0438 mean_entropies: 2.5986, took: 249.4344s
2022-10-09 18:02:54,414 [INFO] 	Process 4 - batch 599: mean_policy_losses: 189.521, mean_net_lifetime: 2462.2337, mean_mc_travel_dist: 1402.2313, mean_rewards: 165.2627, total_rewards: 1091.9987, mean_steps: 14.0600, mean_ecr: 0.0527 mean_entropies: 2.6509, took: 182.0812s
2022-10-09 18:03:47,679 [INFO] 	Process 3 - batch 499: mean_policy_losses: 353.563, mean_net_lifetime: 3191.8533, mean_mc_travel_dist: 1825.5591, mean_rewards: 171.1288, total_rewards: 1420.6699, mean_steps: 17.7200, mean_ecr: 0.0473 mean_entropies: 2.7229, took: 229.6988s
2022-10-09 18:04:11,767 [INFO] 	Process 6 - batch 1099: mean_policy_losses: -554.797, mean_net_lifetime: 1174.2354, mean_mc_travel_dist: 879.9714, mean_rewards: 145.1881, total_rewards: 375.1042, mean_steps: 7.3400, mean_ecr: 0.0555 mean_entropies: 2.4988, took: 106.8604s
2022-10-09 18:04:23,958 [INFO] 	Process 2 - batch 499: mean_policy_losses: 281.665, mean_net_lifetime: 3248.3553, mean_mc_travel_dist: 1910.3451, mean_rewards: 160.8013, total_rewards: 1397.8565, mean_steps: 19.3000, mean_ecr: 0.0416 mean_entropies: 2.7642, took: 242.2848s
2022-10-09 18:05:32,663 [INFO] 	Process 1 - batch 399: mean_policy_losses: 710.052, mean_net_lifetime: 4715.9886, mean_mc_travel_dist: 2439.7721, mean_rewards: 173.2567, total_rewards: 2313.2564, mean_steps: 26.2500, mean_ecr: 0.0401 mean_entropies: 2.6630, took: 335.4102s
2022-10-09 18:06:05,898 [INFO] 	Process 6 - batch 1199: mean_policy_losses: -544.017, mean_net_lifetime: 1224.1596, mean_mc_travel_dist: 878.9327, mean_rewards: 148.9150, total_rewards: 410.5977, mean_steps: 7.4600, mean_ecr: 0.0553 mean_entropies: 2.4486, took: 114.1306s
2022-10-09 18:06:14,537 [INFO] 	Process 4 - batch 699: mean_policy_losses: 141.714, mean_net_lifetime: 2459.6081, mean_mc_travel_dist: 1364.9295, mean_rewards: 155.7434, total_rewards: 1124.8963, mean_steps: 14.9600, mean_ecr: 0.0531 mean_entropies: 2.5453, took: 200.1225s
2022-10-09 18:06:48,149 [INFO] 	Process 5 - batch 499: mean_policy_losses: -58.694, mean_net_lifetime: 3251.2858, mean_mc_travel_dist: 2217.4122, mean_rewards: 140.4098, total_rewards: 1086.5117, mean_steps: 21.9200, mean_ecr: 0.0306 mean_entropies: 2.8523, took: 287.8937s
2022-10-09 18:07:38,670 [INFO] 	Process 7 - batch 599: mean_policy_losses: 239.666, mean_net_lifetime: 3300.7138, mean_mc_travel_dist: 1749.1541, mean_rewards: 136.3754, total_rewards: 1594.9361, mean_steps: 23.5700, mean_ecr: 0.0438 mean_entropies: 2.4758, took: 303.3927s
2022-10-09 18:07:57,344 [INFO] 	Process 6 - batch 1299: mean_policy_losses: -590.739, mean_net_lifetime: 1232.6421, mean_mc_travel_dist: 890.6744, mean_rewards: 147.5017, total_rewards: 406.1994, mean_steps: 7.5300, mean_ecr: 0.0555 mean_entropies: 2.4703, took: 111.4474s
2022-10-09 18:07:59,595 [INFO] 	Process 3 - batch 599: mean_policy_losses: 387.167, mean_net_lifetime: 3332.6599, mean_mc_travel_dist: 1794.3622, mean_rewards: 171.0370, total_rewards: 1574.0794, mean_steps: 18.6000, mean_ecr: 0.0468 mean_entropies: 2.6307, took: 251.9161s
2022-10-09 18:08:44,316 [INFO] 	Process 2 - batch 599: mean_policy_losses: 181.316, mean_net_lifetime: 3203.1678, mean_mc_travel_dist: 1839.7452, mean_rewards: 151.4620, total_rewards: 1406.6708, mean_steps: 20.2600, mean_ecr: 0.0418 mean_entropies: 2.6580, took: 260.3571s
2022-10-09 18:09:32,363 [INFO] 	Process 4 - batch 799: mean_policy_losses: 192.661, mean_net_lifetime: 2590.3469, mean_mc_travel_dist: 1352.0785, mean_rewards: 159.4776, total_rewards: 1266.3598, mean_steps: 15.3700, mean_ecr: 0.0530 mean_entropies: 2.4879, took: 197.8268s
2022-10-09 18:09:42,091 [INFO] 	Process 6 - batch 1399: mean_policy_losses: -693.702, mean_net_lifetime: 1185.1444, mean_mc_travel_dist: 896.7689, mean_rewards: 144.8411, total_rewards: 364.5017, mean_steps: 7.4100, mean_ecr: 0.0557 mean_entropies: 2.4808, took: 104.7454s
2022-10-09 18:10:44,623 [INFO] 	Process 1 - batch 499: mean_policy_losses: 539.078, mean_net_lifetime: 4472.6842, mean_mc_travel_dist: 2365.2567, mean_rewards: 171.8568, total_rewards: 2136.9718, mean_steps: 25.1200, mean_ecr: 0.0405 mean_entropies: 2.6138, took: 311.9580s
2022-10-09 18:11:17,542 [INFO] 	Process 5 - batch 599: mean_policy_losses: -107.506, mean_net_lifetime: 3282.0098, mean_mc_travel_dist: 2168.2322, mean_rewards: 140.9202, total_rewards: 1169.9520, mean_steps: 21.9800, mean_ecr: 0.0306 mean_entropies: 2.8411, took: 269.3931s
2022-10-09 18:11:24,287 [INFO] 	Process 6 - batch 1499: mean_policy_losses: -777.559, mean_net_lifetime: 1234.3557, mean_mc_travel_dist: 906.4979, mean_rewards: 149.8323, total_rewards: 392.4355, mean_steps: 7.3900, mean_ecr: 0.0557 mean_entropies: 2.4213, took: 102.1965s
2022-10-09 18:12:04,890 [INFO] 	Process 3 - batch 699: mean_policy_losses: 438.559, mean_net_lifetime: 3651.0767, mean_mc_travel_dist: 1828.1963, mean_rewards: 175.6516, total_rewards: 1855.5581, mean_steps: 19.8400, mean_ecr: 0.0467 mean_entropies: 2.5721, took: 245.2950s
2022-10-09 18:12:36,977 [INFO] 	Process 7 - batch 699: mean_policy_losses: 122.649, mean_net_lifetime: 3407.3629, mean_mc_travel_dist: 1761.9233, mean_rewards: 131.0478, total_rewards: 1685.5566, mean_steps: 25.5200, mean_ecr: 0.0437 mean_entropies: 2.4121, took: 298.3072s
2022-10-09 18:12:43,529 [INFO] 	Process 2 - batch 699: mean_policy_losses: 112.316, mean_net_lifetime: 3256.7388, mean_mc_travel_dist: 1823.4910, mean_rewards: 156.0327, total_rewards: 1479.7339, mean_steps: 19.9400, mean_ecr: 0.0417 mean_entropies: 2.6276, took: 239.2124s
2022-10-09 18:12:49,312 [INFO] 	Process 4 - batch 899: mean_policy_losses: -2.592, mean_net_lifetime: 2530.4481, mean_mc_travel_dist: 1295.8840, mean_rewards: 151.7355, total_rewards: 1254.7989, mean_steps: 15.8400, mean_ecr: 0.0533 mean_entropies: 2.3842, took: 196.9489s
2022-10-09 18:15:59,722 [INFO] 	Process 5 - batch 699: mean_policy_losses: -272.513, mean_net_lifetime: 3303.3183, mean_mc_travel_dist: 2163.7376, mean_rewards: 143.9853, total_rewards: 1192.7213, mean_steps: 21.7900, mean_ecr: 0.0307 mean_entropies: 2.8414, took: 282.1800s
2022-10-09 18:16:16,637 [INFO] 	Process 1 - batch 599: mean_policy_losses: 453.057, mean_net_lifetime: 4598.6503, mean_mc_travel_dist: 2346.9080, mean_rewards: 169.7658, total_rewards: 2293.8451, mean_steps: 26.1900, mean_ecr: 0.0403 mean_entropies: 2.5678, took: 332.0147s
2022-10-09 18:16:22,721 [INFO] 	Process 4 - batch 999: mean_policy_losses: -39.425, mean_net_lifetime: 2539.7481, mean_mc_travel_dist: 1258.8348, mean_rewards: 150.1413, total_rewards: 1297.1003, mean_steps: 16.1400, mean_ecr: 0.0536 mean_entropies: 2.3379, took: 213.4086s
2022-10-09 18:16:25,241 [INFO] 	Process 3 - batch 799: mean_policy_losses: 286.128, mean_net_lifetime: 3613.8016, mean_mc_travel_dist: 1807.2865, mean_rewards: 174.7772, total_rewards: 1846.1359, mean_steps: 19.8200, mean_ecr: 0.0468 mean_entropies: 2.5295, took: 260.3510s
2022-10-09 18:17:02,932 [INFO] 	Process 2 - batch 799: mean_policy_losses: -21.516, mean_net_lifetime: 3175.1718, mean_mc_travel_dist: 1796.5549, mean_rewards: 151.0507, total_rewards: 1427.0867, mean_steps: 20.1400, mean_ecr: 0.0419 mean_entropies: 2.5982, took: 259.4037s
2022-10-09 18:17:37,551 [INFO] 	Process 7 - batch 799: mean_policy_losses: -27.034, mean_net_lifetime: 3207.5879, mean_mc_travel_dist: 1680.5227, mean_rewards: 132.7979, total_rewards: 1579.5804, mean_steps: 23.5600, mean_ecr: 0.0438 mean_entropies: 2.3989, took: 300.5733s
2022-10-09 18:19:51,460 [INFO] 	Process 4 - batch 1099: mean_policy_losses: -65.294, mean_net_lifetime: 2581.4845, mean_mc_travel_dist: 1284.2445, mean_rewards: 147.3931, total_rewards: 1321.1216, mean_steps: 16.6700, mean_ecr: 0.0535 mean_entropies: 2.3201, took: 208.7393s
2022-10-09 18:20:30,496 [INFO] 	Process 5 - batch 799: mean_policy_losses: -196.757, mean_net_lifetime: 3467.1797, mean_mc_travel_dist: 2170.6705, mean_rewards: 147.7876, total_rewards: 1359.1678, mean_steps: 22.1300, mean_ecr: 0.0308 mean_entropies: 2.7967, took: 270.7741s
2022-10-09 18:20:52,424 [INFO] 	Process 3 - batch 899: mean_policy_losses: 277.810, mean_net_lifetime: 3691.2976, mean_mc_travel_dist: 1770.5737, mean_rewards: 165.1953, total_rewards: 1950.3787, mean_steps: 21.5900, mean_ecr: 0.0471 mean_entropies: 2.4321, took: 267.1819s
2022-10-09 18:21:11,534 [INFO] 	Process 2 - batch 899: mean_policy_losses: -88.027, mean_net_lifetime: 3115.8449, mean_mc_travel_dist: 1757.6479, mean_rewards: 144.0049, total_rewards: 1395.3859, mean_steps: 20.7700, mean_ecr: 0.0420 mean_entropies: 2.4857, took: 248.6022s
2022-10-09 18:21:39,734 [INFO] 	Process 1 - batch 699: mean_policy_losses: 403.471, mean_net_lifetime: 4686.8234, mean_mc_travel_dist: 2400.4036, mean_rewards: 168.9994, total_rewards: 2322.5925, mean_steps: 26.8100, mean_ecr: 0.0403 mean_entropies: 2.5659, took: 323.0946s
2022-10-09 18:22:20,936 [INFO] 	Process 7 - batch 899: mean_policy_losses: 38.924, mean_net_lifetime: 3472.6363, mean_mc_travel_dist: 1734.7419, mean_rewards: 134.2982, total_rewards: 1775.3929, mean_steps: 25.0000, mean_ecr: 0.0437 mean_entropies: 2.4043, took: 283.3862s
2022-10-09 18:23:05,484 [INFO] 	Process 4 - batch 1199: mean_policy_losses: -108.052, mean_net_lifetime: 2511.9237, mean_mc_travel_dist: 1261.1164, mean_rewards: 144.9975, total_rewards: 1269.3629, mean_steps: 16.5800, mean_ecr: 0.0534 mean_entropies: 2.2726, took: 194.0244s
2022-10-09 18:24:54,831 [INFO] 	Process 5 - batch 899: mean_policy_losses: -255.013, mean_net_lifetime: 3437.1707, mean_mc_travel_dist: 2150.2302, mean_rewards: 147.0846, total_rewards: 1338.8775, mean_steps: 22.0600, mean_ecr: 0.0309 mean_entropies: 2.7837, took: 264.3351s
2022-10-09 18:25:18,192 [INFO] 	Process 3 - batch 999: mean_policy_losses: 228.471, mean_net_lifetime: 3653.7163, mean_mc_travel_dist: 1750.1108, mean_rewards: 161.7282, total_rewards: 1941.2821, mean_steps: 21.7600, mean_ecr: 0.0471 mean_entropies: 2.3870, took: 265.7682s
2022-10-09 18:25:29,812 [INFO] 	Process 2 - batch 999: mean_policy_losses: -48.670, mean_net_lifetime: 3263.8595, mean_mc_travel_dist: 1769.5555, mean_rewards: 145.5902, total_rewards: 1526.2597, mean_steps: 21.6300, mean_ecr: 0.0418 mean_entropies: 2.4849, took: 258.2775s
2022-10-09 18:26:40,018 [INFO] 	Process 4 - batch 1299: mean_policy_losses: -128.030, mean_net_lifetime: 2579.0163, mean_mc_travel_dist: 1252.7254, mean_rewards: 149.0625, total_rewards: 1346.9993, mean_steps: 16.4600, mean_ecr: 0.0532 mean_entropies: 2.2393, took: 214.5335s
2022-10-09 18:27:04,212 [INFO] 	Process 1 - batch 799: mean_policy_losses: 336.927, mean_net_lifetime: 4602.0795, mean_mc_travel_dist: 2388.8116, mean_rewards: 167.7959, total_rewards: 2252.3141, mean_steps: 26.5700, mean_ecr: 0.0403 mean_entropies: 2.5573, took: 324.4815s
2022-10-09 18:27:13,700 [INFO] 	Process 7 - batch 999: mean_policy_losses: -25.124, mean_net_lifetime: 3410.2210, mean_mc_travel_dist: 1724.0985, mean_rewards: 143.1288, total_rewards: 1727.3551, mean_steps: 23.3300, mean_ecr: 0.0438 mean_entropies: 2.4159, took: 292.7637s
2022-10-09 18:29:26,522 [INFO] 	Process 5 - batch 999: mean_policy_losses: -187.392, mean_net_lifetime: 3586.0974, mean_mc_travel_dist: 2223.7585, mean_rewards: 150.6726, total_rewards: 1435.1108, mean_steps: 22.4700, mean_ecr: 0.0309 mean_entropies: 2.7737, took: 271.6908s
2022-10-09 18:29:34,707 [INFO] 	Process 3 - batch 1099: mean_policy_losses: 205.055, mean_net_lifetime: 3592.1443, mean_mc_travel_dist: 1714.1408, mean_rewards: 163.5673, total_rewards: 1903.5167, mean_steps: 21.1200, mean_ecr: 0.0469 mean_entropies: 2.3663, took: 256.5127s
2022-10-09 18:29:44,017 [INFO] 	Process 2 - batch 1099: mean_policy_losses: -38.826, mean_net_lifetime: 3299.7693, mean_mc_travel_dist: 1785.2974, mean_rewards: 149.1883, total_rewards: 1549.4955, mean_steps: 21.2300, mean_ecr: 0.0417 mean_entropies: 2.4787, took: 254.2050s
2022-10-09 18:29:59,806 [INFO] 	Process 4 - batch 1399: mean_policy_losses: -162.604, mean_net_lifetime: 2447.8965, mean_mc_travel_dist: 1222.7587, mean_rewards: 139.5676, total_rewards: 1246.7204, mean_steps: 16.7900, mean_ecr: 0.0531 mean_entropies: 2.2197, took: 199.7884s
2022-10-09 18:31:29,475 [INFO] 	Process 7 - batch 1099: mean_policy_losses: 14.733, mean_net_lifetime: 3414.7597, mean_mc_travel_dist: 1747.0878, mean_rewards: 144.7187, total_rewards: 1710.6694, mean_steps: 22.6700, mean_ecr: 0.0436 mean_entropies: 2.4512, took: 255.7755s
2022-10-09 18:32:13,139 [INFO] 	Process 1 - batch 899: mean_policy_losses: 404.048, mean_net_lifetime: 4732.6115, mean_mc_travel_dist: 2429.2856, mean_rewards: 167.6717, total_rewards: 2342.0112, mean_steps: 27.3300, mean_ecr: 0.0402 mean_entropies: 2.5586, took: 308.9268s
2022-10-09 18:33:14,587 [INFO] 	Process 4 - batch 1499: mean_policy_losses: -211.271, mean_net_lifetime: 2462.8568, mean_mc_travel_dist: 1229.1498, mean_rewards: 142.2583, total_rewards: 1256.0636, mean_steps: 16.4200, mean_ecr: 0.0533 mean_entropies: 2.1918, took: 194.7807s
2022-10-09 18:33:35,220 [INFO] 	Process 5 - batch 1099: mean_policy_losses: -295.568, mean_net_lifetime: 3341.5776, mean_mc_travel_dist: 2113.1638, mean_rewards: 147.8760, total_rewards: 1286.1648, mean_steps: 21.3400, mean_ecr: 0.0310 mean_entropies: 2.7579, took: 248.6969s
2022-10-09 18:33:56,467 [INFO] 	Process 3 - batch 1199: mean_policy_losses: 218.975, mean_net_lifetime: 3727.2343, mean_mc_travel_dist: 1765.9070, mean_rewards: 162.8281, total_rewards: 1998.0662, mean_steps: 22.1100, mean_ecr: 0.0471 mean_entropies: 2.3517, took: 261.7627s
2022-10-09 18:33:59,506 [INFO] 	Process 2 - batch 1199: mean_policy_losses: -15.277, mean_net_lifetime: 3402.2586, mean_mc_travel_dist: 1794.6885, mean_rewards: 148.2542, total_rewards: 1641.3811, mean_steps: 22.0600, mean_ecr: 0.0418 mean_entropies: 2.4764, took: 255.4890s
2022-10-09 18:36:09,203 [INFO] 	Process 7 - batch 1199: mean_policy_losses: -62.843, mean_net_lifetime: 3430.4077, mean_mc_travel_dist: 1734.9062, mean_rewards: 139.1914, total_rewards: 1738.0541, mean_steps: 23.8400, mean_ecr: 0.0437 mean_entropies: 2.3888, took: 279.7274s
2022-10-09 18:37:55,863 [INFO] 	Process 1 - batch 999: mean_policy_losses: 305.252, mean_net_lifetime: 4669.3912, mean_mc_travel_dist: 2341.3042, mean_rewards: 160.3095, total_rewards: 2369.7006, mean_steps: 28.3400, mean_ecr: 0.0402 mean_entropies: 2.4678, took: 342.7240s
2022-10-09 18:38:14,035 [INFO] 	Process 5 - batch 1199: mean_policy_losses: -209.763, mean_net_lifetime: 3818.2127, mean_mc_travel_dist: 2328.2954, mean_rewards: 158.4623, total_rewards: 1564.7824, mean_steps: 22.8400, mean_ecr: 0.0309 mean_entropies: 2.7458, took: 278.8157s
2022-10-09 18:38:23,551 [INFO] 	Process 2 - batch 1299: mean_policy_losses: -170.019, mean_net_lifetime: 3310.7776, mean_mc_travel_dist: 1753.7859, mean_rewards: 145.2594, total_rewards: 1589.3194, mean_steps: 21.8500, mean_ecr: 0.0418 mean_entropies: 2.4409, took: 264.0449s
2022-10-09 18:38:27,510 [INFO] 	Process 3 - batch 1299: mean_policy_losses: 119.072, mean_net_lifetime: 3713.5880, mean_mc_travel_dist: 1727.3980, mean_rewards: 161.9132, total_rewards: 2015.0355, mean_steps: 22.1400, mean_ecr: 0.0470 mean_entropies: 2.3031, took: 271.0423s
2022-10-09 18:41:06,510 [INFO] 	Process 7 - batch 1299: mean_policy_losses: -71.982, mean_net_lifetime: 3649.8290, mean_mc_travel_dist: 1776.2861, mean_rewards: 136.0506, total_rewards: 1912.3665, mean_steps: 26.1000, mean_ecr: 0.0437 mean_entropies: 2.3264, took: 297.3069s
2022-10-09 18:42:19,078 [INFO] 	Process 2 - batch 1399: mean_policy_losses: -207.217, mean_net_lifetime: 3282.1501, mean_mc_travel_dist: 1771.8793, mean_rewards: 147.3177, total_rewards: 1553.4164, mean_steps: 21.3600, mean_ecr: 0.0418 mean_entropies: 2.4428, took: 235.5280s
2022-10-09 18:42:39,896 [INFO] 	Process 5 - batch 1299: mean_policy_losses: -249.106, mean_net_lifetime: 3805.3736, mean_mc_travel_dist: 2331.2022, mean_rewards: 153.1215, total_rewards: 1536.9622, mean_steps: 23.6100, mean_ecr: 0.0311 mean_entropies: 2.7214, took: 265.8609s
2022-10-09 18:42:42,056 [INFO] 	Process 3 - batch 1399: mean_policy_losses: 127.623, mean_net_lifetime: 3745.6317, mean_mc_travel_dist: 1732.6516, mean_rewards: 161.5941, total_rewards: 2045.3776, mean_steps: 22.4600, mean_ecr: 0.0472 mean_entropies: 2.2883, took: 254.5469s
2022-10-09 18:43:28,352 [INFO] 	Process 1 - batch 1099: mean_policy_losses: 174.381, mean_net_lifetime: 4594.2093, mean_mc_travel_dist: 2313.0978, mean_rewards: 151.5422, total_rewards: 2311.9256, mean_steps: 29.6300, mean_ecr: 0.0401 mean_entropies: 2.3967, took: 332.4881s
2022-10-09 18:45:42,580 [INFO] 	Process 7 - batch 1399: mean_policy_losses: -134.572, mean_net_lifetime: 3461.5940, mean_mc_travel_dist: 1747.6194, mean_rewards: 139.6130, total_rewards: 1753.9754, mean_steps: 24.0000, mean_ecr: 0.0437 mean_entropies: 2.3496, took: 276.0708s
2022-10-09 18:46:30,753 [INFO] 	Process 2 - batch 1499: mean_policy_losses: -163.432, mean_net_lifetime: 3290.5549, mean_mc_travel_dist: 1746.1641, mean_rewards: 148.2834, total_rewards: 1580.8178, mean_steps: 21.3600, mean_ecr: 0.0420 mean_entropies: 2.3555, took: 251.6741s
2022-10-09 18:47:05,416 [INFO] 	Process 5 - batch 1399: mean_policy_losses: -299.403, mean_net_lifetime: 3642.9816, mean_mc_travel_dist: 2244.3922, mean_rewards: 154.5691, total_rewards: 1466.0484, mean_steps: 22.3500, mean_ecr: 0.0311 mean_entropies: 2.7031, took: 265.5180s
2022-10-09 18:47:15,061 [INFO] 	Process 3 - batch 1499: mean_policy_losses: 73.193, mean_net_lifetime: 3634.5808, mean_mc_travel_dist: 1680.7765, mean_rewards: 155.8250, total_rewards: 1982.9879, mean_steps: 22.5800, mean_ecr: 0.0474 mean_entropies: 2.2116, took: 273.0050s
2022-10-09 18:49:12,390 [INFO] 	Process 1 - batch 1199: mean_policy_losses: 172.639, mean_net_lifetime: 4644.8839, mean_mc_travel_dist: 2344.0746, mean_rewards: 154.4661, total_rewards: 2333.7211, mean_steps: 29.3400, mean_ecr: 0.0400 mean_entropies: 2.3991, took: 344.0375s
2022-10-09 18:50:39,666 [INFO] 	Process 7 - batch 1499: mean_policy_losses: -183.684, mean_net_lifetime: 3608.8885, mean_mc_travel_dist: 1776.5162, mean_rewards: 133.4645, total_rewards: 1875.8833, mean_steps: 26.1300, mean_ecr: 0.0436 mean_entropies: 2.3202, took: 297.0855s
2022-10-09 18:51:25,163 [INFO] 	Process 5 - batch 1499: mean_policy_losses: -316.430, mean_net_lifetime: 3805.4648, mean_mc_travel_dist: 2283.7348, mean_rewards: 155.8240, total_rewards: 1580.5519, mean_steps: 23.2200, mean_ecr: 0.0310 mean_entropies: 2.6950, took: 259.7498s
2022-10-09 18:54:30,624 [INFO] 	Process 1 - batch 1299: mean_policy_losses: 51.798, mean_net_lifetime: 4610.4892, mean_mc_travel_dist: 2333.3131, mean_rewards: 151.6685, total_rewards: 2315.3645, mean_steps: 29.6000, mean_ecr: 0.0401 mean_entropies: 2.3709, took: 318.2356s
2022-10-09 18:56:10,862 [INFO] Process 6 - epoch 1: mean_policy_losses: -477.462, mean_net_lifetime: 1161.3155, mean_mc_travel_dist: 901.6581, mean_entropies: 2.7055, m_net_lifetime_valid: 2766.9405, took: 4175.5795s, (93.0627 / 100 batches)

2022-10-09 18:57:50,959 [INFO] 	Process 6 - batch 1599: mean_policy_losses: -394.450, mean_net_lifetime: 1362.6819, mean_mc_travel_dist: 921.8731, mean_rewards: 161.2393, total_rewards: 500.7749, mean_steps: 7.4400, mean_ecr: 0.0563 mean_entropies: 2.3033, took: 2786.6716s
2022-10-09 18:59:28,162 [INFO] 	Process 6 - batch 1699: mean_policy_losses: 11.614, mean_net_lifetime: 1456.5756, mean_mc_travel_dist: 946.6738, mean_rewards: 166.7274, total_rewards: 580.5890, mean_steps: 7.7700, mean_ecr: 0.0565 mean_entropies: 2.2611, took: 97.2028s
2022-10-09 18:59:36,628 [INFO] 	Process 1 - batch 1399: mean_policy_losses: 628.866, mean_net_lifetime: 4606.7455, mean_mc_travel_dist: 2351.1809, mean_rewards: 160.4284, total_rewards: 2284.1516, mean_steps: 27.9000, mean_ecr: 0.0402 mean_entropies: 2.3983, took: 306.0033s
2022-10-09 19:01:04,236 [INFO] 	Process 6 - batch 1799: mean_policy_losses: -171.404, mean_net_lifetime: 1430.0947, mean_mc_travel_dist: 933.1837, mean_rewards: 163.9208, total_rewards: 563.2374, mean_steps: 7.7600, mean_ecr: 0.0564 mean_entropies: 2.1970, took: 96.0742s
2022-10-09 19:02:43,173 [INFO] 	Process 6 - batch 1899: mean_policy_losses: -196.193, mean_net_lifetime: 1596.4661, mean_mc_travel_dist: 977.0283, mean_rewards: 167.6668, total_rewards: 677.8443, mean_steps: 8.4800, mean_ecr: 0.0566 mean_entropies: 2.1009, took: 98.9383s
2022-10-09 19:04:26,148 [INFO] 	Process 1 - batch 1499: mean_policy_losses: 818.185, mean_net_lifetime: 4494.0804, mean_mc_travel_dist: 2349.8636, mean_rewards: 160.1482, total_rewards: 2175.3215, mean_steps: 27.2400, mean_ecr: 0.0403 mean_entropies: 2.3438, took: 289.5207s
2022-10-09 19:04:26,180 [INFO] 	Process 6 - batch 1999: mean_policy_losses: -86.888, mean_net_lifetime: 1466.6470, mean_mc_travel_dist: 935.6078, mean_rewards: 164.1705, total_rewards: 588.5729, mean_steps: 7.9100, mean_ecr: 0.0565 mean_entropies: 2.0649, took: 103.0059s
2022-10-09 19:06:08,416 [INFO] 	Process 6 - batch 2099: mean_policy_losses: 75.374, mean_net_lifetime: 1486.4642, mean_mc_travel_dist: 950.2907, mean_rewards: 161.3960, total_rewards: 596.5136, mean_steps: 8.2000, mean_ecr: 0.0565 mean_entropies: 2.0426, took: 102.2370s
2022-10-09 19:07:52,417 [INFO] 	Process 6 - batch 2199: mean_policy_losses: 90.755, mean_net_lifetime: 1622.3142, mean_mc_travel_dist: 998.0295, mean_rewards: 175.8009, total_rewards: 690.8512, mean_steps: 8.1600, mean_ecr: 0.0566 mean_entropies: 2.0509, took: 103.9996s
2022-10-09 19:09:25,601 [INFO] 	Process 6 - batch 2299: mean_policy_losses: 27.393, mean_net_lifetime: 1676.0500, mean_mc_travel_dist: 1016.1453, mean_rewards: 176.1700, total_rewards: 722.5387, mean_steps: 8.4200, mean_ecr: 0.0568 mean_entropies: 2.0150, took: 93.1842s
2022-10-09 19:11:05,503 [INFO] 	Process 6 - batch 2399: mean_policy_losses: 56.840, mean_net_lifetime: 1737.8807, mean_mc_travel_dist: 1021.5301, mean_rewards: 180.2074, total_rewards: 775.9213, mean_steps: 8.5300, mean_ecr: 0.0570 mean_entropies: 1.9601, took: 99.9029s
2022-10-09 19:12:47,063 [INFO] 	Process 6 - batch 2499: mean_policy_losses: -44.394, mean_net_lifetime: 1744.7017, mean_mc_travel_dist: 1006.7368, mean_rewards: 180.6241, total_rewards: 791.1082, mean_steps: 8.5900, mean_ecr: 0.0570 mean_entropies: 1.8875, took: 101.5600s
2022-10-09 19:14:41,168 [INFO] 	Process 6 - batch 2599: mean_policy_losses: 31.726, mean_net_lifetime: 1957.2346, mean_mc_travel_dist: 1067.8176, mean_rewards: 187.1037, total_rewards: 939.2122, mean_steps: 9.4100, mean_ecr: 0.0569 mean_entropies: 1.8323, took: 114.1048s
2022-10-09 19:16:34,907 [INFO] 	Process 6 - batch 2699: mean_policy_losses: -17.291, mean_net_lifetime: 1867.7925, mean_mc_travel_dist: 1059.6455, mean_rewards: 175.1423, total_rewards: 867.6478, mean_steps: 9.5300, mean_ecr: 0.0569 mean_entropies: 1.7796, took: 113.7390s
2022-10-09 19:18:37,013 [INFO] 	Process 6 - batch 2799: mean_policy_losses: 24.557, mean_net_lifetime: 1855.3381, mean_mc_travel_dist: 1047.0596, mean_rewards: 172.5182, total_rewards: 870.5713, mean_steps: 9.5500, mean_ecr: 0.0570 mean_entropies: 1.7026, took: 122.1063s
2022-10-09 19:20:26,050 [INFO] Process 4 - epoch 1: mean_policy_losses: 81.865, mean_net_lifetime: 2443.9475, mean_mc_travel_dist: 1345.5805, mean_entropies: 2.5437, m_net_lifetime_valid: 2785.7156, took: 5631.1309s, (174.9791 / 100 batches)

2022-10-09 19:20:45,733 [INFO] 	Process 6 - batch 2899: mean_policy_losses: -28.773, mean_net_lifetime: 2057.6184, mean_mc_travel_dist: 1095.8402, mean_rewards: 185.8196, total_rewards: 1011.5952, mean_steps: 9.9700, mean_ecr: 0.0566 mean_entropies: 1.6634, took: 128.7200s
2022-10-09 19:22:50,018 [INFO] 	Process 6 - batch 2999: mean_policy_losses: -89.911, mean_net_lifetime: 2135.2739, mean_mc_travel_dist: 1127.2320, mean_rewards: 186.3274, total_rewards: 1071.3918, mean_steps: 10.3400, mean_ecr: 0.0569 mean_entropies: 1.6057, took: 124.2844s
2022-10-09 19:24:04,380 [INFO] 	Process 4 - batch 1599: mean_policy_losses: 60.611, mean_net_lifetime: 2436.3333, mean_mc_travel_dist: 1150.7122, mean_rewards: 120.8969, total_rewards: 1295.5347, mean_steps: 19.3100, mean_ecr: 0.0536 mean_entropies: 1.7053, took: 3049.7928s
2022-10-09 19:27:37,877 [INFO] 	Process 4 - batch 1699: mean_policy_losses: 42.427, mean_net_lifetime: 2475.7462, mean_mc_travel_dist: 1161.7756, mean_rewards: 126.9003, total_rewards: 1325.0849, mean_steps: 18.6800, mean_ecr: 0.0537 mean_entropies: 1.7621, took: 213.4970s
2022-10-09 19:31:02,700 [INFO] 	Process 4 - batch 1799: mean_policy_losses: 34.379, mean_net_lifetime: 2475.2365, mean_mc_travel_dist: 1162.4644, mean_rewards: 127.8001, total_rewards: 1327.1535, mean_steps: 18.5700, mean_ecr: 0.0535 mean_entropies: 1.8224, took: 204.8235s
2022-10-09 19:32:56,770 [INFO] Process 3 - epoch 1: mean_policy_losses: 312.789, mean_net_lifetime: 3438.8556, mean_mc_travel_dist: 1784.6147, mean_entropies: 2.5630, m_net_lifetime_valid: 2860.8176, took: 6381.2872s, (227.4735 / 100 batches)

2022-10-09 19:34:34,817 [INFO] 	Process 4 - batch 1899: mean_policy_losses: -0.538, mean_net_lifetime: 2441.0740, mean_mc_travel_dist: 1162.5386, mean_rewards: 125.6425, total_rewards: 1287.2488, mean_steps: 18.6100, mean_ecr: 0.0537 mean_entropies: 1.8424, took: 212.1170s
2022-10-09 19:34:42,669 [INFO] Process 2 - epoch 1: mean_policy_losses: 74.975, mean_net_lifetime: 3172.0806, mean_mc_travel_dist: 1827.1883, mean_entropies: 2.6315, m_net_lifetime_valid: 2839.1292, took: 6487.9586s, (224.7525 / 100 batches)

2022-10-09 19:37:35,891 [INFO] Process 7 - epoch 1: mean_policy_losses: 53.811, mean_net_lifetime: 3142.9768, mean_mc_travel_dist: 1718.7477, mean_entropies: 2.5434, m_net_lifetime_valid: 2906.6777, took: 6661.0285s, (240.3001 / 100 batches)

2022-10-09 19:38:18,657 [INFO] 	Process 4 - batch 1999: mean_policy_losses: 41.583, mean_net_lifetime: 2559.2871, mean_mc_travel_dist: 1189.4683, mean_rewards: 135.3251, total_rewards: 1383.3705, mean_steps: 18.1100, mean_ecr: 0.0534 mean_entropies: 1.9439, took: 223.8399s
2022-10-09 19:38:34,593 [INFO] 	Process 3 - batch 1599: mean_policy_losses: 162.121, mean_net_lifetime: 3468.8699, mean_mc_travel_dist: 1655.4578, mean_rewards: 119.5763, total_rewards: 1828.9298, mean_steps: 28.6100, mean_ecr: 0.0480 mean_entropies: 1.6515, took: 3079.5323s
2022-10-09 19:39:42,042 [INFO] 	Process 2 - batch 1599: mean_policy_losses: -98.454, mean_net_lifetime: 2808.6621, mean_mc_travel_dist: 1586.3053, mean_rewards: 109.1085, total_rewards: 1248.5618, mean_steps: 24.9000, mean_ecr: 0.0427 mean_entropies: 1.7861, took: 3191.2893s
2022-10-09 19:40:35,223 [INFO] Process 5 - epoch 1: mean_policy_losses: -147.119, mean_net_lifetime: 3349.2267, mean_mc_travel_dist: 2185.5977, mean_entropies: 2.8168, m_net_lifetime_valid: 2848.6289, took: 6840.3992s, (243.1461 / 100 batches)

2022-10-09 19:42:01,013 [INFO] 	Process 4 - batch 2099: mean_policy_losses: 8.977, mean_net_lifetime: 2644.3766, mean_mc_travel_dist: 1244.3607, mean_rewards: 142.8389, total_rewards: 1414.2926, mean_steps: 17.6700, mean_ecr: 0.0533 mean_entropies: 2.1130, took: 222.3561s
2022-10-09 19:42:33,741 [INFO] 	Process 7 - batch 1599: mean_policy_losses: 200.089, mean_net_lifetime: 3618.6877, mean_mc_travel_dist: 1784.1360, mean_rewards: 143.8612, total_rewards: 1866.1860, mean_steps: 24.4800, mean_ecr: 0.0435 mean_entropies: 2.3724, took: 3114.0748s
2022-10-09 19:43:37,192 [INFO] 	Process 3 - batch 1699: mean_policy_losses: 220.622, mean_net_lifetime: 3523.5991, mean_mc_travel_dist: 1635.3517, mean_rewards: 140.0370, total_rewards: 1911.1111, mean_steps: 24.5200, mean_ecr: 0.0477 mean_entropies: 1.8615, took: 302.5993s
2022-10-09 19:44:27,509 [INFO] 	Process 2 - batch 1699: mean_policy_losses: -43.957, mean_net_lifetime: 2949.0921, mean_mc_travel_dist: 1623.4595, mean_rewards: 120.5757, total_rewards: 1359.3489, mean_steps: 23.6900, mean_ecr: 0.0424 mean_entropies: 1.9533, took: 285.4672s
2022-10-09 19:44:57,745 [INFO] 	Process 5 - batch 1599: mean_policy_losses: -278.606, mean_net_lifetime: 2720.7985, mean_mc_travel_dist: 1723.9056, mean_rewards: 121.3357, total_rewards: 1040.2094, mean_steps: 21.2700, mean_ecr: 0.0310 mean_entropies: 2.3733, took: 3212.5810s
2022-10-09 19:45:38,415 [INFO] 	Process 4 - batch 2199: mean_policy_losses: -19.527, mean_net_lifetime: 2558.9497, mean_mc_travel_dist: 1218.4548, mean_rewards: 142.6121, total_rewards: 1355.1778, mean_steps: 17.1300, mean_ecr: 0.0534 mean_entropies: 2.1198, took: 217.4015s
2022-10-09 19:47:07,376 [INFO] 	Process 7 - batch 1699: mean_policy_losses: 111.772, mean_net_lifetime: 3398.5544, mean_mc_travel_dist: 1766.5691, mean_rewards: 144.4195, total_rewards: 1678.0480, mean_steps: 22.5500, mean_ecr: 0.0436 mean_entropies: 2.4140, took: 273.6348s
2022-10-09 19:48:57,341 [INFO] 	Process 3 - batch 1799: mean_policy_losses: 228.272, mean_net_lifetime: 3588.1514, mean_mc_travel_dist: 1642.9058, mean_rewards: 138.7869, total_rewards: 1963.4760, mean_steps: 25.2100, mean_ecr: 0.0477 mean_entropies: 1.9162, took: 320.1477s
2022-10-09 19:49:22,289 [INFO] 	Process 2 - batch 1799: mean_policy_losses: -45.723, mean_net_lifetime: 3023.0724, mean_mc_travel_dist: 1616.8753, mean_rewards: 123.0762, total_rewards: 1435.9815, mean_steps: 23.7500, mean_ecr: 0.0422 mean_entropies: 2.0026, took: 294.7797s
2022-10-09 19:49:22,953 [INFO] 	Process 5 - batch 1699: mean_policy_losses: -211.035, mean_net_lifetime: 3020.2038, mean_mc_travel_dist: 1882.7770, mean_rewards: 134.5538, total_rewards: 1197.0794, mean_steps: 21.1100, mean_ecr: 0.0310 mean_entropies: 2.5046, took: 265.2080s
2022-10-09 19:49:24,256 [INFO] 	Process 4 - batch 2299: mean_policy_losses: -63.396, mean_net_lifetime: 2556.9424, mean_mc_travel_dist: 1244.2513, mean_rewards: 138.1623, total_rewards: 1332.1906, mean_steps: 17.7300, mean_ecr: 0.0529 mean_entropies: 2.0999, took: 225.8409s
2022-10-09 19:49:28,109 [INFO] Process 1 - epoch 1: mean_policy_losses: 481.976, mean_net_lifetime: 4519.0604, mean_mc_travel_dist: 2368.3988, mean_entropies: 2.5722, m_net_lifetime_valid: 2857.3567, took: 7373.3097s, (291.9593 / 100 batches)

2022-10-09 19:51:57,624 [INFO] 	Process 7 - batch 1799: mean_policy_losses: 87.726, mean_net_lifetime: 3545.4271, mean_mc_travel_dist: 1785.0047, mean_rewards: 145.9080, total_rewards: 1794.4599, mean_steps: 23.5400, mean_ecr: 0.0435 mean_entropies: 2.3842, took: 290.2477s
2022-10-09 19:53:12,444 [INFO] 	Process 4 - batch 2399: mean_policy_losses: -134.610, mean_net_lifetime: 2679.3881, mean_mc_travel_dist: 1249.6539, mean_rewards: 140.5077, total_rewards: 1453.3172, mean_steps: 18.1700, mean_ecr: 0.0531 mean_entropies: 2.0433, took: 228.1876s
2022-10-09 19:53:55,807 [INFO] 	Process 5 - batch 1799: mean_policy_losses: -201.985, mean_net_lifetime: 3500.7395, mean_mc_travel_dist: 2071.7926, mean_rewards: 146.8044, total_rewards: 1486.7499, mean_steps: 22.3400, mean_ecr: 0.0312 mean_entropies: 2.5570, took: 272.8550s
2022-10-09 19:54:01,714 [INFO] 	Process 3 - batch 1899: mean_policy_losses: 143.786, mean_net_lifetime: 3655.1815, mean_mc_travel_dist: 1657.1203, mean_rewards: 145.2258, total_rewards: 2023.7487, mean_steps: 24.4800, mean_ecr: 0.0477 mean_entropies: 1.9207, took: 304.3739s
2022-10-09 19:54:08,297 [INFO] 	Process 2 - batch 1899: mean_policy_losses: -192.097, mean_net_lifetime: 2999.2736, mean_mc_travel_dist: 1615.4328, mean_rewards: 122.4305, total_rewards: 1411.0942, mean_steps: 23.6900, mean_ecr: 0.0423 mean_entropies: 2.0065, took: 286.0079s
2022-10-09 19:54:57,426 [INFO] 	Process 1 - batch 1599: mean_policy_losses: 331.499, mean_net_lifetime: 4603.4404, mean_mc_travel_dist: 2401.4445, mean_rewards: 164.6886, total_rewards: 2234.0064, mean_steps: 27.0800, mean_ecr: 0.0402 mean_entropies: 2.4109, took: 3031.2766s
2022-10-09 19:56:57,765 [INFO] 	Process 4 - batch 2499: mean_policy_losses: -149.784, mean_net_lifetime: 2555.5304, mean_mc_travel_dist: 1205.6697, mean_rewards: 139.6760, total_rewards: 1370.1166, mean_steps: 17.5500, mean_ecr: 0.0535 mean_entropies: 1.9848, took: 225.3208s
2022-10-09 19:57:13,737 [INFO] 	Process 7 - batch 1899: mean_policy_losses: 70.953, mean_net_lifetime: 3701.7504, mean_mc_travel_dist: 1816.1707, mean_rewards: 141.6741, total_rewards: 1921.5901, mean_steps: 25.4100, mean_ecr: 0.0435 mean_entropies: 2.3214, took: 316.1136s
2022-10-09 19:58:51,662 [INFO] 	Process 5 - batch 1899: mean_policy_losses: -118.506, mean_net_lifetime: 3644.4060, mean_mc_travel_dist: 2157.4939, mean_rewards: 151.9463, total_rewards: 1535.6700, mean_steps: 22.5600, mean_ecr: 0.0310 mean_entropies: 2.5885, took: 295.8537s
2022-10-09 19:59:10,680 [INFO] 	Process 2 - batch 1999: mean_policy_losses: -161.871, mean_net_lifetime: 3025.0584, mean_mc_travel_dist: 1627.3193, mean_rewards: 124.2914, total_rewards: 1433.5696, mean_steps: 23.5100, mean_ecr: 0.0422 mean_entropies: 2.0252, took: 302.3832s
2022-10-09 19:59:31,829 [INFO] 	Process 3 - batch 1999: mean_policy_losses: 124.469, mean_net_lifetime: 3618.1155, mean_mc_travel_dist: 1634.6254, mean_rewards: 139.6393, total_rewards: 2002.9607, mean_steps: 25.2500, mean_ecr: 0.0476 mean_entropies: 1.9284, took: 330.1138s
2022-10-09 20:00:47,789 [INFO] 	Process 1 - batch 1699: mean_policy_losses: 324.624, mean_net_lifetime: 4567.3782, mean_mc_travel_dist: 2358.3858, mean_rewards: 163.0836, total_rewards: 2250.5317, mean_steps: 27.2100, mean_ecr: 0.0403 mean_entropies: 2.3872, took: 350.3636s
2022-10-09 20:00:51,005 [INFO] 	Process 4 - batch 2599: mean_policy_losses: -141.131, mean_net_lifetime: 2616.5255, mean_mc_travel_dist: 1245.0343, mean_rewards: 138.2562, total_rewards: 1390.9011, mean_steps: 18.1700, mean_ecr: 0.0533 mean_entropies: 2.0125, took: 233.2409s
2022-10-09 20:02:12,851 [INFO] 	Process 7 - batch 1999: mean_policy_losses: 32.410, mean_net_lifetime: 3577.5876, mean_mc_travel_dist: 1764.8819, mean_rewards: 145.5586, total_rewards: 1843.0943, mean_steps: 23.7800, mean_ecr: 0.0436 mean_entropies: 2.3526, took: 299.1136s
2022-10-09 20:03:42,706 [INFO] 	Process 5 - batch 1999: mean_policy_losses: -70.349, mean_net_lifetime: 3781.3469, mean_mc_travel_dist: 2208.2714, mean_rewards: 154.2994, total_rewards: 1621.9939, mean_steps: 23.1000, mean_ecr: 0.0310 mean_entropies: 2.6109, took: 291.0442s
2022-10-09 20:04:07,452 [INFO] 	Process 2 - batch 2099: mean_policy_losses: -93.728, mean_net_lifetime: 3203.8965, mean_mc_travel_dist: 1669.9681, mean_rewards: 129.6708, total_rewards: 1558.8699, mean_steps: 23.9000, mean_ecr: 0.0420 mean_entropies: 2.0670, took: 296.7717s
2022-10-09 20:04:43,438 [INFO] 	Process 4 - batch 2699: mean_policy_losses: -201.815, mean_net_lifetime: 2489.9370, mean_mc_travel_dist: 1210.4769, mean_rewards: 133.5914, total_rewards: 1302.6334, mean_steps: 17.9200, mean_ecr: 0.0535 mean_entropies: 1.9863, took: 232.4326s
2022-10-09 20:04:47,236 [INFO] 	Process 3 - batch 2099: mean_policy_losses: 179.588, mean_net_lifetime: 3701.6239, mean_mc_travel_dist: 1647.7220, mean_rewards: 143.5124, total_rewards: 2074.3043, mean_steps: 25.2000, mean_ecr: 0.0477 mean_entropies: 1.9764, took: 315.4077s
2022-10-09 20:06:25,267 [INFO] 	Process 1 - batch 1799: mean_policy_losses: 286.634, mean_net_lifetime: 4542.2661, mean_mc_travel_dist: 2359.0579, mean_rewards: 152.6665, total_rewards: 2218.0114, mean_steps: 29.0100, mean_ecr: 0.0400 mean_entropies: 2.3327, took: 337.4781s
2022-10-09 20:06:50,489 [INFO] 	Process 7 - batch 2099: mean_policy_losses: 56.666, mean_net_lifetime: 3709.0127, mean_mc_travel_dist: 1775.6044, mean_rewards: 131.8267, total_rewards: 1962.3762, mean_steps: 27.6400, mean_ecr: 0.0436 mean_entropies: 2.2549, took: 277.6389s
2022-10-09 20:07:08,551 [INFO] 	Process 4 - batch 2799: mean_policy_losses: -215.714, mean_net_lifetime: 2464.2124, mean_mc_travel_dist: 1184.6721, mean_rewards: 130.6744, total_rewards: 1292.5487, mean_steps: 18.0900, mean_ecr: 0.0534 mean_entropies: 1.9616, took: 145.1137s
2022-10-09 20:07:11,149 [INFO] 	Process 5 - batch 2099: mean_policy_losses: 27.354, mean_net_lifetime: 4019.4975, mean_mc_travel_dist: 2326.4502, mean_rewards: 155.5412, total_rewards: 1744.8778, mean_steps: 24.5300, mean_ecr: 0.0310 mean_entropies: 2.6424, took: 208.4443s
2022-10-09 20:07:16,025 [INFO] 	Process 2 - batch 2199: mean_policy_losses: -132.051, mean_net_lifetime: 3145.3068, mean_mc_travel_dist: 1668.0655, mean_rewards: 130.7613, total_rewards: 1500.3063, mean_steps: 23.2800, mean_ecr: 0.0421 mean_entropies: 2.1101, took: 188.5736s
2022-10-09 20:07:36,122 [INFO] Process 6 - epoch 2: mean_policy_losses: -262.433, mean_net_lifetime: 1429.0956, mean_mc_travel_dist: 954.3189, mean_entropies: 2.3350, m_net_lifetime_valid: 2777.4723, took: 4285.2597s, (186.2817 / 100 batches)

2022-10-09 20:07:39,855 [INFO] 	Process 3 - batch 2199: mean_policy_losses: 190.034, mean_net_lifetime: 3750.3653, mean_mc_travel_dist: 1664.0562, mean_rewards: 147.3076, total_rewards: 2107.5451, mean_steps: 24.8300, mean_ecr: 0.0472 mean_entropies: 2.0106, took: 172.6193s
2022-10-09 20:08:21,846 [INFO] 	Process 6 - batch 3099: mean_policy_losses: -735.024, mean_net_lifetime: 1529.1010, mean_mc_travel_dist: 959.5247, mean_rewards: 168.9708, total_rewards: 623.7487, mean_steps: 8.0300, mean_ecr: 0.0562 mean_entropies: 2.1885, took: 2731.8283s
2022-10-09 20:08:44,774 [INFO] 	Process 4 - batch 2899: mean_policy_losses: -75.139, mean_net_lifetime: 2586.6030, mean_mc_travel_dist: 1206.2327, mean_rewards: 133.0996, total_rewards: 1401.4692, mean_steps: 18.6200, mean_ecr: 0.0531 mean_entropies: 1.9112, took: 96.2231s
2022-10-09 20:08:59,407 [INFO] 	Process 1 - batch 1899: mean_policy_losses: 309.500, mean_net_lifetime: 4597.2132, mean_mc_travel_dist: 2326.7702, mean_rewards: 145.4542, total_rewards: 2300.3726, mean_steps: 30.8700, mean_ecr: 0.0400 mean_entropies: 2.2588, took: 154.1409s
2022-10-09 20:09:07,761 [INFO] 	Process 5 - batch 2199: mean_policy_losses: 59.057, mean_net_lifetime: 3819.9297, mean_mc_travel_dist: 2264.2703, mean_rewards: 154.7692, total_rewards: 1614.7212, mean_steps: 23.5600, mean_ecr: 0.0310 mean_entropies: 2.6166, took: 116.6120s
2022-10-09 20:09:09,855 [INFO] 	Process 6 - batch 3199: mean_policy_losses: -626.876, mean_net_lifetime: 1522.5985, mean_mc_travel_dist: 958.4697, mean_rewards: 161.2291, total_rewards: 616.9546, mean_steps: 8.4500, mean_ecr: 0.0565 mean_entropies: 2.0432, took: 48.0086s
2022-10-09 20:09:15,269 [INFO] 	Process 7 - batch 2199: mean_policy_losses: 189.010, mean_net_lifetime: 3819.4057, mean_mc_travel_dist: 1821.9310, mean_rewards: 127.4112, total_rewards: 2028.7262, mean_steps: 29.5000, mean_ecr: 0.0436 mean_entropies: 2.2335, took: 144.7797s
2022-10-09 20:09:15,332 [INFO] 	Process 2 - batch 2299: mean_policy_losses: 12.600, mean_net_lifetime: 3160.8530, mean_mc_travel_dist: 1656.2843, mean_rewards: 127.9406, total_rewards: 1533.9604, mean_steps: 23.8400, mean_ecr: 0.0421 mean_entropies: 2.0110, took: 119.3066s
2022-10-09 20:09:55,960 [INFO] 	Process 6 - batch 3299: mean_policy_losses: -628.978, mean_net_lifetime: 1529.8819, mean_mc_travel_dist: 961.2847, mean_rewards: 166.5108, total_rewards: 633.8252, mean_steps: 8.2100, mean_ecr: 0.0565 mean_entropies: 2.0827, took: 46.1052s
2022-10-09 20:09:56,184 [INFO] 	Process 3 - batch 2299: mean_policy_losses: 304.457, mean_net_lifetime: 3708.1507, mean_mc_travel_dist: 1624.0045, mean_rewards: 135.9658, total_rewards: 2109.1850, mean_steps: 26.7100, mean_ecr: 0.0478 mean_entropies: 1.8643, took: 136.3281s
2022-10-09 20:10:25,781 [INFO] 	Process 4 - batch 2999: mean_policy_losses: -48.231, mean_net_lifetime: 2455.9730, mean_mc_travel_dist: 1174.5181, mean_rewards: 120.2772, total_rewards: 1291.5587, mean_steps: 19.7200, mean_ecr: 0.0533 mean_entropies: 1.8024, took: 101.0067s
2022-10-09 20:10:42,796 [INFO] 	Process 6 - batch 3399: mean_policy_losses: -614.941, mean_net_lifetime: 1550.1570, mean_mc_travel_dist: 954.2730, mean_rewards: 165.0098, total_rewards: 660.0796, mean_steps: 8.4000, mean_ecr: 0.0564 mean_entropies: 1.9772, took: 46.8369s
2022-10-09 20:11:06,487 [INFO] 	Process 5 - batch 2299: mean_policy_losses: 171.101, mean_net_lifetime: 3918.1918, mean_mc_travel_dist: 2286.3502, mean_rewards: 156.6092, total_rewards: 1697.3283, mean_steps: 23.5700, mean_ecr: 0.0312 mean_entropies: 2.5816, took: 118.7255s
2022-10-09 20:11:14,392 [INFO] 	Process 2 - batch 2399: mean_policy_losses: 46.993, mean_net_lifetime: 3157.6633, mean_mc_travel_dist: 1630.5497, mean_rewards: 126.0801, total_rewards: 1548.5135, mean_steps: 24.2500, mean_ecr: 0.0421 mean_entropies: 1.8985, took: 119.0606s
2022-10-09 20:11:29,152 [INFO] 	Process 6 - batch 3499: mean_policy_losses: -656.835, mean_net_lifetime: 1445.3345, mean_mc_travel_dist: 922.6175, mean_rewards: 156.6512, total_rewards: 580.7606, mean_steps: 8.3500, mean_ecr: 0.0561 mean_entropies: 1.9302, took: 46.3561s
2022-10-09 20:11:31,837 [INFO] 	Process 1 - batch 1999: mean_policy_losses: 371.474, mean_net_lifetime: 4546.9143, mean_mc_travel_dist: 2333.9245, mean_rewards: 139.7101, total_rewards: 2239.4923, mean_steps: 31.8400, mean_ecr: 0.0400 mean_entropies: 2.1423, took: 152.4294s
2022-10-09 20:11:39,547 [INFO] 	Process 7 - batch 2299: mean_policy_losses: 205.866, mean_net_lifetime: 3787.1285, mean_mc_travel_dist: 1823.1947, mean_rewards: 123.9520, total_rewards: 1993.9528, mean_steps: 29.9200, mean_ecr: 0.0435 mean_entropies: 2.1673, took: 144.2780s
2022-10-09 20:12:12,780 [INFO] 	Process 3 - batch 2399: mean_policy_losses: 252.295, mean_net_lifetime: 3672.7986, mean_mc_travel_dist: 1616.3091, mean_rewards: 132.3594, total_rewards: 2084.6399, mean_steps: 27.2500, mean_ecr: 0.0477 mean_entropies: 1.7910, took: 136.5964s
2022-10-09 20:12:18,530 [INFO] 	Process 6 - batch 3599: mean_policy_losses: -590.806, mean_net_lifetime: 1513.9542, mean_mc_travel_dist: 952.6474, mean_rewards: 158.3251, total_rewards: 622.1613, mean_steps: 8.6300, mean_ecr: 0.0563 mean_entropies: 1.9237, took: 49.3761s
2022-10-09 20:13:04,816 [INFO] 	Process 5 - batch 2399: mean_policy_losses: 144.971, mean_net_lifetime: 3948.8212, mean_mc_travel_dist: 2289.3457, mean_rewards: 157.9010, total_rewards: 1710.7621, mean_steps: 23.7300, mean_ecr: 0.0311 mean_entropies: 2.5656, took: 118.3297s
2022-10-09 20:13:07,647 [INFO] 	Process 6 - batch 3699: mean_policy_losses: -573.988, mean_net_lifetime: 1692.3800, mean_mc_travel_dist: 1002.1894, mean_rewards: 168.7357, total_rewards: 749.1926, mean_steps: 9.0200, mean_ecr: 0.0565 mean_entropies: 1.9981, took: 49.1187s
2022-10-09 20:13:12,205 [INFO] 	Process 2 - batch 2499: mean_policy_losses: -29.583, mean_net_lifetime: 3042.8743, mean_mc_travel_dist: 1616.5697, mean_rewards: 120.6806, total_rewards: 1453.8949, mean_steps: 24.3700, mean_ecr: 0.0422 mean_entropies: 1.8369, took: 117.8129s
2022-10-09 20:13:53,533 [INFO] 	Process 6 - batch 3799: mean_policy_losses: -572.525, mean_net_lifetime: 1683.5837, mean_mc_travel_dist: 1001.5065, mean_rewards: 178.2067, total_rewards: 741.2357, mean_steps: 8.3300, mean_ecr: 0.0570 mean_entropies: 2.0156, took: 45.8851s
2022-10-09 20:13:55,515 [INFO] 	Process 7 - batch 2399: mean_policy_losses: 200.574, mean_net_lifetime: 3783.2940, mean_mc_travel_dist: 1832.7974, mean_rewards: 131.5709, total_rewards: 1974.3576, mean_steps: 28.2500, mean_ecr: 0.0435 mean_entropies: 2.1845, took: 135.9684s
2022-10-09 20:14:02,904 [INFO] 	Process 1 - batch 2099: mean_policy_losses: 332.292, mean_net_lifetime: 4526.8463, mean_mc_travel_dist: 2319.6371, mean_rewards: 139.8593, total_rewards: 2237.5718, mean_steps: 31.7400, mean_ecr: 0.0401 mean_entropies: 2.1154, took: 151.0670s
2022-10-09 20:14:29,623 [INFO] 	Process 3 - batch 2499: mean_policy_losses: 162.771, mean_net_lifetime: 3558.7947, mean_mc_travel_dist: 1602.3152, mean_rewards: 124.5594, total_rewards: 1979.5249, mean_steps: 28.0200, mean_ecr: 0.0481 mean_entropies: 1.7106, took: 136.8439s
2022-10-09 20:14:41,296 [INFO] 	Process 6 - batch 3899: mean_policy_losses: -560.706, mean_net_lifetime: 1701.9846, mean_mc_travel_dist: 1001.0884, mean_rewards: 182.7862, total_rewards: 758.4387, mean_steps: 8.2200, mean_ecr: 0.0568 mean_entropies: 2.0389, took: 47.7640s
2022-10-09 20:15:00,956 [INFO] 	Process 5 - batch 2499: mean_policy_losses: 197.100, mean_net_lifetime: 4085.4821, mean_mc_travel_dist: 2349.7289, mean_rewards: 160.7682, total_rewards: 1801.3274, mean_steps: 23.9000, mean_ecr: 0.0311 mean_entropies: 2.5293, took: 116.1395s
2022-10-09 20:15:14,563 [INFO] 	Process 2 - batch 2599: mean_policy_losses: -30.178, mean_net_lifetime: 3026.4992, mean_mc_travel_dist: 1615.7179, mean_rewards: 115.8534, total_rewards: 1440.7397, mean_steps: 25.2700, mean_ecr: 0.0422 mean_entropies: 1.7601, took: 122.3574s
2022-10-09 20:15:29,409 [INFO] 	Process 6 - batch 3999: mean_policy_losses: -479.582, mean_net_lifetime: 1779.1624, mean_mc_travel_dist: 1028.1424, mean_rewards: 181.6813, total_rewards: 808.9407, mean_steps: 8.6900, mean_ecr: 0.0568 mean_entropies: 2.0240, took: 48.1122s
2022-10-09 20:16:07,272 [INFO] 	Process 7 - batch 2499: mean_policy_losses: 212.806, mean_net_lifetime: 3804.8091, mean_mc_travel_dist: 1852.4434, mean_rewards: 137.5495, total_rewards: 1987.1009, mean_steps: 27.1800, mean_ecr: 0.0436 mean_entropies: 2.2309, took: 131.7557s
2022-10-09 20:16:14,785 [INFO] 	Process 6 - batch 4099: mean_policy_losses: -623.759, mean_net_lifetime: 1566.9109, mean_mc_travel_dist: 970.7451, mean_rewards: 171.3073, total_rewards: 661.5533, mean_steps: 8.1200, mean_ecr: 0.0567 mean_entropies: 2.0063, took: 45.3764s
2022-10-09 20:16:36,516 [INFO] 	Process 1 - batch 2199: mean_policy_losses: 354.427, mean_net_lifetime: 4590.6167, mean_mc_travel_dist: 2353.9167, mean_rewards: 140.5586, total_rewards: 2269.1784, mean_steps: 32.0400, mean_ecr: 0.0399 mean_entropies: 2.1121, took: 153.6113s
2022-10-09 20:16:47,371 [INFO] 	Process 3 - batch 2599: mean_policy_losses: 201.500, mean_net_lifetime: 3565.4951, mean_mc_travel_dist: 1605.9336, mean_rewards: 125.7189, total_rewards: 1984.3655, mean_steps: 27.8400, mean_ecr: 0.0480 mean_entropies: 1.6833, took: 137.7473s
2022-10-09 20:16:52,937 [INFO] 	Process 5 - batch 2599: mean_policy_losses: 159.632, mean_net_lifetime: 3891.8986, mean_mc_travel_dist: 2282.6757, mean_rewards: 159.7097, total_rewards: 1672.0047, mean_steps: 23.0000, mean_ecr: 0.0312 mean_entropies: 2.5224, took: 111.9802s
2022-10-09 20:17:00,344 [INFO] 	Process 6 - batch 4199: mean_policy_losses: -591.251, mean_net_lifetime: 1609.7378, mean_mc_travel_dist: 970.5982, mean_rewards: 175.4501, total_rewards: 693.9595, mean_steps: 8.0800, mean_ecr: 0.0567 mean_entropies: 1.9873, took: 45.5591s
2022-10-09 20:17:16,802 [INFO] 	Process 2 - batch 2699: mean_policy_losses: -6.686, mean_net_lifetime: 3042.4947, mean_mc_travel_dist: 1603.6959, mean_rewards: 116.6830, total_rewards: 1458.4300, mean_steps: 25.2200, mean_ecr: 0.0423 mean_entropies: 1.7598, took: 122.2390s
2022-10-09 20:17:46,812 [INFO] 	Process 6 - batch 4299: mean_policy_losses: -572.432, mean_net_lifetime: 1625.7757, mean_mc_travel_dist: 981.7932, mean_rewards: 175.0248, total_rewards: 699.8877, mean_steps: 8.2300, mean_ecr: 0.0566 mean_entropies: 2.0030, took: 46.4679s
2022-10-09 20:18:15,410 [INFO] 	Process 7 - batch 2599: mean_policy_losses: 210.452, mean_net_lifetime: 3699.6431, mean_mc_travel_dist: 1815.1985, mean_rewards: 136.2046, total_rewards: 1917.9211, mean_steps: 26.5200, mean_ecr: 0.0435 mean_entropies: 2.2055, took: 128.1390s
2022-10-09 20:18:32,393 [INFO] 	Process 6 - batch 4399: mean_policy_losses: -539.993, mean_net_lifetime: 1531.8223, mean_mc_travel_dist: 941.9429, mean_rewards: 169.0066, total_rewards: 639.6051, mean_steps: 8.1000, mean_ecr: 0.0566 mean_entropies: 1.9627, took: 45.5811s
2022-10-09 20:18:52,593 [INFO] 	Process 5 - batch 2699: mean_policy_losses: 216.934, mean_net_lifetime: 4078.8659, mean_mc_travel_dist: 2370.4873, mean_rewards: 161.6301, total_rewards: 1767.7531, mean_steps: 23.9700, mean_ecr: 0.0312 mean_entropies: 2.5164, took: 119.6565s
2022-10-09 20:19:03,746 [INFO] 	Process 3 - batch 2699: mean_policy_losses: 205.483, mean_net_lifetime: 3608.2798, mean_mc_travel_dist: 1600.0587, mean_rewards: 125.5619, total_rewards: 2025.3860, mean_steps: 28.2400, mean_ecr: 0.0480 mean_entropies: 1.6884, took: 136.3755s
2022-10-09 20:19:15,362 [INFO] 	Process 1 - batch 2299: mean_policy_losses: 319.135, mean_net_lifetime: 4514.4789, mean_mc_travel_dist: 2310.3308, mean_rewards: 134.6346, total_rewards: 2236.1472, mean_steps: 32.9500, mean_ecr: 0.0400 mean_entropies: 2.0730, took: 158.8468s
2022-10-09 20:19:19,996 [INFO] 	Process 6 - batch 4499: mean_policy_losses: -554.842, mean_net_lifetime: 1698.2442, mean_mc_travel_dist: 1002.3503, mean_rewards: 174.1475, total_rewards: 762.2294, mean_steps: 8.5500, mean_ecr: 0.0568 mean_entropies: 1.9880, took: 47.6030s
2022-10-09 20:19:20,759 [INFO] 	Process 2 - batch 2799: mean_policy_losses: -6.204, mean_net_lifetime: 3074.3671, mean_mc_travel_dist: 1620.9725, mean_rewards: 116.7421, total_rewards: 1473.8060, mean_steps: 25.5300, mean_ecr: 0.0422 mean_entropies: 1.7657, took: 123.9572s
2022-10-09 20:20:27,943 [INFO] 	Process 7 - batch 2699: mean_policy_losses: 92.884, mean_net_lifetime: 3804.7620, mean_mc_travel_dist: 1847.1988, mean_rewards: 133.1087, total_rewards: 1986.8871, mean_steps: 28.0300, mean_ecr: 0.0435 mean_entropies: 2.1979, took: 132.5333s
2022-10-09 20:20:43,940 [INFO] 	Process 5 - batch 2799: mean_policy_losses: -38.889, mean_net_lifetime: 3961.8966, mean_mc_travel_dist: 2317.0744, mean_rewards: 159.4448, total_rewards: 1703.2647, mean_steps: 23.5300, mean_ecr: 0.0312 mean_entropies: 2.5077, took: 111.3477s
2022-10-09 20:21:17,410 [INFO] 	Process 2 - batch 2899: mean_policy_losses: -141.038, mean_net_lifetime: 3181.0090, mean_mc_travel_dist: 1634.2203, mean_rewards: 124.1090, total_rewards: 1572.0135, mean_steps: 24.7500, mean_ecr: 0.0420 mean_entropies: 1.8446, took: 116.6514s
2022-10-09 20:21:18,927 [INFO] 	Process 3 - batch 2799: mean_policy_losses: 73.903, mean_net_lifetime: 3644.5170, mean_mc_travel_dist: 1599.9866, mean_rewards: 127.8186, total_rewards: 2069.5565, mean_steps: 28.0300, mean_ecr: 0.0480 mean_entropies: 1.7389, took: 135.1807s
2022-10-09 20:21:55,427 [INFO] 	Process 1 - batch 2399: mean_policy_losses: 83.969, mean_net_lifetime: 4508.3726, mean_mc_travel_dist: 2343.9941, mean_rewards: 128.8153, total_rewards: 2201.1573, mean_steps: 34.5100, mean_ecr: 0.0398 mean_entropies: 2.0373, took: 160.0640s
2022-10-09 20:22:37,731 [INFO] 	Process 7 - batch 2799: mean_policy_losses: -2.075, mean_net_lifetime: 3862.6843, mean_mc_travel_dist: 1849.8508, mean_rewards: 135.6037, total_rewards: 2051.9591, mean_steps: 27.8600, mean_ecr: 0.0434 mean_entropies: 2.2316, took: 129.7877s
2022-10-09 20:22:45,020 [INFO] 	Process 5 - batch 2899: mean_policy_losses: -8.550, mean_net_lifetime: 4295.0298, mean_mc_travel_dist: 2498.7697, mean_rewards: 159.8288, total_rewards: 1857.4575, mean_steps: 25.6100, mean_ecr: 0.0312 mean_entropies: 2.5416, took: 121.0799s
2022-10-09 20:23:10,490 [INFO] 	Process 2 - batch 2999: mean_policy_losses: -202.979, mean_net_lifetime: 3191.8158, mean_mc_travel_dist: 1637.6904, mean_rewards: 129.1448, total_rewards: 1576.4417, mean_steps: 23.8500, mean_ecr: 0.0421 mean_entropies: 2.0421, took: 113.0799s
2022-10-09 20:23:19,016 [INFO] 	Process 3 - batch 2899: mean_policy_losses: 90.518, mean_net_lifetime: 3741.6391, mean_mc_travel_dist: 1634.9982, mean_rewards: 147.1747, total_rewards: 2126.5015, mean_steps: 24.8200, mean_ecr: 0.0477 mean_entropies: 1.9415, took: 120.0895s
2022-10-09 20:24:23,254 [INFO] 	Process 1 - batch 2499: mean_policy_losses: 59.300, mean_net_lifetime: 4536.0531, mean_mc_travel_dist: 2294.3619, mean_rewards: 135.4995, total_rewards: 2266.9069, mean_steps: 32.9500, mean_ecr: 0.0400 mean_entropies: 2.1487, took: 147.8281s
2022-10-09 20:24:31,903 [INFO] 	Process 5 - batch 2999: mean_policy_losses: -218.032, mean_net_lifetime: 3938.3555, mean_mc_travel_dist: 2352.8191, mean_rewards: 159.1800, total_rewards: 1645.7813, mean_steps: 23.4500, mean_ecr: 0.0311 mean_entropies: 2.5993, took: 106.8827s
2022-10-09 20:24:39,147 [INFO] 	Process 7 - batch 2899: mean_policy_losses: -116.624, mean_net_lifetime: 3703.7472, mean_mc_travel_dist: 1789.2079, mean_rewards: 134.9821, total_rewards: 1951.5291, mean_steps: 26.8400, mean_ecr: 0.0436 mean_entropies: 2.2598, took: 121.4159s
2022-10-09 20:25:11,630 [INFO] 	Process 3 - batch 2999: mean_policy_losses: 25.171, mean_net_lifetime: 3725.3304, mean_mc_travel_dist: 1638.3815, mean_rewards: 142.9287, total_rewards: 2111.9528, mean_steps: 25.4000, mean_ecr: 0.0478 mean_entropies: 1.9495, took: 112.6136s
2022-10-09 20:26:27,308 [INFO] 	Process 7 - batch 2999: mean_policy_losses: -180.818, mean_net_lifetime: 3666.3520, mean_mc_travel_dist: 1798.3719, mean_rewards: 137.5323, total_rewards: 1908.5813, mean_steps: 26.1300, mean_ecr: 0.0436 mean_entropies: 2.2936, took: 108.1613s
2022-10-09 20:26:37,289 [INFO] 	Process 1 - batch 2599: mean_policy_losses: 19.384, mean_net_lifetime: 4530.1787, mean_mc_travel_dist: 2287.8600, mean_rewards: 139.3353, total_rewards: 2275.1495, mean_steps: 31.8800, mean_ecr: 0.0401 mean_entropies: 2.1983, took: 134.0350s
2022-10-09 20:28:36,350 [INFO] 	Process 1 - batch 2699: mean_policy_losses: 9.517, mean_net_lifetime: 4712.4955, mean_mc_travel_dist: 2356.8910, mean_rewards: 150.5335, total_rewards: 2388.4656, mean_steps: 30.6400, mean_ecr: 0.0400 mean_entropies: 2.2848, took: 119.0606s
2022-10-09 20:30:38,647 [INFO] 	Process 1 - batch 2799: mean_policy_losses: 11.594, mean_net_lifetime: 4650.1383, mean_mc_travel_dist: 2344.3429, mean_rewards: 150.8270, total_rewards: 2342.3756, mean_steps: 30.0800, mean_ecr: 0.0400 mean_entropies: 2.3390, took: 122.2968s
2022-10-09 20:31:00,596 [INFO] Process 4 - epoch 2: mean_policy_losses: 12.202, mean_net_lifetime: 2488.5109, mean_mc_travel_dist: 1273.1330, mean_entropies: 2.2422, m_net_lifetime_valid: 2809.4686, took: 4234.5450s, (278.4148 / 100 batches)

2022-10-09 20:32:17,467 [INFO] 	Process 4 - batch 3099: mean_policy_losses: -158.957, mean_net_lifetime: 2523.3991, mean_mc_travel_dist: 1218.9779, mean_rewards: 136.8404, total_rewards: 1326.3378, mean_steps: 17.6800, mean_ecr: 0.0532 mean_entropies: 2.0241, took: 1311.6857s
2022-10-09 20:32:37,998 [INFO] 	Process 1 - batch 2899: mean_policy_losses: 283.477, mean_net_lifetime: 4586.3222, mean_mc_travel_dist: 2363.7470, mean_rewards: 154.7840, total_rewards: 2267.6965, mean_steps: 28.9900, mean_ecr: 0.0401 mean_entropies: 2.3874, took: 119.3510s
2022-10-09 20:33:34,567 [INFO] 	Process 4 - batch 3199: mean_policy_losses: -147.776, mean_net_lifetime: 2542.5993, mean_mc_travel_dist: 1226.6738, mean_rewards: 138.0556, total_rewards: 1336.6276, mean_steps: 17.5900, mean_ecr: 0.0532 mean_entropies: 2.0589, took: 77.0998s
2022-10-09 20:34:26,185 [INFO] 	Process 1 - batch 2999: mean_policy_losses: 340.126, mean_net_lifetime: 4617.6483, mean_mc_travel_dist: 2403.0908, mean_rewards: 165.9531, total_rewards: 2256.8940, mean_steps: 26.9600, mean_ecr: 0.0400 mean_entropies: 2.4445, took: 108.1864s
2022-10-09 20:34:49,789 [INFO] 	Process 4 - batch 3299: mean_policy_losses: -139.873, mean_net_lifetime: 2622.8866, mean_mc_travel_dist: 1252.9840, mean_rewards: 143.4303, total_rewards: 1388.5419, mean_steps: 17.4300, mean_ecr: 0.0533 mean_entropies: 2.0949, took: 75.2228s
2022-10-09 20:36:02,323 [INFO] 	Process 4 - batch 3399: mean_policy_losses: 92.324, mean_net_lifetime: 2592.4262, mean_mc_travel_dist: 1217.6222, mean_rewards: 143.7337, total_rewards: 1395.5858, mean_steps: 17.2800, mean_ecr: 0.0533 mean_entropies: 2.1240, took: 72.5334s
2022-10-09 20:37:15,652 [INFO] 	Process 4 - batch 3499: mean_policy_losses: 84.910, mean_net_lifetime: 2665.4325, mean_mc_travel_dist: 1268.5142, mean_rewards: 147.3714, total_rewards: 1414.4693, mean_steps: 17.2800, mean_ecr: 0.0530 mean_entropies: 2.1632, took: 73.3290s
2022-10-09 20:37:47,219 [INFO] Process 6 - epoch 3: mean_policy_losses: -373.234, mean_net_lifetime: 1485.6332, mean_mc_travel_dist: 960.8609, mean_entropies: 2.2271, m_net_lifetime_valid: 2876.3189, took: 1811.0961s, (199.2329 / 100 batches)

2022-10-09 20:38:25,619 [INFO] 	Process 6 - batch 4599: mean_policy_losses: -227.327, mean_net_lifetime: 1285.1597, mean_mc_travel_dist: 860.6291, mean_rewards: 144.8663, total_rewards: 487.7199, mean_steps: 7.9000, mean_ecr: 0.0570 mean_entropies: 2.0987, took: 1145.6222s
2022-10-09 20:38:28,906 [INFO] 	Process 4 - batch 3599: mean_policy_losses: 319.038, mean_net_lifetime: 2652.0131, mean_mc_travel_dist: 1245.8763, mean_rewards: 148.9606, total_rewards: 1422.3910, mean_steps: 16.9500, mean_ecr: 0.0531 mean_entropies: 2.1633, took: 73.2538s
2022-10-09 20:39:05,702 [INFO] 	Process 6 - batch 4699: mean_policy_losses: -181.721, mean_net_lifetime: 1479.0241, mean_mc_travel_dist: 946.2316, mean_rewards: 165.1960, total_rewards: 598.6008, mean_steps: 7.8300, mean_ecr: 0.0569 mean_entropies: 2.0461, took: 40.0835s
2022-10-09 20:39:46,559 [INFO] 	Process 6 - batch 4799: mean_policy_losses: -219.494, mean_net_lifetime: 1723.4169, mean_mc_travel_dist: 1011.6261, mean_rewards: 179.9482, total_rewards: 775.9757, mean_steps: 8.4600, mean_ecr: 0.0572 mean_entropies: 1.9421, took: 40.8573s
2022-10-09 20:39:48,072 [INFO] 	Process 4 - batch 3699: mean_policy_losses: 244.413, mean_net_lifetime: 2534.0335, mean_mc_travel_dist: 1198.5480, mean_rewards: 132.4789, total_rewards: 1345.9857, mean_steps: 18.3900, mean_ecr: 0.0534 mean_entropies: 1.9277, took: 79.1665s
2022-10-09 20:40:27,679 [INFO] 	Process 6 - batch 4899: mean_policy_losses: -184.885, mean_net_lifetime: 1782.7948, mean_mc_travel_dist: 1030.2013, mean_rewards: 180.1670, total_rewards: 821.4154, mean_steps: 8.8300, mean_ecr: 0.0571 mean_entropies: 1.8260, took: 41.1200s
2022-10-09 20:41:11,621 [INFO] 	Process 6 - batch 4999: mean_policy_losses: -104.178, mean_net_lifetime: 2050.6001, mean_mc_travel_dist: 1093.9499, mean_rewards: 190.3343, total_rewards: 1005.8699, mean_steps: 9.6700, mean_ecr: 0.0569 mean_entropies: 1.7322, took: 43.9415s
2022-10-09 20:41:13,326 [INFO] 	Process 4 - batch 3799: mean_policy_losses: 129.103, mean_net_lifetime: 2529.8371, mean_mc_travel_dist: 1172.1253, mean_rewards: 123.2783, total_rewards: 1375.0895, mean_steps: 19.6800, mean_ecr: 0.0535 mean_entropies: 1.7371, took: 85.2536s
2022-10-09 20:41:57,397 [INFO] 	Process 6 - batch 5099: mean_policy_losses: -87.495, mean_net_lifetime: 2089.7971, mean_mc_travel_dist: 1110.6450, mean_rewards: 188.7359, total_rewards: 1034.9237, mean_steps: 9.9100, mean_ecr: 0.0571 mean_entropies: 1.6778, took: 45.7765s
2022-10-09 20:42:37,249 [INFO] 	Process 4 - batch 3899: mean_policy_losses: 40.888, mean_net_lifetime: 2415.4336, mean_mc_travel_dist: 1144.3432, mean_rewards: 121.4490, total_rewards: 1278.1103, mean_steps: 19.1400, mean_ecr: 0.0536 mean_entropies: 1.6795, took: 83.9237s
2022-10-09 20:42:44,271 [INFO] 	Process 6 - batch 5199: mean_policy_losses: -100.271, mean_net_lifetime: 2117.1389, mean_mc_travel_dist: 1107.7345, mean_rewards: 189.4822, total_rewards: 1063.6178, mean_steps: 10.0100, mean_ecr: 0.0572 mean_entropies: 1.6006, took: 46.8743s
2022-10-09 20:42:57,038 [INFO] Process 2 - epoch 2: mean_policy_losses: -0.011, mean_net_lifetime: 3120.4382, mean_mc_travel_dist: 1727.6984, mean_entropies: 2.2781, m_net_lifetime_valid: 2861.7701, took: 4094.3679s, (303.0896 / 100 batches)

2022-10-09 20:43:05,725 [INFO] Process 5 - epoch 2: mean_policy_losses: -79.220, mean_net_lifetime: 3562.1288, mean_mc_travel_dist: 2205.5392, mean_entropies: 2.6837, m_net_lifetime_valid: 2878.3675, took: 3750.5015s, (305.7122 / 100 batches)

2022-10-09 20:43:16,466 [INFO] Process 3 - epoch 2: mean_policy_losses: 241.894, mean_net_lifetime: 3537.1249, mean_mc_travel_dist: 1707.6149, mean_entropies: 2.2026, m_net_lifetime_valid: 2863.1785, took: 4219.6953s, (306.9724 / 100 batches)

2022-10-09 20:43:36,993 [INFO] 	Process 6 - batch 5299: mean_policy_losses: -48.937, mean_net_lifetime: 2208.7331, mean_mc_travel_dist: 1112.6034, mean_rewards: 187.3517, total_rewards: 1141.8207, mean_steps: 10.6200, mean_ecr: 0.0569 mean_entropies: 1.5477, took: 52.7217s
2022-10-09 20:44:10,548 [INFO] 	Process 4 - batch 3999: mean_policy_losses: 59.426, mean_net_lifetime: 2460.1979, mean_mc_travel_dist: 1145.0081, mean_rewards: 117.0468, total_rewards: 1327.1038, mean_steps: 20.1800, mean_ecr: 0.0537 mean_entropies: 1.6454, took: 93.2986s
2022-10-09 20:44:28,544 [INFO] 	Process 6 - batch 5399: mean_policy_losses: -84.091, mean_net_lifetime: 2092.6857, mean_mc_travel_dist: 1101.4593, mean_rewards: 188.7120, total_rewards: 1048.8722, mean_steps: 9.9900, mean_ecr: 0.0572 mean_entropies: 1.5621, took: 51.5504s
2022-10-09 20:44:57,253 [INFO] 	Process 2 - batch 3099: mean_policy_losses: 12.342, mean_net_lifetime: 2774.5346, mean_mc_travel_dist: 1581.1258, mean_rewards: 102.6240, total_rewards: 1223.6022, mean_steps: 26.1100, mean_ecr: 0.0428 mean_entropies: 1.3720, took: 1306.7622s
2022-10-09 20:44:59,452 [INFO] 	Process 5 - batch 3099: mean_policy_losses: -125.474, mean_net_lifetime: 2577.0904, mean_mc_travel_dist: 1667.6140, mean_rewards: 102.1300, total_rewards: 951.3277, mean_steps: 24.1200, mean_ecr: 0.0309 mean_entropies: 1.9759, took: 1227.5495s
2022-10-09 20:45:13,084 [INFO] Process 7 - epoch 2: mean_policy_losses: 72.629, mean_net_lifetime: 3420.9166, mean_mc_travel_dist: 1763.4592, mean_entropies: 2.4085, m_net_lifetime_valid: 2917.8867, took: 4057.1920s, (309.4337 / 100 batches)

2022-10-09 20:45:22,012 [INFO] 	Process 6 - batch 5499: mean_policy_losses: -103.413, mean_net_lifetime: 2078.9809, mean_mc_travel_dist: 1088.0494, mean_rewards: 186.2009, total_rewards: 1035.6937, mean_steps: 10.1000, mean_ecr: 0.0570 mean_entropies: 1.5539, took: 53.4686s
2022-10-09 20:45:49,413 [INFO] 	Process 4 - batch 4099: mean_policy_losses: 35.868, mean_net_lifetime: 2432.6129, mean_mc_travel_dist: 1146.1933, mean_rewards: 116.6363, total_rewards: 1300.3669, mean_steps: 20.0800, mean_ecr: 0.0536 mean_entropies: 1.6088, took: 98.8647s
2022-10-09 20:45:52,194 [INFO] 	Process 3 - batch 3099: mean_policy_losses: 162.004, mean_net_lifetime: 3435.6868, mean_mc_travel_dist: 1600.3411, mean_rewards: 100.7034, total_rewards: 1853.1501, mean_steps: 33.7600, mean_ecr: 0.0482 mean_entropies: 1.3396, took: 1240.5641s
2022-10-09 20:46:14,926 [INFO] 	Process 6 - batch 5599: mean_policy_losses: -145.963, mean_net_lifetime: 2157.9264, mean_mc_travel_dist: 1114.4655, mean_rewards: 193.2493, total_rewards: 1087.2266, mean_steps: 9.9800, mean_ecr: 0.0569 mean_entropies: 1.5738, took: 52.9137s
2022-10-09 20:46:53,241 [INFO] 	Process 5 - batch 3199: mean_policy_losses: -116.170, mean_net_lifetime: 2841.5456, mean_mc_travel_dist: 1789.6013, mean_rewards: 112.8001, total_rewards: 1096.6509, mean_steps: 23.8400, mean_ecr: 0.0309 mean_entropies: 2.1019, took: 113.7879s
2022-10-09 20:47:02,562 [INFO] 	Process 2 - batch 3199: mean_policy_losses: -8.834, mean_net_lifetime: 2856.1045, mean_mc_travel_dist: 1588.5580, mean_rewards: 105.6071, total_rewards: 1292.2710, mean_steps: 26.1300, mean_ecr: 0.0426 mean_entropies: 1.3681, took: 125.3099s
2022-10-09 20:47:07,500 [INFO] 	Process 6 - batch 5699: mean_policy_losses: -197.577, mean_net_lifetime: 2019.7107, mean_mc_travel_dist: 1079.0437, mean_rewards: 184.6516, total_rewards: 1000.4624, mean_steps: 9.7200, mean_ecr: 0.0569 mean_entropies: 1.6492, took: 52.5744s
2022-10-09 20:47:30,494 [INFO] 	Process 4 - batch 4199: mean_policy_losses: 26.510, mean_net_lifetime: 2501.8119, mean_mc_travel_dist: 1155.6654, mean_rewards: 118.4543, total_rewards: 1358.1846, mean_steps: 20.2300, mean_ecr: 0.0533 mean_entropies: 1.6322, took: 101.0809s
2022-10-09 20:47:48,629 [INFO] 	Process 7 - batch 3099: mean_policy_losses: 271.483, mean_net_lifetime: 3843.2945, mean_mc_travel_dist: 1840.0683, mean_rewards: 115.5630, total_rewards: 2044.6237, mean_steps: 32.9300, mean_ecr: 0.0435 mean_entropies: 2.0433, took: 1281.3205s
2022-10-09 20:47:57,262 [INFO] 	Process 6 - batch 5799: mean_policy_losses: -313.299, mean_net_lifetime: 1860.4587, mean_mc_travel_dist: 1040.2374, mean_rewards: 185.0018, total_rewards: 876.0265, mean_steps: 8.9700, mean_ecr: 0.0572 mean_entropies: 1.7666, took: 49.7611s
2022-10-09 20:48:17,887 [INFO] 	Process 3 - batch 3199: mean_policy_losses: 181.225, mean_net_lifetime: 3511.1306, mean_mc_travel_dist: 1599.6411, mean_rewards: 112.3647, total_rewards: 1930.0665, mean_steps: 30.9300, mean_ecr: 0.0483 mean_entropies: 1.4299, took: 145.6922s
2022-10-09 20:48:46,439 [INFO] 	Process 6 - batch 5899: mean_policy_losses: -219.680, mean_net_lifetime: 1921.9019, mean_mc_travel_dist: 1055.3742, mean_rewards: 184.6668, total_rewards: 931.1284, mean_steps: 9.2200, mean_ecr: 0.0571 mean_entropies: 1.7102, took: 49.1775s
2022-10-09 20:48:50,310 [INFO] 	Process 5 - batch 3299: mean_policy_losses: 69.275, mean_net_lifetime: 3310.9884, mean_mc_travel_dist: 1961.5173, mean_rewards: 132.9494, total_rewards: 1408.6196, mean_steps: 23.4800, mean_ecr: 0.0310 mean_entropies: 2.2811, took: 117.0696s
2022-10-09 20:49:08,750 [INFO] 	Process 2 - batch 3299: mean_policy_losses: -0.058, mean_net_lifetime: 2885.3384, mean_mc_travel_dist: 1582.6695, mean_rewards: 106.1536, total_rewards: 1326.0902, mean_steps: 26.2900, mean_ecr: 0.0425 mean_entropies: 1.4783, took: 126.1872s
2022-10-09 20:49:12,632 [INFO] 	Process 4 - batch 4299: mean_policy_losses: 42.629, mean_net_lifetime: 2495.0348, mean_mc_travel_dist: 1162.4287, mean_rewards: 118.3041, total_rewards: 1343.4149, mean_steps: 20.3500, mean_ecr: 0.0535 mean_entropies: 1.6513, took: 102.1380s
2022-10-09 20:49:35,462 [INFO] 	Process 6 - batch 5999: mean_policy_losses: -271.762, mean_net_lifetime: 1828.9983, mean_mc_travel_dist: 1030.4206, mean_rewards: 181.4583, total_rewards: 865.6802, mean_steps: 9.0400, mean_ecr: 0.0571 mean_entropies: 1.7793, took: 49.0235s
2022-10-09 20:50:12,519 [INFO] 	Process 7 - batch 3199: mean_policy_losses: 248.699, mean_net_lifetime: 3827.8602, mean_mc_travel_dist: 1880.5167, mean_rewards: 122.7393, total_rewards: 1977.6254, mean_steps: 30.6500, mean_ecr: 0.0434 mean_entropies: 2.1187, took: 143.8907s
2022-10-09 20:50:38,835 [INFO] 	Process 3 - batch 3299: mean_policy_losses: 179.330, mean_net_lifetime: 3521.0014, mean_mc_travel_dist: 1595.5747, mean_rewards: 118.5871, total_rewards: 1942.9460, mean_steps: 29.2300, mean_ecr: 0.0482 mean_entropies: 1.5274, took: 140.9479s
2022-10-09 20:50:41,824 [INFO] 	Process 5 - batch 3399: mean_policy_losses: 113.775, mean_net_lifetime: 3708.8499, mean_mc_travel_dist: 2171.2789, mean_rewards: 148.3954, total_rewards: 1598.8543, mean_steps: 23.5300, mean_ecr: 0.0308 mean_entropies: 2.3993, took: 111.5140s
2022-10-09 20:50:48,657 [INFO] 	Process 4 - batch 4399: mean_policy_losses: -41.971, mean_net_lifetime: 2502.1138, mean_mc_travel_dist: 1182.5580, mean_rewards: 123.2996, total_rewards: 1330.7959, mean_steps: 19.6100, mean_ecr: 0.0532 mean_entropies: 1.7190, took: 96.0257s
2022-10-09 20:51:10,305 [INFO] 	Process 2 - batch 3399: mean_policy_losses: -71.321, mean_net_lifetime: 2918.5954, mean_mc_travel_dist: 1588.0015, mean_rewards: 109.0155, total_rewards: 1358.4864, mean_steps: 25.9800, mean_ecr: 0.0424 mean_entropies: 1.5935, took: 121.5558s
2022-10-09 20:52:18,757 [INFO] 	Process 7 - batch 3299: mean_policy_losses: 231.167, mean_net_lifetime: 3806.1387, mean_mc_travel_dist: 1832.7930, mean_rewards: 136.2239, total_rewards: 2021.5158, mean_steps: 27.3100, mean_ecr: 0.0435 mean_entropies: 2.1871, took: 126.2368s
2022-10-09 20:52:24,329 [INFO] 	Process 4 - batch 4499: mean_policy_losses: -101.075, mean_net_lifetime: 2515.8194, mean_mc_travel_dist: 1190.5006, mean_rewards: 122.5243, total_rewards: 1337.6493, mean_steps: 19.8100, mean_ecr: 0.0533 mean_entropies: 1.7403, took: 95.6711s
2022-10-09 20:52:33,338 [INFO] 	Process 5 - batch 3499: mean_policy_losses: 213.571, mean_net_lifetime: 4132.6884, mean_mc_travel_dist: 2345.6005, mean_rewards: 164.7472, total_rewards: 1844.0188, mean_steps: 23.7100, mean_ecr: 0.0311 mean_entropies: 2.4997, took: 111.5135s
2022-10-09 20:52:45,333 [INFO] 	Process 3 - batch 3399: mean_policy_losses: 152.584, mean_net_lifetime: 3565.6742, mean_mc_travel_dist: 1595.6591, mean_rewards: 129.4374, total_rewards: 1990.9127, mean_steps: 26.9300, mean_ecr: 0.0482 mean_entropies: 1.6577, took: 126.4983s
2022-10-09 20:53:05,933 [INFO] 	Process 2 - batch 3499: mean_policy_losses: -65.503, mean_net_lifetime: 3132.9796, mean_mc_travel_dist: 1609.7981, mean_rewards: 119.6503, total_rewards: 1547.9949, mean_steps: 25.2800, mean_ecr: 0.0421 mean_entropies: 1.7361, took: 115.6285s
2022-10-09 20:53:52,314 [INFO] Process 1 - epoch 2: mean_policy_losses: 355.553, mean_net_lifetime: 4547.2090, mean_mc_travel_dist: 2356.1246, mean_entropies: 2.4085, m_net_lifetime_valid: 2831.8902, took: 3864.2055s, (324.8833 / 100 batches)

2022-10-09 20:54:23,138 [INFO] 	Process 7 - batch 3399: mean_policy_losses: 27.908, mean_net_lifetime: 3781.9745, mean_mc_travel_dist: 1835.9847, mean_rewards: 132.8178, total_rewards: 1979.3704, mean_steps: 27.8200, mean_ecr: 0.0434 mean_entropies: 2.2019, took: 124.3821s
2022-10-09 20:54:27,723 [INFO] 	Process 5 - batch 3599: mean_policy_losses: 39.200, mean_net_lifetime: 4249.3934, mean_mc_travel_dist: 2430.3379, mean_rewards: 165.0123, total_rewards: 1869.9663, mean_steps: 24.4500, mean_ecr: 0.0312 mean_entropies: 2.5290, took: 114.3855s
2022-10-09 20:54:43,817 [INFO] 	Process 3 - batch 3499: mean_policy_losses: 111.490, mean_net_lifetime: 3709.2031, mean_mc_travel_dist: 1604.0958, mean_rewards: 141.1950, total_rewards: 2121.3649, mean_steps: 25.5500, mean_ecr: 0.0480 mean_entropies: 1.7800, took: 118.4845s
2022-10-09 20:55:02,426 [INFO] 	Process 2 - batch 3599: mean_policy_losses: -203.359, mean_net_lifetime: 3098.2938, mean_mc_travel_dist: 1619.1280, mean_rewards: 118.8219, total_rewards: 1507.5126, mean_steps: 25.3200, mean_ecr: 0.0422 mean_entropies: 1.8634, took: 116.4917s
2022-10-09 20:56:24,174 [INFO] 	Process 5 - batch 3699: mean_policy_losses: -26.554, mean_net_lifetime: 4267.3784, mean_mc_travel_dist: 2477.6639, mean_rewards: 162.5423, total_rewards: 1841.8328, mean_steps: 25.0100, mean_ecr: 0.0310 mean_entropies: 2.5633, took: 116.4515s
2022-10-09 20:56:32,335 [INFO] 	Process 7 - batch 3499: mean_policy_losses: -55.561, mean_net_lifetime: 3703.8505, mean_mc_travel_dist: 1790.6497, mean_rewards: 130.7168, total_rewards: 1941.7965, mean_steps: 27.8400, mean_ecr: 0.0436 mean_entropies: 2.1913, took: 129.1966s
2022-10-09 20:56:39,694 [INFO] 	Process 1 - batch 3099: mean_policy_losses: 51.599, mean_net_lifetime: 4527.7463, mean_mc_travel_dist: 2336.0904, mean_rewards: 120.9798, total_rewards: 2219.1770, mean_steps: 36.7800, mean_ecr: 0.0398 mean_entropies: 1.9668, took: 1333.5098s
2022-10-09 20:56:44,018 [INFO] 	Process 3 - batch 3599: mean_policy_losses: 78.077, mean_net_lifetime: 3678.4014, mean_mc_travel_dist: 1622.6681, mean_rewards: 141.2984, total_rewards: 2070.2297, mean_steps: 25.5400, mean_ecr: 0.0480 mean_entropies: 1.8738, took: 120.2008s
2022-10-09 20:56:55,101 [INFO] 	Process 2 - batch 3699: mean_policy_losses: -156.323, mean_net_lifetime: 3228.1255, mean_mc_travel_dist: 1649.3488, mean_rewards: 129.0293, total_rewards: 1605.8730, mean_steps: 24.1700, mean_ecr: 0.0420 mean_entropies: 1.9700, took: 112.6756s
2022-10-09 20:58:21,471 [INFO] 	Process 5 - batch 3799: mean_policy_losses: -54.964, mean_net_lifetime: 4180.3336, mean_mc_travel_dist: 2437.2716, mean_rewards: 156.8726, total_rewards: 1795.4953, mean_steps: 25.4200, mean_ecr: 0.0311 mean_entropies: 2.5585, took: 117.2968s
2022-10-09 20:58:41,396 [INFO] 	Process 3 - batch 3699: mean_policy_losses: 139.010, mean_net_lifetime: 3767.3935, mean_mc_travel_dist: 1638.6232, mean_rewards: 149.5304, total_rewards: 2153.4483, mean_steps: 24.4800, mean_ecr: 0.0477 mean_entropies: 1.9797, took: 117.3777s
2022-10-09 20:58:43,158 [INFO] 	Process 7 - batch 3599: mean_policy_losses: -43.968, mean_net_lifetime: 3743.1243, mean_mc_travel_dist: 1796.7244, mean_rewards: 130.2632, total_rewards: 1976.8131, mean_steps: 28.2500, mean_ecr: 0.0436 mean_entropies: 2.2105, took: 130.8231s
2022-10-09 20:58:45,996 [INFO] 	Process 2 - batch 3799: mean_policy_losses: -109.834, mean_net_lifetime: 3349.9576, mean_mc_travel_dist: 1676.7641, mean_rewards: 136.4388, total_rewards: 1696.2380, mean_steps: 23.6200, mean_ecr: 0.0419 mean_entropies: 2.0912, took: 110.8945s
2022-10-09 20:59:28,992 [INFO] 	Process 1 - batch 3199: mean_policy_losses: 45.321, mean_net_lifetime: 4565.9220, mean_mc_travel_dist: 2314.4385, mean_rewards: 121.9446, total_rewards: 2276.9462, mean_steps: 36.9000, mean_ecr: 0.0398 mean_entropies: 1.9882, took: 169.2982s
2022-10-09 21:00:29,617 [INFO] 	Process 5 - batch 3899: mean_policy_losses: -41.125, mean_net_lifetime: 4353.2852, mean_mc_travel_dist: 2545.2149, mean_rewards: 154.4807, total_rewards: 1857.2859, mean_steps: 27.1000, mean_ecr: 0.0310 mean_entropies: 2.5523, took: 128.1449s
2022-10-09 21:00:34,947 [INFO] 	Process 3 - batch 3799: mean_policy_losses: 111.486, mean_net_lifetime: 3791.3431, mean_mc_travel_dist: 1667.3835, mean_rewards: 154.3202, total_rewards: 2150.2138, mean_steps: 23.8500, mean_ecr: 0.0477 mean_entropies: 2.0379, took: 113.5508s
2022-10-09 21:00:38,938 [INFO] 	Process 2 - batch 3899: mean_policy_losses: -82.703, mean_net_lifetime: 3545.8278, mean_mc_travel_dist: 1764.3405, mean_rewards: 142.2498, total_rewards: 1815.8395, mean_steps: 24.0500, mean_ecr: 0.0417 mean_entropies: 2.1483, took: 112.9425s
2022-10-09 21:00:52,851 [INFO] 	Process 7 - batch 3699: mean_policy_losses: -115.438, mean_net_lifetime: 3658.3451, mean_mc_travel_dist: 1787.4841, mean_rewards: 128.0270, total_rewards: 1915.8947, mean_steps: 28.0400, mean_ecr: 0.0436 mean_entropies: 2.2072, took: 129.6931s
2022-10-09 21:02:20,548 [INFO] 	Process 1 - batch 3299: mean_policy_losses: 41.887, mean_net_lifetime: 4577.5297, mean_mc_travel_dist: 2316.2308, mean_rewards: 119.7698, total_rewards: 2286.4383, mean_steps: 37.6400, mean_ecr: 0.0398 mean_entropies: 2.0013, took: 171.5555s
2022-10-09 21:02:27,279 [INFO] 	Process 3 - batch 3899: mean_policy_losses: 151.365, mean_net_lifetime: 3809.1200, mean_mc_travel_dist: 1663.6620, mean_rewards: 157.3497, total_rewards: 2169.6172, mean_steps: 23.4200, mean_ecr: 0.0477 mean_entropies: 2.0115, took: 112.3327s
2022-10-09 21:02:28,753 [INFO] 	Process 5 - batch 3999: mean_policy_losses: -52.387, mean_net_lifetime: 4211.8915, mean_mc_travel_dist: 2460.2849, mean_rewards: 160.5233, total_rewards: 1803.3016, mean_steps: 25.1400, mean_ecr: 0.0310 mean_entropies: 2.5979, took: 119.1367s
2022-10-09 21:02:30,183 [INFO] 	Process 2 - batch 3999: mean_policy_losses: -110.687, mean_net_lifetime: 3396.2948, mean_mc_travel_dist: 1706.2150, mean_rewards: 139.1949, total_rewards: 1717.9948, mean_steps: 23.5700, mean_ecr: 0.0419 mean_entropies: 2.0992, took: 111.2447s
2022-10-09 21:03:05,955 [INFO] 	Process 7 - batch 3799: mean_policy_losses: -94.397, mean_net_lifetime: 3662.7723, mean_mc_travel_dist: 1782.0247, mean_rewards: 125.3715, total_rewards: 1921.8165, mean_steps: 28.7500, mean_ecr: 0.0437 mean_entropies: 2.2401, took: 133.1035s
2022-10-09 21:04:19,290 [INFO] 	Process 3 - batch 3999: mean_policy_losses: 122.856, mean_net_lifetime: 3789.5662, mean_mc_travel_dist: 1665.0168, mean_rewards: 158.0565, total_rewards: 2150.0448, mean_steps: 23.2700, mean_ecr: 0.0477 mean_entropies: 2.0356, took: 112.0107s
2022-10-09 21:04:21,377 [INFO] 	Process 2 - batch 4099: mean_policy_losses: -163.247, mean_net_lifetime: 3405.7971, mean_mc_travel_dist: 1733.3433, mean_rewards: 137.6035, total_rewards: 1705.5031, mean_steps: 23.8600, mean_ecr: 0.0418 mean_entropies: 2.1306, took: 111.1941s
2022-10-09 21:04:30,577 [INFO] 	Process 5 - batch 4099: mean_policy_losses: -18.514, mean_net_lifetime: 4433.0429, mean_mc_travel_dist: 2570.6999, mean_rewards: 159.2249, total_rewards: 1916.2060, mean_steps: 26.7300, mean_ecr: 0.0310 mean_entropies: 2.5706, took: 121.8242s
2022-10-09 21:05:08,910 [INFO] 	Process 1 - batch 3399: mean_policy_losses: 43.397, mean_net_lifetime: 4604.4328, mean_mc_travel_dist: 2352.2225, mean_rewards: 122.3910, total_rewards: 2278.4827, mean_steps: 36.9400, mean_ecr: 0.0397 mean_entropies: 1.9879, took: 168.3620s
2022-10-09 21:05:19,046 [INFO] 	Process 7 - batch 3899: mean_policy_losses: -84.309, mean_net_lifetime: 3745.5289, mean_mc_travel_dist: 1794.4211, mean_rewards: 129.0381, total_rewards: 1983.6490, mean_steps: 28.5100, mean_ecr: 0.0437 mean_entropies: 2.2203, took: 133.0916s
2022-10-09 21:06:15,599 [INFO] 	Process 3 - batch 4099: mean_policy_losses: 116.108, mean_net_lifetime: 3762.5166, mean_mc_travel_dist: 1669.9070, mean_rewards: 152.7111, total_rewards: 2117.7339, mean_steps: 23.9700, mean_ecr: 0.0477 mean_entropies: 2.0354, took: 116.3094s
2022-10-09 21:06:16,159 [INFO] 	Process 2 - batch 4199: mean_policy_losses: -52.993, mean_net_lifetime: 3563.8398, mean_mc_travel_dist: 1773.3366, mean_rewards: 141.2045, total_rewards: 1822.6254, mean_steps: 24.3100, mean_ecr: 0.0416 mean_entropies: 2.1403, took: 114.7821s
2022-10-09 21:06:33,711 [INFO] 	Process 5 - batch 4199: mean_policy_losses: -98.135, mean_net_lifetime: 4084.5229, mean_mc_travel_dist: 2433.6775, mean_rewards: 151.9083, total_rewards: 1717.3360, mean_steps: 25.7800, mean_ecr: 0.0312 mean_entropies: 2.5247, took: 123.1333s
2022-10-09 21:07:27,569 [INFO] 	Process 7 - batch 3999: mean_policy_losses: -84.892, mean_net_lifetime: 3694.2166, mean_mc_travel_dist: 1798.3979, mean_rewards: 129.6983, total_rewards: 1932.9781, mean_steps: 27.7800, mean_ecr: 0.0437 mean_entropies: 2.2404, took: 128.5224s
2022-10-09 21:08:02,705 [INFO] 	Process 3 - batch 4199: mean_policy_losses: 158.182, mean_net_lifetime: 3800.5091, mean_mc_travel_dist: 1692.4013, mean_rewards: 165.3797, total_rewards: 2137.0459, mean_steps: 22.2400, mean_ecr: 0.0476 mean_entropies: 2.1144, took: 107.1052s
2022-10-09 21:08:02,723 [INFO] 	Process 1 - batch 3499: mean_policy_losses: 56.955, mean_net_lifetime: 4631.0319, mean_mc_travel_dist: 2338.9115, mean_rewards: 119.3241, total_rewards: 2317.3434, mean_steps: 38.1500, mean_ecr: 0.0397 mean_entropies: 2.0004, took: 173.8126s
2022-10-09 21:08:07,273 [INFO] 	Process 2 - batch 4299: mean_policy_losses: -115.044, mean_net_lifetime: 3486.6549, mean_mc_travel_dist: 1763.4448, mean_rewards: 143.5630, total_rewards: 1752.0496, mean_steps: 23.3800, mean_ecr: 0.0417 mean_entropies: 2.2327, took: 111.1145s
2022-10-09 21:08:37,176 [INFO] 	Process 5 - batch 4299: mean_policy_losses: -108.245, mean_net_lifetime: 4182.4045, mean_mc_travel_dist: 2497.6220, mean_rewards: 153.1046, total_rewards: 1748.6653, mean_steps: 26.2100, mean_ecr: 0.0311 mean_entropies: 2.5662, took: 123.4656s
2022-10-09 21:09:34,320 [INFO] 	Process 7 - batch 4099: mean_policy_losses: -122.280, mean_net_lifetime: 3632.4327, mean_mc_travel_dist: 1767.5637, mean_rewards: 132.4106, total_rewards: 1900.1106, mean_steps: 26.8700, mean_ecr: 0.0436 mean_entropies: 2.2363, took: 126.7514s
2022-10-09 21:09:46,913 [INFO] Process 6 - epoch 4: mean_policy_losses: -321.427, mean_net_lifetime: 1592.5137, mean_mc_travel_dist: 983.6902, mean_entropies: 2.1047, m_net_lifetime_valid: 2900.9971, took: 1919.6921s, (180.0029 / 100 batches)

2022-10-09 21:09:53,839 [INFO] 	Process 3 - batch 4299: mean_policy_losses: 131.562, mean_net_lifetime: 3855.9674, mean_mc_travel_dist: 1685.7356, mean_rewards: 160.3307, total_rewards: 2187.5910, mean_steps: 23.2400, mean_ecr: 0.0478 mean_entropies: 2.0461, took: 111.1348s
2022-10-09 21:10:00,634 [INFO] 	Process 2 - batch 4399: mean_policy_losses: -121.067, mean_net_lifetime: 3464.1157, mean_mc_travel_dist: 1736.2581, mean_rewards: 138.7620, total_rewards: 1746.9707, mean_steps: 24.0800, mean_ecr: 0.0417 mean_entropies: 2.1419, took: 113.3609s
2022-10-09 21:10:31,467 [INFO] 	Process 6 - batch 6099: mean_policy_losses: -687.152, mean_net_lifetime: 1439.8336, mean_mc_travel_dist: 924.5255, mean_rewards: 163.9145, total_rewards: 576.8468, mean_steps: 7.8300, mean_ecr: 0.0561 mean_entropies: 2.1204, took: 1256.0033s
2022-10-09 21:10:43,794 [INFO] 	Process 5 - batch 4399: mean_policy_losses: 142.820, mean_net_lifetime: 4460.0608, mean_mc_travel_dist: 2595.1165, mean_rewards: 160.4904, total_rewards: 1929.1931, mean_steps: 26.5700, mean_ecr: 0.0310 mean_entropies: 2.5776, took: 126.6178s
2022-10-09 21:11:01,145 [INFO] 	Process 1 - batch 3599: mean_policy_losses: 132.418, mean_net_lifetime: 4613.0333, mean_mc_travel_dist: 2335.0852, mean_rewards: 119.0592, total_rewards: 2311.9833, mean_steps: 38.1000, mean_ecr: 0.0398 mean_entropies: 1.9766, took: 178.4231s
2022-10-09 21:11:19,400 [INFO] 	Process 6 - batch 6199: mean_policy_losses: -591.806, mean_net_lifetime: 1469.3139, mean_mc_travel_dist: 929.7049, mean_rewards: 159.0026, total_rewards: 594.1788, mean_steps: 8.1800, mean_ecr: 0.0561 mean_entropies: 1.9988, took: 47.9348s
2022-10-09 21:11:49,134 [INFO] 	Process 7 - batch 4199: mean_policy_losses: 198.156, mean_net_lifetime: 3735.0737, mean_mc_travel_dist: 1802.7983, mean_rewards: 129.7871, total_rewards: 1960.8149, mean_steps: 28.1800, mean_ecr: 0.0436 mean_entropies: 2.1983, took: 134.8140s
2022-10-09 21:11:52,797 [INFO] 	Process 3 - batch 4399: mean_policy_losses: 373.752, mean_net_lifetime: 3774.6904, mean_mc_travel_dist: 1657.5651, mean_rewards: 149.8522, total_rewards: 2142.9454, mean_steps: 24.6000, mean_ecr: 0.0480 mean_entropies: 1.9152, took: 118.9579s
2022-10-09 21:11:56,098 [INFO] 	Process 2 - batch 4499: mean_policy_losses: 114.623, mean_net_lifetime: 3241.6975, mean_mc_travel_dist: 1641.0488, mean_rewards: 130.6761, total_rewards: 1626.6999, mean_steps: 24.0300, mean_ecr: 0.0420 mean_entropies: 1.9743, took: 115.4632s
2022-10-09 21:12:06,580 [INFO] 	Process 6 - batch 6299: mean_policy_losses: -561.702, mean_net_lifetime: 1565.4612, mean_mc_travel_dist: 961.7455, mean_rewards: 164.0005, total_rewards: 663.5922, mean_steps: 8.5700, mean_ecr: 0.0564 mean_entropies: 1.9476, took: 47.1795s
2022-10-09 21:12:50,860 [INFO] 	Process 5 - batch 4499: mean_policy_losses: 341.115, mean_net_lifetime: 4530.5919, mean_mc_travel_dist: 2571.5981, mean_rewards: 165.8289, total_rewards: 2022.0009, mean_steps: 26.0900, mean_ecr: 0.0309 mean_entropies: 2.5631, took: 127.0660s
2022-10-09 21:12:53,868 [INFO] 	Process 6 - batch 6399: mean_policy_losses: -577.910, mean_net_lifetime: 1578.0373, mean_mc_travel_dist: 963.0105, mean_rewards: 163.0974, total_rewards: 675.2081, mean_steps: 8.7200, mean_ecr: 0.0565 mean_entropies: 1.9311, took: 47.2881s
2022-10-09 21:13:23,140 [INFO] Process 4 - epoch 3: mean_policy_losses: 18.923, mean_net_lifetime: 2503.1329, mean_mc_travel_dist: 1247.1558, mean_entropies: 2.1164, m_net_lifetime_valid: 2826.1481, took: 2542.5432s, (242.3784 / 100 batches)

2022-10-09 21:13:38,678 [INFO] 	Process 6 - batch 6499: mean_policy_losses: -532.096, mean_net_lifetime: 1650.6356, mean_mc_travel_dist: 979.6326, mean_rewards: 175.8727, total_rewards: 722.8326, mean_steps: 8.3100, mean_ecr: 0.0565 mean_entropies: 1.9711, took: 44.8093s
2022-10-09 21:13:49,551 [INFO] 	Process 1 - batch 3699: mean_policy_losses: 239.187, mean_net_lifetime: 4482.8966, mean_mc_travel_dist: 2283.1303, mean_rewards: 119.2829, total_rewards: 2223.4604, mean_steps: 36.9700, mean_ecr: 0.0399 mean_entropies: 1.9034, took: 168.4054s
2022-10-09 21:13:51,725 [INFO] 	Process 3 - batch 4499: mean_policy_losses: 254.854, mean_net_lifetime: 3687.0311, mean_mc_travel_dist: 1619.3079, mean_rewards: 139.0134, total_rewards: 2089.1240, mean_steps: 25.8800, mean_ecr: 0.0481 mean_entropies: 1.7915, took: 118.9281s
2022-10-09 21:14:00,342 [INFO] 	Process 7 - batch 4299: mean_policy_losses: 232.398, mean_net_lifetime: 3794.7267, mean_mc_travel_dist: 1821.1590, mean_rewards: 128.5532, total_rewards: 2010.3177, mean_steps: 29.0400, mean_ecr: 0.0436 mean_entropies: 2.1762, took: 131.2078s
2022-10-09 21:14:20,948 [INFO] 	Process 6 - batch 6599: mean_policy_losses: -391.318, mean_net_lifetime: 1640.3177, mean_mc_travel_dist: 990.9058, mean_rewards: 181.4093, total_rewards: 709.2933, mean_steps: 8.0200, mean_ecr: 0.0570 mean_entropies: 2.0106, took: 42.2702s
2022-10-09 21:14:54,442 [INFO] 	Process 4 - batch 4599: mean_policy_losses: 53.864, mean_net_lifetime: 2525.6369, mean_mc_travel_dist: 1171.7029, mean_rewards: 124.3567, total_rewards: 1367.0926, mean_steps: 19.5200, mean_ecr: 0.0534 mean_entropies: 1.7663, took: 1350.1140s
2022-10-09 21:15:05,438 [INFO] 	Process 6 - batch 6699: mean_policy_losses: -440.539, mean_net_lifetime: 1738.5685, mean_mc_travel_dist: 1014.0206, mean_rewards: 182.1835, total_rewards: 781.8713, mean_steps: 8.3600, mean_ecr: 0.0569 mean_entropies: 1.9772, took: 44.4904s
2022-10-09 21:15:50,823 [INFO] 	Process 6 - batch 6799: mean_policy_losses: -359.001, mean_net_lifetime: 1765.2629, mean_mc_travel_dist: 1012.2699, mean_rewards: 183.0883, total_rewards: 817.5955, mean_steps: 8.5100, mean_ecr: 0.0568 mean_entropies: 1.8619, took: 45.3836s
2022-10-09 21:16:05,784 [INFO] 	Process 7 - batch 4399: mean_policy_losses: 325.461, mean_net_lifetime: 3773.2627, mean_mc_travel_dist: 1802.6849, mean_rewards: 129.2350, total_rewards: 2008.5238, mean_steps: 28.7100, mean_ecr: 0.0435 mean_entropies: 2.1925, took: 125.4419s
2022-10-09 21:16:17,260 [INFO] 	Process 1 - batch 3799: mean_policy_losses: 426.030, mean_net_lifetime: 4543.1115, mean_mc_travel_dist: 2340.0091, mean_rewards: 137.8447, total_rewards: 2231.0702, mean_steps: 32.4200, mean_ecr: 0.0400 mean_entropies: 2.0511, took: 147.7096s
2022-10-09 21:16:24,124 [INFO] 	Process 4 - batch 4699: mean_policy_losses: 14.648, mean_net_lifetime: 2494.1577, mean_mc_travel_dist: 1156.3289, mean_rewards: 123.5132, total_rewards: 1351.9325, mean_steps: 19.4200, mean_ecr: 0.0534 mean_entropies: 1.7652, took: 89.6817s
2022-10-09 21:16:38,159 [INFO] 	Process 6 - batch 6899: mean_policy_losses: -338.554, mean_net_lifetime: 1885.9772, mean_mc_travel_dist: 1046.9080, mean_rewards: 184.5781, total_rewards: 892.7287, mean_steps: 9.0700, mean_ecr: 0.0571 mean_entropies: 1.7987, took: 47.3374s
2022-10-09 21:17:25,556 [INFO] 	Process 6 - batch 6999: mean_policy_losses: -358.429, mean_net_lifetime: 1769.1712, mean_mc_travel_dist: 1016.0036, mean_rewards: 178.6417, total_rewards: 808.3365, mean_steps: 8.7200, mean_ecr: 0.0572 mean_entropies: 1.7361, took: 47.3968s
2022-10-09 21:17:55,724 [INFO] 	Process 4 - batch 4799: mean_policy_losses: 57.253, mean_net_lifetime: 2563.3624, mean_mc_travel_dist: 1152.0925, mean_rewards: 126.2297, total_rewards: 1422.3244, mean_steps: 19.4000, mean_ecr: 0.0534 mean_entropies: 1.7499, took: 91.5994s
2022-10-09 21:18:11,377 [INFO] 	Process 6 - batch 7099: mean_policy_losses: -313.843, mean_net_lifetime: 1943.4899, mean_mc_travel_dist: 1058.0730, mean_rewards: 189.3973, total_rewards: 948.9608, mean_steps: 9.0800, mean_ecr: 0.0570 mean_entropies: 1.6893, took: 45.8206s
2022-10-09 21:18:21,812 [INFO] 	Process 1 - batch 3899: mean_policy_losses: 424.833, mean_net_lifetime: 4488.4769, mean_mc_travel_dist: 2405.1305, mean_rewards: 155.3387, total_rewards: 2123.1063, mean_steps: 28.1200, mean_ecr: 0.0400 mean_entropies: 2.0940, took: 124.5518s
2022-10-09 21:18:23,864 [INFO] 	Process 7 - batch 4499: mean_policy_losses: 282.356, mean_net_lifetime: 3849.7716, mean_mc_travel_dist: 1838.2511, mean_rewards: 122.8254, total_rewards: 2050.3354, mean_steps: 31.1600, mean_ecr: 0.0434 mean_entropies: 2.1221, took: 138.0794s
2022-10-09 21:19:00,549 [INFO] 	Process 6 - batch 7199: mean_policy_losses: -182.209, mean_net_lifetime: 2167.3280, mean_mc_travel_dist: 1123.5023, mean_rewards: 192.0641, total_rewards: 1100.8034, mean_steps: 10.0700, mean_ecr: 0.0571 mean_entropies: 1.6054, took: 49.1733s
2022-10-09 21:19:24,884 [INFO] 	Process 4 - batch 4899: mean_policy_losses: -40.661, mean_net_lifetime: 2423.2755, mean_mc_travel_dist: 1155.1713, mean_rewards: 117.7471, total_rewards: 1278.8189, mean_steps: 19.7200, mean_ecr: 0.0537 mean_entropies: 1.6923, took: 89.1603s
2022-10-09 21:19:49,291 [INFO] 	Process 6 - batch 7299: mean_policy_losses: -155.133, mean_net_lifetime: 2261.0644, mean_mc_travel_dist: 1152.1833, mean_rewards: 192.8985, total_rewards: 1168.6651, mean_steps: 10.5600, mean_ecr: 0.0571 mean_entropies: 1.5076, took: 48.7409s
2022-10-09 21:20:25,302 [INFO] 	Process 1 - batch 3999: mean_policy_losses: 395.443, mean_net_lifetime: 4487.3761, mean_mc_travel_dist: 2464.7879, mean_rewards: 154.1138, total_rewards: 2060.5406, mean_steps: 28.3200, mean_ecr: 0.0400 mean_entropies: 2.0095, took: 123.4898s
2022-10-09 21:20:36,654 [INFO] 	Process 6 - batch 7399: mean_policy_losses: -140.320, mean_net_lifetime: 2163.1980, mean_mc_travel_dist: 1117.4468, mean_rewards: 192.5651, total_rewards: 1098.5600, mean_steps: 10.0500, mean_ecr: 0.0571 mean_entropies: 1.4484, took: 47.3636s
2022-10-09 21:20:54,271 [INFO] 	Process 4 - batch 4999: mean_policy_losses: -3.781, mean_net_lifetime: 2445.7364, mean_mc_travel_dist: 1142.9325, mean_rewards: 118.3992, total_rewards: 1313.3081, mean_steps: 19.7800, mean_ecr: 0.0536 mean_entropies: 1.6177, took: 89.3874s
2022-10-09 21:21:27,548 [INFO] 	Process 6 - batch 7499: mean_policy_losses: -123.088, mean_net_lifetime: 2347.4402, mean_mc_travel_dist: 1177.6312, mean_rewards: 199.1057, total_rewards: 1210.4519, mean_steps: 10.6400, mean_ecr: 0.0569 mean_entropies: 1.4009, took: 50.8936s
2022-10-09 21:22:21,454 [INFO] 	Process 4 - batch 5099: mean_policy_losses: -56.106, mean_net_lifetime: 2411.7898, mean_mc_travel_dist: 1128.9237, mean_rewards: 116.8700, total_rewards: 1297.9551, mean_steps: 19.7900, mean_ecr: 0.0534 mean_entropies: 1.6015, took: 87.1826s
2022-10-09 21:22:24,786 [INFO] 	Process 1 - batch 4099: mean_policy_losses: 326.499, mean_net_lifetime: 4481.4619, mean_mc_travel_dist: 2470.4370, mean_rewards: 153.9089, total_rewards: 2047.5149, mean_steps: 28.2900, mean_ecr: 0.0400 mean_entropies: 1.9616, took: 119.4841s
2022-10-09 21:23:45,639 [INFO] 	Process 4 - batch 5199: mean_policy_losses: -93.869, mean_net_lifetime: 2525.6454, mean_mc_travel_dist: 1157.9854, mean_rewards: 125.1682, total_rewards: 1380.8185, mean_steps: 19.3800, mean_ecr: 0.0533 mean_entropies: 1.7726, took: 84.1847s
2022-10-09 21:24:17,442 [INFO] 	Process 1 - batch 4199: mean_policy_losses: 246.755, mean_net_lifetime: 4493.5593, mean_mc_travel_dist: 2443.4272, mean_rewards: 159.6854, total_rewards: 2090.2080, mean_steps: 27.3100, mean_ecr: 0.0401 mean_entropies: 2.1254, took: 112.6563s
2022-10-09 21:25:05,023 [INFO] 	Process 4 - batch 5299: mean_policy_losses: -80.065, mean_net_lifetime: 2607.2801, mean_mc_travel_dist: 1187.9969, mean_rewards: 138.1002, total_rewards: 1430.1579, mean_steps: 18.0000, mean_ecr: 0.0533 mean_entropies: 1.9071, took: 79.3851s
2022-10-09 21:26:09,504 [INFO] 	Process 1 - batch 4299: mean_policy_losses: 204.634, mean_net_lifetime: 4568.2697, mean_mc_travel_dist: 2480.9648, mean_rewards: 164.4363, total_rewards: 2126.3778, mean_steps: 26.9200, mean_ecr: 0.0402 mean_entropies: 2.2872, took: 112.0621s
2022-10-09 21:26:19,784 [INFO] 	Process 4 - batch 5399: mean_policy_losses: -151.998, mean_net_lifetime: 2649.8454, mean_mc_travel_dist: 1211.3299, mean_rewards: 147.6555, total_rewards: 1450.1702, mean_steps: 17.0500, mean_ecr: 0.0535 mean_entropies: 2.0722, took: 74.7605s
2022-10-09 21:27:33,819 [INFO] 	Process 4 - batch 5499: mean_policy_losses: -153.665, mean_net_lifetime: 2651.3223, mean_mc_travel_dist: 1238.3749, mean_rewards: 149.7745, total_rewards: 1428.1118, mean_steps: 16.8700, mean_ecr: 0.0532 mean_entropies: 2.1869, took: 74.0352s
2022-10-09 21:27:58,875 [INFO] 	Process 1 - batch 4399: mean_policy_losses: 231.277, mean_net_lifetime: 4534.6055, mean_mc_travel_dist: 2424.4397, mean_rewards: 168.0347, total_rewards: 2147.5686, mean_steps: 26.0300, mean_ecr: 0.0404 mean_entropies: 2.4044, took: 109.3708s
2022-10-09 21:28:47,252 [INFO] 	Process 4 - batch 5599: mean_policy_losses: -130.386, mean_net_lifetime: 2720.3190, mean_mc_travel_dist: 1258.0287, mean_rewards: 157.4718, total_rewards: 1481.8489, mean_steps: 16.3600, mean_ecr: 0.0530 mean_entropies: 2.2293, took: 73.4322s
2022-10-09 21:29:43,296 [INFO] 	Process 1 - batch 4499: mean_policy_losses: 196.132, mean_net_lifetime: 4499.6956, mean_mc_travel_dist: 2442.7738, mean_rewards: 168.2897, total_rewards: 2089.7622, mean_steps: 25.8100, mean_ecr: 0.0404 mean_entropies: 2.4044, took: 104.4207s
2022-10-09 21:29:59,302 [INFO] 	Process 4 - batch 5699: mean_policy_losses: -162.851, mean_net_lifetime: 2658.2848, mean_mc_travel_dist: 1276.4473, mean_rewards: 153.0546, total_rewards: 1404.5249, mean_steps: 16.5600, mean_ecr: 0.0530 mean_entropies: 2.2060, took: 72.0506s
2022-10-09 21:31:08,225 [INFO] 	Process 4 - batch 5799: mean_policy_losses: 41.750, mean_net_lifetime: 2649.6244, mean_mc_travel_dist: 1251.7213, mean_rewards: 154.9576, total_rewards: 1422.2793, mean_steps: 16.2000, mean_ecr: 0.0530 mean_entropies: 2.1986, took: 68.9227s
2022-10-09 21:31:57,375 [INFO] Process 2 - epoch 3: mean_policy_losses: -25.208, mean_net_lifetime: 3154.6956, mean_mc_travel_dist: 1707.6518, mean_entropies: 2.1485, m_net_lifetime_valid: 2903.2494, took: 2940.3355s, (267.8562 / 100 batches)

2022-10-09 21:32:12,094 [INFO] Process 5 - epoch 3: mean_policy_losses: -46.631, mean_net_lifetime: 3697.5096, mean_mc_travel_dist: 2247.1395, mean_entropies: 2.6082, m_net_lifetime_valid: 2906.0593, took: 2946.3678s, (269.0442 / 100 batches)

2022-10-09 21:32:20,246 [INFO] 	Process 4 - batch 5899: mean_policy_losses: 108.293, mean_net_lifetime: 2719.5432, mean_mc_travel_dist: 1243.5186, mean_rewards: 154.2207, total_rewards: 1489.4748, mean_steps: 16.7000, mean_ecr: 0.0530 mean_entropies: 2.1681, took: 72.0217s
2022-10-09 21:32:56,094 [INFO] Process 3 - epoch 3: mean_policy_losses: 215.127, mean_net_lifetime: 3590.5107, mean_mc_travel_dist: 1684.5784, mean_entropies: 2.0812, m_net_lifetime_valid: 2870.2492, took: 2979.6270s, (270.3531 / 100 batches)

2022-10-09 21:33:41,255 [INFO] 	Process 4 - batch 5999: mean_policy_losses: 121.380, mean_net_lifetime: 2632.7599, mean_mc_travel_dist: 1238.5486, mean_rewards: 142.4205, total_rewards: 1409.1339, mean_steps: 17.6400, mean_ecr: 0.0530 mean_entropies: 2.1014, took: 81.0087s
2022-10-09 21:33:46,888 [INFO] 	Process 2 - batch 4599: mean_policy_losses: -36.278, mean_net_lifetime: 2877.7680, mean_mc_travel_dist: 1582.6279, mean_rewards: 109.8154, total_rewards: 1318.9711, mean_steps: 25.4000, mean_ecr: 0.0426 mean_entropies: 1.7035, took: 1310.7900s
2022-10-09 21:33:50,828 [INFO] 	Process 5 - batch 4599: mean_policy_losses: -284.032, mean_net_lifetime: 2451.4201, mean_mc_travel_dist: 1608.2666, mean_rewards: 108.9715, total_rewards: 892.7276, mean_steps: 21.5600, mean_ecr: 0.0311 mean_entropies: 2.1447, took: 1259.9678s
2022-10-09 21:34:48,810 [INFO] 	Process 3 - batch 4599: mean_policy_losses: 253.132, mean_net_lifetime: 3532.9278, mean_mc_travel_dist: 1603.8265, mean_rewards: 138.7212, total_rewards: 1950.1686, mean_steps: 24.7700, mean_ecr: 0.0481 mean_entropies: 1.7509, took: 1257.0846s
2022-10-09 21:35:26,162 [INFO] 	Process 5 - batch 4699: mean_policy_losses: -71.018, mean_net_lifetime: 3319.9485, mean_mc_travel_dist: 1975.6731, mean_rewards: 139.9000, total_rewards: 1388.0861, mean_steps: 22.2800, mean_ecr: 0.0309 mean_entropies: 2.4464, took: 95.3342s
2022-10-09 21:35:32,065 [INFO] 	Process 2 - batch 4699: mean_policy_losses: -41.599, mean_net_lifetime: 2996.7129, mean_mc_travel_dist: 1600.5346, mean_rewards: 118.8459, total_rewards: 1420.8053, mean_steps: 24.4500, mean_ecr: 0.0423 mean_entropies: 1.8823, took: 105.1773s
2022-10-09 21:36:35,987 [INFO] 	Process 3 - batch 4699: mean_policy_losses: 192.247, mean_net_lifetime: 3673.6173, mean_mc_travel_dist: 1631.8479, mean_rewards: 146.5579, total_rewards: 2061.3289, mean_steps: 24.3300, mean_ecr: 0.0479 mean_entropies: 1.9240, took: 107.1769s
2022-10-09 21:37:08,508 [INFO] 	Process 5 - batch 4799: mean_policy_losses: -19.600, mean_net_lifetime: 3955.2815, mean_mc_travel_dist: 2309.6749, mean_rewards: 159.7885, total_rewards: 1698.2983, mean_steps: 23.5100, mean_ecr: 0.0311 mean_entropies: 2.6007, took: 102.3461s
2022-10-09 21:37:14,817 [INFO] 	Process 2 - batch 4799: mean_policy_losses: -92.577, mean_net_lifetime: 3257.0485, mean_mc_travel_dist: 1673.2989, mean_rewards: 132.3508, total_rewards: 1607.8385, mean_steps: 23.7300, mean_ecr: 0.0419 mean_entropies: 2.0257, took: 102.7523s
2022-10-09 21:37:19,928 [INFO] Process 7 - epoch 3: mean_policy_losses: 75.459, mean_net_lifetime: 3530.6638, mean_mc_travel_dist: 1779.4511, mean_entropies: 2.3342, m_net_lifetime_valid: 2902.0449, took: 3126.8427s, (276.2826 / 100 batches)

2022-10-09 21:38:26,565 [INFO] 	Process 3 - batch 4799: mean_policy_losses: 142.882, mean_net_lifetime: 3797.8638, mean_mc_travel_dist: 1657.0521, mean_rewards: 150.4512, total_rewards: 2156.8763, mean_steps: 24.5200, mean_ecr: 0.0478 mean_entropies: 1.9836, took: 110.5789s
2022-10-09 21:38:41,918 [INFO] Process 6 - epoch 5: mean_policy_losses: -333.850, mean_net_lifetime: 1639.1456, mean_mc_travel_dist: 993.1863, mean_entropies: 2.0439, m_net_lifetime_valid: 2857.7714, took: 1735.0037s, (169.6351 / 100 batches)

2022-10-09 21:39:02,425 [INFO] 	Process 2 - batch 4899: mean_policy_losses: -33.003, mean_net_lifetime: 3564.9527, mean_mc_travel_dist: 1770.5618, mean_rewards: 144.8235, total_rewards: 1820.4272, mean_steps: 23.7200, mean_ecr: 0.0416 mean_entropies: 2.1355, took: 107.6082s
2022-10-09 21:39:03,188 [INFO] 	Process 5 - batch 4899: mean_policy_losses: -44.012, mean_net_lifetime: 4208.2395, mean_mc_travel_dist: 2458.5498, mean_rewards: 156.8873, total_rewards: 1810.4133, mean_steps: 25.6000, mean_ecr: 0.0313 mean_entropies: 2.5596, took: 114.6801s
2022-10-09 21:39:27,675 [INFO] 	Process 6 - batch 7599: mean_policy_losses: -699.758, mean_net_lifetime: 1417.1717, mean_mc_travel_dist: 912.0511, mean_rewards: 146.4854, total_rewards: 559.3531, mean_steps: 8.7300, mean_ecr: 0.0559 mean_entropies: 1.9016, took: 1080.1272s
2022-10-09 21:39:28,769 [INFO] 	Process 7 - batch 4599: mean_policy_losses: -14.234, mean_net_lifetime: 3702.7545, mean_mc_travel_dist: 1798.2023, mean_rewards: 127.0740, total_rewards: 1946.5289, mean_steps: 28.4700, mean_ecr: 0.0436 mean_entropies: 2.2141, took: 1264.9049s
2022-10-09 21:40:16,400 [INFO] 	Process 6 - batch 7699: mean_policy_losses: -489.389, mean_net_lifetime: 1524.0705, mean_mc_travel_dist: 929.0975, mean_rewards: 152.6580, total_rewards: 636.0217, mean_steps: 8.9700, mean_ecr: 0.0561 mean_entropies: 1.9436, took: 48.7251s
2022-10-09 21:40:24,910 [INFO] 	Process 3 - batch 4899: mean_policy_losses: 312.757, mean_net_lifetime: 3816.1523, mean_mc_travel_dist: 1671.8173, mean_rewards: 148.0861, total_rewards: 2174.4657, mean_steps: 25.0300, mean_ecr: 0.0475 mean_entropies: 1.9650, took: 118.3447s
2022-10-09 21:40:53,700 [INFO] 	Process 2 - batch 4999: mean_policy_losses: 147.037, mean_net_lifetime: 3343.8867, mean_mc_travel_dist: 1685.6142, mean_rewards: 134.5965, total_rewards: 1684.6412, mean_steps: 23.9700, mean_ecr: 0.0418 mean_entropies: 1.9987, took: 111.2744s
2022-10-09 21:40:59,323 [INFO] 	Process 5 - batch 4999: mean_policy_losses: 272.250, mean_net_lifetime: 4194.1583, mean_mc_travel_dist: 2450.1506, mean_rewards: 162.0385, total_rewards: 1791.1656, mean_steps: 24.6700, mean_ecr: 0.0311 mean_entropies: 2.5375, took: 116.1357s
2022-10-09 21:41:00,885 [INFO] 	Process 6 - batch 7799: mean_policy_losses: -544.522, mean_net_lifetime: 1547.3418, mean_mc_travel_dist: 955.1930, mean_rewards: 167.4451, total_rewards: 646.5106, mean_steps: 8.1800, mean_ecr: 0.0563 mean_entropies: 1.9336, took: 44.4838s
2022-10-09 21:41:40,199 [INFO] 	Process 7 - batch 4699: mean_policy_losses: 222.107, mean_net_lifetime: 3665.2015, mean_mc_travel_dist: 1769.5779, mean_rewards: 126.2783, total_rewards: 1925.3770, mean_steps: 28.4600, mean_ecr: 0.0438 mean_entropies: 2.1874, took: 131.4301s
2022-10-09 21:41:51,593 [INFO] 	Process 6 - batch 7899: mean_policy_losses: -345.559, mean_net_lifetime: 1874.1799, mean_mc_travel_dist: 1025.6116, mean_rewards: 175.8413, total_rewards: 893.5665, mean_steps: 9.5400, mean_ecr: 0.0566 mean_entropies: 1.8415, took: 50.7092s
2022-10-09 21:42:34,906 [INFO] 	Process 3 - batch 4999: mean_policy_losses: 231.454, mean_net_lifetime: 3660.6935, mean_mc_travel_dist: 1598.8606, mean_rewards: 130.9691, total_rewards: 2081.8719, mean_steps: 27.4400, mean_ecr: 0.0482 mean_entropies: 1.6415, took: 129.9957s
2022-10-09 21:42:40,771 [INFO] 	Process 6 - batch 7999: mean_policy_losses: -322.801, mean_net_lifetime: 1864.6658, mean_mc_travel_dist: 1013.5997, mean_rewards: 177.7625, total_rewards: 896.3546, mean_steps: 9.4300, mean_ecr: 0.0567 mean_entropies: 1.7334, took: 49.1775s
2022-10-09 21:42:53,136 [INFO] 	Process 5 - batch 5099: mean_policy_losses: 265.483, mean_net_lifetime: 4228.6336, mean_mc_travel_dist: 2429.7815, mean_rewards: 163.3905, total_rewards: 1860.9711, mean_steps: 24.7100, mean_ecr: 0.0309 mean_entropies: 2.4844, took: 113.8125s
2022-10-09 21:42:56,135 [INFO] 	Process 2 - batch 5099: mean_policy_losses: -14.654, mean_net_lifetime: 3096.6586, mean_mc_travel_dist: 1633.0883, mean_rewards: 113.4322, total_rewards: 1484.1232, mean_steps: 26.4400, mean_ecr: 0.0422 mean_entropies: 1.6412, took: 122.4354s
2022-10-09 21:43:30,027 [INFO] 	Process 6 - batch 8099: mean_policy_losses: -364.533, mean_net_lifetime: 1934.2952, mean_mc_travel_dist: 1051.3266, mean_rewards: 185.3384, total_rewards: 931.9251, mean_steps: 9.2400, mean_ecr: 0.0568 mean_entropies: 1.8165, took: 49.2564s
2022-10-09 21:43:55,645 [INFO] 	Process 7 - batch 4799: mean_policy_losses: 261.122, mean_net_lifetime: 3886.0669, mean_mc_travel_dist: 1875.3711, mean_rewards: 129.3689, total_rewards: 2045.4901, mean_steps: 29.5400, mean_ecr: 0.0434 mean_entropies: 2.1338, took: 135.4466s
2022-10-09 21:44:18,058 [INFO] 	Process 6 - batch 8199: mean_policy_losses: -317.856, mean_net_lifetime: 1893.7673, mean_mc_travel_dist: 1035.5272, mean_rewards: 183.4487, total_rewards: 915.0631, mean_steps: 9.2600, mean_ecr: 0.0571 mean_entropies: 1.7119, took: 48.0308s
2022-10-09 21:44:44,447 [INFO] 	Process 3 - batch 5099: mean_policy_losses: 162.533, mean_net_lifetime: 3525.2192, mean_mc_travel_dist: 1594.5848, mean_rewards: 124.8471, total_rewards: 1953.5674, mean_steps: 27.7000, mean_ecr: 0.0482 mean_entropies: 1.4925, took: 129.5412s
2022-10-09 21:44:52,165 [INFO] 	Process 5 - batch 5199: mean_policy_losses: 316.214, mean_net_lifetime: 4360.8599, mean_mc_travel_dist: 2443.5051, mean_rewards: 167.3576, total_rewards: 1969.0837, mean_steps: 24.7400, mean_ecr: 0.0311 mean_entropies: 2.4329, took: 119.0291s
2022-10-09 21:45:02,771 [INFO] 	Process 2 - batch 5199: mean_policy_losses: -23.989, mean_net_lifetime: 3078.2673, mean_mc_travel_dist: 1619.1475, mean_rewards: 108.8770, total_rewards: 1483.6216, mean_steps: 27.4600, mean_ecr: 0.0422 mean_entropies: 1.4789, took: 126.6346s
2022-10-09 21:45:07,049 [INFO] 	Process 6 - batch 8299: mean_policy_losses: -290.641, mean_net_lifetime: 1955.1088, mean_mc_travel_dist: 1047.8081, mean_rewards: 184.3503, total_rewards: 944.9730, mean_steps: 9.5500, mean_ecr: 0.0569 mean_entropies: 1.6663, took: 48.9912s
2022-10-09 21:45:57,978 [INFO] 	Process 6 - batch 8399: mean_policy_losses: -380.572, mean_net_lifetime: 1885.9546, mean_mc_travel_dist: 1038.3701, mean_rewards: 180.7982, total_rewards: 894.3935, mean_steps: 9.3700, mean_ecr: 0.0568 mean_entropies: 1.7188, took: 50.9293s
2022-10-09 21:46:07,413 [INFO] 	Process 7 - batch 4899: mean_policy_losses: 263.494, mean_net_lifetime: 3882.1728, mean_mc_travel_dist: 1872.5397, mean_rewards: 131.4828, total_rewards: 2038.3270, mean_steps: 28.8000, mean_ecr: 0.0434 mean_entropies: 2.1165, took: 131.7678s
2022-10-09 21:46:48,119 [INFO] 	Process 6 - batch 8499: mean_policy_losses: -323.058, mean_net_lifetime: 1937.6771, mean_mc_travel_dist: 1045.3268, mean_rewards: 185.1247, total_rewards: 935.7794, mean_steps: 9.4300, mean_ecr: 0.0567 mean_entropies: 1.7472, took: 50.1404s
2022-10-09 21:46:50,340 [INFO] 	Process 5 - batch 5299: mean_policy_losses: 239.030, mean_net_lifetime: 4227.4994, mean_mc_travel_dist: 2413.4742, mean_rewards: 160.4843, total_rewards: 1875.3519, mean_steps: 25.0000, mean_ecr: 0.0312 mean_entropies: 2.4094, took: 118.1742s
2022-10-09 21:46:52,222 [INFO] 	Process 3 - batch 5199: mean_policy_losses: 166.096, mean_net_lifetime: 3533.1176, mean_mc_travel_dist: 1589.9821, mean_rewards: 125.5840, total_rewards: 1961.4901, mean_steps: 27.6200, mean_ecr: 0.0485 mean_entropies: 1.4735, took: 127.7757s
2022-10-09 21:47:09,144 [INFO] 	Process 2 - batch 5299: mean_policy_losses: -11.775, mean_net_lifetime: 3086.5179, mean_mc_travel_dist: 1598.8761, mean_rewards: 110.8474, total_rewards: 1506.9885, mean_steps: 27.1400, mean_ecr: 0.0422 mean_entropies: 1.5146, took: 126.3742s
2022-10-09 21:47:38,413 [INFO] 	Process 6 - batch 8599: mean_policy_losses: -341.660, mean_net_lifetime: 1924.2507, mean_mc_travel_dist: 1058.9726, mean_rewards: 181.2905, total_rewards: 918.7246, mean_steps: 9.4500, mean_ecr: 0.0569 mean_entropies: 1.6682, took: 50.2940s
2022-10-09 21:48:15,707 [INFO] 	Process 7 - batch 4999: mean_policy_losses: 298.045, mean_net_lifetime: 3926.2549, mean_mc_travel_dist: 1899.2400, mean_rewards: 136.7655, total_rewards: 2061.5011, mean_steps: 27.9800, mean_ecr: 0.0433 mean_entropies: 2.1238, took: 128.2946s
2022-10-09 21:48:28,735 [INFO] 	Process 6 - batch 8699: mean_policy_losses: -309.238, mean_net_lifetime: 1904.8875, mean_mc_travel_dist: 1017.9487, mean_rewards: 182.0866, total_rewards: 916.0608, mean_steps: 9.4200, mean_ecr: 0.0567 mean_entropies: 1.6120, took: 50.3214s
2022-10-09 21:48:44,479 [INFO] 	Process 5 - batch 5399: mean_policy_losses: 187.490, mean_net_lifetime: 4100.3555, mean_mc_travel_dist: 2404.2900, mean_rewards: 163.2580, total_rewards: 1756.7091, mean_steps: 23.8300, mean_ecr: 0.0311 mean_entropies: 2.3774, took: 114.1389s
2022-10-09 21:48:56,076 [INFO] Process 1 - epoch 3: mean_policy_losses: 305.088, mean_net_lifetime: 4544.7871, mean_mc_travel_dist: 2365.1515, mean_entropies: 2.2982, m_net_lifetime_valid: 2811.3495, took: 3303.7610s, (291.0542 / 100 batches)

2022-10-09 21:49:05,908 [INFO] 	Process 3 - batch 5299: mean_policy_losses: 141.045, mean_net_lifetime: 3551.2214, mean_mc_travel_dist: 1617.3331, mean_rewards: 121.3457, total_rewards: 1957.3547, mean_steps: 28.7300, mean_ecr: 0.0483 mean_entropies: 1.4029, took: 133.6860s
2022-10-09 21:49:16,203 [INFO] 	Process 2 - batch 5399: mean_policy_losses: -0.658, mean_net_lifetime: 3141.7723, mean_mc_travel_dist: 1612.6331, mean_rewards: 110.9108, total_rewards: 1547.6718, mean_steps: 27.5000, mean_ecr: 0.0420 mean_entropies: 1.4316, took: 127.0586s
2022-10-09 21:49:21,304 [INFO] 	Process 6 - batch 8799: mean_policy_losses: -334.442, mean_net_lifetime: 1996.6859, mean_mc_travel_dist: 1065.7740, mean_rewards: 183.1244, total_rewards: 977.0305, mean_steps: 9.7600, mean_ecr: 0.0569 mean_entropies: 1.6036, took: 52.5700s
2022-10-09 21:50:15,971 [INFO] 	Process 6 - batch 8899: mean_policy_losses: -330.715, mean_net_lifetime: 1969.1179, mean_mc_travel_dist: 1053.1430, mean_rewards: 180.7213, total_rewards: 949.5607, mean_steps: 9.8900, mean_ecr: 0.0569 mean_entropies: 1.5954, took: 54.6666s
2022-10-09 21:50:33,222 [INFO] 	Process 7 - batch 5099: mean_policy_losses: 218.130, mean_net_lifetime: 3924.2847, mean_mc_travel_dist: 1894.9365, mean_rewards: 131.4893, total_rewards: 2069.9629, mean_steps: 29.2100, mean_ecr: 0.0433 mean_entropies: 2.1040, took: 137.5134s
2022-10-09 21:50:45,161 [INFO] 	Process 5 - batch 5499: mean_policy_losses: 231.355, mean_net_lifetime: 4314.8188, mean_mc_travel_dist: 2491.0030, mean_rewards: 165.9154, total_rewards: 1901.9322, mean_steps: 24.7200, mean_ecr: 0.0311 mean_entropies: 2.3836, took: 120.6830s
2022-10-09 21:51:07,666 [INFO] 	Process 6 - batch 8999: mean_policy_losses: -337.051, mean_net_lifetime: 1991.6104, mean_mc_travel_dist: 1055.2148, mean_rewards: 181.4110, total_rewards: 980.7440, mean_steps: 9.8400, mean_ecr: 0.0570 mean_entropies: 1.5979, took: 51.6955s
2022-10-09 21:51:26,463 [INFO] 	Process 3 - batch 5399: mean_policy_losses: 67.727, mean_net_lifetime: 3478.2924, mean_mc_travel_dist: 1605.8761, mean_rewards: 117.9105, total_rewards: 1886.2968, mean_steps: 28.9800, mean_ecr: 0.0483 mean_entropies: 1.3780, took: 140.5543s
2022-10-09 21:51:27,276 [INFO] 	Process 2 - batch 5499: mean_policy_losses: -52.927, mean_net_lifetime: 3102.8078, mean_mc_travel_dist: 1610.0914, mean_rewards: 109.4298, total_rewards: 1519.1711, mean_steps: 27.6100, mean_ecr: 0.0422 mean_entropies: 1.3945, took: 131.0737s
2022-10-09 21:52:11,189 [INFO] 	Process 1 - batch 4599: mean_policy_losses: 97.179, mean_net_lifetime: 4534.4158, mean_mc_travel_dist: 2387.7446, mean_rewards: 107.9171, total_rewards: 2172.0946, mean_steps: 41.4500, mean_ecr: 0.0396 mean_entropies: 1.6492, took: 1347.8930s
2022-10-09 21:52:45,424 [INFO] 	Process 5 - batch 5599: mean_policy_losses: 156.935, mean_net_lifetime: 4481.7656, mean_mc_travel_dist: 2532.9906, mean_rewards: 169.4991, total_rewards: 2004.3185, mean_steps: 25.2200, mean_ecr: 0.0311 mean_entropies: 2.4178, took: 120.2625s
2022-10-09 21:52:48,062 [INFO] 	Process 7 - batch 5199: mean_policy_losses: 91.746, mean_net_lifetime: 3934.6368, mean_mc_travel_dist: 1879.1508, mean_rewards: 131.3976, total_rewards: 2094.9168, mean_steps: 29.0900, mean_ecr: 0.0434 mean_entropies: 2.1563, took: 134.8415s
2022-10-09 21:52:57,941 [INFO] Process 4 - epoch 4: mean_policy_losses: 6.256, mean_net_lifetime: 2521.9927, mean_mc_travel_dist: 1234.8852, mean_entropies: 2.0712, m_net_lifetime_valid: 2809.0941, took: 2374.7992s, (223.3825 / 100 batches)

2022-10-09 21:53:30,362 [INFO] 	Process 2 - batch 5599: mean_policy_losses: -112.712, mean_net_lifetime: 3201.3532, mean_mc_travel_dist: 1638.9841, mean_rewards: 117.9403, total_rewards: 1584.0696, mean_steps: 26.3200, mean_ecr: 0.0420 mean_entropies: 1.6770, took: 123.0862s
2022-10-09 21:53:34,168 [INFO] 	Process 3 - batch 5499: mean_policy_losses: 103.524, mean_net_lifetime: 3641.6551, mean_mc_travel_dist: 1602.4124, mean_rewards: 133.7033, total_rewards: 2060.6807, mean_steps: 26.6900, mean_ecr: 0.0481 mean_entropies: 1.6342, took: 127.7054s
2022-10-09 21:54:34,908 [INFO] 	Process 4 - batch 6099: mean_policy_losses: -143.076, mean_net_lifetime: 2536.1942, mean_mc_travel_dist: 1197.2390, mean_rewards: 126.9013, total_rewards: 1352.6091, mean_steps: 19.2600, mean_ecr: 0.0534 mean_entropies: 1.7834, took: 1253.6528s
2022-10-09 21:54:47,339 [INFO] 	Process 5 - batch 5699: mean_policy_losses: 90.788, mean_net_lifetime: 4291.9172, mean_mc_travel_dist: 2464.2057, mean_rewards: 161.7450, total_rewards: 1876.9220, mean_steps: 25.2600, mean_ecr: 0.0310 mean_entropies: 2.5260, took: 121.9148s
2022-10-09 21:54:55,252 [INFO] 	Process 7 - batch 5299: mean_policy_losses: 51.140, mean_net_lifetime: 3698.5387, mean_mc_travel_dist: 1818.8035, mean_rewards: 137.2963, total_rewards: 1912.9081, mean_steps: 26.4600, mean_ecr: 0.0435 mean_entropies: 2.2475, took: 127.1902s
2022-10-09 21:55:08,862 [INFO] 	Process 1 - batch 4699: mean_policy_losses: 87.378, mean_net_lifetime: 4530.2370, mean_mc_travel_dist: 2353.5465, mean_rewards: 118.8011, total_rewards: 2211.3329, mean_steps: 37.6000, mean_ecr: 0.0397 mean_entropies: 1.9304, took: 177.6737s
2022-10-09 21:55:29,529 [INFO] 	Process 2 - batch 5699: mean_policy_losses: -92.422, mean_net_lifetime: 3204.6696, mean_mc_travel_dist: 1647.8983, mean_rewards: 125.3560, total_rewards: 1577.5301, mean_steps: 24.7300, mean_ecr: 0.0419 mean_entropies: 1.8888, took: 119.1664s
2022-10-09 21:55:35,357 [INFO] 	Process 3 - batch 5599: mean_policy_losses: 188.422, mean_net_lifetime: 3722.9064, mean_mc_travel_dist: 1632.8980, mean_rewards: 148.2950, total_rewards: 2109.8581, mean_steps: 24.4900, mean_ecr: 0.0481 mean_entropies: 1.8285, took: 121.1883s
2022-10-09 21:56:06,769 [INFO] 	Process 4 - batch 6199: mean_policy_losses: -155.911, mean_net_lifetime: 2539.1764, mean_mc_travel_dist: 1183.1317, mean_rewards: 132.6812, total_rewards: 1363.2035, mean_steps: 18.3700, mean_ecr: 0.0534 mean_entropies: 1.8899, took: 91.8608s
2022-10-09 21:56:44,035 [INFO] 	Process 5 - batch 5799: mean_policy_losses: -0.400, mean_net_lifetime: 4014.7102, mean_mc_travel_dist: 2334.1185, mean_rewards: 158.9814, total_rewards: 1736.2537, mean_steps: 23.9100, mean_ecr: 0.0307 mean_entropies: 2.5869, took: 116.6963s
2022-10-09 21:56:58,701 [INFO] 	Process 7 - batch 5399: mean_policy_losses: 91.110, mean_net_lifetime: 3756.4649, mean_mc_travel_dist: 1832.9970, mean_rewards: 140.5001, total_rewards: 1960.6884, mean_steps: 25.8000, mean_ecr: 0.0434 mean_entropies: 2.2923, took: 123.4482s
2022-10-09 21:57:26,235 [INFO] 	Process 2 - batch 5799: mean_policy_losses: -66.975, mean_net_lifetime: 3257.8224, mean_mc_travel_dist: 1658.5314, mean_rewards: 130.2738, total_rewards: 1618.6289, mean_steps: 24.1500, mean_ecr: 0.0419 mean_entropies: 1.9515, took: 116.7064s
2022-10-09 21:57:34,577 [INFO] 	Process 3 - batch 5699: mean_policy_losses: 191.676, mean_net_lifetime: 3709.0206, mean_mc_travel_dist: 1630.2716, mean_rewards: 147.3362, total_rewards: 2100.0282, mean_steps: 24.4500, mean_ecr: 0.0480 mean_entropies: 1.8944, took: 119.2201s
2022-10-09 21:57:38,414 [INFO] 	Process 4 - batch 6299: mean_policy_losses: -152.015, mean_net_lifetime: 2559.0096, mean_mc_travel_dist: 1202.0183, mean_rewards: 135.3837, total_rewards: 1367.1863, mean_steps: 18.1300, mean_ecr: 0.0533 mean_entropies: 1.9305, took: 91.6453s
2022-10-09 21:57:54,784 [INFO] 	Process 1 - batch 4799: mean_policy_losses: 194.622, mean_net_lifetime: 4590.2940, mean_mc_travel_dist: 2319.4348, mean_rewards: 130.0294, total_rewards: 2297.5808, mean_steps: 34.6900, mean_ecr: 0.0399 mean_entropies: 2.0906, took: 165.9216s
2022-10-09 21:58:40,727 [INFO] 	Process 5 - batch 5899: mean_policy_losses: -20.569, mean_net_lifetime: 4037.0787, mean_mc_travel_dist: 2325.4603, mean_rewards: 156.6512, total_rewards: 1775.7012, mean_steps: 24.3700, mean_ecr: 0.0307 mean_entropies: 2.5826, took: 116.6917s
2022-10-09 21:58:59,405 [INFO] 	Process 7 - batch 5499: mean_policy_losses: -0.985, mean_net_lifetime: 3584.0958, mean_mc_travel_dist: 1777.0950, mean_rewards: 139.2916, total_rewards: 1845.5576, mean_steps: 25.0300, mean_ecr: 0.0435 mean_entropies: 2.3028, took: 120.7045s
2022-10-09 21:59:08,632 [INFO] 	Process 4 - batch 6399: mean_policy_losses: -185.817, mean_net_lifetime: 2521.0887, mean_mc_travel_dist: 1184.9350, mean_rewards: 134.3613, total_rewards: 1349.4060, mean_steps: 17.9700, mean_ecr: 0.0533 mean_entropies: 1.9475, took: 90.2182s
2022-10-09 21:59:23,755 [INFO] 	Process 2 - batch 5899: mean_policy_losses: -99.370, mean_net_lifetime: 3278.9181, mean_mc_travel_dist: 1687.4748, mean_rewards: 129.2730, total_rewards: 1616.2603, mean_steps: 24.5200, mean_ecr: 0.0419 mean_entropies: 1.9680, took: 117.5202s
2022-10-09 21:59:35,031 [INFO] 	Process 3 - batch 5799: mean_policy_losses: 185.092, mean_net_lifetime: 3750.7423, mean_mc_travel_dist: 1642.1214, mean_rewards: 149.8062, total_rewards: 2137.9452, mean_steps: 24.3100, mean_ecr: 0.0479 mean_entropies: 1.9278, took: 120.4543s
2022-10-09 22:00:26,849 [INFO] 	Process 1 - batch 4899: mean_policy_losses: 197.308, mean_net_lifetime: 4521.9201, mean_mc_travel_dist: 2295.7368, mean_rewards: 137.4161, total_rewards: 2261.5339, mean_steps: 32.3100, mean_ecr: 0.0400 mean_entropies: 2.1397, took: 152.0648s
2022-10-09 22:00:36,532 [INFO] 	Process 4 - batch 6499: mean_policy_losses: -163.127, mean_net_lifetime: 2508.3480, mean_mc_travel_dist: 1187.2177, mean_rewards: 137.8455, total_rewards: 1336.8847, mean_steps: 17.4400, mean_ecr: 0.0533 mean_entropies: 1.9940, took: 87.8995s
2022-10-09 22:00:41,971 [INFO] 	Process 5 - batch 5999: mean_policy_losses: -85.736, mean_net_lifetime: 3875.9185, mean_mc_travel_dist: 2267.3750, mean_rewards: 149.5844, total_rewards: 1664.3737, mean_steps: 24.4400, mean_ecr: 0.0307 mean_entropies: 2.5960, took: 121.2436s
2022-10-09 22:01:02,796 [INFO] 	Process 7 - batch 5599: mean_policy_losses: 40.586, mean_net_lifetime: 3642.9344, mean_mc_travel_dist: 1770.2852, mean_rewards: 137.3325, total_rewards: 1913.9202, mean_steps: 26.0400, mean_ecr: 0.0435 mean_entropies: 2.3186, took: 123.3913s
2022-10-09 22:01:16,804 [INFO] 	Process 2 - batch 5999: mean_policy_losses: -107.933, mean_net_lifetime: 3172.8100, mean_mc_travel_dist: 1661.5243, mean_rewards: 128.7916, total_rewards: 1536.7151, mean_steps: 23.8200, mean_ecr: 0.0420 mean_entropies: 2.0004, took: 113.0476s
2022-10-09 22:01:27,315 [INFO] 	Process 3 - batch 5899: mean_policy_losses: 200.551, mean_net_lifetime: 3673.5195, mean_mc_travel_dist: 1626.8010, mean_rewards: 152.5818, total_rewards: 2070.3087, mean_steps: 23.3600, mean_ecr: 0.0479 mean_entropies: 1.9524, took: 112.2831s
2022-10-09 22:02:03,355 [INFO] 	Process 4 - batch 6599: mean_policy_losses: -209.656, mean_net_lifetime: 2548.4523, mean_mc_travel_dist: 1204.5452, mean_rewards: 133.3740, total_rewards: 1359.6672, mean_steps: 18.2500, mean_ecr: 0.0532 mean_entropies: 1.9972, took: 86.8230s
2022-10-09 22:02:49,691 [INFO] 	Process 1 - batch 4999: mean_policy_losses: 180.185, mean_net_lifetime: 4567.9937, mean_mc_travel_dist: 2305.3358, mean_rewards: 137.8701, total_rewards: 2282.3658, mean_steps: 32.5200, mean_ecr: 0.0399 mean_entropies: 2.1853, took: 142.8417s
2022-10-09 22:02:58,501 [INFO] 	Process 7 - batch 5699: mean_policy_losses: -14.381, mean_net_lifetime: 3727.3789, mean_mc_travel_dist: 1816.7447, mean_rewards: 140.4272, total_rewards: 1948.0669, mean_steps: 25.6900, mean_ecr: 0.0435 mean_entropies: 2.3278, took: 115.7046s
2022-10-09 22:03:14,507 [INFO] 	Process 3 - batch 5999: mean_policy_losses: 100.566, mean_net_lifetime: 3667.2377, mean_mc_travel_dist: 1613.2254, mean_rewards: 149.8603, total_rewards: 2068.9380, mean_steps: 23.7000, mean_ecr: 0.0480 mean_entropies: 1.9559, took: 107.1922s
2022-10-09 22:03:27,193 [INFO] 	Process 4 - batch 6699: mean_policy_losses: -207.281, mean_net_lifetime: 2613.5527, mean_mc_travel_dist: 1217.3680, mean_rewards: 139.8926, total_rewards: 1411.1283, mean_steps: 17.8500, mean_ecr: 0.0534 mean_entropies: 2.0518, took: 83.8377s
2022-10-09 22:04:43,677 [INFO] 	Process 7 - batch 5799: mean_policy_losses: -54.490, mean_net_lifetime: 3614.2995, mean_mc_travel_dist: 1798.9638, mean_rewards: 144.8117, total_rewards: 1853.5111, mean_steps: 24.1800, mean_ecr: 0.0434 mean_entropies: 2.3565, took: 105.1766s
2022-10-09 22:04:49,385 [INFO] 	Process 4 - batch 6799: mean_policy_losses: -187.540, mean_net_lifetime: 2633.9654, mean_mc_travel_dist: 1225.3679, mean_rewards: 139.6470, total_rewards: 1422.7357, mean_steps: 17.9700, mean_ecr: 0.0531 mean_entropies: 2.0624, took: 82.1931s
2022-10-09 22:04:59,945 [INFO] 	Process 1 - batch 5099: mean_policy_losses: 206.017, mean_net_lifetime: 4589.7764, mean_mc_travel_dist: 2337.2864, mean_rewards: 147.9418, total_rewards: 2284.2327, mean_steps: 30.2200, mean_ecr: 0.0400 mean_entropies: 2.2741, took: 130.2550s
2022-10-09 22:06:09,084 [INFO] 	Process 4 - batch 6899: mean_policy_losses: -178.473, mean_net_lifetime: 2556.8392, mean_mc_travel_dist: 1191.9698, mean_rewards: 142.5601, total_rewards: 1376.0334, mean_steps: 17.1600, mean_ecr: 0.0535 mean_entropies: 2.0738, took: 79.6991s
2022-10-09 22:06:25,326 [INFO] 	Process 7 - batch 5899: mean_policy_losses: -64.780, mean_net_lifetime: 3478.1693, mean_mc_travel_dist: 1768.8360, mean_rewards: 145.8452, total_rewards: 1752.8934, mean_steps: 22.9800, mean_ecr: 0.0435 mean_entropies: 2.3942, took: 101.6479s
2022-10-09 22:07:05,214 [INFO] 	Process 1 - batch 5199: mean_policy_losses: 232.597, mean_net_lifetime: 4606.4060, mean_mc_travel_dist: 2363.7934, mean_rewards: 152.0554, total_rewards: 2272.4402, mean_steps: 29.4700, mean_ecr: 0.0399 mean_entropies: 2.3017, took: 125.2681s
2022-10-09 22:07:28,464 [INFO] 	Process 4 - batch 6999: mean_policy_losses: -160.467, mean_net_lifetime: 2661.2559, mean_mc_travel_dist: 1244.1381, mean_rewards: 146.0821, total_rewards: 1434.4098, mean_steps: 17.3500, mean_ecr: 0.0532 mean_entropies: 2.1109, took: 79.3792s
2022-10-09 22:08:03,298 [INFO] 	Process 7 - batch 5999: mean_policy_losses: -64.276, mean_net_lifetime: 3523.0943, mean_mc_travel_dist: 1822.9813, mean_rewards: 150.1619, total_rewards: 1744.6542, mean_steps: 22.4000, mean_ecr: 0.0433 mean_entropies: 2.4369, took: 97.9721s
2022-10-09 22:08:46,155 [INFO] 	Process 4 - batch 7099: mean_policy_losses: -128.232, mean_net_lifetime: 2723.8391, mean_mc_travel_dist: 1262.7807, mean_rewards: 148.7672, total_rewards: 1477.8204, mean_steps: 17.4100, mean_ecr: 0.0531 mean_entropies: 2.1157, took: 77.6911s
2022-10-09 22:09:05,228 [INFO] 	Process 1 - batch 5299: mean_policy_losses: 270.477, mean_net_lifetime: 4614.3093, mean_mc_travel_dist: 2391.1033, mean_rewards: 158.7666, total_rewards: 2259.2256, mean_steps: 28.3600, mean_ecr: 0.0400 mean_entropies: 2.3457, took: 120.0143s
2022-10-09 22:10:02,189 [INFO] 	Process 4 - batch 7199: mean_policy_losses: -189.049, mean_net_lifetime: 2599.6544, mean_mc_travel_dist: 1226.8042, mean_rewards: 144.2352, total_rewards: 1391.7506, mean_steps: 17.2100, mean_ecr: 0.0533 mean_entropies: 2.1384, took: 76.0340s
2022-10-09 22:10:58,310 [INFO] 	Process 1 - batch 5399: mean_policy_losses: 316.585, mean_net_lifetime: 4669.3826, mean_mc_travel_dist: 2399.9330, mean_rewards: 166.2780, total_rewards: 2296.0722, mean_steps: 27.2100, mean_ecr: 0.0401 mean_entropies: 2.3847, took: 113.0812s
2022-10-09 22:11:09,875 [INFO] Process 6 - epoch 6: mean_policy_losses: -341.895, mean_net_lifetime: 1672.8523, mean_mc_travel_dist: 997.7104, mean_entropies: 1.9931, m_net_lifetime_valid: 2919.0917, took: 1947.9547s, (161.2350 / 100 batches)

2022-10-09 22:11:17,552 [INFO] 	Process 4 - batch 7299: mean_policy_losses: -158.239, mean_net_lifetime: 2693.4254, mean_mc_travel_dist: 1246.7517, mean_rewards: 150.5481, total_rewards: 1455.7806, mean_steps: 17.0500, mean_ecr: 0.0533 mean_entropies: 2.1645, took: 75.3626s
2022-10-09 22:11:50,959 [INFO] 	Process 6 - batch 9099: mean_policy_losses: -643.243, mean_net_lifetime: 1315.2560, mean_mc_travel_dist: 858.8481, mean_rewards: 139.5149, total_rewards: 521.4475, mean_steps: 8.3900, mean_ecr: 0.0569 mean_entropies: 1.9027, took: 1243.2929s
2022-10-09 22:12:33,052 [INFO] 	Process 6 - batch 9199: mean_policy_losses: -413.885, mean_net_lifetime: 1490.1376, mean_mc_travel_dist: 930.7616, mean_rewards: 160.7551, total_rewards: 628.9009, mean_steps: 8.2600, mean_ecr: 0.0570 mean_entropies: 1.8434, took: 42.0926s
2022-10-09 22:12:38,474 [INFO] 	Process 4 - batch 7399: mean_policy_losses: 278.614, mean_net_lifetime: 2723.6143, mean_mc_travel_dist: 1223.0084, mean_rewards: 144.2902, total_rewards: 1515.9791, mean_steps: 18.0500, mean_ecr: 0.0532 mean_entropies: 2.0384, took: 80.9223s
2022-10-09 22:12:54,128 [INFO] 	Process 1 - batch 5499: mean_policy_losses: 564.351, mean_net_lifetime: 4653.6459, mean_mc_travel_dist: 2434.7414, mean_rewards: 162.4677, total_rewards: 2262.5472, mean_steps: 27.7900, mean_ecr: 0.0400 mean_entropies: 2.2667, took: 115.8192s
2022-10-09 22:13:18,478 [INFO] 	Process 6 - batch 9299: mean_policy_losses: -235.812, mean_net_lifetime: 1997.6542, mean_mc_travel_dist: 1059.0858, mean_rewards: 180.5489, total_rewards: 997.5202, mean_steps: 9.8100, mean_ecr: 0.0568 mean_entropies: 1.5345, took: 45.4262s
2022-10-09 22:14:07,729 [INFO] 	Process 4 - batch 7499: mean_policy_losses: -11.080, mean_net_lifetime: 2510.3035, mean_mc_travel_dist: 1168.7086, mean_rewards: 119.9396, total_rewards: 1358.9813, mean_steps: 20.1000, mean_ecr: 0.0534 mean_entropies: 1.6448, took: 89.2552s
2022-10-09 22:14:11,144 [INFO] 	Process 6 - batch 9399: mean_policy_losses: -140.633, mean_net_lifetime: 2399.5542, mean_mc_travel_dist: 1180.5735, mean_rewards: 190.9959, total_rewards: 1267.3525, mean_steps: 11.2600, mean_ecr: 0.0567 mean_entropies: 1.3268, took: 52.6655s
2022-10-09 22:14:57,998 [INFO] 	Process 1 - batch 5599: mean_policy_losses: 261.695, mean_net_lifetime: 4508.0746, mean_mc_travel_dist: 2437.9324, mean_rewards: 146.6261, total_rewards: 2105.6662, mean_steps: 29.9900, mean_ecr: 0.0399 mean_entropies: 1.8616, took: 123.8692s
2022-10-09 22:15:03,396 [INFO] 	Process 6 - batch 9499: mean_policy_losses: -225.202, mean_net_lifetime: 2508.2016, mean_mc_travel_dist: 1217.1590, mean_rewards: 203.9100, total_rewards: 1330.2980, mean_steps: 11.1300, mean_ecr: 0.0566 mean_entropies: 1.2703, took: 52.2523s
2022-10-09 22:15:57,032 [INFO] 	Process 6 - batch 9599: mean_policy_losses: -251.413, mean_net_lifetime: 2589.7026, mean_mc_travel_dist: 1232.2189, mean_rewards: 202.9865, total_rewards: 1408.5633, mean_steps: 11.6700, mean_ecr: 0.0567 mean_entropies: 1.2016, took: 53.6353s
2022-10-09 22:16:53,284 [INFO] 	Process 6 - batch 9699: mean_policy_losses: -236.350, mean_net_lifetime: 2616.6628, mean_mc_travel_dist: 1257.2013, mean_rewards: 196.2576, total_rewards: 1405.3161, mean_steps: 12.1600, mean_ecr: 0.0565 mean_entropies: 1.1364, took: 56.2520s
2022-10-09 22:17:00,005 [INFO] 	Process 1 - batch 5699: mean_policy_losses: 46.200, mean_net_lifetime: 4475.4648, mean_mc_travel_dist: 2472.7631, mean_rewards: 144.4693, total_rewards: 2043.3646, mean_steps: 30.2200, mean_ecr: 0.0399 mean_entropies: 1.7777, took: 122.0083s
2022-10-09 22:17:50,048 [INFO] 	Process 6 - batch 9799: mean_policy_losses: -189.883, mean_net_lifetime: 2767.8014, mean_mc_travel_dist: 1280.0133, mean_rewards: 208.2500, total_rewards: 1526.4141, mean_steps: 12.2500, mean_ecr: 0.0563 mean_entropies: 1.1069, took: 56.7647s
2022-10-09 22:18:48,325 [INFO] 	Process 6 - batch 9899: mean_policy_losses: -154.687, mean_net_lifetime: 2922.5288, mean_mc_travel_dist: 1341.0946, mean_rewards: 205.4025, total_rewards: 1625.7264, mean_steps: 13.1200, mean_ecr: 0.0559 mean_entropies: 1.0692, took: 58.2775s
2022-10-09 22:18:54,520 [INFO] 	Process 1 - batch 5799: mean_policy_losses: 3.187, mean_net_lifetime: 4486.9437, mean_mc_travel_dist: 2553.1563, mean_rewards: 151.4561, total_rewards: 1964.3607, mean_steps: 28.7800, mean_ecr: 0.0398 mean_entropies: 1.7624, took: 114.5139s
2022-10-09 22:19:47,996 [INFO] 	Process 6 - batch 9999: mean_policy_losses: -219.633, mean_net_lifetime: 2803.9715, mean_mc_travel_dist: 1299.8685, mean_rewards: 200.4401, total_rewards: 1553.0073, mean_steps: 12.7700, mean_ecr: 0.0561 mean_entropies: 1.0602, took: 59.6703s
2022-10-09 22:20:15,950 [INFO] Process 5 - epoch 4: mean_policy_losses: -14.404, mean_net_lifetime: 3774.1756, mean_mc_travel_dist: 2267.1633, mean_entropies: 2.5743, m_net_lifetime_valid: 2928.9710, took: 2883.8550s, (249.9532 / 100 batches)

2022-10-09 22:20:47,846 [INFO] 	Process 6 - batch 10099: mean_policy_losses: -196.954, mean_net_lifetime: 2838.6044, mean_mc_travel_dist: 1324.9456, mean_rewards: 204.8796, total_rewards: 1560.4066, mean_steps: 12.7800, mean_ecr: 0.0562 mean_entropies: 1.0366, took: 59.8502s
2022-10-09 22:20:56,719 [INFO] 	Process 1 - batch 5899: mean_policy_losses: 21.019, mean_net_lifetime: 4481.3960, mean_mc_travel_dist: 2564.9563, mean_rewards: 148.5513, total_rewards: 1954.8837, mean_steps: 29.3600, mean_ecr: 0.0396 mean_entropies: 1.7345, took: 122.1996s
2022-10-09 22:21:00,429 [INFO] Process 2 - epoch 4: mean_policy_losses: -29.570, mean_net_lifetime: 3160.3878, mean_mc_travel_dist: 1692.0870, mean_entropies: 2.0562, m_net_lifetime_valid: 2917.1179, took: 2943.0534s, (250.5261 / 100 batches)

2022-10-09 22:21:49,369 [INFO] 	Process 6 - batch 10199: mean_policy_losses: 39.841, mean_net_lifetime: 2776.9808, mean_mc_travel_dist: 1296.6069, mean_rewards: 201.1218, total_rewards: 1519.7031, mean_steps: 12.7000, mean_ecr: 0.0562 mean_entropies: 1.0830, took: 61.5237s
2022-10-09 22:22:01,055 [INFO] Process 3 - epoch 4: mean_policy_losses: 205.340, mean_net_lifetime: 3605.1195, mean_mc_travel_dist: 1668.7490, mean_entropies: 1.9976, m_net_lifetime_valid: 2920.5175, took: 2944.9596s, (252.4430 / 100 batches)

2022-10-09 22:22:06,691 [INFO] 	Process 5 - batch 6099: mean_policy_losses: -319.672, mean_net_lifetime: 2301.4140, mean_mc_travel_dist: 1558.9547, mean_rewards: 89.6782, total_rewards: 775.2367, mean_steps: 24.6300, mean_ecr: 0.0311 mean_entropies: 1.6256, took: 1284.7206s
2022-10-09 22:22:48,542 [INFO] 	Process 6 - batch 10299: mean_policy_losses: -61.038, mean_net_lifetime: 2372.1613, mean_mc_travel_dist: 1155.5870, mean_rewards: 192.2046, total_rewards: 1256.3630, mean_steps: 11.2000, mean_ecr: 0.0568 mean_entropies: 1.4135, took: 59.1728s
2022-10-09 22:23:00,591 [INFO] 	Process 2 - batch 6099: mean_policy_losses: -45.292, mean_net_lifetime: 2789.0486, mean_mc_travel_dist: 1589.8752, mean_rewards: 101.7752, total_rewards: 1222.6610, mean_steps: 26.4900, mean_ecr: 0.0428 mean_entropies: 1.1528, took: 1303.7879s
2022-10-09 22:23:13,552 [INFO] 	Process 1 - batch 5999: mean_policy_losses: 346.432, mean_net_lifetime: 4496.0231, mean_mc_travel_dist: 2436.1230, mean_rewards: 145.0164, total_rewards: 2093.1058, mean_steps: 30.2900, mean_ecr: 0.0398 mean_entropies: 1.8613, took: 136.8326s
2022-10-09 22:23:38,770 [INFO] 	Process 6 - batch 10399: mean_policy_losses: -171.550, mean_net_lifetime: 2133.7382, mean_mc_travel_dist: 1115.2759, mean_rewards: 190.8608, total_rewards: 1072.8267, mean_steps: 10.1000, mean_ecr: 0.0569 mean_entropies: 1.5845, took: 50.2277s
2022-10-09 22:23:56,529 [INFO] 	Process 5 - batch 6199: mean_policy_losses: -109.986, mean_net_lifetime: 2955.4116, mean_mc_travel_dist: 1839.6490, mean_rewards: 120.0208, total_rewards: 1169.3500, mean_steps: 23.3600, mean_ecr: 0.0306 mean_entropies: 2.1692, took: 109.8368s
2022-10-09 22:24:30,552 [INFO] 	Process 3 - batch 6099: mean_policy_losses: 160.925, mean_net_lifetime: 3521.9069, mean_mc_travel_dist: 1578.7823, mean_rewards: 108.9260, total_rewards: 1968.2803, mean_steps: 32.3400, mean_ecr: 0.0482 mean_entropies: 1.3821, took: 1276.0458s
2022-10-09 22:24:32,146 [INFO] 	Process 6 - batch 10499: mean_policy_losses: -92.751, mean_net_lifetime: 2233.2013, mean_mc_travel_dist: 1133.3815, mean_rewards: 189.8237, total_rewards: 1149.8076, mean_steps: 10.7000, mean_ecr: 0.0569 mean_entropies: 1.4959, took: 53.3765s
2022-10-09 22:24:59,193 [INFO] 	Process 2 - batch 6199: mean_policy_losses: -27.790, mean_net_lifetime: 2945.8811, mean_mc_travel_dist: 1610.1987, mean_rewards: 107.1730, total_rewards: 1359.1049, mean_steps: 26.6200, mean_ecr: 0.0425 mean_entropies: 1.3972, took: 118.6019s
2022-10-09 22:25:47,327 [INFO] 	Process 5 - batch 6299: mean_policy_losses: 113.269, mean_net_lifetime: 4008.2797, mean_mc_travel_dist: 2292.6979, mean_rewards: 151.4543, total_rewards: 1768.9802, mean_steps: 25.0100, mean_ecr: 0.0308 mean_entropies: 2.4102, took: 110.7988s
2022-10-09 22:26:28,572 [INFO] 	Process 3 - batch 6199: mean_policy_losses: 149.778, mean_net_lifetime: 3746.4696, mean_mc_travel_dist: 1622.0746, mean_rewards: 136.9818, total_rewards: 2149.5491, mean_steps: 26.8700, mean_ecr: 0.0479 mean_entropies: 1.7229, took: 118.0197s
2022-10-09 22:26:46,706 [INFO] 	Process 2 - batch 6299: mean_policy_losses: -84.910, mean_net_lifetime: 3360.1196, mean_mc_travel_dist: 1685.3253, mean_rewards: 131.3871, total_rewards: 1703.9271, mean_steps: 24.7000, mean_ecr: 0.0418 mean_entropies: 1.9059, took: 107.5138s
2022-10-09 22:26:55,311 [INFO] Process 7 - epoch 4: mean_policy_losses: 78.666, mean_net_lifetime: 3580.4370, mean_mc_travel_dist: 1791.1837, mean_entropies: 2.3126, m_net_lifetime_valid: 2939.6765, took: 2975.3834s, (257.1874 / 100 batches)

2022-10-09 22:27:50,604 [INFO] 	Process 5 - batch 6399: mean_policy_losses: -74.730, mean_net_lifetime: 4236.0098, mean_mc_travel_dist: 2464.6872, mean_rewards: 148.9602, total_rewards: 1828.0987, mean_steps: 27.4000, mean_ecr: 0.0313 mean_entropies: 2.4612, took: 123.2780s
2022-10-09 22:28:22,113 [INFO] 	Process 3 - batch 6299: mean_policy_losses: 150.240, mean_net_lifetime: 3898.5679, mean_mc_travel_dist: 1665.2479, mean_rewards: 153.4920, total_rewards: 2262.3886, mean_steps: 24.7700, mean_ecr: 0.0476 mean_entropies: 1.9556, took: 113.5414s
2022-10-09 22:28:38,214 [INFO] 	Process 2 - batch 6399: mean_policy_losses: 29.356, mean_net_lifetime: 3848.7636, mean_mc_travel_dist: 1859.5020, mean_rewards: 151.2958, total_rewards: 2014.4250, mean_steps: 24.5400, mean_ecr: 0.0415 mean_entropies: 2.1627, took: 111.5080s
2022-10-09 22:29:11,430 [INFO] 	Process 7 - batch 6099: mean_policy_losses: -110.335, mean_net_lifetime: 3714.4463, mean_mc_travel_dist: 1770.2180, mean_rewards: 118.7013, total_rewards: 1973.3413, mean_steps: 30.8500, mean_ecr: 0.0437 mean_entropies: 2.1212, took: 1268.1326s
2022-10-09 22:29:52,675 [INFO] 	Process 5 - batch 6499: mean_policy_losses: -121.811, mean_net_lifetime: 4138.9482, mean_mc_travel_dist: 2466.9130, mean_rewards: 145.7224, total_rewards: 1735.2964, mean_steps: 27.4000, mean_ecr: 0.0313 mean_entropies: 2.4413, took: 122.0698s
2022-10-09 22:30:13,627 [INFO] 	Process 3 - batch 6399: mean_policy_losses: 125.518, mean_net_lifetime: 3859.5453, mean_mc_travel_dist: 1682.6745, mean_rewards: 152.6921, total_rewards: 2205.7849, mean_steps: 24.6400, mean_ecr: 0.0476 mean_entropies: 2.0163, took: 111.5133s
2022-10-09 22:30:29,936 [INFO] 	Process 2 - batch 6499: mean_policy_losses: 48.235, mean_net_lifetime: 3901.5411, mean_mc_travel_dist: 1881.8883, mean_rewards: 151.8214, total_rewards: 2055.2357, mean_steps: 24.7400, mean_ecr: 0.0414 mean_entropies: 2.1799, took: 111.7214s
2022-10-09 22:31:27,860 [INFO] 	Process 7 - batch 6199: mean_policy_losses: -102.940, mean_net_lifetime: 3726.1608, mean_mc_travel_dist: 1778.4057, mean_rewards: 119.9685, total_rewards: 1982.9445, mean_steps: 30.5800, mean_ecr: 0.0437 mean_entropies: 2.1614, took: 136.4305s
2022-10-09 22:31:53,654 [INFO] 	Process 5 - batch 6599: mean_policy_losses: -17.680, mean_net_lifetime: 4518.6075, mean_mc_travel_dist: 2601.3683, mean_rewards: 157.2380, total_rewards: 1974.0877, mean_steps: 27.5800, mean_ecr: 0.0310 mean_entropies: 2.5207, took: 120.9798s
2022-10-09 22:32:02,432 [INFO] 	Process 3 - batch 6499: mean_policy_losses: 85.528, mean_net_lifetime: 3770.6672, mean_mc_travel_dist: 1636.4348, mean_rewards: 155.5975, total_rewards: 2157.8675, mean_steps: 23.5700, mean_ecr: 0.0477 mean_entropies: 1.9920, took: 108.8052s
2022-10-09 22:32:21,003 [INFO] 	Process 2 - batch 6599: mean_policy_losses: -75.736, mean_net_lifetime: 3693.3460, mean_mc_travel_dist: 1821.2398, mean_rewards: 144.9493, total_rewards: 1902.9483, mean_steps: 24.5200, mean_ecr: 0.0415 mean_entropies: 2.1407, took: 111.0670s
2022-10-09 22:32:24,481 [INFO] Process 4 - epoch 5: mean_policy_losses: -21.014, mean_net_lifetime: 2536.6437, mean_mc_travel_dist: 1230.1213, mean_entropies: 2.0562, m_net_lifetime_valid: 2837.2058, took: 2366.5388s, (211.2212 / 100 batches)

2022-10-09 22:33:36,201 [INFO] 	Process 7 - batch 6299: mean_policy_losses: 5.165, mean_net_lifetime: 3775.2417, mean_mc_travel_dist: 1813.0856, mean_rewards: 131.5361, total_rewards: 2002.6278, mean_steps: 28.3700, mean_ecr: 0.0436 mean_entropies: 2.2145, took: 128.3399s
2022-10-09 22:33:53,008 [INFO] 	Process 4 - batch 7599: mean_policy_losses: -148.278, mean_net_lifetime: 2510.9533, mean_mc_travel_dist: 1184.6292, mean_rewards: 133.1993, total_rewards: 1342.4249, mean_steps: 18.1700, mean_ecr: 0.0535 mean_entropies: 1.8661, took: 1185.2793s
2022-10-09 22:33:55,895 [INFO] 	Process 3 - batch 6599: mean_policy_losses: 241.018, mean_net_lifetime: 3877.3448, mean_mc_travel_dist: 1691.1090, mean_rewards: 157.4280, total_rewards: 2215.6426, mean_steps: 23.8600, mean_ecr: 0.0478 mean_entropies: 2.0092, took: 113.4630s
2022-10-09 22:33:57,065 [INFO] 	Process 5 - batch 6699: mean_policy_losses: 140.759, mean_net_lifetime: 4461.5918, mean_mc_travel_dist: 2544.5935, mean_rewards: 159.7475, total_rewards: 1977.4325, mean_steps: 26.8300, mean_ecr: 0.0312 mean_entropies: 2.5648, took: 123.4104s
2022-10-09 22:34:09,864 [INFO] 	Process 2 - batch 6699: mean_policy_losses: 2.645, mean_net_lifetime: 3385.6100, mean_mc_travel_dist: 1716.6525, mean_rewards: 139.5164, total_rewards: 1703.7911, mean_steps: 23.4200, mean_ecr: 0.0418 mean_entropies: 2.1329, took: 108.8605s
2022-10-09 22:35:22,524 [INFO] 	Process 4 - batch 7699: mean_policy_losses: -95.629, mean_net_lifetime: 2595.2159, mean_mc_travel_dist: 1197.7462, mean_rewards: 135.7194, total_rewards: 1411.7326, mean_steps: 18.4800, mean_ecr: 0.0535 mean_entropies: 1.9185, took: 89.5161s
2022-10-09 22:35:40,095 [INFO] 	Process 7 - batch 6399: mean_policy_losses: 77.831, mean_net_lifetime: 3698.1601, mean_mc_travel_dist: 1795.5040, mean_rewards: 134.6481, total_rewards: 1936.2002, mean_steps: 26.7900, mean_ecr: 0.0436 mean_entropies: 2.2721, took: 123.8945s
2022-10-09 22:35:51,341 [INFO] 	Process 5 - batch 6799: mean_policy_losses: -10.267, mean_net_lifetime: 4033.9470, mean_mc_travel_dist: 2395.9595, mean_rewards: 158.3455, total_rewards: 1701.7421, mean_steps: 24.2500, mean_ecr: 0.0309 mean_entropies: 2.6284, took: 114.2759s
2022-10-09 22:35:52,345 [INFO] 	Process 3 - batch 6699: mean_policy_losses: 271.484, mean_net_lifetime: 3880.5670, mean_mc_travel_dist: 1655.2692, mean_rewards: 154.6457, total_rewards: 2245.3889, mean_steps: 24.3400, mean_ecr: 0.0478 mean_entropies: 1.9954, took: 116.4506s
2022-10-09 22:36:00,766 [INFO] 	Process 2 - batch 6799: mean_policy_losses: 14.539, mean_net_lifetime: 3444.0267, mean_mc_travel_dist: 1729.0617, mean_rewards: 139.5509, total_rewards: 1743.9097, mean_steps: 23.8000, mean_ecr: 0.0416 mean_entropies: 2.1014, took: 110.9025s
2022-10-09 22:36:52,203 [INFO] 	Process 4 - batch 7799: mean_policy_losses: -129.862, mean_net_lifetime: 2641.3541, mean_mc_travel_dist: 1210.3157, mean_rewards: 137.0563, total_rewards: 1445.3185, mean_steps: 18.3900, mean_ecr: 0.0533 mean_entropies: 1.9410, took: 89.6786s
2022-10-09 22:37:42,559 [INFO] 	Process 7 - batch 6499: mean_policy_losses: 26.618, mean_net_lifetime: 3609.9593, mean_mc_travel_dist: 1757.8400, mean_rewards: 133.2358, total_rewards: 1882.7574, mean_steps: 26.5100, mean_ecr: 0.0437 mean_entropies: 2.2648, took: 122.4631s
2022-10-09 22:37:43,057 [INFO] 	Process 3 - batch 6799: mean_policy_losses: 258.815, mean_net_lifetime: 3844.6235, mean_mc_travel_dist: 1680.3843, mean_rewards: 158.0708, total_rewards: 2187.4143, mean_steps: 23.6000, mean_ecr: 0.0477 mean_entropies: 2.0212, took: 110.7115s
2022-10-09 22:37:48,611 [INFO] 	Process 5 - batch 6899: mean_policy_losses: 107.033, mean_net_lifetime: 4290.3281, mean_mc_travel_dist: 2469.1976, mean_rewards: 163.2388, total_rewards: 1881.4824, mean_steps: 25.0600, mean_ecr: 0.0309 mean_entropies: 2.6410, took: 117.2710s
2022-10-09 22:37:51,068 [INFO] 	Process 2 - batch 6899: mean_policy_losses: 12.685, mean_net_lifetime: 3443.8250, mean_mc_travel_dist: 1725.6793, mean_rewards: 140.5138, total_rewards: 1748.9323, mean_steps: 23.6100, mean_ecr: 0.0418 mean_entropies: 2.1209, took: 110.3021s
2022-10-09 22:38:18,596 [INFO] 	Process 4 - batch 7899: mean_policy_losses: -143.714, mean_net_lifetime: 2548.4671, mean_mc_travel_dist: 1190.8276, mean_rewards: 137.5836, total_rewards: 1371.2681, mean_steps: 17.6900, mean_ecr: 0.0531 mean_entropies: 1.9542, took: 86.3932s
2022-10-09 22:39:39,689 [INFO] 	Process 3 - batch 6899: mean_policy_losses: 259.376, mean_net_lifetime: 3833.1666, mean_mc_travel_dist: 1655.2846, mean_rewards: 155.4532, total_rewards: 2206.8098, mean_steps: 23.8600, mean_ecr: 0.0477 mean_entropies: 2.0063, took: 116.6326s
2022-10-09 22:39:40,615 [INFO] 	Process 5 - batch 6999: mean_policy_losses: -0.974, mean_net_lifetime: 4040.2179, mean_mc_travel_dist: 2400.3426, mean_rewards: 157.2848, total_rewards: 1715.3891, mean_steps: 24.3900, mean_ecr: 0.0306 mean_entropies: 2.6359, took: 112.0039s
2022-10-09 22:39:44,687 [INFO] 	Process 2 - batch 6999: mean_policy_losses: 20.029, mean_net_lifetime: 3483.9794, mean_mc_travel_dist: 1743.1298, mean_rewards: 137.7824, total_rewards: 1769.4281, mean_steps: 24.4200, mean_ecr: 0.0417 mean_entropies: 2.0889, took: 113.6183s
2022-10-09 22:39:45,452 [INFO] 	Process 7 - batch 6599: mean_policy_losses: 52.208, mean_net_lifetime: 3653.1458, mean_mc_travel_dist: 1776.9672, mean_rewards: 133.4849, total_rewards: 1904.6201, mean_steps: 26.5400, mean_ecr: 0.0436 mean_entropies: 2.2661, took: 122.8935s
2022-10-09 22:39:48,503 [INFO] 	Process 4 - batch 7999: mean_policy_losses: -128.430, mean_net_lifetime: 2599.8360, mean_mc_travel_dist: 1210.3016, mean_rewards: 135.3985, total_rewards: 1402.0910, mean_steps: 18.5000, mean_ecr: 0.0532 mean_entropies: 1.9756, took: 89.9071s
2022-10-09 22:41:16,985 [INFO] 	Process 4 - batch 8099: mean_policy_losses: -123.465, mean_net_lifetime: 2602.1029, mean_mc_travel_dist: 1207.3061, mean_rewards: 137.4127, total_rewards: 1407.9534, mean_steps: 18.1600, mean_ecr: 0.0535 mean_entropies: 1.9552, took: 88.4822s
2022-10-09 22:41:36,058 [INFO] 	Process 3 - batch 6999: mean_policy_losses: 247.546, mean_net_lifetime: 3790.0882, mean_mc_travel_dist: 1669.2658, mean_rewards: 155.5683, total_rewards: 2144.4671, mean_steps: 23.7300, mean_ecr: 0.0475 mean_entropies: 1.9884, took: 116.3691s
2022-10-09 22:41:36,266 [INFO] 	Process 5 - batch 7099: mean_policy_losses: 39.660, mean_net_lifetime: 4154.5026, mean_mc_travel_dist: 2424.6427, mean_rewards: 160.2834, total_rewards: 1793.0599, mean_steps: 24.5400, mean_ecr: 0.0307 mean_entropies: 2.6268, took: 115.6505s
2022-10-09 22:41:37,006 [INFO] 	Process 2 - batch 7099: mean_policy_losses: -20.565, mean_net_lifetime: 3321.6132, mean_mc_travel_dist: 1667.9541, mean_rewards: 133.6426, total_rewards: 1678.6044, mean_steps: 24.0000, mean_ecr: 0.0419 mean_entropies: 2.0655, took: 112.3185s
2022-10-09 22:41:49,689 [INFO] 	Process 7 - batch 6699: mean_policy_losses: 60.076, mean_net_lifetime: 3678.1426, mean_mc_travel_dist: 1797.5797, mean_rewards: 133.2621, total_rewards: 1909.5257, mean_steps: 26.9600, mean_ecr: 0.0435 mean_entropies: 2.2749, took: 124.2360s
2022-10-09 22:42:44,121 [INFO] 	Process 4 - batch 8199: mean_policy_losses: -131.861, mean_net_lifetime: 2537.5383, mean_mc_travel_dist: 1181.6581, mean_rewards: 136.2388, total_rewards: 1367.9224, mean_steps: 17.9800, mean_ecr: 0.0535 mean_entropies: 1.9613, took: 87.1360s
2022-10-09 22:42:44,295 [INFO] Process 1 - epoch 4: mean_policy_losses: 279.236, mean_net_lifetime: 4547.3617, mean_mc_travel_dist: 2374.7567, mean_entropies: 2.2330, m_net_lifetime_valid: 2917.0564, took: 3228.2190s, (272.1107 / 100 batches)

2022-10-09 22:43:30,302 [INFO] 	Process 2 - batch 7199: mean_policy_losses: -27.237, mean_net_lifetime: 3373.4208, mean_mc_travel_dist: 1696.7118, mean_rewards: 136.1615, total_rewards: 1708.6736, mean_steps: 23.9100, mean_ecr: 0.0418 mean_entropies: 2.0923, took: 113.2969s
2022-10-09 22:43:31,046 [INFO] 	Process 3 - batch 7099: mean_policy_losses: 222.466, mean_net_lifetime: 3795.3275, mean_mc_travel_dist: 1661.1274, mean_rewards: 155.2100, total_rewards: 2154.6018, mean_steps: 23.6400, mean_ecr: 0.0478 mean_entropies: 2.0025, took: 114.9875s
2022-10-09 22:43:35,097 [INFO] 	Process 5 - batch 7199: mean_policy_losses: 50.116, mean_net_lifetime: 4237.7216, mean_mc_travel_dist: 2453.7106, mean_rewards: 159.9931, total_rewards: 1849.4774, mean_steps: 25.0000, mean_ecr: 0.0307 mean_entropies: 2.6317, took: 118.8305s
2022-10-09 22:43:58,522 [INFO] 	Process 7 - batch 6799: mean_policy_losses: 29.366, mean_net_lifetime: 3704.2836, mean_mc_travel_dist: 1798.0739, mean_rewards: 133.5034, total_rewards: 1939.8215, mean_steps: 27.2300, mean_ecr: 0.0435 mean_entropies: 2.2770, took: 128.8343s
2022-10-09 22:43:59,889 [INFO] Process 6 - epoch 7: mean_policy_losses: -323.464, mean_net_lifetime: 1774.5035, mean_mc_travel_dist: 1023.5863, mean_entropies: 1.8995, m_net_lifetime_valid: 2937.9751, took: 1970.0132s, (157.3289 / 100 batches)

2022-10-09 22:44:12,384 [INFO] 	Process 4 - batch 8299: mean_policy_losses: -172.136, mean_net_lifetime: 2526.3547, mean_mc_travel_dist: 1177.8481, mean_rewards: 139.4712, total_rewards: 1362.3270, mean_steps: 17.3700, mean_ecr: 0.0533 mean_entropies: 1.9865, took: 88.2623s
2022-10-09 22:44:43,314 [INFO] 	Process 6 - batch 10599: mean_policy_losses: -663.882, mean_net_lifetime: 1469.5087, mean_mc_travel_dist: 936.7432, mean_rewards: 171.0609, total_rewards: 592.0179, mean_steps: 7.6100, mean_ecr: 0.0564 mean_entropies: 2.1084, took: 1211.1672s
2022-10-09 22:45:28,025 [INFO] 	Process 3 - batch 7199: mean_policy_losses: 322.538, mean_net_lifetime: 3742.4140, mean_mc_travel_dist: 1656.6192, mean_rewards: 156.1732, total_rewards: 2114.1510, mean_steps: 23.1800, mean_ecr: 0.0479 mean_entropies: 1.9578, took: 116.9780s
2022-10-09 22:45:28,362 [INFO] 	Process 6 - batch 10699: mean_policy_losses: -710.110, mean_net_lifetime: 1507.1611, mean_mc_travel_dist: 953.5472, mean_rewards: 170.4452, total_rewards: 619.9710, mean_steps: 7.8200, mean_ecr: 0.0565 mean_entropies: 2.0900, took: 45.0487s
2022-10-09 22:45:29,649 [INFO] 	Process 2 - batch 7299: mean_policy_losses: 39.255, mean_net_lifetime: 3261.6114, mean_mc_travel_dist: 1656.6085, mean_rewards: 130.9689, total_rewards: 1629.8806, mean_steps: 24.0200, mean_ecr: 0.0419 mean_entropies: 2.0240, took: 119.3468s
2022-10-09 22:45:32,962 [INFO] 	Process 1 - batch 6099: mean_policy_losses: 240.998, mean_net_lifetime: 4592.6209, mean_mc_travel_dist: 2327.9678, mean_rewards: 127.5345, total_rewards: 2289.8239, mean_steps: 35.3000, mean_ecr: 0.0398 mean_entropies: 2.0795, took: 1339.4103s
2022-10-09 22:45:41,911 [INFO] 	Process 5 - batch 7299: mean_policy_losses: 178.063, mean_net_lifetime: 4190.0067, mean_mc_travel_dist: 2399.1150, mean_rewards: 155.3025, total_rewards: 1846.0775, mean_steps: 25.5500, mean_ecr: 0.0307 mean_entropies: 2.5938, took: 126.8136s
2022-10-09 22:45:44,558 [INFO] 	Process 4 - batch 8399: mean_policy_losses: 47.249, mean_net_lifetime: 2570.2038, mean_mc_travel_dist: 1191.6008, mean_rewards: 139.9827, total_rewards: 1387.0901, mean_steps: 17.5900, mean_ecr: 0.0534 mean_entropies: 1.9822, took: 92.1746s
2022-10-09 22:46:05,886 [INFO] 	Process 7 - batch 6899: mean_policy_losses: 211.612, mean_net_lifetime: 3666.3490, mean_mc_travel_dist: 1796.3029, mean_rewards: 138.9470, total_rewards: 1913.1514, mean_steps: 25.8200, mean_ecr: 0.0435 mean_entropies: 2.2859, took: 127.3640s
2022-10-09 22:46:16,404 [INFO] 	Process 6 - batch 10799: mean_policy_losses: -512.856, mean_net_lifetime: 1766.9705, mean_mc_travel_dist: 1007.2903, mean_rewards: 180.6813, total_rewards: 808.0519, mean_steps: 8.6000, mean_ecr: 0.0567 mean_entropies: 2.0448, took: 48.0415s
2022-10-09 22:47:03,604 [INFO] 	Process 6 - batch 10899: mean_policy_losses: -613.999, mean_net_lifetime: 1682.6316, mean_mc_travel_dist: 987.3154, mean_rewards: 177.6845, total_rewards: 755.1555, mean_steps: 8.2700, mean_ecr: 0.0570 mean_entropies: 2.0185, took: 47.2001s
2022-10-09 22:47:18,841 [INFO] 	Process 4 - batch 8499: mean_policy_losses: -25.443, mean_net_lifetime: 2546.2781, mean_mc_travel_dist: 1195.0790, mean_rewards: 135.5759, total_rewards: 1362.1866, mean_steps: 18.1300, mean_ecr: 0.0534 mean_entropies: 1.9593, took: 94.2823s
2022-10-09 22:47:32,585 [INFO] 	Process 2 - batch 7399: mean_policy_losses: 15.687, mean_net_lifetime: 3162.8590, mean_mc_travel_dist: 1627.2450, mean_rewards: 123.3986, total_rewards: 1564.8370, mean_steps: 24.8000, mean_ecr: 0.0420 mean_entropies: 1.8414, took: 122.9364s
2022-10-09 22:47:33,388 [INFO] 	Process 3 - batch 7299: mean_policy_losses: 248.632, mean_net_lifetime: 3630.0918, mean_mc_travel_dist: 1611.0183, mean_rewards: 142.8998, total_rewards: 2042.4475, mean_steps: 24.6800, mean_ecr: 0.0480 mean_entropies: 1.8046, took: 125.3638s
2022-10-09 22:47:43,458 [INFO] 	Process 5 - batch 7399: mean_policy_losses: 99.877, mean_net_lifetime: 3946.7547, mean_mc_travel_dist: 2286.2152, mean_rewards: 150.5826, total_rewards: 1703.9114, mean_steps: 24.7200, mean_ecr: 0.0306 mean_entropies: 2.4979, took: 121.5477s
2022-10-09 22:47:52,584 [INFO] 	Process 6 - batch 10999: mean_policy_losses: -519.581, mean_net_lifetime: 1799.4205, mean_mc_travel_dist: 1018.6143, mean_rewards: 184.2078, total_rewards: 836.1175, mean_steps: 8.6100, mean_ecr: 0.0567 mean_entropies: 1.9662, took: 48.9802s
2022-10-09 22:48:08,369 [INFO] 	Process 7 - batch 6999: mean_policy_losses: 186.802, mean_net_lifetime: 3605.9117, mean_mc_travel_dist: 1794.9628, mean_rewards: 143.3891, total_rewards: 1862.6747, mean_steps: 24.3800, mean_ecr: 0.0436 mean_entropies: 2.3067, took: 122.4831s
2022-10-09 22:48:22,032 [INFO] 	Process 1 - batch 6199: mean_policy_losses: 279.711, mean_net_lifetime: 4532.0849, mean_mc_travel_dist: 2309.7486, mean_rewards: 130.4156, total_rewards: 2254.4011, mean_steps: 34.1800, mean_ecr: 0.0399 mean_entropies: 2.0520, took: 169.0700s
2022-10-09 22:48:39,908 [INFO] 	Process 6 - batch 11099: mean_policy_losses: -596.697, mean_net_lifetime: 1634.3705, mean_mc_travel_dist: 970.2005, mean_rewards: 179.5691, total_rewards: 717.7793, mean_steps: 8.0400, mean_ecr: 0.0567 mean_entropies: 1.9378, took: 47.3237s
2022-10-09 22:48:57,418 [INFO] 	Process 4 - batch 8599: mean_policy_losses: 8.879, mean_net_lifetime: 2620.2192, mean_mc_travel_dist: 1193.9294, mean_rewards: 131.7024, total_rewards: 1436.0439, mean_steps: 19.0800, mean_ecr: 0.0531 mean_entropies: 1.8921, took: 98.5776s
2022-10-09 22:49:30,476 [INFO] 	Process 6 - batch 11199: mean_policy_losses: -435.205, mean_net_lifetime: 1734.6941, mean_mc_travel_dist: 993.4388, mean_rewards: 177.6686, total_rewards: 785.7859, mean_steps: 8.7000, mean_ecr: 0.0568 mean_entropies: 1.8538, took: 50.5682s
2022-10-09 22:49:38,143 [INFO] 	Process 2 - batch 7499: mean_policy_losses: 25.899, mean_net_lifetime: 3151.9606, mean_mc_travel_dist: 1627.1141, mean_rewards: 121.1127, total_rewards: 1555.0465, mean_steps: 25.2200, mean_ecr: 0.0421 mean_entropies: 1.7501, took: 125.5577s
2022-10-09 22:49:44,337 [INFO] 	Process 3 - batch 7399: mean_policy_losses: 245.594, mean_net_lifetime: 3623.3156, mean_mc_travel_dist: 1588.4073, mean_rewards: 136.4851, total_rewards: 2050.8561, mean_steps: 25.9300, mean_ecr: 0.0481 mean_entropies: 1.7135, took: 130.9485s
2022-10-09 22:49:50,522 [INFO] 	Process 5 - batch 7499: mean_policy_losses: 224.937, mean_net_lifetime: 4245.3744, mean_mc_travel_dist: 2396.4874, mean_rewards: 155.0985, total_rewards: 1896.6278, mean_steps: 25.9300, mean_ecr: 0.0303 mean_entropies: 2.4651, took: 127.0642s
2022-10-09 22:50:17,377 [INFO] 	Process 6 - batch 11299: mean_policy_losses: -433.975, mean_net_lifetime: 1795.8559, mean_mc_travel_dist: 1018.3272, mean_rewards: 183.1138, total_rewards: 844.4965, mean_steps: 8.6900, mean_ecr: 0.0569 mean_entropies: 1.8331, took: 46.9005s
2022-10-09 22:50:20,169 [INFO] 	Process 7 - batch 7099: mean_policy_losses: 184.207, mean_net_lifetime: 3638.1728, mean_mc_travel_dist: 1787.5145, mean_rewards: 130.9122, total_rewards: 1891.6518, mean_steps: 27.1600, mean_ecr: 0.0436 mean_entropies: 2.2123, took: 131.7986s
2022-10-09 22:50:32,035 [INFO] 	Process 4 - batch 8699: mean_policy_losses: -9.241, mean_net_lifetime: 2531.1103, mean_mc_travel_dist: 1183.1330, mean_rewards: 127.9554, total_rewards: 1365.3108, mean_steps: 19.0300, mean_ecr: 0.0533 mean_entropies: 1.8551, took: 94.6172s
2022-10-09 22:51:03,239 [INFO] 	Process 6 - batch 11399: mean_policy_losses: -485.926, mean_net_lifetime: 1803.6612, mean_mc_travel_dist: 1020.8191, mean_rewards: 183.1479, total_rewards: 841.2928, mean_steps: 8.6800, mean_ecr: 0.0569 mean_entropies: 1.8017, took: 45.8626s
2022-10-09 22:51:06,789 [INFO] 	Process 1 - batch 6299: mean_policy_losses: 286.311, mean_net_lifetime: 4555.9112, mean_mc_travel_dist: 2351.4661, mean_rewards: 130.5688, total_rewards: 2229.5756, mean_steps: 34.3900, mean_ecr: 0.0398 mean_entropies: 1.9891, took: 164.7571s
2022-10-09 22:51:48,577 [INFO] 	Process 3 - batch 7499: mean_policy_losses: 180.430, mean_net_lifetime: 3574.4966, mean_mc_travel_dist: 1599.1909, mean_rewards: 131.5055, total_rewards: 1995.1608, mean_steps: 26.4700, mean_ecr: 0.0481 mean_entropies: 1.6172, took: 124.2408s
2022-10-09 22:51:49,435 [INFO] 	Process 6 - batch 11499: mean_policy_losses: -523.884, mean_net_lifetime: 1798.4914, mean_mc_travel_dist: 1011.6169, mean_rewards: 180.9291, total_rewards: 848.6834, mean_steps: 8.7300, mean_ecr: 0.0570 mean_entropies: 1.7775, took: 46.1955s
2022-10-09 22:52:00,592 [INFO] 	Process 4 - batch 8799: mean_policy_losses: -19.375, mean_net_lifetime: 2625.7871, mean_mc_travel_dist: 1198.3409, mean_rewards: 138.4049, total_rewards: 1438.5458, mean_steps: 18.2600, mean_ecr: 0.0532 mean_entropies: 1.9165, took: 88.5560s
2022-10-09 22:52:23,087 [INFO] 	Process 7 - batch 7199: mean_policy_losses: 224.264, mean_net_lifetime: 3906.0264, mean_mc_travel_dist: 1871.1756, mean_rewards: 142.1431, total_rewards: 2068.7051, mean_steps: 26.9300, mean_ecr: 0.0433 mean_entropies: 2.2635, took: 122.9190s
2022-10-09 22:52:39,270 [INFO] 	Process 6 - batch 11599: mean_policy_losses: -364.154, mean_net_lifetime: 1962.0087, mean_mc_travel_dist: 1051.9336, mean_rewards: 184.4047, total_rewards: 966.9160, mean_steps: 9.4800, mean_ecr: 0.0571 mean_entropies: 1.7545, took: 49.8354s
2022-10-09 22:53:25,980 [INFO] 	Process 1 - batch 6399: mean_policy_losses: 302.707, mean_net_lifetime: 4512.2699, mean_mc_travel_dist: 2363.2413, mean_rewards: 141.2250, total_rewards: 2184.8211, mean_steps: 31.2500, mean_ecr: 0.0398 mean_entropies: 2.0597, took: 139.1895s
2022-10-09 22:53:27,974 [INFO] 	Process 4 - batch 8899: mean_policy_losses: 44.902, mean_net_lifetime: 2673.9273, mean_mc_travel_dist: 1212.5121, mean_rewards: 136.2586, total_rewards: 1476.1081, mean_steps: 18.7900, mean_ecr: 0.0530 mean_entropies: 1.9000, took: 87.3826s
2022-10-09 22:53:28,536 [INFO] 	Process 6 - batch 11699: mean_policy_losses: -318.795, mean_net_lifetime: 1907.1387, mean_mc_travel_dist: 1047.6888, mean_rewards: 180.3982, total_rewards: 924.1401, mean_steps: 9.3900, mean_ecr: 0.0568 mean_entropies: 1.7290, took: 49.2659s
2022-10-09 22:54:17,120 [INFO] 	Process 6 - batch 11799: mean_policy_losses: -428.478, mean_net_lifetime: 1932.8054, mean_mc_travel_dist: 1046.7774, mean_rewards: 179.0926, total_rewards: 941.2459, mean_steps: 9.5300, mean_ecr: 0.0572 mean_entropies: 1.6771, took: 48.5845s
2022-10-09 22:54:23,695 [INFO] 	Process 7 - batch 7299: mean_policy_losses: 276.889, mean_net_lifetime: 3944.8542, mean_mc_travel_dist: 1908.5760, mean_rewards: 142.5181, total_rewards: 2066.6301, mean_steps: 27.1200, mean_ecr: 0.0432 mean_entropies: 2.2553, took: 120.6090s
2022-10-09 22:54:57,055 [INFO] 	Process 4 - batch 8999: mean_policy_losses: -39.125, mean_net_lifetime: 2575.3174, mean_mc_travel_dist: 1175.1426, mean_rewards: 129.9012, total_rewards: 1411.0331, mean_steps: 19.0600, mean_ecr: 0.0534 mean_entropies: 1.8592, took: 89.0814s
2022-10-09 22:55:06,549 [INFO] 	Process 6 - batch 11899: mean_policy_losses: -243.064, mean_net_lifetime: 2099.2607, mean_mc_travel_dist: 1092.1131, mean_rewards: 192.8347, total_rewards: 1059.7718, mean_steps: 9.7200, mean_ecr: 0.0568 mean_entropies: 1.6194, took: 49.4282s
2022-10-09 22:55:42,555 [INFO] 	Process 1 - batch 6499: mean_policy_losses: 279.836, mean_net_lifetime: 4498.0964, mean_mc_travel_dist: 2365.0034, mean_rewards: 145.8426, total_rewards: 2166.2986, mean_steps: 30.0700, mean_ecr: 0.0400 mean_entropies: 2.0250, took: 136.5756s
2022-10-09 22:55:57,692 [INFO] 	Process 6 - batch 11999: mean_policy_losses: -335.351, mean_net_lifetime: 2194.3195, mean_mc_travel_dist: 1132.6085, mean_rewards: 186.4689, total_rewards: 1122.0275, mean_steps: 10.5200, mean_ecr: 0.0570 mean_entropies: 1.5156, took: 51.1424s
2022-10-09 22:56:31,514 [INFO] 	Process 7 - batch 7399: mean_policy_losses: 107.012, mean_net_lifetime: 3973.6276, mean_mc_travel_dist: 1906.5797, mean_rewards: 128.7802, total_rewards: 2103.2568, mean_steps: 30.0200, mean_ecr: 0.0433 mean_entropies: 2.1573, took: 127.8185s
2022-10-09 22:57:44,107 [INFO] 	Process 1 - batch 6599: mean_policy_losses: 75.979, mean_net_lifetime: 4508.4442, mean_mc_travel_dist: 2419.2527, mean_rewards: 151.3744, total_rewards: 2123.9122, mean_steps: 29.0600, mean_ecr: 0.0399 mean_entropies: 2.0323, took: 121.5516s
2022-10-09 22:58:20,302 [INFO] 	Process 7 - batch 7499: mean_policy_losses: -115.780, mean_net_lifetime: 3807.7366, mean_mc_travel_dist: 1871.6180, mean_rewards: 141.4379, total_rewards: 1976.2248, mean_steps: 26.2600, mean_ecr: 0.0433 mean_entropies: 2.2645, took: 108.7874s
2022-10-09 22:59:37,752 [INFO] 	Process 1 - batch 6699: mean_policy_losses: 2.167, mean_net_lifetime: 4512.6937, mean_mc_travel_dist: 2408.8768, mean_rewards: 154.6489, total_rewards: 2138.9340, mean_steps: 28.4100, mean_ecr: 0.0398 mean_entropies: 2.0956, took: 113.6461s
2022-10-09 23:01:31,895 [INFO] 	Process 1 - batch 6799: mean_policy_losses: 30.909, mean_net_lifetime: 4555.7693, mean_mc_travel_dist: 2396.5628, mean_rewards: 154.3181, total_rewards: 2187.3943, mean_steps: 28.7900, mean_ecr: 0.0400 mean_entropies: 2.1225, took: 114.1429s
2022-10-09 23:03:25,829 [INFO] 	Process 1 - batch 6899: mean_policy_losses: 35.119, mean_net_lifetime: 4613.5923, mean_mc_travel_dist: 2381.4377, mean_rewards: 156.6420, total_rewards: 2260.5619, mean_steps: 28.5900, mean_ecr: 0.0399 mean_entropies: 2.1700, took: 113.9340s
2022-10-09 23:05:20,982 [INFO] 	Process 1 - batch 6999: mean_policy_losses: 35.838, mean_net_lifetime: 4612.6255, mean_mc_travel_dist: 2400.3171, mean_rewards: 153.7369, total_rewards: 2247.1975, mean_steps: 29.2500, mean_ecr: 0.0399 mean_entropies: 2.1945, took: 115.1524s
2022-10-09 23:07:14,034 [INFO] 	Process 1 - batch 7099: mean_policy_losses: 40.278, mean_net_lifetime: 4667.2018, mean_mc_travel_dist: 2408.0000, mean_rewards: 159.9089, total_rewards: 2284.6761, mean_steps: 28.3400, mean_ecr: 0.0399 mean_entropies: 2.2364, took: 113.0520s
2022-10-09 23:08:10,167 [INFO] Process 5 - epoch 5: mean_policy_losses: -7.542, mean_net_lifetime: 3816.1287, mean_mc_travel_dist: 2280.3244, mean_entropies: 2.5516, m_net_lifetime_valid: 2981.5402, took: 2874.2156s, (239.4171 / 100 batches)

2022-10-09 23:08:48,718 [INFO] Process 2 - epoch 5: mean_policy_losses: -24.632, mean_net_lifetime: 3202.5450, mean_mc_travel_dist: 1695.5121, mean_entropies: 2.0338, m_net_lifetime_valid: 2960.0749, took: 2868.2876s, (239.2557 / 100 batches)

2022-10-09 23:09:10,352 [INFO] 	Process 1 - batch 7199: mean_policy_losses: 179.139, mean_net_lifetime: 4726.4232, mean_mc_travel_dist: 2401.4140, mean_rewards: 155.8890, total_rewards: 2357.4869, mean_steps: 29.4500, mean_ecr: 0.0399 mean_entropies: 2.2382, took: 116.3186s
2022-10-09 23:09:43,906 [INFO] 	Process 5 - batch 7599: mean_policy_losses: -206.654, mean_net_lifetime: 3099.8036, mean_mc_travel_dist: 1888.8770, mean_rewards: 137.2481, total_rewards: 1264.0572, mean_steps: 21.2000, mean_ecr: 0.0310 mean_entropies: 2.3349, took: 1193.3831s
2022-10-09 23:09:51,729 [INFO] Process 3 - epoch 5: mean_policy_losses: 206.537, mean_net_lifetime: 3635.9435, mean_mc_travel_dist: 1663.7044, mean_entropies: 1.9739, m_net_lifetime_valid: 2926.1021, took: 2870.6729s, (240.9617 / 100 batches)

2022-10-09 23:10:43,430 [INFO] 	Process 2 - batch 7599: mean_policy_losses: -52.549, mean_net_lifetime: 3162.2293, mean_mc_travel_dist: 1625.2043, mean_rewards: 117.6843, total_rewards: 1556.3788, mean_steps: 26.1200, mean_ecr: 0.0420 mean_entropies: 1.7286, took: 1265.2870s
2022-10-09 23:11:33,714 [INFO] 	Process 5 - batch 7699: mean_policy_losses: -70.591, mean_net_lifetime: 3997.1540, mean_mc_travel_dist: 2314.0915, mean_rewards: 160.2110, total_rewards: 1743.7192, mean_steps: 23.5200, mean_ecr: 0.0311 mean_entropies: 2.5322, took: 109.8085s
2022-10-09 23:11:42,912 [INFO] 	Process 1 - batch 7299: mean_policy_losses: 191.142, mean_net_lifetime: 4591.0437, mean_mc_travel_dist: 2308.2194, mean_rewards: 131.0026, total_rewards: 2303.0166, mean_steps: 34.5200, mean_ecr: 0.0399 mean_entropies: 2.0237, took: 152.5605s
2022-10-09 23:11:46,513 [INFO] 	Process 3 - batch 7599: mean_policy_losses: 103.070, mean_net_lifetime: 3718.7197, mean_mc_travel_dist: 1629.8422, mean_rewards: 143.8738, total_rewards: 2111.2910, mean_steps: 25.2400, mean_ecr: 0.0478 mean_entropies: 1.7993, took: 1197.9363s
2022-10-09 23:12:13,854 [INFO] Process 4 - epoch 6: mean_policy_losses: -29.350, mean_net_lifetime: 2543.9216, mean_mc_travel_dist: 1224.1052, mean_entropies: 2.0349, m_net_lifetime_valid: 2872.7490, took: 2389.3719s, (203.3202 / 100 batches)

2022-10-09 23:12:35,617 [INFO] 	Process 2 - batch 7699: mean_policy_losses: -99.451, mean_net_lifetime: 3484.9828, mean_mc_travel_dist: 1740.1777, mean_rewards: 135.1992, total_rewards: 1776.1156, mean_steps: 24.8300, mean_ecr: 0.0417 mean_entropies: 1.9997, took: 112.1872s
2022-10-09 23:12:35,773 [INFO] Process 6 - epoch 8: mean_policy_losses: -342.914, mean_net_lifetime: 1778.4264, mean_mc_travel_dist: 1023.0466, mean_entropies: 1.8931, m_net_lifetime_valid: 2942.4352, took: 1715.8825s, (153.4083 / 100 batches)

2022-10-09 23:13:24,533 [INFO] 	Process 6 - batch 12099: mean_policy_losses: -482.757, mean_net_lifetime: 1638.8364, mean_mc_travel_dist: 957.8847, mean_rewards: 167.7995, total_rewards: 722.6499, mean_steps: 8.7300, mean_ecr: 0.0563 mean_entropies: 1.9265, took: 1046.8417s
2022-10-09 23:13:32,589 [INFO] 	Process 5 - batch 7799: mean_policy_losses: 119.487, mean_net_lifetime: 4294.3295, mean_mc_travel_dist: 2468.2071, mean_rewards: 160.7162, total_rewards: 1882.2874, mean_steps: 25.4600, mean_ecr: 0.0311 mean_entropies: 2.5547, took: 118.8751s
2022-10-09 23:13:45,763 [INFO] 	Process 4 - batch 9099: mean_policy_losses: -23.573, mean_net_lifetime: 2576.0167, mean_mc_travel_dist: 1199.9197, mean_rewards: 134.6802, total_rewards: 1386.6899, mean_steps: 18.4100, mean_ecr: 0.0532 mean_entropies: 1.8945, took: 1128.7080s
2022-10-09 23:13:49,709 [INFO] 	Process 3 - batch 7699: mean_policy_losses: 273.844, mean_net_lifetime: 3807.8012, mean_mc_travel_dist: 1636.9695, mean_rewards: 145.7245, total_rewards: 2197.5259, mean_steps: 25.4500, mean_ecr: 0.0478 mean_entropies: 1.8797, took: 123.1961s
2022-10-09 23:14:11,967 [INFO] 	Process 6 - batch 12199: mean_policy_losses: -490.734, mean_net_lifetime: 1600.7693, mean_mc_travel_dist: 961.4874, mean_rewards: 173.9542, total_rewards: 686.3354, mean_steps: 8.1700, mean_ecr: 0.0566 mean_entropies: 1.9567, took: 47.4342s
2022-10-09 23:14:35,679 [INFO] 	Process 2 - batch 7799: mean_policy_losses: 188.612, mean_net_lifetime: 3496.9083, mean_mc_travel_dist: 1726.8255, mean_rewards: 134.4791, total_rewards: 1800.3675, mean_steps: 25.0600, mean_ecr: 0.0416 mean_entropies: 1.9691, took: 120.0615s
2022-10-09 23:14:35,814 [INFO] 	Process 1 - batch 7399: mean_policy_losses: 249.781, mean_net_lifetime: 4667.5023, mean_mc_travel_dist: 2336.1946, mean_rewards: 124.6394, total_rewards: 2357.5061, mean_steps: 36.7400, mean_ecr: 0.0398 mean_entropies: 1.9836, took: 172.9019s
2022-10-09 23:15:00,154 [INFO] 	Process 6 - batch 12299: mean_policy_losses: -569.613, mean_net_lifetime: 1626.6062, mean_mc_travel_dist: 967.5504, mean_rewards: 174.6303, total_rewards: 707.1689, mean_steps: 8.2800, mean_ecr: 0.0566 mean_entropies: 1.9673, took: 48.1866s
2022-10-09 23:15:14,773 [INFO] 	Process 4 - batch 9199: mean_policy_losses: 11.917, mean_net_lifetime: 2562.1555, mean_mc_travel_dist: 1197.3149, mean_rewards: 137.7872, total_rewards: 1377.0961, mean_steps: 17.7600, mean_ecr: 0.0531 mean_entropies: 1.9397, took: 89.0097s
2022-10-09 23:15:30,898 [INFO] 	Process 5 - batch 7899: mean_policy_losses: 197.048, mean_net_lifetime: 4002.4949, mean_mc_travel_dist: 2286.1436, mean_rewards: 156.7000, total_rewards: 1775.8536, mean_steps: 24.0900, mean_ecr: 0.0309 mean_entropies: 2.5435, took: 118.3091s
2022-10-09 23:15:48,372 [INFO] 	Process 6 - batch 12399: mean_policy_losses: -553.208, mean_net_lifetime: 1679.1425, mean_mc_travel_dist: 987.4381, mean_rewards: 180.2142, total_rewards: 746.4261, mean_steps: 8.2900, mean_ecr: 0.0568 mean_entropies: 1.9345, took: 48.2184s
2022-10-09 23:15:54,409 [INFO] 	Process 3 - batch 7799: mean_policy_losses: 290.582, mean_net_lifetime: 3665.9013, mean_mc_travel_dist: 1615.0168, mean_rewards: 141.1969, total_rewards: 2077.5863, mean_steps: 25.1400, mean_ecr: 0.0481 mean_entropies: 1.7943, took: 124.6971s
2022-10-09 23:16:37,109 [INFO] 	Process 6 - batch 12499: mean_policy_losses: -465.801, mean_net_lifetime: 1760.7454, mean_mc_travel_dist: 1010.8913, mean_rewards: 180.3140, total_rewards: 796.4475, mean_steps: 8.6400, mean_ecr: 0.0568 mean_entropies: 1.9022, took: 48.7373s
2022-10-09 23:16:37,354 [INFO] 	Process 2 - batch 7899: mean_policy_losses: 73.403, mean_net_lifetime: 3269.5255, mean_mc_travel_dist: 1662.3124, mean_rewards: 123.5113, total_rewards: 1638.6020, mean_steps: 25.5700, mean_ecr: 0.0418 mean_entropies: 1.8355, took: 121.6755s
2022-10-09 23:16:44,832 [INFO] 	Process 4 - batch 9299: mean_policy_losses: 47.499, mean_net_lifetime: 2630.5742, mean_mc_travel_dist: 1206.2883, mean_rewards: 140.4502, total_rewards: 1432.8765, mean_steps: 17.8800, mean_ecr: 0.0532 mean_entropies: 1.9434, took: 90.0579s
2022-10-09 23:17:06,173 [INFO] Process 7 - epoch 5: mean_policy_losses: 77.773, mean_net_lifetime: 3612.3792, mean_mc_travel_dist: 1795.9390, mean_entropies: 2.2980, m_net_lifetime_valid: 2953.8117, took: 3010.8603s, (246.1242 / 100 batches)

2022-10-09 23:17:22,197 [INFO] 	Process 1 - batch 7499: mean_policy_losses: 333.690, mean_net_lifetime: 4619.9978, mean_mc_travel_dist: 2360.7232, mean_rewards: 132.3775, total_rewards: 2290.5826, mean_steps: 34.2700, mean_ecr: 0.0398 mean_entropies: 2.0487, took: 166.3827s
2022-10-09 23:17:27,422 [INFO] 	Process 5 - batch 7999: mean_policy_losses: 54.920, mean_net_lifetime: 3675.6027, mean_mc_travel_dist: 2149.6468, mean_rewards: 149.7454, total_rewards: 1584.3696, mean_steps: 23.0600, mean_ecr: 0.0306 mean_entropies: 2.4918, took: 116.5213s
2022-10-09 23:17:28,710 [INFO] 	Process 6 - batch 12599: mean_policy_losses: -381.918, mean_net_lifetime: 1839.3033, mean_mc_travel_dist: 1020.1792, mean_rewards: 178.3075, total_rewards: 869.3877, mean_steps: 9.2300, mean_ecr: 0.0569 mean_entropies: 1.8600, took: 51.6000s
2022-10-09 23:18:04,845 [INFO] 	Process 3 - batch 7899: mean_policy_losses: 266.010, mean_net_lifetime: 3666.7810, mean_mc_travel_dist: 1591.5705, mean_rewards: 135.2161, total_rewards: 2093.9643, mean_steps: 26.5100, mean_ecr: 0.0480 mean_entropies: 1.7208, took: 130.4390s
2022-10-09 23:18:17,649 [INFO] 	Process 4 - batch 9399: mean_policy_losses: 19.191, mean_net_lifetime: 2613.8098, mean_mc_travel_dist: 1189.8537, mean_rewards: 136.2399, total_rewards: 1436.5964, mean_steps: 18.4000, mean_ecr: 0.0531 mean_entropies: 1.9032, took: 92.8186s
2022-10-09 23:18:18,607 [INFO] 	Process 6 - batch 12699: mean_policy_losses: -499.377, mean_net_lifetime: 1744.6860, mean_mc_travel_dist: 1007.3971, mean_rewards: 175.2241, total_rewards: 798.1406, mean_steps: 8.8900, mean_ecr: 0.0567 mean_entropies: 1.8225, took: 49.8979s
2022-10-09 23:18:37,393 [INFO] 	Process 2 - batch 7999: mean_policy_losses: 56.064, mean_net_lifetime: 3207.9631, mean_mc_travel_dist: 1623.4355, mean_rewards: 124.5811, total_rewards: 1609.0442, mean_steps: 24.9200, mean_ecr: 0.0420 mean_entropies: 1.7716, took: 120.0387s
2022-10-09 23:19:04,474 [INFO] 	Process 7 - batch 7599: mean_policy_losses: 191.895, mean_net_lifetime: 3690.9493, mean_mc_travel_dist: 1846.1174, mean_rewards: 145.1579, total_rewards: 1894.5612, mean_steps: 24.6100, mean_ecr: 0.0432 mean_entropies: 2.2944, took: 1244.1731s
2022-10-09 23:19:07,419 [INFO] 	Process 6 - batch 12799: mean_policy_losses: -434.060, mean_net_lifetime: 1829.8229, mean_mc_travel_dist: 1011.8326, mean_rewards: 182.4169, total_rewards: 874.9459, mean_steps: 8.8400, mean_ecr: 0.0568 mean_entropies: 1.8381, took: 48.8119s
2022-10-09 23:19:26,277 [INFO] 	Process 5 - batch 8099: mean_policy_losses: 169.525, mean_net_lifetime: 3947.7882, mean_mc_travel_dist: 2242.1085, mean_rewards: 154.9842, total_rewards: 1751.8047, mean_steps: 24.1400, mean_ecr: 0.0309 mean_entropies: 2.4708, took: 118.8578s
2022-10-09 23:19:50,867 [INFO] 	Process 4 - batch 9499: mean_policy_losses: 43.189, mean_net_lifetime: 2650.8973, mean_mc_travel_dist: 1200.4285, mean_rewards: 136.5560, total_rewards: 1463.0623, mean_steps: 18.5800, mean_ecr: 0.0532 mean_entropies: 1.8971, took: 93.2161s
2022-10-09 23:19:59,306 [INFO] 	Process 6 - batch 12899: mean_policy_losses: -393.303, mean_net_lifetime: 1832.8279, mean_mc_travel_dist: 1026.2708, mean_rewards: 178.0126, total_rewards: 855.7539, mean_steps: 9.1800, mean_ecr: 0.0568 mean_entropies: 1.7743, took: 51.8865s
2022-10-09 23:20:14,850 [INFO] 	Process 3 - batch 7999: mean_policy_losses: 242.704, mean_net_lifetime: 3636.6051, mean_mc_travel_dist: 1595.0515, mean_rewards: 134.1653, total_rewards: 2060.1780, mean_steps: 26.3800, mean_ecr: 0.0480 mean_entropies: 1.6422, took: 130.0045s
2022-10-09 23:20:39,072 [INFO] 	Process 2 - batch 8099: mean_policy_losses: 55.100, mean_net_lifetime: 3163.3957, mean_mc_travel_dist: 1605.9279, mean_rewards: 120.0652, total_rewards: 1575.8922, mean_steps: 25.4500, mean_ecr: 0.0421 mean_entropies: 1.6505, took: 121.6799s
2022-10-09 23:20:49,659 [INFO] 	Process 6 - batch 12999: mean_policy_losses: -412.168, mean_net_lifetime: 1773.2916, mean_mc_travel_dist: 1010.8063, mean_rewards: 177.4893, total_rewards: 819.7107, mean_steps: 8.9000, mean_ecr: 0.0571 mean_entropies: 1.7683, took: 50.3533s
2022-10-09 23:21:04,553 [INFO] 	Process 7 - batch 7699: mean_policy_losses: 305.173, mean_net_lifetime: 3860.6109, mean_mc_travel_dist: 1864.0411, mean_rewards: 147.3037, total_rewards: 2031.2553, mean_steps: 25.3500, mean_ecr: 0.0433 mean_entropies: 2.2777, took: 120.0780s
2022-10-09 23:21:23,553 [INFO] 	Process 4 - batch 9599: mean_policy_losses: 66.940, mean_net_lifetime: 2622.0182, mean_mc_travel_dist: 1201.4578, mean_rewards: 136.8046, total_rewards: 1433.5992, mean_steps: 18.4700, mean_ecr: 0.0532 mean_entropies: 1.8890, took: 92.6869s
2022-10-09 23:21:30,190 [INFO] 	Process 5 - batch 8199: mean_policy_losses: 47.515, mean_net_lifetime: 3629.2533, mean_mc_travel_dist: 2145.5282, mean_rewards: 139.5307, total_rewards: 1534.2577, mean_steps: 24.6400, mean_ecr: 0.0308 mean_entropies: 2.3509, took: 123.9139s
2022-10-09 23:21:41,539 [INFO] 	Process 6 - batch 13099: mean_policy_losses: -380.872, mean_net_lifetime: 1886.1536, mean_mc_travel_dist: 1037.0858, mean_rewards: 181.7198, total_rewards: 895.7981, mean_steps: 9.2600, mean_ecr: 0.0567 mean_entropies: 1.6940, took: 51.8800s
2022-10-09 23:22:33,096 [INFO] 	Process 3 - batch 8099: mean_policy_losses: 215.652, mean_net_lifetime: 3577.6882, mean_mc_travel_dist: 1601.0326, mean_rewards: 127.1353, total_rewards: 1991.5077, mean_steps: 27.7100, mean_ecr: 0.0481 mean_entropies: 1.5503, took: 138.2461s
2022-10-09 23:22:33,128 [INFO] 	Process 6 - batch 13199: mean_policy_losses: -348.593, mean_net_lifetime: 1839.6392, mean_mc_travel_dist: 1023.5441, mean_rewards: 181.6044, total_rewards: 862.7422, mean_steps: 9.1800, mean_ecr: 0.0568 mean_entropies: 1.6572, took: 51.5896s
2022-10-09 23:22:42,838 [INFO] 	Process 2 - batch 8199: mean_policy_losses: 23.551, mean_net_lifetime: 3097.9674, mean_mc_travel_dist: 1616.5110, mean_rewards: 114.9321, total_rewards: 1504.0098, mean_steps: 26.0800, mean_ecr: 0.0422 mean_entropies: 1.5497, took: 123.7650s
2022-10-09 23:22:56,748 [INFO] 	Process 4 - batch 9699: mean_policy_losses: 52.950, mean_net_lifetime: 2640.5988, mean_mc_travel_dist: 1195.8387, mean_rewards: 135.2892, total_rewards: 1458.5766, mean_steps: 18.8100, mean_ecr: 0.0532 mean_entropies: 1.8167, took: 93.1957s
2022-10-09 23:23:19,363 [INFO] 	Process 7 - batch 7799: mean_policy_losses: 270.493, mean_net_lifetime: 3921.9738, mean_mc_travel_dist: 1883.4549, mean_rewards: 135.7006, total_rewards: 2079.1337, mean_steps: 28.5500, mean_ecr: 0.0434 mean_entropies: 2.1948, took: 134.8106s
2022-10-09 23:23:29,193 [INFO] 	Process 6 - batch 13299: mean_policy_losses: -312.562, mean_net_lifetime: 2054.1641, mean_mc_travel_dist: 1080.3662, mean_rewards: 181.4544, total_rewards: 1022.6900, mean_steps: 10.2400, mean_ecr: 0.0568 mean_entropies: 1.6496, took: 56.0636s
2022-10-09 23:23:33,585 [INFO] 	Process 5 - batch 8299: mean_policy_losses: 55.821, mean_net_lifetime: 3773.1554, mean_mc_travel_dist: 2202.5330, mean_rewards: 142.1395, total_rewards: 1629.3069, mean_steps: 24.9700, mean_ecr: 0.0307 mean_entropies: 2.3469, took: 123.3945s
2022-10-09 23:24:22,820 [INFO] 	Process 6 - batch 13399: mean_policy_losses: -364.648, mean_net_lifetime: 1942.3752, mean_mc_travel_dist: 1049.7080, mean_rewards: 182.1753, total_rewards: 944.1865, mean_steps: 9.5400, mean_ecr: 0.0568 mean_entropies: 1.6992, took: 53.6274s
2022-10-09 23:24:32,157 [INFO] 	Process 4 - batch 9799: mean_policy_losses: 40.528, mean_net_lifetime: 2677.6412, mean_mc_travel_dist: 1208.5182, mean_rewards: 136.7418, total_rewards: 1488.6211, mean_steps: 18.8900, mean_ecr: 0.0531 mean_entropies: 1.8284, took: 95.4084s
2022-10-09 23:24:44,988 [INFO] 	Process 3 - batch 8199: mean_policy_losses: 197.251, mean_net_lifetime: 3590.4390, mean_mc_travel_dist: 1587.2933, mean_rewards: 130.0997, total_rewards: 2022.0992, mean_steps: 26.9300, mean_ecr: 0.0482 mean_entropies: 1.5364, took: 131.8916s
2022-10-09 23:24:48,668 [INFO] 	Process 2 - batch 8299: mean_policy_losses: -8.428, mean_net_lifetime: 3123.6205, mean_mc_travel_dist: 1626.0409, mean_rewards: 114.6228, total_rewards: 1520.9983, mean_steps: 26.4400, mean_ecr: 0.0421 mean_entropies: 1.5696, took: 125.8302s
2022-10-09 23:25:16,996 [INFO] 	Process 6 - batch 13499: mean_policy_losses: -281.759, mean_net_lifetime: 2048.1118, mean_mc_travel_dist: 1072.3951, mean_rewards: 187.3041, total_rewards: 1025.3469, mean_steps: 9.7900, mean_ecr: 0.0568 mean_entropies: 1.6587, took: 54.1765s
2022-10-09 23:25:19,267 [INFO] 	Process 7 - batch 7899: mean_policy_losses: 259.489, mean_net_lifetime: 3839.9024, mean_mc_travel_dist: 1885.5967, mean_rewards: 147.2031, total_rewards: 1992.1261, mean_steps: 25.1300, mean_ecr: 0.0432 mean_entropies: 2.2728, took: 119.9038s
2022-10-09 23:25:33,501 [INFO] 	Process 5 - batch 8399: mean_policy_losses: 85.307, mean_net_lifetime: 3808.7003, mean_mc_travel_dist: 2196.1459, mean_rewards: 146.9036, total_rewards: 1665.6060, mean_steps: 24.2900, mean_ecr: 0.0308 mean_entropies: 2.3520, took: 119.9152s
2022-10-09 23:26:02,824 [INFO] 	Process 4 - batch 9899: mean_policy_losses: -22.411, mean_net_lifetime: 2559.2541, mean_mc_travel_dist: 1187.9664, mean_rewards: 134.5418, total_rewards: 1385.9699, mean_steps: 18.2700, mean_ecr: 0.0533 mean_entropies: 1.8480, took: 90.6673s
2022-10-09 23:26:50,008 [INFO] 	Process 3 - batch 8299: mean_policy_losses: 148.047, mean_net_lifetime: 3519.6244, mean_mc_travel_dist: 1599.9143, mean_rewards: 131.0666, total_rewards: 1938.5286, mean_steps: 26.1200, mean_ecr: 0.0480 mean_entropies: 1.5509, took: 125.0197s
2022-10-09 23:26:51,522 [INFO] 	Process 2 - batch 8399: mean_policy_losses: -17.295, mean_net_lifetime: 3128.6825, mean_mc_travel_dist: 1599.5989, mean_rewards: 115.0908, total_rewards: 1553.2823, mean_steps: 26.4000, mean_ecr: 0.0421 mean_entropies: 1.5827, took: 122.8547s
2022-10-09 23:27:14,107 [INFO] 	Process 7 - batch 7999: mean_policy_losses: 132.882, mean_net_lifetime: 3742.2584, mean_mc_travel_dist: 1868.7496, mean_rewards: 146.0666, total_rewards: 1910.9849, mean_steps: 24.7700, mean_ecr: 0.0433 mean_entropies: 2.2864, took: 114.8396s
2022-10-09 23:27:34,511 [INFO] 	Process 4 - batch 9999: mean_policy_losses: -106.127, mean_net_lifetime: 2618.4744, mean_mc_travel_dist: 1204.1346, mean_rewards: 132.8006, total_rewards: 1426.2583, mean_steps: 18.8900, mean_ecr: 0.0532 mean_entropies: 1.8667, took: 91.6869s
2022-10-09 23:27:35,244 [INFO] 	Process 5 - batch 8499: mean_policy_losses: 106.242, mean_net_lifetime: 4165.7611, mean_mc_travel_dist: 2349.0117, mean_rewards: 158.2297, total_rewards: 1867.1524, mean_steps: 24.9700, mean_ecr: 0.0310 mean_entropies: 2.4547, took: 121.7434s
2022-10-09 23:28:50,523 [INFO] 	Process 2 - batch 8499: mean_policy_losses: -12.104, mean_net_lifetime: 3518.8630, mean_mc_travel_dist: 1727.0029, mean_rewards: 131.6229, total_rewards: 1810.9009, mean_steps: 25.8100, mean_ecr: 0.0417 mean_entropies: 1.8690, took: 119.0002s
2022-10-09 23:28:53,325 [INFO] 	Process 3 - batch 8399: mean_policy_losses: 170.551, mean_net_lifetime: 3753.9530, mean_mc_travel_dist: 1619.4194, mean_rewards: 144.3270, total_rewards: 2154.6827, mean_steps: 25.4900, mean_ecr: 0.0481 mean_entropies: 1.7345, took: 123.3171s
2022-10-09 23:29:03,349 [INFO] 	Process 4 - batch 10099: mean_policy_losses: -128.701, mean_net_lifetime: 2595.4406, mean_mc_travel_dist: 1198.3878, mean_rewards: 136.5507, total_rewards: 1410.7004, mean_steps: 18.2700, mean_ecr: 0.0531 mean_entropies: 1.8664, took: 88.8376s
2022-10-09 23:29:15,718 [INFO] 	Process 7 - batch 8099: mean_policy_losses: 33.989, mean_net_lifetime: 3792.6022, mean_mc_travel_dist: 1852.2648, mean_rewards: 139.9723, total_rewards: 1981.8426, mean_steps: 26.3300, mean_ecr: 0.0434 mean_entropies: 2.2579, took: 121.6116s
2022-10-09 23:29:45,458 [INFO] 	Process 5 - batch 8599: mean_policy_losses: 226.828, mean_net_lifetime: 4777.7058, mean_mc_travel_dist: 2660.2268, mean_rewards: 167.3093, total_rewards: 2171.6158, mean_steps: 27.5400, mean_ecr: 0.0309 mean_entropies: 2.5271, took: 130.2145s
2022-10-09 23:30:32,420 [INFO] 	Process 4 - batch 10199: mean_policy_losses: -228.544, mean_net_lifetime: 2503.2691, mean_mc_travel_dist: 1205.3136, mean_rewards: 131.5168, total_rewards: 1306.8874, mean_steps: 18.3200, mean_ecr: 0.0531 mean_entropies: 1.9019, took: 89.0709s
2022-10-09 23:30:49,997 [INFO] 	Process 2 - batch 8599: mean_policy_losses: 68.568, mean_net_lifetime: 3740.5273, mean_mc_travel_dist: 1804.8207, mean_rewards: 139.9190, total_rewards: 1958.9457, mean_steps: 25.7600, mean_ecr: 0.0415 mean_entropies: 1.9720, took: 119.4730s
2022-10-09 23:30:51,812 [INFO] 	Process 3 - batch 8499: mean_policy_losses: 192.680, mean_net_lifetime: 3816.9136, mean_mc_travel_dist: 1657.3666, mean_rewards: 150.9104, total_rewards: 2183.0146, mean_steps: 24.5500, mean_ecr: 0.0478 mean_entropies: 1.8342, took: 118.4866s
2022-10-09 23:31:21,776 [INFO] 	Process 7 - batch 8199: mean_policy_losses: -22.598, mean_net_lifetime: 3721.6351, mean_mc_travel_dist: 1839.2565, mean_rewards: 132.3874, total_rewards: 1928.1993, mean_steps: 27.3300, mean_ecr: 0.0434 mean_entropies: 2.2561, took: 126.0570s
2022-10-09 23:31:49,868 [INFO] 	Process 5 - batch 8699: mean_policy_losses: 79.040, mean_net_lifetime: 4494.9682, mean_mc_travel_dist: 2547.9303, mean_rewards: 165.2969, total_rewards: 2003.5186, mean_steps: 26.0500, mean_ecr: 0.0309 mean_entropies: 2.5510, took: 124.4094s
2022-10-09 23:31:59,618 [INFO] 	Process 4 - batch 10299: mean_policy_losses: -276.055, mean_net_lifetime: 2507.6987, mean_mc_travel_dist: 1193.5026, mean_rewards: 134.5999, total_rewards: 1328.7912, mean_steps: 17.8700, mean_ecr: 0.0534 mean_entropies: 1.9311, took: 87.1986s
2022-10-09 23:32:47,413 [INFO] 	Process 2 - batch 8699: mean_policy_losses: 29.812, mean_net_lifetime: 3726.3034, mean_mc_travel_dist: 1806.8692, mean_rewards: 142.1951, total_rewards: 1946.7763, mean_steps: 25.2300, mean_ecr: 0.0415 mean_entropies: 1.9891, took: 117.4172s
2022-10-09 23:32:51,487 [INFO] 	Process 3 - batch 8599: mean_policy_losses: 155.552, mean_net_lifetime: 3780.0334, mean_mc_travel_dist: 1636.2304, mean_rewards: 151.8173, total_rewards: 2169.5994, mean_steps: 24.2400, mean_ecr: 0.0480 mean_entropies: 1.8665, took: 119.6761s
2022-10-09 23:33:23,525 [INFO] 	Process 7 - batch 8299: mean_policy_losses: 75.074, mean_net_lifetime: 3902.8943, mean_mc_travel_dist: 1868.6438, mean_rewards: 144.0939, total_rewards: 2079.9703, mean_steps: 26.4300, mean_ecr: 0.0435 mean_entropies: 2.2829, took: 121.7498s
2022-10-09 23:33:24,735 [INFO] 	Process 4 - batch 10399: mean_policy_losses: -187.054, mean_net_lifetime: 2524.1158, mean_mc_travel_dist: 1182.6277, mean_rewards: 139.0408, total_rewards: 1355.3137, mean_steps: 17.4000, mean_ecr: 0.0533 mean_entropies: 1.9686, took: 85.1167s
2022-10-09 23:33:53,633 [INFO] 	Process 5 - batch 8799: mean_policy_losses: 56.384, mean_net_lifetime: 4461.5302, mean_mc_travel_dist: 2545.5006, mean_rewards: 161.0826, total_rewards: 1969.6996, mean_steps: 26.3600, mean_ecr: 0.0307 mean_entropies: 2.5683, took: 123.7653s
2022-10-09 23:34:44,025 [INFO] 	Process 2 - batch 8799: mean_policy_losses: 89.791, mean_net_lifetime: 3850.9435, mean_mc_travel_dist: 1828.7885, mean_rewards: 148.5240, total_rewards: 2039.0195, mean_steps: 25.0600, mean_ecr: 0.0415 mean_entropies: 2.0380, took: 116.6124s
2022-10-09 23:34:45,699 [INFO] 	Process 3 - batch 8699: mean_policy_losses: 182.149, mean_net_lifetime: 3832.8621, mean_mc_travel_dist: 1651.3570, mean_rewards: 156.5071, total_rewards: 2202.3733, mean_steps: 23.7200, mean_ecr: 0.0478 mean_entropies: 1.9015, took: 114.2105s
2022-10-09 23:34:51,583 [INFO] 	Process 4 - batch 10499: mean_policy_losses: -245.334, mean_net_lifetime: 2555.6731, mean_mc_travel_dist: 1195.8887, mean_rewards: 138.4726, total_rewards: 1374.1949, mean_steps: 17.7100, mean_ecr: 0.0533 mean_entropies: 1.9486, took: 86.8479s
2022-10-09 23:35:28,818 [INFO] 	Process 7 - batch 8399: mean_policy_losses: -48.687, mean_net_lifetime: 3824.3776, mean_mc_travel_dist: 1848.2021, mean_rewards: 135.2503, total_rewards: 2011.3346, mean_steps: 27.5500, mean_ecr: 0.0434 mean_entropies: 2.2551, took: 125.2922s
2022-10-09 23:36:02,765 [INFO] 	Process 5 - batch 8899: mean_policy_losses: -27.507, mean_net_lifetime: 4659.4626, mean_mc_travel_dist: 2656.2812, mean_rewards: 161.6410, total_rewards: 2054.2108, mean_steps: 27.5300, mean_ecr: 0.0306 mean_entropies: 2.5653, took: 129.1324s
2022-10-09 23:36:36,637 [INFO] 	Process 2 - batch 8899: mean_policy_losses: 25.382, mean_net_lifetime: 3980.9545, mean_mc_travel_dist: 1892.0905, mean_rewards: 154.2414, total_rewards: 2117.1772, mean_steps: 24.9300, mean_ecr: 0.0413 mean_entropies: 2.1240, took: 112.6107s
2022-10-09 23:36:40,554 [INFO] 	Process 3 - batch 8799: mean_policy_losses: 103.951, mean_net_lifetime: 3918.3564, mean_mc_travel_dist: 1705.5319, mean_rewards: 156.6297, total_rewards: 2243.9215, mean_steps: 24.2400, mean_ecr: 0.0480 mean_entropies: 1.9629, took: 114.8562s
2022-10-09 23:37:32,787 [INFO] 	Process 7 - batch 8499: mean_policy_losses: -163.686, mean_net_lifetime: 3752.7122, mean_mc_travel_dist: 1807.5851, mean_rewards: 132.6574, total_rewards: 1977.9550, mean_steps: 27.6600, mean_ecr: 0.0435 mean_entropies: 2.2617, took: 123.9697s
2022-10-09 23:38:04,714 [INFO] 	Process 5 - batch 8999: mean_policy_losses: -173.796, mean_net_lifetime: 4302.8427, mean_mc_travel_dist: 2533.1488, mean_rewards: 154.8015, total_rewards: 1832.0133, mean_steps: 26.7200, mean_ecr: 0.0309 mean_entropies: 2.5502, took: 121.9487s
2022-10-09 23:38:26,083 [INFO] Process 1 - epoch 5: mean_policy_losses: 257.570, mean_net_lifetime: 4554.7730, mean_mc_travel_dist: 2373.6511, mean_entropies: 2.2044, m_net_lifetime_valid: 2988.1624, took: 3341.7857s, (261.1500 / 100 batches)

2022-10-09 23:38:27,427 [INFO] 	Process 2 - batch 8999: mean_policy_losses: 90.318, mean_net_lifetime: 4210.9364, mean_mc_travel_dist: 2000.5995, mean_rewards: 162.8343, total_rewards: 2242.1790, mean_steps: 24.8500, mean_ecr: 0.0410 mean_entropies: 2.2069, took: 110.7907s
2022-10-09 23:38:28,596 [INFO] 	Process 3 - batch 8899: mean_policy_losses: 101.807, mean_net_lifetime: 3932.4250, mean_mc_travel_dist: 1725.6213, mean_rewards: 165.5813, total_rewards: 2226.1123, mean_steps: 22.9700, mean_ecr: 0.0474 mean_entropies: 2.0166, took: 108.0418s
2022-10-09 23:39:31,787 [INFO] 	Process 7 - batch 8599: mean_policy_losses: -125.685, mean_net_lifetime: 3742.1719, mean_mc_travel_dist: 1815.1751, mean_rewards: 132.8085, total_rewards: 1971.7707, mean_steps: 27.7400, mean_ecr: 0.0435 mean_entropies: 2.2376, took: 118.9999s
2022-10-09 23:40:15,411 [INFO] 	Process 3 - batch 8999: mean_policy_losses: 144.250, mean_net_lifetime: 3963.8276, mean_mc_travel_dist: 1692.9665, mean_rewards: 163.9542, total_rewards: 2297.1797, mean_steps: 23.4200, mean_ecr: 0.0478 mean_entropies: 2.0115, took: 106.8147s
2022-10-09 23:41:10,855 [INFO] 	Process 7 - batch 8699: mean_policy_losses: -100.477, mean_net_lifetime: 3692.9822, mean_mc_travel_dist: 1835.4079, mean_rewards: 152.3562, total_rewards: 1898.1594, mean_steps: 23.4700, mean_ecr: 0.0433 mean_entropies: 2.3901, took: 99.0683s
2022-10-09 23:41:11,808 [INFO] 	Process 1 - batch 7599: mean_policy_losses: -7.348, mean_net_lifetime: 4596.1628, mean_mc_travel_dist: 2323.6279, mean_rewards: 117.1187, total_rewards: 2293.4151, mean_steps: 38.7200, mean_ecr: 0.0397 mean_entropies: 1.9435, took: 1429.6111s
2022-10-09 23:42:33,810 [INFO] 	Process 7 - batch 8799: mean_policy_losses: -161.271, mean_net_lifetime: 3212.3326, mean_mc_travel_dist: 1731.2939, mean_rewards: 158.0763, total_rewards: 1526.8062, mean_steps: 19.3000, mean_ecr: 0.0435 mean_entropies: 2.4349, took: 82.9548s
2022-10-09 23:43:52,380 [INFO] 	Process 1 - batch 7699: mean_policy_losses: 88.316, mean_net_lifetime: 4629.4232, mean_mc_travel_dist: 2330.2021, mean_rewards: 118.3590, total_rewards: 2320.4115, mean_steps: 38.4600, mean_ecr: 0.0396 mean_entropies: 2.0340, took: 160.5717s
2022-10-09 23:44:04,530 [INFO] 	Process 7 - batch 8899: mean_policy_losses: -86.299, mean_net_lifetime: 3514.4550, mean_mc_travel_dist: 1800.4188, mean_rewards: 155.7806, total_rewards: 1758.6469, mean_steps: 21.7100, mean_ecr: 0.0434 mean_entropies: 2.4091, took: 90.7195s
2022-10-09 23:45:28,275 [INFO] Process 6 - epoch 9: mean_policy_losses: -352.008, mean_net_lifetime: 1781.5381, mean_mc_travel_dist: 1022.1513, mean_entropies: 1.8836, m_net_lifetime_valid: 2993.4438, took: 1972.4996s, (149.4244 / 100 batches)

2022-10-09 23:45:29,904 [INFO] 	Process 7 - batch 8999: mean_policy_losses: -203.108, mean_net_lifetime: 3251.7759, mean_mc_travel_dist: 1724.7805, mean_rewards: 153.2125, total_rewards: 1572.3083, mean_steps: 20.1400, mean_ecr: 0.0436 mean_entropies: 2.4141, took: 85.3750s
2022-10-09 23:46:07,591 [INFO] 	Process 6 - batch 13599: mean_policy_losses: -370.148, mean_net_lifetime: 1454.0384, mean_mc_travel_dist: 936.0475, mean_rewards: 167.8507, total_rewards: 574.5803, mean_steps: 7.6800, mean_ecr: 0.0563 mean_entropies: 2.1332, took: 1250.5949s
2022-10-09 23:46:23,536 [INFO] 	Process 1 - batch 7799: mean_policy_losses: 259.581, mean_net_lifetime: 4690.5130, mean_mc_travel_dist: 2311.8717, mean_rewards: 125.7692, total_rewards: 2405.7855, mean_steps: 36.7200, mean_ecr: 0.0398 mean_entropies: 2.0577, took: 151.1560s
2022-10-09 23:46:51,691 [INFO] 	Process 6 - batch 13699: mean_policy_losses: -58.937, mean_net_lifetime: 1795.7126, mean_mc_travel_dist: 1028.4425, mean_rewards: 180.6166, total_rewards: 823.7191, mean_steps: 8.8800, mean_ecr: 0.0567 mean_entropies: 2.0183, took: 44.1005s
2022-10-09 23:47:32,156 [INFO] 	Process 6 - batch 13799: mean_policy_losses: -167.882, mean_net_lifetime: 1670.3157, mean_mc_travel_dist: 977.5671, mean_rewards: 176.3995, total_rewards: 756.6365, mean_steps: 8.3500, mean_ecr: 0.0565 mean_entropies: 1.9891, took: 40.4644s
2022-10-09 23:48:15,546 [INFO] 	Process 6 - batch 13899: mean_policy_losses: -238.414, mean_net_lifetime: 1678.1452, mean_mc_travel_dist: 997.4112, mean_rewards: 173.5943, total_rewards: 743.6240, mean_steps: 8.4600, mean_ecr: 0.0570 mean_entropies: 1.8960, took: 43.3893s
2022-10-09 23:48:50,424 [INFO] 	Process 1 - batch 7899: mean_policy_losses: 451.174, mean_net_lifetime: 4723.1313, mean_mc_travel_dist: 2383.8279, mean_rewards: 133.9936, total_rewards: 2366.8848, mean_steps: 34.5600, mean_ecr: 0.0397 mean_entropies: 2.0796, took: 146.8868s
2022-10-09 23:48:57,983 [INFO] 	Process 6 - batch 13999: mean_policy_losses: -194.425, mean_net_lifetime: 1751.8288, mean_mc_travel_dist: 1006.3659, mean_rewards: 181.7662, total_rewards: 794.6502, mean_steps: 8.6100, mean_ecr: 0.0568 mean_entropies: 1.8204, took: 42.4383s
2022-10-09 23:49:42,317 [INFO] 	Process 6 - batch 14099: mean_policy_losses: -150.191, mean_net_lifetime: 1896.7414, mean_mc_travel_dist: 1031.4830, mean_rewards: 186.3927, total_rewards: 912.0122, mean_steps: 9.0200, mean_ecr: 0.0568 mean_entropies: 1.7799, took: 44.3331s
2022-10-09 23:50:26,562 [INFO] 	Process 6 - batch 14199: mean_policy_losses: -198.261, mean_net_lifetime: 1953.4041, mean_mc_travel_dist: 1058.5328, mean_rewards: 187.5564, total_rewards: 956.1606, mean_steps: 9.2200, mean_ecr: 0.0572 mean_entropies: 1.6886, took: 44.2458s
2022-10-09 23:51:04,364 [INFO] 	Process 1 - batch 7999: mean_policy_losses: 398.562, mean_net_lifetime: 4569.4619, mean_mc_travel_dist: 2351.2663, mean_rewards: 141.3438, total_rewards: 2254.0204, mean_steps: 31.7700, mean_ecr: 0.0399 mean_entropies: 2.0500, took: 133.9412s
2022-10-09 23:51:13,504 [INFO] 	Process 6 - batch 14299: mean_policy_losses: -150.330, mean_net_lifetime: 2180.9016, mean_mc_travel_dist: 1102.7824, mean_rewards: 194.8002, total_rewards: 1119.5298, mean_steps: 10.0500, mean_ecr: 0.0567 mean_entropies: 1.6336, took: 46.9415s
2022-10-09 23:52:02,589 [INFO] 	Process 6 - batch 14399: mean_policy_losses: -341.765, mean_net_lifetime: 2092.6583, mean_mc_travel_dist: 1090.0671, mean_rewards: 184.1854, total_rewards: 1052.3567, mean_steps: 10.1500, mean_ecr: 0.0568 mean_entropies: 1.5627, took: 49.0850s
2022-10-09 23:52:52,989 [INFO] 	Process 6 - batch 14499: mean_policy_losses: -340.002, mean_net_lifetime: 2249.0671, mean_mc_travel_dist: 1141.6050, mean_rewards: 194.1846, total_rewards: 1156.6624, mean_steps: 10.3800, mean_ecr: 0.0568 mean_entropies: 1.5047, took: 50.4003s
2022-10-09 23:53:07,955 [INFO] 	Process 1 - batch 8099: mean_policy_losses: 200.950, mean_net_lifetime: 4495.3281, mean_mc_travel_dist: 2391.4136, mean_rewards: 148.7718, total_rewards: 2133.6303, mean_steps: 29.5400, mean_ecr: 0.0400 mean_entropies: 2.0219, took: 123.5902s
2022-10-09 23:53:42,964 [INFO] Process 4 - epoch 7: mean_policy_losses: -34.068, mean_net_lifetime: 2550.3865, mean_mc_travel_dist: 1220.3515, mean_entropies: 2.0151, m_net_lifetime_valid: 2961.1965, took: 2489.1085s, (197.1383 / 100 batches)

2022-10-09 23:53:55,075 [INFO] 	Process 6 - batch 14599: mean_policy_losses: -142.713, mean_net_lifetime: 2844.7345, mean_mc_travel_dist: 1289.7311, mean_rewards: 201.1081, total_rewards: 1585.7006, mean_steps: 13.1000, mean_ecr: 0.0562 mean_entropies: 1.1437, took: 62.0856s
2022-10-09 23:54:59,160 [INFO] 	Process 6 - batch 14699: mean_policy_losses: 57.524, mean_net_lifetime: 2967.3080, mean_mc_travel_dist: 1324.6104, mean_rewards: 203.1076, total_rewards: 1669.9085, mean_steps: 13.5300, mean_ecr: 0.0557 mean_entropies: 0.9712, took: 64.0849s
2022-10-09 23:55:11,571 [INFO] 	Process 4 - batch 10599: mean_policy_losses: -116.139, mean_net_lifetime: 2352.6190, mean_mc_travel_dist: 1127.4980, mean_rewards: 114.9892, total_rewards: 1239.3323, mean_steps: 19.7000, mean_ecr: 0.0534 mean_entropies: 1.4800, took: 1219.9890s
2022-10-09 23:55:19,015 [INFO] 	Process 1 - batch 8199: mean_policy_losses: 128.521, mean_net_lifetime: 4479.0605, mean_mc_travel_dist: 2537.2316, mean_rewards: 144.0508, total_rewards: 1984.2983, mean_steps: 30.3500, mean_ecr: 0.0396 mean_entropies: 1.6804, took: 131.0614s
2022-10-09 23:56:06,607 [INFO] 	Process 6 - batch 14799: mean_policy_losses: 10.143, mean_net_lifetime: 3021.6906, mean_mc_travel_dist: 1324.0116, mean_rewards: 201.3465, total_rewards: 1728.8503, mean_steps: 13.9500, mean_ecr: 0.0558 mean_entropies: 0.9411, took: 67.4471s
2022-10-09 23:56:40,308 [INFO] 	Process 4 - batch 10699: mean_policy_losses: -116.272, mean_net_lifetime: 2498.3438, mean_mc_travel_dist: 1151.5265, mean_rewards: 119.6684, total_rewards: 1359.5864, mean_steps: 20.0200, mean_ecr: 0.0532 mean_entropies: 1.4747, took: 88.7367s
2022-10-09 23:57:11,303 [INFO] 	Process 6 - batch 14899: mean_policy_losses: -61.449, mean_net_lifetime: 2887.8204, mean_mc_travel_dist: 1309.9468, mean_rewards: 197.0548, total_rewards: 1612.0592, mean_steps: 13.6200, mean_ecr: 0.0560 mean_entropies: 0.9506, took: 64.6961s
2022-10-09 23:57:36,011 [INFO] 	Process 1 - batch 8299: mean_policy_losses: 85.085, mean_net_lifetime: 4488.8293, mean_mc_travel_dist: 2525.2470, mean_rewards: 138.1458, total_rewards: 2006.4456, mean_steps: 31.8100, mean_ecr: 0.0396 mean_entropies: 1.6227, took: 136.9956s
2022-10-09 23:57:40,232 [INFO] Process 5 - epoch 6: mean_policy_losses: 1.710, mean_net_lifetime: 3858.8912, mean_mc_travel_dist: 2291.2190, mean_entropies: 2.5396, m_net_lifetime_valid: 2988.8431, took: 2970.0636s, (231.7570 / 100 batches)

2022-10-09 23:57:52,165 [INFO] Process 2 - epoch 6: mean_policy_losses: -14.851, mean_net_lifetime: 3248.3853, mean_mc_travel_dist: 1700.5512, mean_entropies: 2.0043, m_net_lifetime_valid: 3016.6852, took: 2943.4462s, (232.0078 / 100 batches)

2022-10-09 23:58:10,775 [INFO] 	Process 4 - batch 10799: mean_policy_losses: -85.262, mean_net_lifetime: 2502.4773, mean_mc_travel_dist: 1149.7581, mean_rewards: 120.0225, total_rewards: 1363.1069, mean_steps: 20.0400, mean_ecr: 0.0532 mean_entropies: 1.5434, took: 90.4665s
2022-10-09 23:58:19,154 [INFO] 	Process 6 - batch 14999: mean_policy_losses: -28.324, mean_net_lifetime: 2777.1586, mean_mc_travel_dist: 1258.2476, mean_rewards: 191.9204, total_rewards: 1557.4049, mean_steps: 13.2300, mean_ecr: 0.0559 mean_entropies: 1.0712, took: 67.8508s
2022-10-09 23:58:59,468 [INFO] Process 3 - epoch 6: mean_policy_losses: 203.093, mean_net_lifetime: 3654.1966, mean_mc_travel_dist: 1659.1446, mean_entropies: 1.9427, m_net_lifetime_valid: 2938.2622, took: 2947.7372s, (233.1860 / 100 batches)

2022-10-09 23:59:33,597 [INFO] 	Process 5 - batch 9099: mean_policy_losses: -159.019, mean_net_lifetime: 2883.8527, mean_mc_travel_dist: 1788.0469, mean_rewards: 114.0969, total_rewards: 1137.7276, mean_steps: 23.9000, mean_ecr: 0.0308 mean_entropies: 1.9493, took: 1288.8831s
2022-10-09 23:59:39,796 [INFO] 	Process 4 - batch 10899: mean_policy_losses: 105.449, mean_net_lifetime: 2769.4329, mean_mc_travel_dist: 1214.5585, mean_rewards: 141.2530, total_rewards: 1565.6569, mean_steps: 18.7600, mean_ecr: 0.0529 mean_entropies: 1.8743, took: 89.0208s
2022-10-09 23:59:56,684 [INFO] 	Process 2 - batch 9099: mean_policy_losses: -37.369, mean_net_lifetime: 3038.1260, mean_mc_travel_dist: 1608.3526, mean_rewards: 107.2281, total_rewards: 1452.8946, mean_steps: 27.4900, mean_ecr: 0.0423 mean_entropies: 1.3423, took: 1289.2570s
2022-10-10 00:00:07,723 [INFO] 	Process 1 - batch 8399: mean_policy_losses: 269.316, mean_net_lifetime: 4566.7644, mean_mc_travel_dist: 2398.9811, mean_rewards: 136.3391, total_rewards: 2206.6785, mean_steps: 32.8400, mean_ecr: 0.0398 mean_entropies: 1.8785, took: 151.7117s
2022-10-10 00:01:02,123 [INFO] 	Process 3 - batch 9099: mean_policy_losses: 151.661, mean_net_lifetime: 3598.1091, mean_mc_travel_dist: 1594.5749, mean_rewards: 138.6459, total_rewards: 2027.5342, mean_steps: 25.3100, mean_ecr: 0.0481 mean_entropies: 1.6024, took: 1246.7120s
2022-10-10 00:01:07,119 [INFO] 	Process 4 - batch 10999: mean_policy_losses: -94.404, mean_net_lifetime: 2661.4608, mean_mc_travel_dist: 1228.8266, mean_rewards: 144.1783, total_rewards: 1448.2284, mean_steps: 17.7400, mean_ecr: 0.0530 mean_entropies: 2.0007, took: 87.3232s
2022-10-10 00:01:32,352 [INFO] 	Process 5 - batch 9199: mean_policy_losses: -22.925, mean_net_lifetime: 3975.3805, mean_mc_travel_dist: 2272.0791, mean_rewards: 152.9686, total_rewards: 1764.0854, mean_steps: 24.4700, mean_ecr: 0.0307 mean_entropies: 2.4406, took: 118.7549s
2022-10-10 00:01:55,650 [INFO] 	Process 2 - batch 9199: mean_policy_losses: -57.366, mean_net_lifetime: 3296.5352, mean_mc_travel_dist: 1670.0757, mean_rewards: 125.3888, total_rewards: 1652.3454, mean_steps: 25.4400, mean_ecr: 0.0420 mean_entropies: 1.7549, took: 118.9664s
2022-10-10 00:02:33,614 [INFO] 	Process 4 - batch 11099: mean_policy_losses: -116.056, mean_net_lifetime: 2705.0990, mean_mc_travel_dist: 1230.3234, mean_rewards: 148.6461, total_rewards: 1490.4496, mean_steps: 17.3500, mean_ecr: 0.0530 mean_entropies: 2.0263, took: 86.4946s
2022-10-10 00:02:52,380 [INFO] 	Process 1 - batch 8499: mean_policy_losses: 186.534, mean_net_lifetime: 4759.1503, mean_mc_travel_dist: 2400.0078, mean_rewards: 129.3929, total_rewards: 2395.5644, mean_steps: 36.0700, mean_ecr: 0.0397 mean_entropies: 2.0104, took: 164.6558s
2022-10-10 00:03:00,494 [INFO] 	Process 3 - batch 9199: mean_policy_losses: 102.576, mean_net_lifetime: 3661.1198, mean_mc_travel_dist: 1624.1828, mean_rewards: 145.9352, total_rewards: 2065.5027, mean_steps: 24.3700, mean_ecr: 0.0480 mean_entropies: 1.7510, took: 118.3710s
2022-10-10 00:03:31,439 [INFO] 	Process 5 - batch 9299: mean_policy_losses: -7.011, mean_net_lifetime: 4222.6571, mean_mc_travel_dist: 2396.5176, mean_rewards: 160.1007, total_rewards: 1874.8289, mean_steps: 24.9700, mean_ecr: 0.0308 mean_entropies: 2.5399, took: 119.0871s
2022-10-10 00:03:53,029 [INFO] 	Process 2 - batch 9299: mean_policy_losses: -40.861, mean_net_lifetime: 3533.5859, mean_mc_travel_dist: 1738.5295, mean_rewards: 136.7028, total_rewards: 1818.1527, mean_steps: 24.9800, mean_ecr: 0.0415 mean_entropies: 1.9629, took: 117.3797s
2022-10-10 00:03:59,476 [INFO] 	Process 4 - batch 11199: mean_policy_losses: -170.780, mean_net_lifetime: 2691.1018, mean_mc_travel_dist: 1236.0710, mean_rewards: 147.6502, total_rewards: 1471.3539, mean_steps: 17.4100, mean_ecr: 0.0529 mean_entropies: 2.0387, took: 85.8631s
2022-10-10 00:04:54,512 [INFO] 	Process 3 - batch 9299: mean_policy_losses: 148.842, mean_net_lifetime: 3806.3622, mean_mc_travel_dist: 1659.8521, mean_rewards: 158.7702, total_rewards: 2161.7141, mean_steps: 23.2200, mean_ecr: 0.0478 mean_entropies: 1.9258, took: 114.0182s
2022-10-10 00:05:22,800 [INFO] 	Process 4 - batch 11299: mean_policy_losses: -289.977, mean_net_lifetime: 2512.3170, mean_mc_travel_dist: 1213.9815, mean_rewards: 141.5226, total_rewards: 1314.1283, mean_steps: 16.9100, mean_ecr: 0.0531 mean_entropies: 2.0333, took: 83.3238s
2022-10-10 00:05:38,237 [INFO] 	Process 5 - batch 9399: mean_policy_losses: 2.653, mean_net_lifetime: 4426.5479, mean_mc_travel_dist: 2524.5847, mean_rewards: 159.7737, total_rewards: 1955.3814, mean_steps: 26.4200, mean_ecr: 0.0310 mean_entropies: 2.5862, took: 126.7980s
2022-10-10 00:05:42,933 [INFO] 	Process 1 - batch 8599: mean_policy_losses: 58.580, mean_net_lifetime: 4574.7240, mean_mc_travel_dist: 2325.9487, mean_rewards: 121.4113, total_rewards: 2283.0511, mean_steps: 37.0400, mean_ecr: 0.0397 mean_entropies: 1.9941, took: 170.5533s
2022-10-10 00:05:49,212 [INFO] Process 7 - epoch 6: mean_policy_losses: 68.779, mean_net_lifetime: 3626.5786, mean_mc_travel_dist: 1801.8491, mean_entropies: 2.2986, m_net_lifetime_valid: 3039.0720, took: 2923.0370s, (236.6488 / 100 batches)

2022-10-10 00:05:49,431 [INFO] 	Process 2 - batch 9399: mean_policy_losses: 46.517, mean_net_lifetime: 3872.1467, mean_mc_travel_dist: 1869.2111, mean_rewards: 151.8645, total_rewards: 2030.3267, mean_steps: 24.5000, mean_ecr: 0.0413 mean_entropies: 2.1294, took: 116.4015s
2022-10-10 00:06:50,839 [INFO] 	Process 4 - batch 11399: mean_policy_losses: -264.317, mean_net_lifetime: 2575.7222, mean_mc_travel_dist: 1225.0499, mean_rewards: 141.9880, total_rewards: 1361.2626, mean_steps: 17.3600, mean_ecr: 0.0529 mean_entropies: 2.0478, took: 88.0383s
2022-10-10 00:06:55,945 [INFO] 	Process 3 - batch 9399: mean_policy_losses: 157.155, mean_net_lifetime: 3904.4584, mean_mc_travel_dist: 1681.0940, mean_rewards: 156.2408, total_rewards: 2243.0747, mean_steps: 24.3100, mean_ecr: 0.0477 mean_entropies: 1.9365, took: 121.4331s
2022-10-10 00:07:46,543 [INFO] 	Process 2 - batch 9499: mean_policy_losses: -57.892, mean_net_lifetime: 3517.2355, mean_mc_travel_dist: 1716.0582, mean_rewards: 141.5880, total_rewards: 1834.4152, mean_steps: 23.9000, mean_ecr: 0.0418 mean_entropies: 2.0250, took: 117.1120s
2022-10-10 00:07:47,704 [INFO] 	Process 5 - batch 9499: mean_policy_losses: -18.572, mean_net_lifetime: 4415.4762, mean_mc_travel_dist: 2499.5650, mean_rewards: 160.8172, total_rewards: 1979.4470, mean_steps: 26.0700, mean_ecr: 0.0307 mean_entropies: 2.5675, took: 129.4672s
2022-10-10 00:07:51,244 [INFO] 	Process 7 - batch 9099: mean_policy_losses: -54.041, mean_net_lifetime: 3785.0370, mean_mc_travel_dist: 1837.9410, mean_rewards: 144.8908, total_rewards: 1992.6072, mean_steps: 25.3900, mean_ecr: 0.0434 mean_entropies: 2.3140, took: 1341.3394s
2022-10-10 00:08:18,134 [INFO] 	Process 4 - batch 11499: mean_policy_losses: -216.341, mean_net_lifetime: 2601.2708, mean_mc_travel_dist: 1197.4804, mean_rewards: 145.9476, total_rewards: 1417.8270, mean_steps: 16.9800, mean_ecr: 0.0532 mean_entropies: 2.0661, took: 87.2957s
2022-10-10 00:08:40,272 [INFO] 	Process 1 - batch 8699: mean_policy_losses: 73.632, mean_net_lifetime: 4620.8357, mean_mc_travel_dist: 2332.7660, mean_rewards: 124.6407, total_rewards: 2323.8542, mean_steps: 36.4600, mean_ecr: 0.0398 mean_entropies: 2.0141, took: 177.3399s
2022-10-10 00:08:52,193 [INFO] 	Process 3 - batch 9499: mean_policy_losses: 105.282, mean_net_lifetime: 3756.4294, mean_mc_travel_dist: 1653.9222, mean_rewards: 154.8371, total_rewards: 2129.0598, mean_steps: 23.4500, mean_ecr: 0.0477 mean_entropies: 1.9365, took: 116.2472s
2022-10-10 00:09:42,973 [INFO] 	Process 4 - batch 11599: mean_policy_losses: -182.388, mean_net_lifetime: 2618.4008, mean_mc_travel_dist: 1206.7712, mean_rewards: 150.6376, total_rewards: 1428.3469, mean_steps: 16.5800, mean_ecr: 0.0529 mean_entropies: 2.1010, took: 84.8385s
2022-10-10 00:09:45,216 [INFO] 	Process 2 - batch 9599: mean_policy_losses: 30.450, mean_net_lifetime: 3747.0458, mean_mc_travel_dist: 1824.1363, mean_rewards: 147.1005, total_rewards: 1951.1885, mean_steps: 24.5300, mean_ecr: 0.0415 mean_entropies: 2.0961, took: 118.6729s
2022-10-10 00:09:51,634 [INFO] 	Process 5 - batch 9599: mean_policy_losses: -38.447, mean_net_lifetime: 4306.3069, mean_mc_travel_dist: 2492.5136, mean_rewards: 160.0185, total_rewards: 1877.4223, mean_steps: 25.5500, mean_ecr: 0.0307 mean_entropies: 2.5911, took: 123.9295s
2022-10-10 00:09:54,497 [INFO] 	Process 7 - batch 9199: mean_policy_losses: -41.407, mean_net_lifetime: 3716.0705, mean_mc_travel_dist: 1851.3487, mean_rewards: 142.6030, total_rewards: 1910.0358, mean_steps: 25.3200, mean_ecr: 0.0433 mean_entropies: 2.3311, took: 123.2529s
2022-10-10 00:10:51,470 [INFO] 	Process 3 - batch 9599: mean_policy_losses: 168.657, mean_net_lifetime: 3836.3163, mean_mc_travel_dist: 1678.1908, mean_rewards: 159.1257, total_rewards: 2185.1469, mean_steps: 23.3300, mean_ecr: 0.0476 mean_entropies: 1.9567, took: 119.2782s
2022-10-10 00:11:12,169 [INFO] 	Process 4 - batch 11699: mean_policy_losses: -243.959, mean_net_lifetime: 2604.6976, mean_mc_travel_dist: 1235.9525, mean_rewards: 143.4295, total_rewards: 1392.3176, mean_steps: 17.3100, mean_ecr: 0.0531 mean_entropies: 2.1032, took: 89.1959s
2022-10-10 00:11:32,325 [INFO] 	Process 1 - batch 8799: mean_policy_losses: 126.833, mean_net_lifetime: 4628.9622, mean_mc_travel_dist: 2320.5473, mean_rewards: 129.2289, total_rewards: 2336.3806, mean_steps: 35.1500, mean_ecr: 0.0398 mean_entropies: 2.0612, took: 172.0527s
2022-10-10 00:11:45,503 [INFO] 	Process 2 - batch 9699: mean_policy_losses: -37.355, mean_net_lifetime: 3617.5425, mean_mc_travel_dist: 1770.0750, mean_rewards: 140.1360, total_rewards: 1875.0083, mean_steps: 24.8400, mean_ecr: 0.0416 mean_entropies: 2.0224, took: 120.2868s
2022-10-10 00:11:51,530 [INFO] 	Process 7 - batch 9299: mean_policy_losses: -142.633, mean_net_lifetime: 3530.0249, mean_mc_travel_dist: 1771.0716, mean_rewards: 141.8511, total_rewards: 1813.4569, mean_steps: 23.9400, mean_ecr: 0.0435 mean_entropies: 2.3444, took: 117.0327s
2022-10-10 00:12:08,759 [INFO] 	Process 5 - batch 9699: mean_policy_losses: 34.952, mean_net_lifetime: 4643.3209, mean_mc_travel_dist: 2615.6873, mean_rewards: 158.8425, total_rewards: 2090.0917, mean_steps: 27.7700, mean_ecr: 0.0304 mean_entropies: 2.5586, took: 137.1255s
2022-10-10 00:12:39,786 [INFO] 	Process 4 - batch 11799: mean_policy_losses: -192.103, mean_net_lifetime: 2675.6564, mean_mc_travel_dist: 1220.1754, mean_rewards: 148.9661, total_rewards: 1468.6683, mean_steps: 17.1400, mean_ecr: 0.0528 mean_entropies: 2.0915, took: 87.6173s
2022-10-10 00:12:55,732 [INFO] 	Process 3 - batch 9699: mean_policy_losses: 136.972, mean_net_lifetime: 3837.2759, mean_mc_travel_dist: 1660.3721, mean_rewards: 153.2231, total_rewards: 2194.4125, mean_steps: 24.3000, mean_ecr: 0.0477 mean_entropies: 1.9059, took: 124.2617s
2022-10-10 00:13:44,958 [INFO] 	Process 2 - batch 9799: mean_policy_losses: 23.798, mean_net_lifetime: 3750.1302, mean_mc_travel_dist: 1814.2894, mean_rewards: 147.8627, total_rewards: 1965.5528, mean_steps: 24.4900, mean_ecr: 0.0415 mean_entropies: 2.0556, took: 119.4550s
2022-10-10 00:13:59,749 [INFO] 	Process 7 - batch 9399: mean_policy_losses: -5.230, mean_net_lifetime: 3777.5207, mean_mc_travel_dist: 1803.1523, mean_rewards: 139.1527, total_rewards: 2020.3067, mean_steps: 26.5000, mean_ecr: 0.0436 mean_entropies: 2.3004, took: 128.2198s
2022-10-10 00:14:07,233 [INFO] 	Process 4 - batch 11899: mean_policy_losses: -222.909, mean_net_lifetime: 2609.5203, mean_mc_travel_dist: 1198.1322, mean_rewards: 146.2425, total_rewards: 1427.3778, mean_steps: 17.0000, mean_ecr: 0.0531 mean_entropies: 2.0599, took: 87.4466s
2022-10-10 00:14:26,790 [INFO] 	Process 5 - batch 9799: mean_policy_losses: 34.298, mean_net_lifetime: 4753.6968, mean_mc_travel_dist: 2697.5599, mean_rewards: 161.0359, total_rewards: 2108.3364, mean_steps: 28.0800, mean_ecr: 0.0303 mean_entropies: 2.5795, took: 138.0310s
2022-10-10 00:14:32,052 [INFO] 	Process 1 - batch 8899: mean_policy_losses: 95.875, mean_net_lifetime: 4740.0888, mean_mc_travel_dist: 2379.4451, mean_rewards: 123.8485, total_rewards: 2396.2634, mean_steps: 37.6000, mean_ecr: 0.0396 mean_entropies: 2.0021, took: 179.7272s
2022-10-10 00:14:51,365 [INFO] 	Process 3 - batch 9799: mean_policy_losses: 173.880, mean_net_lifetime: 3856.8346, mean_mc_travel_dist: 1664.8655, mean_rewards: 162.5981, total_rewards: 2211.0095, mean_steps: 23.0600, mean_ecr: 0.0476 mean_entropies: 1.9785, took: 115.6340s
2022-10-10 00:15:34,286 [INFO] 	Process 4 - batch 11999: mean_policy_losses: -206.465, mean_net_lifetime: 2617.1121, mean_mc_travel_dist: 1216.7234, mean_rewards: 146.2822, total_rewards: 1422.1345, mean_steps: 17.1500, mean_ecr: 0.0531 mean_entropies: 2.0769, took: 87.0534s
2022-10-10 00:15:40,671 [INFO] 	Process 2 - batch 9899: mean_policy_losses: 23.324, mean_net_lifetime: 3769.5666, mean_mc_travel_dist: 1827.7693, mean_rewards: 151.3000, total_rewards: 1968.4448, mean_steps: 23.9800, mean_ecr: 0.0415 mean_entropies: 2.0794, took: 115.7126s
2022-10-10 00:15:59,352 [INFO] 	Process 7 - batch 9499: mean_policy_losses: -75.612, mean_net_lifetime: 3669.0445, mean_mc_travel_dist: 1822.1840, mean_rewards: 141.8286, total_rewards: 1894.4740, mean_steps: 25.0100, mean_ecr: 0.0434 mean_entropies: 2.3251, took: 119.6027s
2022-10-10 00:16:34,669 [INFO] 	Process 5 - batch 9899: mean_policy_losses: -56.841, mean_net_lifetime: 4449.6162, mean_mc_travel_dist: 2564.4394, mean_rewards: 161.4357, total_rewards: 1944.0474, mean_steps: 26.3600, mean_ecr: 0.0305 mean_entropies: 2.5818, took: 127.8782s
2022-10-10 00:16:45,373 [INFO] 	Process 3 - batch 9899: mean_policy_losses: 121.731, mean_net_lifetime: 3849.4691, mean_mc_travel_dist: 1670.7227, mean_rewards: 162.3213, total_rewards: 2199.9802, mean_steps: 22.9200, mean_ecr: 0.0476 mean_entropies: 1.9654, took: 114.0067s
2022-10-10 00:17:35,325 [INFO] 	Process 1 - batch 8999: mean_policy_losses: 6.789, mean_net_lifetime: 4586.9186, mean_mc_travel_dist: 2335.1258, mean_rewards: 117.6043, total_rewards: 2274.9305, mean_steps: 38.4000, mean_ecr: 0.0397 mean_entropies: 1.9705, took: 183.2723s
2022-10-10 00:17:39,443 [INFO] 	Process 2 - batch 9999: mean_policy_losses: 1.445, mean_net_lifetime: 3971.8238, mean_mc_travel_dist: 1878.9338, mean_rewards: 150.8942, total_rewards: 2118.4412, mean_steps: 25.3400, mean_ecr: 0.0413 mean_entropies: 2.1405, took: 118.7723s
2022-10-10 00:17:53,735 [INFO] 	Process 7 - batch 9599: mean_policy_losses: -174.165, mean_net_lifetime: 3633.5780, mean_mc_travel_dist: 1779.5386, mean_rewards: 143.2883, total_rewards: 1888.7659, mean_steps: 24.6200, mean_ecr: 0.0435 mean_entropies: 2.3140, took: 114.3828s
2022-10-10 00:17:57,477 [INFO] Process 6 - epoch 10: mean_policy_losses: -332.641, mean_net_lifetime: 1824.8611, mean_mc_travel_dist: 1032.4486, mean_entropies: 1.8492, m_net_lifetime_valid: 2996.1824, took: 1949.2006s, (147.7077 / 100 batches)

2022-10-10 00:18:40,292 [INFO] 	Process 3 - batch 9999: mean_policy_losses: 213.984, mean_net_lifetime: 3976.6620, mean_mc_travel_dist: 1718.7137, mean_rewards: 163.9930, total_rewards: 2281.0438, mean_steps: 23.5000, mean_ecr: 0.0476 mean_entropies: 1.9938, took: 114.9198s
2022-10-10 00:18:41,440 [INFO] 	Process 5 - batch 9999: mean_policy_losses: -6.114, mean_net_lifetime: 4582.2424, mean_mc_travel_dist: 2650.6502, mean_rewards: 159.0714, total_rewards: 1993.9384, mean_steps: 27.5800, mean_ecr: 0.0305 mean_entropies: 2.5699, took: 126.7710s
2022-10-10 00:18:44,460 [INFO] 	Process 6 - batch 15099: mean_policy_losses: -708.136, mean_net_lifetime: 1508.4790, mean_mc_travel_dist: 933.0076, mean_rewards: 159.3530, total_rewards: 621.8645, mean_steps: 8.5000, mean_ecr: 0.0559 mean_entropies: 1.9254, took: 1225.3060s
2022-10-10 00:19:30,819 [INFO] 	Process 6 - batch 15199: mean_policy_losses: -664.559, mean_net_lifetime: 1660.0972, mean_mc_travel_dist: 973.1136, mean_rewards: 173.8123, total_rewards: 744.7362, mean_steps: 8.4600, mean_ecr: 0.0564 mean_entropies: 1.9412, took: 46.3588s
2022-10-10 00:19:36,185 [INFO] 	Process 2 - batch 10099: mean_policy_losses: 176.928, mean_net_lifetime: 3930.6461, mean_mc_travel_dist: 1897.3944, mean_rewards: 149.4257, total_rewards: 2064.9125, mean_steps: 25.4300, mean_ecr: 0.0413 mean_entropies: 2.1079, took: 116.7415s
2022-10-10 00:19:53,701 [INFO] 	Process 7 - batch 9699: mean_policy_losses: 136.026, mean_net_lifetime: 3782.0186, mean_mc_travel_dist: 1860.7181, mean_rewards: 141.9564, total_rewards: 1974.1722, mean_steps: 25.9800, mean_ecr: 0.0434 mean_entropies: 2.3077, took: 119.9661s
2022-10-10 00:20:20,860 [INFO] 	Process 6 - batch 15299: mean_policy_losses: -641.277, mean_net_lifetime: 1680.9456, mean_mc_travel_dist: 970.6406, mean_rewards: 166.7639, total_rewards: 750.9879, mean_steps: 9.1200, mean_ecr: 0.0564 mean_entropies: 1.8164, took: 50.0415s
2022-10-10 00:20:36,358 [INFO] 	Process 3 - batch 10099: mean_policy_losses: 267.954, mean_net_lifetime: 3877.7403, mean_mc_travel_dist: 1679.4917, mean_rewards: 154.8985, total_rewards: 2225.2833, mean_steps: 24.2400, mean_ecr: 0.0477 mean_entropies: 1.8652, took: 116.0658s
2022-10-10 00:20:53,951 [INFO] 	Process 5 - batch 10099: mean_policy_losses: 217.453, mean_net_lifetime: 4698.0575, mean_mc_travel_dist: 2624.2453, mean_rewards: 162.5109, total_rewards: 2128.6238, mean_steps: 27.7000, mean_ecr: 0.0308 mean_entropies: 2.5287, took: 132.5109s
2022-10-10 00:21:10,498 [INFO] 	Process 6 - batch 15399: mean_policy_losses: -605.493, mean_net_lifetime: 1741.5996, mean_mc_travel_dist: 981.8547, mean_rewards: 173.1553, total_rewards: 803.6859, mean_steps: 9.0100, mean_ecr: 0.0565 mean_entropies: 1.7794, took: 49.6377s
2022-10-10 00:21:35,715 [INFO] 	Process 2 - batch 10199: mean_policy_losses: 129.575, mean_net_lifetime: 3814.9317, mean_mc_travel_dist: 1821.3188, mean_rewards: 142.7601, total_rewards: 2014.5942, mean_steps: 25.7900, mean_ecr: 0.0415 mean_entropies: 1.9350, took: 119.5308s
2022-10-10 00:21:50,723 [INFO] 	Process 7 - batch 9799: mean_policy_losses: 62.245, mean_net_lifetime: 3694.9901, mean_mc_travel_dist: 1816.7982, mean_rewards: 141.1549, total_rewards: 1914.9829, mean_steps: 25.3500, mean_ecr: 0.0434 mean_entropies: 2.2676, took: 117.0223s
2022-10-10 00:22:00,137 [INFO] 	Process 6 - batch 15499: mean_policy_losses: -527.387, mean_net_lifetime: 1751.0724, mean_mc_travel_dist: 998.5353, mean_rewards: 171.8464, total_rewards: 802.3781, mean_steps: 9.2200, mean_ecr: 0.0567 mean_entropies: 1.7506, took: 49.6390s
2022-10-10 00:22:38,361 [INFO] 	Process 3 - batch 10199: mean_policy_losses: 232.846, mean_net_lifetime: 3833.4704, mean_mc_travel_dist: 1638.2758, mean_rewards: 148.0307, total_rewards: 2217.3226, mean_steps: 25.1700, mean_ecr: 0.0480 mean_entropies: 1.7282, took: 122.0021s
2022-10-10 00:22:50,089 [INFO] 	Process 6 - batch 15599: mean_policy_losses: -596.216, mean_net_lifetime: 1701.0478, mean_mc_travel_dist: 970.6671, mean_rewards: 165.7735, total_rewards: 780.7366, mean_steps: 9.2600, mean_ecr: 0.0563 mean_entropies: 1.6677, took: 49.9514s
2022-10-10 00:23:07,438 [INFO] 	Process 5 - batch 10199: mean_policy_losses: 309.468, mean_net_lifetime: 4950.7931, mean_mc_travel_dist: 2717.1769, mean_rewards: 167.7474, total_rewards: 2297.4535, mean_steps: 28.3900, mean_ecr: 0.0306 mean_entropies: 2.4540, took: 133.4872s
2022-10-10 00:23:40,242 [INFO] 	Process 2 - batch 10299: mean_policy_losses: 71.484, mean_net_lifetime: 3739.5130, mean_mc_travel_dist: 1852.0389, mean_rewards: 134.9860, total_rewards: 1916.6652, mean_steps: 26.7800, mean_ecr: 0.0414 mean_entropies: 1.8263, took: 124.5268s
2022-10-10 00:23:41,919 [INFO] 	Process 6 - batch 15699: mean_policy_losses: -437.835, mean_net_lifetime: 1842.0229, mean_mc_travel_dist: 1005.2688, mean_rewards: 174.8006, total_rewards: 878.4857, mean_steps: 9.5700, mean_ecr: 0.0566 mean_entropies: 1.6239, took: 51.8313s
2022-10-10 00:23:57,129 [INFO] 	Process 7 - batch 9899: mean_policy_losses: 100.272, mean_net_lifetime: 3905.2526, mean_mc_travel_dist: 1899.7543, mean_rewards: 138.4970, total_rewards: 2046.1425, mean_steps: 27.2400, mean_ecr: 0.0433 mean_entropies: 2.2189, took: 126.4050s
2022-10-10 00:24:36,346 [INFO] 	Process 6 - batch 15799: mean_policy_losses: -404.239, mean_net_lifetime: 2033.6923, mean_mc_travel_dist: 1051.6724, mean_rewards: 178.1419, total_rewards: 1022.7811, mean_steps: 10.2500, mean_ecr: 0.0567 mean_entropies: 1.5828, took: 54.4268s
2022-10-10 00:24:45,027 [INFO] 	Process 3 - batch 10299: mean_policy_losses: 120.172, mean_net_lifetime: 3735.1422, mean_mc_travel_dist: 1664.0130, mean_rewards: 138.3927, total_rewards: 2090.8249, mean_steps: 26.3400, mean_ecr: 0.0480 mean_entropies: 1.6218, took: 126.6672s
2022-10-10 00:25:23,379 [INFO] 	Process 5 - batch 10299: mean_policy_losses: 291.476, mean_net_lifetime: 5074.1361, mean_mc_travel_dist: 2758.4469, mean_rewards: 169.4856, total_rewards: 2359.9351, mean_steps: 28.7700, mean_ecr: 0.0306 mean_entropies: 2.4072, took: 135.9414s
2022-10-10 00:25:30,223 [INFO] 	Process 6 - batch 15899: mean_policy_losses: -458.108, mean_net_lifetime: 2017.3120, mean_mc_travel_dist: 1064.6813, mean_rewards: 177.5148, total_rewards: 1005.1480, mean_steps: 10.3400, mean_ecr: 0.0567 mean_entropies: 1.6041, took: 53.8764s
2022-10-10 00:25:45,467 [INFO] 	Process 2 - batch 10399: mean_policy_losses: 61.338, mean_net_lifetime: 3718.2333, mean_mc_travel_dist: 1786.7467, mean_rewards: 133.0763, total_rewards: 1952.9551, mean_steps: 27.0000, mean_ecr: 0.0415 mean_entropies: 1.6914, took: 125.2254s
2022-10-10 00:25:58,191 [INFO] 	Process 7 - batch 9999: mean_policy_losses: 116.062, mean_net_lifetime: 3973.6883, mean_mc_travel_dist: 1938.3418, mean_rewards: 145.3624, total_rewards: 2078.8389, mean_steps: 26.4800, mean_ecr: 0.0432 mean_entropies: 2.2378, took: 121.0624s
2022-10-10 00:26:24,444 [INFO] 	Process 6 - batch 15999: mean_policy_losses: -418.772, mean_net_lifetime: 2022.9019, mean_mc_travel_dist: 1056.9798, mean_rewards: 181.4273, total_rewards: 997.3529, mean_steps: 10.0800, mean_ecr: 0.0566 mean_entropies: 1.5687, took: 54.2214s
2022-10-10 00:26:46,602 [INFO] 	Process 3 - batch 10399: mean_policy_losses: 108.144, mean_net_lifetime: 3664.3153, mean_mc_travel_dist: 1635.8073, mean_rewards: 139.7198, total_rewards: 2049.9221, mean_steps: 25.5400, mean_ecr: 0.0481 mean_entropies: 1.5595, took: 121.5748s
2022-10-10 00:27:19,377 [INFO] 	Process 6 - batch 16099: mean_policy_losses: -496.728, mean_net_lifetime: 1855.3088, mean_mc_travel_dist: 995.3846, mean_rewards: 165.6551, total_rewards: 886.1680, mean_steps: 10.2500, mean_ecr: 0.0566 mean_entropies: 1.5305, took: 54.9321s
2022-10-10 00:27:36,557 [INFO] 	Process 5 - batch 10399: mean_policy_losses: 264.476, mean_net_lifetime: 5011.7764, mean_mc_travel_dist: 2752.5662, mean_rewards: 169.9050, total_rewards: 2313.1549, mean_steps: 28.2500, mean_ecr: 0.0307 mean_entropies: 2.3664, took: 133.1771s
2022-10-10 00:27:48,379 [INFO] 	Process 2 - batch 10499: mean_policy_losses: 72.493, mean_net_lifetime: 3814.8930, mean_mc_travel_dist: 1815.2402, mean_rewards: 138.0246, total_rewards: 2020.1217, mean_steps: 26.6800, mean_ecr: 0.0415 mean_entropies: 1.7066, took: 122.9119s
2022-10-10 00:28:02,104 [INFO] 	Process 7 - batch 10099: mean_policy_losses: 120.954, mean_net_lifetime: 4041.2165, mean_mc_travel_dist: 1911.8642, mean_rewards: 145.6646, total_rewards: 2166.8764, mean_steps: 27.1400, mean_ecr: 0.0432 mean_entropies: 2.1969, took: 123.9117s
2022-10-10 00:28:10,742 [INFO] 	Process 6 - batch 16199: mean_policy_losses: -538.936, mean_net_lifetime: 1806.3961, mean_mc_travel_dist: 985.4097, mean_rewards: 171.7485, total_rewards: 853.0374, mean_steps: 9.4800, mean_ecr: 0.0566 mean_entropies: 1.5736, took: 51.3660s
2022-10-10 00:28:46,242 [INFO] 	Process 3 - batch 10499: mean_policy_losses: 131.016, mean_net_lifetime: 3811.6739, mean_mc_travel_dist: 1674.6596, mean_rewards: 144.8093, total_rewards: 2152.8817, mean_steps: 25.5500, mean_ecr: 0.0478 mean_entropies: 1.6009, took: 119.6402s
2022-10-10 00:29:03,097 [INFO] 	Process 6 - batch 16299: mean_policy_losses: -412.396, mean_net_lifetime: 2026.5341, mean_mc_travel_dist: 1043.5860, mean_rewards: 183.3448, total_rewards: 1014.1842, mean_steps: 10.1500, mean_ecr: 0.0568 mean_entropies: 1.5267, took: 52.3552s
2022-10-10 00:29:43,990 [INFO] 	Process 5 - batch 10499: mean_policy_losses: 289.135, mean_net_lifetime: 4935.6086, mean_mc_travel_dist: 2710.0504, mean_rewards: 168.7787, total_rewards: 2277.0262, mean_steps: 28.1200, mean_ecr: 0.0308 mean_entropies: 2.3445, took: 127.4334s
2022-10-10 00:29:50,945 [INFO] 	Process 6 - batch 16399: mean_policy_losses: -319.486, mean_net_lifetime: 1969.4832, mean_mc_travel_dist: 1050.6300, mean_rewards: 179.2639, total_rewards: 966.6627, mean_steps: 9.8200, mean_ecr: 0.0569 mean_entropies: 1.5015, took: 47.8479s
2022-10-10 00:29:51,395 [INFO] 	Process 7 - batch 10199: mean_policy_losses: 168.653, mean_net_lifetime: 3873.5888, mean_mc_travel_dist: 1898.7182, mean_rewards: 148.7429, total_rewards: 2036.5838, mean_steps: 25.0200, mean_ecr: 0.0432 mean_entropies: 2.2265, took: 109.2930s
2022-10-10 00:30:47,145 [INFO] 	Process 6 - batch 16499: mean_policy_losses: -127.415, mean_net_lifetime: 2383.4357, mean_mc_travel_dist: 1139.4645, mean_rewards: 185.4469, total_rewards: 1282.7731, mean_steps: 11.8100, mean_ecr: 0.0566 mean_entropies: 1.2866, took: 56.1998s
2022-10-10 00:31:35,327 [INFO] 	Process 7 - batch 10299: mean_policy_losses: 184.599, mean_net_lifetime: 4008.4571, mean_mc_travel_dist: 1986.7271, mean_rewards: 152.0878, total_rewards: 2070.2669, mean_steps: 25.4100, mean_ecr: 0.0430 mean_entropies: 2.1727, took: 103.9306s
2022-10-10 00:33:22,046 [INFO] 	Process 7 - batch 10399: mean_policy_losses: -16.722, mean_net_lifetime: 4145.0679, mean_mc_travel_dist: 2013.0039, mean_rewards: 146.5918, total_rewards: 2172.6871, mean_steps: 27.2800, mean_ecr: 0.0429 mean_entropies: 2.1307, took: 106.7199s
2022-10-10 00:35:00,758 [INFO] Process 4 - epoch 8: mean_policy_losses: -49.909, mean_net_lifetime: 2556.5485, mean_mc_travel_dist: 1218.2478, mean_entropies: 2.0050, m_net_lifetime_valid: 3039.9970, took: 2477.7926s, (192.8873 / 100 batches)

2022-10-10 00:35:07,611 [INFO] 	Process 7 - batch 10499: mean_policy_losses: -38.855, mean_net_lifetime: 4115.2949, mean_mc_travel_dist: 2033.4980, mean_rewards: 147.9921, total_rewards: 2128.3286, mean_steps: 26.9100, mean_ecr: 0.0429 mean_entropies: 2.1322, took: 105.5656s
2022-10-10 00:36:24,284 [INFO] 	Process 4 - batch 12099: mean_policy_losses: 44.386, mean_net_lifetime: 2780.2593, mean_mc_travel_dist: 1227.5648, mean_rewards: 134.2515, total_rewards: 1567.0574, mean_steps: 19.9500, mean_ecr: 0.0527 mean_entropies: 1.7340, took: 1249.9983s
2022-10-10 00:36:55,017 [INFO] Process 1 - epoch 6: mean_policy_losses: 241.558, mean_net_lifetime: 4563.9704, mean_mc_travel_dist: 2374.1260, mean_entropies: 2.1639, m_net_lifetime_valid: 3074.3213, took: 3508.9340s, (257.8080 / 100 batches)

2022-10-10 00:37:40,164 [INFO] 	Process 4 - batch 12199: mean_policy_losses: 92.464, mean_net_lifetime: 3159.4022, mean_mc_travel_dist: 1327.9466, mean_rewards: 170.3443, total_rewards: 1849.6156, mean_steps: 17.6900, mean_ecr: 0.0520 mean_entropies: 1.9787, took: 75.8796s
2022-10-10 00:38:49,388 [INFO] 	Process 1 - batch 9099: mean_policy_losses: 55.539, mean_net_lifetime: 4719.5281, mean_mc_travel_dist: 2604.4330, mean_rewards: 161.3503, total_rewards: 2154.9625, mean_steps: 28.3100, mean_ecr: 0.0395 mean_entropies: 1.9831, took: 1274.0636s
2022-10-10 00:38:54,270 [INFO] 	Process 4 - batch 12299: mean_policy_losses: 39.631, mean_net_lifetime: 3479.5731, mean_mc_travel_dist: 1414.1783, mean_rewards: 193.2715, total_rewards: 2085.3675, mean_steps: 16.9300, mean_ecr: 0.0508 mean_entropies: 2.1266, took: 74.1067s
2022-10-10 00:40:08,010 [INFO] 	Process 4 - batch 12399: mean_policy_losses: 59.614, mean_net_lifetime: 3311.0183, mean_mc_travel_dist: 1387.4365, mean_rewards: 188.6258, total_rewards: 1946.0563, mean_steps: 16.4500, mean_ecr: 0.0513 mean_entropies: 2.0801, took: 73.7399s
2022-10-10 00:40:42,973 [INFO] 	Process 1 - batch 9199: mean_policy_losses: 11.019, mean_net_lifetime: 4569.6087, mean_mc_travel_dist: 2606.4632, mean_rewards: 159.4851, total_rewards: 2003.2844, mean_steps: 27.7400, mean_ecr: 0.0395 mean_entropies: 1.9488, took: 113.5854s
2022-10-10 00:41:23,983 [INFO] 	Process 4 - batch 12499: mean_policy_losses: 215.380, mean_net_lifetime: 3672.5830, mean_mc_travel_dist: 1449.8083, mean_rewards: 201.3228, total_rewards: 2247.9909, mean_steps: 17.1600, mean_ecr: 0.0508 mean_entropies: 2.0962, took: 75.9729s
2022-10-10 00:42:37,895 [INFO] 	Process 4 - batch 12599: mean_policy_losses: 98.037, mean_net_lifetime: 3490.0784, mean_mc_travel_dist: 1429.0980, mean_rewards: 198.0969, total_rewards: 2075.7891, mean_steps: 16.5500, mean_ecr: 0.0510 mean_entropies: 2.0948, took: 73.9123s
2022-10-10 00:42:39,121 [INFO] 	Process 1 - batch 9299: mean_policy_losses: 8.021, mean_net_lifetime: 4582.7981, mean_mc_travel_dist: 2606.2854, mean_rewards: 159.7675, total_rewards: 2012.5360, mean_steps: 27.7900, mean_ecr: 0.0396 mean_entropies: 1.9513, took: 116.1477s
2022-10-10 00:43:52,410 [INFO] 	Process 4 - batch 12699: mean_policy_losses: 111.060, mean_net_lifetime: 3545.7436, mean_mc_travel_dist: 1466.9603, mean_rewards: 198.3362, total_rewards: 2097.7971, mean_steps: 16.8400, mean_ecr: 0.0509 mean_entropies: 2.0647, took: 74.5150s
2022-10-10 00:44:38,421 [INFO] 	Process 1 - batch 9399: mean_policy_losses: -18.520, mean_net_lifetime: 4644.0010, mean_mc_travel_dist: 2661.3176, mean_rewards: 158.5218, total_rewards: 2015.7674, mean_steps: 28.4200, mean_ecr: 0.0395 mean_entropies: 1.9023, took: 119.2994s
2022-10-10 00:45:11,643 [INFO] 	Process 4 - batch 12799: mean_policy_losses: 216.815, mean_net_lifetime: 3897.6973, mean_mc_travel_dist: 1546.8571, mean_rewards: 203.6034, total_rewards: 2375.9383, mean_steps: 18.1600, mean_ecr: 0.0500 mean_entropies: 2.0420, took: 79.2328s
2022-10-10 00:45:54,725 [INFO] Process 2 - epoch 7: mean_policy_losses: -8.858, mean_net_lifetime: 3309.3965, mean_mc_travel_dist: 1713.7122, mean_entropies: 1.9930, m_net_lifetime_valid: 3123.9736, took: 2882.5582s, (227.1101 / 100 batches)

2022-10-10 00:46:27,364 [INFO] 	Process 4 - batch 12899: mean_policy_losses: 145.185, mean_net_lifetime: 3590.2795, mean_mc_travel_dist: 1454.9940, mean_rewards: 201.3837, total_rewards: 2155.4799, mean_steps: 16.8500, mean_ecr: 0.0506 mean_entropies: 2.0413, took: 75.7202s
2022-10-10 00:46:35,103 [INFO] 	Process 1 - batch 9499: mean_policy_losses: 3.388, mean_net_lifetime: 4590.5181, mean_mc_travel_dist: 2606.0022, mean_rewards: 155.6813, total_rewards: 2025.8490, mean_steps: 28.5800, mean_ecr: 0.0395 mean_entropies: 1.8879, took: 116.6827s
2022-10-10 00:46:49,980 [INFO] Process 3 - epoch 7: mean_policy_losses: 196.374, mean_net_lifetime: 3675.0769, mean_mc_travel_dist: 1659.2548, mean_entropies: 1.9255, m_net_lifetime_valid: 3106.2921, took: 2870.5111s, (227.6487 / 100 batches)

2022-10-10 00:47:31,101 [INFO] Process 5 - epoch 7: mean_policy_losses: 12.275, mean_net_lifetime: 3948.8540, mean_mc_travel_dist: 2326.4175, mean_entropies: 2.5298, m_net_lifetime_valid: 3066.2671, took: 2990.8678s, (228.1997 / 100 batches)

2022-10-10 00:47:48,680 [INFO] 	Process 4 - batch 12999: mean_policy_losses: 300.434, mean_net_lifetime: 3572.9545, mean_mc_travel_dist: 1434.3192, mean_rewards: 198.0057, total_rewards: 2158.1024, mean_steps: 16.9600, mean_ecr: 0.0507 mean_entropies: 2.1064, took: 81.3164s
2022-10-10 00:48:12,938 [INFO] 	Process 2 - batch 10599: mean_policy_losses: -156.824, mean_net_lifetime: 2904.2433, mean_mc_travel_dist: 1623.8231, mean_rewards: 90.1943, total_rewards: 1302.5756, mean_steps: 31.3300, mean_ecr: 0.0426 mean_entropies: 0.9460, took: 1224.5582s
2022-10-10 00:48:17,435 [INFO] Process 6 - epoch 11: mean_policy_losses: -346.989, mean_net_lifetime: 1828.6636, mean_mc_travel_dist: 1030.8375, mean_entropies: 1.8307, m_net_lifetime_valid: 3065.1211, took: 1819.9560s, (146.0956 / 100 batches)

2022-10-10 00:48:47,191 [INFO] 	Process 1 - batch 9599: mean_policy_losses: 270.353, mean_net_lifetime: 4672.1030, mean_mc_travel_dist: 2526.0214, mean_rewards: 156.7570, total_rewards: 2176.9326, mean_steps: 29.0300, mean_ecr: 0.0394 mean_entropies: 1.9708, took: 132.0883s
2022-10-10 00:48:49,505 [INFO] 	Process 3 - batch 10599: mean_policy_losses: 38.465, mean_net_lifetime: 3317.9116, mean_mc_travel_dist: 1676.3526, mean_rewards: 130.2646, total_rewards: 1665.4439, mean_steps: 24.6100, mean_ecr: 0.0481 mean_entropies: 1.2045, took: 1203.2626s
2022-10-10 00:49:14,757 [INFO] 	Process 4 - batch 13099: mean_policy_losses: 356.712, mean_net_lifetime: 3096.3113, mean_mc_travel_dist: 1315.6045, mean_rewards: 173.0173, total_rewards: 1800.7921, mean_steps: 16.9800, mean_ecr: 0.0521 mean_entropies: 2.0597, took: 86.0769s
2022-10-10 00:49:18,534 [INFO] 	Process 6 - batch 16599: mean_policy_losses: -225.200, mean_net_lifetime: 1700.5251, mean_mc_travel_dist: 947.9921, mean_rewards: 136.8847, total_rewards: 807.8128, mean_steps: 11.1700, mean_ecr: 0.0564 mean_entropies: 1.1730, took: 1111.3886s
2022-10-10 00:49:41,482 [INFO] 	Process 5 - batch 10599: mean_policy_losses: -184.471, mean_net_lifetime: 2885.7663, mean_mc_travel_dist: 1845.5973, mean_rewards: 101.7104, total_rewards: 1089.2517, mean_steps: 26.7600, mean_ecr: 0.0306 mean_entropies: 1.7210, took: 1197.4932s
2022-10-10 00:50:15,620 [INFO] 	Process 6 - batch 16699: mean_policy_losses: -224.757, mean_net_lifetime: 2112.5712, mean_mc_travel_dist: 1074.8659, mean_rewards: 185.2717, total_rewards: 1092.5620, mean_steps: 10.1000, mean_ecr: 0.0568 mean_entropies: 1.4085, took: 57.0860s
2022-10-10 00:50:28,225 [INFO] 	Process 2 - batch 10699: mean_policy_losses: -9.236, mean_net_lifetime: 3043.3842, mean_mc_travel_dist: 1604.0914, mean_rewards: 104.2713, total_rewards: 1463.5797, mean_steps: 28.4800, mean_ecr: 0.0423 mean_entropies: 1.2303, took: 135.2871s
2022-10-10 00:50:46,655 [INFO] 	Process 4 - batch 13199: mean_policy_losses: 62.833, mean_net_lifetime: 2690.9024, mean_mc_travel_dist: 1175.6858, mean_rewards: 141.7199, total_rewards: 1524.2867, mean_steps: 18.2000, mean_ecr: 0.0530 mean_entropies: 1.8346, took: 91.8981s
2022-10-10 00:50:57,484 [INFO] 	Process 3 - batch 10699: mean_policy_losses: 143.647, mean_net_lifetime: 3487.5171, mean_mc_travel_dist: 1627.7929, mean_rewards: 132.5621, total_rewards: 1877.7474, mean_steps: 25.6400, mean_ecr: 0.0482 mean_entropies: 1.3687, took: 127.9789s
2022-10-10 00:51:11,151 [INFO] 	Process 6 - batch 16799: mean_policy_losses: -279.001, mean_net_lifetime: 2148.6749, mean_mc_travel_dist: 1084.9921, mean_rewards: 192.3354, total_rewards: 1106.3212, mean_steps: 10.1500, mean_ecr: 0.0568 mean_entropies: 1.4589, took: 55.5314s
2022-10-10 00:52:05,353 [INFO] 	Process 5 - batch 10699: mean_policy_losses: 124.754, mean_net_lifetime: 4695.9631, mean_mc_travel_dist: 2758.5740, mean_rewards: 148.3249, total_rewards: 1994.8024, mean_steps: 29.9200, mean_ecr: 0.0294 mean_entropies: 2.1211, took: 143.8693s
2022-10-10 00:52:08,229 [INFO] 	Process 6 - batch 16899: mean_policy_losses: -217.524, mean_net_lifetime: 2254.5568, mean_mc_travel_dist: 1104.4112, mean_rewards: 194.3309, total_rewards: 1186.0761, mean_steps: 10.4200, mean_ecr: 0.0567 mean_entropies: 1.4625, took: 57.0782s
2022-10-10 00:52:09,486 [INFO] 	Process 1 - batch 9699: mean_policy_losses: 123.482, mean_net_lifetime: 4534.4531, mean_mc_travel_dist: 2407.6179, mean_rewards: 106.2046, total_rewards: 2158.4719, mean_steps: 42.4300, mean_ecr: 0.0396 mean_entropies: 1.5672, took: 202.2953s
2022-10-10 00:52:18,462 [INFO] 	Process 4 - batch 13299: mean_policy_losses: -1.358, mean_net_lifetime: 2685.1000, mean_mc_travel_dist: 1175.6455, mean_rewards: 141.5761, total_rewards: 1520.3143, mean_steps: 18.1500, mean_ecr: 0.0532 mean_entropies: 1.8506, took: 91.8066s
2022-10-10 00:52:39,677 [INFO] 	Process 2 - batch 10799: mean_policy_losses: 20.684, mean_net_lifetime: 3348.7594, mean_mc_travel_dist: 1678.0515, mean_rewards: 117.3627, total_rewards: 1692.6159, mean_steps: 27.5900, mean_ecr: 0.0419 mean_entropies: 1.4544, took: 131.4524s
2022-10-10 00:53:01,633 [INFO] 	Process 6 - batch 16999: mean_policy_losses: -255.581, mean_net_lifetime: 2100.8216, mean_mc_travel_dist: 1072.9152, mean_rewards: 193.8815, total_rewards: 1067.7024, mean_steps: 9.7600, mean_ecr: 0.0566 mean_entropies: 1.5138, took: 53.4036s
2022-10-10 00:53:09,404 [INFO] 	Process 3 - batch 10799: mean_policy_losses: 183.097, mean_net_lifetime: 3671.1311, mean_mc_travel_dist: 1633.3228, mean_rewards: 138.0470, total_rewards: 2054.6693, mean_steps: 25.8900, mean_ecr: 0.0480 mean_entropies: 1.4740, took: 131.9193s
2022-10-10 00:53:48,569 [INFO] 	Process 4 - batch 13399: mean_policy_losses: 12.976, mean_net_lifetime: 2667.1876, mean_mc_travel_dist: 1187.1024, mean_rewards: 145.5223, total_rewards: 1494.7781, mean_steps: 17.6000, mean_ecr: 0.0530 mean_entropies: 1.9009, took: 90.1070s
2022-10-10 00:53:58,915 [INFO] 	Process 6 - batch 17099: mean_policy_losses: -245.725, mean_net_lifetime: 2185.4601, mean_mc_travel_dist: 1100.6568, mean_rewards: 187.2890, total_rewards: 1128.7531, mean_steps: 10.5200, mean_ecr: 0.0569 mean_entropies: 1.4646, took: 57.2825s
2022-10-10 00:54:18,083 [INFO] Process 7 - epoch 7: mean_policy_losses: 62.193, mean_net_lifetime: 3657.5516, mean_mc_travel_dist: 1813.2483, mean_entropies: 2.2923, m_net_lifetime_valid: 3121.0164, took: 2908.8695s, (231.2523 / 100 batches)

2022-10-10 00:54:27,206 [INFO] 	Process 5 - batch 10799: mean_policy_losses: 80.539, mean_net_lifetime: 4470.8481, mean_mc_travel_dist: 2649.3697, mean_rewards: 145.8930, total_rewards: 1888.0343, mean_steps: 29.2900, mean_ecr: 0.0296 mean_entropies: 2.1748, took: 141.8541s
2022-10-10 00:54:49,302 [INFO] 	Process 2 - batch 10899: mean_policy_losses: -6.777, mean_net_lifetime: 3283.3022, mean_mc_travel_dist: 1663.8571, mean_rewards: 117.6858, total_rewards: 1644.7260, mean_steps: 26.9600, mean_ecr: 0.0419 mean_entropies: 1.4993, took: 129.6247s
2022-10-10 00:54:56,071 [INFO] 	Process 6 - batch 17199: mean_policy_losses: -321.418, mean_net_lifetime: 2098.4106, mean_mc_travel_dist: 1066.1171, mean_rewards: 182.6642, total_rewards: 1082.0361, mean_steps: 10.2200, mean_ecr: 0.0566 mean_entropies: 1.5287, took: 57.1558s
2022-10-10 00:55:20,103 [INFO] 	Process 3 - batch 10899: mean_policy_losses: 169.444, mean_net_lifetime: 3655.2281, mean_mc_travel_dist: 1618.5650, mean_rewards: 137.7619, total_rewards: 2051.2280, mean_steps: 25.9600, mean_ecr: 0.0483 mean_entropies: 1.4955, took: 130.7000s
2022-10-10 00:55:21,658 [INFO] 	Process 4 - batch 13499: mean_policy_losses: 54.484, mean_net_lifetime: 2848.0989, mean_mc_travel_dist: 1240.2275, mean_rewards: 149.5319, total_rewards: 1623.6415, mean_steps: 18.1500, mean_ecr: 0.0526 mean_entropies: 1.9949, took: 93.0897s
2022-10-10 00:55:29,686 [INFO] 	Process 1 - batch 9799: mean_policy_losses: 115.528, mean_net_lifetime: 4530.3684, mean_mc_travel_dist: 2354.8957, mean_rewards: 108.7110, total_rewards: 2204.8114, mean_steps: 41.2400, mean_ecr: 0.0397 mean_entropies: 1.6574, took: 200.2000s
2022-10-10 00:55:53,222 [INFO] 	Process 6 - batch 17299: mean_policy_losses: -340.193, mean_net_lifetime: 2049.1941, mean_mc_travel_dist: 1057.9872, mean_rewards: 182.8278, total_rewards: 1026.9515, mean_steps: 10.1500, mean_ecr: 0.0569 mean_entropies: 1.5197, took: 57.1510s
2022-10-10 00:56:18,643 [INFO] 	Process 7 - batch 10599: mean_policy_losses: 77.830, mean_net_lifetime: 3776.7619, mean_mc_travel_dist: 1879.0227, mean_rewards: 146.9349, total_rewards: 1936.8360, mean_steps: 24.7900, mean_ecr: 0.0432 mean_entropies: 2.2567, took: 1271.0304s
2022-10-10 00:56:49,731 [INFO] 	Process 6 - batch 17399: mean_policy_losses: -391.573, mean_net_lifetime: 1998.0308, mean_mc_travel_dist: 1036.1040, mean_rewards: 179.0435, total_rewards: 1002.8186, mean_steps: 10.0400, mean_ecr: 0.0567 mean_entropies: 1.5463, took: 56.5094s
2022-10-10 00:56:54,996 [INFO] 	Process 5 - batch 10899: mean_policy_losses: 177.361, mean_net_lifetime: 4945.4623, mean_mc_travel_dist: 2811.9218, mean_rewards: 159.1009, total_rewards: 2200.2574, mean_steps: 29.8300, mean_ecr: 0.0298 mean_entropies: 2.2943, took: 147.7887s
2022-10-10 00:56:57,675 [INFO] 	Process 2 - batch 10999: mean_policy_losses: 67.887, mean_net_lifetime: 3692.1444, mean_mc_travel_dist: 1799.0927, mean_rewards: 134.2684, total_rewards: 1920.1640, mean_steps: 26.5400, mean_ecr: 0.0415 mean_entropies: 1.6977, took: 128.3732s
2022-10-10 00:57:27,328 [INFO] 	Process 3 - batch 10999: mean_policy_losses: 183.691, mean_net_lifetime: 3829.9058, mean_mc_travel_dist: 1667.1190, mean_rewards: 147.2943, total_rewards: 2180.0374, mean_steps: 25.3200, mean_ecr: 0.0480 mean_entropies: 1.5972, took: 127.2251s
2022-10-10 00:57:45,936 [INFO] 	Process 6 - batch 17499: mean_policy_losses: -407.388, mean_net_lifetime: 1948.6317, mean_mc_travel_dist: 1034.4926, mean_rewards: 175.4244, total_rewards: 959.1273, mean_steps: 10.0900, mean_ecr: 0.0569 mean_entropies: 1.5288, took: 56.2027s
2022-10-10 00:58:24,899 [INFO] 	Process 7 - batch 10699: mean_policy_losses: 70.461, mean_net_lifetime: 3994.8779, mean_mc_travel_dist: 1942.5135, mean_rewards: 146.1030, total_rewards: 2106.9956, mean_steps: 26.4800, mean_ecr: 0.0431 mean_entropies: 2.2496, took: 126.2565s
2022-10-10 00:58:37,615 [INFO] 	Process 6 - batch 17599: mean_policy_losses: -626.877, mean_net_lifetime: 1761.7778, mean_mc_travel_dist: 999.1180, mean_rewards: 172.8262, total_rewards: 820.5568, mean_steps: 9.1500, mean_ecr: 0.0564 mean_entropies: 1.6876, took: 51.6799s
2022-10-10 00:58:49,648 [INFO] 	Process 1 - batch 9899: mean_policy_losses: 17.942, mean_net_lifetime: 4542.4237, mean_mc_travel_dist: 2354.3870, mean_rewards: 105.6459, total_rewards: 2208.1134, mean_steps: 42.3500, mean_ecr: 0.0397 mean_entropies: 1.6642, took: 199.9609s
2022-10-10 00:59:08,384 [INFO] 	Process 2 - batch 11099: mean_policy_losses: 164.654, mean_net_lifetime: 4196.1548, mean_mc_travel_dist: 1989.0791, mean_rewards: 147.7688, total_rewards: 2227.9613, mean_steps: 27.4800, mean_ecr: 0.0409 mean_entropies: 1.8577, took: 130.7091s
2022-10-10 00:59:17,867 [INFO] 	Process 5 - batch 10999: mean_policy_losses: 241.890, mean_net_lifetime: 5151.1946, mean_mc_travel_dist: 2841.6379, mean_rewards: 168.5281, total_rewards: 2360.7616, mean_steps: 29.5000, mean_ecr: 0.0306 mean_entropies: 2.3812, took: 142.8722s
2022-10-10 00:59:30,113 [INFO] 	Process 3 - batch 11099: mean_policy_losses: 157.994, mean_net_lifetime: 3830.1925, mean_mc_travel_dist: 1683.3218, mean_rewards: 154.6419, total_rewards: 2165.3280, mean_steps: 24.0500, mean_ecr: 0.0479 mean_entropies: 1.6909, took: 122.7835s
2022-10-10 00:59:33,848 [INFO] 	Process 6 - batch 17699: mean_policy_losses: -470.609, mean_net_lifetime: 1997.1829, mean_mc_travel_dist: 1050.6935, mean_rewards: 177.6246, total_rewards: 998.5387, mean_steps: 10.1700, mean_ecr: 0.0566 mean_entropies: 1.6145, took: 56.2340s
2022-10-10 01:00:18,293 [INFO] 	Process 7 - batch 10799: mean_policy_losses: 3.461, mean_net_lifetime: 3821.6967, mean_mc_travel_dist: 1909.0149, mean_rewards: 155.7481, total_rewards: 1950.9040, mean_steps: 23.6000, mean_ecr: 0.0431 mean_entropies: 2.2962, took: 113.3953s
2022-10-10 01:00:28,897 [INFO] 	Process 6 - batch 17799: mean_policy_losses: -474.246, mean_net_lifetime: 1907.9074, mean_mc_travel_dist: 1023.8724, mean_rewards: 175.2327, total_rewards: 926.5921, mean_steps: 10.0300, mean_ecr: 0.0568 mean_entropies: 1.5711, took: 55.0489s
2022-10-10 01:01:21,019 [INFO] 	Process 2 - batch 11199: mean_policy_losses: 235.839, mean_net_lifetime: 4423.0403, mean_mc_travel_dist: 2051.7213, mean_rewards: 155.4503, total_rewards: 2398.4369, mean_steps: 27.4900, mean_ecr: 0.0408 mean_entropies: 1.9346, took: 132.6345s
2022-10-10 01:01:24,127 [INFO] 	Process 6 - batch 17899: mean_policy_losses: -540.736, mean_net_lifetime: 1857.2075, mean_mc_travel_dist: 1011.5823, mean_rewards: 174.8031, total_rewards: 886.5863, mean_steps: 9.7400, mean_ecr: 0.0565 mean_entropies: 1.6493, took: 55.2294s
2022-10-10 01:01:30,506 [INFO] 	Process 3 - batch 11199: mean_policy_losses: 163.811, mean_net_lifetime: 3827.7900, mean_mc_travel_dist: 1681.1976, mean_rewards: 153.3189, total_rewards: 2174.4307, mean_steps: 24.1600, mean_ecr: 0.0478 mean_entropies: 1.7187, took: 120.3936s
2022-10-10 01:01:37,947 [INFO] 	Process 5 - batch 11099: mean_policy_losses: 201.413, mean_net_lifetime: 5006.4478, mean_mc_travel_dist: 2780.0185, mean_rewards: 170.1154, total_rewards: 2286.3062, mean_steps: 28.3800, mean_ecr: 0.0308 mean_entropies: 2.4176, took: 140.0796s
2022-10-10 01:02:06,929 [INFO] 	Process 1 - batch 9999: mean_policy_losses: 23.333, mean_net_lifetime: 4623.1065, mean_mc_travel_dist: 2373.3733, mean_rewards: 107.7530, total_rewards: 2277.6236, mean_steps: 42.2700, mean_ecr: 0.0396 mean_entropies: 1.7415, took: 197.2806s
2022-10-10 01:02:07,866 [INFO] 	Process 7 - batch 10899: mean_policy_losses: -11.322, mean_net_lifetime: 3698.2443, mean_mc_travel_dist: 1884.0503, mean_rewards: 157.4813, total_rewards: 1858.9158, mean_steps: 22.4500, mean_ecr: 0.0432 mean_entropies: 2.3146, took: 109.5731s
2022-10-10 01:02:19,122 [INFO] 	Process 6 - batch 17999: mean_policy_losses: -453.474, mean_net_lifetime: 1875.5517, mean_mc_travel_dist: 1007.8456, mean_rewards: 174.6728, total_rewards: 912.1775, mean_steps: 9.8400, mean_ecr: 0.0567 mean_entropies: 1.5623, took: 54.9960s
2022-10-10 01:03:28,957 [INFO] 	Process 2 - batch 11299: mean_policy_losses: 87.161, mean_net_lifetime: 4196.3322, mean_mc_travel_dist: 1985.9939, mean_rewards: 151.7269, total_rewards: 2234.4590, mean_steps: 26.7200, mean_ecr: 0.0410 mean_entropies: 1.8756, took: 127.9385s
2022-10-10 01:03:31,671 [INFO] 	Process 3 - batch 11299: mean_policy_losses: 115.585, mean_net_lifetime: 3909.3213, mean_mc_travel_dist: 1667.5966, mean_rewards: 152.7978, total_rewards: 2262.7533, mean_steps: 24.8200, mean_ecr: 0.0480 mean_entropies: 1.6620, took: 121.1645s
2022-10-10 01:03:57,732 [INFO] 	Process 5 - batch 11199: mean_policy_losses: 79.216, mean_net_lifetime: 5048.4769, mean_mc_travel_dist: 2759.8657, mean_rewards: 163.0183, total_rewards: 2343.2707, mean_steps: 29.8700, mean_ecr: 0.0308 mean_entropies: 2.3802, took: 139.7849s
2022-10-10 01:04:04,788 [INFO] 	Process 7 - batch 10999: mean_policy_losses: -137.853, mean_net_lifetime: 3924.3780, mean_mc_travel_dist: 1917.3772, mean_rewards: 151.3633, total_rewards: 2057.2686, mean_steps: 24.9300, mean_ecr: 0.0431 mean_entropies: 2.2567, took: 116.9204s
2022-10-10 01:05:25,281 [INFO] 	Process 1 - batch 10099: mean_policy_losses: -114.608, mean_net_lifetime: 4560.8112, mean_mc_travel_dist: 2358.2196, mean_rewards: 106.1678, total_rewards: 2226.6389, mean_steps: 42.3500, mean_ecr: 0.0396 mean_entropies: 1.7224, took: 198.3520s
2022-10-10 01:05:31,005 [INFO] 	Process 3 - batch 11399: mean_policy_losses: 57.807, mean_net_lifetime: 3948.8672, mean_mc_travel_dist: 1714.5752, mean_rewards: 157.5553, total_rewards: 2255.6063, mean_steps: 24.3200, mean_ecr: 0.0477 mean_entropies: 1.8024, took: 119.3345s
2022-10-10 01:05:39,151 [INFO] 	Process 2 - batch 11399: mean_policy_losses: 194.056, mean_net_lifetime: 4785.5708, mean_mc_travel_dist: 2195.0853, mean_rewards: 165.8534, total_rewards: 2618.2204, mean_steps: 27.9300, mean_ecr: 0.0403 mean_entropies: 2.0423, took: 130.1936s
2022-10-10 01:05:53,416 [INFO] 	Process 7 - batch 11099: mean_policy_losses: -279.784, mean_net_lifetime: 3549.3650, mean_mc_travel_dist: 1814.3132, mean_rewards: 149.2618, total_rewards: 1777.1555, mean_steps: 23.0000, mean_ecr: 0.0435 mean_entropies: 2.2901, took: 108.6291s
2022-10-10 01:06:15,380 [INFO] 	Process 5 - batch 11299: mean_policy_losses: -13.946, mean_net_lifetime: 4860.7711, mean_mc_travel_dist: 2710.4462, mean_rewards: 162.5072, total_rewards: 2192.7844, mean_steps: 28.8000, mean_ecr: 0.0309 mean_entropies: 2.4179, took: 137.6478s
2022-10-10 01:07:25,113 [INFO] 	Process 3 - batch 11499: mean_policy_losses: 89.104, mean_net_lifetime: 3965.8896, mean_mc_travel_dist: 1704.7139, mean_rewards: 165.6652, total_rewards: 2281.8894, mean_steps: 23.0600, mean_ecr: 0.0476 mean_entropies: 1.8398, took: 114.1086s
2022-10-10 01:07:42,111 [INFO] 	Process 7 - batch 11199: mean_policy_losses: -234.340, mean_net_lifetime: 3748.1587, mean_mc_travel_dist: 1879.3114, mean_rewards: 155.2639, total_rewards: 1919.5211, mean_steps: 23.0900, mean_ecr: 0.0432 mean_entropies: 2.3144, took: 108.6942s
2022-10-10 01:07:45,709 [INFO] 	Process 2 - batch 11499: mean_policy_losses: 172.236, mean_net_lifetime: 4742.9590, mean_mc_travel_dist: 2212.5375, mean_rewards: 169.2430, total_rewards: 2559.7247, mean_steps: 27.1700, mean_ecr: 0.0405 mean_entropies: 2.0745, took: 126.5579s
2022-10-10 01:08:36,114 [INFO] 	Process 5 - batch 11399: mean_policy_losses: 11.942, mean_net_lifetime: 5016.4133, mean_mc_travel_dist: 2789.1033, mean_rewards: 164.2733, total_rewards: 2290.0695, mean_steps: 29.5500, mean_ecr: 0.0309 mean_entropies: 2.4246, took: 140.7346s
2022-10-10 01:08:43,481 [INFO] 	Process 1 - batch 10199: mean_policy_losses: -106.380, mean_net_lifetime: 4588.5546, mean_mc_travel_dist: 2362.5523, mean_rewards: 107.1264, total_rewards: 2249.2234, mean_steps: 42.2200, mean_ecr: 0.0396 mean_entropies: 1.7645, took: 198.2012s
2022-10-10 01:09:18,212 [INFO] 	Process 3 - batch 11599: mean_policy_losses: 54.594, mean_net_lifetime: 3932.7746, mean_mc_travel_dist: 1693.2616, mean_rewards: 161.6296, total_rewards: 2266.6671, mean_steps: 23.5800, mean_ecr: 0.0478 mean_entropies: 1.8208, took: 113.0979s
2022-10-10 01:09:37,429 [INFO] 	Process 7 - batch 11299: mean_policy_losses: -213.362, mean_net_lifetime: 3791.1264, mean_mc_travel_dist: 1875.7137, mean_rewards: 147.8570, total_rewards: 1970.7618, mean_steps: 24.6800, mean_ecr: 0.0434 mean_entropies: 2.2770, took: 115.3178s
2022-10-10 01:09:50,372 [INFO] 	Process 2 - batch 11599: mean_policy_losses: 144.346, mean_net_lifetime: 4720.0469, mean_mc_travel_dist: 2199.8815, mean_rewards: 169.4576, total_rewards: 2553.9693, mean_steps: 26.9500, mean_ecr: 0.0404 mean_entropies: 2.0619, took: 124.6642s
2022-10-10 01:10:54,722 [INFO] 	Process 5 - batch 11499: mean_policy_losses: -7.002, mean_net_lifetime: 5035.0703, mean_mc_travel_dist: 2761.0078, mean_rewards: 166.8859, total_rewards: 2333.9497, mean_steps: 29.0700, mean_ecr: 0.0309 mean_entropies: 2.4398, took: 138.6075s
2022-10-10 01:11:12,311 [INFO] 	Process 3 - batch 11699: mean_policy_losses: 27.663, mean_net_lifetime: 3953.4453, mean_mc_travel_dist: 1697.0502, mean_rewards: 164.1686, total_rewards: 2276.6173, mean_steps: 23.3200, mean_ecr: 0.0478 mean_entropies: 1.8384, took: 114.0999s
2022-10-10 01:11:32,076 [INFO] 	Process 7 - batch 11399: mean_policy_losses: -189.772, mean_net_lifetime: 3808.2549, mean_mc_travel_dist: 1888.8955, mean_rewards: 152.6209, total_rewards: 1967.8697, mean_steps: 24.0400, mean_ecr: 0.0432 mean_entropies: 2.2828, took: 114.6475s
2022-10-10 01:11:54,262 [INFO] 	Process 1 - batch 10299: mean_policy_losses: -119.698, mean_net_lifetime: 4588.6848, mean_mc_travel_dist: 2316.6195, mean_rewards: 109.4258, total_rewards: 2296.2425, mean_steps: 41.3000, mean_ecr: 0.0397 mean_entropies: 1.7762, took: 190.7813s
2022-10-10 01:11:55,659 [INFO] 	Process 2 - batch 11699: mean_policy_losses: 181.599, mean_net_lifetime: 4840.2340, mean_mc_travel_dist: 2235.5658, mean_rewards: 171.8828, total_rewards: 2636.1839, mean_steps: 27.2800, mean_ecr: 0.0404 mean_entropies: 2.0873, took: 125.2863s
2022-10-10 01:13:07,507 [INFO] 	Process 3 - batch 11799: mean_policy_losses: 50.848, mean_net_lifetime: 3990.9750, mean_mc_travel_dist: 1728.3135, mean_rewards: 164.9225, total_rewards: 2281.9233, mean_steps: 23.3500, mean_ecr: 0.0477 mean_entropies: 1.8582, took: 115.1956s
2022-10-10 01:13:08,838 [INFO] 	Process 5 - batch 11599: mean_policy_losses: -44.357, mean_net_lifetime: 4898.4390, mean_mc_travel_dist: 2712.3380, mean_rewards: 165.2286, total_rewards: 2238.6693, mean_steps: 28.4800, mean_ecr: 0.0310 mean_entropies: 2.4344, took: 134.1167s
2022-10-10 01:13:30,936 [INFO] 	Process 7 - batch 11499: mean_policy_losses: -172.379, mean_net_lifetime: 3923.0238, mean_mc_travel_dist: 1892.6229, mean_rewards: 147.2152, total_rewards: 2072.6827, mean_steps: 25.7000, mean_ecr: 0.0432 mean_entropies: 2.2747, took: 118.8599s
2022-10-10 01:14:00,707 [INFO] 	Process 2 - batch 11799: mean_policy_losses: 170.580, mean_net_lifetime: 4774.6030, mean_mc_travel_dist: 2178.5052, mean_rewards: 170.0761, total_rewards: 2624.8367, mean_steps: 27.1600, mean_ecr: 0.0406 mean_entropies: 2.0967, took: 125.0478s
2022-10-10 01:15:03,940 [INFO] 	Process 3 - batch 11899: mean_policy_losses: 72.941, mean_net_lifetime: 3963.7551, mean_mc_travel_dist: 1695.4105, mean_rewards: 164.6404, total_rewards: 2286.7692, mean_steps: 23.3400, mean_ecr: 0.0478 mean_entropies: 1.8279, took: 116.4331s
2022-10-10 01:15:08,931 [INFO] 	Process 1 - batch 10399: mean_policy_losses: -115.139, mean_net_lifetime: 4541.1367, mean_mc_travel_dist: 2314.3074, mean_rewards: 107.4624, total_rewards: 2254.4706, mean_steps: 41.7000, mean_ecr: 0.0397 mean_entropies: 1.8091, took: 194.6686s
2022-10-10 01:15:23,298 [INFO] 	Process 5 - batch 11699: mean_policy_losses: -96.249, mean_net_lifetime: 4737.9441, mean_mc_travel_dist: 2638.3506, mean_rewards: 158.1515, total_rewards: 2153.7247, mean_steps: 28.7800, mean_ecr: 0.0307 mean_entropies: 2.4544, took: 134.4604s
2022-10-10 01:15:25,255 [INFO] 	Process 7 - batch 11599: mean_policy_losses: -148.929, mean_net_lifetime: 3988.9429, mean_mc_travel_dist: 1944.9251, mean_rewards: 155.0382, total_rewards: 2079.2612, mean_steps: 24.6200, mean_ecr: 0.0432 mean_entropies: 2.3119, took: 114.3191s
2022-10-10 01:15:29,449 [INFO] Process 4 - epoch 9: mean_policy_losses: -30.966, mean_net_lifetime: 2631.6519, mean_mc_travel_dist: 1232.7642, mean_entropies: 2.0045, m_net_lifetime_valid: 3084.3182, took: 2428.6892s, (189.1672 / 100 batches)

2022-10-10 01:16:00,497 [INFO] 	Process 2 - batch 11899: mean_policy_losses: 106.245, mean_net_lifetime: 4340.2662, mean_mc_travel_dist: 2018.8693, mean_rewards: 164.2159, total_rewards: 2357.4008, mean_steps: 25.6000, mean_ecr: 0.0409 mean_entropies: 2.0354, took: 119.7896s
2022-10-10 01:16:52,716 [INFO] 	Process 4 - batch 13599: mean_policy_losses: -243.174, mean_net_lifetime: 2654.8379, mean_mc_travel_dist: 1224.0835, mean_rewards: 154.4629, total_rewards: 1444.1276, mean_steps: 16.2700, mean_ecr: 0.0527 mean_entropies: 2.1270, took: 1291.0575s
2022-10-10 01:17:00,619 [INFO] 	Process 3 - batch 11999: mean_policy_losses: 94.883, mean_net_lifetime: 3829.3815, mean_mc_travel_dist: 1660.1918, mean_rewards: 157.1464, total_rewards: 2195.2253, mean_steps: 23.6200, mean_ecr: 0.0480 mean_entropies: 1.7857, took: 116.6791s
2022-10-10 01:17:18,833 [INFO] 	Process 7 - batch 11699: mean_policy_losses: -33.370, mean_net_lifetime: 3895.2120, mean_mc_travel_dist: 1937.1756, mean_rewards: 157.6216, total_rewards: 2010.9095, mean_steps: 23.7700, mean_ecr: 0.0432 mean_entropies: 2.3288, took: 113.5782s
2022-10-10 01:17:41,148 [INFO] 	Process 5 - batch 11799: mean_policy_losses: 67.012, mean_net_lifetime: 4821.2046, mean_mc_travel_dist: 2672.0410, mean_rewards: 164.8061, total_rewards: 2205.0954, mean_steps: 28.0800, mean_ecr: 0.0306 mean_entropies: 2.4360, took: 137.8492s
2022-10-10 01:18:05,057 [INFO] 	Process 2 - batch 11999: mean_policy_losses: 189.080, mean_net_lifetime: 4382.9622, mean_mc_travel_dist: 2039.0653, mean_rewards: 159.3952, total_rewards: 2371.1125, mean_steps: 26.4700, mean_ecr: 0.0410 mean_entropies: 1.9878, took: 124.5602s
2022-10-10 01:18:12,608 [INFO] 	Process 4 - batch 13699: mean_policy_losses: -191.018, mean_net_lifetime: 2670.6346, mean_mc_travel_dist: 1224.0133, mean_rewards: 158.4203, total_rewards: 1458.1879, mean_steps: 16.0400, mean_ecr: 0.0527 mean_entropies: 2.1652, took: 79.8922s
2022-10-10 01:18:13,530 [INFO] 	Process 1 - batch 10499: mean_policy_losses: 47.937, mean_net_lifetime: 4710.8558, mean_mc_travel_dist: 2363.2565, mean_rewards: 117.6661, total_rewards: 2372.1253, mean_steps: 39.4300, mean_ecr: 0.0397 mean_entropies: 1.8628, took: 184.5979s
2022-10-10 01:19:04,105 [INFO] 	Process 7 - batch 11799: mean_policy_losses: 73.597, mean_net_lifetime: 3752.7291, mean_mc_travel_dist: 1850.3770, mean_rewards: 153.1401, total_rewards: 1950.8523, mean_steps: 23.3700, mean_ecr: 0.0434 mean_entropies: 2.3093, took: 105.2715s
2022-10-10 01:19:27,278 [INFO] 	Process 4 - batch 13799: mean_policy_losses: -24.383, mean_net_lifetime: 2682.2046, mean_mc_travel_dist: 1234.9107, mean_rewards: 156.7036, total_rewards: 1461.7686, mean_steps: 16.2300, mean_ecr: 0.0527 mean_entropies: 2.1636, took: 74.6703s
2022-10-10 01:19:51,968 [INFO] 	Process 5 - batch 11899: mean_policy_losses: 130.238, mean_net_lifetime: 4792.4707, mean_mc_travel_dist: 2681.1280, mean_rewards: 155.7165, total_rewards: 2151.7378, mean_steps: 29.2400, mean_ecr: 0.0302 mean_entropies: 2.3909, took: 130.8201s
2022-10-10 01:20:40,235 [INFO] 	Process 4 - batch 13899: mean_policy_losses: -39.285, mean_net_lifetime: 2772.4747, mean_mc_travel_dist: 1238.4083, mean_rewards: 166.2140, total_rewards: 1547.8557, mean_steps: 15.8800, mean_ecr: 0.0528 mean_entropies: 2.1653, took: 72.9573s
2022-10-10 01:20:41,851 [INFO] 	Process 7 - batch 11899: mean_policy_losses: 122.964, mean_net_lifetime: 3879.5837, mean_mc_travel_dist: 1913.7211, mean_rewards: 163.0024, total_rewards: 2016.0154, mean_steps: 22.5600, mean_ecr: 0.0431 mean_entropies: 2.3390, took: 97.7460s
2022-10-10 01:21:38,613 [INFO] Process 6 - epoch 12: mean_policy_losses: -348.486, mean_net_lifetime: 1842.9222, mean_mc_travel_dist: 1032.0101, mean_entropies: 1.8042, m_net_lifetime_valid: 3186.7259, took: 2001.1768s, (144.4411 / 100 batches)

2022-10-10 01:21:58,333 [INFO] 	Process 4 - batch 13999: mean_policy_losses: 101.021, mean_net_lifetime: 2992.7310, mean_mc_travel_dist: 1289.3456, mean_rewards: 168.2432, total_rewards: 1715.3799, mean_steps: 16.7900, mean_ecr: 0.0523 mean_entropies: 2.1271, took: 78.0981s
2022-10-10 01:22:03,784 [INFO] 	Process 5 - batch 11999: mean_policy_losses: 68.505, mean_net_lifetime: 4680.1404, mean_mc_travel_dist: 2626.9094, mean_rewards: 150.4287, total_rewards: 2108.5708, mean_steps: 29.4900, mean_ecr: 0.0302 mean_entropies: 2.3127, took: 131.8165s
2022-10-10 01:22:26,544 [INFO] 	Process 7 - batch 11999: mean_policy_losses: 178.802, mean_net_lifetime: 4013.6311, mean_mc_travel_dist: 1944.3770, mean_rewards: 159.5918, total_rewards: 2114.1869, mean_steps: 24.1800, mean_ecr: 0.0431 mean_entropies: 2.3122, took: 104.6931s
2022-10-10 01:22:34,568 [INFO] 	Process 6 - batch 18099: mean_policy_losses: -195.535, mean_net_lifetime: 2368.6534, mean_mc_travel_dist: 1140.7176, mean_rewards: 192.4582, total_rewards: 1278.4729, mean_steps: 11.2300, mean_ecr: 0.0567 mean_entropies: 1.3997, took: 1215.4451s
2022-10-10 01:23:11,470 [INFO] 	Process 4 - batch 14099: mean_policy_losses: 139.496, mean_net_lifetime: 3016.2545, mean_mc_travel_dist: 1311.2470, mean_rewards: 175.4373, total_rewards: 1720.6855, mean_steps: 16.1800, mean_ecr: 0.0521 mean_entropies: 2.1199, took: 73.1367s
2022-10-10 01:23:34,482 [INFO] 	Process 6 - batch 18199: mean_policy_losses: -123.540, mean_net_lifetime: 2626.0778, mean_mc_travel_dist: 1208.6026, mean_rewards: 192.4950, total_rewards: 1458.2010, mean_steps: 12.4500, mean_ecr: 0.0563 mean_entropies: 1.2504, took: 59.9137s
2022-10-10 01:24:27,053 [INFO] 	Process 4 - batch 14199: mean_policy_losses: 149.856, mean_net_lifetime: 3098.6032, mean_mc_travel_dist: 1344.0008, mean_rewards: 172.5770, total_rewards: 1768.5371, mean_steps: 16.9500, mean_ecr: 0.0519 mean_entropies: 1.9615, took: 75.5829s
2022-10-10 01:24:32,670 [INFO] 	Process 6 - batch 18299: mean_policy_losses: -173.266, mean_net_lifetime: 2431.1310, mean_mc_travel_dist: 1146.6546, mean_rewards: 178.7163, total_rewards: 1335.2573, mean_steps: 12.2400, mean_ecr: 0.0561 mean_entropies: 1.1148, took: 58.1883s
2022-10-10 01:25:38,982 [INFO] 	Process 6 - batch 18399: mean_policy_losses: -152.774, mean_net_lifetime: 2826.4906, mean_mc_travel_dist: 1250.3204, mean_rewards: 181.0704, total_rewards: 1613.8087, mean_steps: 14.4600, mean_ecr: 0.0558 mean_entropies: 0.9470, took: 66.3119s
2022-10-10 01:25:47,089 [INFO] 	Process 4 - batch 14299: mean_policy_losses: 37.792, mean_net_lifetime: 3193.3166, mean_mc_travel_dist: 1364.0247, mean_rewards: 166.3367, total_rewards: 1844.2753, mean_steps: 18.1500, mean_ecr: 0.0518 mean_entropies: 1.8033, took: 80.0359s
2022-10-10 01:26:46,116 [INFO] 	Process 6 - batch 18499: mean_policy_losses: -123.991, mean_net_lifetime: 2913.4479, mean_mc_travel_dist: 1276.4575, mean_rewards: 185.3685, total_rewards: 1670.5249, mean_steps: 14.5600, mean_ecr: 0.0557 mean_entropies: 0.8718, took: 67.1343s
2022-10-10 01:27:09,141 [INFO] 	Process 4 - batch 14399: mean_policy_losses: 0.184, mean_net_lifetime: 3328.4551, mean_mc_travel_dist: 1387.1181, mean_rewards: 170.4302, total_rewards: 1953.3887, mean_steps: 18.5800, mean_ecr: 0.0515 mean_entropies: 1.7268, took: 82.0519s
2022-10-10 01:27:53,194 [INFO] 	Process 6 - batch 18599: mean_policy_losses: -218.130, mean_net_lifetime: 2856.1588, mean_mc_travel_dist: 1251.4468, mean_rewards: 176.8207, total_rewards: 1641.7452, mean_steps: 14.7800, mean_ecr: 0.0555 mean_entropies: 0.8408, took: 67.0781s
2022-10-10 01:28:29,235 [INFO] 	Process 4 - batch 14499: mean_policy_losses: -80.819, mean_net_lifetime: 3255.7206, mean_mc_travel_dist: 1353.1288, mean_rewards: 166.7549, total_rewards: 1914.8491, mean_steps: 18.4300, mean_ecr: 0.0517 mean_entropies: 1.6963, took: 80.0937s
2022-10-10 01:29:02,836 [INFO] 	Process 6 - batch 18699: mean_policy_losses: -123.097, mean_net_lifetime: 3024.7447, mean_mc_travel_dist: 1298.1906, mean_rewards: 187.6169, total_rewards: 1759.7912, mean_steps: 15.0200, mean_ecr: 0.0555 mean_entropies: 0.8031, took: 69.6418s
2022-10-10 01:29:49,518 [INFO] 	Process 4 - batch 14599: mean_policy_losses: 25.685, mean_net_lifetime: 3251.9717, mean_mc_travel_dist: 1354.7657, mean_rewards: 165.4971, total_rewards: 1912.3194, mean_steps: 18.6900, mean_ecr: 0.0516 mean_entropies: 1.6995, took: 80.2837s
2022-10-10 01:30:11,052 [INFO] 	Process 6 - batch 18799: mean_policy_losses: -155.805, mean_net_lifetime: 2797.0270, mean_mc_travel_dist: 1241.3848, mean_rewards: 174.7570, total_rewards: 1596.4680, mean_steps: 14.6400, mean_ecr: 0.0556 mean_entropies: 0.7621, took: 68.2160s
2022-10-10 01:31:12,214 [INFO] 	Process 4 - batch 14699: mean_policy_losses: -4.962, mean_net_lifetime: 3439.4325, mean_mc_travel_dist: 1414.9609, mean_rewards: 171.9345, total_rewards: 2032.9497, mean_steps: 18.9600, mean_ecr: 0.0513 mean_entropies: 1.6535, took: 82.6957s
2022-10-10 01:31:20,869 [INFO] 	Process 6 - batch 18899: mean_policy_losses: -138.907, mean_net_lifetime: 3003.0960, mean_mc_travel_dist: 1299.8101, mean_rewards: 177.8807, total_rewards: 1738.4429, mean_steps: 15.6900, mean_ecr: 0.0553 mean_entropies: 0.7433, took: 69.8174s
2022-10-10 01:32:33,220 [INFO] 	Process 6 - batch 18999: mean_policy_losses: -134.090, mean_net_lifetime: 3083.7401, mean_mc_travel_dist: 1313.8820, mean_rewards: 184.5438, total_rewards: 1802.4868, mean_steps: 15.6600, mean_ecr: 0.0554 mean_entropies: 0.7385, took: 72.3505s
2022-10-10 01:32:33,338 [INFO] 	Process 4 - batch 14799: mean_policy_losses: -70.887, mean_net_lifetime: 3236.5377, mean_mc_travel_dist: 1331.8573, mean_rewards: 163.3945, total_rewards: 1915.9062, mean_steps: 18.7800, mean_ecr: 0.0518 mean_entropies: 1.6388, took: 81.1242s
2022-10-10 01:33:43,700 [INFO] 	Process 6 - batch 19099: mean_policy_losses: -151.412, mean_net_lifetime: 3022.8953, mean_mc_travel_dist: 1296.5563, mean_rewards: 183.0279, total_rewards: 1764.7818, mean_steps: 15.3700, mean_ecr: 0.0554 mean_entropies: 0.6985, took: 70.4798s
2022-10-10 01:33:56,587 [INFO] 	Process 4 - batch 14899: mean_policy_losses: 11.283, mean_net_lifetime: 3491.2001, mean_mc_travel_dist: 1417.1779, mean_rewards: 171.2921, total_rewards: 2087.0825, mean_steps: 19.4100, mean_ecr: 0.0510 mean_entropies: 1.6190, took: 83.2484s
2022-10-10 01:34:53,829 [INFO] 	Process 6 - batch 19199: mean_policy_losses: -137.876, mean_net_lifetime: 3009.4804, mean_mc_travel_dist: 1295.6752, mean_rewards: 178.9502, total_rewards: 1749.4120, mean_steps: 15.6100, mean_ecr: 0.0554 mean_entropies: 0.6792, took: 70.1296s
2022-10-10 01:34:58,583 [INFO] Process 3 - epoch 8: mean_policy_losses: 185.190, mean_net_lifetime: 3691.6430, mean_mc_travel_dist: 1661.4211, mean_entropies: 1.8930, m_net_lifetime_valid: 3326.1679, took: 2888.6016s, (223.3482 / 100 batches)

2022-10-10 01:35:19,777 [INFO] 	Process 4 - batch 14999: mean_policy_losses: -60.589, mean_net_lifetime: 3313.7335, mean_mc_travel_dist: 1369.4203, mean_rewards: 163.7821, total_rewards: 1955.4491, mean_steps: 19.2900, mean_ecr: 0.0516 mean_entropies: 1.5458, took: 83.1902s
2022-10-10 01:35:41,803 [INFO] Process 1 - epoch 7: mean_policy_losses: 208.975, mean_net_lifetime: 4569.1075, mean_mc_travel_dist: 2385.5913, mean_entropies: 2.1139, m_net_lifetime_valid: 3320.5994, took: 3526.7841s, (255.6484 / 100 batches)

2022-10-10 01:36:02,353 [INFO] Process 2 - epoch 8: mean_policy_losses: 5.262, mean_net_lifetime: 3409.6720, mean_mc_travel_dist: 1745.1250, mean_entropies: 1.9679, m_net_lifetime_valid: 3309.1721, took: 3007.6265s, (223.8871 / 100 batches)

2022-10-10 01:36:07,156 [INFO] 	Process 6 - batch 19299: mean_policy_losses: -59.976, mean_net_lifetime: 3244.0903, mean_mc_travel_dist: 1365.1287, mean_rewards: 197.8442, total_rewards: 1903.4925, mean_steps: 15.4900, mean_ecr: 0.0552 mean_entropies: 0.6832, took: 73.3266s
2022-10-10 01:37:21,571 [INFO] 	Process 6 - batch 19399: mean_policy_losses: -37.010, mean_net_lifetime: 3077.9529, mean_mc_travel_dist: 1318.6369, mean_rewards: 197.4281, total_rewards: 1788.2999, mean_steps: 14.6000, mean_ecr: 0.0557 mean_entropies: 0.8046, took: 74.4147s
2022-10-10 01:37:28,551 [INFO] 	Process 3 - batch 12099: mean_policy_losses: -70.069, mean_net_lifetime: 3395.1501, mean_mc_travel_dist: 1645.7030, mean_rewards: 100.5904, total_rewards: 1772.5042, mean_steps: 33.5600, mean_ecr: 0.0484 mean_entropies: 0.8697, took: 1227.9314s
2022-10-10 01:38:07,757 [INFO] 	Process 2 - batch 12099: mean_policy_losses: -112.896, mean_net_lifetime: 2870.6962, mean_mc_travel_dist: 1609.6680, mean_rewards: 97.8051, total_rewards: 1284.0288, mean_steps: 28.4600, mean_ecr: 0.0426 mean_entropies: 0.7706, took: 1202.6998s
2022-10-10 01:38:26,567 [INFO] 	Process 1 - batch 10599: mean_policy_losses: 50.639, mean_net_lifetime: 4510.1118, mean_mc_travel_dist: 2527.5688, mean_rewards: 117.4495, total_rewards: 2019.2891, mean_steps: 37.8000, mean_ecr: 0.0395 mean_entropies: 1.3401, took: 1213.0383s
2022-10-10 01:38:32,793 [INFO] 	Process 6 - batch 19499: mean_policy_losses: -15.834, mean_net_lifetime: 2930.9354, mean_mc_travel_dist: 1276.8851, mean_rewards: 195.6492, total_rewards: 1678.0656, mean_steps: 13.9900, mean_ecr: 0.0559 mean_entropies: 0.8861, took: 71.2228s
2022-10-10 01:39:23,270 [INFO] Process 5 - epoch 8: mean_policy_losses: 17.715, mean_net_lifetime: 4047.3024, mean_mc_travel_dist: 2369.2679, mean_entropies: 2.5036, m_net_lifetime_valid: 3192.9067, took: 3112.1677s, (225.8592 / 100 batches)

2022-10-10 01:39:42,636 [INFO] 	Process 3 - batch 12199: mean_policy_losses: 56.317, mean_net_lifetime: 3488.9119, mean_mc_travel_dist: 1622.4261, mean_rewards: 116.4627, total_rewards: 1884.8806, mean_steps: 29.5500, mean_ecr: 0.0485 mean_entropies: 1.0923, took: 134.0864s
2022-10-10 01:39:47,020 [INFO] Process 7 - epoch 8: mean_policy_losses: 46.969, mean_net_lifetime: 3680.0742, mean_mc_travel_dist: 1823.8707, mean_entropies: 2.2926, m_net_lifetime_valid: 3210.1967, took: 2728.9359s, (226.0469 / 100 batches)

2022-10-10 01:40:12,945 [INFO] 	Process 2 - batch 12199: mean_policy_losses: -76.188, mean_net_lifetime: 3049.7340, mean_mc_travel_dist: 1626.9661, mean_rewards: 104.2020, total_rewards: 1452.7570, mean_steps: 28.4400, mean_ecr: 0.0422 mean_entropies: 1.0986, took: 125.1890s
2022-10-10 01:41:30,339 [INFO] 	Process 1 - batch 10699: mean_policy_losses: 67.636, mean_net_lifetime: 4518.0697, mean_mc_travel_dist: 2386.7760, mean_rewards: 110.2853, total_rewards: 2157.8496, mean_steps: 40.7100, mean_ecr: 0.0397 mean_entropies: 1.5620, took: 183.7716s
2022-10-10 01:41:45,103 [INFO] 	Process 5 - batch 12099: mean_policy_losses: 37.868, mean_net_lifetime: 4765.5728, mean_mc_travel_dist: 2775.4395, mean_rewards: 151.9740, total_rewards: 2054.5930, mean_steps: 29.7700, mean_ecr: 0.0297 mean_entropies: 2.1322, took: 1181.3185s
2022-10-10 01:41:48,341 [INFO] 	Process 3 - batch 12299: mean_policy_losses: 73.130, mean_net_lifetime: 3781.9988, mean_mc_travel_dist: 1663.8573, mean_rewards: 144.1509, total_rewards: 2135.8541, mean_steps: 25.6000, mean_ecr: 0.0481 mean_entropies: 1.5158, took: 125.7046s
2022-10-10 01:41:58,618 [INFO] 	Process 7 - batch 12099: mean_policy_losses: 20.773, mean_net_lifetime: 4096.3463, mean_mc_travel_dist: 1952.4129, mean_rewards: 139.0175, total_rewards: 2179.5983, mean_steps: 28.6100, mean_ecr: 0.0432 mean_entropies: 2.1908, took: 1172.0741s
2022-10-10 01:42:19,484 [INFO] 	Process 2 - batch 12299: mean_policy_losses: 6.240, mean_net_lifetime: 3910.9527, mean_mc_travel_dist: 1845.6017, mean_rewards: 139.1784, total_rewards: 2095.9175, mean_steps: 27.1400, mean_ecr: 0.0414 mean_entropies: 1.7115, took: 126.5381s
2022-10-10 01:43:42,725 [INFO] 	Process 3 - batch 12399: mean_policy_losses: 26.769, mean_net_lifetime: 3897.1191, mean_mc_travel_dist: 1696.1671, mean_rewards: 162.3470, total_rewards: 2225.8434, mean_steps: 23.1100, mean_ecr: 0.0478 mean_entropies: 1.8020, took: 114.3832s
2022-10-10 01:44:00,418 [INFO] 	Process 7 - batch 12199: mean_policy_losses: -114.394, mean_net_lifetime: 4044.4861, mean_mc_travel_dist: 1926.3918, mean_rewards: 146.7202, total_rewards: 2157.7790, mean_steps: 26.4400, mean_ecr: 0.0432 mean_entropies: 2.2598, took: 121.8003s
2022-10-10 01:44:09,410 [INFO] 	Process 5 - batch 12199: mean_policy_losses: 53.165, mean_net_lifetime: 5410.3313, mean_mc_travel_dist: 3024.2562, mean_rewards: 169.3081, total_rewards: 2450.6615, mean_steps: 30.6800, mean_ecr: 0.0301 mean_entropies: 2.4008, took: 144.3060s
2022-10-10 01:44:26,074 [INFO] 	Process 2 - batch 12399: mean_policy_losses: 125.948, mean_net_lifetime: 4628.3900, mean_mc_travel_dist: 2142.8784, mean_rewards: 163.9493, total_rewards: 2526.5838, mean_steps: 27.3200, mean_ecr: 0.0406 mean_entropies: 2.0001, took: 126.5907s
2022-10-10 01:44:46,308 [INFO] 	Process 1 - batch 10799: mean_policy_losses: -110.938, mean_net_lifetime: 4549.4798, mean_mc_travel_dist: 2327.0919, mean_rewards: 104.9116, total_rewards: 2248.7939, mean_steps: 42.7600, mean_ecr: 0.0398 mean_entropies: 1.7101, took: 195.9688s
2022-10-10 01:45:36,800 [INFO] 	Process 3 - batch 12499: mean_policy_losses: 25.861, mean_net_lifetime: 4029.5393, mean_mc_travel_dist: 1737.9894, mean_rewards: 165.7050, total_rewards: 2317.6737, mean_steps: 23.5800, mean_ecr: 0.0476 mean_entropies: 1.8310, took: 114.0750s
2022-10-10 01:46:04,750 [INFO] 	Process 7 - batch 12299: mean_policy_losses: -86.740, mean_net_lifetime: 4089.5578, mean_mc_travel_dist: 1946.0872, mean_rewards: 147.9169, total_rewards: 2196.4397, mean_steps: 26.7800, mean_ecr: 0.0433 mean_entropies: 2.2424, took: 124.3323s
2022-10-10 01:46:31,503 [INFO] 	Process 5 - batch 12299: mean_policy_losses: 25.451, mean_net_lifetime: 5294.6064, mean_mc_travel_dist: 2938.3614, mean_rewards: 169.8234, total_rewards: 2408.0635, mean_steps: 30.0500, mean_ecr: 0.0304 mean_entropies: 2.3839, took: 142.0927s
2022-10-10 01:46:33,572 [INFO] 	Process 2 - batch 12499: mean_policy_losses: 127.114, mean_net_lifetime: 4698.6844, mean_mc_travel_dist: 2164.7702, mean_rewards: 164.6919, total_rewards: 2565.6120, mean_steps: 27.6900, mean_ecr: 0.0406 mean_entropies: 1.9830, took: 127.4975s
2022-10-10 01:47:31,582 [INFO] 	Process 3 - batch 12599: mean_policy_losses: 34.141, mean_net_lifetime: 3961.2124, mean_mc_travel_dist: 1716.1753, mean_rewards: 162.1197, total_rewards: 2274.9961, mean_steps: 23.6100, mean_ecr: 0.0479 mean_entropies: 1.7829, took: 114.7827s
2022-10-10 01:48:00,979 [INFO] 	Process 1 - batch 10899: mean_policy_losses: -114.967, mean_net_lifetime: 4611.3066, mean_mc_travel_dist: 2328.8593, mean_rewards: 107.9926, total_rewards: 2304.7693, mean_steps: 42.0800, mean_ecr: 0.0397 mean_entropies: 1.7380, took: 194.6705s
2022-10-10 01:48:01,719 [INFO] 	Process 7 - batch 12399: mean_policy_losses: -162.550, mean_net_lifetime: 3953.3833, mean_mc_travel_dist: 1933.2697, mean_rewards: 150.7240, total_rewards: 2065.7366, mean_steps: 25.1700, mean_ecr: 0.0432 mean_entropies: 2.2521, took: 116.9668s
2022-10-10 01:48:41,104 [INFO] 	Process 2 - batch 12599: mean_policy_losses: 126.163, mean_net_lifetime: 4753.2926, mean_mc_travel_dist: 2195.7690, mean_rewards: 167.3851, total_rewards: 2582.4206, mean_steps: 27.4700, mean_ecr: 0.0404 mean_entropies: 2.0109, took: 127.5319s
2022-10-10 01:48:48,466 [INFO] 	Process 5 - batch 12399: mean_policy_losses: -92.394, mean_net_lifetime: 5024.2932, mean_mc_travel_dist: 2830.9401, mean_rewards: 167.1574, total_rewards: 2252.6078, mean_steps: 28.7500, mean_ecr: 0.0306 mean_entropies: 2.3659, took: 136.9648s
2022-10-10 01:49:25,765 [INFO] 	Process 3 - batch 12699: mean_policy_losses: 125.880, mean_net_lifetime: 4224.2800, mean_mc_travel_dist: 1772.6491, mean_rewards: 178.0090, total_rewards: 2475.3907, mean_steps: 22.8500, mean_ecr: 0.0477 mean_entropies: 1.8336, took: 114.1828s
2022-10-10 01:50:11,070 [INFO] 	Process 7 - batch 12499: mean_policy_losses: -142.678, mean_net_lifetime: 4170.4309, mean_mc_travel_dist: 1972.0144, mean_rewards: 145.5003, total_rewards: 2233.3245, mean_steps: 27.7200, mean_ecr: 0.0433 mean_entropies: 2.2190, took: 129.3526s
2022-10-10 01:50:46,779 [INFO] 	Process 2 - batch 12699: mean_policy_losses: 112.334, mean_net_lifetime: 4744.6269, mean_mc_travel_dist: 2197.9606, mean_rewards: 169.3571, total_rewards: 2573.8765, mean_steps: 27.1400, mean_ecr: 0.0404 mean_entropies: 2.0310, took: 125.6758s
2022-10-10 01:51:14,399 [INFO] 	Process 5 - batch 12499: mean_policy_losses: 2.210, mean_net_lifetime: 5363.3324, mean_mc_travel_dist: 2957.7485, mean_rewards: 168.2686, total_rewards: 2467.1895, mean_steps: 30.7600, mean_ecr: 0.0303 mean_entropies: 2.3922, took: 145.9323s
2022-10-10 01:51:17,899 [INFO] 	Process 1 - batch 10999: mean_policy_losses: -143.502, mean_net_lifetime: 4606.0452, mean_mc_travel_dist: 2338.3156, mean_rewards: 106.1557, total_rewards: 2291.9784, mean_steps: 42.7900, mean_ecr: 0.0397 mean_entropies: 1.7520, took: 196.9201s
2022-10-10 01:51:22,575 [INFO] 	Process 3 - batch 12799: mean_policy_losses: 20.443, mean_net_lifetime: 3996.2149, mean_mc_travel_dist: 1730.4033, mean_rewards: 165.4448, total_rewards: 2289.1115, mean_steps: 23.3200, mean_ecr: 0.0477 mean_entropies: 1.8308, took: 116.8096s
2022-10-10 01:52:12,989 [INFO] 	Process 7 - batch 12599: mean_policy_losses: -110.066, mean_net_lifetime: 4141.0926, mean_mc_travel_dist: 1988.2995, mean_rewards: 151.2433, total_rewards: 2205.7880, mean_steps: 26.3000, mean_ecr: 0.0430 mean_entropies: 2.2528, took: 121.9192s
2022-10-10 01:52:56,888 [INFO] 	Process 2 - batch 12799: mean_policy_losses: 163.052, mean_net_lifetime: 4948.6340, mean_mc_travel_dist: 2261.9113, mean_rewards: 169.5778, total_rewards: 2716.5068, mean_steps: 28.2800, mean_ecr: 0.0402 mean_entropies: 1.9978, took: 130.1086s
2022-10-10 01:53:15,662 [INFO] 	Process 3 - batch 12899: mean_policy_losses: 12.367, mean_net_lifetime: 4011.9829, mean_mc_travel_dist: 1740.7670, mean_rewards: 168.3764, total_rewards: 2297.5796, mean_steps: 23.0000, mean_ecr: 0.0478 mean_entropies: 1.7886, took: 113.0877s
2022-10-10 01:53:35,125 [INFO] 	Process 5 - batch 12599: mean_policy_losses: 33.379, mean_net_lifetime: 5368.4047, mean_mc_travel_dist: 2900.3796, mean_rewards: 172.6610, total_rewards: 2511.3680, mean_steps: 29.9200, mean_ecr: 0.0308 mean_entropies: 2.3434, took: 140.7261s
2022-10-10 01:53:59,838 [INFO] Process 4 - epoch 10: mean_policy_losses: -29.535, mean_net_lifetime: 2677.8074, mean_mc_travel_dist: 1241.8775, mean_entropies: 1.9921, m_net_lifetime_valid: 3000.4824, took: 2310.3872s, (186.2573 / 100 batches)

2022-10-10 01:54:03,947 [INFO] 	Process 7 - batch 12699: mean_policy_losses: -228.801, mean_net_lifetime: 3829.2644, mean_mc_travel_dist: 1927.9446, mean_rewards: 156.0203, total_rewards: 1958.5125, mean_steps: 23.5000, mean_ecr: 0.0432 mean_entropies: 2.2405, took: 110.9579s
2022-10-10 01:54:34,296 [INFO] 	Process 1 - batch 11099: mean_policy_losses: -111.855, mean_net_lifetime: 4619.9330, mean_mc_travel_dist: 2337.4860, mean_rewards: 107.4598, total_rewards: 2308.3760, mean_steps: 42.3700, mean_ecr: 0.0397 mean_entropies: 1.7858, took: 196.3966s
2022-10-10 01:55:06,062 [INFO] 	Process 2 - batch 12899: mean_policy_losses: 203.082, mean_net_lifetime: 4804.2053, mean_mc_travel_dist: 2221.8000, mean_rewards: 169.5563, total_rewards: 2612.1551, mean_steps: 27.4800, mean_ecr: 0.0404 mean_entropies: 2.0181, took: 129.1743s
2022-10-10 01:55:11,905 [INFO] 	Process 3 - batch 12999: mean_policy_losses: 122.343, mean_net_lifetime: 4065.5124, mean_mc_travel_dist: 1761.8261, mean_rewards: 169.3744, total_rewards: 2330.9115, mean_steps: 23.1000, mean_ecr: 0.0473 mean_entropies: 1.8382, took: 116.2424s
2022-10-10 01:55:21,415 [INFO] 	Process 4 - batch 15099: mean_policy_losses: -315.298, mean_net_lifetime: 2570.1380, mean_mc_travel_dist: 1221.3206, mean_rewards: 152.4827, total_rewards: 1368.7000, mean_steps: 15.9700, mean_ecr: 0.0525 mean_entropies: 2.0995, took: 1201.6373s
2022-10-10 01:55:56,513 [INFO] 	Process 5 - batch 12699: mean_policy_losses: 159.839, mean_net_lifetime: 5353.2899, mean_mc_travel_dist: 2897.5150, mean_rewards: 174.5170, total_rewards: 2501.4235, mean_steps: 29.5800, mean_ecr: 0.0307 mean_entropies: 2.3780, took: 141.3887s
2022-10-10 01:55:56,809 [INFO] 	Process 7 - batch 12799: mean_policy_losses: -79.951, mean_net_lifetime: 3805.4888, mean_mc_travel_dist: 1920.4324, mean_rewards: 156.8230, total_rewards: 1943.7283, mean_steps: 23.2100, mean_ecr: 0.0432 mean_entropies: 2.2775, took: 112.8624s
2022-10-10 01:56:44,799 [INFO] 	Process 4 - batch 15199: mean_policy_losses: -154.184, mean_net_lifetime: 2801.4014, mean_mc_travel_dist: 1265.0626, mean_rewards: 162.1215, total_rewards: 1553.6631, mean_steps: 16.4300, mean_ecr: 0.0521 mean_entropies: 2.1101, took: 83.3849s
2022-10-10 01:56:53,320 [INFO] Process 6 - epoch 13: mean_policy_losses: -331.635, mean_net_lifetime: 1922.7791, mean_mc_travel_dist: 1049.9599, mean_entropies: 1.7332, m_net_lifetime_valid: 3116.7952, took: 2114.7054s, (144.4771 / 100 batches)

2022-10-10 01:57:11,661 [INFO] 	Process 2 - batch 12999: mean_policy_losses: 151.528, mean_net_lifetime: 4339.5649, mean_mc_travel_dist: 2000.8707, mean_rewards: 161.1796, total_rewards: 2366.5772, mean_steps: 25.9600, mean_ecr: 0.0411 mean_entropies: 1.9342, took: 125.5989s
2022-10-10 01:57:16,151 [INFO] 	Process 3 - batch 13099: mean_policy_losses: 143.609, mean_net_lifetime: 4046.6339, mean_mc_travel_dist: 1744.0731, mean_rewards: 161.9277, total_rewards: 2318.3482, mean_steps: 24.2700, mean_ecr: 0.0475 mean_entropies: 1.7314, took: 124.2459s
2022-10-10 01:57:50,123 [INFO] 	Process 1 - batch 11199: mean_policy_losses: 43.427, mean_net_lifetime: 4712.0784, mean_mc_travel_dist: 2358.2364, mean_rewards: 116.1701, total_rewards: 2380.3392, mean_steps: 40.0500, mean_ecr: 0.0398 mean_entropies: 1.7811, took: 195.8281s
2022-10-10 01:57:55,271 [INFO] 	Process 7 - batch 12899: mean_policy_losses: 1.974, mean_net_lifetime: 3855.9119, mean_mc_travel_dist: 1891.5795, mean_rewards: 153.3888, total_rewards: 2009.9629, mean_steps: 24.2000, mean_ecr: 0.0433 mean_entropies: 2.2337, took: 118.4616s
2022-10-10 01:57:56,837 [INFO] 	Process 6 - batch 19599: mean_policy_losses: -342.868, mean_net_lifetime: 2147.5520, mean_mc_travel_dist: 1083.9841, mean_rewards: 176.0187, total_rewards: 1106.2394, mean_steps: 11.2900, mean_ecr: 0.0567 mean_entropies: 1.3360, took: 1164.0441s
2022-10-10 01:58:09,934 [INFO] 	Process 4 - batch 15299: mean_policy_losses: 45.243, mean_net_lifetime: 2927.6160, mean_mc_travel_dist: 1265.2698, mean_rewards: 171.7748, total_rewards: 1680.2026, mean_steps: 16.2100, mean_ecr: 0.0521 mean_entropies: 2.1351, took: 85.1352s
2022-10-10 01:58:32,697 [INFO] 	Process 5 - batch 12799: mean_policy_losses: 170.827, mean_net_lifetime: 5400.3245, mean_mc_travel_dist: 2972.0240, mean_rewards: 162.3175, total_rewards: 2480.5476, mean_steps: 31.8700, mean_ecr: 0.0299 mean_entropies: 2.2279, took: 156.1837s
2022-10-10 01:59:04,371 [INFO] 	Process 6 - batch 19699: mean_policy_losses: -266.492, mean_net_lifetime: 2361.9761, mean_mc_travel_dist: 1125.7988, mean_rewards: 184.4589, total_rewards: 1268.2044, mean_steps: 11.8400, mean_ecr: 0.0565 mean_entropies: 1.1834, took: 67.5344s
2022-10-10 01:59:23,400 [INFO] 	Process 3 - batch 13199: mean_policy_losses: 100.140, mean_net_lifetime: 3751.7459, mean_mc_travel_dist: 1671.0935, mean_rewards: 144.6293, total_rewards: 2098.1116, mean_steps: 25.1400, mean_ecr: 0.0479 mean_entropies: 1.4855, took: 127.2495s
2022-10-10 01:59:25,859 [INFO] 	Process 2 - batch 13099: mean_policy_losses: 83.080, mean_net_lifetime: 3939.0479, mean_mc_travel_dist: 1880.5360, mean_rewards: 139.4424, total_rewards: 2087.7496, mean_steps: 27.2100, mean_ecr: 0.0413 mean_entropies: 1.6134, took: 134.1972s
2022-10-10 01:59:33,537 [INFO] 	Process 4 - batch 15399: mean_policy_losses: 121.611, mean_net_lifetime: 3074.7263, mean_mc_travel_dist: 1324.4130, mean_rewards: 184.2697, total_rewards: 1771.0768, mean_steps: 15.7500, mean_ecr: 0.0519 mean_entropies: 2.1362, took: 83.6024s
2022-10-10 01:59:43,984 [INFO] 	Process 7 - batch 12999: mean_policy_losses: -23.351, mean_net_lifetime: 3671.9646, mean_mc_travel_dist: 1885.8134, mean_rewards: 160.8261, total_rewards: 1834.3550, mean_steps: 21.8000, mean_ecr: 0.0431 mean_entropies: 2.2619, took: 108.7128s
2022-10-10 02:00:16,374 [INFO] 	Process 6 - batch 19799: mean_policy_losses: -159.855, mean_net_lifetime: 2456.8653, mean_mc_travel_dist: 1152.7278, mean_rewards: 178.7718, total_rewards: 1335.4231, mean_steps: 12.7500, mean_ecr: 0.0565 mean_entropies: 1.1326, took: 72.0026s
2022-10-10 02:01:02,345 [INFO] 	Process 4 - batch 15499: mean_policy_losses: 169.940, mean_net_lifetime: 3242.1622, mean_mc_travel_dist: 1330.6947, mean_rewards: 184.9723, total_rewards: 1924.3094, mean_steps: 16.6100, mean_ecr: 0.0516 mean_entropies: 2.0923, took: 88.8081s
2022-10-10 02:01:07,654 [INFO] 	Process 5 - batch 12899: mean_policy_losses: 13.879, mean_net_lifetime: 4871.5587, mean_mc_travel_dist: 2794.4326, mean_rewards: 149.2635, total_rewards: 2142.4677, mean_steps: 30.9700, mean_ecr: 0.0296 mean_entropies: 2.0573, took: 154.9567s
2022-10-10 02:01:18,384 [INFO] 	Process 1 - batch 11299: mean_policy_losses: 38.074, mean_net_lifetime: 4626.9817, mean_mc_travel_dist: 2402.4390, mean_rewards: 108.6588, total_rewards: 2250.7925, mean_steps: 42.0300, mean_ecr: 0.0397 mean_entropies: 1.5719, took: 208.2598s
2022-10-10 02:01:28,467 [INFO] 	Process 6 - batch 19899: mean_policy_losses: -195.273, mean_net_lifetime: 2557.1499, mean_mc_travel_dist: 1174.6420, mean_rewards: 181.3355, total_rewards: 1412.4209, mean_steps: 13.1400, mean_ecr: 0.0567 mean_entropies: 1.1151, took: 72.0923s
2022-10-10 02:01:34,245 [INFO] 	Process 3 - batch 13299: mean_policy_losses: 80.209, mean_net_lifetime: 3774.5424, mean_mc_travel_dist: 1678.5661, mean_rewards: 141.7637, total_rewards: 2117.4183, mean_steps: 25.8700, mean_ecr: 0.0480 mean_entropies: 1.3892, took: 130.8446s
2022-10-10 02:01:39,422 [INFO] 	Process 2 - batch 13199: mean_policy_losses: -17.032, mean_net_lifetime: 3631.7898, mean_mc_travel_dist: 1758.4992, mean_rewards: 129.8604, total_rewards: 1898.9234, mean_steps: 26.9200, mean_ecr: 0.0417 mean_entropies: 1.4668, took: 133.5632s
2022-10-10 02:01:39,584 [INFO] 	Process 7 - batch 13099: mean_policy_losses: 23.925, mean_net_lifetime: 3869.1996, mean_mc_travel_dist: 1915.6256, mean_rewards: 159.8346, total_rewards: 1992.5933, mean_steps: 23.0100, mean_ecr: 0.0431 mean_entropies: 2.2410, took: 115.6001s
2022-10-10 02:02:28,827 [INFO] 	Process 4 - batch 15599: mean_policy_losses: 195.293, mean_net_lifetime: 3359.6171, mean_mc_travel_dist: 1376.8409, mean_rewards: 194.4828, total_rewards: 2007.6968, mean_steps: 16.3200, mean_ecr: 0.0512 mean_entropies: 2.1261, took: 86.4823s
2022-10-10 02:02:39,702 [INFO] 	Process 6 - batch 19999: mean_policy_losses: -188.234, mean_net_lifetime: 2480.1015, mean_mc_travel_dist: 1169.4709, mean_rewards: 181.9930, total_rewards: 1355.8722, mean_steps: 12.6600, mean_ecr: 0.0565 mean_entropies: 1.0886, took: 71.2347s
2022-10-10 02:03:35,339 [INFO] 	Process 5 - batch 12999: mean_policy_losses: -181.231, mean_net_lifetime: 4254.6500, mean_mc_travel_dist: 2542.7704, mean_rewards: 136.7039, total_rewards: 1780.5068, mean_steps: 29.1100, mean_ecr: 0.0298 mean_entropies: 2.0052, took: 147.6843s
2022-10-10 02:03:44,749 [INFO] 	Process 7 - batch 13199: mean_policy_losses: 146.562, mean_net_lifetime: 4138.6915, mean_mc_travel_dist: 1990.8143, mean_rewards: 157.9693, total_rewards: 2188.4083, mean_steps: 25.1200, mean_ecr: 0.0431 mean_entropies: 2.2018, took: 125.1654s
2022-10-10 02:03:52,171 [INFO] 	Process 3 - batch 13399: mean_policy_losses: 58.352, mean_net_lifetime: 3759.9198, mean_mc_travel_dist: 1656.9827, mean_rewards: 132.3382, total_rewards: 2125.9998, mean_steps: 27.6600, mean_ecr: 0.0482 mean_entropies: 1.3306, took: 137.9255s
2022-10-10 02:03:52,881 [INFO] 	Process 2 - batch 13299: mean_policy_losses: -33.581, mean_net_lifetime: 3577.6487, mean_mc_travel_dist: 1763.8977, mean_rewards: 128.9605, total_rewards: 1842.3233, mean_steps: 26.7300, mean_ecr: 0.0417 mean_entropies: 1.3852, took: 133.4597s
2022-10-10 02:03:53,012 [INFO] 	Process 6 - batch 20099: mean_policy_losses: -161.227, mean_net_lifetime: 2543.9844, mean_mc_travel_dist: 1183.5691, mean_rewards: 180.8042, total_rewards: 1391.0510, mean_steps: 13.0700, mean_ecr: 0.0566 mean_entropies: 1.0360, took: 73.3107s
2022-10-10 02:03:55,735 [INFO] 	Process 4 - batch 15699: mean_policy_losses: 202.242, mean_net_lifetime: 3341.8493, mean_mc_travel_dist: 1404.6291, mean_rewards: 192.9162, total_rewards: 1961.4669, mean_steps: 16.2600, mean_ecr: 0.0513 mean_entropies: 2.0801, took: 86.9080s
2022-10-10 02:04:24,390 [INFO] 	Process 1 - batch 11399: mean_policy_losses: 45.928, mean_net_lifetime: 4561.8463, mean_mc_travel_dist: 2375.5540, mean_rewards: 116.7045, total_rewards: 2210.9549, mean_steps: 38.5900, mean_ecr: 0.0398 mean_entropies: 1.5572, took: 186.0065s
2022-10-10 02:05:02,757 [INFO] 	Process 6 - batch 20199: mean_policy_losses: -216.635, mean_net_lifetime: 2597.9239, mean_mc_travel_dist: 1179.4154, mean_rewards: 190.5051, total_rewards: 1442.8151, mean_steps: 12.6600, mean_ecr: 0.0562 mean_entropies: 1.1258, took: 69.7448s
2022-10-10 02:05:21,142 [INFO] 	Process 4 - batch 15799: mean_policy_losses: 5.731, mean_net_lifetime: 3082.8020, mean_mc_travel_dist: 1330.0944, mean_rewards: 186.8064, total_rewards: 1777.1219, mean_steps: 15.5100, mean_ecr: 0.0515 mean_entropies: 2.1431, took: 85.4069s
2022-10-10 02:05:40,914 [INFO] 	Process 7 - batch 13299: mean_policy_losses: 83.915, mean_net_lifetime: 4078.5768, mean_mc_travel_dist: 1976.7646, mean_rewards: 170.4034, total_rewards: 2154.7893, mean_steps: 22.9000, mean_ecr: 0.0430 mean_entropies: 2.2483, took: 116.1649s
2022-10-10 02:06:06,369 [INFO] 	Process 3 - batch 13499: mean_policy_losses: 29.166, mean_net_lifetime: 3730.0956, mean_mc_travel_dist: 1658.5809, mean_rewards: 137.7070, total_rewards: 2092.7539, mean_steps: 26.3600, mean_ecr: 0.0481 mean_entropies: 1.3861, took: 134.1988s
2022-10-10 02:06:10,319 [INFO] 	Process 5 - batch 13099: mean_policy_losses: -28.955, mean_net_lifetime: 4874.1698, mean_mc_travel_dist: 2849.9963, mean_rewards: 149.5033, total_rewards: 2097.7311, mean_steps: 31.1800, mean_ecr: 0.0294 mean_entropies: 2.0349, took: 154.9808s
2022-10-10 02:06:10,561 [INFO] 	Process 2 - batch 13399: mean_policy_losses: 3.015, mean_net_lifetime: 3845.3043, mean_mc_travel_dist: 1833.6228, mean_rewards: 136.2977, total_rewards: 2037.6409, mean_steps: 27.2400, mean_ecr: 0.0415 mean_entropies: 1.4820, took: 137.6798s
2022-10-10 02:06:11,437 [INFO] 	Process 6 - batch 20299: mean_policy_losses: -234.926, mean_net_lifetime: 2586.6690, mean_mc_travel_dist: 1193.7499, mean_rewards: 190.2805, total_rewards: 1435.8693, mean_steps: 12.6300, mean_ecr: 0.0562 mean_entropies: 1.1237, took: 68.6805s
2022-10-10 02:06:45,183 [INFO] 	Process 4 - batch 15899: mean_policy_losses: 141.610, mean_net_lifetime: 3297.6291, mean_mc_travel_dist: 1370.0917, mean_rewards: 193.1578, total_rewards: 1952.2384, mean_steps: 15.9700, mean_ecr: 0.0510 mean_entropies: 2.1419, took: 84.0407s
2022-10-10 02:07:20,260 [INFO] 	Process 6 - batch 20399: mean_policy_losses: -202.899, mean_net_lifetime: 2608.1264, mean_mc_travel_dist: 1208.7165, mean_rewards: 184.6475, total_rewards: 1446.2450, mean_steps: 13.1200, mean_ecr: 0.0565 mean_entropies: 1.0325, took: 68.8231s
2022-10-10 02:07:34,425 [INFO] 	Process 7 - batch 13399: mean_policy_losses: 84.958, mean_net_lifetime: 4032.4529, mean_mc_travel_dist: 1977.5186, mean_rewards: 168.4216, total_rewards: 2106.0192, mean_steps: 22.6200, mean_ecr: 0.0429 mean_entropies: 2.2309, took: 113.5094s
2022-10-10 02:07:38,263 [INFO] 	Process 1 - batch 11499: mean_policy_losses: 21.253, mean_net_lifetime: 4590.3084, mean_mc_travel_dist: 2377.5596, mean_rewards: 114.3764, total_rewards: 2237.6484, mean_steps: 39.5300, mean_ecr: 0.0398 mean_entropies: 1.5996, took: 193.8743s
2022-10-10 02:08:10,589 [INFO] 	Process 4 - batch 15999: mean_policy_losses: 345.494, mean_net_lifetime: 3761.0452, mean_mc_travel_dist: 1469.4857, mean_rewards: 215.6071, total_rewards: 2311.0154, mean_steps: 16.3700, mean_ecr: 0.0506 mean_entropies: 2.0659, took: 85.4065s
2022-10-10 02:08:22,746 [INFO] 	Process 2 - batch 13499: mean_policy_losses: -24.053, mean_net_lifetime: 3664.4124, mean_mc_travel_dist: 1790.3878, mean_rewards: 130.3011, total_rewards: 1906.3425, mean_steps: 27.1100, mean_ecr: 0.0416 mean_entropies: 1.3569, took: 132.1847s
2022-10-10 02:08:29,141 [INFO] 	Process 6 - batch 20499: mean_policy_losses: -123.630, mean_net_lifetime: 2656.7145, mean_mc_travel_dist: 1205.4230, mean_rewards: 186.1032, total_rewards: 1481.1294, mean_steps: 13.1800, mean_ecr: 0.0564 mean_entropies: 0.9799, took: 68.8805s
2022-10-10 02:08:31,429 [INFO] 	Process 5 - batch 13199: mean_policy_losses: -167.845, mean_net_lifetime: 4332.5288, mean_mc_travel_dist: 2573.4767, mean_rewards: 138.9719, total_rewards: 1815.5371, mean_steps: 29.4000, mean_ecr: 0.0297 mean_entropies: 1.9625, took: 141.1106s
2022-10-10 02:09:30,902 [INFO] 	Process 7 - batch 13499: mean_policy_losses: 69.249, mean_net_lifetime: 4199.3139, mean_mc_travel_dist: 2009.1194, mean_rewards: 165.3261, total_rewards: 2231.7969, mean_steps: 24.2100, mean_ecr: 0.0429 mean_entropies: 2.1932, took: 116.4788s
2022-10-10 02:09:36,006 [INFO] 	Process 4 - batch 16099: mean_policy_losses: 253.719, mean_net_lifetime: 3665.9675, mean_mc_travel_dist: 1478.8555, mean_rewards: 205.0168, total_rewards: 2208.5100, mean_steps: 16.8900, mean_ecr: 0.0505 mean_entropies: 2.0105, took: 85.4169s
2022-10-10 02:09:41,440 [INFO] 	Process 6 - batch 20599: mean_policy_losses: -177.389, mean_net_lifetime: 2563.0148, mean_mc_travel_dist: 1175.7375, mean_rewards: 175.8633, total_rewards: 1424.5497, mean_steps: 13.7200, mean_ecr: 0.0566 mean_entropies: 0.9045, took: 72.2989s
2022-10-10 02:10:33,563 [INFO] 	Process 1 - batch 11599: mean_policy_losses: -15.659, mean_net_lifetime: 4506.4873, mean_mc_travel_dist: 2392.3842, mean_rewards: 120.3779, total_rewards: 2144.2728, mean_steps: 37.0300, mean_ecr: 0.0398 mean_entropies: 1.5055, took: 175.2994s
2022-10-10 02:10:48,402 [INFO] 	Process 5 - batch 13299: mean_policy_losses: -325.129, mean_net_lifetime: 3692.4850, mean_mc_travel_dist: 2291.1736, mean_rewards: 119.2734, total_rewards: 1469.2385, mean_steps: 28.8000, mean_ecr: 0.0300 mean_entropies: 1.7438, took: 136.9724s
2022-10-10 02:10:54,233 [INFO] 	Process 6 - batch 20699: mean_policy_losses: -140.017, mean_net_lifetime: 2875.4780, mean_mc_travel_dist: 1253.8203, mean_rewards: 189.0632, total_rewards: 1656.0246, mean_steps: 14.2300, mean_ecr: 0.0557 mean_entropies: 0.8269, took: 72.7926s
2022-10-10 02:10:59,160 [INFO] 	Process 4 - batch 16199: mean_policy_losses: 310.795, mean_net_lifetime: 3850.0108, mean_mc_travel_dist: 1529.8854, mean_rewards: 210.9137, total_rewards: 2347.2810, mean_steps: 17.2600, mean_ecr: 0.0502 mean_entropies: 1.8617, took: 83.1533s
2022-10-10 02:12:08,470 [INFO] 	Process 6 - batch 20799: mean_policy_losses: -83.563, mean_net_lifetime: 3134.0351, mean_mc_travel_dist: 1316.2927, mean_rewards: 193.8123, total_rewards: 1841.8125, mean_steps: 15.1300, mean_ecr: 0.0555 mean_entropies: 0.7715, took: 74.2378s
2022-10-10 02:12:20,437 [INFO] 	Process 4 - batch 16299: mean_policy_losses: 210.697, mean_net_lifetime: 3828.9848, mean_mc_travel_dist: 1546.0503, mean_rewards: 210.1892, total_rewards: 2298.9044, mean_steps: 17.2100, mean_ecr: 0.0501 mean_entropies: 1.8037, took: 81.2778s
2022-10-10 02:12:54,725 [INFO] 	Process 5 - batch 13399: mean_policy_losses: -489.802, mean_net_lifetime: 3017.4487, mean_mc_travel_dist: 1962.9270, mean_rewards: 107.6122, total_rewards: 1109.4514, mean_steps: 26.2200, mean_ecr: 0.0304 mean_entropies: 1.6404, took: 126.3227s
2022-10-10 02:13:21,841 [INFO] 	Process 1 - batch 11699: mean_policy_losses: -37.310, mean_net_lifetime: 4523.4061, mean_mc_travel_dist: 2463.1814, mean_rewards: 122.7825, total_rewards: 2089.0149, mean_steps: 36.2300, mean_ecr: 0.0397 mean_entropies: 1.4187, took: 168.2780s
2022-10-10 02:13:26,825 [INFO] 	Process 6 - batch 20899: mean_policy_losses: -75.087, mean_net_lifetime: 3230.0358, mean_mc_travel_dist: 1354.9359, mean_rewards: 192.3058, total_rewards: 1903.5543, mean_steps: 15.9300, mean_ecr: 0.0554 mean_entropies: 0.7630, took: 78.3544s
2022-10-10 02:13:44,429 [INFO] 	Process 4 - batch 16399: mean_policy_losses: 278.736, mean_net_lifetime: 3996.2549, mean_mc_travel_dist: 1573.4073, mean_rewards: 214.0024, total_rewards: 2441.4512, mean_steps: 17.6800, mean_ecr: 0.0497 mean_entropies: 1.8330, took: 83.9913s
2022-10-10 02:14:46,366 [INFO] 	Process 6 - batch 20999: mean_policy_losses: -67.618, mean_net_lifetime: 3156.2190, mean_mc_travel_dist: 1324.8228, mean_rewards: 188.4825, total_rewards: 1854.5240, mean_steps: 15.8200, mean_ecr: 0.0554 mean_entropies: 0.7321, took: 79.5422s
2022-10-10 02:15:01,737 [INFO] 	Process 5 - batch 13499: mean_policy_losses: -435.654, mean_net_lifetime: 3249.1556, mean_mc_travel_dist: 2070.4692, mean_rewards: 111.1149, total_rewards: 1235.0554, mean_steps: 27.3000, mean_ecr: 0.0302 mean_entropies: 1.6099, took: 127.0115s
2022-10-10 02:15:10,768 [INFO] 	Process 4 - batch 16499: mean_policy_losses: 337.295, mean_net_lifetime: 4128.4471, mean_mc_travel_dist: 1594.2943, mean_rewards: 213.9865, total_rewards: 2569.3793, mean_steps: 18.2200, mean_ecr: 0.0496 mean_entropies: 1.7897, took: 86.3394s
2022-10-10 02:15:58,634 [INFO] 	Process 1 - batch 11799: mean_policy_losses: -36.064, mean_net_lifetime: 4505.5918, mean_mc_travel_dist: 2491.0084, mean_rewards: 125.4207, total_rewards: 2051.5818, mean_steps: 35.7200, mean_ecr: 0.0396 mean_entropies: 1.4244, took: 156.7928s
2022-10-10 02:18:01,773 [INFO] 	Process 1 - batch 11899: mean_policy_losses: 63.015, mean_net_lifetime: 4784.0705, mean_mc_travel_dist: 2545.8660, mean_rewards: 156.1027, total_rewards: 2274.3817, mean_steps: 29.8700, mean_ecr: 0.0394 mean_entropies: 1.9517, took: 123.1385s
2022-10-10 02:20:07,963 [INFO] 	Process 1 - batch 11999: mean_policy_losses: 121.475, mean_net_lifetime: 5079.3051, mean_mc_travel_dist: 2557.0100, mean_rewards: 162.6485, total_rewards: 2557.7513, mean_steps: 30.3400, mean_ecr: 0.0393 mean_entropies: 2.1666, took: 126.1907s
2022-10-10 02:23:27,210 [INFO] Process 3 - epoch 9: mean_policy_losses: 170.826, mean_net_lifetime: 3710.4594, mean_mc_travel_dist: 1665.6874, mean_entropies: 1.8568, m_net_lifetime_valid: 3354.8766, took: 2908.6255s, (220.3742 / 100 batches)

2022-10-10 02:25:04,478 [INFO] Process 2 - epoch 9: mean_policy_losses: 10.883, mean_net_lifetime: 3485.6861, mean_mc_travel_dist: 1768.2233, mean_entropies: 1.9334, m_net_lifetime_valid: 3391.8557, took: 2942.1236s, (221.3826 / 100 batches)

2022-10-10 02:25:11,605 [INFO] 	Process 3 - batch 13599: mean_policy_losses: 5.590, mean_net_lifetime: 3631.6444, mean_mc_travel_dist: 1629.5127, mean_rewards: 147.9233, total_rewards: 2026.0959, mean_steps: 23.6900, mean_ecr: 0.0480 mean_entropies: 1.5741, took: 1145.2364s
2022-10-10 02:25:54,527 [INFO] Process 7 - epoch 9: mean_policy_losses: 37.919, mean_net_lifetime: 3715.4450, mean_mc_travel_dist: 1837.6191, mean_entropies: 2.2863, m_net_lifetime_valid: 3259.9310, took: 2767.5053s, (221.8826 / 100 batches)

2022-10-10 02:26:59,081 [INFO] 	Process 2 - batch 13599: mean_policy_losses: 10.773, mean_net_lifetime: 4676.3228, mean_mc_travel_dist: 2199.0716, mean_rewards: 164.9086, total_rewards: 2505.2585, mean_steps: 27.5600, mean_ecr: 0.0404 mean_entropies: 2.0138, took: 1116.3356s
2022-10-10 02:27:00,795 [INFO] 	Process 3 - batch 13699: mean_policy_losses: 36.257, mean_net_lifetime: 4274.2844, mean_mc_travel_dist: 1806.5526, mean_rewards: 175.1360, total_rewards: 2487.1446, mean_steps: 23.6000, mean_ecr: 0.0472 mean_entropies: 1.8497, took: 109.1897s
2022-10-10 02:27:44,268 [INFO] 	Process 7 - batch 13599: mean_policy_losses: -285.270, mean_net_lifetime: 4009.3220, mean_mc_travel_dist: 1917.7982, mean_rewards: 151.4262, total_rewards: 2138.7095, mean_steps: 25.5500, mean_ecr: 0.0433 mean_entropies: 2.2562, took: 1093.3653s
2022-10-10 02:28:50,803 [INFO] 	Process 3 - batch 13799: mean_policy_losses: 8.884, mean_net_lifetime: 4249.8162, mean_mc_travel_dist: 1812.1968, mean_rewards: 173.9689, total_rewards: 2469.2644, mean_steps: 23.5700, mean_ecr: 0.0471 mean_entropies: 1.8933, took: 110.0068s
2022-10-10 02:28:56,449 [INFO] 	Process 2 - batch 13699: mean_policy_losses: 84.660, mean_net_lifetime: 4846.8597, mean_mc_travel_dist: 2236.2898, mean_rewards: 171.3034, total_rewards: 2641.7581, mean_steps: 27.4900, mean_ecr: 0.0403 mean_entropies: 2.0582, took: 117.3676s
2022-10-10 02:29:36,055 [INFO] 	Process 7 - batch 13699: mean_policy_losses: -283.276, mean_net_lifetime: 4013.5855, mean_mc_travel_dist: 1945.4866, mean_rewards: 147.9521, total_rewards: 2119.4249, mean_steps: 26.1000, mean_ecr: 0.0433 mean_entropies: 2.2607, took: 111.7872s
2022-10-10 02:30:37,610 [INFO] 	Process 3 - batch 13899: mean_policy_losses: 69.174, mean_net_lifetime: 4204.3434, mean_mc_travel_dist: 1793.0525, mean_rewards: 180.5888, total_rewards: 2433.0664, mean_steps: 22.4600, mean_ecr: 0.0474 mean_entropies: 1.8560, took: 106.8079s
2022-10-10 02:30:52,376 [INFO] 	Process 2 - batch 13799: mean_policy_losses: 42.332, mean_net_lifetime: 4655.1284, mean_mc_travel_dist: 2163.1817, mean_rewards: 167.5333, total_rewards: 2517.6845, mean_steps: 26.9600, mean_ecr: 0.0405 mean_entropies: 2.0232, took: 115.9267s
2022-10-10 02:30:52,404 [INFO] Process 6 - epoch 14: mean_policy_losses: -320.497, mean_net_lifetime: 1975.7036, mean_mc_travel_dist: 1061.1680, mean_entropies: 1.6816, m_net_lifetime_valid: 3180.1581, took: 2039.0827s, (144.5075 / 100 batches)

2022-10-10 02:31:13,509 [INFO] Process 4 - epoch 11: mean_policy_losses: -13.826, mean_net_lifetime: 2743.0289, mean_mc_travel_dist: 1256.7395, mean_entropies: 1.9954, m_net_lifetime_valid: 3096.6481, took: 2233.6699s, (183.8304 / 100 batches)

2022-10-10 02:31:31,104 [INFO] 	Process 7 - batch 13799: mean_policy_losses: -113.629, mean_net_lifetime: 4287.5809, mean_mc_travel_dist: 2026.4849, mean_rewards: 155.6606, total_rewards: 2307.5530, mean_steps: 26.5700, mean_ecr: 0.0431 mean_entropies: 2.2587, took: 115.0490s
2022-10-10 02:31:46,743 [INFO] 	Process 6 - batch 21099: mean_policy_losses: -592.361, mean_net_lifetime: 1950.2936, mean_mc_travel_dist: 996.9190, mean_rewards: 174.7427, total_rewards: 995.7951, mean_steps: 10.1200, mean_ecr: 0.0564 mean_entropies: 1.5169, took: 1020.3756s
2022-10-10 02:31:51,654 [INFO] Process 5 - epoch 9: mean_policy_losses: 6.677, mean_net_lifetime: 4118.1366, mean_mc_travel_dist: 2405.1412, mean_entropies: 2.4601, m_net_lifetime_valid: 3192.0355, took: 3148.3833s, (224.3155 / 100 batches)

2022-10-10 02:32:32,333 [INFO] 	Process 4 - batch 16599: mean_policy_losses: 142.247, mean_net_lifetime: 3234.0186, mean_mc_travel_dist: 1376.1243, mean_rewards: 196.0144, total_rewards: 1888.7756, mean_steps: 15.4700, mean_ecr: 0.0515 mean_entropies: 2.2803, took: 1041.5653s
2022-10-10 02:32:34,812 [INFO] 	Process 3 - batch 13999: mean_policy_losses: 198.905, mean_net_lifetime: 4152.7862, mean_mc_travel_dist: 1750.4634, mean_rewards: 169.9031, total_rewards: 2431.4363, mean_steps: 23.6500, mean_ecr: 0.0474 mean_entropies: 1.7394, took: 117.2023s
2022-10-10 02:32:48,314 [INFO] 	Process 6 - batch 21199: mean_policy_losses: -301.580, mean_net_lifetime: 2184.1544, mean_mc_travel_dist: 1084.4467, mean_rewards: 183.8517, total_rewards: 1133.3442, mean_steps: 10.9200, mean_ecr: 0.0568 mean_entropies: 1.3229, took: 61.5713s
2022-10-10 02:32:54,086 [INFO] 	Process 2 - batch 13899: mean_policy_losses: 137.387, mean_net_lifetime: 4226.9017, mean_mc_travel_dist: 1977.4537, mean_rewards: 154.7613, total_rewards: 2275.0988, mean_steps: 26.3300, mean_ecr: 0.0411 mean_entropies: 1.8027, took: 121.7105s
2022-10-10 02:33:29,131 [INFO] 	Process 7 - batch 13899: mean_policy_losses: -0.878, mean_net_lifetime: 3907.0883, mean_mc_travel_dist: 1934.1189, mean_rewards: 151.2067, total_rewards: 2021.5545, mean_steps: 24.7800, mean_ecr: 0.0433 mean_entropies: 2.2422, took: 118.0270s
2022-10-10 02:33:51,869 [INFO] 	Process 6 - batch 21299: mean_policy_losses: -327.288, mean_net_lifetime: 2383.3048, mean_mc_travel_dist: 1126.8214, mean_rewards: 188.3825, total_rewards: 1300.4041, mean_steps: 11.5300, mean_ecr: 0.0565 mean_entropies: 1.1584, took: 63.5552s
2022-10-10 02:33:55,647 [INFO] 	Process 4 - batch 16699: mean_policy_losses: 149.192, mean_net_lifetime: 3475.7204, mean_mc_travel_dist: 1417.4085, mean_rewards: 201.2746, total_rewards: 2074.2828, mean_steps: 16.2000, mean_ecr: 0.0511 mean_entropies: 2.1396, took: 83.3136s
2022-10-10 02:34:30,164 [INFO] 	Process 5 - batch 13599: mean_policy_losses: 55.988, mean_net_lifetime: 5285.0895, mean_mc_travel_dist: 3072.2062, mean_rewards: 156.8342, total_rewards: 2273.7246, mean_steps: 32.1900, mean_ecr: 0.0292 mean_entropies: 2.0668, took: 1168.4285s
2022-10-10 02:34:50,013 [INFO] 	Process 3 - batch 14099: mean_policy_losses: 76.350, mean_net_lifetime: 3933.6781, mean_mc_travel_dist: 1695.7185, mean_rewards: 145.4290, total_rewards: 2258.0631, mean_steps: 26.3200, mean_ecr: 0.0483 mean_entropies: 1.3919, took: 135.2010s
2022-10-10 02:34:58,541 [INFO] 	Process 6 - batch 21399: mean_policy_losses: -256.901, mean_net_lifetime: 2597.5906, mean_mc_travel_dist: 1181.9540, mean_rewards: 193.6574, total_rewards: 1455.3644, mean_steps: 12.3600, mean_ecr: 0.0563 mean_entropies: 1.0857, took: 66.6726s
2022-10-10 02:35:06,709 [INFO] 	Process 2 - batch 13999: mean_policy_losses: -0.386, mean_net_lifetime: 3928.7120, mean_mc_travel_dist: 1866.3742, mean_rewards: 135.5793, total_rewards: 2091.3689, mean_steps: 27.9500, mean_ecr: 0.0414 mean_entropies: 1.4449, took: 132.6230s
2022-10-10 02:35:17,196 [INFO] 	Process 4 - batch 16799: mean_policy_losses: 132.611, mean_net_lifetime: 3450.2087, mean_mc_travel_dist: 1424.6649, mean_rewards: 203.2532, total_rewards: 2050.2563, mean_steps: 15.9000, mean_ecr: 0.0505 mean_entropies: 2.0732, took: 81.5487s
2022-10-10 02:35:20,248 [INFO] 	Process 7 - batch 13999: mean_policy_losses: -29.426, mean_net_lifetime: 3958.9044, mean_mc_travel_dist: 1967.0233, mean_rewards: 163.1614, total_rewards: 2048.8244, mean_steps: 23.0400, mean_ecr: 0.0431 mean_entropies: 2.2077, took: 111.1172s
2022-10-10 02:36:11,660 [INFO] 	Process 6 - batch 21499: mean_policy_losses: -147.863, mean_net_lifetime: 2683.6098, mean_mc_travel_dist: 1211.7001, mean_rewards: 185.3278, total_rewards: 1513.3930, mean_steps: 13.5000, mean_ecr: 0.0566 mean_entropies: 0.9635, took: 73.1187s
2022-10-10 02:36:43,469 [INFO] 	Process 4 - batch 16899: mean_policy_losses: 192.057, mean_net_lifetime: 3666.8629, mean_mc_travel_dist: 1461.2209, mean_rewards: 204.6755, total_rewards: 2232.6782, mean_steps: 16.8800, mean_ecr: 0.0507 mean_entropies: 1.9850, took: 86.2731s
2022-10-10 02:37:06,903 [INFO] 	Process 3 - batch 14199: mean_policy_losses: 12.667, mean_net_lifetime: 3786.3922, mean_mc_travel_dist: 1674.0329, mean_rewards: 137.2523, total_rewards: 2130.4630, mean_steps: 26.8600, mean_ecr: 0.0482 mean_entropies: 1.2616, took: 136.8904s
2022-10-10 02:37:13,936 [INFO] 	Process 5 - batch 13699: mean_policy_losses: 56.987, mean_net_lifetime: 5493.8149, mean_mc_travel_dist: 3197.9542, mean_rewards: 158.2971, total_rewards: 2363.8812, mean_steps: 33.4400, mean_ecr: 0.0289 mean_entropies: 1.8805, took: 163.7717s
2022-10-10 02:37:17,031 [INFO] 	Process 2 - batch 14099: mean_policy_losses: -35.709, mean_net_lifetime: 3833.8071, mean_mc_travel_dist: 1831.0115, mean_rewards: 134.3794, total_rewards: 2032.6593, mean_steps: 27.5000, mean_ecr: 0.0416 mean_entropies: 1.3129, took: 130.3217s
2022-10-10 02:37:22,163 [INFO] 	Process 7 - batch 14099: mean_policy_losses: 46.285, mean_net_lifetime: 4310.3716, mean_mc_travel_dist: 2046.3907, mean_rewards: 159.9143, total_rewards: 2308.3732, mean_steps: 25.7600, mean_ecr: 0.0429 mean_entropies: 2.1376, took: 121.9148s
2022-10-10 02:37:26,134 [INFO] 	Process 6 - batch 21599: mean_policy_losses: -134.152, mean_net_lifetime: 2731.5408, mean_mc_travel_dist: 1205.6337, mean_rewards: 188.9370, total_rewards: 1556.4121, mean_steps: 13.4800, mean_ecr: 0.0564 mean_entropies: 0.9264, took: 74.4737s
2022-10-10 02:38:08,448 [INFO] 	Process 4 - batch 16999: mean_policy_losses: 240.348, mean_net_lifetime: 3711.0853, mean_mc_travel_dist: 1431.8405, mean_rewards: 209.6136, total_rewards: 2300.0917, mean_steps: 16.6300, mean_ecr: 0.0505 mean_entropies: 1.9612, took: 84.9787s
2022-10-10 02:38:23,484 [INFO] Process 1 - epoch 8: mean_policy_losses: 181.863, mean_net_lifetime: 4575.5109, mean_mc_travel_dist: 2389.1369, mean_entropies: 2.0569, m_net_lifetime_valid: 3227.7671, took: 3761.6811s, (254.6542 / 100 batches)

2022-10-10 02:38:37,034 [INFO] 	Process 6 - batch 21699: mean_policy_losses: -191.704, mean_net_lifetime: 2471.5253, mean_mc_travel_dist: 1151.5252, mean_rewards: 178.1925, total_rewards: 1358.8924, mean_steps: 12.8200, mean_ecr: 0.0566 mean_entropies: 0.9264, took: 70.8986s
2022-10-10 02:39:25,052 [INFO] 	Process 3 - batch 14299: mean_policy_losses: 40.268, mean_net_lifetime: 3810.7154, mean_mc_travel_dist: 1684.3489, mean_rewards: 141.3158, total_rewards: 2144.8875, mean_steps: 26.1800, mean_ecr: 0.0481 mean_entropies: 1.2501, took: 138.1484s
2022-10-10 02:39:25,985 [INFO] 	Process 7 - batch 14199: mean_policy_losses: 18.235, mean_net_lifetime: 4134.3753, mean_mc_travel_dist: 2027.9420, mean_rewards: 159.0625, total_rewards: 2158.8448, mean_steps: 25.0300, mean_ecr: 0.0429 mean_entropies: 2.1186, took: 123.8219s
2022-10-10 02:39:34,370 [INFO] 	Process 2 - batch 14199: mean_policy_losses: -22.257, mean_net_lifetime: 3864.0726, mean_mc_travel_dist: 1862.2356, mean_rewards: 135.2663, total_rewards: 2022.8291, mean_steps: 27.5600, mean_ecr: 0.0415 mean_entropies: 1.2823, took: 137.3387s
2022-10-10 02:39:38,099 [INFO] 	Process 4 - batch 17099: mean_policy_losses: 152.233, mean_net_lifetime: 3531.4073, mean_mc_travel_dist: 1420.0637, mean_rewards: 205.7458, total_rewards: 2139.0432, mean_steps: 16.1800, mean_ecr: 0.0508 mean_entropies: 1.9529, took: 89.6523s
2022-10-10 02:39:55,886 [INFO] 	Process 6 - batch 21799: mean_policy_losses: -173.838, mean_net_lifetime: 2652.7046, mean_mc_travel_dist: 1186.3544, mean_rewards: 186.6568, total_rewards: 1494.6301, mean_steps: 13.2400, mean_ecr: 0.0563 mean_entropies: 0.9374, took: 78.8533s
2022-10-10 02:40:02,200 [INFO] 	Process 5 - batch 13799: mean_policy_losses: -10.172, mean_net_lifetime: 5202.9419, mean_mc_travel_dist: 3072.6516, mean_rewards: 155.0725, total_rewards: 2188.2100, mean_steps: 32.2500, mean_ecr: 0.0290 mean_entropies: 1.8160, took: 168.2634s
2022-10-10 02:41:08,780 [INFO] 	Process 4 - batch 17199: mean_policy_losses: 274.384, mean_net_lifetime: 3811.9702, mean_mc_travel_dist: 1502.2234, mean_rewards: 212.9973, total_rewards: 2335.1069, mean_steps: 16.8000, mean_ecr: 0.0500 mean_entropies: 1.9198, took: 90.6807s
2022-10-10 02:41:10,843 [INFO] 	Process 6 - batch 21899: mean_policy_losses: -134.149, mean_net_lifetime: 2740.9627, mean_mc_travel_dist: 1225.9607, mean_rewards: 195.3841, total_rewards: 1546.2331, mean_steps: 12.9900, mean_ecr: 0.0562 mean_entropies: 0.8984, took: 74.9559s
2022-10-10 02:41:26,115 [INFO] 	Process 7 - batch 14299: mean_policy_losses: 40.699, mean_net_lifetime: 4179.2586, mean_mc_travel_dist: 2011.2044, mean_rewards: 168.7970, total_rewards: 2208.9558, mean_steps: 23.7200, mean_ecr: 0.0429 mean_entropies: 2.1427, took: 120.1307s
2022-10-10 02:41:44,945 [INFO] 	Process 3 - batch 14399: mean_policy_losses: 41.514, mean_net_lifetime: 3820.1669, mean_mc_travel_dist: 1671.6475, mean_rewards: 142.9021, total_rewards: 2173.2357, mean_steps: 26.0300, mean_ecr: 0.0481 mean_entropies: 1.2420, took: 139.8923s
2022-10-10 02:41:51,558 [INFO] 	Process 2 - batch 14299: mean_policy_losses: -63.084, mean_net_lifetime: 3673.9018, mean_mc_travel_dist: 1785.8485, mean_rewards: 128.0756, total_rewards: 1913.5612, mean_steps: 27.6200, mean_ecr: 0.0416 mean_entropies: 1.2555, took: 137.1884s
2022-10-10 02:42:13,031 [INFO] 	Process 1 - batch 12099: mean_policy_losses: -47.660, mean_net_lifetime: 4542.0753, mean_mc_travel_dist: 2387.8388, mean_rewards: 101.7419, total_rewards: 2187.1121, mean_steps: 44.3900, mean_ecr: 0.0399 mean_entropies: 1.3423, took: 1325.0680s
2022-10-10 02:42:25,149 [INFO] 	Process 6 - batch 21999: mean_policy_losses: -166.437, mean_net_lifetime: 2737.8968, mean_mc_travel_dist: 1220.9487, mean_rewards: 189.5718, total_rewards: 1548.8601, mean_steps: 13.3800, mean_ecr: 0.0563 mean_entropies: 0.9398, took: 74.3076s
2022-10-10 02:42:36,865 [INFO] 	Process 4 - batch 17299: mean_policy_losses: 284.553, mean_net_lifetime: 3887.4181, mean_mc_travel_dist: 1520.8509, mean_rewards: 217.3333, total_rewards: 2387.6694, mean_steps: 16.8300, mean_ecr: 0.0499 mean_entropies: 1.9568, took: 88.0844s
2022-10-10 02:42:53,294 [INFO] 	Process 5 - batch 13899: mean_policy_losses: -20.173, mean_net_lifetime: 5231.5434, mean_mc_travel_dist: 3067.6809, mean_rewards: 148.7198, total_rewards: 2220.8407, mean_steps: 33.6800, mean_ecr: 0.0290 mean_entropies: 1.8268, took: 171.0934s
2022-10-10 02:43:14,671 [INFO] 	Process 7 - batch 14399: mean_policy_losses: -24.736, mean_net_lifetime: 3852.4782, mean_mc_travel_dist: 1916.2123, mean_rewards: 168.7798, total_rewards: 1976.6506, mean_steps: 21.7400, mean_ecr: 0.0430 mean_entropies: 2.1595, took: 108.5551s
2022-10-10 02:43:41,116 [INFO] 	Process 6 - batch 22099: mean_policy_losses: -165.237, mean_net_lifetime: 2748.2034, mean_mc_travel_dist: 1219.6149, mean_rewards: 188.5251, total_rewards: 1559.9456, mean_steps: 13.6100, mean_ecr: 0.0563 mean_entropies: 0.8970, took: 75.9663s
2022-10-10 02:44:02,380 [INFO] 	Process 3 - batch 14499: mean_policy_losses: 4.759, mean_net_lifetime: 3705.3169, mean_mc_travel_dist: 1666.2191, mean_rewards: 137.0435, total_rewards: 2061.1125, mean_steps: 26.4100, mean_ecr: 0.0482 mean_entropies: 1.2312, took: 137.4355s
2022-10-10 02:44:04,000 [INFO] 	Process 2 - batch 14399: mean_policy_losses: -49.587, mean_net_lifetime: 3673.5675, mean_mc_travel_dist: 1765.8722, mean_rewards: 130.3967, total_rewards: 1933.6897, mean_steps: 27.0900, mean_ecr: 0.0417 mean_entropies: 1.2242, took: 132.4411s
2022-10-10 02:44:04,895 [INFO] 	Process 4 - batch 17399: mean_policy_losses: 322.197, mean_net_lifetime: 3947.8036, mean_mc_travel_dist: 1529.3107, mean_rewards: 221.5970, total_rewards: 2438.8826, mean_steps: 16.7600, mean_ecr: 0.0498 mean_entropies: 1.9054, took: 88.0297s
2022-10-10 02:44:53,950 [INFO] 	Process 6 - batch 22199: mean_policy_losses: -210.296, mean_net_lifetime: 2627.0696, mean_mc_travel_dist: 1183.9005, mean_rewards: 188.9533, total_rewards: 1468.8932, mean_steps: 12.9400, mean_ecr: 0.0564 mean_entropies: 0.9402, took: 72.8347s
2022-10-10 02:45:05,038 [INFO] 	Process 7 - batch 14499: mean_policy_losses: -112.654, mean_net_lifetime: 3811.8465, mean_mc_travel_dist: 1907.0718, mean_rewards: 163.6304, total_rewards: 1950.1005, mean_steps: 22.1400, mean_ecr: 0.0432 mean_entropies: 2.1554, took: 110.3675s
2022-10-10 02:45:32,180 [INFO] 	Process 4 - batch 17499: mean_policy_losses: 261.482, mean_net_lifetime: 3778.7980, mean_mc_travel_dist: 1470.6680, mean_rewards: 217.3478, total_rewards: 2333.1574, mean_steps: 16.3100, mean_ecr: 0.0502 mean_entropies: 1.9790, took: 87.2860s
2022-10-10 02:45:36,332 [INFO] 	Process 5 - batch 13999: mean_policy_losses: -39.429, mean_net_lifetime: 5102.5400, mean_mc_travel_dist: 3035.0084, mean_rewards: 152.5835, total_rewards: 2130.9637, mean_steps: 31.9900, mean_ecr: 0.0293 mean_entropies: 1.8371, took: 163.0389s
2022-10-10 02:45:56,096 [INFO] 	Process 1 - batch 12199: mean_policy_losses: -47.804, mean_net_lifetime: 4630.0029, mean_mc_travel_dist: 2422.5459, mean_rewards: 103.3487, total_rewards: 2237.0323, mean_steps: 44.4000, mean_ecr: 0.0398 mean_entropies: 1.3589, took: 223.0642s
2022-10-10 02:46:04,611 [INFO] 	Process 6 - batch 22299: mean_policy_losses: -166.482, mean_net_lifetime: 2646.8883, mean_mc_travel_dist: 1191.7618, mean_rewards: 191.0522, total_rewards: 1487.4020, mean_steps: 12.8600, mean_ecr: 0.0564 mean_entropies: 0.9633, took: 70.6615s
2022-10-10 02:46:14,899 [INFO] 	Process 3 - batch 14599: mean_policy_losses: 50.028, mean_net_lifetime: 3905.9021, mean_mc_travel_dist: 1718.3530, mean_rewards: 149.6295, total_rewards: 2212.1010, mean_steps: 25.2900, mean_ecr: 0.0483 mean_entropies: 1.3045, took: 132.5185s
2022-10-10 02:46:21,409 [INFO] 	Process 2 - batch 14499: mean_policy_losses: 39.354, mean_net_lifetime: 4210.7215, mean_mc_travel_dist: 1988.5206, mean_rewards: 147.2915, total_rewards: 2249.4916, mean_steps: 27.7000, mean_ecr: 0.0412 mean_entropies: 1.3804, took: 137.4088s
2022-10-10 02:46:57,418 [INFO] 	Process 7 - batch 14599: mean_policy_losses: -38.463, mean_net_lifetime: 4026.4705, mean_mc_travel_dist: 1987.4095, mean_rewards: 169.4272, total_rewards: 2094.0312, mean_steps: 22.6200, mean_ecr: 0.0429 mean_entropies: 2.1463, took: 112.3804s
2022-10-10 02:47:01,169 [INFO] 	Process 4 - batch 17599: mean_policy_losses: 278.680, mean_net_lifetime: 3916.1720, mean_mc_travel_dist: 1519.9193, mean_rewards: 219.5062, total_rewards: 2431.4153, mean_steps: 16.7500, mean_ecr: 0.0500 mean_entropies: 1.9138, took: 88.9881s
2022-10-10 02:47:20,893 [INFO] 	Process 6 - batch 22399: mean_policy_losses: -112.003, mean_net_lifetime: 2843.6117, mean_mc_travel_dist: 1235.9650, mean_rewards: 194.8341, total_rewards: 1641.5238, mean_steps: 13.6300, mean_ecr: 0.0564 mean_entropies: 0.8863, took: 76.2814s
2022-10-10 02:48:25,641 [INFO] 	Process 4 - batch 17699: mean_policy_losses: 163.238, mean_net_lifetime: 3669.3751, mean_mc_travel_dist: 1483.7847, mean_rewards: 214.1404, total_rewards: 2218.1175, mean_steps: 16.0800, mean_ecr: 0.0504 mean_entropies: 1.9480, took: 84.4719s
2022-10-10 02:48:28,518 [INFO] 	Process 5 - batch 14099: mean_policy_losses: 48.637, mean_net_lifetime: 5518.1632, mean_mc_travel_dist: 3230.1535, mean_rewards: 157.3848, total_rewards: 2343.9707, mean_steps: 33.8400, mean_ecr: 0.0289 mean_entropies: 1.8218, took: 172.1850s
2022-10-10 02:48:30,468 [INFO] 	Process 6 - batch 22499: mean_policy_losses: -220.810, mean_net_lifetime: 2528.6848, mean_mc_travel_dist: 1160.2762, mean_rewards: 190.9735, total_rewards: 1401.1358, mean_steps: 12.2700, mean_ecr: 0.0565 mean_entropies: 0.9355, took: 69.5742s
2022-10-10 02:48:31,707 [INFO] 	Process 3 - batch 14699: mean_policy_losses: 40.543, mean_net_lifetime: 3880.5347, mean_mc_travel_dist: 1713.3910, mean_rewards: 145.1400, total_rewards: 2188.5386, mean_steps: 25.9600, mean_ecr: 0.0481 mean_entropies: 1.2643, took: 136.8082s
2022-10-10 02:48:37,050 [INFO] 	Process 2 - batch 14599: mean_policy_losses: 44.576, mean_net_lifetime: 4163.3286, mean_mc_travel_dist: 1951.3722, mean_rewards: 145.5954, total_rewards: 2240.7832, mean_steps: 27.6800, mean_ecr: 0.0413 mean_entropies: 1.3233, took: 135.6424s
2022-10-10 02:48:49,259 [INFO] 	Process 7 - batch 14699: mean_policy_losses: -89.331, mean_net_lifetime: 3922.3039, mean_mc_travel_dist: 1919.0128, mean_rewards: 166.6372, total_rewards: 2047.9719, mean_steps: 22.5300, mean_ecr: 0.0431 mean_entropies: 2.1334, took: 111.8405s
2022-10-10 02:49:48,742 [INFO] 	Process 1 - batch 12299: mean_policy_losses: -86.888, mean_net_lifetime: 4560.4813, mean_mc_travel_dist: 2403.5351, mean_rewards: 98.7020, total_rewards: 2179.4535, mean_steps: 46.1200, mean_ecr: 0.0398 mean_entropies: 1.3235, took: 232.6465s
2022-10-10 02:49:51,519 [INFO] 	Process 4 - batch 17799: mean_policy_losses: 86.069, mean_net_lifetime: 3709.8687, mean_mc_travel_dist: 1451.9732, mean_rewards: 211.3262, total_rewards: 2273.0676, mean_steps: 16.5300, mean_ecr: 0.0507 mean_entropies: 1.9612, took: 85.8784s
2022-10-10 02:50:43,935 [INFO] 	Process 3 - batch 14799: mean_policy_losses: 66.646, mean_net_lifetime: 4209.8011, mean_mc_travel_dist: 1776.4890, mean_rewards: 167.4865, total_rewards: 2456.1038, mean_steps: 24.3700, mean_ecr: 0.0478 mean_entropies: 1.4111, took: 132.2279s
2022-10-10 02:50:46,738 [INFO] 	Process 2 - batch 14699: mean_policy_losses: 23.847, mean_net_lifetime: 4534.6845, mean_mc_travel_dist: 2151.4673, mean_rewards: 164.2011, total_rewards: 2419.1850, mean_steps: 26.7400, mean_ecr: 0.0407 mean_entropies: 1.5053, took: 129.6868s
2022-10-10 02:51:03,897 [INFO] 	Process 7 - batch 14799: mean_policy_losses: -109.839, mean_net_lifetime: 4294.4589, mean_mc_travel_dist: 2031.4333, mean_rewards: 149.7809, total_rewards: 2306.6663, mean_steps: 27.6400, mean_ecr: 0.0431 mean_entropies: 2.1180, took: 134.6364s
2022-10-10 02:51:18,400 [INFO] 	Process 4 - batch 17899: mean_policy_losses: 43.122, mean_net_lifetime: 3632.9784, mean_mc_travel_dist: 1458.4919, mean_rewards: 210.3456, total_rewards: 2209.4015, mean_steps: 16.1700, mean_ecr: 0.0505 mean_entropies: 2.0000, took: 86.8804s
2022-10-10 02:51:31,899 [INFO] 	Process 5 - batch 14199: mean_policy_losses: -36.328, mean_net_lifetime: 5715.1862, mean_mc_travel_dist: 3426.4051, mean_rewards: 156.2174, total_rewards: 2358.9476, mean_steps: 35.5500, mean_ecr: 0.0287 mean_entropies: 1.8515, took: 183.3798s
2022-10-10 02:52:43,705 [INFO] 	Process 4 - batch 17999: mean_policy_losses: 27.855, mean_net_lifetime: 3586.5740, mean_mc_travel_dist: 1431.2286, mean_rewards: 212.1977, total_rewards: 2190.3210, mean_steps: 15.7900, mean_ecr: 0.0508 mean_entropies: 1.9748, took: 85.3055s
2022-10-10 02:52:59,808 [INFO] 	Process 3 - batch 14899: mean_policy_losses: 51.883, mean_net_lifetime: 4162.5927, mean_mc_travel_dist: 1771.9459, mean_rewards: 164.1737, total_rewards: 2407.8840, mean_steps: 24.5400, mean_ecr: 0.0478 mean_entropies: 1.4080, took: 135.8727s
2022-10-10 02:53:00,155 [INFO] 	Process 2 - batch 14799: mean_policy_losses: 60.594, mean_net_lifetime: 4552.1576, mean_mc_travel_dist: 2088.5664, mean_rewards: 163.1071, total_rewards: 2487.7169, mean_steps: 27.0400, mean_ecr: 0.0409 mean_entropies: 1.4860, took: 133.4163s
2022-10-10 02:53:04,480 [INFO] 	Process 7 - batch 14899: mean_policy_losses: -98.213, mean_net_lifetime: 4214.1759, mean_mc_travel_dist: 2010.3469, mean_rewards: 163.7435, total_rewards: 2260.3197, mean_steps: 24.4600, mean_ecr: 0.0430 mean_entropies: 2.1422, took: 120.5852s
2022-10-10 02:53:41,966 [INFO] 	Process 1 - batch 12399: mean_policy_losses: -126.434, mean_net_lifetime: 4579.0454, mean_mc_travel_dist: 2351.1040, mean_rewards: 101.4726, total_rewards: 2250.5177, mean_steps: 44.7700, mean_ecr: 0.0399 mean_entropies: 1.3808, took: 233.2243s
2022-10-10 02:54:36,138 [INFO] 	Process 5 - batch 14299: mean_policy_losses: 46.107, mean_net_lifetime: 6023.3619, mean_mc_travel_dist: 3429.0268, mean_rewards: 163.7999, total_rewards: 2667.8154, mean_steps: 35.7600, mean_ecr: 0.0290 mean_entropies: 1.9443, took: 184.2404s
2022-10-10 02:54:52,679 [INFO] 	Process 7 - batch 14999: mean_policy_losses: -230.976, mean_net_lifetime: 3917.6741, mean_mc_travel_dist: 1922.1514, mean_rewards: 166.0088, total_rewards: 2057.2986, mean_steps: 22.4500, mean_ecr: 0.0432 mean_entropies: 2.1819, took: 108.1984s
2022-10-10 02:55:01,403 [INFO] 	Process 3 - batch 14999: mean_policy_losses: 100.293, mean_net_lifetime: 4257.5841, mean_mc_travel_dist: 1802.9854, mean_rewards: 183.2385, total_rewards: 2474.5650, mean_steps: 22.3800, mean_ecr: 0.0478 mean_entropies: 1.5548, took: 121.5955s
2022-10-10 02:55:07,558 [INFO] 	Process 2 - batch 14899: mean_policy_losses: 80.742, mean_net_lifetime: 4817.2821, mean_mc_travel_dist: 2259.7625, mean_rewards: 174.3325, total_rewards: 2589.0836, mean_steps: 26.8200, mean_ecr: 0.0403 mean_entropies: 1.6475, took: 127.4042s
2022-10-10 02:57:07,268 [INFO] 	Process 1 - batch 12499: mean_policy_losses: -161.458, mean_net_lifetime: 4674.7832, mean_mc_travel_dist: 2347.6920, mean_rewards: 110.5050, total_rewards: 2357.1499, mean_steps: 42.2000, mean_ecr: 0.0398 mean_entropies: 1.6282, took: 205.3011s
2022-10-10 02:57:09,501 [INFO] 	Process 5 - batch 14399: mean_policy_losses: 69.268, mean_net_lifetime: 6050.9652, mean_mc_travel_dist: 3270.4787, mean_rewards: 182.6634, total_rewards: 2837.8488, mean_steps: 31.7300, mean_ecr: 0.0298 mean_entropies: 2.1205, took: 153.3628s
2022-10-10 02:57:12,819 [INFO] 	Process 2 - batch 14999: mean_policy_losses: 107.834, mean_net_lifetime: 5055.6288, mean_mc_travel_dist: 2335.9814, mean_rewards: 170.4601, total_rewards: 2752.7560, mean_steps: 28.8300, mean_ecr: 0.0400 mean_entropies: 1.7045, took: 125.2620s
2022-10-10 02:59:12,788 [INFO] 	Process 5 - batch 14499: mean_policy_losses: 28.880, mean_net_lifetime: 5118.9184, mean_mc_travel_dist: 2741.0822, mean_rewards: 184.5305, total_rewards: 2433.7260, mean_steps: 26.3900, mean_ecr: 0.0310 mean_entropies: 2.2036, took: 123.2880s
2022-10-10 02:59:57,425 [INFO] 	Process 1 - batch 12599: mean_policy_losses: 63.087, mean_net_lifetime: 5202.3139, mean_mc_travel_dist: 2485.1389, mean_rewards: 136.0283, total_rewards: 2757.6427, mean_steps: 37.4200, mean_ecr: 0.0395 mean_entropies: 1.9326, took: 170.1573s
2022-10-10 03:01:12,502 [INFO] 	Process 5 - batch 14599: mean_policy_losses: -29.856, mean_net_lifetime: 5058.0077, mean_mc_travel_dist: 2751.4451, mean_rewards: 187.1331, total_rewards: 2376.0684, mean_steps: 25.5400, mean_ecr: 0.0308 mean_entropies: 2.2347, took: 119.7139s
2022-10-10 03:02:43,170 [INFO] 	Process 1 - batch 12699: mean_policy_losses: 23.651, mean_net_lifetime: 5171.3507, mean_mc_travel_dist: 2481.3077, mean_rewards: 137.9275, total_rewards: 2719.7713, mean_steps: 36.6100, mean_ecr: 0.0395 mean_entropies: 1.9594, took: 165.7455s
2022-10-10 03:03:16,926 [INFO] 	Process 5 - batch 14699: mean_policy_losses: 9.131, mean_net_lifetime: 5170.5139, mean_mc_travel_dist: 2778.7008, mean_rewards: 186.5710, total_rewards: 2451.2863, mean_steps: 26.3500, mean_ecr: 0.0311 mean_entropies: 2.2207, took: 124.4223s
2022-10-10 03:05:17,090 [INFO] 	Process 5 - batch 14799: mean_policy_losses: -5.558, mean_net_lifetime: 5139.1858, mean_mc_travel_dist: 2779.0343, mean_rewards: 190.9516, total_rewards: 2421.4977, mean_steps: 25.6200, mean_ecr: 0.0312 mean_entropies: 2.1672, took: 120.1652s
2022-10-10 03:05:32,631 [INFO] 	Process 1 - batch 12799: mean_policy_losses: 101.929, mean_net_lifetime: 5501.7669, mean_mc_travel_dist: 2588.9279, mean_rewards: 143.2707, total_rewards: 2949.2337, mean_steps: 37.4300, mean_ecr: 0.0392 mean_entropies: 1.9757, took: 169.4599s
2022-10-10 03:07:16,442 [INFO] 	Process 5 - batch 14899: mean_policy_losses: -71.819, mean_net_lifetime: 5183.2952, mean_mc_travel_dist: 2746.4398, mean_rewards: 190.8840, total_rewards: 2490.5978, mean_steps: 25.8700, mean_ecr: 0.0313 mean_entropies: 2.1692, took: 119.3521s
2022-10-10 03:08:06,590 [INFO] 	Process 1 - batch 12899: mean_policy_losses: 34.166, mean_net_lifetime: 5491.8788, mean_mc_travel_dist: 2595.5262, mean_rewards: 150.1478, total_rewards: 2926.9948, mean_steps: 35.5600, mean_ecr: 0.0392 mean_entropies: 2.0323, took: 153.9599s
2022-10-10 03:08:11,709 [INFO] Process 6 - epoch 15: mean_policy_losses: -313.802, mean_net_lifetime: 2015.2258, mean_mc_travel_dist: 1068.5736, mean_entropies: 1.6375, m_net_lifetime_valid: 3494.2798, took: 2239.3028s, (143.8725 / 100 batches)

2022-10-10 03:09:08,625 [INFO] 	Process 6 - batch 22599: mean_policy_losses: -365.489, mean_net_lifetime: 2196.7151, mean_mc_travel_dist: 1073.0625, mean_rewards: 174.9658, total_rewards: 1179.4408, mean_steps: 11.1800, mean_ecr: 0.0562 mean_entropies: 1.2354, took: 1238.1581s
2022-10-10 03:09:13,583 [INFO] 	Process 5 - batch 14999: mean_policy_losses: 56.288, mean_net_lifetime: 5248.1635, mean_mc_travel_dist: 2793.9265, mean_rewards: 188.5269, total_rewards: 2509.1048, mean_steps: 26.4700, mean_ecr: 0.0311 mean_entropies: 2.1766, took: 117.1413s
2022-10-10 03:09:33,495 [INFO] Process 4 - epoch 12: mean_policy_losses: 2.606, mean_net_lifetime: 2820.0557, mean_mc_travel_dist: 1273.6767, mean_entropies: 1.9955, m_net_lifetime_valid: 3463.4720, took: 2299.9848s, (181.0430 / 100 batches)

2022-10-10 03:10:15,133 [INFO] 	Process 6 - batch 22699: mean_policy_losses: -172.396, mean_net_lifetime: 2776.1727, mean_mc_travel_dist: 1224.3350, mean_rewards: 185.2767, total_rewards: 1578.7209, mean_steps: 13.7900, mean_ecr: 0.0556 mean_entropies: 1.0369, took: 66.5072s
2022-10-10 03:10:37,716 [INFO] 	Process 1 - batch 12999: mean_policy_losses: 134.135, mean_net_lifetime: 4985.6331, mean_mc_travel_dist: 2442.3532, mean_rewards: 142.0856, total_rewards: 2575.4465, mean_steps: 34.2600, mean_ecr: 0.0395 mean_entropies: 1.8691, took: 151.1263s
2022-10-10 03:10:46,238 [INFO] 	Process 4 - batch 18099: mean_policy_losses: -75.899, mean_net_lifetime: 3113.9136, mean_mc_travel_dist: 1309.0498, mean_rewards: 184.1907, total_rewards: 1841.6564, mean_steps: 15.8200, mean_ecr: 0.0510 mean_entropies: 1.8436, took: 1082.5332s
2022-10-10 03:11:28,733 [INFO] 	Process 6 - batch 22799: mean_policy_losses: -142.881, mean_net_lifetime: 3037.8292, mean_mc_travel_dist: 1290.1742, mean_rewards: 187.5065, total_rewards: 1778.1712, mean_steps: 15.2700, mean_ecr: 0.0558 mean_entropies: 0.7847, took: 73.6000s
2022-10-10 03:12:02,832 [INFO] 	Process 4 - batch 18199: mean_policy_losses: 163.553, mean_net_lifetime: 4056.1254, mean_mc_travel_dist: 1597.1370, mean_rewards: 225.3616, total_rewards: 2481.7078, mean_steps: 16.9200, mean_ecr: 0.0494 mean_entropies: 1.7463, took: 76.5944s
2022-10-10 03:12:15,346 [INFO] Process 7 - epoch 10: mean_policy_losses: 25.384, mean_net_lifetime: 3749.4998, mean_mc_travel_dist: 1850.9911, mean_entropies: 2.2754, m_net_lifetime_valid: 3607.9097, took: 2780.8171s, (217.8663 / 100 batches)

2022-10-10 03:12:42,769 [INFO] 	Process 6 - batch 22899: mean_policy_losses: -149.771, mean_net_lifetime: 3016.8898, mean_mc_travel_dist: 1286.2981, mean_rewards: 190.7843, total_rewards: 1754.9863, mean_steps: 14.8200, mean_ecr: 0.0558 mean_entropies: 0.7467, took: 74.0363s
2022-10-10 03:13:09,017 [INFO] 	Process 1 - batch 13099: mean_policy_losses: -77.772, mean_net_lifetime: 4578.0660, mean_mc_travel_dist: 2487.9623, mean_rewards: 134.2850, total_rewards: 2132.0675, mean_steps: 33.5900, mean_ecr: 0.0397 mean_entropies: 1.4589, took: 151.3008s
2022-10-10 03:13:27,248 [INFO] 	Process 4 - batch 18299: mean_policy_losses: 293.787, mean_net_lifetime: 4366.8836, mean_mc_travel_dist: 1718.6609, mean_rewards: 229.4686, total_rewards: 2676.9161, mean_steps: 17.9700, mean_ecr: 0.0487 mean_entropies: 1.6589, took: 84.4153s
2022-10-10 03:13:54,612 [INFO] 	Process 7 - batch 15099: mean_policy_losses: -185.224, mean_net_lifetime: 3916.9164, mean_mc_travel_dist: 1939.8699, mean_rewards: 167.6074, total_rewards: 2021.9549, mean_steps: 22.2700, mean_ecr: 0.0430 mean_entropies: 2.1168, took: 1141.9330s
2022-10-10 03:13:56,106 [INFO] Process 3 - epoch 10: mean_policy_losses: 159.102, mean_net_lifetime: 3739.3172, mean_mc_travel_dist: 1672.2314, mean_entropies: 1.8193, m_net_lifetime_valid: 3574.0203, took: 3028.8942s, (217.9200 / 100 batches)

2022-10-10 03:14:00,052 [INFO] 	Process 6 - batch 22999: mean_policy_losses: -90.374, mean_net_lifetime: 3153.1488, mean_mc_travel_dist: 1315.9893, mean_rewards: 191.5267, total_rewards: 1860.4589, mean_steps: 15.6000, mean_ecr: 0.0556 mean_entropies: 0.7083, took: 77.2837s
2022-10-10 03:14:50,187 [INFO] 	Process 4 - batch 18399: mean_policy_losses: 234.161, mean_net_lifetime: 4116.6811, mean_mc_travel_dist: 1617.6575, mean_rewards: 223.6910, total_rewards: 2524.5842, mean_steps: 17.3400, mean_ecr: 0.0494 mean_entropies: 1.6756, took: 82.9390s
2022-10-10 03:15:20,367 [INFO] 	Process 6 - batch 23099: mean_policy_losses: -96.836, mean_net_lifetime: 3094.5374, mean_mc_travel_dist: 1305.3885, mean_rewards: 196.7714, total_rewards: 1816.5211, mean_steps: 14.8900, mean_ecr: 0.0558 mean_entropies: 0.7079, took: 80.3122s
2022-10-10 03:15:40,986 [INFO] Process 2 - epoch 10: mean_policy_losses: 12.869, mean_net_lifetime: 3568.5380, mean_mc_travel_dist: 1794.4877, mean_entropies: 1.8965, m_net_lifetime_valid: 3581.1893, took: 3036.5064s, (218.7954 / 100 batches)

2022-10-10 03:15:44,601 [INFO] 	Process 7 - batch 15199: mean_policy_losses: -114.001, mean_net_lifetime: 4015.3654, mean_mc_travel_dist: 1980.1359, mean_rewards: 163.7138, total_rewards: 2072.4985, mean_steps: 23.3500, mean_ecr: 0.0430 mean_entropies: 2.0855, took: 109.9891s
2022-10-10 03:16:00,278 [INFO] 	Process 1 - batch 13199: mean_policy_losses: -60.489, mean_net_lifetime: 4502.5005, mean_mc_travel_dist: 2448.9402, mean_rewards: 126.3425, total_rewards: 2081.2172, mean_steps: 35.1800, mean_ecr: 0.0397 mean_entropies: 1.3591, took: 171.2605s
2022-10-10 03:16:19,390 [INFO] 	Process 4 - batch 18499: mean_policy_losses: 325.390, mean_net_lifetime: 4145.5382, mean_mc_travel_dist: 1567.8582, mean_rewards: 223.2213, total_rewards: 2596.5110, mean_steps: 17.5200, mean_ecr: 0.0495 mean_entropies: 1.7682, took: 89.2026s
2022-10-10 03:16:38,505 [INFO] 	Process 3 - batch 15099: mean_policy_losses: -59.309, mean_net_lifetime: 3667.3694, mean_mc_travel_dist: 1639.1172, mean_rewards: 114.6200, total_rewards: 2048.3024, mean_steps: 31.6700, mean_ecr: 0.0484 mean_entropies: 1.0174, took: 1297.1019s
2022-10-10 03:16:45,395 [INFO] 	Process 6 - batch 23199: mean_policy_losses: -46.474, mean_net_lifetime: 3053.7718, mean_mc_travel_dist: 1298.3488, mean_rewards: 194.5886, total_rewards: 1786.3367, mean_steps: 14.7100, mean_ecr: 0.0560 mean_entropies: 0.7531, took: 85.0297s
2022-10-10 03:17:47,071 [INFO] 	Process 4 - batch 18599: mean_policy_losses: 291.230, mean_net_lifetime: 3858.0398, mean_mc_travel_dist: 1482.1491, mean_rewards: 218.2446, total_rewards: 2399.2433, mean_steps: 16.6500, mean_ecr: 0.0503 mean_entropies: 1.8600, took: 87.6814s
2022-10-10 03:17:47,107 [INFO] 	Process 7 - batch 15299: mean_policy_losses: 67.790, mean_net_lifetime: 4346.0291, mean_mc_travel_dist: 2110.1759, mean_rewards: 166.8564, total_rewards: 2288.9998, mean_steps: 25.0800, mean_ecr: 0.0427 mean_entropies: 2.0892, took: 122.5064s
2022-10-10 03:17:55,519 [INFO] 	Process 2 - batch 15099: mean_policy_losses: -43.547, mean_net_lifetime: 3728.1926, mean_mc_travel_dist: 1792.1110, mean_rewards: 130.4720, total_rewards: 1962.9381, mean_steps: 27.5100, mean_ecr: 0.0417 mean_entropies: 1.1490, took: 1242.6991s
2022-10-10 03:18:01,852 [INFO] 	Process 6 - batch 23299: mean_policy_losses: -174.546, mean_net_lifetime: 2651.0287, mean_mc_travel_dist: 1186.3388, mean_rewards: 191.2036, total_rewards: 1492.2810, mean_steps: 12.8200, mean_ecr: 0.0564 mean_entropies: 0.8473, took: 76.4567s
2022-10-10 03:19:12,979 [INFO] 	Process 3 - batch 15199: mean_policy_losses: 32.896, mean_net_lifetime: 3944.3237, mean_mc_travel_dist: 1702.2830, mean_rewards: 136.7680, total_rewards: 2266.7203, mean_steps: 28.2700, mean_ecr: 0.0483 mean_entropies: 1.2068, took: 154.4726s
2022-10-10 03:19:17,177 [INFO] 	Process 6 - batch 23399: mean_policy_losses: -188.192, mean_net_lifetime: 2684.2496, mean_mc_travel_dist: 1192.2470, mean_rewards: 194.9719, total_rewards: 1523.3013, mean_steps: 12.6700, mean_ecr: 0.0563 mean_entropies: 0.9312, took: 75.3248s
2022-10-10 03:19:18,326 [INFO] 	Process 4 - batch 18699: mean_policy_losses: 280.455, mean_net_lifetime: 4039.3652, mean_mc_travel_dist: 1545.5500, mean_rewards: 220.6750, total_rewards: 2520.1118, mean_steps: 17.2900, mean_ecr: 0.0498 mean_entropies: 1.8782, took: 91.2556s
2022-10-10 03:19:24,294 [INFO] 	Process 1 - batch 13299: mean_policy_losses: -34.671, mean_net_lifetime: 4558.4440, mean_mc_travel_dist: 2342.9937, mean_rewards: 116.1831, total_rewards: 2254.8221, mean_steps: 38.6800, mean_ecr: 0.0400 mean_entropies: 1.3848, took: 204.0158s
2022-10-10 03:19:41,759 [INFO] 	Process 7 - batch 15399: mean_policy_losses: -45.433, mean_net_lifetime: 4156.8422, mean_mc_travel_dist: 2009.3529, mean_rewards: 170.9838, total_rewards: 2188.8975, mean_steps: 23.2200, mean_ecr: 0.0430 mean_entropies: 2.1338, took: 114.6507s
2022-10-10 03:20:09,210 [INFO] 	Process 2 - batch 15199: mean_policy_losses: 60.108, mean_net_lifetime: 4341.9673, mean_mc_travel_dist: 2013.9508, mean_rewards: 152.4041, total_rewards: 2358.1919, mean_steps: 27.5700, mean_ecr: 0.0412 mean_entropies: 1.3722, took: 133.6915s
2022-10-10 03:20:27,841 [INFO] 	Process 6 - batch 23499: mean_policy_losses: -235.859, mean_net_lifetime: 2404.5866, mean_mc_travel_dist: 1120.3144, mean_rewards: 187.5724, total_rewards: 1319.1433, mean_steps: 11.7400, mean_ecr: 0.0563 mean_entropies: 0.9864, took: 70.6643s
2022-10-10 03:20:44,539 [INFO] 	Process 4 - batch 18799: mean_policy_losses: 184.902, mean_net_lifetime: 3755.6138, mean_mc_travel_dist: 1474.4617, mean_rewards: 217.3446, total_rewards: 2301.4429, mean_steps: 16.1800, mean_ecr: 0.0503 mean_entropies: 1.9128, took: 86.2120s
2022-10-10 03:21:34,788 [INFO] 	Process 3 - batch 15299: mean_policy_losses: 75.998, mean_net_lifetime: 4090.1586, mean_mc_travel_dist: 1722.1505, mean_rewards: 154.6901, total_rewards: 2379.2525, mean_steps: 25.6900, mean_ecr: 0.0482 mean_entropies: 1.3125, took: 141.8105s
2022-10-10 03:21:37,052 [INFO] 	Process 7 - batch 15499: mean_policy_losses: -63.858, mean_net_lifetime: 4063.3391, mean_mc_travel_dist: 1994.8095, mean_rewards: 168.9360, total_rewards: 2113.7376, mean_steps: 23.1100, mean_ecr: 0.0429 mean_entropies: 2.1338, took: 115.2930s
2022-10-10 03:21:41,927 [INFO] 	Process 6 - batch 23599: mean_policy_losses: -192.850, mean_net_lifetime: 2671.5792, mean_mc_travel_dist: 1190.1143, mean_rewards: 199.2439, total_rewards: 1515.8395, mean_steps: 12.4000, mean_ecr: 0.0563 mean_entropies: 0.9664, took: 74.0857s
2022-10-10 03:22:15,990 [INFO] 	Process 4 - batch 18899: mean_policy_losses: 270.229, mean_net_lifetime: 4139.5027, mean_mc_travel_dist: 1600.0497, mean_rewards: 223.1622, total_rewards: 2557.9860, mean_steps: 17.4300, mean_ecr: 0.0495 mean_entropies: 1.8520, took: 91.4517s
2022-10-10 03:22:25,034 [INFO] 	Process 2 - batch 15299: mean_policy_losses: 66.017, mean_net_lifetime: 4454.2303, mean_mc_travel_dist: 2061.0076, mean_rewards: 154.9327, total_rewards: 2420.3141, mean_steps: 27.8500, mean_ecr: 0.0411 mean_entropies: 1.3561, took: 135.8230s
2022-10-10 03:22:55,048 [INFO] 	Process 1 - batch 13399: mean_policy_losses: -61.061, mean_net_lifetime: 4566.6312, mean_mc_travel_dist: 2363.8273, mean_rewards: 113.4813, total_rewards: 2227.9243, mean_steps: 40.0200, mean_ecr: 0.0399 mean_entropies: 1.4255, took: 210.7547s
2022-10-10 03:22:55,269 [INFO] 	Process 6 - batch 23699: mean_policy_losses: -168.395, mean_net_lifetime: 2728.1040, mean_mc_travel_dist: 1186.0459, mean_rewards: 203.9569, total_rewards: 1571.2156, mean_steps: 12.3400, mean_ecr: 0.0565 mean_entropies: 0.9709, took: 73.3428s
2022-10-10 03:23:25,803 [INFO] 	Process 7 - batch 15599: mean_policy_losses: -194.211, mean_net_lifetime: 3858.2688, mean_mc_travel_dist: 1933.4501, mean_rewards: 168.8135, total_rewards: 1971.2854, mean_steps: 21.6100, mean_ecr: 0.0431 mean_entropies: 2.1503, took: 108.7520s
2022-10-10 03:23:42,307 [INFO] 	Process 4 - batch 18999: mean_policy_losses: 138.605, mean_net_lifetime: 3761.6010, mean_mc_travel_dist: 1494.7585, mean_rewards: 218.4246, total_rewards: 2294.1750, mean_steps: 16.1200, mean_ecr: 0.0501 mean_entropies: 1.9083, took: 86.3163s
2022-10-10 03:23:48,276 [INFO] 	Process 3 - batch 15399: mean_policy_losses: 92.505, mean_net_lifetime: 4129.3407, mean_mc_travel_dist: 1755.5419, mean_rewards: 166.3305, total_rewards: 2392.5149, mean_steps: 24.0400, mean_ecr: 0.0481 mean_entropies: 1.3620, took: 133.4868s
2022-10-10 03:24:07,078 [INFO] 	Process 6 - batch 23799: mean_policy_losses: -249.686, mean_net_lifetime: 2601.4926, mean_mc_travel_dist: 1160.4757, mean_rewards: 196.0597, total_rewards: 1474.6755, mean_steps: 12.1200, mean_ecr: 0.0563 mean_entropies: 0.9987, took: 71.8087s
2022-10-10 03:24:35,531 [INFO] 	Process 2 - batch 15399: mean_policy_losses: 55.976, mean_net_lifetime: 4427.9061, mean_mc_travel_dist: 2061.1372, mean_rewards: 160.4563, total_rewards: 2390.5953, mean_steps: 26.6900, mean_ecr: 0.0410 mean_entropies: 1.4534, took: 130.4968s
2022-10-10 03:25:08,850 [INFO] 	Process 4 - batch 19099: mean_policy_losses: 211.834, mean_net_lifetime: 3933.5427, mean_mc_travel_dist: 1555.9048, mean_rewards: 226.9358, total_rewards: 2399.0253, mean_steps: 16.2900, mean_ecr: 0.0500 mean_entropies: 1.8558, took: 86.5436s
2022-10-10 03:25:12,567 [INFO] 	Process 7 - batch 15699: mean_policy_losses: -183.196, mean_net_lifetime: 3831.0320, mean_mc_travel_dist: 1933.3610, mean_rewards: 167.7155, total_rewards: 1956.9562, mean_steps: 21.6500, mean_ecr: 0.0431 mean_entropies: 2.1480, took: 106.7635s
2022-10-10 03:25:18,931 [INFO] 	Process 6 - batch 23899: mean_policy_losses: -227.359, mean_net_lifetime: 2585.1085, mean_mc_travel_dist: 1177.5403, mean_rewards: 195.3872, total_rewards: 1446.4231, mean_steps: 12.2000, mean_ecr: 0.0565 mean_entropies: 0.9427, took: 71.8475s
2022-10-10 03:26:08,256 [INFO] 	Process 3 - batch 15499: mean_policy_losses: 82.646, mean_net_lifetime: 4100.7852, mean_mc_travel_dist: 1735.0498, mean_rewards: 156.6883, total_rewards: 2385.5697, mean_steps: 25.3500, mean_ecr: 0.0480 mean_entropies: 1.3140, took: 139.9808s
2022-10-10 03:26:14,148 [INFO] 	Process 1 - batch 13499: mean_policy_losses: -49.278, mean_net_lifetime: 4550.1847, mean_mc_travel_dist: 2328.2587, mean_rewards: 118.3809, total_rewards: 2251.6341, mean_steps: 37.9400, mean_ecr: 0.0401 mean_entropies: 1.4757, took: 199.0985s
2022-10-10 03:26:32,037 [INFO] 	Process 6 - batch 23999: mean_policy_losses: -204.878, mean_net_lifetime: 2628.3671, mean_mc_travel_dist: 1178.3932, mean_rewards: 197.2575, total_rewards: 1487.0922, mean_steps: 12.3200, mean_ecr: 0.0562 mean_entropies: 0.8843, took: 73.1114s
2022-10-10 03:26:33,758 [INFO] 	Process 4 - batch 19199: mean_policy_losses: 237.129, mean_net_lifetime: 3919.8903, mean_mc_travel_dist: 1556.4644, mean_rewards: 226.5646, total_rewards: 2391.6519, mean_steps: 16.2100, mean_ecr: 0.0497 mean_entropies: 1.8037, took: 84.9077s
2022-10-10 03:26:48,581 [INFO] 	Process 2 - batch 15499: mean_policy_losses: 13.962, mean_net_lifetime: 4190.9672, mean_mc_travel_dist: 1967.1020, mean_rewards: 147.5895, total_rewards: 2246.5828, mean_steps: 27.5000, mean_ecr: 0.0414 mean_entropies: 1.3141, took: 133.0506s
2022-10-10 03:26:58,396 [INFO] 	Process 7 - batch 15799: mean_policy_losses: -141.885, mean_net_lifetime: 3926.6263, mean_mc_travel_dist: 1948.5186, mean_rewards: 169.1851, total_rewards: 2026.1053, mean_steps: 21.9100, mean_ecr: 0.0429 mean_entropies: 2.1272, took: 105.8290s
2022-10-10 03:27:57,914 [INFO] 	Process 4 - batch 19299: mean_policy_losses: 141.038, mean_net_lifetime: 4147.0764, mean_mc_travel_dist: 1574.0450, mean_rewards: 227.0542, total_rewards: 2599.5143, mean_steps: 17.2500, mean_ecr: 0.0497 mean_entropies: 1.8617, took: 84.1560s
2022-10-10 03:28:16,128 [INFO] 	Process 3 - batch 15599: mean_policy_losses: 19.674, mean_net_lifetime: 4280.7804, mean_mc_travel_dist: 1779.1006, mean_rewards: 166.4160, total_rewards: 2518.5456, mean_steps: 24.9300, mean_ecr: 0.0479 mean_entropies: 1.3356, took: 127.8727s
2022-10-10 03:28:47,204 [INFO] 	Process 2 - batch 15599: mean_policy_losses: -45.142, mean_net_lifetime: 4560.5787, mean_mc_travel_dist: 2128.5266, mean_rewards: 167.4902, total_rewards: 2470.3765, mean_steps: 26.3600, mean_ecr: 0.0408 mean_entropies: 1.4484, took: 118.6233s
2022-10-10 03:28:58,835 [INFO] 	Process 7 - batch 15899: mean_policy_losses: -237.973, mean_net_lifetime: 4352.8779, mean_mc_travel_dist: 2025.1438, mean_rewards: 157.8585, total_rewards: 2372.2610, mean_steps: 26.4600, mean_ecr: 0.0431 mean_entropies: 2.0878, took: 120.4387s
2022-10-10 03:29:19,261 [INFO] 	Process 4 - batch 19399: mean_policy_losses: 19.727, mean_net_lifetime: 3930.6584, mean_mc_travel_dist: 1519.4664, mean_rewards: 222.2775, total_rewards: 2439.3686, mean_steps: 16.6200, mean_ecr: 0.0501 mean_entropies: 1.8844, took: 81.3477s
2022-10-10 03:30:18,886 [INFO] 	Process 3 - batch 15699: mean_policy_losses: 52.595, mean_net_lifetime: 4459.5188, mean_mc_travel_dist: 1857.5328, mean_rewards: 178.7219, total_rewards: 2629.5161, mean_steps: 24.0300, mean_ecr: 0.0477 mean_entropies: 1.4078, took: 122.7572s
2022-10-10 03:30:39,259 [INFO] 	Process 4 - batch 19499: mean_policy_losses: 8.172, mean_net_lifetime: 3787.4118, mean_mc_travel_dist: 1486.1404, mean_rewards: 221.2754, total_rewards: 2322.9178, mean_steps: 16.1100, mean_ecr: 0.0504 mean_entropies: 1.9090, took: 79.9968s
2022-10-10 03:30:47,598 [INFO] 	Process 2 - batch 15699: mean_policy_losses: -10.638, mean_net_lifetime: 4605.0556, mean_mc_travel_dist: 2161.1470, mean_rewards: 168.0391, total_rewards: 2476.2498, mean_steps: 26.5000, mean_ecr: 0.0407 mean_entropies: 1.4928, took: 120.3928s
2022-10-10 03:30:56,827 [INFO] 	Process 7 - batch 15999: mean_policy_losses: -189.091, mean_net_lifetime: 4301.8757, mean_mc_travel_dist: 2026.6483, mean_rewards: 159.8717, total_rewards: 2312.0378, mean_steps: 25.9300, mean_ecr: 0.0430 mean_entropies: 2.0926, took: 117.9931s
2022-10-10 03:31:36,991 [INFO] Process 5 - epoch 10: mean_policy_losses: 7.062, mean_net_lifetime: 4243.2675, mean_mc_travel_dist: 2467.2417, mean_entropies: 2.4163, m_net_lifetime_valid: 3473.8663, took: 3585.3355s, (223.5679 / 100 batches)

2022-10-10 03:32:13,878 [INFO] 	Process 3 - batch 15799: mean_policy_losses: 67.472, mean_net_lifetime: 4363.3539, mean_mc_travel_dist: 1831.3047, mean_rewards: 187.4039, total_rewards: 2553.0953, mean_steps: 22.3600, mean_ecr: 0.0476 mean_entropies: 1.4638, took: 114.9922s
2022-10-10 03:32:42,067 [INFO] 	Process 2 - batch 15799: mean_policy_losses: 19.085, mean_net_lifetime: 4671.1682, mean_mc_travel_dist: 2166.5556, mean_rewards: 176.0373, total_rewards: 2530.8435, mean_steps: 25.6700, mean_ecr: 0.0407 mean_entropies: 1.5458, took: 114.4700s
2022-10-10 03:32:54,698 [INFO] 	Process 7 - batch 16099: mean_policy_losses: -238.498, mean_net_lifetime: 4206.7964, mean_mc_travel_dist: 2002.2611, mean_rewards: 154.2138, total_rewards: 2260.1817, mean_steps: 26.0800, mean_ecr: 0.0430 mean_entropies: 2.1060, took: 117.8704s
2022-10-10 03:34:05,020 [INFO] 	Process 3 - batch 15899: mean_policy_losses: 49.716, mean_net_lifetime: 4298.4931, mean_mc_travel_dist: 1846.5859, mean_rewards: 187.3846, total_rewards: 2477.3468, mean_steps: 22.1000, mean_ecr: 0.0478 mean_entropies: 1.4937, took: 111.1428s
2022-10-10 03:34:16,553 [INFO] 	Process 5 - batch 15099: mean_policy_losses: -31.790, mean_net_lifetime: 5862.1870, mean_mc_travel_dist: 3320.5615, mean_rewards: 166.2984, total_rewards: 2601.8347, mean_steps: 34.1800, mean_ecr: 0.0294 mean_entropies: 1.9271, took: 1502.9695s
2022-10-10 03:34:36,938 [INFO] 	Process 2 - batch 15899: mean_policy_losses: 39.586, mean_net_lifetime: 4738.0738, mean_mc_travel_dist: 2240.1814, mean_rewards: 177.5619, total_rewards: 2538.6122, mean_steps: 25.8100, mean_ecr: 0.0404 mean_entropies: 1.5849, took: 114.8706s
2022-10-10 03:34:46,997 [INFO] 	Process 7 - batch 16199: mean_policy_losses: -228.418, mean_net_lifetime: 4218.1911, mean_mc_travel_dist: 2021.2990, mean_rewards: 159.5553, total_rewards: 2244.3566, mean_steps: 25.3000, mean_ecr: 0.0431 mean_entropies: 2.1175, took: 112.2985s
2022-10-10 03:35:58,152 [INFO] 	Process 3 - batch 15999: mean_policy_losses: 108.291, mean_net_lifetime: 4552.0035, mean_mc_travel_dist: 1904.6789, mean_rewards: 193.2167, total_rewards: 2667.3246, mean_steps: 22.6600, mean_ecr: 0.0474 mean_entropies: 1.5504, took: 113.1315s
2022-10-10 03:36:31,219 [INFO] 	Process 7 - batch 16299: mean_policy_losses: -325.102, mean_net_lifetime: 3969.6732, mean_mc_travel_dist: 1940.2661, mean_rewards: 161.6531, total_rewards: 2080.8766, mean_steps: 23.5300, mean_ecr: 0.0431 mean_entropies: 2.1507, took: 104.2224s
2022-10-10 03:36:36,632 [INFO] 	Process 2 - batch 15999: mean_policy_losses: 76.134, mean_net_lifetime: 5044.3814, mean_mc_travel_dist: 2376.0471, mean_rewards: 180.1804, total_rewards: 2699.6397, mean_steps: 27.0900, mean_ecr: 0.0400 mean_entropies: 1.6565, took: 119.6945s
2022-10-10 03:36:46,346 [INFO] 	Process 5 - batch 15199: mean_policy_losses: 51.761, mean_net_lifetime: 5994.3587, mean_mc_travel_dist: 3193.3981, mean_rewards: 177.7393, total_rewards: 2852.4239, mean_steps: 32.5300, mean_ecr: 0.0304 mean_entropies: 2.0255, took: 149.7932s
2022-10-10 03:37:50,519 [INFO] 	Process 3 - batch 16099: mean_policy_losses: 57.152, mean_net_lifetime: 4386.3587, mean_mc_travel_dist: 1836.2483, mean_rewards: 184.7099, total_rewards: 2577.7274, mean_steps: 22.9000, mean_ecr: 0.0477 mean_entropies: 1.5181, took: 112.3678s
2022-10-10 03:38:15,439 [INFO] 	Process 7 - batch 16399: mean_policy_losses: -270.925, mean_net_lifetime: 4141.2121, mean_mc_travel_dist: 1996.4744, mean_rewards: 167.5252, total_rewards: 2190.6965, mean_steps: 23.4400, mean_ecr: 0.0430 mean_entropies: 2.1236, took: 104.2201s
2022-10-10 03:38:33,822 [INFO] 	Process 2 - batch 16099: mean_policy_losses: 10.099, mean_net_lifetime: 4798.6943, mean_mc_travel_dist: 2254.7300, mean_rewards: 175.2531, total_rewards: 2577.8051, mean_steps: 26.5400, mean_ecr: 0.0403 mean_entropies: 1.5934, took: 117.1896s
2022-10-10 03:39:14,489 [INFO] 	Process 5 - batch 15299: mean_policy_losses: 64.098, mean_net_lifetime: 5994.3525, mean_mc_travel_dist: 3144.9860, mean_rewards: 183.9704, total_rewards: 2902.6494, mean_steps: 31.3400, mean_ecr: 0.0304 mean_entropies: 2.0116, took: 148.1425s
2022-10-10 03:39:41,318 [INFO] 	Process 3 - batch 16199: mean_policy_losses: 59.215, mean_net_lifetime: 4371.7007, mean_mc_travel_dist: 1825.7468, mean_rewards: 184.1191, total_rewards: 2565.4925, mean_steps: 22.9000, mean_ecr: 0.0477 mean_entropies: 1.4838, took: 110.7992s
2022-10-10 03:40:06,173 [INFO] 	Process 7 - batch 16499: mean_policy_losses: -206.216, mean_net_lifetime: 4335.4614, mean_mc_travel_dist: 2056.4733, mean_rewards: 165.4546, total_rewards: 2323.9928, mean_steps: 24.9800, mean_ecr: 0.0429 mean_entropies: 2.1201, took: 110.7338s
2022-10-10 03:40:30,827 [INFO] 	Process 2 - batch 16199: mean_policy_losses: 19.640, mean_net_lifetime: 4927.2049, mean_mc_travel_dist: 2332.2754, mean_rewards: 176.9668, total_rewards: 2624.0594, mean_steps: 26.9700, mean_ecr: 0.0400 mean_entropies: 1.6217, took: 117.0051s
2022-10-10 03:41:29,381 [INFO] 	Process 3 - batch 16299: mean_policy_losses: 45.043, mean_net_lifetime: 4469.2847, mean_mc_travel_dist: 1852.3785, mean_rewards: 186.6326, total_rewards: 2638.3240, mean_steps: 23.1000, mean_ecr: 0.0474 mean_entropies: 1.5203, took: 108.0626s
2022-10-10 03:41:30,578 [INFO] 	Process 5 - batch 15399: mean_policy_losses: 44.566, mean_net_lifetime: 5904.6807, mean_mc_travel_dist: 3072.2832, mean_rewards: 189.0279, total_rewards: 2874.3323, mean_steps: 30.0400, mean_ecr: 0.0307 mean_entropies: 2.0413, took: 136.0891s
2022-10-10 03:42:24,147 [INFO] 	Process 2 - batch 16299: mean_policy_losses: 5.863, mean_net_lifetime: 4877.3448, mean_mc_travel_dist: 2320.4788, mean_rewards: 174.8266, total_rewards: 2598.1315, mean_steps: 27.0300, mean_ecr: 0.0400 mean_entropies: 1.6113, took: 113.3206s
2022-10-10 03:43:18,856 [INFO] 	Process 3 - batch 16399: mean_policy_losses: 34.314, mean_net_lifetime: 4463.8330, mean_mc_travel_dist: 1871.9267, mean_rewards: 183.4125, total_rewards: 2622.0614, mean_steps: 23.4100, mean_ecr: 0.0475 mean_entropies: 1.4965, took: 109.4747s
2022-10-10 03:43:48,565 [INFO] 	Process 5 - batch 15499: mean_policy_losses: 86.130, mean_net_lifetime: 6004.2767, mean_mc_travel_dist: 3107.2845, mean_rewards: 186.9415, total_rewards: 2948.4493, mean_steps: 30.8700, mean_ecr: 0.0308 mean_entropies: 2.0218, took: 137.9876s
2022-10-10 03:44:18,349 [INFO] 	Process 2 - batch 16399: mean_policy_losses: 12.659, mean_net_lifetime: 4898.8701, mean_mc_travel_dist: 2287.2816, mean_rewards: 175.7601, total_rewards: 2642.3371, mean_steps: 27.0100, mean_ecr: 0.0402 mean_entropies: 1.5949, took: 114.2024s
2022-10-10 03:44:21,012 [INFO] Process 6 - epoch 16: mean_policy_losses: -305.465, mean_net_lifetime: 2061.2891, mean_mc_travel_dist: 1077.5589, mean_entropies: 1.5914, m_net_lifetime_valid: 3547.0641, took: 2169.3018s, (144.3849 / 100 batches)

2022-10-10 03:44:24,215 [INFO] Process 1 - epoch 9: mean_policy_losses: 158.718, mean_net_lifetime: 4601.1590, mean_mc_travel_dist: 2393.8843, mean_entropies: 2.0054, m_net_lifetime_valid: 3537.9221, took: 3960.7296s, (255.7305 / 100 batches)

2022-10-10 03:45:11,842 [INFO] 	Process 3 - batch 16499: mean_policy_losses: 90.636, mean_net_lifetime: 4392.7101, mean_mc_travel_dist: 1829.7514, mean_rewards: 181.4093, total_rewards: 2584.1297, mean_steps: 23.3800, mean_ecr: 0.0476 mean_entropies: 1.4993, took: 112.9864s
2022-10-10 03:45:20,660 [INFO] 	Process 6 - batch 24099: mean_policy_losses: -373.719, mean_net_lifetime: 2291.9390, mean_mc_travel_dist: 1066.6589, mean_rewards: 194.2757, total_rewards: 1269.2334, mean_steps: 10.7700, mean_ecr: 0.0557 mean_entropies: 1.2319, took: 1128.6235s
2022-10-10 03:46:00,293 [INFO] 	Process 5 - batch 15599: mean_policy_losses: 71.420, mean_net_lifetime: 5239.0420, mean_mc_travel_dist: 2754.6817, mean_rewards: 179.5978, total_rewards: 2543.9446, mean_steps: 27.8800, mean_ecr: 0.0311 mean_entropies: 2.0402, took: 131.7272s
2022-10-10 03:46:20,716 [INFO] 	Process 2 - batch 16499: mean_policy_losses: 174.290, mean_net_lifetime: 4812.5108, mean_mc_travel_dist: 2190.0900, mean_rewards: 170.1599, total_rewards: 2649.7088, mean_steps: 27.4300, mean_ecr: 0.0404 mean_entropies: 1.5952, took: 122.3660s
2022-10-10 03:46:21,322 [INFO] 	Process 6 - batch 24199: mean_policy_losses: -198.875, mean_net_lifetime: 2525.9549, mean_mc_travel_dist: 1143.3166, mean_rewards: 196.7125, total_rewards: 1421.7610, mean_steps: 11.6600, mean_ecr: 0.0562 mean_entropies: 1.0836, took: 60.6623s
2022-10-10 03:46:41,667 [INFO] Process 4 - epoch 13: mean_policy_losses: 16.376, mean_net_lifetime: 2906.0609, mean_mc_travel_dist: 1294.1598, mean_entropies: 1.9826, m_net_lifetime_valid: 3621.6971, took: 2228.1705s, (178.7976 / 100 batches)

2022-10-10 03:47:11,409 [INFO] 	Process 1 - batch 13599: mean_policy_losses: 45.035, mean_net_lifetime: 4779.4994, mean_mc_travel_dist: 2339.0227, mean_rewards: 128.4375, total_rewards: 2469.2853, mean_steps: 36.7300, mean_ecr: 0.0399 mean_entropies: 1.6555, took: 1257.2621s
2022-10-10 03:47:24,641 [INFO] 	Process 6 - batch 24299: mean_policy_losses: -113.523, mean_net_lifetime: 2694.8185, mean_mc_travel_dist: 1193.4715, mean_rewards: 200.3185, total_rewards: 1532.5219, mean_steps: 12.3400, mean_ecr: 0.0562 mean_entropies: 0.9950, took: 63.3184s
2022-10-10 03:47:54,410 [INFO] 	Process 4 - batch 19599: mean_policy_losses: -120.320, mean_net_lifetime: 2690.4578, mean_mc_travel_dist: 1172.5506, mean_rewards: 163.4707, total_rewards: 1544.3781, mean_steps: 15.4800, mean_ecr: 0.0517 mean_entropies: 1.8558, took: 1035.1516s
2022-10-10 03:48:03,893 [INFO] 	Process 5 - batch 15699: mean_policy_losses: 94.366, mean_net_lifetime: 4692.5839, mean_mc_travel_dist: 2545.7424, mean_rewards: 170.4460, total_rewards: 2203.5989, mean_steps: 26.2400, mean_ecr: 0.0311 mean_entropies: 1.9729, took: 123.5996s
2022-10-10 03:48:31,657 [INFO] 	Process 6 - batch 24399: mean_policy_losses: -68.252, mean_net_lifetime: 2879.9478, mean_mc_travel_dist: 1231.0020, mean_rewards: 204.2204, total_rewards: 1687.9563, mean_steps: 13.1000, mean_ecr: 0.0556 mean_entropies: 0.9329, took: 67.0161s
2022-10-10 03:49:08,104 [INFO] 	Process 4 - batch 19699: mean_policy_losses: 1.956, mean_net_lifetime: 3254.5404, mean_mc_travel_dist: 1312.9519, mean_rewards: 195.7233, total_rewards: 1977.9210, mean_steps: 15.4800, mean_ecr: 0.0508 mean_entropies: 1.7752, took: 73.6943s
2022-10-10 03:49:41,059 [INFO] 	Process 1 - batch 13699: mean_policy_losses: 51.892, mean_net_lifetime: 4690.0027, mean_mc_travel_dist: 2413.4360, mean_rewards: 142.5206, total_rewards: 2308.8992, mean_steps: 32.3500, mean_ecr: 0.0398 mean_entropies: 1.6022, took: 149.6508s
2022-10-10 03:49:48,868 [INFO] 	Process 6 - batch 24499: mean_policy_losses: -88.385, mean_net_lifetime: 3141.5287, mean_mc_travel_dist: 1312.6570, mean_rewards: 191.8623, total_rewards: 1857.0236, mean_steps: 15.3900, mean_ecr: 0.0554 mean_entropies: 0.7217, took: 77.2102s
2022-10-10 03:50:08,059 [INFO] 	Process 5 - batch 15799: mean_policy_losses: -429.007, mean_net_lifetime: 3307.9050, mean_mc_travel_dist: 1989.0143, mean_rewards: 115.4364, total_rewards: 1372.1402, mean_steps: 26.5300, mean_ecr: 0.0308 mean_entropies: 1.6483, took: 124.1669s
2022-10-10 03:50:27,470 [INFO] 	Process 4 - batch 19799: mean_policy_losses: 245.316, mean_net_lifetime: 4060.1095, mean_mc_travel_dist: 1542.3920, mean_rewards: 225.2933, total_rewards: 2541.9290, mean_steps: 16.9600, mean_ecr: 0.0495 mean_entropies: 1.6454, took: 79.3657s
2022-10-10 03:51:01,873 [INFO] 	Process 6 - batch 24599: mean_policy_losses: -85.994, mean_net_lifetime: 3097.6126, mean_mc_travel_dist: 1298.2625, mean_rewards: 200.5147, total_rewards: 1827.0695, mean_steps: 14.4400, mean_ecr: 0.0557 mean_entropies: 0.6777, took: 73.0058s
2022-10-10 03:51:52,254 [INFO] 	Process 4 - batch 19899: mean_policy_losses: 302.938, mean_net_lifetime: 4295.4316, mean_mc_travel_dist: 1630.4944, mean_rewards: 229.7078, total_rewards: 2692.7604, mean_steps: 17.6700, mean_ecr: 0.0490 mean_entropies: 1.6321, took: 84.7843s
2022-10-10 03:52:10,425 [INFO] 	Process 1 - batch 13799: mean_policy_losses: -68.672, mean_net_lifetime: 4485.9666, mean_mc_travel_dist: 2479.5481, mean_rewards: 135.5971, total_rewards: 2039.6963, mean_steps: 32.6400, mean_ecr: 0.0397 mean_entropies: 1.3670, took: 149.3656s
2022-10-10 03:52:21,401 [INFO] 	Process 6 - batch 24699: mean_policy_losses: -58.223, mean_net_lifetime: 3287.2916, mean_mc_travel_dist: 1349.8559, mean_rewards: 202.9993, total_rewards: 1959.8847, mean_steps: 15.3700, mean_ecr: 0.0555 mean_entropies: 0.6777, took: 79.5276s
2022-10-10 03:52:22,466 [INFO] 	Process 5 - batch 15899: mean_policy_losses: -406.583, mean_net_lifetime: 3526.1298, mean_mc_travel_dist: 2142.4313, mean_rewards: 112.6132, total_rewards: 1445.8499, mean_steps: 29.0400, mean_ecr: 0.0303 mean_entropies: 1.5693, took: 134.4075s
2022-10-10 03:53:19,252 [INFO] 	Process 4 - batch 19999: mean_policy_losses: 337.936, mean_net_lifetime: 4483.6586, mean_mc_travel_dist: 1706.0013, mean_rewards: 231.6531, total_rewards: 2807.7477, mean_steps: 18.2900, mean_ecr: 0.0486 mean_entropies: 1.5986, took: 86.9984s
2022-10-10 03:53:37,340 [INFO] 	Process 6 - batch 24799: mean_policy_losses: -64.770, mean_net_lifetime: 3189.1918, mean_mc_travel_dist: 1336.9088, mean_rewards: 199.2532, total_rewards: 1874.2677, mean_steps: 15.1200, mean_ecr: 0.0556 mean_entropies: 0.6420, took: 75.9385s
2022-10-10 03:54:39,612 [INFO] 	Process 1 - batch 13899: mean_policy_losses: -72.541, mean_net_lifetime: 4491.7170, mean_mc_travel_dist: 2486.4077, mean_rewards: 133.9851, total_rewards: 2032.8755, mean_steps: 32.9400, mean_ecr: 0.0397 mean_entropies: 1.3455, took: 149.1854s
2022-10-10 03:54:40,959 [INFO] 	Process 4 - batch 20099: mean_policy_losses: 272.622, mean_net_lifetime: 4192.3229, mean_mc_travel_dist: 1606.9550, mean_rewards: 227.8881, total_rewards: 2609.1839, mean_steps: 17.3900, mean_ecr: 0.0492 mean_entropies: 1.6335, took: 81.7057s
2022-10-10 03:54:48,998 [INFO] 	Process 5 - batch 15999: mean_policy_losses: -291.704, mean_net_lifetime: 4041.8077, mean_mc_travel_dist: 2389.6677, mean_rewards: 120.5852, total_rewards: 1705.2752, mean_steps: 31.5200, mean_ecr: 0.0301 mean_entropies: 1.5535, took: 146.5322s
2022-10-10 03:54:52,592 [INFO] 	Process 6 - batch 24899: mean_policy_losses: -97.532, mean_net_lifetime: 3064.4816, mean_mc_travel_dist: 1303.8361, mean_rewards: 198.2442, total_rewards: 1785.6702, mean_steps: 14.5200, mean_ecr: 0.0559 mean_entropies: 0.6685, took: 75.2535s
2022-10-10 03:56:04,614 [INFO] 	Process 4 - batch 20199: mean_policy_losses: 291.239, mean_net_lifetime: 4310.2302, mean_mc_travel_dist: 1626.6219, mean_rewards: 229.5632, total_rewards: 2715.1591, mean_steps: 17.7600, mean_ecr: 0.0490 mean_entropies: 1.6218, took: 83.6552s
2022-10-10 03:56:07,588 [INFO] 	Process 6 - batch 24999: mean_policy_losses: -70.682, mean_net_lifetime: 3146.7397, mean_mc_travel_dist: 1307.5369, mean_rewards: 201.6343, total_rewards: 1864.4105, mean_steps: 14.6700, mean_ecr: 0.0557 mean_entropies: 0.6661, took: 74.9957s
2022-10-10 03:57:11,624 [INFO] 	Process 5 - batch 16099: mean_policy_losses: -302.728, mean_net_lifetime: 4033.7712, mean_mc_travel_dist: 2378.0510, mean_rewards: 122.6573, total_rewards: 1715.5495, mean_steps: 30.6900, mean_ecr: 0.0300 mean_entropies: 1.5308, took: 142.6251s
2022-10-10 03:57:14,771 [INFO] 	Process 1 - batch 13999: mean_policy_losses: -85.134, mean_net_lifetime: 4508.4000, mean_mc_travel_dist: 2476.1861, mean_rewards: 130.1997, total_rewards: 2062.8343, mean_steps: 34.0900, mean_ecr: 0.0397 mean_entropies: 1.2953, took: 155.1606s
2022-10-10 03:57:22,376 [INFO] 	Process 6 - batch 25099: mean_policy_losses: -99.241, mean_net_lifetime: 3141.8511, mean_mc_travel_dist: 1321.5036, mean_rewards: 199.6177, total_rewards: 1848.5826, mean_steps: 14.8600, mean_ecr: 0.0558 mean_entropies: 0.6490, took: 74.7877s
2022-10-10 03:57:29,663 [INFO] 	Process 4 - batch 20299: mean_policy_losses: 290.271, mean_net_lifetime: 4426.8836, mean_mc_travel_dist: 1658.2425, mean_rewards: 230.4034, total_rewards: 2790.9982, mean_steps: 18.1700, mean_ecr: 0.0487 mean_entropies: 1.5948, took: 85.0498s
2022-10-10 03:57:43,287 [INFO] Process 7 - epoch 11: mean_policy_losses: 7.584, mean_net_lifetime: 3782.2150, mean_mc_travel_dist: 1864.0418, mean_entropies: 2.2612, m_net_lifetime_valid: 3711.9399, took: 2727.9399s, (214.5260 / 100 batches)

2022-10-10 03:58:39,050 [INFO] 	Process 6 - batch 25199: mean_policy_losses: -86.297, mean_net_lifetime: 3163.5528, mean_mc_travel_dist: 1313.5571, mean_rewards: 204.6102, total_rewards: 1874.4951, mean_steps: 14.5700, mean_ecr: 0.0556 mean_entropies: 0.6175, took: 76.6738s
2022-10-10 03:58:59,810 [INFO] 	Process 4 - batch 20399: mean_policy_losses: 289.564, mean_net_lifetime: 4437.6915, mean_mc_travel_dist: 1652.4239, mean_rewards: 229.0207, total_rewards: 2808.7473, mean_steps: 18.4500, mean_ecr: 0.0490 mean_entropies: 1.5499, took: 90.1465s
2022-10-10 03:59:43,164 [INFO] 	Process 5 - batch 16199: mean_policy_losses: -271.034, mean_net_lifetime: 4218.6699, mean_mc_travel_dist: 2501.3541, mean_rewards: 124.3976, total_rewards: 1764.7897, mean_steps: 31.6700, mean_ecr: 0.0298 mean_entropies: 1.4913, took: 151.5402s
2022-10-10 03:59:44,255 [INFO] 	Process 7 - batch 16599: mean_policy_losses: 24.036, mean_net_lifetime: 4613.1857, mean_mc_travel_dist: 2184.7211, mean_rewards: 168.4086, total_rewards: 2468.4489, mean_steps: 26.1800, mean_ecr: 0.0426 mean_entropies: 1.9817, took: 1178.0820s
2022-10-10 03:59:55,232 [INFO] 	Process 6 - batch 25299: mean_policy_losses: -75.551, mean_net_lifetime: 3162.9258, mean_mc_travel_dist: 1326.2425, mean_rewards: 205.3005, total_rewards: 1865.2017, mean_steps: 14.4500, mean_ecr: 0.0559 mean_entropies: 0.6438, took: 76.1818s
2022-10-10 04:00:02,028 [INFO] 	Process 1 - batch 14099: mean_policy_losses: -83.918, mean_net_lifetime: 4503.4562, mean_mc_travel_dist: 2481.9153, mean_rewards: 125.3576, total_rewards: 2054.4092, mean_steps: 35.7000, mean_ecr: 0.0397 mean_entropies: 1.2210, took: 167.2578s
2022-10-10 04:00:31,957 [INFO] 	Process 4 - batch 20499: mean_policy_losses: 304.894, mean_net_lifetime: 4505.3306, mean_mc_travel_dist: 1672.3945, mean_rewards: 227.5267, total_rewards: 2851.5432, mean_steps: 18.8200, mean_ecr: 0.0486 mean_entropies: 1.5720, took: 92.1474s
2022-10-10 04:01:14,848 [INFO] 	Process 6 - batch 25399: mean_policy_losses: -76.494, mean_net_lifetime: 3246.3249, mean_mc_travel_dist: 1334.1696, mean_rewards: 204.4172, total_rewards: 1935.4949, mean_steps: 14.9200, mean_ecr: 0.0554 mean_entropies: 0.6527, took: 79.6154s
2022-10-10 04:01:22,428 [INFO] 	Process 7 - batch 16699: mean_policy_losses: -215.848, mean_net_lifetime: 3891.7199, mean_mc_travel_dist: 1957.4708, mean_rewards: 174.7427, total_rewards: 1987.7222, mean_steps: 20.9900, mean_ecr: 0.0429 mean_entropies: 2.0298, took: 98.1733s
2022-10-10 04:01:58,619 [INFO] 	Process 4 - batch 20599: mean_policy_losses: 237.664, mean_net_lifetime: 4145.7201, mean_mc_travel_dist: 1545.8363, mean_rewards: 221.6620, total_rewards: 2625.1190, mean_steps: 17.6200, mean_ecr: 0.0492 mean_entropies: 1.6345, took: 86.6614s
2022-10-10 04:02:19,649 [INFO] 	Process 5 - batch 16299: mean_policy_losses: -185.948, mean_net_lifetime: 4610.6939, mean_mc_travel_dist: 2665.6260, mean_rewards: 133.3686, total_rewards: 2005.2870, mean_steps: 32.6200, mean_ecr: 0.0297 mean_entropies: 1.5220, took: 156.4851s
2022-10-10 04:02:31,772 [INFO] 	Process 6 - batch 25499: mean_policy_losses: -66.600, mean_net_lifetime: 3208.3281, mean_mc_travel_dist: 1331.8841, mean_rewards: 210.8864, total_rewards: 1901.9512, mean_steps: 14.2500, mean_ecr: 0.0556 mean_entropies: 0.6211, took: 76.9244s
2022-10-10 04:02:58,380 [INFO] 	Process 1 - batch 14199: mean_policy_losses: -84.240, mean_net_lifetime: 4511.3898, mean_mc_travel_dist: 2474.9378, mean_rewards: 121.1613, total_rewards: 2070.3472, mean_steps: 36.9200, mean_ecr: 0.0398 mean_entropies: 1.2361, took: 176.3512s
2022-10-10 04:03:14,621 [INFO] 	Process 7 - batch 16799: mean_policy_losses: -78.092, mean_net_lifetime: 4281.2331, mean_mc_travel_dist: 2103.0456, mean_rewards: 166.4383, total_rewards: 2221.2585, mean_steps: 24.5300, mean_ecr: 0.0427 mean_entropies: 1.9712, took: 112.1929s
2022-10-10 04:03:26,234 [INFO] 	Process 4 - batch 20699: mean_policy_losses: 294.534, mean_net_lifetime: 4261.6038, mean_mc_travel_dist: 1581.3862, mean_rewards: 222.5657, total_rewards: 2703.0897, mean_steps: 18.1800, mean_ecr: 0.0493 mean_entropies: 1.6112, took: 87.6150s
2022-10-10 04:03:48,836 [INFO] Process 3 - epoch 11: mean_policy_losses: 149.540, mean_net_lifetime: 3787.0763, mean_mc_travel_dist: 1683.7824, mean_entropies: 1.7811, m_net_lifetime_valid: 3693.6515, took: 2992.7283s, (216.3636 / 100 batches)

2022-10-10 04:04:30,771 [INFO] Process 2 - epoch 11: mean_policy_losses: 14.451, mean_net_lifetime: 3662.7748, mean_mc_travel_dist: 1827.4289, mean_entropies: 1.8598, m_net_lifetime_valid: 3773.2805, took: 2929.7833s, (216.7832 / 100 batches)

2022-10-10 04:04:53,690 [INFO] 	Process 4 - batch 20799: mean_policy_losses: 226.025, mean_net_lifetime: 4000.8059, mean_mc_travel_dist: 1514.3054, mean_rewards: 217.9381, total_rewards: 2517.7970, mean_steps: 17.3100, mean_ecr: 0.0495 mean_entropies: 1.6634, took: 87.4570s
2022-10-10 04:04:57,120 [INFO] 	Process 5 - batch 16399: mean_policy_losses: -128.569, mean_net_lifetime: 4824.9163, mean_mc_travel_dist: 2776.7264, mean_rewards: 140.1984, total_rewards: 2108.5449, mean_steps: 32.5800, mean_ecr: 0.0297 mean_entropies: 1.5438, took: 157.4703s
2022-10-10 04:05:10,427 [INFO] 	Process 7 - batch 16899: mean_policy_losses: 13.206, mean_net_lifetime: 4453.5268, mean_mc_travel_dist: 2149.3302, mean_rewards: 172.1280, total_rewards: 2345.2978, mean_steps: 24.5300, mean_ecr: 0.0426 mean_entropies: 2.0038, took: 115.8068s
2022-10-10 04:06:02,760 [INFO] 	Process 3 - batch 16599: mean_policy_losses: 30.336, mean_net_lifetime: 4010.4753, mean_mc_travel_dist: 1714.1962, mean_rewards: 147.4564, total_rewards: 2314.6577, mean_steps: 26.7900, mean_ecr: 0.0483 mean_entropies: 1.1642, took: 1250.9183s
2022-10-10 04:06:04,103 [INFO] 	Process 1 - batch 14299: mean_policy_losses: -86.458, mean_net_lifetime: 4531.7174, mean_mc_travel_dist: 2413.8048, mean_rewards: 115.2152, total_rewards: 2149.6084, mean_steps: 38.8300, mean_ecr: 0.0399 mean_entropies: 1.2797, took: 185.7225s
2022-10-10 04:06:18,575 [INFO] 	Process 4 - batch 20899: mean_policy_losses: 16.069, mean_net_lifetime: 3574.1208, mean_mc_travel_dist: 1405.1065, mean_rewards: 206.8927, total_rewards: 2196.2462, mean_steps: 16.2200, mean_ecr: 0.0504 mean_entropies: 1.8184, took: 84.8844s
2022-10-10 04:06:42,544 [INFO] 	Process 2 - batch 16599: mean_policy_losses: 16.595, mean_net_lifetime: 4411.9394, mean_mc_travel_dist: 2056.2789, mean_rewards: 157.0222, total_rewards: 2390.7681, mean_steps: 27.3000, mean_ecr: 0.0411 mean_entropies: 1.2987, took: 1221.8277s
2022-10-10 04:07:09,967 [INFO] 	Process 7 - batch 16999: mean_policy_losses: -112.965, mean_net_lifetime: 4350.1710, mean_mc_travel_dist: 2075.9295, mean_rewards: 168.4809, total_rewards: 2337.9600, mean_steps: 24.6000, mean_ecr: 0.0428 mean_entropies: 2.0578, took: 119.5390s
2022-10-10 04:07:45,161 [INFO] 	Process 5 - batch 16499: mean_policy_losses: 98.705, mean_net_lifetime: 6163.2079, mean_mc_travel_dist: 3357.1932, mean_rewards: 173.3826, total_rewards: 2856.3879, mean_steps: 34.3100, mean_ecr: 0.0294 mean_entropies: 1.7817, took: 168.0421s
2022-10-10 04:07:45,267 [INFO] 	Process 4 - batch 20999: mean_policy_losses: -0.477, mean_net_lifetime: 3771.2058, mean_mc_travel_dist: 1467.7244, mean_rewards: 212.5526, total_rewards: 2332.1129, mean_steps: 16.6600, mean_ecr: 0.0502 mean_entropies: 1.8059, took: 86.6918s
2022-10-10 04:08:03,820 [INFO] 	Process 3 - batch 16699: mean_policy_losses: 79.904, mean_net_lifetime: 4369.1120, mean_mc_travel_dist: 1816.5548, mean_rewards: 176.5657, total_rewards: 2573.7379, mean_steps: 23.8900, mean_ecr: 0.0479 mean_entropies: 1.3162, took: 121.0589s
2022-10-10 04:08:41,543 [INFO] 	Process 2 - batch 16699: mean_policy_losses: 19.456, mean_net_lifetime: 4603.1534, mean_mc_travel_dist: 2141.0119, mean_rewards: 172.3708, total_rewards: 2490.7643, mean_steps: 25.8800, mean_ecr: 0.0407 mean_entropies: 1.4408, took: 118.9996s
2022-10-10 04:08:57,199 [INFO] 	Process 7 - batch 17099: mean_policy_losses: -246.656, mean_net_lifetime: 4128.2612, mean_mc_travel_dist: 2003.1219, mean_rewards: 166.5157, total_rewards: 2175.9894, mean_steps: 23.6300, mean_ecr: 0.0430 mean_entropies: 2.1004, took: 107.2326s
2022-10-10 04:09:18,468 [INFO] 	Process 1 - batch 14399: mean_policy_losses: -175.558, mean_net_lifetime: 4538.6132, mean_mc_travel_dist: 2324.4591, mean_rewards: 108.8251, total_rewards: 2251.0561, mean_steps: 41.3300, mean_ecr: 0.0401 mean_entropies: 1.4075, took: 194.3654s
2022-10-10 04:09:50,306 [INFO] 	Process 3 - batch 16799: mean_policy_losses: 84.294, mean_net_lifetime: 4293.0253, mean_mc_travel_dist: 1825.4222, mean_rewards: 188.9996, total_rewards: 2506.0762, mean_steps: 21.8300, mean_ecr: 0.0477 mean_entropies: 1.5118, took: 106.4806s
2022-10-10 04:10:32,399 [INFO] 	Process 7 - batch 17199: mean_policy_losses: -334.562, mean_net_lifetime: 3859.2299, mean_mc_travel_dist: 1918.1793, mean_rewards: 174.7226, total_rewards: 1990.5412, mean_steps: 20.9300, mean_ecr: 0.0432 mean_entropies: 2.1708, took: 95.2000s
2022-10-10 04:10:37,779 [INFO] 	Process 2 - batch 16799: mean_policy_losses: 91.971, mean_net_lifetime: 4823.9322, mean_mc_travel_dist: 2215.9541, mean_rewards: 180.3700, total_rewards: 2636.8988, mean_steps: 25.8700, mean_ecr: 0.0404 mean_entropies: 1.6350, took: 116.2350s
2022-10-10 04:11:46,631 [INFO] 	Process 3 - batch 16899: mean_policy_losses: 99.390, mean_net_lifetime: 4333.6993, mean_mc_travel_dist: 1839.7464, mean_rewards: 190.4714, total_rewards: 2521.2905, mean_steps: 21.8500, mean_ecr: 0.0473 mean_entropies: 1.5916, took: 116.3293s
2022-10-10 04:12:14,881 [INFO] 	Process 7 - batch 17299: mean_policy_losses: -364.896, mean_net_lifetime: 3880.9367, mean_mc_travel_dist: 1923.9075, mean_rewards: 167.0798, total_rewards: 2005.7343, mean_steps: 21.9700, mean_ecr: 0.0431 mean_entropies: 2.1991, took: 102.4818s
2022-10-10 04:12:31,370 [INFO] 	Process 1 - batch 14499: mean_policy_losses: -145.416, mean_net_lifetime: 4821.3687, mean_mc_travel_dist: 2382.4288, mean_rewards: 120.5298, total_rewards: 2464.6247, mean_steps: 39.3400, mean_ecr: 0.0399 mean_entropies: 1.6790, took: 192.9010s
2022-10-10 04:12:37,727 [INFO] 	Process 2 - batch 16899: mean_policy_losses: 70.771, mean_net_lifetime: 4835.4154, mean_mc_travel_dist: 2226.5626, mean_rewards: 178.1486, total_rewards: 2641.7984, mean_steps: 26.3100, mean_ecr: 0.0404 mean_entropies: 1.7303, took: 119.9479s
2022-10-10 04:13:40,888 [INFO] 	Process 3 - batch 16999: mean_policy_losses: 84.037, mean_net_lifetime: 4363.5572, mean_mc_travel_dist: 1828.4273, mean_rewards: 195.8324, total_rewards: 2559.8800, mean_steps: 21.4300, mean_ecr: 0.0479 mean_entropies: 1.5778, took: 114.2570s
2022-10-10 04:14:13,886 [INFO] 	Process 7 - batch 17399: mean_policy_losses: -201.676, mean_net_lifetime: 4364.0342, mean_mc_travel_dist: 2063.3404, mean_rewards: 162.3183, total_rewards: 2358.5628, mean_steps: 25.6900, mean_ecr: 0.0428 mean_entropies: 2.1207, took: 119.0045s
2022-10-10 04:14:35,009 [INFO] 	Process 2 - batch 16999: mean_policy_losses: 32.550, mean_net_lifetime: 4681.9518, mean_mc_travel_dist: 2170.2165, mean_rewards: 181.1409, total_rewards: 2547.9851, mean_steps: 25.0400, mean_ecr: 0.0407 mean_entropies: 1.6270, took: 117.2819s
2022-10-10 04:15:37,660 [INFO] 	Process 3 - batch 17099: mean_policy_losses: 125.441, mean_net_lifetime: 4446.7980, mean_mc_travel_dist: 1858.8277, mean_rewards: 194.6776, total_rewards: 2623.6545, mean_steps: 21.9900, mean_ecr: 0.0476 mean_entropies: 1.5743, took: 116.7731s
2022-10-10 04:15:40,011 [INFO] 	Process 1 - batch 14599: mean_policy_losses: -174.099, mean_net_lifetime: 4564.1467, mean_mc_travel_dist: 2266.2681, mean_rewards: 118.4086, total_rewards: 2325.8943, mean_steps: 37.9500, mean_ecr: 0.0401 mean_entropies: 1.6190, took: 188.6410s
2022-10-10 04:15:53,361 [INFO] 	Process 7 - batch 17499: mean_policy_losses: -347.893, mean_net_lifetime: 3748.0627, mean_mc_travel_dist: 1881.4367, mean_rewards: 165.5809, total_rewards: 1915.6955, mean_steps: 21.4200, mean_ecr: 0.0433 mean_entropies: 2.1849, took: 99.4742s
2022-10-10 04:16:32,712 [INFO] 	Process 2 - batch 17099: mean_policy_losses: 90.974, mean_net_lifetime: 4771.6878, mean_mc_travel_dist: 2182.6256, mean_rewards: 179.0404, total_rewards: 2624.5009, mean_steps: 25.7800, mean_ecr: 0.0405 mean_entropies: 1.7088, took: 117.7039s
2022-10-10 04:17:29,898 [INFO] 	Process 7 - batch 17599: mean_policy_losses: -422.956, mean_net_lifetime: 3666.7172, mean_mc_travel_dist: 1868.7065, mean_rewards: 166.4903, total_rewards: 1848.2182, mean_steps: 20.5900, mean_ecr: 0.0432 mean_entropies: 2.1804, took: 96.5373s
2022-10-10 04:17:32,400 [INFO] 	Process 3 - batch 17199: mean_policy_losses: 106.553, mean_net_lifetime: 4332.1114, mean_mc_travel_dist: 1817.4010, mean_rewards: 192.3669, total_rewards: 2540.1222, mean_steps: 21.6600, mean_ecr: 0.0477 mean_entropies: 1.5712, took: 114.7393s
2022-10-10 04:18:31,495 [INFO] 	Process 2 - batch 17199: mean_policy_losses: 80.555, mean_net_lifetime: 4701.3576, mean_mc_travel_dist: 2139.6281, mean_rewards: 178.0742, total_rewards: 2589.7512, mean_steps: 25.5300, mean_ecr: 0.0407 mean_entropies: 1.6346, took: 118.7833s
2022-10-10 04:18:40,080 [INFO] 	Process 1 - batch 14699: mean_policy_losses: -123.284, mean_net_lifetime: 4700.6014, mean_mc_travel_dist: 2318.7633, mean_rewards: 126.0273, total_rewards: 2408.8177, mean_steps: 36.6700, mean_ecr: 0.0401 mean_entropies: 1.6771, took: 180.0686s
2022-10-10 04:19:08,623 [INFO] 	Process 7 - batch 17699: mean_policy_losses: -298.423, mean_net_lifetime: 3826.3648, mean_mc_travel_dist: 1880.9652, mean_rewards: 171.9807, total_rewards: 1997.5146, mean_steps: 20.9700, mean_ecr: 0.0432 mean_entropies: 2.1634, took: 98.7254s
2022-10-10 04:19:30,053 [INFO] 	Process 3 - batch 17299: mean_policy_losses: 86.513, mean_net_lifetime: 4332.3426, mean_mc_travel_dist: 1816.1570, mean_rewards: 186.3436, total_rewards: 2540.4918, mean_steps: 22.3700, mean_ecr: 0.0477 mean_entropies: 1.5145, took: 117.6535s
2022-10-10 04:20:28,396 [INFO] 	Process 2 - batch 17299: mean_policy_losses: 87.413, mean_net_lifetime: 4721.0005, mean_mc_travel_dist: 2139.3402, mean_rewards: 181.8667, total_rewards: 2614.1295, mean_steps: 25.1600, mean_ecr: 0.0407 mean_entropies: 1.6371, took: 116.8996s
2022-10-10 04:20:51,995 [INFO] 	Process 7 - batch 17799: mean_policy_losses: -306.865, mean_net_lifetime: 3900.2779, mean_mc_travel_dist: 1949.2218, mean_rewards: 170.7021, total_rewards: 2007.1455, mean_steps: 21.6900, mean_ecr: 0.0430 mean_entropies: 2.1708, took: 103.3720s
2022-10-10 04:21:28,934 [INFO] 	Process 3 - batch 17399: mean_policy_losses: 95.607, mean_net_lifetime: 4355.0899, mean_mc_travel_dist: 1821.1836, mean_rewards: 188.9504, total_rewards: 2561.1992, mean_steps: 22.1700, mean_ecr: 0.0476 mean_entropies: 1.5377, took: 118.8718s
2022-10-10 04:21:37,443 [INFO] 	Process 1 - batch 14799: mean_policy_losses: -119.494, mean_net_lifetime: 4669.7900, mean_mc_travel_dist: 2302.7054, mean_rewards: 129.1266, total_rewards: 2402.2028, mean_steps: 35.6000, mean_ecr: 0.0401 mean_entropies: 1.6720, took: 177.3633s
2022-10-10 04:22:18,161 [INFO] Process 6 - epoch 17: mean_policy_losses: -293.865, mean_net_lifetime: 2117.4583, mean_mc_travel_dist: 1089.3529, mean_entropies: 1.5428, m_net_lifetime_valid: 3518.0606, took: 2277.1470s, (144.3613 / 100 batches)

2022-10-10 04:22:30,232 [INFO] 	Process 2 - batch 17399: mean_policy_losses: 73.038, mean_net_lifetime: 4786.4461, mean_mc_travel_dist: 2182.7289, mean_rewards: 177.4462, total_rewards: 2638.9411, mean_steps: 26.1000, mean_ecr: 0.0405 mean_entropies: 1.6363, took: 121.8367s
2022-10-10 04:22:35,299 [INFO] 	Process 7 - batch 17899: mean_policy_losses: -315.995, mean_net_lifetime: 3854.9126, mean_mc_travel_dist: 1914.6850, mean_rewards: 168.1735, total_rewards: 1993.8500, mean_steps: 21.7500, mean_ecr: 0.0432 mean_entropies: 2.1669, took: 103.3041s
2022-10-10 04:23:24,364 [INFO] 	Process 6 - batch 25599: mean_policy_losses: -272.827, mean_net_lifetime: 2430.3304, mean_mc_travel_dist: 1125.4039, mean_rewards: 200.7186, total_rewards: 1348.8342, mean_steps: 11.0200, mean_ecr: 0.0563 mean_entropies: 1.0501, took: 1252.5918s
2022-10-10 04:23:32,325 [INFO] 	Process 3 - batch 17499: mean_policy_losses: 148.980, mean_net_lifetime: 4358.1284, mean_mc_travel_dist: 1812.5808, mean_rewards: 185.7062, total_rewards: 2568.1649, mean_steps: 22.6400, mean_ecr: 0.0477 mean_entropies: 1.4634, took: 123.4004s
2022-10-10 04:24:15,123 [INFO] 	Process 7 - batch 17999: mean_policy_losses: -157.930, mean_net_lifetime: 3772.0888, mean_mc_travel_dist: 1923.6418, mean_rewards: 174.5860, total_rewards: 1901.2688, mean_steps: 20.3000, mean_ecr: 0.0430 mean_entropies: 2.1210, took: 99.8240s
2022-10-10 04:24:35,914 [INFO] 	Process 6 - batch 25699: mean_policy_losses: -216.220, mean_net_lifetime: 2646.6476, mean_mc_travel_dist: 1183.7440, mean_rewards: 197.6243, total_rewards: 1505.8336, mean_steps: 12.2500, mean_ecr: 0.0561 mean_entropies: 0.9856, took: 71.5510s
2022-10-10 04:24:36,358 [INFO] 	Process 2 - batch 17499: mean_policy_losses: 165.853, mean_net_lifetime: 4606.3472, mean_mc_travel_dist: 2067.2160, mean_rewards: 170.2610, total_rewards: 2560.6767, mean_steps: 26.3200, mean_ecr: 0.0410 mean_entropies: 1.4464, took: 126.1270s
2022-10-10 04:24:37,041 [INFO] 	Process 1 - batch 14899: mean_policy_losses: -32.718, mean_net_lifetime: 4651.4385, mean_mc_travel_dist: 2328.8383, mean_rewards: 130.4417, total_rewards: 2343.9582, mean_steps: 35.1300, mean_ecr: 0.0401 mean_entropies: 1.6028, took: 179.5995s
2022-10-10 04:24:47,275 [INFO] Process 4 - epoch 14: mean_policy_losses: 29.445, mean_net_lifetime: 2986.1523, mean_mc_travel_dist: 1311.6978, mean_entropies: 1.9601, m_net_lifetime_valid: 3672.9919, took: 2285.6068s, (176.6367 / 100 batches)

2022-10-10 04:25:38,384 [INFO] 	Process 3 - batch 17599: mean_policy_losses: 103.050, mean_net_lifetime: 4136.5705, mean_mc_travel_dist: 1743.5101, mean_rewards: 169.9389, total_rewards: 2418.8309, mean_steps: 23.5300, mean_ecr: 0.0480 mean_entropies: 1.3561, took: 126.0591s
2022-10-10 04:25:48,537 [INFO] 	Process 6 - batch 25799: mean_policy_losses: -215.877, mean_net_lifetime: 2763.1380, mean_mc_travel_dist: 1223.8378, mean_rewards: 204.8969, total_rewards: 1576.5557, mean_steps: 12.4000, mean_ecr: 0.0560 mean_entropies: 0.9647, took: 72.6222s
2022-10-10 04:26:11,503 [INFO] 	Process 4 - batch 21099: mean_policy_losses: 87.559, mean_net_lifetime: 3684.7367, mean_mc_travel_dist: 1431.9974, mean_rewards: 213.2003, total_rewards: 2286.6959, mean_steps: 16.1700, mean_ecr: 0.0504 mean_entropies: 1.7611, took: 1106.2355s
2022-10-10 04:26:41,607 [INFO] 	Process 2 - batch 17599: mean_policy_losses: 26.969, mean_net_lifetime: 4285.4462, mean_mc_travel_dist: 1958.2108, mean_rewards: 156.7521, total_rewards: 2352.2150, mean_steps: 26.3700, mean_ecr: 0.0413 mean_entropies: 1.3274, took: 125.2481s
2022-10-10 04:27:01,583 [INFO] 	Process 6 - batch 25899: mean_policy_losses: -164.047, mean_net_lifetime: 2922.3813, mean_mc_travel_dist: 1240.1405, mean_rewards: 213.4248, total_rewards: 1714.1887, mean_steps: 12.5100, mean_ecr: 0.0559 mean_entropies: 0.8930, took: 73.0460s
2022-10-10 04:27:28,197 [INFO] 	Process 1 - batch 14999: mean_policy_losses: -45.465, mean_net_lifetime: 4594.9503, mean_mc_travel_dist: 2360.9321, mean_rewards: 136.1910, total_rewards: 2260.3108, mean_steps: 33.0600, mean_ecr: 0.0400 mean_entropies: 1.5356, took: 171.1558s
2022-10-10 04:27:32,055 [INFO] 	Process 4 - batch 21199: mean_policy_losses: 12.003, mean_net_lifetime: 3529.7209, mean_mc_travel_dist: 1414.1616, mean_rewards: 214.5903, total_rewards: 2145.4258, mean_steps: 15.4200, mean_ecr: 0.0504 mean_entropies: 1.7541, took: 80.5524s
2022-10-10 04:27:49,954 [INFO] 	Process 3 - batch 17699: mean_policy_losses: 81.980, mean_net_lifetime: 4236.4440, mean_mc_travel_dist: 1755.7759, mean_rewards: 167.2992, total_rewards: 2506.8950, mean_steps: 24.5300, mean_ecr: 0.0481 mean_entropies: 1.3007, took: 131.5687s
2022-10-10 04:27:53,469 [INFO] Process 5 - epoch 11: mean_policy_losses: -2.891, mean_net_lifetime: 4308.5376, mean_mc_travel_dist: 2493.4864, mean_entropies: 2.3584, m_net_lifetime_valid: 3714.1172, took: 3376.4760s, (224.5201 / 100 batches)

2022-10-10 04:28:11,103 [INFO] 	Process 6 - batch 25999: mean_policy_losses: -278.325, mean_net_lifetime: 2694.6707, mean_mc_travel_dist: 1176.4538, mean_rewards: 205.0375, total_rewards: 1549.6447, mean_steps: 12.0300, mean_ecr: 0.0563 mean_entropies: 0.9544, took: 69.5204s
2022-10-10 04:28:49,420 [INFO] 	Process 2 - batch 17699: mean_policy_losses: 67.115, mean_net_lifetime: 4592.7031, mean_mc_travel_dist: 2056.7217, mean_rewards: 166.0128, total_rewards: 2565.2144, mean_steps: 26.8900, mean_ecr: 0.0410 mean_entropies: 1.3869, took: 127.8131s
2022-10-10 04:28:56,329 [INFO] 	Process 4 - batch 21299: mean_policy_losses: -40.809, mean_net_lifetime: 3684.3986, mean_mc_travel_dist: 1457.0838, mean_rewards: 213.6834, total_rewards: 2262.1740, mean_steps: 16.1500, mean_ecr: 0.0502 mean_entropies: 1.7756, took: 84.2746s
2022-10-10 04:29:22,682 [INFO] 	Process 6 - batch 26099: mean_policy_losses: -270.184, mean_net_lifetime: 2759.0492, mean_mc_travel_dist: 1199.6628, mean_rewards: 204.0572, total_rewards: 1596.1044, mean_steps: 12.3200, mean_ecr: 0.0559 mean_entropies: 0.9320, took: 71.5783s
2022-10-10 04:29:59,740 [INFO] 	Process 3 - batch 17799: mean_policy_losses: 90.656, mean_net_lifetime: 4379.1150, mean_mc_travel_dist: 1802.9638, mean_rewards: 176.0704, total_rewards: 2598.5375, mean_steps: 24.0000, mean_ecr: 0.0479 mean_entropies: 1.3160, took: 129.7862s
2022-10-10 04:30:20,178 [INFO] 	Process 4 - batch 21399: mean_policy_losses: 37.997, mean_net_lifetime: 3854.9067, mean_mc_travel_dist: 1493.2582, mean_rewards: 220.3036, total_rewards: 2390.8124, mean_steps: 16.4300, mean_ecr: 0.0499 mean_entropies: 1.7438, took: 83.8485s
2022-10-10 04:30:36,340 [INFO] 	Process 6 - batch 26199: mean_policy_losses: -181.948, mean_net_lifetime: 2918.2964, mean_mc_travel_dist: 1253.3740, mean_rewards: 210.9101, total_rewards: 1704.4374, mean_steps: 12.7600, mean_ecr: 0.0559 mean_entropies: 0.8756, took: 73.6584s
2022-10-10 04:30:40,527 [INFO] 	Process 5 - batch 16599: mean_policy_losses: -44.837, mean_net_lifetime: 5592.3096, mean_mc_travel_dist: 3079.5569, mean_rewards: 165.2786, total_rewards: 2569.5261, mean_steps: 32.3800, mean_ecr: 0.0294 mean_entropies: 1.8054, took: 1375.3657s
2022-10-10 04:30:56,866 [INFO] 	Process 2 - batch 17799: mean_policy_losses: 15.311, mean_net_lifetime: 4485.3324, mean_mc_travel_dist: 2049.5562, mean_rewards: 162.2761, total_rewards: 2462.3224, mean_steps: 26.8600, mean_ecr: 0.0412 mean_entropies: 1.3349, took: 127.4464s
2022-10-10 04:31:42,608 [INFO] 	Process 4 - batch 21499: mean_policy_losses: 31.334, mean_net_lifetime: 3707.6695, mean_mc_travel_dist: 1449.6023, mean_rewards: 219.1049, total_rewards: 2286.3390, mean_steps: 15.8600, mean_ecr: 0.0505 mean_entropies: 1.6959, took: 82.4297s
2022-10-10 04:31:47,714 [INFO] 	Process 6 - batch 26299: mean_policy_losses: -203.049, mean_net_lifetime: 2852.9443, mean_mc_travel_dist: 1223.9829, mean_rewards: 212.4851, total_rewards: 1671.6509, mean_steps: 12.2800, mean_ecr: 0.0560 mean_entropies: 0.8706, took: 71.3738s
2022-10-10 04:32:11,026 [INFO] 	Process 3 - batch 17899: mean_policy_losses: 43.027, mean_net_lifetime: 4247.2365, mean_mc_travel_dist: 1796.9201, mean_rewards: 167.0470, total_rewards: 2481.9220, mean_steps: 24.5800, mean_ecr: 0.0478 mean_entropies: 1.2641, took: 131.2866s
2022-10-10 04:33:00,971 [INFO] 	Process 6 - batch 26399: mean_policy_losses: -197.523, mean_net_lifetime: 2864.1860, mean_mc_travel_dist: 1233.3364, mean_rewards: 207.5816, total_rewards: 1670.4405, mean_steps: 12.7300, mean_ecr: 0.0561 mean_entropies: 0.8944, took: 73.2571s
2022-10-10 04:33:01,013 [INFO] 	Process 2 - batch 17899: mean_policy_losses: 8.267, mean_net_lifetime: 4415.5309, mean_mc_travel_dist: 2017.5926, mean_rewards: 162.6641, total_rewards: 2423.9116, mean_steps: 26.3200, mean_ecr: 0.0412 mean_entropies: 1.3111, took: 124.1460s
2022-10-10 04:33:04,926 [INFO] 	Process 4 - batch 21599: mean_policy_losses: 13.030, mean_net_lifetime: 3705.4204, mean_mc_travel_dist: 1436.2600, mean_rewards: 218.5960, total_rewards: 2296.0677, mean_steps: 15.8200, mean_ecr: 0.0504 mean_entropies: 1.7252, took: 82.3185s
2022-10-10 04:33:22,121 [INFO] 	Process 5 - batch 16699: mean_policy_losses: -118.363, mean_net_lifetime: 5432.4428, mean_mc_travel_dist: 3028.7376, mean_rewards: 163.7467, total_rewards: 2465.8550, mean_steps: 31.5800, mean_ecr: 0.0294 mean_entropies: 1.7729, took: 161.5936s
2022-10-10 04:34:11,325 [INFO] 	Process 6 - batch 26499: mean_policy_losses: -245.889, mean_net_lifetime: 2805.9349, mean_mc_travel_dist: 1214.8814, mean_rewards: 205.3422, total_rewards: 1629.5179, mean_steps: 12.4900, mean_ecr: 0.0562 mean_entropies: 0.9193, took: 70.3551s
2022-10-10 04:34:14,156 [INFO] 	Process 3 - batch 17999: mean_policy_losses: 88.076, mean_net_lifetime: 4433.5466, mean_mc_travel_dist: 1825.4637, mean_rewards: 183.4349, total_rewards: 2637.7749, mean_steps: 23.3100, mean_ecr: 0.0480 mean_entropies: 1.3255, took: 123.1314s
2022-10-10 04:34:23,495 [INFO] 	Process 4 - batch 21699: mean_policy_losses: -43.073, mean_net_lifetime: 3638.5899, mean_mc_travel_dist: 1432.0608, mean_rewards: 217.0377, total_rewards: 2233.8231, mean_steps: 15.7000, mean_ecr: 0.0506 mean_entropies: 1.7361, took: 78.5690s
2022-10-10 04:35:00,315 [INFO] 	Process 2 - batch 17999: mean_policy_losses: 5.045, mean_net_lifetime: 4481.6223, mean_mc_travel_dist: 2045.3240, mean_rewards: 166.5162, total_rewards: 2472.2024, mean_steps: 26.0900, mean_ecr: 0.0411 mean_entropies: 1.3397, took: 119.3025s
2022-10-10 04:35:15,937 [INFO] 	Process 6 - batch 26599: mean_policy_losses: -191.762, mean_net_lifetime: 2913.4463, mean_mc_travel_dist: 1244.5970, mean_rewards: 215.6488, total_rewards: 1699.0077, mean_steps: 12.4200, mean_ecr: 0.0556 mean_entropies: 0.8451, took: 64.6116s
2022-10-10 04:35:40,518 [INFO] 	Process 4 - batch 21799: mean_policy_losses: 105.935, mean_net_lifetime: 3982.6070, mean_mc_travel_dist: 1551.9824, mean_rewards: 226.1264, total_rewards: 2456.5898, mean_steps: 16.5600, mean_ecr: 0.0496 mean_entropies: 1.6094, took: 77.0234s
2022-10-10 04:35:56,563 [INFO] 	Process 5 - batch 16799: mean_policy_losses: -100.778, mean_net_lifetime: 5383.2106, mean_mc_travel_dist: 2995.4933, mean_rewards: 156.8538, total_rewards: 2443.4797, mean_steps: 32.6400, mean_ecr: 0.0296 mean_entropies: 1.7062, took: 154.4421s
2022-10-10 04:36:22,422 [INFO] 	Process 6 - batch 26699: mean_policy_losses: -148.695, mean_net_lifetime: 3083.0265, mean_mc_travel_dist: 1290.7398, mean_rewards: 213.2085, total_rewards: 1824.1059, mean_steps: 13.4300, mean_ecr: 0.0558 mean_entropies: 0.7319, took: 66.4846s
2022-10-10 04:36:58,961 [INFO] 	Process 4 - batch 21899: mean_policy_losses: 164.593, mean_net_lifetime: 4239.4501, mean_mc_travel_dist: 1618.1887, mean_rewards: 233.2186, total_rewards: 2648.7290, mean_steps: 17.1100, mean_ecr: 0.0491 mean_entropies: 1.5584, took: 78.4425s
2022-10-10 04:37:26,325 [INFO] 	Process 6 - batch 26799: mean_policy_losses: -134.215, mean_net_lifetime: 3033.3982, mean_mc_travel_dist: 1280.5857, mean_rewards: 214.2709, total_rewards: 1783.7866, mean_steps: 13.1500, mean_ecr: 0.0560 mean_entropies: 0.6844, took: 63.9027s
2022-10-10 04:38:17,927 [INFO] 	Process 4 - batch 21999: mean_policy_losses: 188.857, mean_net_lifetime: 4370.0773, mean_mc_travel_dist: 1649.6635, mean_rewards: 235.9599, total_rewards: 2747.1283, mean_steps: 17.4600, mean_ecr: 0.0488 mean_entropies: 1.4793, took: 78.9655s
2022-10-10 04:38:28,223 [INFO] 	Process 5 - batch 16899: mean_policy_losses: -159.740, mean_net_lifetime: 5218.4296, mean_mc_travel_dist: 2941.8767, mean_rewards: 144.6654, total_rewards: 2330.2602, mean_steps: 34.2900, mean_ecr: 0.0294 mean_entropies: 1.5318, took: 151.6610s
2022-10-10 04:38:36,031 [INFO] 	Process 6 - batch 26899: mean_policy_losses: -126.011, mean_net_lifetime: 3151.1132, mean_mc_travel_dist: 1306.4732, mean_rewards: 208.1732, total_rewards: 1865.6388, mean_steps: 14.1300, mean_ecr: 0.0560 mean_entropies: 0.6592, took: 69.7062s
2022-10-10 04:39:41,942 [INFO] 	Process 4 - batch 22099: mean_policy_losses: 239.732, mean_net_lifetime: 4585.5542, mean_mc_travel_dist: 1706.7408, mean_rewards: 240.7468, total_rewards: 2905.6540, mean_steps: 18.0800, mean_ecr: 0.0484 mean_entropies: 1.4125, took: 84.0145s
2022-10-10 04:39:45,017 [INFO] 	Process 6 - batch 26999: mean_policy_losses: -112.786, mean_net_lifetime: 3205.8730, mean_mc_travel_dist: 1328.5220, mean_rewards: 214.2021, total_rewards: 1908.5087, mean_steps: 13.9500, mean_ecr: 0.0557 mean_entropies: 0.6154, took: 68.9858s
2022-10-10 04:40:57,429 [INFO] 	Process 5 - batch 16999: mean_policy_losses: -282.309, mean_net_lifetime: 4864.2641, mean_mc_travel_dist: 2849.3174, mean_rewards: 136.0939, total_rewards: 2078.6134, mean_steps: 34.0600, mean_ecr: 0.0294 mean_entropies: 1.4509, took: 149.2058s
2022-10-10 04:41:02,201 [INFO] 	Process 4 - batch 22199: mean_policy_losses: 180.707, mean_net_lifetime: 4641.5755, mean_mc_travel_dist: 1732.2763, mean_rewards: 243.3547, total_rewards: 2940.9636, mean_steps: 18.0600, mean_ecr: 0.0481 mean_entropies: 1.4318, took: 80.2595s
2022-10-10 04:41:43,859 [INFO] Process 7 - epoch 12: mean_policy_losses: -11.756, mean_net_lifetime: 3803.6455, mean_mc_travel_dist: 1874.2478, mean_entropies: 2.2485, m_net_lifetime_valid: 3893.2711, took: 2640.5707s, (211.3826 / 100 batches)

2022-10-10 04:42:23,374 [INFO] 	Process 4 - batch 22299: mean_policy_losses: 107.639, mean_net_lifetime: 4400.5980, mean_mc_travel_dist: 1620.3125, mean_rewards: 232.8825, total_rewards: 2799.8566, mean_steps: 17.8200, mean_ecr: 0.0488 mean_entropies: 1.4748, took: 81.1734s
2022-10-10 04:43:27,209 [INFO] 	Process 5 - batch 17099: mean_policy_losses: -208.408, mean_net_lifetime: 5297.4044, mean_mc_travel_dist: 3016.7695, mean_rewards: 148.7352, total_rewards: 2344.8016, mean_steps: 34.1600, mean_ecr: 0.0293 mean_entropies: 1.4437, took: 149.7794s
2022-10-10 04:43:46,583 [INFO] 	Process 4 - batch 22399: mean_policy_losses: 84.300, mean_net_lifetime: 4475.1478, mean_mc_travel_dist: 1692.1573, mean_rewards: 228.4733, total_rewards: 2805.7229, mean_steps: 18.5800, mean_ecr: 0.0488 mean_entropies: 1.4682, took: 83.2094s
2022-10-10 04:43:46,905 [INFO] 	Process 7 - batch 18099: mean_policy_losses: -144.453, mean_net_lifetime: 4857.1389, mean_mc_travel_dist: 2255.8182, mean_rewards: 159.2934, total_rewards: 2659.6483, mean_steps: 29.3900, mean_ecr: 0.0425 mean_entropies: 1.9014, took: 1171.7825s
2022-10-10 04:45:10,850 [INFO] 	Process 4 - batch 22499: mean_policy_losses: 185.774, mean_net_lifetime: 4526.5828, mean_mc_travel_dist: 1675.1317, mean_rewards: 229.2071, total_rewards: 2884.9469, mean_steps: 18.7700, mean_ecr: 0.0487 mean_entropies: 1.4705, took: 84.2667s
2022-10-10 04:45:33,540 [INFO] Process 1 - epoch 10: mean_policy_losses: 134.846, mean_net_lifetime: 4601.3301, mean_mc_travel_dist: 2393.4936, mean_entropies: 1.9529, m_net_lifetime_valid: 3871.4278, took: 3669.3234s, (254.6583 / 100 batches)

2022-10-10 04:45:41,262 [INFO] 	Process 7 - batch 18199: mean_policy_losses: -149.963, mean_net_lifetime: 4654.8261, mean_mc_travel_dist: 2191.4405, mean_rewards: 161.1702, total_rewards: 2507.6564, mean_steps: 27.6600, mean_ecr: 0.0426 mean_entropies: 1.9149, took: 114.3573s
2022-10-10 04:45:54,319 [INFO] 	Process 5 - batch 17199: mean_policy_losses: -134.770, mean_net_lifetime: 5361.3688, mean_mc_travel_dist: 3038.4841, mean_rewards: 152.0130, total_rewards: 2393.6275, mean_steps: 33.9200, mean_ecr: 0.0292 mean_entropies: 1.4506, took: 147.1102s
2022-10-10 04:47:32,080 [INFO] 	Process 7 - batch 18299: mean_policy_losses: -7.656, mean_net_lifetime: 4279.6690, mean_mc_travel_dist: 2091.2142, mean_rewards: 171.8965, total_rewards: 2236.7317, mean_steps: 23.7500, mean_ecr: 0.0426 mean_entropies: 2.0030, took: 110.8167s
2022-10-10 04:48:10,492 [INFO] 	Process 5 - batch 17299: mean_policy_losses: 147.930, mean_net_lifetime: 5704.8587, mean_mc_travel_dist: 2989.8690, mean_rewards: 183.6325, total_rewards: 2771.1973, mean_steps: 29.8900, mean_ecr: 0.0305 mean_entropies: 1.7534, took: 136.1723s
2022-10-10 04:48:39,224 [INFO] 	Process 1 - batch 15099: mean_policy_losses: -80.578, mean_net_lifetime: 4568.4914, mean_mc_travel_dist: 2344.0883, mean_rewards: 108.6624, total_rewards: 2249.5485, mean_steps: 41.7100, mean_ecr: 0.0401 mean_entropies: 1.2902, took: 1271.0263s
2022-10-10 04:49:13,774 [INFO] 	Process 7 - batch 18399: mean_policy_losses: -151.200, mean_net_lifetime: 3894.8608, mean_mc_travel_dist: 1983.3166, mean_rewards: 171.4260, total_rewards: 1967.6705, mean_steps: 21.4100, mean_ecr: 0.0428 mean_entropies: 2.0197, took: 101.6934s
2022-10-10 04:50:19,445 [INFO] 	Process 5 - batch 17399: mean_policy_losses: 194.092, mean_net_lifetime: 5515.9452, mean_mc_travel_dist: 2924.0604, mean_rewards: 189.7948, total_rewards: 2652.1822, mean_steps: 27.7700, mean_ecr: 0.0309 mean_entropies: 1.7977, took: 128.9538s
2022-10-10 04:50:39,256 [INFO] 	Process 7 - batch 18499: mean_policy_losses: -281.895, mean_net_lifetime: 3177.8185, mean_mc_travel_dist: 1747.4802, mean_rewards: 170.3565, total_rewards: 1474.1132, mean_steps: 17.3700, mean_ecr: 0.0435 mean_entropies: 2.0070, took: 85.4827s
2022-10-10 04:51:28,507 [INFO] 	Process 1 - batch 15199: mean_policy_losses: 86.263, mean_net_lifetime: 4919.4453, mean_mc_travel_dist: 2383.7667, mean_rewards: 128.0477, total_rewards: 2565.3291, mean_steps: 37.9100, mean_ecr: 0.0399 mean_entropies: 1.5709, took: 169.2834s
2022-10-10 04:51:33,225 [INFO] Process 3 - epoch 12: mean_policy_losses: 144.566, mean_net_lifetime: 3830.5269, mean_mc_travel_dist: 1693.8846, mean_entropies: 1.7515, m_net_lifetime_valid: 3787.4129, took: 2864.3878s, (214.6888 / 100 batches)

2022-10-10 04:52:09,293 [INFO] 	Process 7 - batch 18599: mean_policy_losses: -219.196, mean_net_lifetime: 3425.6500, mean_mc_travel_dist: 1823.6763, mean_rewards: 174.2728, total_rewards: 1655.1321, mean_steps: 18.2100, mean_ecr: 0.0431 mean_entropies: 2.0144, took: 90.0374s
2022-10-10 04:52:11,412 [INFO] Process 2 - epoch 12: mean_policy_losses: 17.979, mean_net_lifetime: 3742.0095, mean_mc_travel_dist: 1850.9708, mean_entropies: 1.8297, m_net_lifetime_valid: 3836.6447, took: 2860.6400s, (214.9481 / 100 batches)

2022-10-10 04:52:24,405 [INFO] 	Process 5 - batch 17499: mean_policy_losses: 191.833, mean_net_lifetime: 5224.8210, mean_mc_travel_dist: 2772.8061, mean_rewards: 189.9370, total_rewards: 2520.7624, mean_steps: 26.2600, mean_ecr: 0.0313 mean_entropies: 1.8356, took: 124.9596s
2022-10-10 04:53:32,244 [INFO] 	Process 3 - batch 18099: mean_policy_losses: 82.551, mean_net_lifetime: 4282.7885, mean_mc_travel_dist: 1818.3218, mean_rewards: 180.9464, total_rewards: 2483.8008, mean_steps: 22.7500, mean_ecr: 0.0478 mean_entropies: 1.3223, took: 1158.0867s
2022-10-10 04:54:05,146 [INFO] 	Process 7 - batch 18699: mean_policy_losses: -344.840, mean_net_lifetime: 3921.3258, mean_mc_travel_dist: 1969.0982, mean_rewards: 169.3533, total_rewards: 2011.5519, mean_steps: 21.7900, mean_ecr: 0.0428 mean_entropies: 2.0347, took: 115.8533s
2022-10-10 04:54:27,519 [INFO] 	Process 2 - batch 18099: mean_policy_losses: 32.150, mean_net_lifetime: 4700.7944, mean_mc_travel_dist: 2176.2229, mean_rewards: 176.0679, total_rewards: 2563.9596, mean_steps: 25.8500, mean_ecr: 0.0405 mean_entropies: 1.4279, took: 1167.2044s
2022-10-10 04:54:46,824 [INFO] 	Process 1 - batch 15299: mean_policy_losses: -135.696, mean_net_lifetime: 4697.0633, mean_mc_travel_dist: 2353.2883, mean_rewards: 113.5028, total_rewards: 2383.4593, mean_steps: 40.9900, mean_ecr: 0.0400 mean_entropies: 1.4303, took: 198.3171s
2022-10-10 04:54:52,620 [INFO] 	Process 5 - batch 17599: mean_policy_losses: 94.996, mean_net_lifetime: 6006.7258, mean_mc_travel_dist: 3088.9962, mean_rewards: 194.1746, total_rewards: 2974.5096, mean_steps: 29.6800, mean_ecr: 0.0307 mean_entropies: 1.8330, took: 148.2153s
2022-10-10 04:55:27,068 [INFO] 	Process 3 - batch 18199: mean_policy_losses: 118.205, mean_net_lifetime: 4535.3490, mean_mc_travel_dist: 1878.9898, mean_rewards: 194.6027, total_rewards: 2689.0745, mean_steps: 22.4000, mean_ecr: 0.0476 mean_entropies: 1.3589, took: 114.8241s
2022-10-10 04:56:06,014 [INFO] 	Process 7 - batch 18799: mean_policy_losses: -306.047, mean_net_lifetime: 4163.4321, mean_mc_travel_dist: 2024.0583, mean_rewards: 172.0372, total_rewards: 2191.1647, mean_steps: 22.8100, mean_ecr: 0.0430 mean_entropies: 2.0533, took: 120.8678s
2022-10-10 04:56:42,090 [INFO] 	Process 2 - batch 18199: mean_policy_losses: 20.029, mean_net_lifetime: 4750.5928, mean_mc_travel_dist: 2175.1352, mean_rewards: 180.0208, total_rewards: 2608.0622, mean_steps: 25.5100, mean_ecr: 0.0405 mean_entropies: 1.4629, took: 134.5710s
2022-10-10 04:57:21,263 [INFO] 	Process 3 - batch 18299: mean_policy_losses: 116.793, mean_net_lifetime: 4535.2172, mean_mc_travel_dist: 1881.0095, mean_rewards: 197.8518, total_rewards: 2679.5994, mean_steps: 21.9600, mean_ecr: 0.0474 mean_entropies: 1.3821, took: 114.1926s
2022-10-10 04:57:22,630 [INFO] 	Process 5 - batch 17699: mean_policy_losses: 110.050, mean_net_lifetime: 6134.4600, mean_mc_travel_dist: 3139.8453, mean_rewards: 193.6845, total_rewards: 3051.5526, mean_steps: 30.3500, mean_ecr: 0.0305 mean_entropies: 1.8573, took: 150.0056s
2022-10-10 04:57:53,635 [INFO] Process 6 - epoch 18: mean_policy_losses: -288.500, mean_net_lifetime: 2159.2456, mean_mc_travel_dist: 1097.4471, mean_entropies: 1.5048, m_net_lifetime_valid: 3551.7418, took: 2135.4711s, (144.6116 / 100 batches)

2022-10-10 04:57:58,211 [INFO] 	Process 1 - batch 15399: mean_policy_losses: -166.990, mean_net_lifetime: 4642.3437, mean_mc_travel_dist: 2301.3470, mean_rewards: 115.4404, total_rewards: 2369.1372, mean_steps: 39.7700, mean_ecr: 0.0402 mean_entropies: 1.4582, took: 191.3853s
2022-10-10 04:57:58,798 [INFO] 	Process 7 - batch 18899: mean_policy_losses: -396.288, mean_net_lifetime: 3807.5979, mean_mc_travel_dist: 1909.1575, mean_rewards: 170.8210, total_rewards: 1942.5835, mean_steps: 21.1400, mean_ecr: 0.0431 mean_entropies: 2.0519, took: 112.7833s
2022-10-10 04:58:58,852 [INFO] 	Process 2 - batch 18299: mean_policy_losses: 110.734, mean_net_lifetime: 4831.9549, mean_mc_travel_dist: 2202.2488, mean_rewards: 182.7540, total_rewards: 2665.3036, mean_steps: 25.6200, mean_ecr: 0.0405 mean_entropies: 1.4939, took: 136.7615s
2022-10-10 04:58:59,033 [INFO] 	Process 6 - batch 27099: mean_policy_losses: -241.833, mean_net_lifetime: 2632.8293, mean_mc_travel_dist: 1156.8063, mean_rewards: 210.9283, total_rewards: 1526.2509, mean_steps: 11.2900, mean_ecr: 0.0560 mean_entropies: 1.0173, took: 1154.0157s
2022-10-10 04:59:17,856 [INFO] 	Process 3 - batch 18399: mean_policy_losses: 92.982, mean_net_lifetime: 4213.1847, mean_mc_travel_dist: 1790.3013, mean_rewards: 183.6138, total_rewards: 2446.4504, mean_steps: 22.0600, mean_ecr: 0.0480 mean_entropies: 1.3923, took: 116.5957s
2022-10-10 04:59:40,187 [INFO] 	Process 5 - batch 17799: mean_policy_losses: 97.119, mean_net_lifetime: 5484.6305, mean_mc_travel_dist: 2864.5765, mean_rewards: 194.9173, total_rewards: 2681.9870, mean_steps: 26.8800, mean_ecr: 0.0313 mean_entropies: 1.8549, took: 137.5612s
2022-10-10 04:59:43,508 [INFO] 	Process 7 - batch 18999: mean_policy_losses: -299.034, mean_net_lifetime: 3599.5904, mean_mc_travel_dist: 1882.4754, mean_rewards: 177.9145, total_rewards: 1771.7866, mean_steps: 18.9200, mean_ecr: 0.0431 mean_entropies: 2.0500, took: 104.7105s
2022-10-10 05:00:05,107 [INFO] 	Process 6 - batch 27199: mean_policy_losses: -304.938, mean_net_lifetime: 2565.8385, mean_mc_travel_dist: 1147.1316, mean_rewards: 203.2226, total_rewards: 1455.2413, mean_steps: 11.4300, mean_ecr: 0.0557 mean_entropies: 0.9528, took: 66.0744s
2022-10-10 05:01:09,794 [INFO] 	Process 1 - batch 15499: mean_policy_losses: -41.007, mean_net_lifetime: 4853.5188, mean_mc_travel_dist: 2380.2201, mean_rewards: 125.5127, total_rewards: 2508.7502, mean_steps: 38.0700, mean_ecr: 0.0399 mean_entropies: 1.4875, took: 191.5832s
2022-10-10 05:01:14,394 [INFO] 	Process 6 - batch 27299: mean_policy_losses: -208.526, mean_net_lifetime: 2790.0292, mean_mc_travel_dist: 1194.6516, mean_rewards: 210.6753, total_rewards: 1631.0459, mean_steps: 12.1100, mean_ecr: 0.0559 mean_entropies: 0.8802, took: 69.2874s
2022-10-10 05:01:16,066 [INFO] 	Process 2 - batch 18399: mean_policy_losses: 113.325, mean_net_lifetime: 4724.8755, mean_mc_travel_dist: 2130.7386, mean_rewards: 175.0763, total_rewards: 2623.8808, mean_steps: 26.1600, mean_ecr: 0.0407 mean_entropies: 1.3763, took: 137.2134s
2022-10-10 05:01:23,841 [INFO] 	Process 3 - batch 18499: mean_policy_losses: 112.933, mean_net_lifetime: 4367.2390, mean_mc_travel_dist: 1815.7586, mean_rewards: 177.4338, total_rewards: 2578.3039, mean_steps: 23.7600, mean_ecr: 0.0479 mean_entropies: 1.2934, took: 125.9848s
2022-10-10 05:01:34,847 [INFO] 	Process 7 - batch 19099: mean_policy_losses: -259.277, mean_net_lifetime: 3827.4361, mean_mc_travel_dist: 1935.7167, mean_rewards: 173.5588, total_rewards: 1938.7708, mean_steps: 20.8300, mean_ecr: 0.0429 mean_entropies: 2.0135, took: 111.3361s
2022-10-10 05:02:05,928 [INFO] 	Process 5 - batch 17899: mean_policy_losses: 53.895, mean_net_lifetime: 5422.9338, mean_mc_travel_dist: 2833.4375, mean_rewards: 183.8045, total_rewards: 2644.7070, mean_steps: 28.2000, mean_ecr: 0.0310 mean_entropies: 1.8010, took: 145.7406s
2022-10-10 05:02:24,334 [INFO] 	Process 6 - batch 27399: mean_policy_losses: -160.728, mean_net_lifetime: 2761.2902, mean_mc_travel_dist: 1193.9180, mean_rewards: 207.2706, total_rewards: 1599.5702, mean_steps: 12.1600, mean_ecr: 0.0558 mean_entropies: 0.8846, took: 69.9401s
2022-10-10 05:03:29,386 [INFO] 	Process 3 - batch 18599: mean_policy_losses: 145.573, mean_net_lifetime: 4526.4151, mean_mc_travel_dist: 1852.8520, mean_rewards: 184.6525, total_rewards: 2695.9209, mean_steps: 23.6700, mean_ecr: 0.0476 mean_entropies: 1.3081, took: 125.5453s
2022-10-10 05:03:31,502 [INFO] 	Process 2 - batch 18499: mean_policy_losses: 87.104, mean_net_lifetime: 4645.4598, mean_mc_travel_dist: 2109.8161, mean_rewards: 174.7809, total_rewards: 2567.8119, mean_steps: 25.7400, mean_ecr: 0.0409 mean_entropies: 1.3789, took: 135.4359s
2022-10-10 05:03:35,500 [INFO] 	Process 6 - batch 27499: mean_policy_losses: -232.040, mean_net_lifetime: 2751.6283, mean_mc_travel_dist: 1189.3817, mean_rewards: 203.3703, total_rewards: 1599.1913, mean_steps: 12.4400, mean_ecr: 0.0559 mean_entropies: 0.9046, took: 71.1657s
2022-10-10 05:03:35,960 [INFO] 	Process 7 - batch 19199: mean_policy_losses: -173.528, mean_net_lifetime: 4093.0909, mean_mc_travel_dist: 2000.9792, mean_rewards: 169.7999, total_rewards: 2127.3689, mean_steps: 22.9400, mean_ecr: 0.0429 mean_entropies: 2.0071, took: 121.1163s
2022-10-10 05:03:55,648 [INFO] Process 4 - epoch 15: mean_policy_losses: 33.507, mean_net_lifetime: 3058.3067, mean_mc_travel_dist: 1328.0774, mean_entropies: 1.9366, m_net_lifetime_valid: 3586.5310, took: 2348.3713s, (174.8492 / 100 batches)

2022-10-10 05:04:14,064 [INFO] 	Process 1 - batch 15599: mean_policy_losses: -73.401, mean_net_lifetime: 4654.9337, mean_mc_travel_dist: 2335.6469, mean_rewards: 125.9913, total_rewards: 2343.9194, mean_steps: 36.5500, mean_ecr: 0.0401 mean_entropies: 1.4427, took: 184.2708s
2022-10-10 05:04:36,081 [INFO] 	Process 5 - batch 17999: mean_policy_losses: 83.242, mean_net_lifetime: 5482.7803, mean_mc_travel_dist: 2874.4506, mean_rewards: 184.0433, total_rewards: 2677.8381, mean_steps: 28.7400, mean_ecr: 0.0312 mean_entropies: 1.7953, took: 150.1531s
2022-10-10 05:04:45,249 [INFO] 	Process 6 - batch 27599: mean_policy_losses: -187.913, mean_net_lifetime: 2793.0117, mean_mc_travel_dist: 1206.3563, mean_rewards: 211.2411, total_rewards: 1621.5019, mean_steps: 12.1400, mean_ecr: 0.0558 mean_entropies: 0.8243, took: 69.7432s
2022-10-10 05:05:23,664 [INFO] 	Process 7 - batch 19299: mean_policy_losses: -243.497, mean_net_lifetime: 3764.0452, mean_mc_travel_dist: 1901.1222, mean_rewards: 177.3316, total_rewards: 1906.8687, mean_steps: 19.9300, mean_ecr: 0.0431 mean_entropies: 2.0302, took: 107.7039s
2022-10-10 05:05:26,323 [INFO] 	Process 4 - batch 22599: mean_policy_losses: -52.926, mean_net_lifetime: 3306.1699, mean_mc_travel_dist: 1336.0881, mean_rewards: 197.4692, total_rewards: 2006.5167, mean_steps: 15.6700, mean_ecr: 0.0510 mean_entropies: 1.6576, took: 1215.4723s
2022-10-10 05:05:36,191 [INFO] 	Process 3 - batch 18699: mean_policy_losses: 78.646, mean_net_lifetime: 4228.6940, mean_mc_travel_dist: 1762.8911, mean_rewards: 170.6705, total_rewards: 2488.3506, mean_steps: 23.9100, mean_ecr: 0.0483 mean_entropies: 1.2170, took: 126.8043s
2022-10-10 05:05:51,383 [INFO] 	Process 2 - batch 18599: mean_policy_losses: 51.012, mean_net_lifetime: 4480.2407, mean_mc_travel_dist: 2030.8413, mean_rewards: 162.4494, total_rewards: 2475.1921, mean_steps: 26.6700, mean_ecr: 0.0411 mean_entropies: 1.2584, took: 139.8813s
2022-10-10 05:05:55,132 [INFO] 	Process 6 - batch 27699: mean_policy_losses: -208.120, mean_net_lifetime: 2837.5666, mean_mc_travel_dist: 1225.9101, mean_rewards: 209.6852, total_rewards: 1654.3185, mean_steps: 12.4100, mean_ecr: 0.0559 mean_entropies: 0.8200, took: 69.8890s
2022-10-10 05:06:59,842 [INFO] 	Process 4 - batch 22699: mean_policy_losses: 171.282, mean_net_lifetime: 3988.9735, mean_mc_travel_dist: 1519.2066, mean_rewards: 230.2267, total_rewards: 2491.9929, mean_steps: 16.3400, mean_ecr: 0.0498 mean_entropies: 1.5422, took: 93.5194s
2022-10-10 05:07:09,063 [INFO] 	Process 1 - batch 15699: mean_policy_losses: -74.679, mean_net_lifetime: 4551.5888, mean_mc_travel_dist: 2373.0008, mean_rewards: 129.1614, total_rewards: 2213.3491, mean_steps: 34.9000, mean_ecr: 0.0400 mean_entropies: 1.3461, took: 174.9996s
2022-10-10 05:07:10,046 [INFO] 	Process 6 - batch 27799: mean_policy_losses: -132.745, mean_net_lifetime: 3139.0218, mean_mc_travel_dist: 1296.6213, mean_rewards: 214.4410, total_rewards: 1868.4349, mean_steps: 13.5400, mean_ecr: 0.0559 mean_entropies: 0.7312, took: 74.9125s
2022-10-10 05:07:26,655 [INFO] 	Process 7 - batch 19399: mean_policy_losses: -62.991, mean_net_lifetime: 4403.7896, mean_mc_travel_dist: 2093.8701, mean_rewards: 180.4318, total_rewards: 2342.1032, mean_steps: 23.2400, mean_ecr: 0.0426 mean_entropies: 1.9981, took: 122.9908s
2022-10-10 05:07:50,781 [INFO] 	Process 3 - batch 18799: mean_policy_losses: 66.687, mean_net_lifetime: 4360.1051, mean_mc_travel_dist: 1786.1096, mean_rewards: 166.0153, total_rewards: 2594.6196, mean_steps: 25.4500, mean_ecr: 0.0480 mean_entropies: 1.1963, took: 134.5907s
2022-10-10 05:08:13,691 [INFO] 	Process 2 - batch 18699: mean_policy_losses: -26.217, mean_net_lifetime: 4370.5944, mean_mc_travel_dist: 2059.1653, mean_rewards: 154.1851, total_rewards: 2344.7233, mean_steps: 27.4700, mean_ecr: 0.0411 mean_entropies: 1.1757, took: 142.3093s
2022-10-10 05:08:22,535 [INFO] 	Process 6 - batch 27899: mean_policy_losses: -202.029, mean_net_lifetime: 2838.3566, mean_mc_travel_dist: 1222.2275, mean_rewards: 201.3997, total_rewards: 1658.4486, mean_steps: 12.9100, mean_ecr: 0.0561 mean_entropies: 0.8127, took: 72.4906s
2022-10-10 05:08:31,191 [INFO] 	Process 4 - batch 22799: mean_policy_losses: 118.835, mean_net_lifetime: 4004.4333, mean_mc_travel_dist: 1550.5801, mean_rewards: 229.3773, total_rewards: 2482.0547, mean_steps: 16.4000, mean_ecr: 0.0495 mean_entropies: 1.5989, took: 91.3480s
2022-10-10 05:09:15,279 [INFO] 	Process 7 - batch 19499: mean_policy_losses: -229.690, mean_net_lifetime: 4037.7537, mean_mc_travel_dist: 2012.2800, mean_rewards: 176.7121, total_rewards: 2073.4402, mean_steps: 21.7800, mean_ecr: 0.0429 mean_entropies: 2.0073, took: 108.6251s
2022-10-10 05:09:31,032 [INFO] 	Process 6 - batch 27999: mean_policy_losses: -146.996, mean_net_lifetime: 3013.1274, mean_mc_travel_dist: 1267.5688, mean_rewards: 215.1386, total_rewards: 1783.4168, mean_steps: 12.9300, mean_ecr: 0.0558 mean_entropies: 0.7710, took: 68.4978s
2022-10-10 05:09:50,041 [INFO] 	Process 4 - batch 22899: mean_policy_losses: 52.116, mean_net_lifetime: 3684.5649, mean_mc_travel_dist: 1469.4517, mean_rewards: 221.9861, total_rewards: 2245.8205, mean_steps: 15.5000, mean_ecr: 0.0502 mean_entropies: 1.5121, took: 78.8506s
2022-10-10 05:09:52,437 [INFO] 	Process 3 - batch 18899: mean_policy_losses: 74.184, mean_net_lifetime: 4276.1943, mean_mc_travel_dist: 1775.4034, mean_rewards: 169.9334, total_rewards: 2524.9958, mean_steps: 24.3400, mean_ecr: 0.0482 mean_entropies: 1.2176, took: 121.6562s
2022-10-10 05:09:54,343 [INFO] 	Process 1 - batch 15799: mean_policy_losses: -72.228, mean_net_lifetime: 4552.3706, mean_mc_travel_dist: 2349.7174, mean_rewards: 134.0611, total_rewards: 2230.8448, mean_steps: 33.7500, mean_ecr: 0.0401 mean_entropies: 1.3841, took: 165.2803s
2022-10-10 05:10:20,784 [INFO] 	Process 2 - batch 18799: mean_policy_losses: 9.199, mean_net_lifetime: 4370.4480, mean_mc_travel_dist: 2003.2115, mean_rewards: 156.4274, total_rewards: 2396.1203, mean_steps: 27.0400, mean_ecr: 0.0413 mean_entropies: 1.1884, took: 127.0926s
2022-10-10 05:10:38,310 [INFO] 	Process 6 - batch 28099: mean_policy_losses: -106.105, mean_net_lifetime: 3152.5628, mean_mc_travel_dist: 1305.8587, mean_rewards: 221.3232, total_rewards: 1885.9474, mean_steps: 13.1800, mean_ecr: 0.0558 mean_entropies: 0.7348, took: 67.2778s
2022-10-10 05:11:11,740 [INFO] 	Process 4 - batch 22999: mean_policy_losses: 96.652, mean_net_lifetime: 3991.4273, mean_mc_travel_dist: 1533.3491, mean_rewards: 225.7983, total_rewards: 2491.5665, mean_steps: 16.6400, mean_ecr: 0.0496 mean_entropies: 1.5778, took: 81.7002s
2022-10-10 05:11:45,262 [INFO] 	Process 6 - batch 28199: mean_policy_losses: -178.870, mean_net_lifetime: 3031.2812, mean_mc_travel_dist: 1272.0917, mean_rewards: 219.7022, total_rewards: 1791.6320, mean_steps: 12.7500, mean_ecr: 0.0560 mean_entropies: 0.8089, took: 66.9515s
2022-10-10 05:11:48,119 [INFO] 	Process 3 - batch 18999: mean_policy_losses: 56.822, mean_net_lifetime: 4339.3368, mean_mc_travel_dist: 1791.2108, mean_rewards: 178.1873, total_rewards: 2568.4421, mean_steps: 23.5000, mean_ecr: 0.0480 mean_entropies: 1.2282, took: 115.6824s
2022-10-10 05:12:21,521 [INFO] 	Process 2 - batch 18899: mean_policy_losses: 21.373, mean_net_lifetime: 4552.0000, mean_mc_travel_dist: 2073.0047, mean_rewards: 167.5550, total_rewards: 2509.0535, mean_steps: 26.3800, mean_ecr: 0.0411 mean_entropies: 1.2589, took: 120.7364s
2022-10-10 05:12:31,623 [INFO] 	Process 4 - batch 23099: mean_policy_losses: 77.758, mean_net_lifetime: 3950.8218, mean_mc_travel_dist: 1511.2929, mean_rewards: 227.9937, total_rewards: 2462.1761, mean_steps: 16.2400, mean_ecr: 0.0499 mean_entropies: 1.6022, took: 79.8830s
2022-10-10 05:12:36,175 [INFO] 	Process 1 - batch 15899: mean_policy_losses: -109.329, mean_net_lifetime: 4572.7534, mean_mc_travel_dist: 2371.7275, mean_rewards: 131.9783, total_rewards: 2232.9607, mean_steps: 34.2600, mean_ecr: 0.0400 mean_entropies: 1.4091, took: 161.8314s
2022-10-10 05:12:48,848 [INFO] 	Process 6 - batch 28299: mean_policy_losses: -221.020, mean_net_lifetime: 2924.8299, mean_mc_travel_dist: 1246.4887, mean_rewards: 218.2433, total_rewards: 1712.2879, mean_steps: 12.2500, mean_ecr: 0.0557 mean_entropies: 0.8056, took: 63.5851s
2022-10-10 05:13:41,535 [INFO] 	Process 3 - batch 19099: mean_policy_losses: 70.080, mean_net_lifetime: 4324.6051, mean_mc_travel_dist: 1806.3412, mean_rewards: 178.9266, total_rewards: 2544.2754, mean_steps: 23.3400, mean_ecr: 0.0481 mean_entropies: 1.2677, took: 113.4160s
2022-10-10 05:13:50,689 [INFO] 	Process 4 - batch 23199: mean_policy_losses: -30.342, mean_net_lifetime: 3716.1879, mean_mc_travel_dist: 1455.9733, mean_rewards: 215.9870, total_rewards: 2282.8467, mean_steps: 16.0900, mean_ecr: 0.0502 mean_entropies: 1.6025, took: 79.0648s
2022-10-10 05:13:56,326 [INFO] 	Process 6 - batch 28399: mean_policy_losses: -181.406, mean_net_lifetime: 3079.7223, mean_mc_travel_dist: 1287.7692, mean_rewards: 219.0157, total_rewards: 1828.7381, mean_steps: 12.9500, mean_ecr: 0.0558 mean_entropies: 0.8285, took: 67.4792s
2022-10-10 05:14:22,162 [INFO] 	Process 2 - batch 18999: mean_policy_losses: 25.063, mean_net_lifetime: 4575.1988, mean_mc_travel_dist: 2076.5167, mean_rewards: 168.5826, total_rewards: 2527.8095, mean_steps: 26.3000, mean_ecr: 0.0409 mean_entropies: 1.3043, took: 120.6401s
2022-10-10 05:14:59,355 [INFO] 	Process 6 - batch 28499: mean_policy_losses: -234.417, mean_net_lifetime: 2816.3296, mean_mc_travel_dist: 1216.0092, mean_rewards: 213.8819, total_rewards: 1643.1236, mean_steps: 12.0600, mean_ecr: 0.0559 mean_entropies: 0.8390, took: 63.0286s
2022-10-10 05:15:07,090 [INFO] 	Process 1 - batch 15999: mean_policy_losses: -106.181, mean_net_lifetime: 4555.1053, mean_mc_travel_dist: 2313.0881, mean_rewards: 138.7694, total_rewards: 2271.2220, mean_steps: 32.3200, mean_ecr: 0.0402 mean_entropies: 1.4781, took: 150.9159s
2022-10-10 05:15:08,391 [INFO] 	Process 4 - batch 23299: mean_policy_losses: 69.429, mean_net_lifetime: 3949.4076, mean_mc_travel_dist: 1537.5195, mean_rewards: 234.4837, total_rewards: 2439.1814, mean_steps: 15.8100, mean_ecr: 0.0498 mean_entropies: 1.6025, took: 77.7025s
2022-10-10 05:15:31,023 [INFO] 	Process 3 - batch 19199: mean_policy_losses: 107.631, mean_net_lifetime: 4548.5245, mean_mc_travel_dist: 1853.2395, mean_rewards: 191.5678, total_rewards: 2715.2069, mean_steps: 22.8700, mean_ecr: 0.0477 mean_entropies: 1.2762, took: 109.4879s
2022-10-10 05:16:17,728 [INFO] 	Process 2 - batch 19099: mean_policy_losses: 9.304, mean_net_lifetime: 4598.6994, mean_mc_travel_dist: 2067.6206, mean_rewards: 172.7177, total_rewards: 2557.9746, mean_steps: 25.8100, mean_ecr: 0.0410 mean_entropies: 1.3335, took: 115.5676s
2022-10-10 05:16:20,694 [INFO] 	Process 4 - batch 23399: mean_policy_losses: -74.574, mean_net_lifetime: 3659.6690, mean_mc_travel_dist: 1452.7728, mean_rewards: 226.1199, total_rewards: 2236.2273, mean_steps: 15.1500, mean_ecr: 0.0502 mean_entropies: 1.6095, took: 72.3028s
2022-10-10 05:17:17,074 [INFO] 	Process 3 - batch 19299: mean_policy_losses: 67.512, mean_net_lifetime: 4360.6719, mean_mc_travel_dist: 1830.6634, mean_rewards: 189.9543, total_rewards: 2554.4737, mean_steps: 22.1000, mean_ecr: 0.0479 mean_entropies: 1.3173, took: 106.0503s
2022-10-10 05:17:27,004 [INFO] 	Process 1 - batch 16099: mean_policy_losses: -89.975, mean_net_lifetime: 4759.3108, mean_mc_travel_dist: 2374.8243, mean_rewards: 149.3279, total_rewards: 2418.6943, mean_steps: 31.1300, mean_ecr: 0.0400 mean_entropies: 1.5539, took: 139.9135s
2022-10-10 05:17:32,669 [INFO] 	Process 4 - batch 23499: mean_policy_losses: -67.328, mean_net_lifetime: 3625.4121, mean_mc_travel_dist: 1454.4561, mean_rewards: 224.4006, total_rewards: 2206.3236, mean_steps: 15.1300, mean_ecr: 0.0502 mean_entropies: 1.6289, took: 71.9750s
2022-10-10 05:18:08,929 [INFO] 	Process 2 - batch 19199: mean_policy_losses: 15.548, mean_net_lifetime: 4586.5215, mean_mc_travel_dist: 2050.7016, mean_rewards: 176.6145, total_rewards: 2567.9589, mean_steps: 25.1600, mean_ecr: 0.0410 mean_entropies: 1.3906, took: 111.2007s
2022-10-10 05:18:44,542 [INFO] 	Process 4 - batch 23599: mean_policy_losses: -114.302, mean_net_lifetime: 3718.1832, mean_mc_travel_dist: 1481.0224, mean_rewards: 231.6491, total_rewards: 2274.4017, mean_steps: 15.0100, mean_ecr: 0.0501 mean_entropies: 1.6710, took: 71.8732s
2022-10-10 05:18:56,958 [INFO] 	Process 3 - batch 19399: mean_policy_losses: 73.655, mean_net_lifetime: 4479.2854, mean_mc_travel_dist: 1857.0574, mean_rewards: 203.1367, total_rewards: 2650.3624, mean_steps: 21.1600, mean_ecr: 0.0478 mean_entropies: 1.3614, took: 99.8843s
2022-10-10 05:19:56,683 [INFO] 	Process 4 - batch 23699: mean_policy_losses: -125.171, mean_net_lifetime: 3688.4532, mean_mc_travel_dist: 1487.0269, mean_rewards: 228.6301, total_rewards: 2228.6990, mean_steps: 15.0500, mean_ecr: 0.0502 mean_entropies: 1.6329, took: 72.1414s
2022-10-10 05:19:58,905 [INFO] 	Process 2 - batch 19299: mean_policy_losses: -40.275, mean_net_lifetime: 4536.2568, mean_mc_travel_dist: 2065.9568, mean_rewards: 176.1117, total_rewards: 2507.4270, mean_steps: 24.9200, mean_ecr: 0.0410 mean_entropies: 1.3708, took: 109.9761s
2022-10-10 05:20:03,501 [INFO] 	Process 1 - batch 16199: mean_policy_losses: -165.846, mean_net_lifetime: 4748.5980, mean_mc_travel_dist: 2383.4765, mean_rewards: 133.0721, total_rewards: 2399.5193, mean_steps: 34.9800, mean_ecr: 0.0401 mean_entropies: 1.4941, took: 156.4952s
2022-10-10 05:20:41,000 [INFO] 	Process 3 - batch 19499: mean_policy_losses: 105.457, mean_net_lifetime: 4637.0036, mean_mc_travel_dist: 1891.5815, mean_rewards: 202.5272, total_rewards: 2769.7368, mean_steps: 21.9800, mean_ecr: 0.0477 mean_entropies: 1.2971, took: 104.0426s
2022-10-10 05:21:12,419 [INFO] 	Process 4 - batch 23799: mean_policy_losses: 83.900, mean_net_lifetime: 4139.4945, mean_mc_travel_dist: 1590.9579, mean_rewards: 240.6611, total_rewards: 2582.5447, mean_steps: 16.2000, mean_ecr: 0.0495 mean_entropies: 1.5971, took: 75.7363s
2022-10-10 05:21:38,461 [INFO] Process 5 - epoch 12: mean_policy_losses: -3.072, mean_net_lifetime: 4405.7517, mean_mc_travel_dist: 2532.5752, mean_entropies: 2.3045, m_net_lifetime_valid: 3880.7793, took: 3224.9896s, (224.7583 / 100 batches)

2022-10-10 05:21:48,021 [INFO] 	Process 2 - batch 19399: mean_policy_losses: -17.663, mean_net_lifetime: 4548.1298, mean_mc_travel_dist: 2061.2912, mean_rewards: 175.1022, total_rewards: 2520.9608, mean_steps: 25.1000, mean_ecr: 0.0411 mean_entropies: 1.3310, took: 109.1161s
2022-10-10 05:22:26,151 [INFO] 	Process 4 - batch 23899: mean_policy_losses: 9.613, mean_net_lifetime: 3861.7904, mean_mc_travel_dist: 1475.4903, mean_rewards: 232.9352, total_rewards: 2410.5987, mean_steps: 15.5300, mean_ecr: 0.0503 mean_entropies: 1.6435, took: 73.7320s
2022-10-10 05:22:36,670 [INFO] 	Process 1 - batch 16299: mean_policy_losses: -149.264, mean_net_lifetime: 4656.2398, mean_mc_travel_dist: 2339.3905, mean_rewards: 133.2348, total_rewards: 2349.9685, mean_steps: 34.4700, mean_ecr: 0.0402 mean_entropies: 1.4926, took: 153.1709s
2022-10-10 05:23:39,918 [INFO] 	Process 2 - batch 19499: mean_policy_losses: 24.319, mean_net_lifetime: 4625.6250, mean_mc_travel_dist: 2088.2722, mean_rewards: 178.1071, total_rewards: 2574.0411, mean_steps: 25.1600, mean_ecr: 0.0409 mean_entropies: 1.3835, took: 111.8969s
2022-10-10 05:23:41,089 [INFO] 	Process 4 - batch 23999: mean_policy_losses: -18.374, mean_net_lifetime: 3780.8961, mean_mc_travel_dist: 1480.0749, mean_rewards: 227.1329, total_rewards: 2331.5997, mean_steps: 15.5800, mean_ecr: 0.0503 mean_entropies: 1.6546, took: 74.9382s
2022-10-10 05:24:01,097 [INFO] 	Process 5 - batch 18099: mean_policy_losses: -59.946, mean_net_lifetime: 5805.6378, mean_mc_travel_dist: 3126.0996, mean_rewards: 174.9139, total_rewards: 2731.3901, mean_steps: 31.4900, mean_ecr: 0.0298 mean_entropies: 1.7625, took: 1165.0158s
2022-10-10 05:24:56,895 [INFO] 	Process 1 - batch 16399: mean_policy_losses: -67.893, mean_net_lifetime: 4698.3931, mean_mc_travel_dist: 2340.3454, mean_rewards: 140.4487, total_rewards: 2388.5895, mean_steps: 32.6800, mean_ecr: 0.0401 mean_entropies: 1.6042, took: 140.2250s
2022-10-10 05:25:18,721 [INFO] Process 7 - epoch 13: mean_policy_losses: -27.619, mean_net_lifetime: 3818.2780, mean_mc_travel_dist: 1883.0067, mean_entropies: 2.2299, m_net_lifetime_valid: 3746.2973, took: 2614.8597s, (208.9817 / 100 batches)

2022-10-10 05:26:01,209 [INFO] 	Process 5 - batch 18199: mean_policy_losses: 129.479, mean_net_lifetime: 5814.9904, mean_mc_travel_dist: 2922.4663, mean_rewards: 200.0924, total_rewards: 2951.9329, mean_steps: 28.4400, mean_ecr: 0.0307 mean_entropies: 1.8150, took: 120.1124s
2022-10-10 05:26:23,032 [INFO] 	Process 7 - batch 19599: mean_policy_losses: -412.949, mean_net_lifetime: 3101.9365, mean_mc_travel_dist: 1489.1991, mean_rewards: 210.8984, total_rewards: 1661.3517, mean_steps: 14.1900, mean_ecr: 0.0433 mean_entropies: 2.0018, took: 1027.7529s
2022-10-10 05:26:47,374 [INFO] 	Process 1 - batch 16499: mean_policy_losses: 140.656, mean_net_lifetime: 4776.7228, mean_mc_travel_dist: 2082.6879, mean_rewards: 191.1227, total_rewards: 2716.9233, mean_steps: 25.1900, mean_ecr: 0.0393 mean_entropies: 1.5307, took: 110.4794s
2022-10-10 05:26:58,730 [INFO] 	Process 5 - batch 18299: mean_policy_losses: -141.247, mean_net_lifetime: 3704.0715, mean_mc_travel_dist: 1374.1678, mean_rewards: 294.1714, total_rewards: 2412.1380, mean_steps: 12.1600, mean_ecr: 0.0300 mean_entropies: 1.2993, took: 57.5218s
2022-10-10 05:27:23,861 [INFO] 	Process 7 - batch 19699: mean_policy_losses: 163.526, mean_net_lifetime: 3425.9772, mean_mc_travel_dist: 1265.5830, mean_rewards: 232.9229, total_rewards: 2206.4163, mean_steps: 13.8500, mean_ecr: 0.0422 mean_entropies: 1.7762, took: 60.8286s
2022-10-10 05:28:10,157 [INFO] 	Process 5 - batch 18399: mean_policy_losses: -139.083, mean_net_lifetime: 4435.3414, mean_mc_travel_dist: 1677.6040, mean_rewards: 266.2323, total_rewards: 2808.5449, mean_steps: 15.8000, mean_ecr: 0.0303 mean_entropies: 1.2732, took: 71.4257s
2022-10-10 05:28:29,518 [INFO] 	Process 7 - batch 19799: mean_policy_losses: -51.140, mean_net_lifetime: 3600.8788, mean_mc_travel_dist: 1330.4153, mean_rewards: 220.5835, total_rewards: 2326.4025, mean_steps: 15.5400, mean_ecr: 0.0421 mean_entropies: 1.6783, took: 65.6566s
2022-10-10 05:29:23,881 [INFO] 	Process 5 - batch 18499: mean_policy_losses: -169.431, mean_net_lifetime: 4526.3125, mean_mc_travel_dist: 1848.6303, mean_rewards: 261.2844, total_rewards: 2753.4199, mean_steps: 16.3200, mean_ecr: 0.0296 mean_entropies: 1.1592, took: 73.7257s
2022-10-10 05:29:48,244 [INFO] 	Process 7 - batch 19899: mean_policy_losses: 108.982, mean_net_lifetime: 3956.5100, mean_mc_travel_dist: 1443.2732, mean_rewards: 208.6845, total_rewards: 2563.1192, mean_steps: 18.5300, mean_ecr: 0.0420 mean_entropies: 1.6726, took: 78.7263s
2022-10-10 05:30:07,874 [INFO] Process 6 - epoch 19: mean_policy_losses: -283.659, mean_net_lifetime: 2196.9254, mean_mc_travel_dist: 1104.3492, mean_entropies: 1.4698, m_net_lifetime_valid: 3847.3402, took: 1934.2374s, (144.4198 / 100 batches)

2022-10-10 05:30:31,321 [INFO] 	Process 6 - batch 28599: mean_policy_losses: -113.174, mean_net_lifetime: 1119.0974, mean_mc_travel_dist: 413.1326, mean_rewards: 257.7556, total_rewards: 788.9986, mean_steps: 3.4800, mean_ecr: 0.0569 mean_entropies: 0.5715, took: 931.9663s
2022-10-10 05:30:31,715 [INFO] 	Process 5 - batch 18599: mean_policy_losses: -203.480, mean_net_lifetime: 3908.9975, mean_mc_travel_dist: 1668.0545, mean_rewards: 247.2132, total_rewards: 2326.2870, mean_steps: 14.8800, mean_ecr: 0.0302 mean_entropies: 0.8577, took: 67.8341s
2022-10-10 05:30:52,295 [INFO] 	Process 7 - batch 19999: mean_policy_losses: 296.607, mean_net_lifetime: 3509.1718, mean_mc_travel_dist: 1405.5974, mean_rewards: 233.4455, total_rewards: 2151.7628, mean_steps: 14.2600, mean_ecr: 0.0419 mean_entropies: 1.5192, took: 64.0518s
2022-10-10 05:30:55,907 [INFO] 	Process 6 - batch 28699: mean_policy_losses: -101.420, mean_net_lifetime: 1189.8919, mean_mc_travel_dist: 372.0264, mean_rewards: 254.8979, total_rewards: 858.8202, mean_steps: 3.8300, mean_ecr: 0.0573 mean_entropies: 0.6025, took: 24.5863s
2022-10-10 05:31:18,775 [INFO] 	Process 6 - batch 28799: mean_policy_losses: -137.927, mean_net_lifetime: 1161.3988, mean_mc_travel_dist: 379.5555, mean_rewards: 269.6194, total_rewards: 843.9546, mean_steps: 3.4900, mean_ecr: 0.0568 mean_entropies: 0.6829, took: 22.8683s
2022-10-10 05:31:42,284 [INFO] 	Process 6 - batch 28899: mean_policy_losses: -108.615, mean_net_lifetime: 1191.0746, mean_mc_travel_dist: 357.6534, mean_rewards: 275.7921, total_rewards: 880.3225, mean_steps: 3.5600, mean_ecr: 0.0567 mean_entropies: 0.7080, took: 23.5084s
2022-10-10 05:31:45,458 [INFO] 	Process 7 - batch 20099: mean_policy_losses: 131.022, mean_net_lifetime: 2886.1372, mean_mc_travel_dist: 1144.0374, mean_rewards: 234.4400, total_rewards: 1792.1618, mean_steps: 11.4800, mean_ecr: 0.0423 mean_entropies: 1.4849, took: 53.1630s
2022-10-10 05:31:45,552 [INFO] 	Process 5 - batch 18699: mean_policy_losses: -42.830, mean_net_lifetime: 3828.0920, mean_mc_travel_dist: 1540.2976, mean_rewards: 228.3892, total_rewards: 2357.8528, mean_steps: 15.9600, mean_ecr: 0.0309 mean_entropies: 0.9145, took: 73.8361s
2022-10-10 05:32:06,124 [INFO] 	Process 6 - batch 28999: mean_policy_losses: -139.133, mean_net_lifetime: 1289.3799, mean_mc_travel_dist: 391.4640, mean_rewards: 276.8541, total_rewards: 943.5245, mean_steps: 3.8000, mean_ecr: 0.0571 mean_entropies: 0.8124, took: 23.8401s
2022-10-10 05:32:32,550 [INFO] 	Process 6 - batch 29099: mean_policy_losses: -153.913, mean_net_lifetime: 1442.7967, mean_mc_travel_dist: 413.7562, mean_rewards: 277.7203, total_rewards: 1068.9660, mean_steps: 4.3700, mean_ecr: 0.0573 mean_entropies: 0.7056, took: 26.4262s
2022-10-10 05:32:39,856 [INFO] 	Process 7 - batch 20199: mean_policy_losses: 215.536, mean_net_lifetime: 2962.0013, mean_mc_travel_dist: 1116.0221, mean_rewards: 228.0591, total_rewards: 1907.8767, mean_steps: 12.0300, mean_ecr: 0.0423 mean_entropies: 1.6370, took: 54.3970s
2022-10-10 05:32:59,669 [INFO] 	Process 5 - batch 18799: mean_policy_losses: 88.293, mean_net_lifetime: 4127.7640, mean_mc_travel_dist: 1532.8789, mean_rewards: 245.1445, total_rewards: 2649.7644, mean_steps: 16.0500, mean_ecr: 0.0309 mean_entropies: 1.2065, took: 74.1173s
2022-10-10 05:33:03,623 [INFO] 	Process 6 - batch 29199: mean_policy_losses: -225.460, mean_net_lifetime: 1560.8036, mean_mc_travel_dist: 458.7710, mean_rewards: 264.6563, total_rewards: 1138.3659, mean_steps: 5.1400, mean_ecr: 0.0577 mean_entropies: 0.6193, took: 31.0728s
2022-10-10 05:33:40,014 [INFO] 	Process 6 - batch 29299: mean_policy_losses: -197.592, mean_net_lifetime: 2061.7095, mean_mc_travel_dist: 606.4857, mean_rewards: 269.8787, total_rewards: 1493.1363, mean_steps: 6.7000, mean_ecr: 0.0575 mean_entropies: 0.5846, took: 36.3915s
2022-10-10 05:33:46,038 [INFO] 	Process 7 - batch 20299: mean_policy_losses: 78.814, mean_net_lifetime: 3587.2714, mean_mc_travel_dist: 1318.6901, mean_rewards: 224.9626, total_rewards: 2317.2687, mean_steps: 15.0700, mean_ecr: 0.0417 mean_entropies: 1.6281, took: 66.1819s
2022-10-10 05:34:02,934 [INFO] 	Process 5 - batch 18899: mean_policy_losses: -118.759, mean_net_lifetime: 3920.5187, mean_mc_travel_dist: 1401.5433, mean_rewards: 289.0719, total_rewards: 2588.8876, mean_steps: 13.1800, mean_ecr: 0.0306 mean_entropies: 1.2056, took: 63.2646s
2022-10-10 05:34:19,739 [INFO] 	Process 6 - batch 29399: mean_policy_losses: -111.705, mean_net_lifetime: 2218.3678, mean_mc_travel_dist: 631.4448, mean_rewards: 260.2368, total_rewards: 1624.3203, mean_steps: 7.5100, mean_ecr: 0.0569 mean_entropies: 0.4795, took: 39.7245s
2022-10-10 05:34:33,714 [INFO] Process 1 - epoch 11: mean_policy_losses: 115.883, mean_net_lifetime: 4608.5236, mean_mc_travel_dist: 2388.1858, mean_entropies: 1.9085, m_net_lifetime_valid: 3829.5451, took: 2940.1725s, (253.0878 / 100 batches)

2022-10-10 05:34:54,477 [INFO] 	Process 7 - batch 20399: mean_policy_losses: -3.975, mean_net_lifetime: 3595.8863, mean_mc_travel_dist: 1332.7227, mean_rewards: 224.6171, total_rewards: 2307.1028, mean_steps: 15.3600, mean_ecr: 0.0418 mean_entropies: 1.5726, took: 68.4390s
2022-10-10 05:35:00,929 [INFO] 	Process 5 - batch 18999: mean_policy_losses: -261.518, mean_net_lifetime: 3476.8903, mean_mc_travel_dist: 1239.8982, mean_rewards: 288.5225, total_rewards: 2308.0242, mean_steps: 11.6700, mean_ecr: 0.0305 mean_entropies: 1.1310, took: 57.9950s
2022-10-10 05:35:01,765 [INFO] 	Process 6 - batch 29499: mean_policy_losses: -150.262, mean_net_lifetime: 2248.2836, mean_mc_travel_dist: 642.7395, mean_rewards: 259.1836, total_rewards: 1648.1092, mean_steps: 7.8200, mean_ecr: 0.0574 mean_entropies: 0.4485, took: 42.0259s
2022-10-10 05:35:24,369 [INFO] Process 3 - epoch 13: mean_policy_losses: 140.470, mean_net_lifetime: 3874.4075, mean_mc_travel_dist: 1704.0562, mean_entropies: 1.7164, m_net_lifetime_valid: 3891.3921, took: 2631.1421s, (212.4771 / 100 batches)

2022-10-10 05:35:46,071 [INFO] 	Process 6 - batch 29599: mean_policy_losses: -189.016, mean_net_lifetime: 2340.9106, mean_mc_travel_dist: 636.9390, mean_rewards: 269.6300, total_rewards: 1744.0992, mean_steps: 7.8100, mean_ecr: 0.0569 mean_entropies: 0.4399, took: 44.3055s
2022-10-10 05:36:04,230 [INFO] 	Process 5 - batch 19099: mean_policy_losses: -348.979, mean_net_lifetime: 3540.0468, mean_mc_travel_dist: 1328.4758, mean_rewards: 276.3491, total_rewards: 2286.5466, mean_steps: 12.4100, mean_ecr: 0.0306 mean_entropies: 0.9767, took: 63.3012s
2022-10-10 05:36:13,785 [INFO] 	Process 7 - batch 20499: mean_policy_losses: -35.885, mean_net_lifetime: 3829.7563, mean_mc_travel_dist: 1426.5879, mean_rewards: 215.7088, total_rewards: 2463.5603, mean_steps: 16.9800, mean_ecr: 0.0415 mean_entropies: 1.4097, took: 79.3080s
2022-10-10 05:36:22,292 [INFO] 	Process 6 - batch 29699: mean_policy_losses: -144.312, mean_net_lifetime: 1939.9544, mean_mc_travel_dist: 539.2763, mean_rewards: 286.3897, total_rewards: 1437.0588, mean_steps: 6.0100, mean_ecr: 0.0577 mean_entropies: 0.4733, took: 36.2211s
2022-10-10 05:36:29,548 [INFO] 	Process 1 - batch 16599: mean_policy_losses: 70.454, mean_net_lifetime: 4536.9488, mean_mc_travel_dist: 1858.1371, mean_rewards: 181.5881, total_rewards: 2710.6327, mean_steps: 24.7800, mean_ecr: 0.0385 mean_entropies: 0.9907, took: 582.1726s
2022-10-10 05:36:54,104 [INFO] 	Process 3 - batch 19599: mean_policy_losses: 182.633, mean_net_lifetime: 3643.8496, mean_mc_travel_dist: 1056.0212, mean_rewards: 199.9858, total_rewards: 2604.8624, mean_steps: 17.9700, mean_ecr: 0.0491 mean_entropies: 0.8064, took: 973.1033s
2022-10-10 05:37:02,573 [INFO] 	Process 5 - batch 19199: mean_policy_losses: -214.271, mean_net_lifetime: 3349.4506, mean_mc_travel_dist: 1256.8382, mean_rewards: 288.7791, total_rewards: 2170.4060, mean_steps: 11.2200, mean_ecr: 0.0306 mean_entropies: 0.8873, took: 58.3429s
2022-10-10 05:37:07,010 [INFO] 	Process 6 - batch 29799: mean_policy_losses: -166.568, mean_net_lifetime: 2307.4994, mean_mc_travel_dist: 624.9651, mean_rewards: 267.3252, total_rewards: 1712.8367, mean_steps: 7.6900, mean_ecr: 0.0568 mean_entropies: 0.3964, took: 44.7180s
2022-10-10 05:37:35,515 [INFO] 	Process 7 - batch 20599: mean_policy_losses: -65.747, mean_net_lifetime: 3798.5753, mean_mc_travel_dist: 1436.0108, mean_rewards: 212.8211, total_rewards: 2418.6475, mean_steps: 17.2200, mean_ecr: 0.0414 mean_entropies: 1.4163, took: 81.7299s
2022-10-10 05:37:47,386 [INFO] Process 4 - epoch 16: mean_policy_losses: 32.232, mean_net_lifetime: 3104.9371, mean_mc_travel_dist: 1338.1362, mean_entropies: 1.9161, m_net_lifetime_valid: 3867.1479, took: 2031.7357s, (173.5526 / 100 batches)

2022-10-10 05:37:55,024 [INFO] 	Process 6 - batch 29899: mean_policy_losses: -142.500, mean_net_lifetime: 2586.5428, mean_mc_travel_dist: 708.8487, mean_rewards: 270.7510, total_rewards: 1921.7091, mean_steps: 8.7100, mean_ecr: 0.0566 mean_entropies: 0.4095, took: 48.0145s
2022-10-10 05:38:00,686 [INFO] 	Process 5 - batch 19299: mean_policy_losses: -335.290, mean_net_lifetime: 3207.0068, mean_mc_travel_dist: 1218.2736, mean_rewards: 285.4564, total_rewards: 2067.4499, mean_steps: 10.8300, mean_ecr: 0.0306 mean_entropies: 0.8291, took: 58.1135s
2022-10-10 05:38:17,525 [INFO] 	Process 1 - batch 16699: mean_policy_losses: 68.187, mean_net_lifetime: 4486.8711, mean_mc_travel_dist: 1894.7510, mean_rewards: 192.1694, total_rewards: 2612.3960, mean_steps: 22.8600, mean_ecr: 0.0383 mean_entropies: 0.9024, took: 107.9782s
2022-10-10 05:38:36,484 [INFO] 	Process 6 - batch 29999: mean_policy_losses: -95.439, mean_net_lifetime: 2094.5135, mean_mc_travel_dist: 581.2024, mean_rewards: 266.6004, total_rewards: 1558.4405, mean_steps: 7.0100, mean_ecr: 0.0576 mean_entropies: 0.3622, took: 41.4595s
2022-10-10 05:38:37,567 [INFO] 	Process 3 - batch 19699: mean_policy_losses: 167.249, mean_net_lifetime: 3603.7582, mean_mc_travel_dist: 1050.3507, mean_rewards: 173.0031, total_rewards: 2569.8601, mean_steps: 20.7400, mean_ecr: 0.0492 mean_entropies: 0.7263, took: 103.4626s
2022-10-10 05:38:53,072 [INFO] 	Process 5 - batch 19399: mean_policy_losses: -217.381, mean_net_lifetime: 3026.6291, mean_mc_travel_dist: 1087.1794, mean_rewards: 309.1637, total_rewards: 2012.1398, mean_steps: 9.7600, mean_ecr: 0.0301 mean_entropies: 0.8892, took: 52.3852s
2022-10-10 05:38:55,065 [INFO] 	Process 4 - batch 24099: mean_policy_losses: -64.438, mean_net_lifetime: 2456.2301, mean_mc_travel_dist: 923.2438, mean_rewards: 179.0847, total_rewards: 1563.2334, mean_steps: 12.9300, mean_ecr: 0.0519 mean_entropies: 1.1852, took: 913.9749s
2022-10-10 05:38:58,305 [INFO] 	Process 7 - batch 20699: mean_policy_losses: 1.187, mean_net_lifetime: 3773.7458, mean_mc_travel_dist: 1437.2824, mean_rewards: 213.0980, total_rewards: 2384.4683, mean_steps: 17.0800, mean_ecr: 0.0414 mean_entropies: 1.3723, took: 82.7902s
2022-10-10 05:38:59,153 [INFO] Process 2 - epoch 13: mean_policy_losses: 18.827, mean_net_lifetime: 3807.4826, mean_mc_travel_dist: 1869.4640, mean_entropies: 1.7923, m_net_lifetime_valid: 4039.7953, took: 2807.7367s, (213.3939 / 100 batches)

2022-10-10 05:39:54,264 [INFO] 	Process 5 - batch 19499: mean_policy_losses: -318.430, mean_net_lifetime: 3181.5488, mean_mc_travel_dist: 1185.0075, mean_rewards: 281.6352, total_rewards: 2087.9340, mean_steps: 11.2600, mean_ecr: 0.0303 mean_entropies: 0.8874, took: 61.1930s
2022-10-10 05:40:01,494 [INFO] 	Process 4 - batch 24199: mean_policy_losses: -150.996, mean_net_lifetime: 2341.9410, mean_mc_travel_dist: 945.3707, mean_rewards: 170.2121, total_rewards: 1416.5595, mean_steps: 12.8200, mean_ecr: 0.0521 mean_entropies: 1.0871, took: 66.4296s
2022-10-10 05:40:03,856 [INFO] 	Process 3 - batch 19799: mean_policy_losses: 140.548, mean_net_lifetime: 3515.8341, mean_mc_travel_dist: 1206.7212, mean_rewards: 214.1525, total_rewards: 2341.5892, mean_steps: 17.2100, mean_ecr: 0.0478 mean_entropies: 0.7191, took: 86.2897s
2022-10-10 05:40:07,340 [INFO] 	Process 2 - batch 19599: mean_policy_losses: -8.457, mean_net_lifetime: 3452.1784, mean_mc_travel_dist: 1496.5834, mean_rewards: 241.1035, total_rewards: 2013.9406, mean_steps: 13.6200, mean_ecr: 0.0401 mean_entropies: 0.7277, took: 987.4216s
2022-10-10 05:40:13,606 [INFO] 	Process 7 - batch 20799: mean_policy_losses: -80.592, mean_net_lifetime: 3358.5887, mean_mc_travel_dist: 1352.6762, mean_rewards: 210.3191, total_rewards: 2074.3916, mean_steps: 15.3800, mean_ecr: 0.0418 mean_entropies: 1.2014, took: 75.3015s
2022-10-10 05:40:22,363 [INFO] 	Process 1 - batch 16799: mean_policy_losses: 44.559, mean_net_lifetime: 4502.5641, mean_mc_travel_dist: 2012.3675, mean_rewards: 178.0451, total_rewards: 2532.3709, mean_steps: 25.6400, mean_ecr: 0.0382 mean_entropies: 0.8171, took: 124.8378s
2022-10-10 05:41:13,906 [INFO] 	Process 4 - batch 24299: mean_policy_losses: -122.123, mean_net_lifetime: 2627.1306, mean_mc_travel_dist: 899.3007, mean_rewards: 171.6991, total_rewards: 1747.2932, mean_steps: 14.7700, mean_ecr: 0.0519 mean_entropies: 1.2376, took: 72.4114s
2022-10-10 05:41:25,401 [INFO] 	Process 2 - batch 19699: mean_policy_losses: 17.272, mean_net_lifetime: 4340.9818, mean_mc_travel_dist: 1621.2414, mean_rewards: 251.2886, total_rewards: 2747.4387, mean_steps: 16.4300, mean_ecr: 0.0394 mean_entropies: 1.0413, took: 78.0617s
2022-10-10 05:41:34,077 [INFO] 	Process 3 - batch 19899: mean_policy_losses: 163.730, mean_net_lifetime: 3943.7199, mean_mc_travel_dist: 1159.3770, mean_rewards: 212.6645, total_rewards: 2808.6854, mean_steps: 17.8800, mean_ecr: 0.0481 mean_entropies: 0.9473, took: 90.2209s
2022-10-10 05:41:45,230 [INFO] 	Process 7 - batch 20899: mean_policy_losses: -3.519, mean_net_lifetime: 4292.8525, mean_mc_travel_dist: 1526.9713, mean_rewards: 207.6950, total_rewards: 2811.6767, mean_steps: 19.8200, mean_ecr: 0.0413 mean_entropies: 1.5447, took: 91.6240s
2022-10-10 05:42:18,494 [INFO] 	Process 4 - batch 24399: mean_policy_losses: -242.584, mean_net_lifetime: 2420.8428, mean_mc_travel_dist: 923.9148, mean_rewards: 175.1331, total_rewards: 1518.3799, mean_steps: 13.0200, mean_ecr: 0.0521 mean_entropies: 1.1453, took: 64.5879s
2022-10-10 05:42:22,113 [INFO] 	Process 1 - batch 16899: mean_policy_losses: -56.138, mean_net_lifetime: 4525.2833, mean_mc_travel_dist: 2011.8980, mean_rewards: 174.0171, total_rewards: 2541.5225, mean_steps: 25.8000, mean_ecr: 0.0379 mean_entropies: 0.8917, took: 119.7503s
2022-10-10 05:42:30,324 [INFO] 	Process 2 - batch 19799: mean_policy_losses: -34.425, mean_net_lifetime: 3764.9669, mean_mc_travel_dist: 1558.0587, mean_rewards: 265.8142, total_rewards: 2245.5454, mean_steps: 13.2700, mean_ecr: 0.0398 mean_entropies: 0.9286, took: 64.9224s
2022-10-10 05:42:47,489 [INFO] 	Process 3 - batch 19999: mean_policy_losses: 245.803, mean_net_lifetime: 3785.4339, mean_mc_travel_dist: 1267.7317, mean_rewards: 248.5887, total_rewards: 2549.8888, mean_steps: 14.4300, mean_ecr: 0.0474 mean_entropies: 0.8914, took: 73.4121s
2022-10-10 05:42:53,649 [INFO] 	Process 7 - batch 20999: mean_policy_losses: -189.616, mean_net_lifetime: 3287.1776, mean_mc_travel_dist: 1356.2387, mean_rewards: 217.9433, total_rewards: 1982.6607, mean_steps: 14.3400, mean_ecr: 0.0417 mean_entropies: 1.2785, took: 68.4186s
2022-10-10 05:43:18,595 [INFO] 	Process 4 - batch 24499: mean_policy_losses: -168.941, mean_net_lifetime: 2331.6829, mean_mc_travel_dist: 969.4050, mean_rewards: 180.2920, total_rewards: 1380.7138, mean_steps: 12.0500, mean_ecr: 0.0523 mean_entropies: 1.0022, took: 60.1019s
2022-10-10 05:43:35,756 [INFO] 	Process 2 - batch 19899: mean_policy_losses: 23.040, mean_net_lifetime: 3734.5348, mean_mc_travel_dist: 1529.6862, mean_rewards: 258.8500, total_rewards: 2246.8181, mean_steps: 13.8700, mean_ecr: 0.0400 mean_entropies: 0.9509, took: 65.4322s
2022-10-10 05:44:13,665 [INFO] 	Process 3 - batch 20099: mean_policy_losses: 157.095, mean_net_lifetime: 3966.2236, mean_mc_travel_dist: 1171.8374, mean_rewards: 210.6916, total_rewards: 2813.9394, mean_steps: 18.3300, mean_ecr: 0.0481 mean_entropies: 0.9211, took: 86.1759s
2022-10-10 05:44:19,782 [INFO] 	Process 1 - batch 16999: mean_policy_losses: -21.430, mean_net_lifetime: 4488.8592, mean_mc_travel_dist: 1931.9061, mean_rewards: 172.9732, total_rewards: 2579.9396, mean_steps: 26.2000, mean_ecr: 0.0383 mean_entropies: 0.8926, took: 117.6689s
2022-10-10 05:44:23,093 [INFO] 	Process 4 - batch 24599: mean_policy_losses: -177.745, mean_net_lifetime: 2970.9838, mean_mc_travel_dist: 949.3622, mean_rewards: 209.1850, total_rewards: 2043.3657, mean_steps: 13.3600, mean_ecr: 0.0510 mean_entropies: 1.3657, took: 64.4978s
2022-10-10 05:44:50,343 [INFO] Process 5 - epoch 13: mean_policy_losses: -14.902, mean_net_lifetime: 4373.7877, mean_mc_travel_dist: 2462.9279, mean_entropies: 2.2149, m_net_lifetime_valid: 3221.7917, took: 1391.8804s, (218.3645 / 100 batches)

2022-10-10 05:44:55,278 [INFO] 	Process 2 - batch 19999: mean_policy_losses: -11.560, mean_net_lifetime: 4084.0250, mean_mc_travel_dist: 1416.0217, mean_rewards: 226.4675, total_rewards: 2698.0534, mean_steps: 17.4700, mean_ecr: 0.0400 mean_entropies: 1.0018, took: 79.5221s
2022-10-10 05:45:19,717 [INFO] 	Process 4 - batch 24699: mean_policy_losses: -244.913, mean_net_lifetime: 2377.8258, mean_mc_travel_dist: 868.1801, mean_rewards: 197.9150, total_rewards: 1533.8949, mean_steps: 11.1700, mean_ecr: 0.0521 mean_entropies: 1.1298, took: 56.6242s
2022-10-10 05:45:26,662 [INFO] 	Process 3 - batch 20199: mean_policy_losses: 223.955, mean_net_lifetime: 3678.7722, mean_mc_travel_dist: 1194.8397, mean_rewards: 245.0218, total_rewards: 2515.3746, mean_steps: 14.5300, mean_ecr: 0.0482 mean_entropies: 0.9428, took: 72.9974s
2022-10-10 05:45:43,135 [INFO] 	Process 5 - batch 19599: mean_policy_losses: -286.647, mean_net_lifetime: 2991.0081, mean_mc_travel_dist: 1202.1247, mean_rewards: 282.3026, total_rewards: 1884.2143, mean_steps: 10.0100, mean_ecr: 0.0303 mean_entropies: 0.8082, took: 348.8696s
2022-10-10 05:45:54,588 [INFO] 	Process 1 - batch 17099: mean_policy_losses: 7.211, mean_net_lifetime: 4550.3161, mean_mc_travel_dist: 2076.9090, mean_rewards: 223.9926, total_rewards: 2510.4778, mean_steps: 19.8100, mean_ecr: 0.0381 mean_entropies: 0.9947, took: 94.8056s
2022-10-10 05:46:06,082 [INFO] 	Process 2 - batch 20099: mean_policy_losses: 102.370, mean_net_lifetime: 3924.0517, mean_mc_travel_dist: 1578.6467, mean_rewards: 253.1348, total_rewards: 2385.4598, mean_steps: 14.8300, mean_ecr: 0.0398 mean_entropies: 0.9766, took: 70.8044s
2022-10-10 05:46:21,630 [INFO] 	Process 4 - batch 24799: mean_policy_losses: -90.813, mean_net_lifetime: 2831.7344, mean_mc_travel_dist: 954.5035, mean_rewards: 211.2104, total_rewards: 1920.3902, mean_steps: 12.3400, mean_ecr: 0.0515 mean_entropies: 1.2582, took: 61.9132s
2022-10-10 05:46:35,923 [INFO] 	Process 5 - batch 19699: mean_policy_losses: -701.811, mean_net_lifetime: 3048.2039, mean_mc_travel_dist: 1036.7634, mean_rewards: 294.7102, total_rewards: 2073.2861, mean_steps: 10.2100, mean_ecr: 0.0294 mean_entropies: 1.3141, took: 52.7889s
2022-10-10 05:46:53,336 [INFO] 	Process 3 - batch 20299: mean_policy_losses: 247.803, mean_net_lifetime: 3972.9957, mean_mc_travel_dist: 1164.1328, mean_rewards: 224.1140, total_rewards: 2825.6870, mean_steps: 17.0800, mean_ecr: 0.0487 mean_entropies: 0.9866, took: 86.6734s
2022-10-10 05:47:26,165 [INFO] 	Process 4 - batch 24899: mean_policy_losses: -160.723, mean_net_lifetime: 3069.9173, mean_mc_travel_dist: 958.2816, mean_rewards: 223.1738, total_rewards: 2141.6255, mean_steps: 12.7400, mean_ecr: 0.0506 mean_entropies: 1.3861, took: 64.5354s
2022-10-10 05:47:37,855 [INFO] 	Process 2 - batch 20199: mean_policy_losses: 139.157, mean_net_lifetime: 4443.8112, mean_mc_travel_dist: 1502.1194, mean_rewards: 217.2627, total_rewards: 2971.3453, mean_steps: 19.6300, mean_ecr: 0.0399 mean_entropies: 1.1452, took: 91.7728s
2022-10-10 05:47:50,251 [INFO] 	Process 5 - batch 19799: mean_policy_losses: -553.120, mean_net_lifetime: 4058.4916, mean_mc_travel_dist: 1409.7210, mean_rewards: 268.3932, total_rewards: 2717.8861, mean_steps: 14.9000, mean_ecr: 0.0297 mean_entropies: 1.3983, took: 74.3278s
2022-10-10 05:47:50,699 [INFO] 	Process 1 - batch 17199: mean_policy_losses: -10.503, mean_net_lifetime: 4524.5944, mean_mc_travel_dist: 1717.6072, mean_rewards: 180.5220, total_rewards: 2832.0077, mean_steps: 24.7800, mean_ecr: 0.0391 mean_entropies: 1.2072, took: 116.1109s
2022-10-10 05:48:16,498 [INFO] 	Process 3 - batch 20399: mean_policy_losses: 188.523, mean_net_lifetime: 4072.4507, mean_mc_travel_dist: 1181.4707, mean_rewards: 232.1965, total_rewards: 2911.9091, mean_steps: 16.6500, mean_ecr: 0.0481 mean_entropies: 1.0724, took: 83.1628s
2022-10-10 05:48:26,070 [INFO] 	Process 4 - batch 24999: mean_policy_losses: -357.611, mean_net_lifetime: 2638.4511, mean_mc_travel_dist: 886.3513, mean_rewards: 206.1794, total_rewards: 1790.3704, mean_steps: 11.7900, mean_ecr: 0.0518 mean_entropies: 1.2589, took: 59.9040s
2022-10-10 05:48:58,152 [INFO] 	Process 5 - batch 19899: mean_policy_losses: -530.115, mean_net_lifetime: 3672.9507, mean_mc_travel_dist: 1253.0622, mean_rewards: 271.8538, total_rewards: 2490.2573, mean_steps: 13.0700, mean_ecr: 0.0298 mean_entropies: 1.3446, took: 67.9008s
2022-10-10 05:49:06,720 [INFO] 	Process 2 - batch 20299: mean_policy_losses: 169.236, mean_net_lifetime: 4513.5660, mean_mc_travel_dist: 1495.6060, mean_rewards: 226.0431, total_rewards: 3044.1303, mean_steps: 19.2100, mean_ecr: 0.0399 mean_entropies: 1.1561, took: 88.8651s
2022-10-10 05:49:22,773 [INFO] Process 7 - epoch 14: mean_policy_losses: -24.921, mean_net_lifetime: 3797.7652, mean_mc_travel_dist: 1845.5601, mean_entropies: 2.1811, m_net_lifetime_valid: 3487.6431, took: 1444.0510s, (203.6909 / 100 batches)

2022-10-10 05:49:26,363 [INFO] 	Process 4 - batch 25099: mean_policy_losses: -344.996, mean_net_lifetime: 2767.5276, mean_mc_travel_dist: 872.2685, mean_rewards: 214.9039, total_rewards: 1924.8484, mean_steps: 11.9000, mean_ecr: 0.0515 mean_entropies: 1.3738, took: 60.2935s
2022-10-10 05:49:35,457 [INFO] Process 6 - epoch 20: mean_policy_losses: -276.733, mean_net_lifetime: 2176.2532, mean_mc_travel_dist: 1074.9926, mean_entropies: 1.4240, m_net_lifetime_valid: 3603.2907, took: 1167.5824s, (141.9309 / 100 batches)

2022-10-10 05:49:40,431 [INFO] 	Process 1 - batch 17299: mean_policy_losses: 45.149, mean_net_lifetime: 4589.2918, mean_mc_travel_dist: 1727.8750, mean_rewards: 195.0754, total_rewards: 2886.7568, mean_steps: 23.0200, mean_ecr: 0.0391 mean_entropies: 1.3154, took: 109.7321s
2022-10-10 05:49:42,352 [INFO] 	Process 3 - batch 20499: mean_policy_losses: 207.033, mean_net_lifetime: 4136.1844, mean_mc_travel_dist: 1203.8268, mean_rewards: 232.0805, total_rewards: 2959.2697, mean_steps: 16.9500, mean_ecr: 0.0480 mean_entropies: 1.0926, took: 85.8541s
2022-10-10 05:50:09,430 [INFO] 	Process 6 - batch 30099: mean_policy_losses: -290.370, mean_net_lifetime: 1620.6779, mean_mc_travel_dist: 460.4803, mean_rewards: 270.1799, total_rewards: 1206.0416, mean_steps: 5.0800, mean_ecr: 0.0574 mean_entropies: 0.5705, took: 692.9466s
2022-10-10 05:50:16,385 [INFO] 	Process 5 - batch 19999: mean_policy_losses: -321.842, mean_net_lifetime: 4050.6053, mean_mc_travel_dist: 1391.1085, mean_rewards: 258.4124, total_rewards: 2724.0113, mean_steps: 15.1100, mean_ecr: 0.0305 mean_entropies: 1.3293, took: 78.2331s
2022-10-10 05:50:30,131 [INFO] 	Process 7 - batch 21099: mean_policy_losses: -337.319, mean_net_lifetime: 3177.7194, mean_mc_travel_dist: 1148.4668, mean_rewards: 227.6455, total_rewards: 2084.3505, mean_steps: 12.9600, mean_ecr: 0.0423 mean_entropies: 1.6356, took: 456.4820s
2022-10-10 05:50:31,919 [INFO] 	Process 4 - batch 25199: mean_policy_losses: -36.773, mean_net_lifetime: 2834.3289, mean_mc_travel_dist: 893.8493, mean_rewards: 214.4143, total_rewards: 1965.6626, mean_steps: 12.1600, mean_ecr: 0.0514 mean_entropies: 1.3497, took: 65.5540s
2022-10-10 05:50:41,085 [INFO] 	Process 2 - batch 20399: mean_policy_losses: 209.088, mean_net_lifetime: 4363.9506, mean_mc_travel_dist: 1462.1604, mean_rewards: 216.8605, total_rewards: 2937.7281, mean_steps: 19.2800, mean_ecr: 0.0399 mean_entropies: 1.1598, took: 94.3651s
2022-10-10 05:50:52,730 [INFO] 	Process 6 - batch 30199: mean_policy_losses: -364.805, mean_net_lifetime: 2157.7086, mean_mc_travel_dist: 600.0010, mean_rewards: 270.7391, total_rewards: 1600.1006, mean_steps: 7.0500, mean_ecr: 0.0576 mean_entropies: 0.4994, took: 43.2992s
2022-10-10 05:51:13,476 [INFO] 	Process 5 - batch 20099: mean_policy_losses: -507.564, mean_net_lifetime: 2967.6517, mean_mc_travel_dist: 980.8977, mean_rewards: 292.9156, total_rewards: 2040.8717, mean_steps: 10.2600, mean_ecr: 0.0291 mean_entropies: 1.2788, took: 57.0916s
2022-10-10 05:51:15,580 [INFO] 	Process 3 - batch 20599: mean_policy_losses: 254.095, mean_net_lifetime: 3893.3021, mean_mc_travel_dist: 1099.3180, mean_rewards: 212.4431, total_rewards: 2817.3023, mean_steps: 17.5300, mean_ecr: 0.0488 mean_entropies: 0.9611, took: 93.2272s
2022-10-10 05:51:34,888 [INFO] 	Process 1 - batch 17399: mean_policy_losses: 158.487, mean_net_lifetime: 4629.5615, mean_mc_travel_dist: 1796.4131, mean_rewards: 195.1506, total_rewards: 2865.6147, mean_steps: 23.0500, mean_ecr: 0.0389 mean_entropies: 1.2145, took: 114.4578s
2022-10-10 05:51:39,880 [INFO] 	Process 6 - batch 30299: mean_policy_losses: -109.929, mean_net_lifetime: 2597.1481, mean_mc_travel_dist: 686.8522, mean_rewards: 287.1767, total_rewards: 1939.6661, mean_steps: 7.9900, mean_ecr: 0.0563 mean_entropies: 0.4434, took: 47.1504s
2022-10-10 05:51:40,044 [INFO] 	Process 4 - batch 25299: mean_policy_losses: -74.612, mean_net_lifetime: 3246.9526, mean_mc_travel_dist: 1038.2501, mean_rewards: 236.9786, total_rewards: 2235.2178, mean_steps: 12.5800, mean_ecr: 0.0504 mean_entropies: 1.1774, took: 68.1266s
2022-10-10 05:51:41,318 [INFO] 	Process 7 - batch 21199: mean_policy_losses: -252.567, mean_net_lifetime: 3443.3420, mean_mc_travel_dist: 1252.1363, mean_rewards: 234.1564, total_rewards: 2242.2364, mean_steps: 13.8200, mean_ecr: 0.0420 mean_entropies: 1.6076, took: 71.1870s
2022-10-10 05:52:02,905 [INFO] 	Process 5 - batch 20199: mean_policy_losses: -658.373, mean_net_lifetime: 2540.7270, mean_mc_travel_dist: 762.4092, mean_rewards: 290.7919, total_rewards: 1823.2868, mean_steps: 8.5900, mean_ecr: 0.0292 mean_entropies: 1.2287, took: 49.4281s
2022-10-10 05:52:14,128 [INFO] 	Process 2 - batch 20499: mean_policy_losses: 72.585, mean_net_lifetime: 3772.4591, mean_mc_travel_dist: 1289.4063, mean_rewards: 194.1227, total_rewards: 2514.2604, mean_steps: 18.6300, mean_ecr: 0.0404 mean_entropies: 0.8754, took: 93.0426s
2022-10-10 05:52:29,347 [INFO] 	Process 6 - batch 30399: mean_policy_losses: -224.589, mean_net_lifetime: 2495.9239, mean_mc_travel_dist: 671.5940, mean_rewards: 272.9867, total_rewards: 1860.1672, mean_steps: 8.1500, mean_ecr: 0.0568 mean_entropies: 0.4151, took: 49.4669s
2022-10-10 05:52:53,282 [INFO] 	Process 3 - batch 20699: mean_policy_losses: 128.310, mean_net_lifetime: 3779.4978, mean_mc_travel_dist: 1056.3386, mean_rewards: 194.7646, total_rewards: 2738.3219, mean_steps: 18.6500, mean_ecr: 0.0491 mean_entropies: 0.8483, took: 97.7022s
2022-10-10 05:52:55,493 [INFO] 	Process 4 - batch 25399: mean_policy_losses: 143.412, mean_net_lifetime: 3881.9209, mean_mc_travel_dist: 1165.5825, mean_rewards: 256.4515, total_rewards: 2748.0220, mean_steps: 14.1100, mean_ecr: 0.0492 mean_entropies: 1.1826, took: 75.4494s
2022-10-10 05:52:56,284 [INFO] 	Process 7 - batch 21299: mean_policy_losses: -280.875, mean_net_lifetime: 3604.5557, mean_mc_travel_dist: 1266.5821, mean_rewards: 233.4717, total_rewards: 2381.8116, mean_steps: 14.5900, mean_ecr: 0.0419 mean_entropies: 1.6514, took: 74.9662s
2022-10-10 05:53:06,857 [INFO] 	Process 5 - batch 20299: mean_policy_losses: -511.283, mean_net_lifetime: 3070.4722, mean_mc_travel_dist: 1008.2767, mean_rewards: 267.6279, total_rewards: 2121.6169, mean_steps: 11.5200, mean_ecr: 0.0291 mean_entropies: 1.1958, took: 63.9529s
2022-10-10 05:53:13,866 [INFO] 	Process 6 - batch 30499: mean_policy_losses: -217.932, mean_net_lifetime: 2442.1889, mean_mc_travel_dist: 655.1911, mean_rewards: 286.1261, total_rewards: 1824.5744, mean_steps: 7.5400, mean_ecr: 0.0565 mean_entropies: 0.4051, took: 44.5189s
2022-10-10 05:53:34,542 [INFO] 	Process 1 - batch 17499: mean_policy_losses: 41.971, mean_net_lifetime: 4515.3142, mean_mc_travel_dist: 1831.0509, mean_rewards: 180.6844, total_rewards: 2716.8114, mean_steps: 24.5400, mean_ecr: 0.0388 mean_entropies: 1.0692, took: 119.6538s
2022-10-10 05:53:42,788 [INFO] 	Process 2 - batch 20599: mean_policy_losses: 11.233, mean_net_lifetime: 3619.6658, mean_mc_travel_dist: 1225.4784, mean_rewards: 196.3092, total_rewards: 2421.1534, mean_steps: 17.5900, mean_ecr: 0.0407 mean_entropies: 0.8199, took: 88.6598s
2022-10-10 05:53:55,074 [INFO] 	Process 5 - batch 20399: mean_policy_losses: -647.315, mean_net_lifetime: 2635.5818, mean_mc_travel_dist: 863.5661, mean_rewards: 308.0796, total_rewards: 1828.0853, mean_steps: 8.2900, mean_ecr: 0.0289 mean_entropies: 1.2029, took: 48.2170s
2022-10-10 05:54:02,037 [INFO] 	Process 6 - batch 30599: mean_policy_losses: -237.756, mean_net_lifetime: 2365.8631, mean_mc_travel_dist: 654.2861, mean_rewards: 265.2399, total_rewards: 1754.1517, mean_steps: 8.0300, mean_ecr: 0.0570 mean_entropies: 0.4042, took: 48.1708s
2022-10-10 05:54:05,862 [INFO] 	Process 4 - batch 25499: mean_policy_losses: 95.442, mean_net_lifetime: 3533.4653, mean_mc_travel_dist: 1077.1107, mean_rewards: 250.0796, total_rewards: 2486.8560, mean_steps: 13.0500, mean_ecr: 0.0499 mean_entropies: 1.1922, took: 70.3688s
2022-10-10 05:54:15,706 [INFO] 	Process 7 - batch 21399: mean_policy_losses: -164.820, mean_net_lifetime: 3845.5471, mean_mc_travel_dist: 1352.1123, mean_rewards: 233.5572, total_rewards: 2532.4280, mean_steps: 15.7300, mean_ecr: 0.0417 mean_entropies: 1.5987, took: 79.4219s
2022-10-10 05:54:33,135 [INFO] 	Process 3 - batch 20799: mean_policy_losses: 154.986, mean_net_lifetime: 3864.0863, mean_mc_travel_dist: 1078.6825, mean_rewards: 198.9385, total_rewards: 2809.2154, mean_steps: 18.6400, mean_ecr: 0.0491 mean_entropies: 0.8204, took: 99.8534s
2022-10-10 05:54:45,735 [INFO] 	Process 6 - batch 30699: mean_policy_losses: -356.236, mean_net_lifetime: 2238.5868, mean_mc_travel_dist: 604.6116, mean_rewards: 270.8654, total_rewards: 1671.5218, mean_steps: 7.2800, mean_ecr: 0.0571 mean_entropies: 0.4047, took: 43.6987s
2022-10-10 05:55:06,681 [INFO] 	Process 5 - batch 20499: mean_policy_losses: -407.441, mean_net_lifetime: 3822.7273, mean_mc_travel_dist: 1333.6882, mean_rewards: 280.0092, total_rewards: 2548.4082, mean_steps: 13.5300, mean_ecr: 0.0296 mean_entropies: 1.2122, took: 71.6070s
2022-10-10 05:55:16,906 [INFO] 	Process 2 - batch 20699: mean_policy_losses: 76.329, mean_net_lifetime: 4111.4326, mean_mc_travel_dist: 1351.2076, mean_rewards: 207.8592, total_rewards: 2790.2405, mean_steps: 19.0300, mean_ecr: 0.0404 mean_entropies: 0.8922, took: 94.1189s
2022-10-10 05:55:28,863 [INFO] 	Process 7 - batch 21499: mean_policy_losses: -419.583, mean_net_lifetime: 3409.9202, mean_mc_travel_dist: 1228.3548, mean_rewards: 219.4500, total_rewards: 2233.0722, mean_steps: 14.5500, mean_ecr: 0.0420 mean_entropies: 1.5242, took: 73.1575s
2022-10-10 05:55:31,095 [INFO] 	Process 6 - batch 30799: mean_policy_losses: -285.976, mean_net_lifetime: 2458.8610, mean_mc_travel_dist: 661.3097, mean_rewards: 277.9913, total_rewards: 1833.7805, mean_steps: 7.8700, mean_ecr: 0.0566 mean_entropies: 0.4269, took: 45.3597s
2022-10-10 05:55:34,477 [INFO] 	Process 1 - batch 17599: mean_policy_losses: 23.722, mean_net_lifetime: 4552.1279, mean_mc_travel_dist: 1800.6475, mean_rewards: 183.4766, total_rewards: 2777.6364, mean_steps: 24.4200, mean_ecr: 0.0388 mean_entropies: 1.0294, took: 119.9349s
2022-10-10 05:56:06,705 [INFO] 	Process 3 - batch 20899: mean_policy_losses: 110.517, mean_net_lifetime: 3780.2218, mean_mc_travel_dist: 1093.3338, mean_rewards: 198.4904, total_rewards: 2707.4302, mean_steps: 18.3000, mean_ecr: 0.0489 mean_entropies: 0.8364, took: 93.5697s
2022-10-10 05:56:15,910 [INFO] 	Process 6 - batch 30899: mean_policy_losses: -246.805, mean_net_lifetime: 2430.8727, mean_mc_travel_dist: 641.8748, mean_rewards: 281.8804, total_rewards: 1820.9302, mean_steps: 7.6700, mean_ecr: 0.0567 mean_entropies: 0.4340, took: 44.8146s
2022-10-10 05:56:21,172 [INFO] 	Process 5 - batch 20599: mean_policy_losses: -324.789, mean_net_lifetime: 3976.9185, mean_mc_travel_dist: 1402.0949, mean_rewards: 267.7413, total_rewards: 2637.7720, mean_steps: 14.5600, mean_ecr: 0.0306 mean_entropies: 1.0766, took: 74.4911s
2022-10-10 05:56:33,403 [INFO] 	Process 7 - batch 21599: mean_policy_losses: -479.427, mean_net_lifetime: 3080.2815, mean_mc_travel_dist: 1126.6925, mean_rewards: 222.1877, total_rewards: 2007.8946, mean_steps: 12.8500, mean_ecr: 0.0423 mean_entropies: 1.4595, took: 64.5394s
2022-10-10 05:56:49,857 [INFO] 	Process 2 - batch 20799: mean_policy_losses: 140.806, mean_net_lifetime: 4387.9428, mean_mc_travel_dist: 1427.7490, mean_rewards: 219.3575, total_rewards: 2987.9414, mean_steps: 19.1800, mean_ecr: 0.0399 mean_entropies: 0.9533, took: 92.9506s
2022-10-10 05:56:59,376 [INFO] 	Process 6 - batch 30999: mean_policy_losses: -287.344, mean_net_lifetime: 2355.9074, mean_mc_travel_dist: 638.1935, mean_rewards: 274.5447, total_rewards: 1766.3611, mean_steps: 7.4800, mean_ecr: 0.0569 mean_entropies: 0.4433, took: 43.4664s
2022-10-10 05:57:31,949 [INFO] 	Process 1 - batch 17699: mean_policy_losses: 49.391, mean_net_lifetime: 4593.0866, mean_mc_travel_dist: 1719.2979, mean_rewards: 186.9605, total_rewards: 2904.6410, mean_steps: 24.1300, mean_ecr: 0.0390 mean_entropies: 1.1063, took: 117.4716s
2022-10-10 05:57:36,339 [INFO] 	Process 3 - batch 20999: mean_policy_losses: 129.790, mean_net_lifetime: 3884.2410, mean_mc_travel_dist: 1103.5611, mean_rewards: 210.9288, total_rewards: 2800.0750, mean_steps: 17.5800, mean_ecr: 0.0489 mean_entropies: 0.8570, took: 89.6341s
2022-10-10 05:57:41,513 [INFO] 	Process 7 - batch 21699: mean_policy_losses: -496.383, mean_net_lifetime: 3256.2181, mean_mc_travel_dist: 1167.5632, mean_rewards: 224.0921, total_rewards: 2135.5244, mean_steps: 13.5800, mean_ecr: 0.0422 mean_entropies: 1.5008, took: 68.1102s
2022-10-10 05:57:43,824 [INFO] 	Process 5 - batch 20699: mean_policy_losses: -293.642, mean_net_lifetime: 4406.3669, mean_mc_travel_dist: 1583.8621, mean_rewards: 256.0149, total_rewards: 2874.6903, mean_steps: 16.4400, mean_ecr: 0.0311 mean_entropies: 1.0731, took: 82.6514s
2022-10-10 05:57:45,497 [INFO] 	Process 6 - batch 31099: mean_policy_losses: -256.836, mean_net_lifetime: 2543.2122, mean_mc_travel_dist: 676.1489, mean_rewards: 276.5962, total_rewards: 1905.7157, mean_steps: 8.2500, mean_ecr: 0.0569 mean_entropies: 0.4317, took: 46.1212s
2022-10-10 05:58:18,455 [INFO] 	Process 2 - batch 20899: mean_policy_losses: 172.650, mean_net_lifetime: 4356.7060, mean_mc_travel_dist: 1481.9197, mean_rewards: 225.1407, total_rewards: 2910.6097, mean_steps: 18.5100, mean_ecr: 0.0397 mean_entropies: 0.9650, took: 88.5977s
2022-10-10 05:58:26,674 [INFO] 	Process 6 - batch 31199: mean_policy_losses: -226.287, mean_net_lifetime: 2355.6771, mean_mc_travel_dist: 643.8280, mean_rewards: 290.7004, total_rewards: 1748.7007, mean_steps: 7.2500, mean_ecr: 0.0564 mean_entropies: 0.4275, took: 41.1768s
2022-10-10 05:58:47,184 [INFO] 	Process 7 - batch 21799: mean_policy_losses: -332.729, mean_net_lifetime: 3067.7507, mean_mc_travel_dist: 1168.4549, mean_rewards: 211.3920, total_rewards: 1946.9458, mean_steps: 13.6900, mean_ecr: 0.0422 mean_entropies: 1.3510, took: 65.6708s
2022-10-10 05:58:51,937 [INFO] 	Process 5 - batch 20799: mean_policy_losses: -311.438, mean_net_lifetime: 3759.9666, mean_mc_travel_dist: 1332.9395, mean_rewards: 274.6417, total_rewards: 2489.2914, mean_steps: 13.3900, mean_ecr: 0.0307 mean_entropies: 0.9789, took: 68.1135s
2022-10-10 05:59:12,158 [INFO] 	Process 6 - batch 31299: mean_policy_losses: -282.684, mean_net_lifetime: 2577.2652, mean_mc_travel_dist: 676.1559, mean_rewards: 279.9837, total_rewards: 1930.9768, mean_steps: 8.2300, mean_ecr: 0.0563 mean_entropies: 0.3554, took: 45.4842s
2022-10-10 05:59:20,106 [INFO] 	Process 1 - batch 17799: mean_policy_losses: 29.804, mean_net_lifetime: 4521.7329, mean_mc_travel_dist: 1837.6634, mean_rewards: 194.0355, total_rewards: 2708.3401, mean_steps: 22.8500, mean_ecr: 0.0385 mean_entropies: 1.0128, took: 108.1563s
2022-10-10 05:59:46,763 [INFO] 	Process 2 - batch 20999: mean_policy_losses: 58.943, mean_net_lifetime: 4032.9297, mean_mc_travel_dist: 1354.1557, mean_rewards: 207.8731, total_rewards: 2705.3233, mean_steps: 18.5200, mean_ecr: 0.0400 mean_entropies: 0.8711, took: 88.3083s
2022-10-10 05:59:59,678 [INFO] 	Process 7 - batch 21899: mean_policy_losses: -346.367, mean_net_lifetime: 3472.6582, mean_mc_travel_dist: 1244.8113, mean_rewards: 215.5472, total_rewards: 2266.1808, mean_steps: 15.2100, mean_ecr: 0.0421 mean_entropies: 1.3742, took: 72.4939s
2022-10-10 06:00:02,212 [INFO] 	Process 6 - batch 31399: mean_policy_losses: -219.575, mean_net_lifetime: 2770.5946, mean_mc_travel_dist: 726.6239, mean_rewards: 276.5593, total_rewards: 2074.2643, mean_steps: 9.1100, mean_ecr: 0.0561 mean_entropies: 0.3400, took: 50.0529s
2022-10-10 06:00:10,734 [INFO] 	Process 5 - batch 20899: mean_policy_losses: -202.638, mean_net_lifetime: 4439.0568, mean_mc_travel_dist: 1580.0947, mean_rewards: 268.5491, total_rewards: 2905.0745, mean_steps: 15.9800, mean_ecr: 0.0311 mean_entropies: 0.9812, took: 78.7960s
2022-10-10 06:00:49,222 [INFO] 	Process 6 - batch 31499: mean_policy_losses: -88.762, mean_net_lifetime: 2744.0791, mean_mc_travel_dist: 719.7223, mean_rewards: 274.0280, total_rewards: 2055.9791, mean_steps: 8.9600, mean_ecr: 0.0562 mean_entropies: 0.3396, took: 47.0110s
2022-10-10 06:01:04,385 [INFO] 	Process 1 - batch 17899: mean_policy_losses: 25.830, mean_net_lifetime: 4529.0681, mean_mc_travel_dist: 1832.3874, mean_rewards: 199.2862, total_rewards: 2723.9222, mean_steps: 22.2600, mean_ecr: 0.0386 mean_entropies: 0.9325, took: 104.2800s
2022-10-10 06:01:09,358 [INFO] 	Process 7 - batch 21999: mean_policy_losses: -284.338, mean_net_lifetime: 3304.1787, mean_mc_travel_dist: 1241.7864, mean_rewards: 204.8675, total_rewards: 2120.4507, mean_steps: 15.2100, mean_ecr: 0.0421 mean_entropies: 1.2622, took: 69.6789s
2022-10-10 06:01:18,130 [INFO] 	Process 5 - batch 20999: mean_policy_losses: -221.784, mean_net_lifetime: 3920.0117, mean_mc_travel_dist: 1441.3402, mean_rewards: 275.8565, total_rewards: 2541.2005, mean_steps: 13.8900, mean_ecr: 0.0309 mean_entropies: 0.8920, took: 67.3966s
2022-10-10 06:02:17,799 [INFO] 	Process 7 - batch 22099: mean_policy_losses: -218.423, mean_net_lifetime: 3319.0540, mean_mc_travel_dist: 1291.8862, mean_rewards: 193.9776, total_rewards: 2083.4009, mean_steps: 16.1000, mean_ecr: 0.0418 mean_entropies: 1.1818, took: 68.4424s
2022-10-10 06:02:32,118 [INFO] 	Process 1 - batch 17999: mean_policy_losses: 8.965, mean_net_lifetime: 4490.4734, mean_mc_travel_dist: 2003.9830, mean_rewards: 210.1576, total_rewards: 2505.6744, mean_steps: 20.7800, mean_ecr: 0.0381 mean_entropies: 0.8250, took: 87.7334s
2022-10-10 06:03:21,360 [INFO] 	Process 7 - batch 22199: mean_policy_losses: 60.536, mean_net_lifetime: 3445.0085, mean_mc_travel_dist: 1298.0992, mean_rewards: 204.5272, total_rewards: 2204.4153, mean_steps: 15.7700, mean_ecr: 0.0418 mean_entropies: 1.2038, took: 63.5602s
2022-10-10 06:03:26,167 [INFO] Process 4 - epoch 17: mean_policy_losses: 22.499, mean_net_lifetime: 3088.2974, mean_mc_travel_dist: 1315.5986, mean_entropies: 1.8753, m_net_lifetime_valid: 3715.7290, took: 1538.7796s, (170.5115 / 100 batches)

2022-10-10 06:04:28,545 [INFO] 	Process 4 - batch 25599: mean_policy_losses: 22.164, mean_net_lifetime: 3466.1599, mean_mc_travel_dist: 1024.6370, mean_rewards: 231.9141, total_rewards: 2471.7129, mean_steps: 13.9700, mean_ecr: 0.0498 mean_entropies: 1.1771, took: 622.6835s
2022-10-10 06:04:53,709 [INFO] 	Process 7 - batch 22299: mean_policy_losses: -27.751, mean_net_lifetime: 4970.7427, mean_mc_travel_dist: 1736.3136, mean_rewards: 209.2504, total_rewards: 3276.8551, mean_steps: 23.1500, mean_ecr: 0.0405 mean_entropies: 1.4347, took: 92.3494s
2022-10-10 06:05:43,614 [INFO] 	Process 4 - batch 25699: mean_policy_losses: 4.492, mean_net_lifetime: 4782.2509, mean_mc_travel_dist: 1428.1337, mean_rewards: 264.4507, total_rewards: 3377.7915, mean_steps: 17.2600, mean_ecr: 0.0469 mean_entropies: 0.9667, took: 75.0683s
2022-10-10 06:06:21,260 [INFO] 	Process 7 - batch 22399: mean_policy_losses: -413.177, mean_net_lifetime: 4857.0589, mean_mc_travel_dist: 1673.5457, mean_rewards: 221.9076, total_rewards: 3218.3817, mean_steps: 21.6000, mean_ecr: 0.0407 mean_entropies: 1.4384, took: 87.5508s
2022-10-10 06:06:57,463 [INFO] 	Process 4 - batch 25799: mean_policy_losses: 7.895, mean_net_lifetime: 4830.2619, mean_mc_travel_dist: 1416.2128, mean_rewards: 271.6473, total_rewards: 3441.4647, mean_steps: 17.0200, mean_ecr: 0.0471 mean_entropies: 0.9495, took: 73.8487s
2022-10-10 06:07:38,576 [INFO] Process 3 - epoch 14: mean_policy_losses: 143.303, mean_net_lifetime: 3871.5716, mean_mc_travel_dist: 1663.7072, mean_entropies: 1.6578, m_net_lifetime_valid: 3769.2350, took: 1934.2057s, (207.8713 / 100 batches)

2022-10-10 06:07:50,811 [INFO] 	Process 7 - batch 22499: mean_policy_losses: -444.025, mean_net_lifetime: 4736.0341, mean_mc_travel_dist: 1624.6446, mean_rewards: 212.8934, total_rewards: 3146.2721, mean_steps: 21.8600, mean_ecr: 0.0409 mean_entropies: 1.4207, took: 89.5518s
2022-10-10 06:08:16,249 [INFO] 	Process 4 - batch 25899: mean_policy_losses: 34.946, mean_net_lifetime: 4990.8506, mean_mc_travel_dist: 1503.1684, mean_rewards: 266.0329, total_rewards: 3523.0735, mean_steps: 18.2100, mean_ecr: 0.0465 mean_entropies: 0.9549, took: 78.7860s
2022-10-10 06:08:19,333 [INFO] Process 1 - epoch 12: mean_policy_losses: 108.925, mean_net_lifetime: 4602.4583, mean_mc_travel_dist: 2345.0197, mean_entropies: 1.8339, m_net_lifetime_valid: 3498.5525, took: 2025.6177s, (243.9631 / 100 batches)

2022-10-10 06:08:34,854 [INFO] Process 5 - epoch 14: mean_policy_losses: -44.694, mean_net_lifetime: 4315.4730, mean_mc_travel_dist: 2375.4900, mean_entropies: 2.1392, m_net_lifetime_valid: 3633.3811, took: 1424.5101s, (208.9256 / 100 batches)

2022-10-10 06:08:50,897 [INFO] Process 2 - epoch 14: mean_policy_losses: 22.903, mean_net_lifetime: 3825.5348, mean_mc_travel_dist: 1839.6930, mean_entropies: 1.7331, m_net_lifetime_valid: 3785.8060, took: 1791.7425s, (208.4931 / 100 batches)

2022-10-10 06:09:16,606 [INFO] 	Process 5 - batch 21099: mean_policy_losses: -645.818, mean_net_lifetime: 2230.8938, mean_mc_travel_dist: 627.6933, mean_rewards: 297.1237, total_rewards: 1649.0326, mean_steps: 7.0900, mean_ecr: 0.0294 mean_entropies: 1.0309, took: 478.4765s
2022-10-10 06:09:29,191 [INFO] 	Process 4 - batch 25999: mean_policy_losses: 196.186, mean_net_lifetime: 4109.2132, mean_mc_travel_dist: 1199.6623, mean_rewards: 255.6071, total_rewards: 2935.6381, mean_steps: 15.0500, mean_ecr: 0.0487 mean_entropies: 1.0816, took: 72.9418s
2022-10-10 06:09:36,345 [INFO] 	Process 3 - batch 21099: mean_policy_losses: 18.740, mean_net_lifetime: 3781.0550, mean_mc_travel_dist: 1033.2523, mean_rewards: 151.8109, total_rewards: 2763.4277, mean_steps: 25.6700, mean_ecr: 0.0493 mean_entropies: 0.5982, took: 720.0064s
2022-10-10 06:09:40,774 [INFO] Process 6 - epoch 21: mean_policy_losses: -275.288, mean_net_lifetime: 2187.3985, mean_mc_travel_dist: 1054.6497, mean_entropies: 1.3763, m_net_lifetime_valid: 3656.1028, took: 1205.3154s, (139.4112 / 100 batches)

2022-10-10 06:10:18,265 [INFO] 	Process 5 - batch 21199: mean_policy_losses: -516.313, mean_net_lifetime: 3280.4808, mean_mc_travel_dist: 1090.8317, mean_rewards: 280.2477, total_rewards: 2263.1325, mean_steps: 11.4700, mean_ecr: 0.0296 mean_entropies: 1.1860, took: 61.6586s
2022-10-10 06:10:18,909 [INFO] 	Process 2 - batch 21099: mean_policy_losses: 57.920, mean_net_lifetime: 3866.2234, mean_mc_travel_dist: 1321.5211, mean_rewards: 200.4234, total_rewards: 2579.8843, mean_steps: 18.4800, mean_ecr: 0.0404 mean_entropies: 0.7867, took: 632.1458s
2022-10-10 06:10:24,017 [INFO] 	Process 6 - batch 31599: mean_policy_losses: -257.021, mean_net_lifetime: 2207.5457, mean_mc_travel_dist: 597.7377, mean_rewards: 265.5079, total_rewards: 1642.6583, mean_steps: 7.4500, mean_ecr: 0.0571 mean_entropies: 0.3554, took: 574.7956s
2022-10-10 06:10:24,120 [INFO] 	Process 1 - batch 18099: mean_policy_losses: -26.606, mean_net_lifetime: 4485.8002, mean_mc_travel_dist: 1877.1576, mean_rewards: 165.5353, total_rewards: 2633.4962, mean_steps: 26.8500, mean_ecr: 0.0385 mean_entropies: 0.8533, took: 472.0023s
2022-10-10 06:10:39,623 [INFO] 	Process 4 - batch 26099: mean_policy_losses: 76.245, mean_net_lifetime: 3562.4347, mean_mc_travel_dist: 1053.0111, mean_rewards: 242.2241, total_rewards: 2530.3605, mean_steps: 13.6500, mean_ecr: 0.0497 mean_entropies: 1.1885, took: 70.4328s
2022-10-10 06:10:59,496 [INFO] 	Process 5 - batch 21299: mean_policy_losses: -601.852, mean_net_lifetime: 2362.9581, mean_mc_travel_dist: 747.9808, mean_rewards: 311.9502, total_rewards: 1669.2972, mean_steps: 7.2300, mean_ecr: 0.0293 mean_entropies: 1.0275, took: 41.2316s
2022-10-10 06:11:11,141 [INFO] 	Process 6 - batch 31699: mean_policy_losses: -119.781, mean_net_lifetime: 2803.7590, mean_mc_travel_dist: 739.0636, mean_rewards: 292.8985, total_rewards: 2087.9293, mean_steps: 8.5900, mean_ecr: 0.0560 mean_entropies: 0.3200, took: 47.1236s
2022-10-10 06:11:11,919 [INFO] 	Process 3 - batch 21199: mean_policy_losses: 156.317, mean_net_lifetime: 3750.1902, mean_mc_travel_dist: 1046.4352, mean_rewards: 190.3576, total_rewards: 2721.9788, mean_steps: 18.9500, mean_ecr: 0.0493 mean_entropies: 0.7717, took: 95.5736s
2022-10-10 06:11:40,472 [INFO] 	Process 2 - batch 21199: mean_policy_losses: 41.374, mean_net_lifetime: 3643.6791, mean_mc_travel_dist: 1285.9987, mean_rewards: 208.5987, total_rewards: 2383.0316, mean_steps: 16.6500, mean_ecr: 0.0402 mean_entropies: 0.7899, took: 81.5630s
2022-10-10 06:11:42,227 [INFO] 	Process 4 - batch 26199: mean_policy_losses: -110.208, mean_net_lifetime: 2823.3343, mean_mc_travel_dist: 929.3226, mean_rewards: 218.0996, total_rewards: 1921.2490, mean_steps: 11.8900, mean_ecr: 0.0510 mean_entropies: 1.0528, took: 62.6041s
2022-10-10 06:11:55,652 [INFO] 	Process 5 - batch 21399: mean_policy_losses: -448.310, mean_net_lifetime: 3055.9588, mean_mc_travel_dist: 1025.3720, mean_rewards: 301.1684, total_rewards: 2094.6096, mean_steps: 10.2300, mean_ecr: 0.0301 mean_entropies: 1.0178, took: 56.1554s
2022-10-10 06:11:59,931 [INFO] 	Process 6 - batch 31799: mean_policy_losses: -147.723, mean_net_lifetime: 2662.8756, mean_mc_travel_dist: 706.6304, mean_rewards: 279.2926, total_rewards: 1988.7811, mean_steps: 8.4400, mean_ecr: 0.0564 mean_entropies: 0.3906, took: 48.7900s
2022-10-10 06:12:03,478 [INFO] 	Process 1 - batch 18199: mean_policy_losses: 44.602, mean_net_lifetime: 4542.3393, mean_mc_travel_dist: 1864.7391, mean_rewards: 217.7527, total_rewards: 2703.9191, mean_steps: 20.2500, mean_ecr: 0.0386 mean_entropies: 0.9873, took: 99.3572s
2022-10-10 06:12:40,176 [INFO] 	Process 3 - batch 21299: mean_policy_losses: 156.543, mean_net_lifetime: 3812.4615, mean_mc_travel_dist: 1096.4123, mean_rewards: 210.9969, total_rewards: 2735.4695, mean_steps: 17.2500, mean_ecr: 0.0490 mean_entropies: 0.8311, took: 88.2573s
2022-10-10 06:12:43,398 [INFO] 	Process 4 - batch 26299: mean_policy_losses: -288.999, mean_net_lifetime: 2422.3087, mean_mc_travel_dist: 781.2929, mean_rewards: 195.6104, total_rewards: 1667.0176, mean_steps: 11.5400, mean_ecr: 0.0519 mean_entropies: 1.2644, took: 61.1704s
2022-10-10 06:12:45,807 [INFO] 	Process 6 - batch 31899: mean_policy_losses: -280.103, mean_net_lifetime: 2500.3065, mean_mc_travel_dist: 669.9272, mean_rewards: 279.7867, total_rewards: 1863.1799, mean_steps: 7.9000, mean_ecr: 0.0567 mean_entropies: 0.4241, took: 45.8750s
2022-10-10 06:13:12,545 [INFO] 	Process 2 - batch 21299: mean_policy_losses: 150.634, mean_net_lifetime: 4396.5237, mean_mc_travel_dist: 1473.5658, mean_rewards: 220.7409, total_rewards: 2949.1652, mean_steps: 19.0800, mean_ecr: 0.0396 mean_entropies: 1.0030, took: 92.0730s
2022-10-10 06:13:17,076 [INFO] 	Process 5 - batch 21499: mean_policy_losses: -292.554, mean_net_lifetime: 4244.2735, mean_mc_travel_dist: 1491.6279, mean_rewards: 256.0616, total_rewards: 2799.2589, mean_steps: 16.0900, mean_ecr: 0.0311 mean_entropies: 1.0231, took: 81.4232s
2022-10-10 06:13:31,839 [INFO] 	Process 6 - batch 31999: mean_policy_losses: -270.483, mean_net_lifetime: 2585.5897, mean_mc_travel_dist: 690.3478, mean_rewards: 291.5941, total_rewards: 1924.5588, mean_steps: 7.9400, mean_ecr: 0.0560 mean_entropies: 0.4315, took: 46.0323s
2022-10-10 06:13:44,833 [INFO] 	Process 4 - batch 26399: mean_policy_losses: -340.670, mean_net_lifetime: 2200.3591, mean_mc_travel_dist: 792.1861, mean_rewards: 177.1311, total_rewards: 1444.0049, mean_steps: 11.6100, mean_ecr: 0.0523 mean_entropies: 1.1322, took: 61.4352s
2022-10-10 06:13:46,617 [INFO] 	Process 1 - batch 18299: mean_policy_losses: -10.898, mean_net_lifetime: 4590.6232, mean_mc_travel_dist: 1836.8042, mean_rewards: 211.8067, total_rewards: 2787.7327, mean_steps: 21.1400, mean_ecr: 0.0386 mean_entropies: 1.0327, took: 103.1390s
2022-10-10 06:14:05,694 [INFO] 	Process 3 - batch 21399: mean_policy_losses: 183.574, mean_net_lifetime: 3803.3462, mean_mc_travel_dist: 1088.7145, mean_rewards: 216.6674, total_rewards: 2731.1918, mean_steps: 16.6800, mean_ecr: 0.0491 mean_entropies: 0.8735, took: 85.5173s
2022-10-10 06:14:21,529 [INFO] 	Process 6 - batch 32099: mean_policy_losses: -218.931, mean_net_lifetime: 2697.7003, mean_mc_travel_dist: 714.5707, mean_rewards: 284.9903, total_rewards: 2015.6852, mean_steps: 8.4900, mean_ecr: 0.0560 mean_entropies: 0.4047, took: 49.6911s
2022-10-10 06:14:39,200 [INFO] 	Process 2 - batch 21399: mean_policy_losses: 106.641, mean_net_lifetime: 4212.8917, mean_mc_travel_dist: 1403.3734, mean_rewards: 225.9635, total_rewards: 2839.2806, mean_steps: 17.8100, mean_ecr: 0.0400 mean_entropies: 0.9259, took: 86.6553s
2022-10-10 06:14:39,633 [INFO] 	Process 5 - batch 21599: mean_policy_losses: -272.491, mean_net_lifetime: 4218.1604, mean_mc_travel_dist: 1488.2702, mean_rewards: 252.5155, total_rewards: 2791.6906, mean_steps: 16.1500, mean_ecr: 0.0310 mean_entropies: 0.9954, took: 82.5586s
2022-10-10 06:14:43,191 [INFO] 	Process 4 - batch 26499: mean_policy_losses: -371.643, mean_net_lifetime: 2260.4339, mean_mc_travel_dist: 768.4718, mean_rewards: 191.8781, total_rewards: 1516.2885, mean_steps: 10.9200, mean_ecr: 0.0521 mean_entropies: 1.2044, took: 58.3584s
2022-10-10 06:15:09,979 [INFO] 	Process 6 - batch 32199: mean_policy_losses: -236.794, mean_net_lifetime: 2716.1319, mean_mc_travel_dist: 716.6503, mean_rewards: 282.1313, total_rewards: 2039.8328, mean_steps: 8.5800, mean_ecr: 0.0562 mean_entropies: 0.3616, took: 48.4484s
2022-10-10 06:15:32,421 [INFO] 	Process 1 - batch 18399: mean_policy_losses: 0.927, mean_net_lifetime: 4579.8629, mean_mc_travel_dist: 1831.9256, mean_rewards: 206.9972, total_rewards: 2779.8404, mean_steps: 21.6600, mean_ecr: 0.0387 mean_entropies: 1.0351, took: 105.8038s
2022-10-10 06:15:34,255 [INFO] 	Process 3 - batch 21499: mean_policy_losses: 138.004, mean_net_lifetime: 3751.4093, mean_mc_travel_dist: 1076.9244, mean_rewards: 208.8881, total_rewards: 2695.1418, mean_steps: 17.2200, mean_ecr: 0.0491 mean_entropies: 0.8301, took: 88.5619s
2022-10-10 06:15:42,892 [INFO] 	Process 4 - batch 26599: mean_policy_losses: -312.926, mean_net_lifetime: 2406.3515, mean_mc_travel_dist: 819.0572, mean_rewards: 197.8622, total_rewards: 1620.6616, mean_steps: 11.2800, mean_ecr: 0.0519 mean_entropies: 1.0956, took: 59.7003s
2022-10-10 06:15:51,098 [INFO] 	Process 5 - batch 21699: mean_policy_losses: -327.803, mean_net_lifetime: 3671.1559, mean_mc_travel_dist: 1261.1987, mean_rewards: 266.3146, total_rewards: 2477.0397, mean_steps: 13.4600, mean_ecr: 0.0308 mean_entropies: 0.9977, took: 71.4642s
2022-10-10 06:15:56,371 [INFO] 	Process 6 - batch 32299: mean_policy_losses: -156.401, mean_net_lifetime: 2647.3445, mean_mc_travel_dist: 702.5017, mean_rewards: 293.0105, total_rewards: 1979.7418, mean_steps: 7.9800, mean_ecr: 0.0564 mean_entropies: 0.4042, took: 46.3921s
2022-10-10 06:16:03,493 [INFO] 	Process 2 - batch 21499: mean_policy_losses: 90.758, mean_net_lifetime: 4012.0645, mean_mc_travel_dist: 1334.6430, mean_rewards: 221.6164, total_rewards: 2703.6220, mean_steps: 17.2800, mean_ecr: 0.0403 mean_entropies: 0.8467, took: 84.2928s
2022-10-10 06:16:41,382 [INFO] 	Process 4 - batch 26699: mean_policy_losses: -267.519, mean_net_lifetime: 2461.1183, mean_mc_travel_dist: 803.4414, mean_rewards: 207.4314, total_rewards: 1688.0976, mean_steps: 10.9100, mean_ecr: 0.0516 mean_entropies: 1.1587, took: 58.4906s
2022-10-10 06:16:43,586 [INFO] 	Process 6 - batch 32399: mean_policy_losses: -289.116, mean_net_lifetime: 2605.9695, mean_mc_travel_dist: 701.3471, mean_rewards: 286.8063, total_rewards: 1930.4384, mean_steps: 8.1000, mean_ecr: 0.0563 mean_entropies: 0.3830, took: 47.2164s
2022-10-10 06:16:59,634 [INFO] 	Process 3 - batch 21599: mean_policy_losses: 186.769, mean_net_lifetime: 3733.0787, mean_mc_travel_dist: 1071.4390, mean_rewards: 212.4972, total_rewards: 2682.4730, mean_steps: 16.7100, mean_ecr: 0.0490 mean_entropies: 0.8554, took: 85.3778s
2022-10-10 06:17:08,443 [INFO] 	Process 5 - batch 21799: mean_policy_losses: -333.270, mean_net_lifetime: 3976.0152, mean_mc_travel_dist: 1376.1326, mean_rewards: 263.3470, total_rewards: 2661.5797, mean_steps: 14.8800, mean_ecr: 0.0304 mean_entropies: 1.0340, took: 77.3449s
2022-10-10 06:17:11,209 [INFO] 	Process 1 - batch 18499: mean_policy_losses: 32.604, mean_net_lifetime: 4554.6904, mean_mc_travel_dist: 1834.2293, mean_rewards: 219.5822, total_rewards: 2757.1993, mean_steps: 20.0400, mean_ecr: 0.0387 mean_entropies: 1.0229, took: 98.7878s
2022-10-10 06:17:31,119 [INFO] 	Process 2 - batch 21599: mean_policy_losses: 104.991, mean_net_lifetime: 4211.6019, mean_mc_travel_dist: 1410.0542, mean_rewards: 225.0873, total_rewards: 2833.7642, mean_steps: 17.9200, mean_ecr: 0.0401 mean_entropies: 0.8792, took: 87.6254s
2022-10-10 06:17:31,908 [INFO] 	Process 6 - batch 32499: mean_policy_losses: -205.019, mean_net_lifetime: 2782.8867, mean_mc_travel_dist: 734.5769, mean_rewards: 290.0833, total_rewards: 2077.3164, mean_steps: 8.5800, mean_ecr: 0.0557 mean_entropies: 0.3695, took: 48.3210s
2022-10-10 06:17:41,930 [INFO] 	Process 4 - batch 26799: mean_policy_losses: -229.958, mean_net_lifetime: 2589.0015, mean_mc_travel_dist: 840.0365, mean_rewards: 212.4111, total_rewards: 1771.1658, mean_steps: 11.2200, mean_ecr: 0.0516 mean_entropies: 1.1027, took: 60.5472s
2022-10-10 06:18:05,665 [INFO] 	Process 5 - batch 21899: mean_policy_losses: -578.557, mean_net_lifetime: 3026.7232, mean_mc_travel_dist: 959.4858, mean_rewards: 279.8433, total_rewards: 2127.6259, mean_steps: 10.6200, mean_ecr: 0.0298 mean_entropies: 1.0753, took: 57.2228s
2022-10-10 06:18:19,663 [INFO] 	Process 6 - batch 32599: mean_policy_losses: -198.208, mean_net_lifetime: 2667.4327, mean_mc_travel_dist: 719.3713, mean_rewards: 284.8378, total_rewards: 1980.6855, mean_steps: 8.3500, mean_ecr: 0.0561 mean_entropies: 0.3060, took: 47.7555s
2022-10-10 06:18:31,919 [INFO] 	Process 3 - batch 21699: mean_policy_losses: 124.056, mean_net_lifetime: 3768.4374, mean_mc_travel_dist: 1064.5669, mean_rewards: 201.3566, total_rewards: 2724.1477, mean_steps: 17.9500, mean_ecr: 0.0492 mean_entropies: 0.7772, took: 92.2862s
2022-10-10 06:18:48,309 [INFO] 	Process 4 - batch 26899: mean_policy_losses: -27.581, mean_net_lifetime: 3194.1394, mean_mc_travel_dist: 972.4228, mean_rewards: 233.9156, total_rewards: 2255.9127, mean_steps: 12.6100, mean_ecr: 0.0504 mean_entropies: 1.1482, took: 66.3795s
2022-10-10 06:18:59,275 [INFO] 	Process 1 - batch 18599: mean_policy_losses: -38.940, mean_net_lifetime: 4521.7584, mean_mc_travel_dist: 1869.3955, mean_rewards: 202.2105, total_rewards: 2680.8752, mean_steps: 21.8100, mean_ecr: 0.0385 mean_entropies: 0.9222, took: 108.0668s
2022-10-10 06:19:01,271 [INFO] 	Process 2 - batch 21699: mean_policy_losses: 58.087, mean_net_lifetime: 3928.4740, mean_mc_travel_dist: 1307.1537, mean_rewards: 204.0365, total_rewards: 2645.5392, mean_steps: 18.4400, mean_ecr: 0.0404 mean_entropies: 0.7967, took: 90.1531s
2022-10-10 06:19:08,134 [INFO] 	Process 6 - batch 32699: mean_policy_losses: -178.028, mean_net_lifetime: 2642.4395, mean_mc_travel_dist: 708.1579, mean_rewards: 276.1458, total_rewards: 1968.3830, mean_steps: 8.5300, mean_ecr: 0.0563 mean_entropies: 0.3534, took: 48.4709s
2022-10-10 06:19:09,261 [INFO] 	Process 5 - batch 21999: mean_policy_losses: -458.461, mean_net_lifetime: 3457.8581, mean_mc_travel_dist: 1181.6659, mean_rewards: 278.2890, total_rewards: 2339.3450, mean_steps: 12.4000, mean_ecr: 0.0295 mean_entropies: 1.1259, took: 63.5957s
2022-10-10 06:19:53,294 [INFO] 	Process 4 - batch 26999: mean_policy_losses: -155.296, mean_net_lifetime: 2900.8687, mean_mc_travel_dist: 898.4395, mean_rewards: 220.5406, total_rewards: 2035.3727, mean_steps: 12.1700, mean_ecr: 0.0511 mean_entropies: 1.2108, took: 64.9853s
2022-10-10 06:19:57,817 [INFO] 	Process 6 - batch 32799: mean_policy_losses: -229.990, mean_net_lifetime: 2693.7110, mean_mc_travel_dist: 722.2678, mean_rewards: 280.5133, total_rewards: 2016.8283, mean_steps: 8.5300, mean_ecr: 0.0563 mean_entropies: 0.3563, took: 49.6828s
2022-10-10 06:19:59,024 [INFO] 	Process 3 - batch 21799: mean_policy_losses: 132.731, mean_net_lifetime: 3836.3467, mean_mc_travel_dist: 1095.7760, mean_rewards: 215.5303, total_rewards: 2764.3432, mean_steps: 16.9600, mean_ecr: 0.0491 mean_entropies: 0.8287, took: 87.1051s
2022-10-10 06:20:17,032 [INFO] Process 7 - epoch 15: mean_policy_losses: -42.981, mean_net_lifetime: 3788.9811, mean_mc_travel_dist: 1810.6181, mean_entropies: 2.1319, m_net_lifetime_valid: 3533.3942, took: 1854.2577s, (196.7962 / 100 batches)

2022-10-10 06:20:30,829 [INFO] 	Process 5 - batch 22099: mean_policy_losses: -304.439, mean_net_lifetime: 4311.1363, mean_mc_travel_dist: 1490.8859, mean_rewards: 260.8388, total_rewards: 2873.2334, mean_steps: 15.8800, mean_ecr: 0.0306 mean_entropies: 1.0962, took: 81.5681s
2022-10-10 06:20:34,762 [INFO] 	Process 2 - batch 21799: mean_policy_losses: 101.793, mean_net_lifetime: 4367.3083, mean_mc_travel_dist: 1481.0485, mean_rewards: 216.0738, total_rewards: 2915.0968, mean_steps: 19.3300, mean_ecr: 0.0397 mean_entropies: 0.9486, took: 93.4910s
2022-10-10 06:20:39,340 [INFO] 	Process 1 - batch 18699: mean_policy_losses: -103.423, mean_net_lifetime: 4517.1534, mean_mc_travel_dist: 1863.1166, mean_rewards: 210.6359, total_rewards: 2684.5042, mean_steps: 20.9300, mean_ecr: 0.0386 mean_entropies: 0.9550, took: 100.0644s
2022-10-10 06:20:41,700 [INFO] 	Process 6 - batch 32899: mean_policy_losses: -321.024, mean_net_lifetime: 2407.3617, mean_mc_travel_dist: 650.9399, mean_rewards: 282.9595, total_rewards: 1796.4911, mean_steps: 7.5400, mean_ecr: 0.0565 mean_entropies: 0.4407, took: 43.8825s
2022-10-10 06:21:23,640 [INFO] 	Process 3 - batch 21899: mean_policy_losses: 162.139, mean_net_lifetime: 3941.8951, mean_mc_travel_dist: 1146.3777, mean_rewards: 227.9121, total_rewards: 2813.3290, mean_steps: 16.4200, mean_ecr: 0.0487 mean_entropies: 0.9102, took: 84.6159s
2022-10-10 06:21:24,491 [INFO] 	Process 6 - batch 32999: mean_policy_losses: -271.771, mean_net_lifetime: 2349.2037, mean_mc_travel_dist: 632.0632, mean_rewards: 280.1987, total_rewards: 1751.7135, mean_steps: 7.4100, mean_ecr: 0.0567 mean_entropies: 0.4135, took: 42.7919s
2022-10-10 06:21:36,617 [INFO] 	Process 7 - batch 22599: mean_policy_losses: -243.183, mean_net_lifetime: 3753.8350, mean_mc_travel_dist: 1277.6541, mean_rewards: 222.6572, total_rewards: 2518.8949, mean_steps: 15.9200, mean_ecr: 0.0420 mean_entropies: 1.5215, took: 825.8050s
2022-10-10 06:21:57,405 [INFO] 	Process 5 - batch 22199: mean_policy_losses: -270.977, mean_net_lifetime: 4620.9876, mean_mc_travel_dist: 1628.8921, mean_rewards: 255.0429, total_rewards: 3050.6534, mean_steps: 17.5200, mean_ecr: 0.0310 mean_entropies: 1.0932, took: 86.5758s
2022-10-10 06:22:10,120 [INFO] 	Process 2 - batch 21899: mean_policy_losses: 94.222, mean_net_lifetime: 4610.2845, mean_mc_travel_dist: 1574.1754, mean_rewards: 226.8693, total_rewards: 3069.8187, mean_steps: 19.6200, mean_ecr: 0.0395 mean_entropies: 1.0211, took: 95.3580s
2022-10-10 06:22:22,805 [INFO] 	Process 1 - batch 18799: mean_policy_losses: -148.662, mean_net_lifetime: 4574.2764, mean_mc_travel_dist: 1837.0799, mean_rewards: 207.3324, total_rewards: 2763.6177, mean_steps: 21.4500, mean_ecr: 0.0386 mean_entropies: 0.9953, took: 103.4648s
2022-10-10 06:22:43,050 [INFO] 	Process 3 - batch 21999: mean_policy_losses: 173.947, mean_net_lifetime: 4163.1075, mean_mc_travel_dist: 1241.0733, mean_rewards: 250.8145, total_rewards: 2946.3581, mean_steps: 15.7700, mean_ecr: 0.0480 mean_entropies: 0.9558, took: 79.4101s
2022-10-10 06:23:02,564 [INFO] 	Process 7 - batch 22699: mean_policy_losses: -136.841, mean_net_lifetime: 4173.7458, mean_mc_travel_dist: 1408.4048, mean_rewards: 218.3237, total_rewards: 2801.9274, mean_steps: 18.3600, mean_ecr: 0.0417 mean_entropies: 1.5260, took: 85.9472s
2022-10-10 06:23:28,295 [INFO] 	Process 2 - batch 21999: mean_policy_losses: 1.491, mean_net_lifetime: 4402.0920, mean_mc_travel_dist: 1684.1268, mean_rewards: 256.7364, total_rewards: 2746.0951, mean_steps: 16.3300, mean_ecr: 0.0394 mean_entropies: 0.9353, took: 78.1749s
2022-10-10 06:23:28,568 [INFO] 	Process 5 - batch 22299: mean_policy_losses: -297.087, mean_net_lifetime: 4525.7461, mean_mc_travel_dist: 1673.7141, mean_rewards: 238.6057, total_rewards: 2907.5373, mean_steps: 18.2600, mean_ecr: 0.0312 mean_entropies: 0.9543, took: 91.1627s
2022-10-10 06:23:59,146 [INFO] 	Process 3 - batch 22099: mean_policy_losses: 227.878, mean_net_lifetime: 4042.9768, mean_mc_travel_dist: 1271.1288, mean_rewards: 255.8609, total_rewards: 2795.3561, mean_steps: 14.9400, mean_ecr: 0.0478 mean_entropies: 0.9185, took: 76.0948s
2022-10-10 06:24:01,632 [INFO] 	Process 1 - batch 18899: mean_policy_losses: -176.518, mean_net_lifetime: 4475.6011, mean_mc_travel_dist: 2094.0251, mean_rewards: 212.5483, total_rewards: 2412.9407, mean_steps: 20.6700, mean_ecr: 0.0379 mean_entropies: 0.8043, took: 98.8248s
2022-10-10 06:24:19,170 [INFO] 	Process 7 - batch 22799: mean_policy_losses: -241.580, mean_net_lifetime: 3382.0676, mean_mc_travel_dist: 1258.2657, mean_rewards: 196.1967, total_rewards: 2174.8591, mean_steps: 16.3100, mean_ecr: 0.0420 mean_entropies: 1.2272, took: 76.6061s
2022-10-10 06:24:35,293 [INFO] 	Process 2 - batch 22099: mean_policy_losses: -35.896, mean_net_lifetime: 3892.4689, mean_mc_travel_dist: 1690.9179, mean_rewards: 265.9340, total_rewards: 2245.8905, mean_steps: 13.6500, mean_ecr: 0.0399 mean_entropies: 0.7719, took: 66.9966s
2022-10-10 06:24:56,482 [INFO] 	Process 5 - batch 22399: mean_policy_losses: -205.628, mean_net_lifetime: 4128.9822, mean_mc_travel_dist: 1671.9355, mean_rewards: 223.4048, total_rewards: 2543.1621, mean_steps: 17.6900, mean_ecr: 0.0310 mean_entropies: 0.7771, took: 87.9143s
2022-10-10 06:25:06,697 [INFO] 	Process 3 - batch 22199: mean_policy_losses: 203.835, mean_net_lifetime: 3766.6346, mean_mc_travel_dist: 1371.5173, mean_rewards: 276.0628, total_rewards: 2427.6143, mean_steps: 12.7200, mean_ecr: 0.0468 mean_entropies: 0.7778, took: 67.5520s
2022-10-10 06:25:39,330 [INFO] 	Process 2 - batch 22199: mean_policy_losses: -87.076, mean_net_lifetime: 3659.6659, mean_mc_travel_dist: 1706.3730, mean_rewards: 265.1610, total_rewards: 2012.5251, mean_steps: 12.7800, mean_ecr: 0.0400 mean_entropies: 0.6798, took: 64.0377s
2022-10-10 06:25:40,931 [INFO] 	Process 1 - batch 18999: mean_policy_losses: -58.402, mean_net_lifetime: 4488.1118, mean_mc_travel_dist: 2297.5370, mean_rewards: 215.9150, total_rewards: 2229.8204, mean_steps: 20.2600, mean_ecr: 0.0375 mean_entropies: 0.6386, took: 99.3021s
2022-10-10 06:25:51,088 [INFO] 	Process 7 - batch 22899: mean_policy_losses: -61.266, mean_net_lifetime: 3852.8288, mean_mc_travel_dist: 1433.0190, mean_rewards: 191.6852, total_rewards: 2457.7825, mean_steps: 19.7200, mean_ecr: 0.0417 mean_entropies: 1.2319, took: 91.9175s
2022-10-10 06:26:16,746 [INFO] 	Process 3 - batch 22299: mean_policy_losses: 193.491, mean_net_lifetime: 3909.9535, mean_mc_travel_dist: 1386.1401, mean_rewards: 271.0720, total_rewards: 2548.0952, mean_steps: 13.4900, mean_ecr: 0.0466 mean_entropies: 0.7502, took: 70.0484s
2022-10-10 06:26:19,675 [INFO] 	Process 5 - batch 22499: mean_policy_losses: -220.054, mean_net_lifetime: 3952.9207, mean_mc_travel_dist: 1636.3321, mean_rewards: 218.5645, total_rewards: 2408.1468, mean_steps: 17.2500, mean_ecr: 0.0310 mean_entropies: 0.7342, took: 83.1931s
2022-10-10 06:26:45,633 [INFO] 	Process 2 - batch 22299: mean_policy_losses: -74.627, mean_net_lifetime: 4010.1533, mean_mc_travel_dist: 1707.0066, mean_rewards: 271.6298, total_rewards: 2344.5132, mean_steps: 13.7400, mean_ecr: 0.0397 mean_entropies: 0.7069, took: 66.3037s
2022-10-10 06:27:27,982 [INFO] 	Process 3 - batch 22399: mean_policy_losses: 56.179, mean_net_lifetime: 3820.6435, mean_mc_travel_dist: 1298.5856, mean_rewards: 251.0017, total_rewards: 2565.4179, mean_steps: 14.4100, mean_ecr: 0.0471 mean_entropies: 0.7148, took: 71.2364s
2022-10-10 06:27:31,341 [INFO] 	Process 1 - batch 19099: mean_policy_losses: -135.496, mean_net_lifetime: 4498.7379, mean_mc_travel_dist: 2223.3992, mean_rewards: 185.9016, total_rewards: 2313.7176, mean_steps: 24.1500, mean_ecr: 0.0373 mean_entropies: 0.6141, took: 110.4091s
2022-10-10 06:27:31,777 [INFO] 	Process 7 - batch 22999: mean_policy_losses: -27.814, mean_net_lifetime: 4366.5844, mean_mc_travel_dist: 1515.9679, mean_rewards: 189.2762, total_rewards: 2887.1208, mean_steps: 22.7200, mean_ecr: 0.0416 mean_entropies: 1.3324, took: 100.6902s
2022-10-10 06:27:51,310 [INFO] 	Process 2 - batch 22399: mean_policy_losses: -137.448, mean_net_lifetime: 4010.0241, mean_mc_travel_dist: 1717.3627, mean_rewards: 267.1153, total_rewards: 2339.0092, mean_steps: 14.0000, mean_ecr: 0.0396 mean_entropies: 0.7083, took: 65.6764s
2022-10-10 06:28:34,664 [INFO] 	Process 3 - batch 22499: mean_policy_losses: 136.945, mean_net_lifetime: 3799.2041, mean_mc_travel_dist: 1358.8867, mean_rewards: 271.6354, total_rewards: 2471.4841, mean_steps: 13.0800, mean_ecr: 0.0470 mean_entropies: 0.7455, took: 66.6817s
2022-10-10 06:28:52,197 [INFO] 	Process 7 - batch 23099: mean_policy_losses: -173.790, mean_net_lifetime: 3783.7859, mean_mc_travel_dist: 1358.9558, mean_rewards: 201.8407, total_rewards: 2464.6279, mean_steps: 17.9900, mean_ecr: 0.0419 mean_entropies: 1.3240, took: 80.4195s
2022-10-10 06:28:54,622 [INFO] Process 4 - epoch 18: mean_policy_losses: 14.720, mean_net_lifetime: 3098.2034, mean_mc_travel_dist: 1298.9154, mean_entropies: 1.8329, m_net_lifetime_valid: 3934.3113, took: 1528.4530s, (166.7837 / 100 batches)

2022-10-10 06:29:02,075 [INFO] 	Process 2 - batch 22499: mean_policy_losses: -10.884, mean_net_lifetime: 4291.1041, mean_mc_travel_dist: 1746.3072, mean_rewards: 261.2734, total_rewards: 2577.5337, mean_steps: 15.4500, mean_ecr: 0.0394 mean_entropies: 0.7488, took: 70.7654s
2022-10-10 06:29:10,767 [INFO] 	Process 1 - batch 19199: mean_policy_losses: -152.525, mean_net_lifetime: 4495.0338, mean_mc_travel_dist: 2279.1426, mean_rewards: 202.8928, total_rewards: 2246.1389, mean_steps: 22.0100, mean_ecr: 0.0374 mean_entropies: 0.6421, took: 99.4266s
2022-10-10 06:30:03,473 [INFO] 	Process 4 - batch 27099: mean_policy_losses: 4.917, mean_net_lifetime: 2532.2570, mean_mc_travel_dist: 877.6507, mean_rewards: 162.6863, total_rewards: 1674.3980, mean_steps: 14.8800, mean_ecr: 0.0524 mean_entropies: 1.0836, took: 610.1781s
2022-10-10 06:30:29,151 [INFO] 	Process 7 - batch 23199: mean_policy_losses: 199.317, mean_net_lifetime: 4528.0838, mean_mc_travel_dist: 1545.4629, mean_rewards: 193.3668, total_rewards: 3022.0692, mean_steps: 22.7200, mean_ecr: 0.0414 mean_entropies: 1.4090, took: 96.9534s
2022-10-10 06:30:52,087 [INFO] Process 6 - epoch 22: mean_policy_losses: -273.018, mean_net_lifetime: 2206.0630, mean_mc_travel_dist: 1038.2449, mean_entropies: 1.3311, m_net_lifetime_valid: 3842.5132, took: 1271.3114s, (136.8254 / 100 batches)

2022-10-10 06:30:56,357 [INFO] 	Process 1 - batch 19299: mean_policy_losses: -76.992, mean_net_lifetime: 4503.9997, mean_mc_travel_dist: 2147.6883, mean_rewards: 183.5085, total_rewards: 2378.1547, mean_steps: 24.5400, mean_ecr: 0.0375 mean_entropies: 0.6490, took: 105.5899s
2022-10-10 06:31:08,551 [INFO] 	Process 4 - batch 27199: mean_policy_losses: 78.338, mean_net_lifetime: 2956.7129, mean_mc_travel_dist: 959.1297, mean_rewards: 201.4394, total_rewards: 2019.3317, mean_steps: 13.9400, mean_ecr: 0.0512 mean_entropies: 1.2003, took: 65.0784s
2022-10-10 06:31:38,159 [INFO] 	Process 6 - batch 33099: mean_policy_losses: -218.961, mean_net_lifetime: 2697.5811, mean_mc_travel_dist: 722.9746, mean_rewards: 271.6210, total_rewards: 2003.1752, mean_steps: 8.9300, mean_ecr: 0.0561 mean_entropies: 0.2692, took: 613.6676s
2022-10-10 06:31:58,681 [INFO] 	Process 7 - batch 23299: mean_policy_losses: -49.123, mean_net_lifetime: 4569.5951, mean_mc_travel_dist: 1581.8011, mean_rewards: 216.4365, total_rewards: 3035.4344, mean_steps: 20.4900, mean_ecr: 0.0411 mean_entropies: 1.4736, took: 89.5305s
2022-10-10 06:32:12,418 [INFO] Process 5 - epoch 15: mean_policy_losses: -67.375, mean_net_lifetime: 4272.5048, mean_mc_travel_dist: 2303.1330, mean_entropies: 2.0640, m_net_lifetime_valid: 3370.4498, took: 1417.5635s, (201.7029 / 100 batches)

2022-10-10 06:32:23,360 [INFO] 	Process 4 - batch 27299: mean_policy_losses: 172.685, mean_net_lifetime: 4318.1600, mean_mc_travel_dist: 1295.7813, mean_rewards: 258.8066, total_rewards: 3053.6950, mean_steps: 15.7500, mean_ecr: 0.0480 mean_entropies: 0.9990, took: 74.8094s
2022-10-10 06:32:30,228 [INFO] 	Process 6 - batch 33199: mean_policy_losses: -89.619, mean_net_lifetime: 3078.0623, mean_mc_travel_dist: 804.5230, mean_rewards: 285.7070, total_rewards: 2292.6824, mean_steps: 9.8900, mean_ecr: 0.0553 mean_entropies: 0.2586, took: 52.0688s
2022-10-10 06:32:41,418 [INFO] 	Process 1 - batch 19399: mean_policy_losses: -70.526, mean_net_lifetime: 4492.6068, mean_mc_travel_dist: 1987.6152, mean_rewards: 192.2397, total_rewards: 2529.4415, mean_steps: 22.9300, mean_ecr: 0.0382 mean_entropies: 0.7504, took: 105.0609s
2022-10-10 06:32:44,268 [INFO] 	Process 5 - batch 22599: mean_policy_losses: -479.045, mean_net_lifetime: 2000.8051, mean_mc_travel_dist: 606.4774, mean_rewards: 340.4728, total_rewards: 1437.4422, mean_steps: 5.3200, mean_ecr: 0.0290 mean_entropies: 0.7744, took: 384.5919s
2022-10-10 06:33:22,909 [INFO] 	Process 6 - batch 33299: mean_policy_losses: -93.431, mean_net_lifetime: 3072.5626, mean_mc_travel_dist: 800.1361, mean_rewards: 283.8080, total_rewards: 2289.7025, mean_steps: 9.9100, mean_ecr: 0.0551 mean_entropies: 0.2367, took: 52.6819s
2022-10-10 06:33:30,174 [INFO] 	Process 7 - batch 23399: mean_policy_losses: -38.666, mean_net_lifetime: 4473.5928, mean_mc_travel_dist: 1566.3595, mean_rewards: 216.4108, total_rewards: 2945.2894, mean_steps: 19.9600, mean_ecr: 0.0410 mean_entropies: 1.3918, took: 91.4922s
2022-10-10 06:33:33,170 [INFO] 	Process 5 - batch 22699: mean_policy_losses: -582.805, mean_net_lifetime: 2527.1843, mean_mc_travel_dist: 774.3039, mean_rewards: 277.6507, total_rewards: 1800.4637, mean_steps: 9.0700, mean_ecr: 0.0293 mean_entropies: 0.9538, took: 48.9030s
2022-10-10 06:33:37,375 [INFO] 	Process 4 - batch 27399: mean_policy_losses: 341.305, mean_net_lifetime: 4120.0593, mean_mc_travel_dist: 1225.2875, mean_rewards: 258.3032, total_rewards: 2924.6424, mean_steps: 14.9000, mean_ecr: 0.0486 mean_entropies: 1.0048, took: 74.0144s
2022-10-10 06:33:38,824 [INFO] Process 3 - epoch 15: mean_policy_losses: 143.755, mean_net_lifetime: 3869.8256, mean_mc_travel_dist: 1631.2255, mean_entropies: 1.6012, m_net_lifetime_valid: 3279.3407, took: 1560.2458s, (202.2973 / 100 batches)

2022-10-10 06:34:18,506 [INFO] 	Process 6 - batch 33399: mean_policy_losses: -133.835, mean_net_lifetime: 3142.5842, mean_mc_travel_dist: 818.4043, mean_rewards: 287.0172, total_rewards: 2344.4898, mean_steps: 9.9900, mean_ecr: 0.0550 mean_entropies: 0.2378, took: 55.5961s
2022-10-10 06:34:24,637 [INFO] 	Process 5 - batch 22799: mean_policy_losses: -560.859, mean_net_lifetime: 2659.6597, mean_mc_travel_dist: 838.4835, mean_rewards: 272.2543, total_rewards: 1882.4174, mean_steps: 9.6200, mean_ecr: 0.0290 mean_entropies: 0.9367, took: 51.4667s
2022-10-10 06:34:27,146 [INFO] 	Process 1 - batch 19499: mean_policy_losses: -48.914, mean_net_lifetime: 4505.2186, mean_mc_travel_dist: 1990.6088, mean_rewards: 193.4425, total_rewards: 2545.8400, mean_steps: 22.6300, mean_ecr: 0.0381 mean_entropies: 0.7661, took: 105.7275s
2022-10-10 06:34:56,772 [INFO] 	Process 4 - batch 27499: mean_policy_losses: 192.577, mean_net_lifetime: 4330.7920, mean_mc_travel_dist: 1270.6318, mean_rewards: 258.5184, total_rewards: 3088.5054, mean_steps: 15.7100, mean_ecr: 0.0483 mean_entropies: 1.0414, took: 79.3968s
2022-10-10 06:35:06,234 [INFO] 	Process 7 - batch 23499: mean_policy_losses: -97.837, mean_net_lifetime: 4647.4025, mean_mc_travel_dist: 1587.5879, mean_rewards: 218.5687, total_rewards: 3100.0339, mean_steps: 20.5600, mean_ecr: 0.0410 mean_entropies: 1.4437, took: 96.0610s
2022-10-10 06:35:10,172 [INFO] 	Process 6 - batch 33499: mean_policy_losses: -203.852, mean_net_lifetime: 2925.2003, mean_mc_travel_dist: 769.0112, mean_rewards: 281.4756, total_rewards: 2182.0485, mean_steps: 9.3800, mean_ecr: 0.0559 mean_entropies: 0.2797, took: 51.6657s
2022-10-10 06:35:19,261 [INFO] 	Process 3 - batch 22599: mean_policy_losses: 40.789, mean_net_lifetime: 3788.6974, mean_mc_travel_dist: 1026.5067, mean_rewards: 177.9834, total_rewards: 2780.8496, mean_steps: 20.7500, mean_ecr: 0.0492 mean_entropies: 0.6690, took: 404.5969s
2022-10-10 06:35:41,345 [INFO] 	Process 5 - batch 22899: mean_policy_losses: -403.084, mean_net_lifetime: 4105.0108, mean_mc_travel_dist: 1487.2460, mean_rewards: 267.7898, total_rewards: 2666.3365, mean_steps: 15.2900, mean_ecr: 0.0286 mean_entropies: 1.0513, took: 76.7088s
2022-10-10 06:35:45,470 [INFO] Process 2 - epoch 15: mean_policy_losses: 23.429, mean_net_lifetime: 3843.8972, mean_mc_travel_dist: 1818.5740, mean_entropies: 1.6733, m_net_lifetime_valid: 3594.1622, took: 1614.5705s, (202.4220 / 100 batches)

2022-10-10 06:35:58,194 [INFO] 	Process 6 - batch 33599: mean_policy_losses: -377.405, mean_net_lifetime: 2834.0442, mean_mc_travel_dist: 743.6166, mean_rewards: 290.9135, total_rewards: 2109.2211, mean_steps: 8.9200, mean_ecr: 0.0558 mean_entropies: 0.2892, took: 48.0221s
2022-10-10 06:36:11,857 [INFO] 	Process 4 - batch 27599: mean_policy_losses: 153.864, mean_net_lifetime: 4104.9683, mean_mc_travel_dist: 1177.8324, mean_rewards: 258.3494, total_rewards: 2960.3504, mean_steps: 14.9100, mean_ecr: 0.0489 mean_entropies: 1.1158, took: 75.0854s
2022-10-10 06:36:38,330 [INFO] 	Process 7 - batch 23599: mean_policy_losses: -193.246, mean_net_lifetime: 4516.6450, mean_mc_travel_dist: 1530.9588, mean_rewards: 223.2584, total_rewards: 3020.7944, mean_steps: 19.5200, mean_ecr: 0.0412 mean_entropies: 1.5155, took: 92.0957s
2022-10-10 06:36:53,047 [INFO] 	Process 6 - batch 33699: mean_policy_losses: -136.907, mean_net_lifetime: 3082.7245, mean_mc_travel_dist: 792.7498, mean_rewards: 291.1914, total_rewards: 2306.9420, mean_steps: 9.6900, mean_ecr: 0.0555 mean_entropies: 0.2935, took: 54.8532s
2022-10-10 06:36:53,882 [INFO] 	Process 3 - batch 22699: mean_policy_losses: 33.692, mean_net_lifetime: 3771.4546, mean_mc_travel_dist: 1049.8093, mean_rewards: 192.4403, total_rewards: 2736.2348, mean_steps: 18.9500, mean_ecr: 0.0493 mean_entropies: 0.7003, took: 94.6215s
2022-10-10 06:36:58,947 [INFO] 	Process 5 - batch 22999: mean_policy_losses: -477.988, mean_net_lifetime: 4054.3131, mean_mc_travel_dist: 1466.9166, mean_rewards: 266.9862, total_rewards: 2649.5323, mean_steps: 15.1300, mean_ecr: 0.0287 mean_entropies: 1.0322, took: 77.6013s
2022-10-10 06:37:08,845 [INFO] 	Process 2 - batch 22599: mean_policy_losses: -80.876, mean_net_lifetime: 3656.7489, mean_mc_travel_dist: 1211.3713, mean_rewards: 204.4325, total_rewards: 2470.5868, mean_steps: 17.0500, mean_ecr: 0.0407 mean_entropies: 0.6945, took: 486.7695s
2022-10-10 06:37:19,907 [INFO] 	Process 4 - batch 27699: mean_policy_losses: -133.838, mean_net_lifetime: 3329.6896, mean_mc_travel_dist: 1023.8731, mean_rewards: 237.1649, total_rewards: 2332.2023, mean_steps: 13.0400, mean_ecr: 0.0502 mean_entropies: 1.1200, took: 68.0505s
2022-10-10 06:37:45,728 [INFO] 	Process 6 - batch 33799: mean_policy_losses: -191.531, mean_net_lifetime: 2935.0128, mean_mc_travel_dist: 764.8953, mean_rewards: 292.2728, total_rewards: 2190.6986, mean_steps: 9.1300, mean_ecr: 0.0556 mean_entropies: 0.3239, took: 52.6813s
2022-10-10 06:38:07,220 [INFO] 	Process 7 - batch 23699: mean_policy_losses: -269.241, mean_net_lifetime: 4127.1231, mean_mc_travel_dist: 1373.8091, mean_rewards: 215.6457, total_rewards: 2787.1381, mean_steps: 18.4500, mean_ecr: 0.0415 mean_entropies: 1.4639, took: 88.8898s
2022-10-10 06:38:26,112 [INFO] 	Process 3 - batch 22799: mean_policy_losses: 75.457, mean_net_lifetime: 3900.3923, mean_mc_travel_dist: 1093.7885, mean_rewards: 210.1177, total_rewards: 2831.1260, mean_steps: 17.7300, mean_ecr: 0.0492 mean_entropies: 0.7648, took: 92.2299s
2022-10-10 06:38:33,581 [INFO] 	Process 6 - batch 33899: mean_policy_losses: -309.890, mean_net_lifetime: 2591.2177, mean_mc_travel_dist: 682.4973, mean_rewards: 278.6075, total_rewards: 1942.9090, mean_steps: 8.3100, mean_ecr: 0.0565 mean_entropies: 0.3691, took: 47.8532s
2022-10-10 06:38:36,914 [INFO] 	Process 5 - batch 23099: mean_policy_losses: -162.052, mean_net_lifetime: 5130.5393, mean_mc_travel_dist: 1970.0954, mean_rewards: 261.2354, total_rewards: 3223.1843, mean_steps: 19.4500, mean_ecr: 0.0279 mean_entropies: 1.0851, took: 97.9674s
2022-10-10 06:38:38,121 [INFO] 	Process 4 - batch 27799: mean_policy_losses: 40.354, mean_net_lifetime: 3837.4688, mean_mc_travel_dist: 1156.2964, mean_rewards: 233.9902, total_rewards: 2708.4137, mean_steps: 15.2700, mean_ecr: 0.0493 mean_entropies: 1.1442, took: 78.2141s
2022-10-10 06:38:38,810 [INFO] 	Process 2 - batch 22699: mean_policy_losses: -24.201, mean_net_lifetime: 4062.2691, mean_mc_travel_dist: 1387.3218, mean_rewards: 210.5903, total_rewards: 2705.5453, mean_steps: 18.4500, mean_ecr: 0.0402 mean_entropies: 0.8005, took: 89.9652s
2022-10-10 06:39:23,052 [INFO] 	Process 6 - batch 33999: mean_policy_losses: -302.902, mean_net_lifetime: 2802.3759, mean_mc_travel_dist: 732.1323, mean_rewards: 295.3653, total_rewards: 2095.0740, mean_steps: 8.5000, mean_ecr: 0.0559 mean_entropies: 0.3385, took: 49.4714s
2022-10-10 06:39:35,850 [INFO] 	Process 7 - batch 23799: mean_policy_losses: -248.041, mean_net_lifetime: 4297.3096, mean_mc_travel_dist: 1424.0233, mean_rewards: 227.5218, total_rewards: 2910.4321, mean_steps: 18.2500, mean_ecr: 0.0414 mean_entropies: 1.5118, took: 88.6307s
2022-10-10 06:39:47,331 [INFO] 	Process 4 - batch 27899: mean_policy_losses: -68.104, mean_net_lifetime: 3446.8069, mean_mc_travel_dist: 1032.9378, mean_rewards: 241.2226, total_rewards: 2435.7390, mean_steps: 13.2200, mean_ecr: 0.0503 mean_entropies: 1.1011, took: 69.2098s
2022-10-10 06:39:54,685 [INFO] 	Process 3 - batch 22899: mean_policy_losses: 65.316, mean_net_lifetime: 3875.2589, mean_mc_travel_dist: 1112.5180, mean_rewards: 218.0347, total_rewards: 2789.2500, mean_steps: 16.9400, mean_ecr: 0.0492 mean_entropies: 0.7982, took: 88.5730s
2022-10-10 06:40:02,460 [INFO] 	Process 5 - batch 23199: mean_policy_losses: -326.573, mean_net_lifetime: 4626.4156, mean_mc_travel_dist: 1701.3666, mean_rewards: 270.9106, total_rewards: 2983.2583, mean_steps: 17.0800, mean_ecr: 0.0288 mean_entropies: 1.0992, took: 85.5458s
2022-10-10 06:40:09,845 [INFO] 	Process 2 - batch 22799: mean_policy_losses: -2.372, mean_net_lifetime: 4205.1292, mean_mc_travel_dist: 1412.7536, mean_rewards: 216.3727, total_rewards: 2824.4719, mean_steps: 18.6500, mean_ecr: 0.0402 mean_entropies: 0.8412, took: 91.0351s
2022-10-10 06:40:12,234 [INFO] 	Process 6 - batch 34099: mean_policy_losses: -271.772, mean_net_lifetime: 2815.4388, mean_mc_travel_dist: 739.9665, mean_rewards: 292.2635, total_rewards: 2099.9971, mean_steps: 8.6800, mean_ecr: 0.0557 mean_entropies: 0.3749, took: 49.1811s
2022-10-10 06:40:58,636 [INFO] 	Process 4 - batch 27999: mean_policy_losses: -27.248, mean_net_lifetime: 3589.7121, mean_mc_travel_dist: 1042.5323, mean_rewards: 243.7816, total_rewards: 2570.1100, mean_steps: 13.6700, mean_ecr: 0.0499 mean_entropies: 1.1626, took: 71.3044s
2022-10-10 06:40:58,842 [INFO] 	Process 6 - batch 34199: mean_policy_losses: -383.399, mean_net_lifetime: 2696.4751, mean_mc_travel_dist: 712.1412, mean_rewards: 291.6977, total_rewards: 2017.8248, mean_steps: 8.2200, mean_ecr: 0.0562 mean_entropies: 0.3634, took: 46.6082s
2022-10-10 06:41:02,969 [INFO] 	Process 7 - batch 23899: mean_policy_losses: -393.394, mean_net_lifetime: 4019.9317, mean_mc_travel_dist: 1400.3150, mean_rewards: 215.0114, total_rewards: 2664.3368, mean_steps: 17.8500, mean_ecr: 0.0415 mean_entropies: 1.5349, took: 87.1191s
2022-10-10 06:41:21,559 [INFO] 	Process 3 - batch 22999: mean_policy_losses: 60.300, mean_net_lifetime: 3917.9787, mean_mc_travel_dist: 1104.4802, mean_rewards: 221.6630, total_rewards: 2835.5044, mean_steps: 16.8400, mean_ecr: 0.0492 mean_entropies: 0.8497, took: 86.8739s
2022-10-10 06:41:29,971 [INFO] 	Process 5 - batch 23299: mean_policy_losses: -328.807, mean_net_lifetime: 4754.4601, mean_mc_travel_dist: 1726.7291, mean_rewards: 266.8902, total_rewards: 3095.0997, mean_steps: 17.3500, mean_ecr: 0.0291 mean_entropies: 1.1291, took: 87.5107s
2022-10-10 06:41:36,823 [INFO] 	Process 2 - batch 22899: mean_policy_losses: -15.638, mean_net_lifetime: 4289.4254, mean_mc_travel_dist: 1421.4717, mean_rewards: 229.5354, total_rewards: 2896.4239, mean_steps: 17.8100, mean_ecr: 0.0401 mean_entropies: 0.8859, took: 86.9779s
2022-10-10 06:41:48,985 [INFO] 	Process 6 - batch 34299: mean_policy_losses: -266.917, mean_net_lifetime: 2943.0748, mean_mc_travel_dist: 780.6890, mean_rewards: 296.6217, total_rewards: 2191.2267, mean_steps: 8.9400, mean_ecr: 0.0556 mean_entropies: 0.3891, took: 50.1425s
2022-10-10 06:42:09,776 [INFO] 	Process 4 - batch 28099: mean_policy_losses: -13.804, mean_net_lifetime: 3530.5887, mean_mc_travel_dist: 1048.5535, mean_rewards: 242.1143, total_rewards: 2506.8493, mean_steps: 13.6100, mean_ecr: 0.0498 mean_entropies: 1.1414, took: 71.1408s
2022-10-10 06:42:33,027 [INFO] 	Process 7 - batch 23999: mean_policy_losses: -236.135, mean_net_lifetime: 4196.1035, mean_mc_travel_dist: 1435.1006, mean_rewards: 213.8284, total_rewards: 2807.6609, mean_steps: 18.8000, mean_ecr: 0.0414 mean_entropies: 1.4936, took: 90.0579s
2022-10-10 06:42:36,364 [INFO] 	Process 6 - batch 34399: mean_policy_losses: -245.560, mean_net_lifetime: 2701.9593, mean_mc_travel_dist: 714.2237, mean_rewards: 289.0044, total_rewards: 2020.8962, mean_steps: 8.3200, mean_ecr: 0.0564 mean_entropies: 0.3663, took: 47.3793s
2022-10-10 06:42:43,881 [INFO] 	Process 5 - batch 23399: mean_policy_losses: -379.056, mean_net_lifetime: 3986.0487, mean_mc_travel_dist: 1472.4279, mean_rewards: 286.7343, total_rewards: 2569.7712, mean_steps: 14.2100, mean_ecr: 0.0284 mean_entropies: 1.0376, took: 73.9109s
2022-10-10 06:42:48,336 [INFO] 	Process 3 - batch 23099: mean_policy_losses: 109.653, mean_net_lifetime: 3878.1831, mean_mc_travel_dist: 1084.7340, mean_rewards: 217.0848, total_rewards: 2815.0541, mean_steps: 17.0300, mean_ecr: 0.0493 mean_entropies: 0.7976, took: 86.7774s
2022-10-10 06:42:52,665 [INFO] 	Process 2 - batch 22999: mean_policy_losses: -81.145, mean_net_lifetime: 3676.3985, mean_mc_travel_dist: 1322.8217, mean_rewards: 225.7481, total_rewards: 2387.6446, mean_steps: 15.4900, mean_ecr: 0.0404 mean_entropies: 0.7968, took: 75.8426s
2022-10-10 06:43:08,322 [INFO] 	Process 4 - batch 28199: mean_policy_losses: -55.264, mean_net_lifetime: 2804.5377, mean_mc_travel_dist: 951.3028, mean_rewards: 227.8274, total_rewards: 1893.4130, mean_steps: 11.2300, mean_ecr: 0.0512 mean_entropies: 1.0667, took: 58.5453s
2022-10-10 06:43:26,033 [INFO] 	Process 6 - batch 34499: mean_policy_losses: -161.421, mean_net_lifetime: 2867.6120, mean_mc_travel_dist: 754.1070, mean_rewards: 286.2391, total_rewards: 2141.3605, mean_steps: 9.0500, mean_ecr: 0.0557 mean_entropies: 0.3432, took: 49.6694s
2022-10-10 06:43:48,216 [INFO] 	Process 5 - batch 23499: mean_policy_losses: -349.287, mean_net_lifetime: 3732.9527, mean_mc_travel_dist: 1398.1047, mean_rewards: 295.1553, total_rewards: 2410.3173, mean_steps: 13.0000, mean_ecr: 0.0285 mean_entropies: 0.9459, took: 64.3341s
2022-10-10 06:44:10,599 [INFO] 	Process 3 - batch 23199: mean_policy_losses: 77.402, mean_net_lifetime: 4009.1525, mean_mc_travel_dist: 1122.8439, mean_rewards: 225.7875, total_rewards: 2903.4940, mean_steps: 16.9100, mean_ecr: 0.0490 mean_entropies: 0.8013, took: 82.2627s
2022-10-10 06:44:17,193 [INFO] 	Process 2 - batch 23099: mean_policy_losses: -13.561, mean_net_lifetime: 4186.3350, mean_mc_travel_dist: 1386.3349, mean_rewards: 220.1174, total_rewards: 2831.7139, mean_steps: 18.1500, mean_ecr: 0.0403 mean_entropies: 0.8413, took: 84.5273s
2022-10-10 06:44:18,772 [INFO] 	Process 4 - batch 28299: mean_policy_losses: -15.740, mean_net_lifetime: 3809.5012, mean_mc_travel_dist: 1117.1293, mean_rewards: 247.4004, total_rewards: 2722.6727, mean_steps: 14.4800, mean_ecr: 0.0495 mean_entropies: 1.1555, took: 70.4506s
2022-10-10 06:44:19,659 [INFO] Process 1 - epoch 13: mean_policy_losses: 95.573, mean_net_lifetime: 4596.2477, mean_mc_travel_dist: 2317.6308, mean_entropies: 1.7578, m_net_lifetime_valid: 3724.5558, took: 2160.3243s, (235.0630 / 100 batches)

2022-10-10 06:45:23,556 [INFO] 	Process 5 - batch 23599: mean_policy_losses: -227.192, mean_net_lifetime: 5449.0196, mean_mc_travel_dist: 2070.7294, mean_rewards: 262.5009, total_rewards: 3435.9871, mean_steps: 20.1900, mean_ecr: 0.0288 mean_entropies: 1.1549, took: 95.3406s
2022-10-10 06:45:28,823 [INFO] 	Process 4 - batch 28399: mean_policy_losses: 53.863, mean_net_lifetime: 3618.6887, mean_mc_travel_dist: 1084.6559, mean_rewards: 242.5708, total_rewards: 2557.4287, mean_steps: 14.0100, mean_ecr: 0.0496 mean_entropies: 1.2456, took: 70.0510s
2022-10-10 06:45:32,079 [INFO] 	Process 3 - batch 23299: mean_policy_losses: 136.655, mean_net_lifetime: 4202.8310, mean_mc_travel_dist: 1224.3777, mean_rewards: 250.6351, total_rewards: 2998.6610, mean_steps: 15.9000, mean_ecr: 0.0481 mean_entropies: 0.9158, took: 81.4801s
2022-10-10 06:45:38,150 [INFO] 	Process 2 - batch 23199: mean_policy_losses: 8.653, mean_net_lifetime: 4427.0975, mean_mc_travel_dist: 1552.8688, mean_rewards: 245.7119, total_rewards: 2902.9466, mean_steps: 17.1900, mean_ecr: 0.0397 mean_entropies: 0.9625, took: 80.9571s
2022-10-10 06:46:10,879 [INFO] 	Process 1 - batch 19599: mean_policy_losses: -196.826, mean_net_lifetime: 4507.0817, mean_mc_travel_dist: 1933.7362, mean_rewards: 193.7503, total_rewards: 2604.4664, mean_steps: 23.2800, mean_ecr: 0.0383 mean_entropies: 0.8422, took: 703.7339s
2022-10-10 06:46:40,295 [INFO] 	Process 4 - batch 28499: mean_policy_losses: -27.288, mean_net_lifetime: 3482.4660, mean_mc_travel_dist: 1109.9210, mean_rewards: 227.9815, total_rewards: 2402.5698, mean_steps: 14.2400, mean_ecr: 0.0502 mean_entropies: 1.1324, took: 71.4719s
2022-10-10 06:46:51,088 [INFO] 	Process 5 - batch 23699: mean_policy_losses: -270.146, mean_net_lifetime: 4867.3119, mean_mc_travel_dist: 1829.5925, mean_rewards: 268.1799, total_rewards: 3086.5538, mean_steps: 17.5000, mean_ecr: 0.0289 mean_entropies: 1.1845, took: 87.5320s
2022-10-10 06:46:51,342 [INFO] 	Process 3 - batch 23399: mean_policy_losses: 231.519, mean_net_lifetime: 4321.8748, mean_mc_travel_dist: 1255.1305, mean_rewards: 262.8118, total_rewards: 3100.3270, mean_steps: 15.5400, mean_ecr: 0.0482 mean_entropies: 0.9233, took: 79.2623s
2022-10-10 06:46:57,493 [INFO] 	Process 2 - batch 23299: mean_policy_losses: 0.884, mean_net_lifetime: 4327.6626, mean_mc_travel_dist: 1510.1695, mean_rewards: 246.0914, total_rewards: 2843.3664, mean_steps: 16.7400, mean_ecr: 0.0398 mean_entropies: 1.0044, took: 79.3434s
2022-10-10 06:47:46,809 [INFO] 	Process 1 - batch 19699: mean_policy_losses: -198.809, mean_net_lifetime: 4515.5537, mean_mc_travel_dist: 2056.8623, mean_rewards: 213.4075, total_rewards: 2493.1781, mean_steps: 20.7300, mean_ecr: 0.0380 mean_entropies: 0.8703, took: 95.9296s
2022-10-10 06:48:01,226 [INFO] 	Process 3 - batch 23499: mean_policy_losses: 234.231, mean_net_lifetime: 4178.3677, mean_mc_travel_dist: 1354.6268, mean_rewards: 279.8281, total_rewards: 2854.4646, mean_steps: 14.0300, mean_ecr: 0.0472 mean_entropies: 1.0068, took: 69.8850s
2022-10-10 06:48:07,710 [INFO] 	Process 2 - batch 23399: mean_policy_losses: 15.916, mean_net_lifetime: 4299.0228, mean_mc_travel_dist: 1642.0088, mean_rewards: 265.6722, total_rewards: 2684.8085, mean_steps: 15.2600, mean_ecr: 0.0396 mean_entropies: 0.9605, took: 70.2162s
2022-10-10 06:48:08,045 [INFO] 	Process 5 - batch 23799: mean_policy_losses: -337.080, mean_net_lifetime: 4475.9058, mean_mc_travel_dist: 1715.7769, mean_rewards: 263.7611, total_rewards: 2832.9953, mean_steps: 16.1200, mean_ecr: 0.0300 mean_entropies: 1.1187, took: 76.9562s
2022-10-10 06:49:13,973 [INFO] 	Process 3 - batch 23599: mean_policy_losses: 293.059, mean_net_lifetime: 4250.8836, mean_mc_travel_dist: 1324.0356, mean_rewards: 274.6768, total_rewards: 2961.7087, mean_steps: 14.5800, mean_ecr: 0.0477 mean_entropies: 0.9945, took: 72.7457s
2022-10-10 06:49:18,558 [INFO] 	Process 1 - batch 19799: mean_policy_losses: -205.152, mean_net_lifetime: 4544.6258, mean_mc_travel_dist: 2238.2242, mean_rewards: 218.3663, total_rewards: 2347.5793, mean_steps: 20.3600, mean_ecr: 0.0376 mean_entropies: 0.7902, took: 91.7489s
2022-10-10 06:49:23,776 [INFO] 	Process 2 - batch 23499: mean_policy_losses: 37.196, mean_net_lifetime: 4538.1321, mean_mc_travel_dist: 1728.7929, mean_rewards: 260.8476, total_rewards: 2840.4231, mean_steps: 16.4800, mean_ecr: 0.0394 mean_entropies: 0.9328, took: 76.0665s
2022-10-10 06:49:30,499 [INFO] 	Process 5 - batch 23899: mean_policy_losses: -275.974, mean_net_lifetime: 4661.9925, mean_mc_travel_dist: 1715.0201, mean_rewards: 254.8863, total_rewards: 3006.7477, mean_steps: 17.4400, mean_ecr: 0.0307 mean_entropies: 1.1068, took: 82.4546s
2022-10-10 06:50:21,661 [INFO] 	Process 3 - batch 23699: mean_policy_losses: 306.614, mean_net_lifetime: 4088.2248, mean_mc_travel_dist: 1325.4453, mean_rewards: 280.5986, total_rewards: 2787.3168, mean_steps: 13.6400, mean_ecr: 0.0475 mean_entropies: 0.9588, took: 67.6897s
2022-10-10 06:50:29,571 [INFO] 	Process 2 - batch 23599: mean_policy_losses: -50.539, mean_net_lifetime: 3992.8958, mean_mc_travel_dist: 1749.2820, mean_rewards: 263.3340, total_rewards: 2298.0614, mean_steps: 14.1600, mean_ecr: 0.0397 mean_entropies: 0.7409, took: 65.7957s
2022-10-10 06:50:36,142 [INFO] Process 7 - epoch 16: mean_policy_losses: -49.506, mean_net_lifetime: 3813.3725, mean_mc_travel_dist: 1787.8615, mean_entropies: 2.0878, m_net_lifetime_valid: 3612.6790, took: 1819.1093s, (193.1874 / 100 batches)

2022-10-10 06:50:40,793 [INFO] 	Process 1 - batch 19899: mean_policy_losses: -143.186, mean_net_lifetime: 4461.0337, mean_mc_travel_dist: 2354.5782, mean_rewards: 240.5486, total_rewards: 2157.8324, mean_steps: 17.6300, mean_ecr: 0.0378 mean_entropies: 0.6904, took: 82.2351s
2022-10-10 06:50:46,379 [INFO] 	Process 5 - batch 23999: mean_policy_losses: -256.888, mean_net_lifetime: 3889.8930, mean_mc_travel_dist: 1524.0922, mean_rewards: 238.8573, total_rewards: 2424.4421, mean_steps: 15.4600, mean_ecr: 0.0308 mean_entropies: 0.8628, took: 75.8797s
2022-10-10 06:51:26,700 [INFO] 	Process 3 - batch 23799: mean_policy_losses: 206.401, mean_net_lifetime: 3880.8084, mean_mc_travel_dist: 1384.2980, mean_rewards: 279.9475, total_rewards: 2532.2631, mean_steps: 12.9100, mean_ecr: 0.0467 mean_entropies: 0.8931, took: 65.0377s
2022-10-10 06:51:38,868 [INFO] 	Process 2 - batch 23699: mean_policy_losses: -30.006, mean_net_lifetime: 4043.0159, mean_mc_travel_dist: 1758.3123, mean_rewards: 260.3676, total_rewards: 2345.4620, mean_steps: 14.4700, mean_ecr: 0.0398 mean_entropies: 0.7578, took: 69.2967s
2022-10-10 06:51:57,736 [INFO] 	Process 7 - batch 24099: mean_policy_losses: -94.793, mean_net_lifetime: 3900.7770, mean_mc_travel_dist: 1362.1067, mean_rewards: 205.9512, total_rewards: 2579.3601, mean_steps: 18.1500, mean_ecr: 0.0419 mean_entropies: 1.5155, took: 564.7083s
2022-10-10 06:52:05,063 [INFO] 	Process 1 - batch 19999: mean_policy_losses: -200.183, mean_net_lifetime: 4506.0450, mean_mc_travel_dist: 2361.1329, mean_rewards: 237.2209, total_rewards: 2200.4830, mean_steps: 18.1900, mean_ecr: 0.0377 mean_entropies: 0.6869, took: 84.2702s
2022-10-10 06:52:40,819 [INFO] 	Process 3 - batch 23899: mean_policy_losses: 199.755, mean_net_lifetime: 4158.1873, mean_mc_travel_dist: 1331.7573, mean_rewards: 262.6517, total_rewards: 2860.8378, mean_steps: 14.9400, mean_ecr: 0.0472 mean_entropies: 0.9220, took: 74.1197s
2022-10-10 06:52:50,194 [INFO] 	Process 2 - batch 23799: mean_policy_losses: -71.492, mean_net_lifetime: 4318.8896, mean_mc_travel_dist: 1781.9959, mean_rewards: 264.3234, total_rewards: 2577.8309, mean_steps: 15.3400, mean_ecr: 0.0396 mean_entropies: 0.7701, took: 71.3255s
2022-10-10 06:53:30,895 [INFO] 	Process 7 - batch 24199: mean_policy_losses: -100.767, mean_net_lifetime: 4236.6382, mean_mc_travel_dist: 1404.1158, mean_rewards: 194.4849, total_rewards: 2875.9801, mean_steps: 21.0600, mean_ecr: 0.0419 mean_entropies: 1.5128, took: 93.1591s
2022-10-10 06:53:39,660 [INFO] Process 6 - epoch 23: mean_policy_losses: -270.966, mean_net_lifetime: 2235.3238, mean_mc_travel_dist: 1025.9504, mean_entropies: 1.2869, m_net_lifetime_valid: 3841.6488, took: 1367.5715s, (134.7131 / 100 batches)

2022-10-10 06:53:45,655 [INFO] 	Process 1 - batch 20099: mean_policy_losses: -227.092, mean_net_lifetime: 4526.0981, mean_mc_travel_dist: 2296.2930, mean_rewards: 198.7120, total_rewards: 2260.8618, mean_steps: 22.4500, mean_ecr: 0.0373 mean_entropies: 0.7020, took: 100.5919s
2022-10-10 06:53:58,729 [INFO] 	Process 3 - batch 23999: mean_policy_losses: 217.629, mean_net_lifetime: 4327.0510, mean_mc_travel_dist: 1367.9584, mean_rewards: 264.7682, total_rewards: 2994.3258, mean_steps: 15.5300, mean_ecr: 0.0468 mean_entropies: 0.9111, took: 77.9101s
2022-10-10 06:54:07,058 [INFO] 	Process 6 - batch 34599: mean_policy_losses: -317.639, mean_net_lifetime: 1405.7599, mean_mc_travel_dist: 471.4014, mean_rewards: 271.1374, total_rewards: 1027.1931, mean_steps: 4.2800, mean_ecr: 0.0578 mean_entropies: 0.5019, took: 641.0252s
2022-10-10 06:54:08,194 [INFO] 	Process 2 - batch 23899: mean_policy_losses: 128.729, mean_net_lifetime: 4665.7980, mean_mc_travel_dist: 1772.4889, mean_rewards: 260.0317, total_rewards: 2936.2116, mean_steps: 17.0200, mean_ecr: 0.0393 mean_entropies: 0.8777, took: 78.0001s
2022-10-10 06:54:34,752 [INFO] Process 4 - epoch 19: mean_policy_losses: 16.390, mean_net_lifetime: 3123.9556, mean_mc_travel_dist: 1288.0023, mean_entropies: 1.7951, m_net_lifetime_valid: 3755.1040, took: 1540.1295s, (163.6552 / 100 batches)

2022-10-10 06:54:55,193 [INFO] 	Process 6 - batch 34699: mean_policy_losses: -294.240, mean_net_lifetime: 2745.2913, mean_mc_travel_dist: 719.0783, mean_rewards: 284.9665, total_rewards: 2050.0190, mean_steps: 8.7300, mean_ecr: 0.0560 mean_entropies: 0.4243, took: 48.1344s
2022-10-10 06:54:56,811 [INFO] 	Process 7 - batch 24299: mean_policy_losses: -5.202, mean_net_lifetime: 4094.4324, mean_mc_travel_dist: 1391.7712, mean_rewards: 205.3528, total_rewards: 2745.0221, mean_steps: 18.9800, mean_ecr: 0.0417 mean_entropies: 1.4720, took: 85.9162s
2022-10-10 06:55:32,225 [INFO] 	Process 1 - batch 20199: mean_policy_losses: -4.777, mean_net_lifetime: 4557.2036, mean_mc_travel_dist: 1908.3342, mean_rewards: 193.0630, total_rewards: 2673.5671, mean_steps: 23.4600, mean_ecr: 0.0382 mean_entropies: 0.8635, took: 106.5698s
2022-10-10 06:55:33,983 [INFO] 	Process 2 - batch 23999: mean_policy_losses: 96.120, mean_net_lifetime: 4344.1852, mean_mc_travel_dist: 1431.8868, mean_rewards: 225.5209, total_rewards: 2934.2891, mean_steps: 18.3600, mean_ecr: 0.0401 mean_entropies: 0.8084, took: 85.7889s
2022-10-10 06:55:40,578 [INFO] 	Process 4 - batch 28599: mean_policy_losses: -15.370, mean_net_lifetime: 3029.4803, mean_mc_travel_dist: 918.2472, mean_rewards: 215.4302, total_rewards: 2126.0556, mean_steps: 13.1300, mean_ecr: 0.0504 mean_entropies: 1.1476, took: 540.2827s
2022-10-10 06:55:44,900 [INFO] 	Process 6 - batch 34799: mean_policy_losses: -201.717, mean_net_lifetime: 2949.4516, mean_mc_travel_dist: 769.0469, mean_rewards: 291.2905, total_rewards: 2202.1295, mean_steps: 9.1400, mean_ecr: 0.0555 mean_entropies: 0.3289, took: 49.7071s
2022-10-10 06:55:47,546 [INFO] Process 5 - epoch 16: mean_policy_losses: -85.734, mean_net_lifetime: 4259.3129, mean_mc_travel_dist: 2252.0928, mean_entropies: 1.9995, m_net_lifetime_valid: 3197.8679, took: 1415.1260s, (195.2347 / 100 batches)

2022-10-10 06:56:36,269 [INFO] 	Process 7 - batch 24399: mean_policy_losses: -42.103, mean_net_lifetime: 4790.2928, mean_mc_travel_dist: 1566.5378, mean_rewards: 214.4645, total_rewards: 3263.5761, mean_steps: 21.7600, mean_ecr: 0.0410 mean_entropies: 1.4631, took: 99.4581s
2022-10-10 06:56:36,870 [INFO] 	Process 6 - batch 34899: mean_policy_losses: -213.313, mean_net_lifetime: 3094.9156, mean_mc_travel_dist: 802.2031, mean_rewards: 290.7961, total_rewards: 2315.7729, mean_steps: 9.6000, mean_ecr: 0.0552 mean_entropies: 0.2998, took: 51.9707s
2022-10-10 06:56:56,869 [INFO] 	Process 4 - batch 28699: mean_policy_losses: 266.777, mean_net_lifetime: 4063.5252, mean_mc_travel_dist: 1159.3632, mean_rewards: 248.0495, total_rewards: 2942.6362, mean_steps: 15.4500, mean_ecr: 0.0490 mean_entropies: 1.1385, took: 76.2905s
2022-10-10 06:57:01,453 [INFO] 	Process 5 - batch 24099: mean_policy_losses: -490.278, mean_net_lifetime: 4023.0213, mean_mc_travel_dist: 1392.1057, mean_rewards: 264.5221, total_rewards: 2687.1974, mean_steps: 15.2000, mean_ecr: 0.0290 mean_entropies: 1.0679, took: 375.0733s
2022-10-10 06:57:27,062 [INFO] 	Process 6 - batch 34999: mean_policy_losses: -305.776, mean_net_lifetime: 3021.2614, mean_mc_travel_dist: 787.6537, mean_rewards: 300.9136, total_rewards: 2253.4157, mean_steps: 9.1400, mean_ecr: 0.0552 mean_entropies: 0.2826, took: 50.1921s
2022-10-10 06:57:36,273 [INFO] 	Process 1 - batch 20299: mean_policy_losses: -63.267, mean_net_lifetime: 4555.8364, mean_mc_travel_dist: 1827.7950, mean_rewards: 166.8032, total_rewards: 2752.5425, mean_steps: 27.3000, mean_ecr: 0.0387 mean_entropies: 0.8096, took: 124.0482s
2022-10-10 06:58:10,822 [INFO] 	Process 7 - batch 24499: mean_policy_losses: -78.978, mean_net_lifetime: 4661.0245, mean_mc_travel_dist: 1524.0424, mean_rewards: 219.7609, total_rewards: 3167.5331, mean_steps: 20.4600, mean_ecr: 0.0412 mean_entropies: 1.5380, took: 94.5530s
2022-10-10 06:58:16,323 [INFO] 	Process 5 - batch 24199: mean_policy_losses: -502.155, mean_net_lifetime: 3836.6978, mean_mc_travel_dist: 1333.6416, mean_rewards: 260.2956, total_rewards: 2552.4384, mean_steps: 15.1200, mean_ecr: 0.0287 mean_entropies: 1.0524, took: 74.8714s
2022-10-10 06:58:16,572 [INFO] 	Process 4 - batch 28799: mean_policy_losses: 362.770, mean_net_lifetime: 4508.6349, mean_mc_travel_dist: 1272.6502, mean_rewards: 266.1980, total_rewards: 3261.0838, mean_steps: 16.1300, mean_ecr: 0.0480 mean_entropies: 1.0903, took: 79.7031s
2022-10-10 06:58:19,104 [INFO] 	Process 6 - batch 35099: mean_policy_losses: -210.177, mean_net_lifetime: 3055.5823, mean_mc_travel_dist: 800.2698, mean_rewards: 293.3104, total_rewards: 2281.5012, mean_steps: 9.5300, mean_ecr: 0.0554 mean_entropies: 0.2685, took: 52.0415s
2022-10-10 06:59:10,348 [INFO] 	Process 6 - batch 35199: mean_policy_losses: -306.351, mean_net_lifetime: 3013.9337, mean_mc_travel_dist: 788.4935, mean_rewards: 294.2792, total_rewards: 2248.6605, mean_steps: 9.4100, mean_ecr: 0.0556 mean_entropies: 0.2941, took: 51.2442s
2022-10-10 06:59:31,049 [INFO] 	Process 4 - batch 28899: mean_policy_losses: 272.770, mean_net_lifetime: 4107.4637, mean_mc_travel_dist: 1187.9987, mean_rewards: 258.8577, total_rewards: 2948.7828, mean_steps: 14.9000, mean_ecr: 0.0490 mean_entropies: 1.0808, took: 74.4765s
2022-10-10 06:59:38,215 [INFO] 	Process 1 - batch 20399: mean_policy_losses: -61.362, mean_net_lifetime: 4522.1454, mean_mc_travel_dist: 1845.7774, mean_rewards: 171.4505, total_rewards: 2700.9519, mean_steps: 26.3000, mean_ecr: 0.0386 mean_entropies: 0.8212, took: 121.9418s
2022-10-10 06:59:38,578 [INFO] 	Process 5 - batch 24299: mean_policy_losses: -457.085, mean_net_lifetime: 4180.9500, mean_mc_travel_dist: 1519.6093, mean_rewards: 259.0352, total_rewards: 2728.6665, mean_steps: 16.2600, mean_ecr: 0.0285 mean_entropies: 1.0485, took: 82.2540s
2022-10-10 06:59:50,797 [INFO] 	Process 7 - batch 24599: mean_policy_losses: 65.044, mean_net_lifetime: 4837.8839, mean_mc_travel_dist: 1588.4937, mean_rewards: 217.8747, total_rewards: 3289.0126, mean_steps: 21.6100, mean_ecr: 0.0411 mean_entropies: 1.5324, took: 99.9751s
2022-10-10 07:00:01,051 [INFO] 	Process 6 - batch 35299: mean_policy_losses: -230.994, mean_net_lifetime: 3047.8976, mean_mc_travel_dist: 793.3134, mean_rewards: 296.3939, total_rewards: 2282.0794, mean_steps: 9.3400, mean_ecr: 0.0552 mean_entropies: 0.3400, took: 50.7023s
2022-10-10 07:00:42,830 [INFO] 	Process 4 - batch 28999: mean_policy_losses: 210.445, mean_net_lifetime: 3842.7715, mean_mc_travel_dist: 1100.5906, mean_rewards: 254.6949, total_rewards: 2778.3869, mean_steps: 14.1100, mean_ecr: 0.0492 mean_entropies: 1.1783, took: 71.7817s
2022-10-10 07:00:53,195 [INFO] 	Process 6 - batch 35399: mean_policy_losses: -154.260, mean_net_lifetime: 3181.7259, mean_mc_travel_dist: 839.3542, mean_rewards: 295.1543, total_rewards: 2361.5801, mean_steps: 9.8600, mean_ecr: 0.0551 mean_entropies: 0.3733, took: 52.1443s
2022-10-10 07:01:02,934 [INFO] 	Process 5 - batch 24399: mean_policy_losses: -244.572, mean_net_lifetime: 4653.2819, mean_mc_travel_dist: 1683.6342, mean_rewards: 260.9047, total_rewards: 3038.7284, mean_steps: 17.6100, mean_ecr: 0.0287 mean_entropies: 1.1021, took: 84.3574s
2022-10-10 07:01:12,435 [INFO] 	Process 7 - batch 24699: mean_policy_losses: -287.024, mean_net_lifetime: 3953.3131, mean_mc_travel_dist: 1320.6564, mean_rewards: 217.1747, total_rewards: 2672.2751, mean_steps: 17.3200, mean_ecr: 0.0419 mean_entropies: 1.5264, took: 81.6381s
2022-10-10 07:01:26,581 [INFO] 	Process 1 - batch 20499: mean_policy_losses: -38.276, mean_net_lifetime: 4543.5073, mean_mc_travel_dist: 1802.3894, mean_rewards: 194.2776, total_rewards: 2764.5106, mean_steps: 23.1700, mean_ecr: 0.0387 mean_entropies: 0.8718, took: 108.3658s
2022-10-10 07:01:30,442 [INFO] Process 3 - epoch 16: mean_policy_losses: 144.306, mean_net_lifetime: 3880.2505, mean_mc_travel_dist: 1604.9502, mean_entropies: 1.5549, m_net_lifetime_valid: 3641.4095, took: 1671.6167s, (196.0301 / 100 batches)

2022-10-10 07:01:46,230 [INFO] 	Process 6 - batch 35499: mean_policy_losses: -251.258, mean_net_lifetime: 3070.9836, mean_mc_travel_dist: 804.3402, mean_rewards: 293.5680, total_rewards: 2291.7883, mean_steps: 9.5800, mean_ecr: 0.0554 mean_entropies: 0.3488, took: 53.0349s
2022-10-10 07:01:52,044 [INFO] 	Process 4 - batch 29099: mean_policy_losses: 78.300, mean_net_lifetime: 3592.2637, mean_mc_travel_dist: 1074.7365, mean_rewards: 246.1470, total_rewards: 2546.2661, mean_steps: 13.5000, mean_ecr: 0.0499 mean_entropies: 1.0675, took: 69.2138s
2022-10-10 07:02:30,504 [INFO] 	Process 6 - batch 35599: mean_policy_losses: -358.029, mean_net_lifetime: 2596.0711, mean_mc_travel_dist: 697.4501, mean_rewards: 291.5543, total_rewards: 1932.5264, mean_steps: 7.8700, mean_ecr: 0.0565 mean_entropies: 0.3565, took: 44.2738s
2022-10-10 07:02:31,071 [INFO] 	Process 5 - batch 24499: mean_policy_losses: -358.557, mean_net_lifetime: 4533.1876, mean_mc_travel_dist: 1653.3825, mean_rewards: 261.4163, total_rewards: 2940.3692, mean_steps: 17.5200, mean_ecr: 0.0284 mean_entropies: 1.0645, took: 88.1363s
2022-10-10 07:02:54,824 [INFO] 	Process 7 - batch 24799: mean_policy_losses: -9.440, mean_net_lifetime: 4821.7464, mean_mc_travel_dist: 1564.2056, mean_rewards: 218.0664, total_rewards: 3295.9991, mean_steps: 21.2900, mean_ecr: 0.0410 mean_entropies: 1.5262, took: 102.3887s
2022-10-10 07:03:05,767 [INFO] 	Process 3 - batch 24099: mean_policy_losses: 75.995, mean_net_lifetime: 3961.6906, mean_mc_travel_dist: 1083.5829, mean_rewards: 210.5097, total_rewards: 2903.5435, mean_steps: 18.0100, mean_ecr: 0.0491 mean_entropies: 0.7798, took: 547.0378s
2022-10-10 07:03:12,242 [INFO] 	Process 1 - batch 20599: mean_policy_losses: -99.755, mean_net_lifetime: 4525.7577, mean_mc_travel_dist: 1909.4252, mean_rewards: 203.4329, total_rewards: 2648.7899, mean_steps: 21.7400, mean_ecr: 0.0384 mean_entropies: 0.8216, took: 105.6608s
2022-10-10 07:03:12,346 [INFO] 	Process 4 - batch 29199: mean_policy_losses: 307.635, mean_net_lifetime: 4190.3824, mean_mc_travel_dist: 1225.6721, mean_rewards: 250.9193, total_rewards: 3000.6282, mean_steps: 15.6700, mean_ecr: 0.0486 mean_entropies: 1.1507, took: 80.3029s
2022-10-10 07:03:19,231 [INFO] 	Process 6 - batch 35699: mean_policy_losses: -296.597, mean_net_lifetime: 2847.6154, mean_mc_travel_dist: 749.9470, mean_rewards: 298.7794, total_rewards: 2125.6927, mean_steps: 8.5600, mean_ecr: 0.0557 mean_entropies: 0.3558, took: 48.7268s
2022-10-10 07:04:02,223 [INFO] 	Process 5 - batch 24599: mean_policy_losses: -272.735, mean_net_lifetime: 4744.9906, mean_mc_travel_dist: 1700.1359, mean_rewards: 261.0551, total_rewards: 3095.4055, mean_steps: 18.0900, mean_ecr: 0.0288 mean_entropies: 1.1616, took: 91.1516s
2022-10-10 07:04:07,964 [INFO] 	Process 6 - batch 35799: mean_policy_losses: -300.278, mean_net_lifetime: 2929.4139, mean_mc_travel_dist: 768.9275, mean_rewards: 303.8841, total_rewards: 2180.5266, mean_steps: 8.7200, mean_ecr: 0.0555 mean_entropies: 0.3884, took: 48.7332s
2022-10-10 07:04:23,290 [INFO] 	Process 7 - batch 24899: mean_policy_losses: -156.840, mean_net_lifetime: 4290.9609, mean_mc_travel_dist: 1454.4012, mean_rewards: 224.6524, total_rewards: 2884.5417, mean_steps: 18.1100, mean_ecr: 0.0415 mean_entropies: 1.5814, took: 88.4659s
2022-10-10 07:04:24,164 [INFO] 	Process 4 - batch 29299: mean_policy_losses: 210.640, mean_net_lifetime: 3782.2167, mean_mc_travel_dist: 1104.8519, mean_rewards: 255.1481, total_rewards: 2705.8924, mean_steps: 13.7900, mean_ecr: 0.0493 mean_entropies: 1.1925, took: 71.8175s
2022-10-10 07:04:33,245 [INFO] 	Process 3 - batch 24199: mean_policy_losses: 76.245, mean_net_lifetime: 3997.9303, mean_mc_travel_dist: 1100.7450, mean_rewards: 223.3883, total_rewards: 2913.3485, mean_steps: 17.0300, mean_ecr: 0.0491 mean_entropies: 0.8122, took: 87.4770s
2022-10-10 07:04:48,011 [INFO] 	Process 1 - batch 20699: mean_policy_losses: -123.702, mean_net_lifetime: 4560.8635, mean_mc_travel_dist: 1904.4603, mean_rewards: 228.9970, total_rewards: 2680.6019, mean_steps: 19.3600, mean_ecr: 0.0385 mean_entropies: 0.9002, took: 95.7701s
2022-10-10 07:04:54,979 [INFO] 	Process 6 - batch 35899: mean_policy_losses: -324.467, mean_net_lifetime: 2789.2317, mean_mc_travel_dist: 746.7016, mean_rewards: 304.4463, total_rewards: 2071.1088, mean_steps: 8.2400, mean_ecr: 0.0560 mean_entropies: 0.4015, took: 47.0150s
2022-10-10 07:05:33,982 [INFO] 	Process 5 - batch 24699: mean_policy_losses: -264.955, mean_net_lifetime: 4817.7559, mean_mc_travel_dist: 1752.2007, mean_rewards: 262.2101, total_rewards: 3127.7552, mean_steps: 17.9600, mean_ecr: 0.0288 mean_entropies: 1.1684, took: 91.7592s
2022-10-10 07:05:38,775 [INFO] 	Process 4 - batch 29399: mean_policy_losses: 260.114, mean_net_lifetime: 3853.8706, mean_mc_travel_dist: 1099.0243, mean_rewards: 254.0738, total_rewards: 2774.4355, mean_steps: 14.2000, mean_ecr: 0.0494 mean_entropies: 1.2024, took: 74.6111s
2022-10-10 07:05:42,906 [INFO] 	Process 6 - batch 35999: mean_policy_losses: -363.625, mean_net_lifetime: 2709.1380, mean_mc_travel_dist: 725.2574, mean_rewards: 296.2526, total_rewards: 2011.9389, mean_steps: 8.2300, mean_ecr: 0.0559 mean_entropies: 0.4248, took: 47.9277s
2022-10-10 07:05:57,624 [INFO] 	Process 7 - batch 24999: mean_policy_losses: -178.983, mean_net_lifetime: 4453.9385, mean_mc_travel_dist: 1494.2605, mean_rewards: 220.3301, total_rewards: 3002.3253, mean_steps: 19.6500, mean_ecr: 0.0414 mean_entropies: 1.5777, took: 94.3347s
2022-10-10 07:06:00,991 [INFO] 	Process 3 - batch 24299: mean_policy_losses: 76.708, mean_net_lifetime: 4112.2326, mean_mc_travel_dist: 1150.3911, mean_rewards: 226.2525, total_rewards: 2982.5229, mean_steps: 17.3200, mean_ecr: 0.0488 mean_entropies: 0.8219, took: 87.7471s
2022-10-10 07:06:27,319 [INFO] 	Process 1 - batch 20799: mean_policy_losses: -151.889, mean_net_lifetime: 4522.2914, mean_mc_travel_dist: 1941.3279, mean_rewards: 212.1884, total_rewards: 2611.9071, mean_steps: 20.9600, mean_ecr: 0.0384 mean_entropies: 0.8521, took: 99.3065s
2022-10-10 07:06:45,003 [INFO] Process 2 - epoch 16: mean_policy_losses: 21.622, mean_net_lifetime: 3866.2911, mean_mc_travel_dist: 1801.0376, mean_entropies: 1.6216, m_net_lifetime_valid: 4018.8342, took: 1859.5322s, (196.4285 / 100 batches)

2022-10-10 07:07:00,540 [INFO] 	Process 4 - batch 29499: mean_policy_losses: 276.786, mean_net_lifetime: 4324.0820, mean_mc_travel_dist: 1250.1421, mean_rewards: 250.6830, total_rewards: 3102.1277, mean_steps: 16.2600, mean_ecr: 0.0482 mean_entropies: 1.2398, took: 81.7638s
2022-10-10 07:07:12,637 [INFO] 	Process 5 - batch 24799: mean_policy_losses: -174.967, mean_net_lifetime: 5430.4030, mean_mc_travel_dist: 2033.7683, mean_rewards: 262.7065, total_rewards: 3445.2109, mean_steps: 20.1400, mean_ecr: 0.0286 mean_entropies: 1.1815, took: 98.6544s
2022-10-10 07:07:25,901 [INFO] 	Process 3 - batch 24399: mean_policy_losses: 83.698, mean_net_lifetime: 4222.1768, mean_mc_travel_dist: 1207.7554, mean_rewards: 241.0955, total_rewards: 3054.8019, mean_steps: 16.6300, mean_ecr: 0.0483 mean_entropies: 0.8948, took: 84.9094s
2022-10-10 07:07:35,578 [INFO] 	Process 7 - batch 25099: mean_policy_losses: -134.965, mean_net_lifetime: 4643.6576, mean_mc_travel_dist: 1555.5866, mean_rewards: 215.3247, total_rewards: 3132.3612, mean_steps: 20.7700, mean_ecr: 0.0414 mean_entropies: 1.6074, took: 97.9539s
2022-10-10 07:08:05,318 [INFO] 	Process 1 - batch 20899: mean_policy_losses: -202.217, mean_net_lifetime: 4522.9877, mean_mc_travel_dist: 1979.6749, mean_rewards: 219.2545, total_rewards: 2570.7087, mean_steps: 20.1200, mean_ecr: 0.0383 mean_entropies: 0.8726, took: 98.0001s
2022-10-10 07:08:11,937 [INFO] 	Process 2 - batch 24099: mean_policy_losses: -45.438, mean_net_lifetime: 4423.8118, mean_mc_travel_dist: 1495.3101, mean_rewards: 241.2458, total_rewards: 2951.8986, mean_steps: 17.5100, mean_ecr: 0.0399 mean_entropies: 0.9741, took: 757.9541s
2022-10-10 07:08:14,767 [INFO] 	Process 4 - batch 29599: mean_policy_losses: 154.130, mean_net_lifetime: 3729.4968, mean_mc_travel_dist: 1091.5511, mean_rewards: 250.1256, total_rewards: 2663.8431, mean_steps: 13.9900, mean_ecr: 0.0497 mean_entropies: 1.2608, took: 74.2282s
2022-10-10 07:08:48,966 [INFO] 	Process 3 - batch 24499: mean_policy_losses: 60.102, mean_net_lifetime: 4195.0922, mean_mc_travel_dist: 1221.6662, mean_rewards: 246.9337, total_rewards: 2995.2772, mean_steps: 16.1500, mean_ecr: 0.0483 mean_entropies: 0.8988, took: 83.0649s
2022-10-10 07:08:49,802 [INFO] 	Process 5 - batch 24899: mean_policy_losses: -190.871, mean_net_lifetime: 5313.4759, mean_mc_travel_dist: 1912.4346, mean_rewards: 265.9758, total_rewards: 3449.7285, mean_steps: 19.3800, mean_ecr: 0.0295 mean_entropies: 1.1903, took: 97.1649s
2022-10-10 07:09:08,130 [INFO] 	Process 7 - batch 25199: mean_policy_losses: -269.140, mean_net_lifetime: 4292.4346, mean_mc_travel_dist: 1433.0230, mean_rewards: 217.9724, total_rewards: 2889.7732, mean_steps: 19.0900, mean_ecr: 0.0416 mean_entropies: 1.5870, took: 92.5516s
2022-10-10 07:09:32,262 [INFO] 	Process 4 - batch 29699: mean_policy_losses: 144.324, mean_net_lifetime: 3827.7433, mean_mc_travel_dist: 1122.8019, mean_rewards: 240.7582, total_rewards: 2731.5101, mean_steps: 14.9300, mean_ecr: 0.0495 mean_entropies: 1.2338, took: 77.4947s
2022-10-10 07:09:41,363 [INFO] 	Process 2 - batch 24199: mean_policy_losses: -29.550, mean_net_lifetime: 4576.1342, mean_mc_travel_dist: 1551.7287, mean_rewards: 239.3928, total_rewards: 3052.0161, mean_steps: 18.2800, mean_ecr: 0.0398 mean_entropies: 0.9828, took: 89.4264s
2022-10-10 07:09:58,143 [INFO] 	Process 1 - batch 20999: mean_policy_losses: -182.356, mean_net_lifetime: 4510.2025, mean_mc_travel_dist: 1877.0337, mean_rewards: 192.0668, total_rewards: 2661.2431, mean_steps: 23.2500, mean_ecr: 0.0384 mean_entropies: 0.8632, took: 112.8246s
2022-10-10 07:10:14,445 [INFO] 	Process 3 - batch 24599: mean_policy_losses: 103.035, mean_net_lifetime: 4460.2607, mean_mc_travel_dist: 1269.8809, mean_rewards: 258.3610, total_rewards: 3216.2972, mean_steps: 16.3700, mean_ecr: 0.0479 mean_entropies: 0.9104, took: 85.4794s
2022-10-10 07:10:29,181 [INFO] 	Process 5 - batch 24999: mean_policy_losses: -265.869, mean_net_lifetime: 5534.6486, mean_mc_travel_dist: 2101.2570, mean_rewards: 264.4736, total_rewards: 3495.1609, mean_steps: 20.5400, mean_ecr: 0.0286 mean_entropies: 1.1731, took: 99.3790s
2022-10-10 07:10:45,880 [INFO] 	Process 7 - batch 25299: mean_policy_losses: -213.423, mean_net_lifetime: 4628.3382, mean_mc_travel_dist: 1501.1766, mean_rewards: 215.8174, total_rewards: 3151.0065, mean_steps: 20.7400, mean_ecr: 0.0414 mean_entropies: 1.6070, took: 97.7498s
2022-10-10 07:10:48,356 [INFO] 	Process 4 - batch 29799: mean_policy_losses: 136.827, mean_net_lifetime: 4022.8086, mean_mc_travel_dist: 1169.4225, mean_rewards: 249.7426, total_rewards: 2878.8765, mean_steps: 15.0500, mean_ecr: 0.0490 mean_entropies: 1.2217, took: 76.0945s
2022-10-10 07:11:10,913 [INFO] 	Process 2 - batch 24299: mean_policy_losses: -67.519, mean_net_lifetime: 4476.3994, mean_mc_travel_dist: 1470.7806, mean_rewards: 228.6548, total_rewards: 3036.6076, mean_steps: 18.7300, mean_ecr: 0.0401 mean_entropies: 0.9253, took: 89.5488s
2022-10-10 07:11:37,105 [INFO] 	Process 3 - batch 24699: mean_policy_losses: -8.653, mean_net_lifetime: 4072.6443, mean_mc_travel_dist: 1155.0001, mean_rewards: 235.1865, total_rewards: 2946.6504, mean_steps: 16.4500, mean_ecr: 0.0487 mean_entropies: 0.8750, took: 82.6598s
2022-10-10 07:12:02,518 [INFO] 	Process 4 - batch 29899: mean_policy_losses: 247.382, mean_net_lifetime: 4309.2037, mean_mc_travel_dist: 1219.8456, mean_rewards: 272.9136, total_rewards: 3114.5637, mean_steps: 14.8800, mean_ecr: 0.0488 mean_entropies: 1.1667, took: 74.1620s
2022-10-10 07:12:09,556 [INFO] 	Process 7 - batch 25399: mean_policy_losses: -310.475, mean_net_lifetime: 4365.7942, mean_mc_travel_dist: 1426.6262, mean_rewards: 235.0862, total_rewards: 2977.8185, mean_steps: 17.8900, mean_ecr: 0.0416 mean_entropies: 1.5999, took: 83.6761s
2022-10-10 07:12:12,012 [INFO] 	Process 5 - batch 25099: mean_policy_losses: -234.509, mean_net_lifetime: 5610.4010, mean_mc_travel_dist: 2103.9807, mean_rewards: 259.5745, total_rewards: 3570.8433, mean_steps: 21.3600, mean_ecr: 0.0282 mean_entropies: 1.1826, took: 102.8316s
2022-10-10 07:12:38,485 [INFO] 	Process 2 - batch 24399: mean_policy_losses: -79.236, mean_net_lifetime: 4387.9646, mean_mc_travel_dist: 1403.0303, mean_rewards: 226.3593, total_rewards: 3014.5887, mean_steps: 18.6100, mean_ecr: 0.0404 mean_entropies: 0.8772, took: 87.5723s
2022-10-10 07:12:58,310 [INFO] 	Process 3 - batch 24799: mean_policy_losses: 4.562, mean_net_lifetime: 4212.6170, mean_mc_travel_dist: 1190.6971, mean_rewards: 247.9846, total_rewards: 3049.5457, mean_steps: 16.1100, mean_ecr: 0.0485 mean_entropies: 0.8833, took: 81.2042s
2022-10-10 07:13:18,090 [INFO] 	Process 4 - batch 29999: mean_policy_losses: 155.842, mean_net_lifetime: 4165.8056, mean_mc_travel_dist: 1204.5044, mean_rewards: 257.9381, total_rewards: 2988.6267, mean_steps: 15.1900, mean_ecr: 0.0487 mean_entropies: 1.2182, took: 75.5721s
2022-10-10 07:13:41,305 [INFO] 	Process 7 - batch 25499: mean_policy_losses: -259.904, mean_net_lifetime: 4606.1926, mean_mc_travel_dist: 1533.2123, mean_rewards: 221.2082, total_rewards: 3125.1356, mean_steps: 20.0000, mean_ecr: 0.0414 mean_entropies: 1.6216, took: 91.7494s
2022-10-10 07:13:57,422 [INFO] 	Process 5 - batch 25199: mean_policy_losses: -223.610, mean_net_lifetime: 5965.1030, mean_mc_travel_dist: 2235.9241, mean_rewards: 257.7124, total_rewards: 3785.4845, mean_steps: 22.4800, mean_ecr: 0.0288 mean_entropies: 1.1980, took: 105.4098s
2022-10-10 07:14:02,478 [INFO] 	Process 2 - batch 24499: mean_policy_losses: -76.112, mean_net_lifetime: 4551.4047, mean_mc_travel_dist: 1508.8275, mean_rewards: 236.1403, total_rewards: 3070.6356, mean_steps: 18.4900, mean_ecr: 0.0399 mean_entropies: 0.9656, took: 83.9933s
2022-10-10 07:14:14,087 [INFO] 	Process 3 - batch 24899: mean_policy_losses: 60.511, mean_net_lifetime: 4348.6991, mean_mc_travel_dist: 1228.0557, mean_rewards: 259.4103, total_rewards: 3149.6742, mean_steps: 15.8600, mean_ecr: 0.0482 mean_entropies: 0.8950, took: 75.7780s
2022-10-10 07:14:37,154 [INFO] Process 6 - epoch 24: mean_policy_losses: -271.145, mean_net_lifetime: 2260.1250, mean_mc_travel_dist: 1014.4898, mean_entropies: 1.2483, m_net_lifetime_valid: 3753.4854, took: 1257.4922s, (132.8189 / 100 batches)

2022-10-10 07:15:13,338 [INFO] 	Process 6 - batch 36099: mean_policy_losses: -396.893, mean_net_lifetime: 2179.9283, mean_mc_travel_dist: 618.5113, mean_rewards: 304.1806, total_rewards: 1603.6205, mean_steps: 6.2400, mean_ecr: 0.0568 mean_entropies: 0.4826, took: 570.4315s
2022-10-10 07:15:20,591 [INFO] 	Process 2 - batch 24599: mean_policy_losses: 29.958, mean_net_lifetime: 4581.3073, mean_mc_travel_dist: 1566.0967, mean_rewards: 248.7779, total_rewards: 3029.3720, mean_steps: 17.6000, mean_ecr: 0.0397 mean_entropies: 0.9855, took: 78.1127s
2022-10-10 07:15:25,575 [INFO] 	Process 5 - batch 25299: mean_policy_losses: -184.217, mean_net_lifetime: 5122.3645, mean_mc_travel_dist: 1835.4228, mean_rewards: 265.2958, total_rewards: 3348.9402, mean_steps: 18.6300, mean_ecr: 0.0297 mean_entropies: 1.1722, took: 88.1529s
2022-10-10 07:15:28,475 [INFO] 	Process 3 - batch 24999: mean_policy_losses: 104.475, mean_net_lifetime: 4038.3564, mean_mc_travel_dist: 1199.7375, mean_rewards: 256.0686, total_rewards: 2862.7892, mean_steps: 14.9300, mean_ecr: 0.0485 mean_entropies: 0.8924, took: 74.3879s
2022-10-10 07:15:56,791 [INFO] 	Process 6 - batch 36199: mean_policy_losses: -375.948, mean_net_lifetime: 2705.6424, mean_mc_travel_dist: 722.6306, mean_rewards: 299.5966, total_rewards: 2015.9377, mean_steps: 7.9900, mean_ecr: 0.0561 mean_entropies: 0.4001, took: 43.4539s
2022-10-10 07:16:39,943 [INFO] 	Process 6 - batch 36299: mean_policy_losses: -424.791, mean_net_lifetime: 2789.9163, mean_mc_travel_dist: 742.9005, mean_rewards: 302.3588, total_rewards: 2077.8968, mean_steps: 8.2500, mean_ecr: 0.0561 mean_entropies: 0.4333, took: 43.1508s
2022-10-10 07:16:45,243 [INFO] 	Process 3 - batch 25099: mean_policy_losses: 69.213, mean_net_lifetime: 3982.1409, mean_mc_travel_dist: 1122.8206, mean_rewards: 236.6053, total_rewards: 2885.8442, mean_steps: 15.9100, mean_ecr: 0.0491 mean_entropies: 0.8406, took: 76.7681s
2022-10-10 07:16:46,257 [INFO] 	Process 2 - batch 24699: mean_policy_losses: 91.975, mean_net_lifetime: 4580.2439, mean_mc_travel_dist: 1438.8048, mean_rewards: 232.6835, total_rewards: 3169.9215, mean_steps: 18.8600, mean_ecr: 0.0402 mean_entropies: 0.8874, took: 85.6668s
2022-10-10 07:16:49,791 [INFO] 	Process 5 - batch 25399: mean_policy_losses: -271.217, mean_net_lifetime: 4795.5582, mean_mc_travel_dist: 1682.1329, mean_rewards: 258.9702, total_rewards: 3177.5504, mean_steps: 17.8900, mean_ecr: 0.0301 mean_entropies: 1.1336, took: 84.2155s
2022-10-10 07:17:25,288 [INFO] 	Process 6 - batch 36399: mean_policy_losses: -295.022, mean_net_lifetime: 2930.6178, mean_mc_travel_dist: 776.5115, mean_rewards: 307.0856, total_rewards: 2181.5684, mean_steps: 8.6300, mean_ecr: 0.0556 mean_entropies: 0.4445, took: 45.3450s
2022-10-10 07:18:04,136 [INFO] 	Process 3 - batch 25199: mean_policy_losses: 47.647, mean_net_lifetime: 3960.8870, mean_mc_travel_dist: 1126.3059, mean_rewards: 234.8868, total_rewards: 2851.7358, mean_steps: 15.9600, mean_ecr: 0.0489 mean_entropies: 0.8742, took: 78.8929s
2022-10-10 07:18:05,799 [INFO] 	Process 6 - batch 36499: mean_policy_losses: -514.553, mean_net_lifetime: 2431.8968, mean_mc_travel_dist: 656.8548, mean_rewards: 299.7901, total_rewards: 1816.5603, mean_steps: 7.1500, mean_ecr: 0.0568 mean_entropies: 0.4469, took: 40.5113s
2022-10-10 07:18:13,289 [INFO] 	Process 2 - batch 24799: mean_policy_losses: 104.597, mean_net_lifetime: 4693.0886, mean_mc_travel_dist: 1483.1649, mean_rewards: 233.2131, total_rewards: 3236.6406, mean_steps: 19.2900, mean_ecr: 0.0399 mean_entropies: 0.9297, took: 87.0315s
2022-10-10 07:18:20,260 [INFO] 	Process 5 - batch 25499: mean_policy_losses: -220.386, mean_net_lifetime: 5065.3898, mean_mc_travel_dist: 1735.8538, mean_rewards: 258.6731, total_rewards: 3384.7351, mean_steps: 18.7800, mean_ecr: 0.0307 mean_entropies: 1.1392, took: 90.4701s
2022-10-10 07:18:47,662 [INFO] 	Process 6 - batch 36599: mean_policy_losses: -500.721, mean_net_lifetime: 2740.1313, mean_mc_travel_dist: 728.6497, mean_rewards: 305.9883, total_rewards: 2041.2339, mean_steps: 7.9600, mean_ecr: 0.0560 mean_entropies: 0.3998, took: 41.8634s
2022-10-10 07:19:15,843 [INFO] Process 1 - epoch 14: mean_policy_losses: 78.751, mean_net_lifetime: 4591.1883, mean_mc_travel_dist: 2296.0717, mean_entropies: 1.6906, m_net_lifetime_valid: 3903.1057, took: 2096.1820s, (228.4519 / 100 batches)

2022-10-10 07:19:22,278 [INFO] 	Process 3 - batch 25299: mean_policy_losses: 48.338, mean_net_lifetime: 3947.7994, mean_mc_travel_dist: 1103.6308, mean_rewards: 226.3863, total_rewards: 2863.5176, mean_steps: 16.5100, mean_ecr: 0.0492 mean_entropies: 0.8454, took: 78.1421s
2022-10-10 07:19:29,555 [INFO] 	Process 6 - batch 36699: mean_policy_losses: -452.037, mean_net_lifetime: 2679.2298, mean_mc_travel_dist: 716.2386, mean_rewards: 299.6253, total_rewards: 1992.6491, mean_steps: 8.0200, mean_ecr: 0.0560 mean_entropies: 0.4438, took: 41.8929s
2022-10-10 07:19:36,350 [INFO] 	Process 2 - batch 24899: mean_policy_losses: 66.150, mean_net_lifetime: 4650.5040, mean_mc_travel_dist: 1488.1125, mean_rewards: 235.6273, total_rewards: 3188.9470, mean_steps: 18.8900, mean_ecr: 0.0400 mean_entropies: 0.9309, took: 83.0609s
2022-10-10 07:20:15,041 [INFO] 	Process 6 - batch 36799: mean_policy_losses: -375.009, mean_net_lifetime: 2932.8521, mean_mc_travel_dist: 786.2184, mean_rewards: 308.6723, total_rewards: 2179.6971, mean_steps: 8.4900, mean_ecr: 0.0557 mean_entropies: 0.4691, took: 45.4854s
2022-10-10 07:20:41,973 [INFO] 	Process 3 - batch 25399: mean_policy_losses: 50.489, mean_net_lifetime: 3977.9600, mean_mc_travel_dist: 1128.1551, mean_rewards: 235.6997, total_rewards: 2871.1455, mean_steps: 15.9600, mean_ecr: 0.0490 mean_entropies: 0.8794, took: 79.6945s
2022-10-10 07:20:49,439 [INFO] 	Process 1 - batch 21099: mean_policy_losses: -63.538, mean_net_lifetime: 4684.4407, mean_mc_travel_dist: 1849.0628, mean_rewards: 222.8736, total_rewards: 2863.1070, mean_steps: 20.5400, mean_ecr: 0.0386 mean_entropies: 1.0192, took: 651.2966s
2022-10-10 07:20:56,440 [INFO] 	Process 6 - batch 36899: mean_policy_losses: -496.812, mean_net_lifetime: 2633.4864, mean_mc_travel_dist: 708.6955, mean_rewards: 304.7956, total_rewards: 1949.2592, mean_steps: 7.6900, mean_ecr: 0.0562 mean_entropies: 0.4205, took: 41.3997s
2022-10-10 07:21:04,847 [INFO] 	Process 2 - batch 24999: mean_policy_losses: 73.915, mean_net_lifetime: 4648.3547, mean_mc_travel_dist: 1462.5963, mean_rewards: 225.6482, total_rewards: 3206.8820, mean_steps: 19.7900, mean_ecr: 0.0399 mean_entropies: 0.9437, took: 88.4967s
2022-10-10 07:21:41,751 [INFO] 	Process 6 - batch 36999: mean_policy_losses: -401.555, mean_net_lifetime: 2884.1619, mean_mc_travel_dist: 773.4564, mean_rewards: 311.3710, total_rewards: 2135.3914, mean_steps: 8.3200, mean_ecr: 0.0555 mean_entropies: 0.4120, took: 45.3111s
2022-10-10 07:21:50,878 [INFO] Process 4 - epoch 20: mean_policy_losses: 25.801, mean_net_lifetime: 3165.5903, mean_mc_travel_dist: 1280.9402, mean_entropies: 1.7639, m_net_lifetime_valid: 3856.2017, took: 1636.1239s, (160.8079 / 100 batches)

2022-10-10 07:22:02,112 [INFO] 	Process 3 - batch 25499: mean_policy_losses: 16.865, mean_net_lifetime: 3927.0015, mean_mc_travel_dist: 1088.9438, mean_rewards: 223.9937, total_rewards: 2860.8512, mean_steps: 16.6200, mean_ecr: 0.0491 mean_entropies: 0.8657, took: 80.1395s
2022-10-10 07:22:27,701 [INFO] 	Process 6 - batch 37099: mean_policy_losses: -426.405, mean_net_lifetime: 2872.4715, mean_mc_travel_dist: 765.7204, mean_rewards: 305.9863, total_rewards: 2134.1220, mean_steps: 8.3900, mean_ecr: 0.0560 mean_entropies: 0.3919, took: 45.9495s
2022-10-10 07:22:28,609 [INFO] 	Process 1 - batch 21199: mean_policy_losses: -42.073, mean_net_lifetime: 4754.9220, mean_mc_travel_dist: 1834.1208, mean_rewards: 215.9064, total_rewards: 2953.6314, mean_steps: 21.6300, mean_ecr: 0.0387 mean_entropies: 1.0668, took: 99.1692s
2022-10-10 07:22:35,012 [INFO] 	Process 2 - batch 25099: mean_policy_losses: 86.264, mean_net_lifetime: 4684.6325, mean_mc_travel_dist: 1474.1926, mean_rewards: 227.9549, total_rewards: 3240.1419, mean_steps: 19.7300, mean_ecr: 0.0400 mean_entropies: 0.9148, took: 90.1656s
2022-10-10 07:22:54,169 [INFO] Process 7 - epoch 17: mean_policy_losses: -54.739, mean_net_lifetime: 3850.1444, mean_mc_travel_dist: 1769.4391, mean_entropies: 2.0562, m_net_lifetime_valid: 4226.1391, took: 1938.0263s, (189.1658 / 100 batches)

2022-10-10 07:23:00,216 [INFO] 	Process 4 - batch 30099: mean_policy_losses: 154.995, mean_net_lifetime: 3568.8371, mean_mc_travel_dist: 1024.5202, mean_rewards: 242.1452, total_rewards: 2571.4537, mean_steps: 13.7500, mean_ecr: 0.0498 mean_entropies: 1.2326, took: 582.1262s
2022-10-10 07:23:16,864 [INFO] 	Process 6 - batch 37199: mean_policy_losses: -399.473, mean_net_lifetime: 2945.2912, mean_mc_travel_dist: 793.1611, mean_rewards: 304.6679, total_rewards: 2182.2716, mean_steps: 8.7000, mean_ecr: 0.0559 mean_entropies: 0.4020, took: 49.1627s
2022-10-10 07:24:04,817 [INFO] 	Process 1 - batch 21299: mean_policy_losses: -73.433, mean_net_lifetime: 4606.8343, mean_mc_travel_dist: 1822.4725, mean_rewards: 224.5808, total_rewards: 2813.6703, mean_steps: 19.8200, mean_ecr: 0.0388 mean_entropies: 1.0447, took: 96.2069s
2022-10-10 07:24:06,700 [INFO] 	Process 2 - batch 25199: mean_policy_losses: 8.055, mean_net_lifetime: 4423.9165, mean_mc_travel_dist: 1373.9297, mean_rewards: 222.3794, total_rewards: 3069.5956, mean_steps: 19.0500, mean_ecr: 0.0404 mean_entropies: 0.8403, took: 91.6880s
2022-10-10 07:24:08,032 [INFO] 	Process 6 - batch 37299: mean_policy_losses: -322.075, mean_net_lifetime: 3042.2307, mean_mc_travel_dist: 805.0949, mean_rewards: 312.0348, total_rewards: 2261.5327, mean_steps: 8.8700, mean_ecr: 0.0558 mean_entropies: 0.4107, took: 51.1681s
2022-10-10 07:24:10,842 [INFO] 	Process 7 - batch 25599: mean_policy_losses: -376.460, mean_net_lifetime: 3899.2849, mean_mc_travel_dist: 1357.0649, mean_rewards: 233.1242, total_rewards: 2594.7724, mean_steps: 15.8300, mean_ecr: 0.0417 mean_entropies: 1.5885, took: 629.5368s
2022-10-10 07:24:11,469 [INFO] 	Process 4 - batch 30199: mean_policy_losses: 241.779, mean_net_lifetime: 3725.7102, mean_mc_travel_dist: 1069.3810, mean_rewards: 257.3277, total_rewards: 2689.9576, mean_steps: 13.4900, mean_ecr: 0.0497 mean_entropies: 1.2238, took: 71.2528s
2022-10-10 07:24:58,875 [INFO] 	Process 6 - batch 37399: mean_policy_losses: -327.498, mean_net_lifetime: 3040.8902, mean_mc_travel_dist: 812.8158, mean_rewards: 307.6734, total_rewards: 2256.6261, mean_steps: 8.9700, mean_ecr: 0.0553 mean_entropies: 0.3904, took: 50.8429s
2022-10-10 07:25:23,864 [INFO] 	Process 4 - batch 30299: mean_policy_losses: 322.836, mean_net_lifetime: 3923.5229, mean_mc_travel_dist: 1105.8087, mean_rewards: 260.1339, total_rewards: 2843.1816, mean_steps: 14.1600, mean_ecr: 0.0496 mean_entropies: 1.1645, took: 72.3951s
2022-10-10 07:25:28,965 [INFO] 	Process 2 - batch 25299: mean_policy_losses: -93.516, mean_net_lifetime: 4104.5516, mean_mc_travel_dist: 1325.8340, mean_rewards: 231.0245, total_rewards: 2811.3295, mean_steps: 16.9200, mean_ecr: 0.0405 mean_entropies: 0.8254, took: 82.2645s
2022-10-10 07:25:33,337 [INFO] 	Process 7 - batch 25699: mean_policy_losses: -278.023, mean_net_lifetime: 4204.2902, mean_mc_travel_dist: 1418.9572, mean_rewards: 233.1617, total_rewards: 2820.0037, mean_steps: 17.3100, mean_ecr: 0.0414 mean_entropies: 1.5396, took: 82.4946s
2022-10-10 07:25:38,853 [INFO] 	Process 1 - batch 21399: mean_policy_losses: -75.035, mean_net_lifetime: 4558.9442, mean_mc_travel_dist: 1892.9526, mean_rewards: 233.3990, total_rewards: 2693.9683, mean_steps: 18.9600, mean_ecr: 0.0387 mean_entropies: 0.9323, took: 94.0375s
2022-10-10 07:25:47,803 [INFO] 	Process 6 - batch 37499: mean_policy_losses: -378.438, mean_net_lifetime: 2946.9266, mean_mc_travel_dist: 788.9548, mean_rewards: 308.8520, total_rewards: 2188.1733, mean_steps: 8.5400, mean_ecr: 0.0560 mean_entropies: 0.4221, took: 48.9264s
2022-10-10 07:26:36,635 [INFO] 	Process 4 - batch 30399: mean_policy_losses: 304.913, mean_net_lifetime: 4015.6299, mean_mc_travel_dist: 1148.8789, mean_rewards: 259.9618, total_rewards: 2898.5716, mean_steps: 14.5300, mean_ecr: 0.0491 mean_entropies: 1.2040, took: 72.7704s
2022-10-10 07:26:52,572 [INFO] 	Process 2 - batch 25399: mean_policy_losses: -61.307, mean_net_lifetime: 4438.2918, mean_mc_travel_dist: 1482.9762, mean_rewards: 238.8538, total_rewards: 2981.5841, mean_steps: 17.7700, mean_ecr: 0.0399 mean_entropies: 0.9186, took: 83.6072s
2022-10-10 07:26:57,869 [INFO] 	Process 7 - batch 25799: mean_policy_losses: -285.249, mean_net_lifetime: 4276.8786, mean_mc_travel_dist: 1435.5189, mean_rewards: 220.9670, total_rewards: 2886.1197, mean_steps: 18.4200, mean_ecr: 0.0416 mean_entropies: 1.5976, took: 84.5325s
2022-10-10 07:27:11,183 [INFO] 	Process 1 - batch 21499: mean_policy_losses: -125.824, mean_net_lifetime: 4534.8611, mean_mc_travel_dist: 1890.4929, mean_rewards: 220.0116, total_rewards: 2663.9060, mean_steps: 20.2400, mean_ecr: 0.0385 mean_entropies: 0.8727, took: 92.3303s
2022-10-10 07:27:24,756 [INFO] Process 5 - epoch 17: mean_policy_losses: -97.773, mean_net_lifetime: 4297.4993, mean_mc_travel_dist: 2224.2265, mean_entropies: 1.9486, m_net_lifetime_valid: 3864.0499, took: 1897.2082s, (190.2556 / 100 batches)

2022-10-10 07:27:51,846 [INFO] 	Process 4 - batch 30499: mean_policy_losses: 285.326, mean_net_lifetime: 4224.4531, mean_mc_travel_dist: 1234.8082, mean_rewards: 258.3146, total_rewards: 3014.0342, mean_steps: 15.3400, mean_ecr: 0.0487 mean_entropies: 1.1678, took: 75.2116s
2022-10-10 07:28:16,560 [INFO] 	Process 2 - batch 25499: mean_policy_losses: -11.294, mean_net_lifetime: 4509.6037, mean_mc_travel_dist: 1483.2571, mean_rewards: 240.0635, total_rewards: 3052.2600, mean_steps: 18.0000, mean_ecr: 0.0398 mean_entropies: 0.9227, took: 83.9884s
2022-10-10 07:28:28,628 [INFO] 	Process 7 - batch 25899: mean_policy_losses: -176.252, mean_net_lifetime: 4545.6086, mean_mc_travel_dist: 1495.9999, mean_rewards: 221.6125, total_rewards: 3084.1015, mean_steps: 19.8500, mean_ecr: 0.0413 mean_entropies: 1.5668, took: 90.7590s
2022-10-10 07:28:52,740 [INFO] 	Process 1 - batch 21599: mean_policy_losses: -81.140, mean_net_lifetime: 4557.1019, mean_mc_travel_dist: 1813.9675, mean_rewards: 205.6128, total_rewards: 2766.1518, mean_steps: 21.8800, mean_ecr: 0.0387 mean_entropies: 0.9399, took: 101.5571s
2022-10-10 07:28:57,827 [INFO] 	Process 5 - batch 25599: mean_policy_losses: -171.832, mean_net_lifetime: 5219.8349, mean_mc_travel_dist: 1899.8909, mean_rewards: 258.1352, total_rewards: 3386.0897, mean_steps: 19.3700, mean_ecr: 0.0292 mean_entropies: 1.1641, took: 637.5665s
2022-10-10 07:29:03,610 [INFO] 	Process 4 - batch 30599: mean_policy_losses: 246.229, mean_net_lifetime: 3839.1418, mean_mc_travel_dist: 1107.2449, mean_rewards: 247.8011, total_rewards: 2760.9602, mean_steps: 14.5800, mean_ecr: 0.0496 mean_entropies: 1.2053, took: 71.7637s
2022-10-10 07:30:04,534 [INFO] 	Process 7 - batch 25999: mean_policy_losses: -80.321, mean_net_lifetime: 4758.3294, mean_mc_travel_dist: 1546.1263, mean_rewards: 213.6948, total_rewards: 3237.9823, mean_steps: 21.4700, mean_ecr: 0.0411 mean_entropies: 1.5950, took: 95.9052s
2022-10-10 07:30:17,479 [INFO] 	Process 4 - batch 30699: mean_policy_losses: 335.953, mean_net_lifetime: 4142.0128, mean_mc_travel_dist: 1199.6193, mean_rewards: 252.5015, total_rewards: 2965.1238, mean_steps: 15.4000, mean_ecr: 0.0490 mean_entropies: 1.2292, took: 73.8682s
2022-10-10 07:30:29,494 [INFO] 	Process 5 - batch 25699: mean_policy_losses: -197.186, mean_net_lifetime: 5193.4190, mean_mc_travel_dist: 1893.1413, mean_rewards: 262.8912, total_rewards: 3353.4404, mean_steps: 19.1100, mean_ecr: 0.0289 mean_entropies: 1.1838, took: 91.6670s
2022-10-10 07:30:34,841 [INFO] 	Process 1 - batch 21699: mean_policy_losses: -64.590, mean_net_lifetime: 4579.7859, mean_mc_travel_dist: 1837.9053, mean_rewards: 201.6616, total_rewards: 2767.7572, mean_steps: 22.6500, mean_ecr: 0.0386 mean_entropies: 0.9475, took: 102.1007s
2022-10-10 07:31:28,390 [INFO] 	Process 7 - batch 26099: mean_policy_losses: -219.120, mean_net_lifetime: 4263.2399, mean_mc_travel_dist: 1374.6290, mean_rewards: 221.2031, total_rewards: 2922.7770, mean_steps: 18.5700, mean_ecr: 0.0416 mean_entropies: 1.5710, took: 83.8560s
2022-10-10 07:31:33,940 [INFO] 	Process 4 - batch 30799: mean_policy_losses: 339.226, mean_net_lifetime: 4293.0065, mean_mc_travel_dist: 1230.5824, mean_rewards: 252.9026, total_rewards: 3087.4313, mean_steps: 16.1100, mean_ecr: 0.0489 mean_entropies: 1.1638, took: 76.4619s
2022-10-10 07:31:59,551 [INFO] 	Process 5 - batch 25799: mean_policy_losses: -267.755, mean_net_lifetime: 5137.7105, mean_mc_travel_dist: 1915.8138, mean_rewards: 260.8793, total_rewards: 3279.1553, mean_steps: 19.4800, mean_ecr: 0.0283 mean_entropies: 1.1430, took: 90.0563s
2022-10-10 07:32:25,359 [INFO] 	Process 1 - batch 21799: mean_policy_losses: -28.733, mean_net_lifetime: 4535.5642, mean_mc_travel_dist: 1741.8870, mean_rewards: 183.9354, total_rewards: 2823.2820, mean_steps: 24.5900, mean_ecr: 0.0390 mean_entropies: 0.9589, took: 110.5179s
2022-10-10 07:32:46,891 [INFO] Process 3 - epoch 17: mean_policy_losses: 139.226, mean_net_lifetime: 3892.8533, mean_mc_travel_dist: 1578.6879, mean_entropies: 1.5143, m_net_lifetime_valid: 4106.8087, took: 1876.4474s, (191.1196 / 100 batches)

2022-10-10 07:32:50,264 [INFO] 	Process 4 - batch 30899: mean_policy_losses: 365.601, mean_net_lifetime: 4366.7527, mean_mc_travel_dist: 1266.2438, mean_rewards: 259.9318, total_rewards: 3122.5223, mean_steps: 15.8000, mean_ecr: 0.0484 mean_entropies: 1.1817, took: 76.3236s
2022-10-10 07:33:01,538 [INFO] 	Process 7 - batch 26199: mean_policy_losses: -89.769, mean_net_lifetime: 4599.5480, mean_mc_travel_dist: 1513.4111, mean_rewards: 214.8279, total_rewards: 3128.7565, mean_steps: 20.6900, mean_ecr: 0.0413 mean_entropies: 1.6213, took: 93.1486s
2022-10-10 07:33:22,448 [INFO] 	Process 5 - batch 25899: mean_policy_losses: -496.493, mean_net_lifetime: 4711.3271, mean_mc_travel_dist: 1763.8983, mean_rewards: 281.8473, total_rewards: 3006.0403, mean_steps: 16.6600, mean_ecr: 0.0286 mean_entropies: 1.1665, took: 82.8978s
2022-10-10 07:34:02,815 [INFO] Process 6 - epoch 25: mean_policy_losses: -276.532, mean_net_lifetime: 2281.0684, mean_mc_travel_dist: 1003.7673, mean_entropies: 1.2153, m_net_lifetime_valid: 3801.6816, took: 1165.6603s, (130.7248 / 100 batches)

2022-10-10 07:34:08,939 [INFO] 	Process 1 - batch 21899: mean_policy_losses: -77.184, mean_net_lifetime: 4607.6570, mean_mc_travel_dist: 1866.0603, mean_rewards: 202.3615, total_rewards: 2764.1610, mean_steps: 22.3500, mean_ecr: 0.0385 mean_entropies: 0.9513, took: 103.5804s
2022-10-10 07:34:09,860 [INFO] 	Process 3 - batch 25599: mean_policy_losses: 99.908, mean_net_lifetime: 4464.1876, mean_mc_travel_dist: 1314.7455, mean_rewards: 259.6534, total_rewards: 3180.6921, mean_steps: 16.2700, mean_ecr: 0.0475 mean_entropies: 0.8851, took: 727.7479s
2022-10-10 07:34:13,970 [INFO] 	Process 4 - batch 30999: mean_policy_losses: 377.558, mean_net_lifetime: 4721.0538, mean_mc_travel_dist: 1365.4271, mean_rewards: 264.0545, total_rewards: 3376.7859, mean_steps: 16.9700, mean_ecr: 0.0476 mean_entropies: 1.1225, took: 83.7059s
2022-10-10 07:34:28,083 [INFO] 	Process 7 - batch 26299: mean_policy_losses: -273.132, mean_net_lifetime: 4189.6991, mean_mc_travel_dist: 1404.1678, mean_rewards: 220.7578, total_rewards: 2824.6292, mean_steps: 18.3700, mean_ecr: 0.0416 mean_entropies: 1.5255, took: 86.5445s
2022-10-10 07:34:34,526 [INFO] 	Process 6 - batch 37599: mean_policy_losses: -420.816, mean_net_lifetime: 1632.9678, mean_mc_travel_dist: 447.6880, mean_rewards: 273.6315, total_rewards: 1225.2268, mean_steps: 5.0300, mean_ecr: 0.0575 mean_entropies: 0.4280, took: 526.7247s
2022-10-10 07:34:53,418 [INFO] 	Process 5 - batch 25999: mean_policy_losses: -205.539, mean_net_lifetime: 4954.2806, mean_mc_travel_dist: 1838.5593, mean_rewards: 259.1484, total_rewards: 3178.0885, mean_steps: 18.5000, mean_ecr: 0.0286 mean_entropies: 1.1794, took: 90.9704s
2022-10-10 07:35:18,265 [INFO] 	Process 6 - batch 37699: mean_policy_losses: -339.356, mean_net_lifetime: 2562.4999, mean_mc_travel_dist: 688.6619, mean_rewards: 292.1518, total_rewards: 1911.1186, mean_steps: 7.6600, mean_ecr: 0.0561 mean_entropies: 0.3766, took: 43.7390s
2022-10-10 07:35:34,501 [INFO] 	Process 4 - batch 31099: mean_policy_losses: 381.602, mean_net_lifetime: 4307.4559, mean_mc_travel_dist: 1249.0059, mean_rewards: 257.5124, total_rewards: 3090.3758, mean_steps: 15.7200, mean_ecr: 0.0485 mean_entropies: 1.1137, took: 80.5311s
2022-10-10 07:35:38,586 [INFO] 	Process 3 - batch 25699: mean_policy_losses: 160.776, mean_net_lifetime: 4278.1660, mean_mc_travel_dist: 1199.2442, mean_rewards: 241.4552, total_rewards: 3104.5996, mean_steps: 16.8700, mean_ecr: 0.0485 mean_entropies: 0.8546, took: 88.7263s
2022-10-10 07:35:59,776 [INFO] 	Process 7 - batch 26399: mean_policy_losses: -130.370, mean_net_lifetime: 4377.0111, mean_mc_travel_dist: 1438.9865, mean_rewards: 219.0155, total_rewards: 2977.4100, mean_steps: 19.1900, mean_ecr: 0.0415 mean_entropies: 1.5277, took: 91.6938s
2022-10-10 07:36:04,354 [INFO] 	Process 1 - batch 21999: mean_policy_losses: 47.965, mean_net_lifetime: 4594.3004, mean_mc_travel_dist: 1737.6235, mean_rewards: 192.5454, total_rewards: 2885.4791, mean_steps: 23.4400, mean_ecr: 0.0391 mean_entropies: 1.0268, took: 115.4145s
2022-10-10 07:36:06,038 [INFO] 	Process 6 - batch 37799: mean_policy_losses: -303.928, mean_net_lifetime: 2814.5409, mean_mc_travel_dist: 758.8252, mean_rewards: 297.4513, total_rewards: 2088.8472, mean_steps: 8.3700, mean_ecr: 0.0557 mean_entropies: 0.3826, took: 47.7729s
2022-10-10 07:36:27,256 [INFO] 	Process 5 - batch 26099: mean_policy_losses: -268.528, mean_net_lifetime: 5016.0587, mean_mc_travel_dist: 1780.2849, mean_rewards: 260.2743, total_rewards: 3290.9740, mean_steps: 18.8700, mean_ecr: 0.0292 mean_entropies: 1.1659, took: 93.8374s
2022-10-10 07:36:50,434 [INFO] 	Process 6 - batch 37899: mean_policy_losses: -380.575, mean_net_lifetime: 2550.3152, mean_mc_travel_dist: 694.5121, mean_rewards: 306.7535, total_rewards: 1901.5899, mean_steps: 7.3400, mean_ecr: 0.0560 mean_entropies: 0.4517, took: 44.3969s
2022-10-10 07:36:51,021 [INFO] 	Process 4 - batch 31199: mean_policy_losses: 349.267, mean_net_lifetime: 4226.5775, mean_mc_travel_dist: 1200.9382, mean_rewards: 263.8273, total_rewards: 3053.5461, mean_steps: 15.0300, mean_ecr: 0.0490 mean_entropies: 1.1219, took: 76.5206s
2022-10-10 07:37:03,720 [INFO] 	Process 3 - batch 25799: mean_policy_losses: 92.701, mean_net_lifetime: 4198.1906, mean_mc_travel_dist: 1190.6955, mean_rewards: 242.9517, total_rewards: 3032.8256, mean_steps: 16.3700, mean_ecr: 0.0486 mean_entropies: 0.8572, took: 85.1339s
2022-10-10 07:37:15,325 [INFO] 	Process 7 - batch 26499: mean_policy_losses: -513.273, mean_net_lifetime: 3617.7718, mean_mc_travel_dist: 1253.2802, mean_rewards: 228.1362, total_rewards: 2408.3683, mean_steps: 15.3200, mean_ecr: 0.0419 mean_entropies: 1.5221, took: 75.5488s
2022-10-10 07:37:36,938 [INFO] 	Process 6 - batch 37999: mean_policy_losses: -378.450, mean_net_lifetime: 2823.0919, mean_mc_travel_dist: 751.1482, mean_rewards: 310.4627, total_rewards: 2094.8213, mean_steps: 8.1400, mean_ecr: 0.0560 mean_entropies: 0.4343, took: 46.5026s
2022-10-10 07:37:37,709 [INFO] Process 2 - epoch 17: mean_policy_losses: 20.338, mean_net_lifetime: 3904.4709, mean_mc_travel_dist: 1781.4026, mean_entropies: 1.5804, m_net_lifetime_valid: 4040.6739, took: 1852.7044s, (192.5853 / 100 batches)

2022-10-10 07:37:41,831 [INFO] 	Process 1 - batch 22099: mean_policy_losses: 4.151, mean_net_lifetime: 4583.7516, mean_mc_travel_dist: 1753.8894, mean_rewards: 222.6414, total_rewards: 2857.8461, mean_steps: 20.0700, mean_ecr: 0.0391 mean_entropies: 1.1121, took: 97.4769s
2022-10-10 07:38:00,050 [INFO] 	Process 5 - batch 26199: mean_policy_losses: -253.931, mean_net_lifetime: 4800.1252, mean_mc_travel_dist: 1690.2325, mean_rewards: 255.6232, total_rewards: 3174.9704, mean_steps: 18.0400, mean_ecr: 0.0294 mean_entropies: 1.1990, took: 92.7944s
2022-10-10 07:38:07,005 [INFO] 	Process 4 - batch 31299: mean_policy_losses: 329.728, mean_net_lifetime: 4164.1647, mean_mc_travel_dist: 1187.3523, mean_rewards: 267.4993, total_rewards: 3002.9770, mean_steps: 14.5700, mean_ecr: 0.0490 mean_entropies: 1.1023, took: 75.9837s
2022-10-10 07:38:25,430 [INFO] 	Process 7 - batch 26599: mean_policy_losses: -565.760, mean_net_lifetime: 3280.2675, mean_mc_travel_dist: 1152.4646, mean_rewards: 223.9990, total_rewards: 2171.1501, mean_steps: 13.7300, mean_ecr: 0.0423 mean_entropies: 1.4571, took: 70.1043s
2022-10-10 07:38:26,548 [INFO] 	Process 6 - batch 38099: mean_policy_losses: -346.479, mean_net_lifetime: 2953.9557, mean_mc_travel_dist: 792.6405, mean_rewards: 307.4883, total_rewards: 2191.7389, mean_steps: 8.5800, mean_ecr: 0.0557 mean_entropies: 0.4277, took: 49.6108s
2022-10-10 07:38:28,125 [INFO] 	Process 3 - batch 25899: mean_policy_losses: 74.388, mean_net_lifetime: 4066.1392, mean_mc_travel_dist: 1159.3539, mean_rewards: 240.9081, total_rewards: 2929.5603, mean_steps: 15.9600, mean_ecr: 0.0487 mean_entropies: 0.8652, took: 84.4045s
2022-10-10 07:39:12,556 [INFO] 	Process 2 - batch 25599: mean_policy_losses: 47.795, mean_net_lifetime: 4475.2675, mean_mc_travel_dist: 1422.4992, mean_rewards: 228.6868, total_rewards: 3082.9261, mean_steps: 18.8200, mean_ecr: 0.0402 mean_entropies: 0.9017, took: 655.9956s
2022-10-10 07:39:19,199 [INFO] 	Process 6 - batch 38199: mean_policy_losses: -305.738, mean_net_lifetime: 3094.9104, mean_mc_travel_dist: 827.7537, mean_rewards: 309.1208, total_rewards: 2294.7278, mean_steps: 9.0700, mean_ecr: 0.0555 mean_entropies: 0.4297, took: 52.6516s
2022-10-10 07:39:19,939 [INFO] 	Process 1 - batch 22199: mean_policy_losses: 12.968, mean_net_lifetime: 4633.9417, mean_mc_travel_dist: 1801.4532, mean_rewards: 229.8553, total_rewards: 2859.6980, mean_steps: 19.5200, mean_ecr: 0.0389 mean_entropies: 1.0712, took: 98.1082s
2022-10-10 07:39:23,539 [INFO] 	Process 4 - batch 31399: mean_policy_losses: 234.910, mean_net_lifetime: 3886.5973, mean_mc_travel_dist: 1137.0272, mean_rewards: 253.2721, total_rewards: 2781.2444, mean_steps: 14.3500, mean_ecr: 0.0495 mean_entropies: 1.0825, took: 76.5334s
2022-10-10 07:39:26,505 [INFO] 	Process 5 - batch 26299: mean_policy_losses: -449.195, mean_net_lifetime: 4309.0763, mean_mc_travel_dist: 1477.2477, mean_rewards: 258.1183, total_rewards: 2883.8906, mean_steps: 16.2800, mean_ecr: 0.0300 mean_entropies: 1.1359, took: 86.4539s
2022-10-10 07:39:42,227 [INFO] 	Process 7 - batch 26699: mean_policy_losses: -440.360, mean_net_lifetime: 3563.9997, mean_mc_travel_dist: 1223.8037, mean_rewards: 220.6426, total_rewards: 2383.1128, mean_steps: 14.9800, mean_ecr: 0.0421 mean_entropies: 1.4561, took: 76.7973s
2022-10-10 07:39:57,477 [INFO] 	Process 3 - batch 25999: mean_policy_losses: 58.716, mean_net_lifetime: 4062.1269, mean_mc_travel_dist: 1131.2701, mean_rewards: 233.0067, total_rewards: 2951.4526, mean_steps: 16.5400, mean_ecr: 0.0489 mean_entropies: 0.8431, took: 89.3522s
2022-10-10 07:40:05,814 [INFO] 	Process 6 - batch 38299: mean_policy_losses: -351.796, mean_net_lifetime: 2762.3685, mean_mc_travel_dist: 744.8591, mean_rewards: 302.9365, total_rewards: 2052.5878, mean_steps: 8.0500, mean_ecr: 0.0562 mean_entropies: 0.4029, took: 46.6148s
2022-10-10 07:40:39,195 [INFO] 	Process 4 - batch 31499: mean_policy_losses: 253.194, mean_net_lifetime: 3838.4882, mean_mc_travel_dist: 1100.9663, mean_rewards: 254.6747, total_rewards: 2775.6374, mean_steps: 14.1000, mean_ecr: 0.0496 mean_entropies: 1.1543, took: 75.6562s
2022-10-10 07:40:47,268 [INFO] 	Process 2 - batch 25699: mean_policy_losses: 61.826, mean_net_lifetime: 4582.7829, mean_mc_travel_dist: 1451.4979, mean_rewards: 233.5400, total_rewards: 3159.0166, mean_steps: 18.8400, mean_ecr: 0.0401 mean_entropies: 0.9069, took: 94.7121s
2022-10-10 07:40:48,029 [INFO] 	Process 6 - batch 38399: mean_policy_losses: -438.530, mean_net_lifetime: 2267.1551, mean_mc_travel_dist: 629.0430, mean_rewards: 290.0165, total_rewards: 1691.2815, mean_steps: 6.7500, mean_ecr: 0.0564 mean_entropies: 0.4422, took: 42.2148s
2022-10-10 07:40:56,252 [INFO] 	Process 5 - batch 26399: mean_policy_losses: -331.421, mean_net_lifetime: 4654.0524, mean_mc_travel_dist: 1607.5951, mean_rewards: 265.9422, total_rewards: 3104.9437, mean_steps: 17.0600, mean_ecr: 0.0301 mean_entropies: 1.1632, took: 89.7484s
2022-10-10 07:41:06,330 [INFO] 	Process 1 - batch 22299: mean_policy_losses: -2.001, mean_net_lifetime: 4646.7952, mean_mc_travel_dist: 1791.9242, mean_rewards: 212.2931, total_rewards: 2890.8061, mean_steps: 21.4200, mean_ecr: 0.0389 mean_entropies: 1.0316, took: 106.3914s
2022-10-10 07:41:13,508 [INFO] 	Process 7 - batch 26799: mean_policy_losses: -203.309, mean_net_lifetime: 4131.6459, mean_mc_travel_dist: 1356.8208, mean_rewards: 212.4196, total_rewards: 2819.8009, mean_steps: 18.5100, mean_ecr: 0.0416 mean_entropies: 1.5056, took: 91.2810s
2022-10-10 07:41:24,606 [INFO] 	Process 3 - batch 26099: mean_policy_losses: 145.926, mean_net_lifetime: 4250.1676, mean_mc_travel_dist: 1169.9352, mean_rewards: 245.9385, total_rewards: 3102.0694, mean_steps: 16.3700, mean_ecr: 0.0486 mean_entropies: 0.8702, took: 87.1292s
2022-10-10 07:41:28,368 [INFO] 	Process 6 - batch 38499: mean_policy_losses: -456.977, mean_net_lifetime: 2206.2892, mean_mc_travel_dist: 617.7580, mean_rewards: 294.7852, total_rewards: 1631.9707, mean_steps: 6.4600, mean_ecr: 0.0568 mean_entropies: 0.4317, took: 40.3388s
2022-10-10 07:42:17,346 [INFO] 	Process 6 - batch 38599: mean_policy_losses: -306.837, mean_net_lifetime: 2822.7908, mean_mc_travel_dist: 763.6423, mean_rewards: 309.5875, total_rewards: 2092.1711, mean_steps: 8.1200, mean_ecr: 0.0561 mean_entropies: 0.4380, took: 48.9776s
2022-10-10 07:42:22,289 [INFO] 	Process 2 - batch 25799: mean_policy_losses: 88.444, mean_net_lifetime: 4655.5011, mean_mc_travel_dist: 1501.9883, mean_rewards: 242.2628, total_rewards: 3179.4696, mean_steps: 18.3700, mean_ecr: 0.0398 mean_entropies: 0.9489, took: 95.0209s
2022-10-10 07:42:26,241 [INFO] 	Process 7 - batch 26899: mean_policy_losses: -622.039, mean_net_lifetime: 2708.0321, mean_mc_travel_dist: 990.9478, mean_rewards: 182.9952, total_rewards: 1758.4089, mean_steps: 13.7000, mean_ecr: 0.0426 mean_entropies: 1.1474, took: 72.7334s
2022-10-10 07:42:30,965 [INFO] 	Process 5 - batch 26499: mean_policy_losses: -273.211, mean_net_lifetime: 4705.0012, mean_mc_travel_dist: 1595.0898, mean_rewards: 248.6465, total_rewards: 3168.9202, mean_steps: 18.0700, mean_ecr: 0.0312 mean_entropies: 1.0232, took: 94.7128s
2022-10-10 07:42:49,701 [INFO] 	Process 3 - batch 26199: mean_policy_losses: 83.539, mean_net_lifetime: 4012.1720, mean_mc_travel_dist: 1120.1584, mean_rewards: 243.9780, total_rewards: 2916.2500, mean_steps: 15.5500, mean_ecr: 0.0489 mean_entropies: 0.8678, took: 85.0942s
2022-10-10 07:42:55,242 [INFO] 	Process 1 - batch 22399: mean_policy_losses: 96.993, mean_net_lifetime: 4672.8079, mean_mc_travel_dist: 1748.8196, mean_rewards: 214.8672, total_rewards: 2955.5098, mean_steps: 21.2900, mean_ecr: 0.0390 mean_entropies: 1.0970, took: 108.9125s
2022-10-10 07:43:09,464 [INFO] 	Process 6 - batch 38699: mean_policy_losses: -334.952, mean_net_lifetime: 2909.8548, mean_mc_travel_dist: 786.4524, mean_rewards: 309.4130, total_rewards: 2159.2238, mean_steps: 8.3900, mean_ecr: 0.0558 mean_entropies: 0.4492, took: 52.1186s
2022-10-10 07:43:49,230 [INFO] 	Process 7 - batch 26999: mean_policy_losses: -476.634, mean_net_lifetime: 3045.3050, mean_mc_travel_dist: 1051.1892, mean_rewards: 189.2707, total_rewards: 2025.3147, mean_steps: 15.0100, mean_ecr: 0.0425 mean_entropies: 1.1764, took: 82.9888s
2022-10-10 07:44:02,926 [INFO] 	Process 2 - batch 25899: mean_policy_losses: 37.441, mean_net_lifetime: 4672.9489, mean_mc_travel_dist: 1537.5808, mean_rewards: 236.9801, total_rewards: 3163.3644, mean_steps: 18.8500, mean_ecr: 0.0397 mean_entropies: 0.9270, took: 100.6364s
2022-10-10 07:44:03,901 [INFO] 	Process 6 - batch 38799: mean_policy_losses: -264.957, mean_net_lifetime: 3090.7544, mean_mc_travel_dist: 823.4008, mean_rewards: 306.4999, total_rewards: 2308.0680, mean_steps: 9.0300, mean_ecr: 0.0557 mean_entropies: 0.3903, took: 54.4370s
2022-10-10 07:44:10,879 [INFO] 	Process 5 - batch 26599: mean_policy_losses: -220.535, mean_net_lifetime: 4832.0489, mean_mc_travel_dist: 1687.6770, mean_rewards: 245.8367, total_rewards: 3204.2584, mean_steps: 18.8300, mean_ecr: 0.0314 mean_entropies: 0.9945, took: 99.9132s
2022-10-10 07:44:23,382 [INFO] 	Process 3 - batch 26299: mean_policy_losses: 31.631, mean_net_lifetime: 3907.1388, mean_mc_travel_dist: 1068.3222, mean_rewards: 216.4595, total_rewards: 2864.2579, mean_steps: 17.2000, mean_ecr: 0.0491 mean_entropies: 0.8309, took: 93.6812s
2022-10-10 07:44:41,006 [INFO] 	Process 1 - batch 22499: mean_policy_losses: 88.245, mean_net_lifetime: 4790.7734, mean_mc_travel_dist: 1795.7550, mean_rewards: 228.5779, total_rewards: 3021.7157, mean_steps: 20.5600, mean_ecr: 0.0388 mean_entropies: 1.0686, took: 105.7624s
2022-10-10 07:44:55,186 [INFO] 	Process 6 - batch 38899: mean_policy_losses: -252.346, mean_net_lifetime: 3080.5727, mean_mc_travel_dist: 838.2890, mean_rewards: 308.5597, total_rewards: 2285.2775, mean_steps: 8.9700, mean_ecr: 0.0556 mean_entropies: 0.4367, took: 51.2843s
2022-10-10 07:45:41,637 [INFO] 	Process 2 - batch 25999: mean_policy_losses: 45.020, mean_net_lifetime: 4630.8578, mean_mc_travel_dist: 1501.7023, mean_rewards: 232.2238, total_rewards: 3162.8451, mean_steps: 19.1500, mean_ecr: 0.0398 mean_entropies: 0.9138, took: 98.7120s
2022-10-10 07:45:43,441 [INFO] 	Process 6 - batch 38999: mean_policy_losses: -369.552, mean_net_lifetime: 2909.6679, mean_mc_travel_dist: 785.0185, mean_rewards: 309.1514, total_rewards: 2158.4645, mean_steps: 8.4300, mean_ecr: 0.0554 mean_entropies: 0.3873, took: 48.2558s
2022-10-10 07:45:45,179 [INFO] 	Process 5 - batch 26699: mean_policy_losses: -217.159, mean_net_lifetime: 4814.8604, mean_mc_travel_dist: 1673.6123, mean_rewards: 242.7431, total_rewards: 3197.9022, mean_steps: 18.9400, mean_ecr: 0.0313 mean_entropies: 0.9904, took: 94.3001s
2022-10-10 07:45:50,907 [INFO] 	Process 3 - batch 26399: mean_policy_losses: 64.763, mean_net_lifetime: 4056.4801, mean_mc_travel_dist: 1099.1365, mean_rewards: 224.2910, total_rewards: 2975.6496, mean_steps: 17.2200, mean_ecr: 0.0491 mean_entropies: 0.8285, took: 87.5252s
2022-10-10 07:47:10,334 [INFO] 	Process 2 - batch 26099: mean_policy_losses: 12.965, mean_net_lifetime: 4697.9622, mean_mc_travel_dist: 1601.1907, mean_rewards: 246.4708, total_rewards: 3134.8508, mean_steps: 18.2300, mean_ecr: 0.0395 mean_entropies: 0.9428, took: 88.6964s
2022-10-10 07:47:11,420 [INFO] 	Process 3 - batch 26499: mean_policy_losses: 101.571, mean_net_lifetime: 4284.8515, mean_mc_travel_dist: 1210.0674, mean_rewards: 248.2923, total_rewards: 3100.9456, mean_steps: 16.3800, mean_ecr: 0.0483 mean_entropies: 0.8840, took: 80.5133s
2022-10-10 07:47:17,505 [INFO] 	Process 5 - batch 26799: mean_policy_losses: -212.602, mean_net_lifetime: 5087.1965, mean_mc_travel_dist: 1751.9642, mean_rewards: 247.8009, total_rewards: 3382.7015, mean_steps: 19.7400, mean_ecr: 0.0313 mean_entropies: 1.0861, took: 92.3258s
2022-10-10 07:48:31,786 [INFO] 	Process 3 - batch 26599: mean_policy_losses: 127.672, mean_net_lifetime: 4409.8984, mean_mc_travel_dist: 1258.4951, mean_rewards: 257.6941, total_rewards: 3180.7969, mean_steps: 16.2100, mean_ecr: 0.0478 mean_entropies: 0.9084, took: 80.3650s
2022-10-10 07:48:34,337 [INFO] 	Process 2 - batch 26199: mean_policy_losses: 23.361, mean_net_lifetime: 4655.8844, mean_mc_travel_dist: 1566.2396, mean_rewards: 253.8120, total_rewards: 3118.2359, mean_steps: 17.4700, mean_ecr: 0.0396 mean_entropies: 0.9783, took: 84.0020s
2022-10-10 07:48:52,655 [INFO] 	Process 5 - batch 26899: mean_policy_losses: -226.086, mean_net_lifetime: 5194.3746, mean_mc_travel_dist: 1801.7432, mean_rewards: 246.3327, total_rewards: 3432.3191, mean_steps: 20.3300, mean_ecr: 0.0309 mean_entropies: 1.0524, took: 95.1509s
2022-10-10 07:49:54,722 [INFO] 	Process 3 - batch 26699: mean_policy_losses: 85.091, mean_net_lifetime: 4513.0366, mean_mc_travel_dist: 1309.4485, mean_rewards: 256.4542, total_rewards: 3239.8923, mean_steps: 16.7400, mean_ecr: 0.0476 mean_entropies: 0.9124, took: 82.9369s
2022-10-10 07:49:59,590 [INFO] 	Process 2 - batch 26299: mean_policy_losses: -6.686, mean_net_lifetime: 4693.3283, mean_mc_travel_dist: 1553.2465, mean_rewards: 241.1914, total_rewards: 3166.5723, mean_steps: 18.5900, mean_ecr: 0.0396 mean_entropies: 1.0231, took: 85.2541s
2022-10-10 07:50:25,924 [INFO] 	Process 5 - batch 26999: mean_policy_losses: -267.073, mean_net_lifetime: 5245.7279, mean_mc_travel_dist: 1804.7658, mean_rewards: 257.9855, total_rewards: 3490.2533, mean_steps: 19.4700, mean_ecr: 0.0311 mean_entropies: 1.1048, took: 93.2672s
2022-10-10 07:50:56,040 [INFO] Process 4 - epoch 21: mean_policy_losses: 38.932, mean_net_lifetime: 3209.2714, mean_mc_travel_dist: 1275.9044, mean_entropies: 1.7354, m_net_lifetime_valid: 4315.4474, took: 1745.1604s, (158.3680 / 100 batches)

2022-10-10 07:51:13,618 [INFO] 	Process 3 - batch 26799: mean_policy_losses: 25.407, mean_net_lifetime: 4304.8460, mean_mc_travel_dist: 1225.9443, mean_rewards: 250.4160, total_rewards: 3117.7238, mean_steps: 16.2800, mean_ecr: 0.0483 mean_entropies: 0.8703, took: 78.8966s
2022-10-10 07:51:17,477 [INFO] 	Process 2 - batch 26399: mean_policy_losses: -41.600, mean_net_lifetime: 4619.7642, mean_mc_travel_dist: 1510.1303, mean_rewards: 251.3932, total_rewards: 3141.2740, mean_steps: 17.4800, mean_ecr: 0.0397 mean_entropies: 0.9310, took: 77.8866s
2022-10-10 07:52:03,436 [INFO] 	Process 4 - batch 31599: mean_policy_losses: 126.310, mean_net_lifetime: 3543.9355, mean_mc_travel_dist: 1047.4742, mean_rewards: 236.0879, total_rewards: 2527.2530, mean_steps: 14.0000, mean_ecr: 0.0500 mean_entropies: 1.1978, took: 684.2409s
2022-10-10 07:52:34,688 [INFO] 	Process 3 - batch 26899: mean_policy_losses: -28.931, mean_net_lifetime: 4287.3414, mean_mc_travel_dist: 1194.4809, mean_rewards: 251.4895, total_rewards: 3123.3594, mean_steps: 16.1400, mean_ecr: 0.0486 mean_entropies: 0.8403, took: 81.0693s
2022-10-10 07:52:41,787 [INFO] 	Process 2 - batch 26499: mean_policy_losses: -109.484, mean_net_lifetime: 4502.0907, mean_mc_travel_dist: 1456.6235, mean_rewards: 230.6625, total_rewards: 3068.9779, mean_steps: 18.7500, mean_ecr: 0.0401 mean_entropies: 0.8496, took: 84.3101s
2022-10-10 07:53:18,073 [INFO] 	Process 4 - batch 31699: mean_policy_losses: 310.676, mean_net_lifetime: 4475.9890, mean_mc_travel_dist: 1268.6778, mean_rewards: 271.0464, total_rewards: 3233.9862, mean_steps: 15.5500, mean_ecr: 0.0482 mean_entropies: 1.0891, took: 74.6368s
2022-10-10 07:53:57,032 [INFO] 	Process 3 - batch 26999: mean_policy_losses: -35.908, mean_net_lifetime: 4396.4528, mean_mc_travel_dist: 1227.0991, mean_rewards: 253.2233, total_rewards: 3193.3364, mean_steps: 16.4700, mean_ecr: 0.0482 mean_entropies: 0.8491, took: 82.3433s
2022-10-10 07:54:05,415 [INFO] 	Process 2 - batch 26599: mean_policy_losses: -133.708, mean_net_lifetime: 4483.1332, mean_mc_travel_dist: 1449.4066, mean_rewards: 227.7166, total_rewards: 3053.5876, mean_steps: 18.9200, mean_ecr: 0.0402 mean_entropies: 0.8536, took: 83.6280s
2022-10-10 07:54:28,279 [INFO] 	Process 4 - batch 31799: mean_policy_losses: 250.916, mean_net_lifetime: 4346.7519, mean_mc_travel_dist: 1229.0416, mean_rewards: 274.7032, total_rewards: 3155.4167, mean_steps: 14.8400, mean_ecr: 0.0487 mean_entropies: 1.1242, took: 70.2064s
2022-10-10 07:54:31,667 [INFO] Process 7 - epoch 18: mean_policy_losses: -69.217, mean_net_lifetime: 3856.4731, mean_mc_travel_dist: 1745.2605, mean_entropies: 2.0249, m_net_lifetime_valid: 3905.2992, took: 1897.4966s, (185.3667 / 100 batches)

2022-10-10 07:55:20,645 [INFO] Process 1 - epoch 15: mean_policy_losses: 71.798, mean_net_lifetime: 4593.2979, mean_mc_travel_dist: 2263.7931, mean_entropies: 1.6452, m_net_lifetime_valid: 4089.5239, took: 2164.8004s, (222.5053 / 100 batches)

2022-10-10 07:55:27,019 [INFO] 	Process 2 - batch 26699: mean_policy_losses: -106.126, mean_net_lifetime: 4411.2295, mean_mc_travel_dist: 1406.7205, mean_rewards: 234.7222, total_rewards: 3031.0986, mean_steps: 18.2100, mean_ecr: 0.0404 mean_entropies: 0.8191, took: 81.6041s
2022-10-10 07:55:45,058 [INFO] 	Process 4 - batch 31899: mean_policy_losses: 298.440, mean_net_lifetime: 4652.2256, mean_mc_travel_dist: 1318.3163, mean_rewards: 276.7035, total_rewards: 3353.1231, mean_steps: 15.9100, mean_ecr: 0.0476 mean_entropies: 1.0566, took: 76.7792s
2022-10-10 07:55:54,657 [INFO] 	Process 7 - batch 27099: mean_policy_losses: -389.823, mean_net_lifetime: 4327.5084, mean_mc_travel_dist: 1463.4026, mean_rewards: 225.5491, total_rewards: 2907.4242, mean_steps: 18.3000, mean_ecr: 0.0414 mean_entropies: 1.5832, took: 725.4270s
2022-10-10 07:56:42,953 [INFO] Process 6 - epoch 26: mean_policy_losses: -279.361, mean_net_lifetime: 2297.1343, mean_mc_travel_dist: 993.2370, mean_entropies: 1.1848, m_net_lifetime_valid: 3974.1416, took: 1360.1357s, (128.7677 / 100 batches)

2022-10-10 07:56:55,287 [INFO] 	Process 2 - batch 26799: mean_policy_losses: -58.817, mean_net_lifetime: 4445.2220, mean_mc_travel_dist: 1409.6597, mean_rewards: 229.4739, total_rewards: 3061.2441, mean_steps: 18.5700, mean_ecr: 0.0403 mean_entropies: 0.8461, took: 88.2687s
2022-10-10 07:56:59,285 [INFO] 	Process 1 - batch 22599: mean_policy_losses: -82.492, mean_net_lifetime: 4566.3227, mean_mc_travel_dist: 1809.1091, mean_rewards: 221.3297, total_rewards: 2792.4461, mean_steps: 19.9700, mean_ecr: 0.0390 mean_entropies: 1.0199, took: 738.2791s
2022-10-10 07:57:04,309 [INFO] 	Process 4 - batch 31999: mean_policy_losses: 386.481, mean_net_lifetime: 4691.5673, mean_mc_travel_dist: 1342.4365, mean_rewards: 277.3232, total_rewards: 3374.2808, mean_steps: 15.9700, mean_ecr: 0.0476 mean_entropies: 1.0358, took: 79.2510s
2022-10-10 07:57:10,497 [INFO] 	Process 7 - batch 27199: mean_policy_losses: -506.911, mean_net_lifetime: 3917.7930, mean_mc_travel_dist: 1341.5757, mean_rewards: 233.1962, total_rewards: 2619.4959, mean_steps: 16.0200, mean_ecr: 0.0416 mean_entropies: 1.5318, took: 75.8394s
2022-10-10 07:57:31,207 [INFO] 	Process 6 - batch 39099: mean_policy_losses: -487.609, mean_net_lifetime: 2754.0477, mean_mc_travel_dist: 746.7139, mean_rewards: 313.7289, total_rewards: 2031.1292, mean_steps: 7.8400, mean_ecr: 0.0560 mean_entropies: 0.3936, took: 707.7653s
2022-10-10 07:58:18,296 [INFO] 	Process 6 - batch 39199: mean_policy_losses: -326.505, mean_net_lifetime: 2610.5414, mean_mc_travel_dist: 725.2959, mean_rewards: 308.4285, total_rewards: 1927.5364, mean_steps: 7.4600, mean_ecr: 0.0563 mean_entropies: 0.4290, took: 47.0894s
2022-10-10 07:58:20,949 [INFO] 	Process 2 - batch 26899: mean_policy_losses: -5.141, mean_net_lifetime: 4325.5637, mean_mc_travel_dist: 1418.0238, mean_rewards: 238.1946, total_rewards: 2940.8010, mean_steps: 17.4100, mean_ecr: 0.0402 mean_entropies: 0.8272, took: 85.6620s
2022-10-10 07:58:22,379 [INFO] 	Process 7 - batch 27299: mean_policy_losses: -474.780, mean_net_lifetime: 3603.3098, mean_mc_travel_dist: 1281.2619, mean_rewards: 232.1971, total_rewards: 2371.1293, mean_steps: 14.6200, mean_ecr: 0.0418 mean_entropies: 1.5388, took: 71.8825s
2022-10-10 07:58:26,321 [INFO] 	Process 4 - batch 32099: mean_policy_losses: 424.368, mean_net_lifetime: 4620.2729, mean_mc_travel_dist: 1351.5547, mean_rewards: 271.5287, total_rewards: 3299.7320, mean_steps: 16.1500, mean_ecr: 0.0476 mean_entropies: 1.0382, took: 82.0121s
2022-10-10 07:58:41,632 [INFO] 	Process 1 - batch 22699: mean_policy_losses: -4.371, mean_net_lifetime: 4528.5653, mean_mc_travel_dist: 1819.0033, mean_rewards: 222.4996, total_rewards: 2732.9034, mean_steps: 19.8400, mean_ecr: 0.0388 mean_entropies: 0.9529, took: 102.3470s
2022-10-10 07:59:00,870 [INFO] 	Process 6 - batch 39299: mean_policy_losses: -364.507, mean_net_lifetime: 2445.6219, mean_mc_travel_dist: 671.7798, mean_rewards: 301.8343, total_rewards: 1816.2203, mean_steps: 7.0300, mean_ecr: 0.0568 mean_entropies: 0.4474, took: 42.5734s
2022-10-10 07:59:39,648 [INFO] 	Process 6 - batch 39399: mean_policy_losses: -480.538, mean_net_lifetime: 2403.4049, mean_mc_travel_dist: 654.3849, mean_rewards: 304.6658, total_rewards: 1783.1403, mean_steps: 6.8100, mean_ecr: 0.0563 mean_entropies: 0.4231, took: 38.7786s
2022-10-10 07:59:44,708 [INFO] 	Process 7 - batch 27399: mean_policy_losses: -310.347, mean_net_lifetime: 4187.4573, mean_mc_travel_dist: 1408.3664, mean_rewards: 231.8932, total_rewards: 2814.3259, mean_steps: 17.5000, mean_ecr: 0.0416 mean_entropies: 1.5665, took: 82.3285s
2022-10-10 07:59:45,880 [INFO] 	Process 4 - batch 32199: mean_policy_losses: 417.041, mean_net_lifetime: 4636.8563, mean_mc_travel_dist: 1292.7060, mean_rewards: 277.0929, total_rewards: 3367.7835, mean_steps: 15.8100, mean_ecr: 0.0477 mean_entropies: 1.0519, took: 79.5590s
2022-10-10 07:59:49,632 [INFO] 	Process 2 - batch 26999: mean_policy_losses: 29.214, mean_net_lifetime: 4492.5735, mean_mc_travel_dist: 1425.8394, mean_rewards: 233.0270, total_rewards: 3093.9522, mean_steps: 18.6600, mean_ecr: 0.0403 mean_entropies: 0.8316, took: 88.6829s
2022-10-10 08:00:16,395 [INFO] Process 5 - epoch 18: mean_policy_losses: -107.373, mean_net_lifetime: 4332.3608, mean_mc_travel_dist: 2197.6270, mean_entropies: 1.9024, m_net_lifetime_valid: 4085.4303, took: 1971.6372s, (186.8306 / 100 batches)

2022-10-10 08:00:26,218 [INFO] 	Process 6 - batch 39499: mean_policy_losses: -256.038, mean_net_lifetime: 2954.6387, mean_mc_travel_dist: 794.2575, mean_rewards: 311.1099, total_rewards: 2190.7566, mean_steps: 8.5300, mean_ecr: 0.0559 mean_entropies: 0.4016, took: 46.5696s
2022-10-10 08:00:30,724 [INFO] 	Process 1 - batch 22799: mean_policy_losses: 4.612, mean_net_lifetime: 4583.0024, mean_mc_travel_dist: 1720.1922, mean_rewards: 199.0024, total_rewards: 2894.9873, mean_steps: 22.6600, mean_ecr: 0.0393 mean_entropies: 1.0517, took: 109.0929s
2022-10-10 08:01:00,402 [INFO] 	Process 4 - batch 32299: mean_policy_losses: 335.388, mean_net_lifetime: 4389.7414, mean_mc_travel_dist: 1242.1369, mean_rewards: 275.4482, total_rewards: 3169.9714, mean_steps: 15.0100, mean_ecr: 0.0483 mean_entropies: 1.0423, took: 74.5225s
2022-10-10 08:01:04,843 [INFO] 	Process 7 - batch 27499: mean_policy_losses: -324.214, mean_net_lifetime: 4147.6630, mean_mc_travel_dist: 1395.0413, mean_rewards: 234.7301, total_rewards: 2788.3714, mean_steps: 16.8800, mean_ecr: 0.0416 mean_entropies: 1.5638, took: 80.1352s
2022-10-10 08:01:16,726 [INFO] 	Process 6 - batch 39599: mean_policy_losses: -338.819, mean_net_lifetime: 3140.8193, mean_mc_travel_dist: 837.6103, mean_rewards: 312.7732, total_rewards: 2340.1494, mean_steps: 9.0800, mean_ecr: 0.0554 mean_entropies: 0.3997, took: 50.5090s
2022-10-10 08:01:41,280 [INFO] 	Process 5 - batch 27099: mean_policy_losses: -438.809, mean_net_lifetime: 4539.5636, mean_mc_travel_dist: 1570.8772, mean_rewards: 268.0059, total_rewards: 3018.7488, mean_steps: 17.0500, mean_ecr: 0.0292 mean_entropies: 1.0879, took: 675.3564s
2022-10-10 08:02:01,457 [INFO] 	Process 6 - batch 39699: mean_policy_losses: -339.227, mean_net_lifetime: 2788.7513, mean_mc_travel_dist: 755.9739, mean_rewards: 308.6885, total_rewards: 2067.1734, mean_steps: 8.0100, mean_ecr: 0.0560 mean_entropies: 0.3630, took: 44.7301s
2022-10-10 08:02:11,126 [INFO] 	Process 1 - batch 22899: mean_policy_losses: 4.762, mean_net_lifetime: 4641.0473, mean_mc_travel_dist: 1750.6907, mean_rewards: 213.9627, total_rewards: 2925.8265, mean_steps: 21.1300, mean_ecr: 0.0390 mean_entropies: 1.0617, took: 100.4016s
2022-10-10 08:02:13,878 [INFO] 	Process 4 - batch 32399: mean_policy_losses: 313.981, mean_net_lifetime: 4141.7180, mean_mc_travel_dist: 1169.5425, mean_rewards: 270.2889, total_rewards: 2996.6670, mean_steps: 14.3400, mean_ecr: 0.0488 mean_entropies: 1.0595, took: 73.4755s
2022-10-10 08:02:33,740 [INFO] 	Process 7 - batch 27599: mean_policy_losses: -134.816, mean_net_lifetime: 4609.6467, mean_mc_travel_dist: 1514.8590, mean_rewards: 231.6621, total_rewards: 3132.2694, mean_steps: 19.1500, mean_ecr: 0.0412 mean_entropies: 1.5337, took: 88.8976s
2022-10-10 08:02:52,741 [INFO] 	Process 6 - batch 39799: mean_policy_losses: -279.369, mean_net_lifetime: 3066.9163, mean_mc_travel_dist: 818.6521, mean_rewards: 309.8947, total_rewards: 2279.3973, mean_steps: 8.8900, mean_ecr: 0.0557 mean_entropies: 0.3795, took: 51.2846s
2022-10-10 08:03:02,424 [INFO] 	Process 5 - batch 27199: mean_policy_losses: -465.063, mean_net_lifetime: 4374.0002, mean_mc_travel_dist: 1531.2281, mean_rewards: 265.5735, total_rewards: 2909.4873, mean_steps: 16.2500, mean_ecr: 0.0292 mean_entropies: 1.0957, took: 81.1438s
2022-10-10 08:03:24,674 [INFO] 	Process 4 - batch 32499: mean_policy_losses: 306.879, mean_net_lifetime: 4128.6007, mean_mc_travel_dist: 1151.3252, mean_rewards: 272.6372, total_rewards: 3008.6048, mean_steps: 14.2000, mean_ecr: 0.0488 mean_entropies: 1.0833, took: 70.7952s
2022-10-10 08:03:36,249 [INFO] 	Process 6 - batch 39899: mean_policy_losses: -458.071, mean_net_lifetime: 2598.6823, mean_mc_travel_dist: 701.0057, mean_rewards: 311.1490, total_rewards: 1933.7534, mean_steps: 7.3500, mean_ecr: 0.0565 mean_entropies: 0.3884, took: 43.5070s
2022-10-10 08:03:51,490 [INFO] 	Process 1 - batch 22999: mean_policy_losses: -9.537, mean_net_lifetime: 4684.7464, mean_mc_travel_dist: 1771.6074, mean_rewards: 215.7164, total_rewards: 2940.8040, mean_steps: 21.0700, mean_ecr: 0.0390 mean_entropies: 1.0766, took: 100.3642s
2022-10-10 08:04:00,392 [INFO] 	Process 7 - batch 27699: mean_policy_losses: -221.353, mean_net_lifetime: 4413.8610, mean_mc_travel_dist: 1468.7093, mean_rewards: 229.0118, total_rewards: 2993.0065, mean_steps: 18.4800, mean_ecr: 0.0415 mean_entropies: 1.5549, took: 86.6518s
2022-10-10 08:04:29,747 [INFO] 	Process 6 - batch 39999: mean_policy_losses: -300.921, mean_net_lifetime: 3362.6580, mean_mc_travel_dist: 900.9726, mean_rewards: 313.9615, total_rewards: 2497.3636, mean_steps: 9.8100, mean_ecr: 0.0551 mean_entropies: 0.3838, took: 53.4995s
2022-10-10 08:04:30,376 [INFO] 	Process 5 - batch 27299: mean_policy_losses: -419.047, mean_net_lifetime: 4679.0657, mean_mc_travel_dist: 1643.7702, mean_rewards: 259.4635, total_rewards: 3093.1672, mean_steps: 17.6900, mean_ecr: 0.0292 mean_entropies: 1.0920, took: 87.9529s
2022-10-10 08:04:33,660 [INFO] Process 3 - epoch 18: mean_policy_losses: 135.518, mean_net_lifetime: 3911.7363, mean_mc_travel_dist: 1557.1993, mean_entropies: 1.4782, m_net_lifetime_valid: 3975.2902, took: 1906.7662s, (187.6072 / 100 batches)

2022-10-10 08:04:37,406 [INFO] 	Process 4 - batch 32599: mean_policy_losses: 289.540, mean_net_lifetime: 4290.9270, mean_mc_travel_dist: 1203.9276, mean_rewards: 275.5664, total_rewards: 3121.3737, mean_steps: 14.5600, mean_ecr: 0.0484 mean_entropies: 1.0334, took: 72.7325s
2022-10-10 08:05:17,311 [INFO] 	Process 6 - batch 40099: mean_policy_losses: -273.537, mean_net_lifetime: 2898.3677, mean_mc_travel_dist: 785.0867, mean_rewards: 303.4968, total_rewards: 2146.6818, mean_steps: 8.4900, mean_ecr: 0.0559 mean_entropies: 0.3367, took: 47.5640s
2022-10-10 08:05:38,787 [INFO] 	Process 1 - batch 23099: mean_policy_losses: -12.373, mean_net_lifetime: 4620.1459, mean_mc_travel_dist: 1711.6070, mean_rewards: 198.5409, total_rewards: 2931.9233, mean_steps: 22.8400, mean_ecr: 0.0392 mean_entropies: 0.9913, took: 107.2969s
2022-10-10 08:05:39,291 [INFO] 	Process 7 - batch 27799: mean_policy_losses: -94.702, mean_net_lifetime: 4830.1422, mean_mc_travel_dist: 1593.8263, mean_rewards: 224.5230, total_rewards: 3273.2648, mean_steps: 20.7000, mean_ecr: 0.0410 mean_entropies: 1.5398, took: 98.8990s
2022-10-10 08:05:56,287 [INFO] 	Process 4 - batch 32699: mean_policy_losses: 328.600, mean_net_lifetime: 4367.1484, mean_mc_travel_dist: 1222.3624, mean_rewards: 270.6558, total_rewards: 3168.2980, mean_steps: 15.1500, mean_ecr: 0.0484 mean_entropies: 1.0604, took: 78.8805s
2022-10-10 08:06:02,200 [INFO] 	Process 3 - batch 27099: mean_policy_losses: 27.599, mean_net_lifetime: 4057.9387, mean_mc_travel_dist: 1109.3862, mean_rewards: 227.1808, total_rewards: 2969.6431, mean_steps: 17.0100, mean_ecr: 0.0491 mean_entropies: 0.7759, took: 725.1688s
2022-10-10 08:06:08,139 [INFO] 	Process 6 - batch 40199: mean_policy_losses: -348.564, mean_net_lifetime: 3015.0425, mean_mc_travel_dist: 806.2716, mean_rewards: 311.6619, total_rewards: 2238.7053, mean_steps: 8.6500, mean_ecr: 0.0558 mean_entropies: 0.3901, took: 50.8272s
2022-10-10 08:06:09,183 [INFO] 	Process 5 - batch 27399: mean_policy_losses: -220.392, mean_net_lifetime: 5063.4890, mean_mc_travel_dist: 1822.9294, mean_rewards: 254.8871, total_rewards: 3285.5709, mean_steps: 19.3400, mean_ecr: 0.0290 mean_entropies: 1.0690, took: 98.8076s
2022-10-10 08:06:47,728 [INFO] 	Process 6 - batch 40299: mean_policy_losses: -483.117, mean_net_lifetime: 2328.0775, mean_mc_travel_dist: 643.4232, mean_rewards: 302.6929, total_rewards: 1726.0659, mean_steps: 6.6300, mean_ecr: 0.0567 mean_entropies: 0.4623, took: 39.5886s
2022-10-10 08:07:11,469 [INFO] 	Process 7 - batch 27899: mean_policy_losses: -182.427, mean_net_lifetime: 4431.5567, mean_mc_travel_dist: 1477.0282, mean_rewards: 223.2656, total_rewards: 2992.4923, mean_steps: 19.1200, mean_ecr: 0.0416 mean_entropies: 1.5805, took: 92.1777s
2022-10-10 08:07:12,070 [INFO] 	Process 4 - batch 32799: mean_policy_losses: 270.645, mean_net_lifetime: 4029.2127, mean_mc_travel_dist: 1129.5836, mean_rewards: 259.0231, total_rewards: 2931.3947, mean_steps: 14.6600, mean_ecr: 0.0490 mean_entropies: 1.1444, took: 75.7833s
2022-10-10 08:07:25,061 [INFO] 	Process 1 - batch 23199: mean_policy_losses: -25.615, mean_net_lifetime: 4632.4413, mean_mc_travel_dist: 1751.2636, mean_rewards: 210.0922, total_rewards: 2916.7353, mean_steps: 21.5600, mean_ecr: 0.0391 mean_entropies: 1.0066, took: 106.2744s
2022-10-10 08:07:26,562 [INFO] 	Process 3 - batch 27199: mean_policy_losses: 78.998, mean_net_lifetime: 4296.2630, mean_mc_travel_dist: 1198.5462, mean_rewards: 250.4277, total_rewards: 3123.4308, mean_steps: 16.2600, mean_ecr: 0.0485 mean_entropies: 0.8011, took: 84.3626s
2022-10-10 08:07:36,246 [INFO] 	Process 6 - batch 40399: mean_policy_losses: -325.520, mean_net_lifetime: 2959.8598, mean_mc_travel_dist: 785.0158, mean_rewards: 315.7272, total_rewards: 2205.8291, mean_steps: 8.4100, mean_ecr: 0.0556 mean_entropies: 0.3858, took: 48.5191s
2022-10-10 08:07:44,299 [INFO] 	Process 5 - batch 27499: mean_policy_losses: -170.915, mean_net_lifetime: 5252.5720, mean_mc_travel_dist: 1876.2020, mean_rewards: 269.3046, total_rewards: 3425.6906, mean_steps: 19.0400, mean_ecr: 0.0293 mean_entropies: 1.0969, took: 95.1160s
2022-10-10 08:08:26,450 [INFO] 	Process 6 - batch 40499: mean_policy_losses: -262.136, mean_net_lifetime: 3099.8622, mean_mc_travel_dist: 834.2671, mean_rewards: 314.1917, total_rewards: 2297.4337, mean_steps: 8.9100, mean_ecr: 0.0557 mean_entropies: 0.4038, took: 50.2037s
2022-10-10 08:08:31,746 [INFO] 	Process 4 - batch 32899: mean_policy_losses: 355.767, mean_net_lifetime: 4496.6662, mean_mc_travel_dist: 1275.3087, mean_rewards: 274.1318, total_rewards: 3248.4592, mean_steps: 15.5200, mean_ecr: 0.0482 mean_entropies: 1.0612, took: 79.6756s
2022-10-10 08:08:46,776 [INFO] 	Process 7 - batch 27999: mean_policy_losses: -171.294, mean_net_lifetime: 4584.4532, mean_mc_travel_dist: 1524.6187, mean_rewards: 227.4663, total_rewards: 3098.9118, mean_steps: 19.4700, mean_ecr: 0.0413 mean_entropies: 1.5651, took: 95.3073s
2022-10-10 08:08:51,536 [INFO] 	Process 3 - batch 27299: mean_policy_losses: 81.301, mean_net_lifetime: 4388.6261, mean_mc_travel_dist: 1197.7974, mean_rewards: 248.9076, total_rewards: 3213.7767, mean_steps: 16.7300, mean_ecr: 0.0484 mean_entropies: 0.7653, took: 84.9735s
2022-10-10 08:09:08,292 [INFO] 	Process 1 - batch 23299: mean_policy_losses: -66.961, mean_net_lifetime: 4594.4938, mean_mc_travel_dist: 1772.4852, mean_rewards: 211.3588, total_rewards: 2841.7164, mean_steps: 21.2500, mean_ecr: 0.0389 mean_entropies: 0.9824, took: 103.2308s
2022-10-10 08:09:13,766 [INFO] 	Process 5 - batch 27599: mean_policy_losses: -342.772, mean_net_lifetime: 4717.3340, mean_mc_travel_dist: 1736.3081, mean_rewards: 259.6218, total_rewards: 3035.5717, mean_steps: 17.8900, mean_ecr: 0.0290 mean_entropies: 1.0758, took: 89.4666s
2022-10-10 08:09:50,479 [INFO] 	Process 4 - batch 32999: mean_policy_losses: 304.126, mean_net_lifetime: 4664.4264, mean_mc_travel_dist: 1325.3084, mean_rewards: 279.2967, total_rewards: 3369.8277, mean_steps: 15.8400, mean_ecr: 0.0480 mean_entropies: 1.0391, took: 78.7334s
2022-10-10 08:10:08,944 [INFO] 	Process 3 - batch 27399: mean_policy_losses: 33.307, mean_net_lifetime: 4300.6187, mean_mc_travel_dist: 1221.2237, mean_rewards: 259.4671, total_rewards: 3113.6846, mean_steps: 15.6400, mean_ecr: 0.0484 mean_entropies: 0.8381, took: 77.4084s
2022-10-10 08:10:11,127 [INFO] 	Process 7 - batch 28099: mean_policy_losses: -329.397, mean_net_lifetime: 4300.1249, mean_mc_travel_dist: 1489.8584, mean_rewards: 226.6543, total_rewards: 2856.9717, mean_steps: 18.2600, mean_ecr: 0.0414 mean_entropies: 1.6014, took: 84.3518s
2022-10-10 08:10:16,720 [INFO] Process 2 - epoch 18: mean_policy_losses: 18.780, mean_net_lifetime: 3940.6822, mean_mc_travel_dist: 1764.7038, mean_entropies: 1.5426, m_net_lifetime_valid: 4280.6575, took: 1959.0097s, (188.9111 / 100 batches)

2022-10-10 08:10:41,688 [INFO] 	Process 5 - batch 27699: mean_policy_losses: -370.031, mean_net_lifetime: 4892.0466, mean_mc_travel_dist: 1741.9396, mean_rewards: 270.4980, total_rewards: 3191.9521, mean_steps: 17.8900, mean_ecr: 0.0293 mean_entropies: 1.1341, took: 87.9217s
2022-10-10 08:10:45,713 [INFO] 	Process 1 - batch 23399: mean_policy_losses: -44.091, mean_net_lifetime: 4569.0161, mean_mc_travel_dist: 1678.7144, mean_rewards: 219.6390, total_rewards: 2913.7936, mean_steps: 20.2100, mean_ecr: 0.0394 mean_entropies: 1.1270, took: 97.4210s
2022-10-10 08:11:23,922 [INFO] 	Process 3 - batch 27499: mean_policy_losses: 36.685, mean_net_lifetime: 4327.1392, mean_mc_travel_dist: 1272.5316, mean_rewards: 274.2542, total_rewards: 3079.2729, mean_steps: 14.8500, mean_ecr: 0.0479 mean_entropies: 0.9107, took: 74.9775s
2022-10-10 08:11:25,165 [INFO] 	Process 7 - batch 28199: mean_policy_losses: -555.509, mean_net_lifetime: 3853.8264, mean_mc_travel_dist: 1327.1473, mean_rewards: 235.1472, total_rewards: 2568.4766, mean_steps: 15.5500, mean_ecr: 0.0418 mean_entropies: 1.6357, took: 74.0375s
2022-10-10 08:11:42,839 [INFO] 	Process 2 - batch 27099: mean_policy_losses: -1.914, mean_net_lifetime: 4710.4189, mean_mc_travel_dist: 1493.1768, mean_rewards: 247.6742, total_rewards: 3244.9118, mean_steps: 18.2100, mean_ecr: 0.0399 mean_entropies: 1.0135, took: 713.2072s
2022-10-10 08:12:16,894 [INFO] 	Process 5 - batch 27799: mean_policy_losses: -210.855, mean_net_lifetime: 5440.7321, mean_mc_travel_dist: 1876.8781, mean_rewards: 263.7386, total_rewards: 3605.5476, mean_steps: 19.7600, mean_ecr: 0.0306 mean_entropies: 1.2060, took: 95.2062s
2022-10-10 08:12:24,151 [INFO] 	Process 1 - batch 23499: mean_policy_losses: -61.956, mean_net_lifetime: 4853.7751, mean_mc_travel_dist: 1788.8775, mean_rewards: 231.8389, total_rewards: 3086.5573, mean_steps: 20.3200, mean_ecr: 0.0390 mean_entropies: 1.1497, took: 98.4375s
2022-10-10 08:12:40,351 [INFO] 	Process 3 - batch 27599: mean_policy_losses: 89.700, mean_net_lifetime: 4386.3952, mean_mc_travel_dist: 1295.6377, mean_rewards: 278.0065, total_rewards: 3126.8140, mean_steps: 14.8400, mean_ecr: 0.0477 mean_entropies: 0.9132, took: 76.4292s
2022-10-10 08:12:49,465 [INFO] 	Process 7 - batch 28299: mean_policy_losses: -302.247, mean_net_lifetime: 4101.9642, mean_mc_travel_dist: 1344.5984, mean_rewards: 218.1367, total_rewards: 2792.7165, mean_steps: 17.8900, mean_ecr: 0.0420 mean_entropies: 1.5422, took: 84.3003s
2022-10-10 08:13:07,835 [INFO] 	Process 2 - batch 27199: mean_policy_losses: 43.945, mean_net_lifetime: 4688.6794, mean_mc_travel_dist: 1554.4335, mean_rewards: 253.9176, total_rewards: 3159.2912, mean_steps: 17.6400, mean_ecr: 0.0396 mean_entropies: 0.9554, took: 84.9952s
2022-10-10 08:13:49,766 [INFO] 	Process 5 - batch 27899: mean_policy_losses: -303.950, mean_net_lifetime: 4981.0914, mean_mc_travel_dist: 1757.4865, mean_rewards: 257.5278, total_rewards: 3277.7240, mean_steps: 18.6400, mean_ecr: 0.0307 mean_entropies: 1.0213, took: 92.8717s
2022-10-10 08:14:00,214 [INFO] 	Process 3 - batch 27699: mean_policy_losses: 93.576, mean_net_lifetime: 4418.9844, mean_mc_travel_dist: 1224.2831, mean_rewards: 260.3351, total_rewards: 3216.3859, mean_steps: 16.0600, mean_ecr: 0.0483 mean_entropies: 0.8372, took: 79.8628s
2022-10-10 08:14:03,928 [INFO] 	Process 1 - batch 23599: mean_policy_losses: 5.815, mean_net_lifetime: 4702.5781, mean_mc_travel_dist: 1806.2746, mean_rewards: 218.9171, total_rewards: 2925.8999, mean_steps: 20.9800, mean_ecr: 0.0388 mean_entropies: 1.0037, took: 99.7781s
2022-10-10 08:14:11,207 [INFO] 	Process 7 - batch 28399: mean_policy_losses: -430.190, mean_net_lifetime: 3750.4546, mean_mc_travel_dist: 1208.6223, mean_rewards: 206.9527, total_rewards: 2586.4091, mean_steps: 17.2900, mean_ecr: 0.0420 mean_entropies: 1.3840, took: 81.7416s
2022-10-10 08:14:35,433 [INFO] 	Process 2 - batch 27299: mean_policy_losses: 30.317, mean_net_lifetime: 4718.7967, mean_mc_travel_dist: 1517.3734, mean_rewards: 245.2183, total_rewards: 3228.8415, mean_steps: 18.3900, mean_ecr: 0.0397 mean_entropies: 0.9454, took: 87.5988s
2022-10-10 08:15:23,722 [INFO] 	Process 3 - batch 27799: mean_policy_losses: 66.037, mean_net_lifetime: 4462.2689, mean_mc_travel_dist: 1234.8742, mean_rewards: 264.4065, total_rewards: 3252.1638, mean_steps: 15.9600, mean_ecr: 0.0482 mean_entropies: 0.8521, took: 83.5078s
2022-10-10 08:15:29,506 [INFO] 	Process 5 - batch 27999: mean_policy_losses: -250.338, mean_net_lifetime: 5402.5412, mean_mc_travel_dist: 1849.4550, mean_rewards: 256.0728, total_rewards: 3595.3188, mean_steps: 20.2000, mean_ecr: 0.0310 mean_entropies: 1.0505, took: 99.7404s
2022-10-10 08:15:48,265 [INFO] 	Process 7 - batch 28499: mean_policy_losses: -208.829, mean_net_lifetime: 4513.2383, mean_mc_travel_dist: 1422.0830, mean_rewards: 208.4190, total_rewards: 3131.9296, mean_steps: 20.7600, mean_ecr: 0.0416 mean_entropies: 1.4752, took: 97.0579s
2022-10-10 08:15:49,595 [INFO] 	Process 1 - batch 23699: mean_policy_losses: -45.061, mean_net_lifetime: 4635.3467, mean_mc_travel_dist: 1688.0019, mean_rewards: 207.4496, total_rewards: 2972.9878, mean_steps: 22.0600, mean_ecr: 0.0393 mean_entropies: 1.0918, took: 105.6651s
2022-10-10 08:16:02,691 [INFO] 	Process 2 - batch 27399: mean_policy_losses: 16.085, mean_net_lifetime: 4711.4908, mean_mc_travel_dist: 1492.8692, mean_rewards: 244.2799, total_rewards: 3239.8282, mean_steps: 18.4500, mean_ecr: 0.0398 mean_entropies: 0.9646, took: 87.2580s
2022-10-10 08:16:39,933 [INFO] 	Process 3 - batch 27899: mean_policy_losses: 59.954, mean_net_lifetime: 4364.9831, mean_mc_travel_dist: 1253.7228, mean_rewards: 267.8168, total_rewards: 3140.2892, mean_steps: 15.3700, mean_ecr: 0.0481 mean_entropies: 0.8936, took: 76.2118s
2022-10-10 08:17:01,414 [INFO] 	Process 5 - batch 28099: mean_policy_losses: -339.547, mean_net_lifetime: 5052.9882, mean_mc_travel_dist: 1743.3756, mean_rewards: 253.3245, total_rewards: 3366.2347, mean_steps: 19.3100, mean_ecr: 0.0309 mean_entropies: 1.0690, took: 91.9085s
2022-10-10 08:17:23,229 [INFO] 	Process 1 - batch 23799: mean_policy_losses: 20.253, mean_net_lifetime: 4913.8050, mean_mc_travel_dist: 1828.4188, mean_rewards: 233.7148, total_rewards: 3120.2661, mean_steps: 20.3200, mean_ecr: 0.0388 mean_entropies: 1.1200, took: 93.6348s
2022-10-10 08:17:27,348 [INFO] 	Process 2 - batch 27499: mean_policy_losses: 28.313, mean_net_lifetime: 4851.7405, mean_mc_travel_dist: 1589.3711, mean_rewards: 249.4666, total_rewards: 3288.9306, mean_steps: 18.6200, mean_ecr: 0.0395 mean_entropies: 1.0172, took: 84.6562s
2022-10-10 08:17:54,412 [INFO] 	Process 3 - batch 27999: mean_policy_losses: 95.171, mean_net_lifetime: 4548.3649, mean_mc_travel_dist: 1322.2081, mean_rewards: 280.8889, total_rewards: 3263.6578, mean_steps: 15.2500, mean_ecr: 0.0477 mean_entropies: 0.9400, took: 74.4777s
2022-10-10 08:18:17,257 [INFO] Process 6 - epoch 27: mean_policy_losses: -282.161, mean_net_lifetime: 2316.8140, mean_mc_travel_dist: 984.7485, mean_entropies: 1.1557, m_net_lifetime_valid: 3992.8303, took: 1294.3020s, (127.3674 / 100 batches)

2022-10-10 08:18:39,431 [INFO] 	Process 5 - batch 28199: mean_policy_losses: -156.085, mean_net_lifetime: 5566.3173, mean_mc_travel_dist: 1919.0568, mean_rewards: 257.9532, total_rewards: 3700.1784, mean_steps: 20.7000, mean_ecr: 0.0307 mean_entropies: 1.1166, took: 98.0163s
2022-10-10 08:18:50,796 [INFO] 	Process 2 - batch 27599: mean_policy_losses: 91.129, mean_net_lifetime: 4743.9310, mean_mc_travel_dist: 1535.1207, mean_rewards: 251.9625, total_rewards: 3236.4852, mean_steps: 18.0000, mean_ecr: 0.0396 mean_entropies: 1.0010, took: 83.4481s
2022-10-10 08:18:56,091 [INFO] 	Process 6 - batch 40599: mean_policy_losses: -461.123, mean_net_lifetime: 2343.4364, mean_mc_travel_dist: 636.8953, mean_rewards: 313.6941, total_rewards: 1734.7102, mean_steps: 6.5000, mean_ecr: 0.0562 mean_entropies: 0.5126, took: 629.6408s
2022-10-10 08:19:01,426 [INFO] 	Process 1 - batch 23899: mean_policy_losses: 51.082, mean_net_lifetime: 4801.5640, mean_mc_travel_dist: 1773.2640, mean_rewards: 223.0776, total_rewards: 3057.1967, mean_steps: 20.8000, mean_ecr: 0.0390 mean_entropies: 1.1584, took: 98.1978s
2022-10-10 08:19:05,162 [INFO] Process 4 - epoch 22: mean_policy_losses: 51.463, mean_net_lifetime: 3261.8077, mean_mc_travel_dist: 1274.1805, mean_entropies: 1.7054, m_net_lifetime_valid: 4082.4939, took: 1689.1208s, (156.4820 / 100 batches)

2022-10-10 08:19:12,810 [INFO] 	Process 3 - batch 28099: mean_policy_losses: 145.707, mean_net_lifetime: 4440.9309, mean_mc_travel_dist: 1259.7485, mean_rewards: 267.5187, total_rewards: 3211.8246, mean_steps: 15.6900, mean_ecr: 0.0482 mean_entropies: 0.8726, took: 78.3989s
2022-10-10 08:19:37,467 [INFO] 	Process 6 - batch 40699: mean_policy_losses: -476.568, mean_net_lifetime: 2484.3016, mean_mc_travel_dist: 679.7405, mean_rewards: 311.1473, total_rewards: 1842.3353, mean_steps: 7.0300, mean_ecr: 0.0562 mean_entropies: 0.4549, took: 41.3764s
2022-10-10 08:20:12,974 [INFO] 	Process 5 - batch 28299: mean_policy_losses: -282.398, mean_net_lifetime: 5031.7402, mean_mc_travel_dist: 1745.0928, mean_rewards: 256.3191, total_rewards: 3340.4376, mean_steps: 18.7600, mean_ecr: 0.0306 mean_entropies: 1.0633, took: 93.5436s
2022-10-10 08:20:17,476 [INFO] 	Process 6 - batch 40799: mean_policy_losses: -428.272, mean_net_lifetime: 2197.1780, mean_mc_travel_dist: 602.7583, mean_rewards: 289.9578, total_rewards: 1643.4386, mean_steps: 6.5000, mean_ecr: 0.0567 mean_entropies: 0.4511, took: 40.0085s
2022-10-10 08:20:17,715 [INFO] 	Process 4 - batch 33099: mean_policy_losses: 128.559, mean_net_lifetime: 3377.7128, mean_mc_travel_dist: 1012.1445, mean_rewards: 226.7875, total_rewards: 2391.5541, mean_steps: 13.8700, mean_ecr: 0.0503 mean_entropies: 1.1223, took: 627.2365s
2022-10-10 08:20:19,877 [INFO] 	Process 2 - batch 27699: mean_policy_losses: 76.062, mean_net_lifetime: 4692.3134, mean_mc_travel_dist: 1458.7985, mean_rewards: 247.0995, total_rewards: 3254.9909, mean_steps: 18.1800, mean_ecr: 0.0401 mean_entropies: 0.8963, took: 89.0808s
2022-10-10 08:20:36,595 [INFO] 	Process 3 - batch 28199: mean_policy_losses: 100.847, mean_net_lifetime: 4306.1920, mean_mc_travel_dist: 1187.6055, mean_rewards: 258.5106, total_rewards: 3139.0551, mean_steps: 15.7400, mean_ecr: 0.0484 mean_entropies: 0.8194, took: 83.7854s
2022-10-10 08:20:43,554 [INFO] 	Process 1 - batch 23999: mean_policy_losses: 57.104, mean_net_lifetime: 4710.9189, mean_mc_travel_dist: 1725.4524, mean_rewards: 216.7570, total_rewards: 3016.6289, mean_steps: 21.1700, mean_ecr: 0.0392 mean_entropies: 1.1206, took: 102.1274s
2022-10-10 08:20:58,694 [INFO] 	Process 6 - batch 40899: mean_policy_losses: -569.228, mean_net_lifetime: 2430.6649, mean_mc_travel_dist: 677.9318, mean_rewards: 302.6420, total_rewards: 1791.9445, mean_steps: 6.9700, mean_ecr: 0.0565 mean_entropies: 0.4374, took: 41.2177s
2022-10-10 08:21:33,303 [INFO] 	Process 4 - batch 33199: mean_policy_losses: 289.253, mean_net_lifetime: 4117.6433, mean_mc_travel_dist: 1187.6663, mean_rewards: 256.1750, total_rewards: 2952.4035, mean_steps: 15.0700, mean_ecr: 0.0488 mean_entropies: 1.0708, took: 75.5879s
2022-10-10 08:21:37,523 [INFO] 	Process 5 - batch 28399: mean_policy_losses: -341.543, mean_net_lifetime: 4530.9609, mean_mc_travel_dist: 1571.9106, mean_rewards: 255.8799, total_rewards: 3010.3491, mean_steps: 17.3000, mean_ecr: 0.0296 mean_entropies: 1.0711, took: 84.5487s
2022-10-10 08:21:45,827 [INFO] 	Process 2 - batch 27799: mean_policy_losses: 32.734, mean_net_lifetime: 4526.1083, mean_mc_travel_dist: 1384.2119, mean_rewards: 238.8364, total_rewards: 3168.1825, mean_steps: 18.1200, mean_ecr: 0.0404 mean_entropies: 0.8090, took: 85.9505s
2022-10-10 08:21:46,991 [INFO] 	Process 6 - batch 40999: mean_policy_losses: -342.224, mean_net_lifetime: 3128.8971, mean_mc_travel_dist: 839.5495, mean_rewards: 311.8073, total_rewards: 2309.1984, mean_steps: 9.1100, mean_ecr: 0.0556 mean_entropies: 0.3839, took: 48.2980s
2022-10-10 08:21:57,987 [INFO] 	Process 3 - batch 28299: mean_policy_losses: 21.514, mean_net_lifetime: 4038.8135, mean_mc_travel_dist: 1120.3683, mean_rewards: 235.2374, total_rewards: 2941.1468, mean_steps: 16.2600, mean_ecr: 0.0492 mean_entropies: 0.7902, took: 81.3914s
2022-10-10 08:22:29,663 [INFO] 	Process 6 - batch 41099: mean_policy_losses: -599.951, mean_net_lifetime: 2647.7298, mean_mc_travel_dist: 719.4318, mean_rewards: 313.1444, total_rewards: 1958.7198, mean_steps: 7.4200, mean_ecr: 0.0562 mean_entropies: 0.4360, took: 42.6717s
2022-10-10 08:22:44,747 [INFO] 	Process 4 - batch 33299: mean_policy_losses: 227.332, mean_net_lifetime: 3954.6333, mean_mc_travel_dist: 1117.3318, mean_rewards: 261.7297, total_rewards: 2861.3551, mean_steps: 14.1400, mean_ecr: 0.0493 mean_entropies: 1.0785, took: 71.4435s
2022-10-10 08:23:03,626 [INFO] 	Process 5 - batch 28499: mean_policy_losses: -410.080, mean_net_lifetime: 4750.7364, mean_mc_travel_dist: 1651.4504, mean_rewards: 265.2152, total_rewards: 3144.4920, mean_steps: 17.5800, mean_ecr: 0.0295 mean_entropies: 1.1202, took: 86.1025s
2022-10-10 08:23:10,682 [INFO] 	Process 6 - batch 41199: mean_policy_losses: -504.661, mean_net_lifetime: 2623.4723, mean_mc_travel_dist: 727.2028, mean_rewards: 316.8456, total_rewards: 1939.9093, mean_steps: 7.3100, mean_ecr: 0.0562 mean_entropies: 0.4440, took: 41.0189s
2022-10-10 08:23:11,485 [INFO] 	Process 2 - batch 27899: mean_policy_losses: 23.182, mean_net_lifetime: 4622.9551, mean_mc_travel_dist: 1406.6142, mean_rewards: 244.8528, total_rewards: 3236.8577, mean_steps: 18.0600, mean_ecr: 0.0403 mean_entropies: 0.8571, took: 85.6574s
2022-10-10 08:23:18,739 [INFO] 	Process 3 - batch 28399: mean_policy_losses: 39.284, mean_net_lifetime: 4293.7546, mean_mc_travel_dist: 1192.0039, mean_rewards: 254.2151, total_rewards: 3131.7752, mean_steps: 15.9600, mean_ecr: 0.0486 mean_entropies: 0.8294, took: 80.7518s
2022-10-10 08:23:52,191 [INFO] 	Process 6 - batch 41299: mean_policy_losses: -379.640, mean_net_lifetime: 2635.6214, mean_mc_travel_dist: 736.0158, mean_rewards: 300.3167, total_rewards: 1936.9998, mean_steps: 7.6800, mean_ecr: 0.0562 mean_entropies: 0.4289, took: 41.5085s
2022-10-10 08:23:58,577 [INFO] 	Process 4 - batch 33399: mean_policy_losses: 292.311, mean_net_lifetime: 4371.9863, mean_mc_travel_dist: 1213.5260, mean_rewards: 273.3458, total_rewards: 3177.6247, mean_steps: 15.0800, mean_ecr: 0.0485 mean_entropies: 1.0554, took: 73.8305s
2022-10-10 08:24:33,093 [INFO] 	Process 2 - batch 27999: mean_policy_losses: -12.096, mean_net_lifetime: 4534.4761, mean_mc_travel_dist: 1380.6860, mean_rewards: 242.8897, total_rewards: 3182.8239, mean_steps: 17.9000, mean_ecr: 0.0404 mean_entropies: 0.7994, took: 81.6071s
2022-10-10 08:24:35,615 [INFO] 	Process 6 - batch 41399: mean_policy_losses: -491.751, mean_net_lifetime: 2775.5194, mean_mc_travel_dist: 765.1186, mean_rewards: 308.3560, total_rewards: 2044.4118, mean_steps: 7.9700, mean_ecr: 0.0563 mean_entropies: 0.3930, took: 43.4248s
2022-10-10 08:24:39,031 [INFO] 	Process 3 - batch 28499: mean_policy_losses: 20.024, mean_net_lifetime: 4251.4043, mean_mc_travel_dist: 1166.4427, mean_rewards: 245.4259, total_rewards: 3112.4606, mean_steps: 16.4200, mean_ecr: 0.0488 mean_entropies: 0.7983, took: 80.2920s
2022-10-10 08:25:10,633 [INFO] 	Process 4 - batch 33499: mean_policy_losses: 262.577, mean_net_lifetime: 4521.8244, mean_mc_travel_dist: 1280.8570, mean_rewards: 277.8161, total_rewards: 3270.8139, mean_steps: 15.3300, mean_ecr: 0.0481 mean_entropies: 0.9990, took: 72.0555s
2022-10-10 08:25:22,884 [INFO] 	Process 6 - batch 41499: mean_policy_losses: -336.310, mean_net_lifetime: 3185.4326, mean_mc_travel_dist: 864.7002, mean_rewards: 310.6417, total_rewards: 2349.7580, mean_steps: 9.3400, mean_ecr: 0.0555 mean_entropies: 0.4111, took: 47.2686s
2022-10-10 08:25:52,537 [INFO] 	Process 2 - batch 28099: mean_policy_losses: -19.296, mean_net_lifetime: 4531.3891, mean_mc_travel_dist: 1366.8187, mean_rewards: 242.2960, total_rewards: 3195.5472, mean_steps: 17.8900, mean_ecr: 0.0405 mean_entropies: 0.8233, took: 79.4452s
2022-10-10 08:26:07,008 [INFO] 	Process 6 - batch 41599: mean_policy_losses: -410.906, mean_net_lifetime: 2945.7964, mean_mc_travel_dist: 791.9490, mean_rewards: 318.0971, total_rewards: 2188.3499, mean_steps: 8.3300, mean_ecr: 0.0557 mean_entropies: 0.4012, took: 44.1240s
2022-10-10 08:26:24,866 [INFO] 	Process 4 - batch 33599: mean_policy_losses: 277.982, mean_net_lifetime: 4665.7368, mean_mc_travel_dist: 1310.4361, mean_rewards: 277.2403, total_rewards: 3387.0515, mean_steps: 15.8900, mean_ecr: 0.0478 mean_entropies: 0.9938, took: 74.2333s
2022-10-10 08:26:49,899 [INFO] 	Process 6 - batch 41699: mean_policy_losses: -401.172, mean_net_lifetime: 2810.5995, mean_mc_travel_dist: 768.8495, mean_rewards: 311.8100, total_rewards: 2079.6916, mean_steps: 7.9500, mean_ecr: 0.0563 mean_entropies: 0.3806, took: 42.8901s
2022-10-10 08:26:50,639 [INFO] Process 7 - epoch 19: mean_policy_losses: -81.843, mean_net_lifetime: 3876.5639, mean_mc_travel_dist: 1728.0047, mean_entropies: 1.9998, m_net_lifetime_valid: 4572.3354, took: 1938.9699s, (182.3545 / 100 batches)

2022-10-10 08:27:13,142 [INFO] 	Process 2 - batch 28199: mean_policy_losses: 10.791, mean_net_lifetime: 4584.3342, mean_mc_travel_dist: 1396.6726, mean_rewards: 240.1257, total_rewards: 3213.5169, mean_steps: 18.2700, mean_ecr: 0.0404 mean_entropies: 0.7889, took: 80.6042s
2022-10-10 08:27:28,207 [INFO] 	Process 6 - batch 41799: mean_policy_losses: -465.692, mean_net_lifetime: 2412.3317, mean_mc_travel_dist: 669.0777, mean_rewards: 303.4234, total_rewards: 1786.0413, mean_steps: 6.9200, mean_ecr: 0.0566 mean_entropies: 0.4102, took: 38.3086s
2022-10-10 08:27:39,794 [INFO] 	Process 4 - batch 33699: mean_policy_losses: 282.632, mean_net_lifetime: 4496.5755, mean_mc_travel_dist: 1286.5239, mean_rewards: 270.5711, total_rewards: 3239.6486, mean_steps: 15.7800, mean_ecr: 0.0480 mean_entropies: 1.0511, took: 74.9279s
2022-10-10 08:28:13,308 [INFO] 	Process 7 - batch 28599: mean_policy_losses: -301.940, mean_net_lifetime: 4352.7164, mean_mc_travel_dist: 1443.4632, mean_rewards: 225.6558, total_rewards: 2945.7460, mean_steps: 18.5600, mean_ecr: 0.0413 mean_entropies: 1.5629, took: 745.0435s
2022-10-10 08:28:13,531 [INFO] 	Process 6 - batch 41899: mean_policy_losses: -290.799, mean_net_lifetime: 2987.9581, mean_mc_travel_dist: 806.4633, mean_rewards: 311.0143, total_rewards: 2224.6844, mean_steps: 8.5700, mean_ecr: 0.0560 mean_entropies: 0.3601, took: 45.3241s
2022-10-10 08:28:38,299 [INFO] 	Process 2 - batch 28299: mean_policy_losses: 8.560, mean_net_lifetime: 4513.5866, mean_mc_travel_dist: 1392.0344, mean_rewards: 234.6583, total_rewards: 3157.8785, mean_steps: 18.3900, mean_ecr: 0.0404 mean_entropies: 0.7542, took: 85.1584s
2022-10-10 08:28:55,652 [INFO] 	Process 6 - batch 41999: mean_policy_losses: -384.435, mean_net_lifetime: 2827.0782, mean_mc_travel_dist: 758.0673, mean_rewards: 316.5556, total_rewards: 2102.5613, mean_steps: 7.8900, mean_ecr: 0.0562 mean_entropies: 0.4074, took: 42.1210s
2022-10-10 08:28:58,390 [INFO] 	Process 4 - batch 33799: mean_policy_losses: 286.220, mean_net_lifetime: 4857.2999, mean_mc_travel_dist: 1373.2280, mean_rewards: 279.6509, total_rewards: 3513.5339, mean_steps: 16.4600, mean_ecr: 0.0474 mean_entropies: 0.9799, took: 78.5964s
2022-10-10 08:29:33,681 [INFO] 	Process 7 - batch 28699: mean_policy_losses: -446.114, mean_net_lifetime: 4319.0704, mean_mc_travel_dist: 1425.6004, mean_rewards: 231.0901, total_rewards: 2927.6720, mean_steps: 18.1100, mean_ecr: 0.0416 mean_entropies: 1.5747, took: 80.3722s
2022-10-10 08:29:59,879 [INFO] 	Process 2 - batch 28399: mean_policy_losses: -34.866, mean_net_lifetime: 4643.7480, mean_mc_travel_dist: 1424.1238, mean_rewards: 245.3355, total_rewards: 3243.6798, mean_steps: 18.1700, mean_ecr: 0.0404 mean_entropies: 0.7776, took: 81.5794s
2022-10-10 08:30:14,570 [INFO] 	Process 4 - batch 33899: mean_policy_losses: 209.680, mean_net_lifetime: 4956.2990, mean_mc_travel_dist: 1391.6040, mean_rewards: 283.5349, total_rewards: 3596.9373, mean_steps: 16.5900, mean_ecr: 0.0472 mean_entropies: 0.9899, took: 76.1792s
2022-10-10 08:30:22,177 [INFO] Process 1 - epoch 16: mean_policy_losses: 66.441, mean_net_lifetime: 4598.0408, mean_mc_travel_dist: 2232.2850, mean_entropies: 1.6087, m_net_lifetime_valid: 4214.6609, took: 2101.5302s, (217.6297 / 100 batches)

2022-10-10 08:30:42,383 [INFO] 	Process 7 - batch 28799: mean_policy_losses: -775.567, mean_net_lifetime: 3742.4977, mean_mc_travel_dist: 1265.0781, mean_rewards: 238.6291, total_rewards: 2523.2910, mean_steps: 14.9600, mean_ecr: 0.0419 mean_entropies: 1.5286, took: 68.7029s
2022-10-10 08:31:17,935 [INFO] 	Process 2 - batch 28499: mean_policy_losses: -33.367, mean_net_lifetime: 4461.9236, mean_mc_travel_dist: 1383.2485, mean_rewards: 254.0102, total_rewards: 3100.1925, mean_steps: 16.8000, mean_ecr: 0.0404 mean_entropies: 0.8308, took: 78.0569s
2022-10-10 08:31:25,777 [INFO] 	Process 4 - batch 33999: mean_policy_losses: 133.653, mean_net_lifetime: 4209.8883, mean_mc_travel_dist: 1216.6551, mean_rewards: 268.6488, total_rewards: 3020.8983, mean_steps: 14.6800, mean_ecr: 0.0486 mean_entropies: 0.9993, took: 71.2079s
2022-10-10 08:31:53,611 [INFO] 	Process 1 - batch 24099: mean_policy_losses: -87.827, mean_net_lifetime: 4528.3410, mean_mc_travel_dist: 1742.4608, mean_rewards: 215.0905, total_rewards: 2817.8028, mean_steps: 20.5800, mean_ecr: 0.0391 mean_entropies: 0.9923, took: 670.0569s
2022-10-10 08:32:00,240 [INFO] 	Process 7 - batch 28899: mean_policy_losses: -336.185, mean_net_lifetime: 4193.7070, mean_mc_travel_dist: 1436.8869, mean_rewards: 227.7536, total_rewards: 2798.8652, mean_steps: 17.4700, mean_ecr: 0.0413 mean_entropies: 1.4867, took: 77.8571s
2022-10-10 08:32:40,968 [INFO] 	Process 4 - batch 34099: mean_policy_losses: 286.344, mean_net_lifetime: 4733.9480, mean_mc_travel_dist: 1388.2155, mean_rewards: 277.4081, total_rewards: 3377.2398, mean_steps: 16.1500, mean_ecr: 0.0476 mean_entropies: 0.9765, took: 75.1911s
2022-10-10 08:32:46,097 [INFO] Process 5 - epoch 19: mean_policy_losses: -118.290, mean_net_lifetime: 4364.9565, mean_mc_travel_dist: 2173.3236, mean_entropies: 1.8597, m_net_lifetime_valid: 4353.8125, took: 1949.7007s, (183.8769 / 100 batches)

2022-10-10 08:33:20,765 [INFO] 	Process 7 - batch 28999: mean_policy_losses: -309.183, mean_net_lifetime: 4357.4541, mean_mc_travel_dist: 1483.6390, mean_rewards: 232.4856, total_rewards: 2910.9415, mean_steps: 18.0500, mean_ecr: 0.0414 mean_entropies: 1.5159, took: 80.5236s
2022-10-10 08:33:27,469 [INFO] 	Process 1 - batch 24199: mean_policy_losses: -81.250, mean_net_lifetime: 4573.1496, mean_mc_travel_dist: 1749.2482, mean_rewards: 209.5228, total_rewards: 2848.8307, mean_steps: 21.2900, mean_ecr: 0.0391 mean_entropies: 0.9765, took: 93.8579s
2022-10-10 08:34:00,044 [INFO] 	Process 4 - batch 34199: mean_policy_losses: 326.013, mean_net_lifetime: 4731.9962, mean_mc_travel_dist: 1363.7745, mean_rewards: 272.8970, total_rewards: 3396.6208, mean_steps: 16.4800, mean_ecr: 0.0477 mean_entropies: 1.0887, took: 79.0754s
2022-10-10 08:34:06,249 [INFO] 	Process 5 - batch 28599: mean_policy_losses: -311.591, mean_net_lifetime: 4871.8219, mean_mc_travel_dist: 1754.9057, mean_rewards: 273.9913, total_rewards: 3166.3746, mean_steps: 17.2700, mean_ecr: 0.0292 mean_entropies: 1.0701, took: 662.6232s
2022-10-10 08:34:26,530 [INFO] Process 3 - epoch 19: mean_policy_losses: 131.858, mean_net_lifetime: 3933.5139, mean_mc_travel_dist: 1539.2989, mean_entropies: 1.4447, m_net_lifetime_valid: 4131.9172, took: 1792.8684s, (184.2082 / 100 batches)

2022-10-10 08:34:48,006 [INFO] 	Process 7 - batch 29099: mean_policy_losses: -300.168, mean_net_lifetime: 4421.2641, mean_mc_travel_dist: 1485.0797, mean_rewards: 221.6465, total_rewards: 2973.4056, mean_steps: 19.0400, mean_ecr: 0.0415 mean_entropies: 1.5925, took: 87.2421s
2022-10-10 08:35:01,016 [INFO] 	Process 1 - batch 24299: mean_policy_losses: -84.817, mean_net_lifetime: 4655.2924, mean_mc_travel_dist: 1768.5394, mean_rewards: 220.0403, total_rewards: 2913.8182, mean_steps: 20.5100, mean_ecr: 0.0391 mean_entropies: 1.0073, took: 93.5473s
2022-10-10 08:35:20,513 [INFO] 	Process 4 - batch 34299: mean_policy_losses: 286.882, mean_net_lifetime: 4704.4744, mean_mc_travel_dist: 1353.2112, mean_rewards: 277.1972, total_rewards: 3388.9156, mean_steps: 16.0300, mean_ecr: 0.0477 mean_entropies: 1.0352, took: 80.4692s
2022-10-10 08:35:35,605 [INFO] 	Process 5 - batch 28699: mean_policy_losses: -258.945, mean_net_lifetime: 5088.0588, mean_mc_travel_dist: 1850.4829, mean_rewards: 269.9524, total_rewards: 3286.0279, mean_steps: 18.8500, mean_ecr: 0.0286 mean_entropies: 1.0546, took: 89.3558s
2022-10-10 08:35:45,811 [INFO] 	Process 3 - batch 28599: mean_policy_losses: 37.580, mean_net_lifetime: 4400.6099, mean_mc_travel_dist: 1257.8589, mean_rewards: 264.0318, total_rewards: 3176.6268, mean_steps: 15.7400, mean_ecr: 0.0482 mean_entropies: 0.8018, took: 666.7805s
2022-10-10 08:36:19,989 [INFO] 	Process 7 - batch 29199: mean_policy_losses: -253.438, mean_net_lifetime: 4552.3931, mean_mc_travel_dist: 1513.2156, mean_rewards: 228.4773, total_rewards: 3092.6055, mean_steps: 19.3500, mean_ecr: 0.0411 mean_entropies: 1.5325, took: 91.9830s
2022-10-10 08:36:40,005 [INFO] 	Process 1 - batch 24399: mean_policy_losses: -102.706, mean_net_lifetime: 4572.5360, mean_mc_travel_dist: 1766.0719, mean_rewards: 208.9019, total_rewards: 2838.2451, mean_steps: 21.3600, mean_ecr: 0.0390 mean_entropies: 0.9884, took: 98.9896s
2022-10-10 08:36:45,958 [INFO] 	Process 4 - batch 34399: mean_policy_losses: 258.502, mean_net_lifetime: 4903.6550, mean_mc_travel_dist: 1414.0918, mean_rewards: 275.7795, total_rewards: 3513.8741, mean_steps: 17.0100, mean_ecr: 0.0474 mean_entropies: 1.0239, took: 85.4450s
2022-10-10 08:36:55,912 [INFO] 	Process 5 - batch 28799: mean_policy_losses: -455.976, mean_net_lifetime: 4527.8843, mean_mc_travel_dist: 1654.9066, mean_rewards: 280.6031, total_rewards: 2928.0286, mean_steps: 16.7000, mean_ecr: 0.0285 mean_entropies: 0.9916, took: 80.3077s
2022-10-10 08:37:05,508 [INFO] 	Process 3 - batch 28699: mean_policy_losses: 61.181, mean_net_lifetime: 4273.0628, mean_mc_travel_dist: 1186.5308, mean_rewards: 254.4340, total_rewards: 3112.9214, mean_steps: 15.8900, mean_ecr: 0.0484 mean_entropies: 0.7745, took: 79.6967s
2022-10-10 08:37:50,344 [INFO] 	Process 7 - batch 29299: mean_policy_losses: -253.930, mean_net_lifetime: 4571.8613, mean_mc_travel_dist: 1542.9155, mean_rewards: 228.2562, total_rewards: 3070.9613, mean_steps: 19.2200, mean_ecr: 0.0412 mean_entropies: 1.5703, took: 90.3551s
2022-10-10 08:38:11,140 [INFO] 	Process 4 - batch 34499: mean_policy_losses: 305.784, mean_net_lifetime: 4939.2647, mean_mc_travel_dist: 1393.3480, mean_rewards: 277.0682, total_rewards: 3566.8056, mean_steps: 16.9400, mean_ecr: 0.0470 mean_entropies: 1.0745, took: 85.1813s
2022-10-10 08:38:22,418 [INFO] 	Process 1 - batch 24499: mean_policy_losses: -117.592, mean_net_lifetime: 4582.0938, mean_mc_travel_dist: 1725.1769, mean_rewards: 205.8875, total_rewards: 2887.9422, mean_steps: 21.8200, mean_ecr: 0.0393 mean_entropies: 0.9877, took: 102.4127s
2022-10-10 08:38:25,840 [INFO] 	Process 5 - batch 28899: mean_policy_losses: -357.144, mean_net_lifetime: 5223.8094, mean_mc_travel_dist: 1910.0768, mean_rewards: 270.8018, total_rewards: 3357.6873, mean_steps: 19.0600, mean_ecr: 0.0289 mean_entropies: 1.0984, took: 89.9282s
2022-10-10 08:38:26,268 [INFO] 	Process 3 - batch 28799: mean_policy_losses: 62.051, mean_net_lifetime: 4511.7998, mean_mc_travel_dist: 1276.6259, mean_rewards: 265.4142, total_rewards: 3263.1812, mean_steps: 16.1100, mean_ecr: 0.0478 mean_entropies: 0.8104, took: 80.7602s
2022-10-10 08:38:29,279 [INFO] Process 6 - epoch 28: mean_policy_losses: -287.662, mean_net_lifetime: 2330.3469, mean_mc_travel_dist: 975.8735, mean_entropies: 1.1294, m_net_lifetime_valid: 4131.9649, took: 1212.0203s, (125.7491 / 100 batches)

2022-10-10 08:39:12,394 [INFO] 	Process 6 - batch 42099: mean_policy_losses: -283.483, mean_net_lifetime: 2706.8128, mean_mc_travel_dist: 738.5284, mean_rewards: 308.9072, total_rewards: 2010.3499, mean_steps: 7.7200, mean_ecr: 0.0562 mean_entropies: 0.4279, took: 616.7429s
2022-10-10 08:39:14,249 [INFO] 	Process 7 - batch 29399: mean_policy_losses: -262.524, mean_net_lifetime: 4273.8733, mean_mc_travel_dist: 1417.2487, mean_rewards: 228.9808, total_rewards: 2891.8457, mean_steps: 17.7600, mean_ecr: 0.0417 mean_entropies: 1.5324, took: 83.9048s
2022-10-10 08:39:36,857 [INFO] 	Process 5 - batch 28999: mean_policy_losses: -417.179, mean_net_lifetime: 3920.6751, mean_mc_travel_dist: 1368.2224, mean_rewards: 271.6806, total_rewards: 2620.2837, mean_steps: 14.3400, mean_ecr: 0.0293 mean_entropies: 1.0211, took: 71.0169s
2022-10-10 08:39:46,528 [INFO] 	Process 3 - batch 28899: mean_policy_losses: 130.609, mean_net_lifetime: 4197.7901, mean_mc_travel_dist: 1174.4120, mean_rewards: 247.7250, total_rewards: 3036.7957, mean_steps: 16.0300, mean_ecr: 0.0487 mean_entropies: 0.7753, took: 80.2594s
2022-10-10 08:39:52,952 [INFO] 	Process 1 - batch 24599: mean_policy_losses: 51.687, mean_net_lifetime: 4656.5564, mean_mc_travel_dist: 1834.5888, mean_rewards: 239.6621, total_rewards: 2845.1039, mean_steps: 18.7700, mean_ecr: 0.0389 mean_entropies: 0.9839, took: 90.5332s
2022-10-10 08:40:01,608 [INFO] 	Process 6 - batch 42199: mean_policy_losses: -271.444, mean_net_lifetime: 3122.5234, mean_mc_travel_dist: 839.3445, mean_rewards: 315.6762, total_rewards: 2313.3334, mean_steps: 8.9900, mean_ecr: 0.0556 mean_entropies: 0.3818, took: 49.2127s
2022-10-10 08:40:29,511 [INFO] Process 2 - epoch 19: mean_policy_losses: 18.703, mean_net_lifetime: 3977.2634, mean_mc_travel_dist: 1748.2301, mean_entropies: 1.5078, m_net_lifetime_valid: 4157.0089, took: 1812.7892s, (185.6057 / 100 batches)

2022-10-10 08:40:31,208 [INFO] 	Process 7 - batch 29499: mean_policy_losses: -341.196, mean_net_lifetime: 3602.8700, mean_mc_travel_dist: 1189.8300, mean_rewards: 213.9386, total_rewards: 2448.7741, mean_steps: 16.0200, mean_ecr: 0.0421 mean_entropies: 1.3712, took: 76.9591s
2022-10-10 08:40:46,547 [INFO] 	Process 6 - batch 42299: mean_policy_losses: -347.150, mean_net_lifetime: 2702.5691, mean_mc_travel_dist: 740.7717, mean_rewards: 303.1845, total_rewards: 2000.8409, mean_steps: 7.8700, mean_ecr: 0.0564 mean_entropies: 0.4073, took: 44.9400s
2022-10-10 08:41:04,948 [INFO] 	Process 5 - batch 29099: mean_policy_losses: -286.338, mean_net_lifetime: 4635.2656, mean_mc_travel_dist: 1588.1172, mean_rewards: 250.7908, total_rewards: 3119.9916, mean_steps: 17.8400, mean_ecr: 0.0307 mean_entropies: 0.9366, took: 88.0909s
2022-10-10 08:41:10,507 [INFO] 	Process 3 - batch 28999: mean_policy_losses: 122.964, mean_net_lifetime: 4177.5983, mean_mc_travel_dist: 1128.9026, mean_rewards: 239.8072, total_rewards: 3074.0885, mean_steps: 16.5400, mean_ecr: 0.0491 mean_entropies: 0.7570, took: 83.9797s
2022-10-10 08:41:29,373 [INFO] 	Process 1 - batch 24699: mean_policy_losses: 24.789, mean_net_lifetime: 4655.8789, mean_mc_travel_dist: 1846.1629, mean_rewards: 230.6353, total_rewards: 2837.6767, mean_steps: 19.8900, mean_ecr: 0.0387 mean_entropies: 0.9131, took: 96.4222s
2022-10-10 08:41:39,420 [INFO] 	Process 6 - batch 42399: mean_policy_losses: -237.672, mean_net_lifetime: 3284.4808, mean_mc_travel_dist: 882.3856, mean_rewards: 314.2250, total_rewards: 2434.5879, mean_steps: 9.4300, mean_ecr: 0.0557 mean_entropies: 0.3521, took: 52.8727s
2022-10-10 08:41:56,328 [INFO] 	Process 7 - batch 29599: mean_policy_losses: -328.828, mean_net_lifetime: 3850.9304, mean_mc_travel_dist: 1277.8968, mean_rewards: 209.5201, total_rewards: 2618.4683, mean_steps: 17.4600, mean_ecr: 0.0419 mean_entropies: 1.3123, took: 85.1196s
2022-10-10 08:41:58,005 [INFO] 	Process 2 - batch 28599: mean_policy_losses: 24.793, mean_net_lifetime: 4499.5619, mean_mc_travel_dist: 1426.6442, mean_rewards: 241.6922, total_rewards: 3104.2688, mean_steps: 17.7500, mean_ecr: 0.0400 mean_entropies: 0.8009, took: 640.0687s
2022-10-10 08:42:27,368 [INFO] 	Process 6 - batch 42499: mean_policy_losses: -283.990, mean_net_lifetime: 3000.9173, mean_mc_travel_dist: 811.5999, mean_rewards: 310.1501, total_rewards: 2233.5055, mean_steps: 8.6000, mean_ecr: 0.0562 mean_entropies: 0.3744, took: 47.9472s
2022-10-10 08:42:34,823 [INFO] 	Process 3 - batch 29099: mean_policy_losses: 34.360, mean_net_lifetime: 4069.8874, mean_mc_travel_dist: 1093.2217, mean_rewards: 231.8377, total_rewards: 2998.1206, mean_steps: 16.6200, mean_ecr: 0.0493 mean_entropies: 0.7320, took: 84.3159s
2022-10-10 08:42:35,415 [INFO] 	Process 5 - batch 29199: mean_policy_losses: -180.208, mean_net_lifetime: 4925.9330, mean_mc_travel_dist: 1664.5061, mean_rewards: 260.4418, total_rewards: 3313.2445, mean_steps: 18.1000, mean_ecr: 0.0311 mean_entropies: 0.9804, took: 90.4668s
2022-10-10 08:43:13,641 [INFO] 	Process 6 - batch 42599: mean_policy_losses: -412.098, mean_net_lifetime: 2814.0558, mean_mc_travel_dist: 773.5969, mean_rewards: 312.5100, total_rewards: 2073.0286, mean_steps: 8.0300, mean_ecr: 0.0562 mean_entropies: 0.4081, took: 46.2742s
2022-10-10 08:43:15,709 [INFO] 	Process 1 - batch 24799: mean_policy_losses: 22.776, mean_net_lifetime: 4760.0418, mean_mc_travel_dist: 1766.9625, mean_rewards: 217.0939, total_rewards: 3018.3107, mean_steps: 21.5600, mean_ecr: 0.0390 mean_entropies: 1.0286, took: 106.3351s
2022-10-10 08:43:28,210 [INFO] 	Process 7 - batch 29699: mean_policy_losses: -279.901, mean_net_lifetime: 4112.3031, mean_mc_travel_dist: 1342.3111, mean_rewards: 210.2135, total_rewards: 2801.5323, mean_steps: 18.6800, mean_ecr: 0.0417 mean_entropies: 1.3985, took: 91.8821s
2022-10-10 08:43:31,881 [INFO] 	Process 2 - batch 28699: mean_policy_losses: 67.290, mean_net_lifetime: 4712.2303, mean_mc_travel_dist: 1452.1215, mean_rewards: 240.8863, total_rewards: 3292.6122, mean_steps: 18.6900, mean_ecr: 0.0400 mean_entropies: 0.8528, took: 93.8765s
2022-10-10 08:44:00,691 [INFO] 	Process 6 - batch 42699: mean_policy_losses: -428.000, mean_net_lifetime: 2823.2115, mean_mc_travel_dist: 761.6833, mean_rewards: 313.6170, total_rewards: 2099.3585, mean_steps: 8.0200, mean_ecr: 0.0558 mean_entropies: 0.3825, took: 47.0487s
2022-10-10 08:44:02,068 [INFO] 	Process 3 - batch 29199: mean_policy_losses: 68.767, mean_net_lifetime: 4234.1409, mean_mc_travel_dist: 1159.6522, mean_rewards: 238.7340, total_rewards: 3102.9923, mean_steps: 16.8500, mean_ecr: 0.0488 mean_entropies: 0.7967, took: 87.2449s
2022-10-10 08:44:09,417 [INFO] 	Process 5 - batch 29299: mean_policy_losses: -275.521, mean_net_lifetime: 4921.3158, mean_mc_travel_dist: 1683.5107, mean_rewards: 256.8870, total_rewards: 3300.9166, mean_steps: 18.7100, mean_ecr: 0.0309 mean_entropies: 1.0076, took: 94.0014s
2022-10-10 08:44:49,008 [INFO] 	Process 6 - batch 42799: mean_policy_losses: -345.631, mean_net_lifetime: 2934.2959, mean_mc_travel_dist: 796.2540, mean_rewards: 313.2766, total_rewards: 2167.9840, mean_steps: 8.3600, mean_ecr: 0.0559 mean_entropies: 0.3578, took: 48.3177s
2022-10-10 08:44:54,001 [INFO] 	Process 1 - batch 24899: mean_policy_losses: 20.425, mean_net_lifetime: 4659.4236, mean_mc_travel_dist: 1764.8707, mean_rewards: 228.6466, total_rewards: 2925.0398, mean_steps: 19.7600, mean_ecr: 0.0390 mean_entropies: 1.0273, took: 98.2922s
2022-10-10 08:44:58,285 [INFO] 	Process 7 - batch 29799: mean_policy_losses: -273.166, mean_net_lifetime: 4151.0536, mean_mc_travel_dist: 1363.1391, mean_rewards: 213.8422, total_rewards: 2827.3686, mean_steps: 18.5400, mean_ecr: 0.0416 mean_entropies: 1.3806, took: 90.0757s
2022-10-10 08:45:03,302 [INFO] 	Process 2 - batch 28799: mean_policy_losses: 45.503, mean_net_lifetime: 4584.5391, mean_mc_travel_dist: 1383.3702, mean_rewards: 241.6562, total_rewards: 3223.9999, mean_steps: 18.1600, mean_ecr: 0.0404 mean_entropies: 0.7555, took: 91.4208s
2022-10-10 08:45:28,282 [INFO] 	Process 3 - batch 29299: mean_policy_losses: 74.849, mean_net_lifetime: 4288.2694, mean_mc_travel_dist: 1170.1133, mean_rewards: 247.4971, total_rewards: 3150.5238, mean_steps: 16.4000, mean_ecr: 0.0489 mean_entropies: 0.7617, took: 86.2144s
2022-10-10 08:45:34,636 [INFO] 	Process 6 - batch 42899: mean_policy_losses: -400.651, mean_net_lifetime: 2854.2692, mean_mc_travel_dist: 776.7275, mean_rewards: 325.3520, total_rewards: 2110.6689, mean_steps: 7.8700, mean_ecr: 0.0558 mean_entropies: 0.4073, took: 45.6283s
2022-10-10 08:45:39,358 [INFO] 	Process 5 - batch 29399: mean_policy_losses: -307.632, mean_net_lifetime: 4820.2558, mean_mc_travel_dist: 1630.0206, mean_rewards: 260.4786, total_rewards: 3250.1923, mean_steps: 17.8900, mean_ecr: 0.0306 mean_entropies: 1.0148, took: 89.9413s
2022-10-10 08:46:21,984 [INFO] 	Process 6 - batch 42999: mean_policy_losses: -286.045, mean_net_lifetime: 2952.1326, mean_mc_travel_dist: 807.4853, mean_rewards: 313.3605, total_rewards: 2176.4780, mean_steps: 8.3500, mean_ecr: 0.0560 mean_entropies: 0.4108, took: 47.3480s
2022-10-10 08:46:22,897 [INFO] 	Process 1 - batch 24999: mean_policy_losses: 7.267, mean_net_lifetime: 4638.6874, mean_mc_travel_dist: 1850.6675, mean_rewards: 247.2667, total_rewards: 2815.3026, mean_steps: 17.9800, mean_ecr: 0.0388 mean_entropies: 0.9657, took: 88.8966s
2022-10-10 08:46:29,326 [INFO] 	Process 7 - batch 29899: mean_policy_losses: -228.513, mean_net_lifetime: 4184.0979, mean_mc_travel_dist: 1363.2382, mean_rewards: 212.6548, total_rewards: 2849.7013, mean_steps: 18.6600, mean_ecr: 0.0415 mean_entropies: 1.3809, took: 91.0403s
2022-10-10 08:46:29,375 [INFO] 	Process 2 - batch 28899: mean_policy_losses: 47.974, mean_net_lifetime: 4633.3389, mean_mc_travel_dist: 1419.8449, mean_rewards: 258.5866, total_rewards: 3241.3623, mean_steps: 17.1000, mean_ecr: 0.0402 mean_entropies: 0.8382, took: 86.0730s
2022-10-10 08:46:49,770 [INFO] 	Process 3 - batch 29399: mean_policy_losses: 102.989, mean_net_lifetime: 4323.0236, mean_mc_travel_dist: 1189.4480, mean_rewards: 259.6438, total_rewards: 3153.9119, mean_steps: 15.7300, mean_ecr: 0.0485 mean_entropies: 0.8187, took: 81.4876s
2022-10-10 08:47:11,800 [INFO] 	Process 5 - batch 29499: mean_policy_losses: -276.210, mean_net_lifetime: 4897.5490, mean_mc_travel_dist: 1687.2717, mean_rewards: 252.7776, total_rewards: 3275.4035, mean_steps: 18.5100, mean_ecr: 0.0309 mean_entropies: 0.9809, took: 92.4422s
2022-10-10 08:47:12,424 [INFO] 	Process 6 - batch 43099: mean_policy_losses: -332.884, mean_net_lifetime: 3127.8830, mean_mc_travel_dist: 857.1495, mean_rewards: 317.0531, total_rewards: 2308.4363, mean_steps: 8.9100, mean_ecr: 0.0556 mean_entropies: 0.3937, took: 50.4393s
2022-10-10 08:47:53,547 [INFO] 	Process 7 - batch 29999: mean_policy_losses: -396.218, mean_net_lifetime: 3639.7714, mean_mc_travel_dist: 1191.7134, mean_rewards: 202.1619, total_rewards: 2485.8776, mean_steps: 17.1200, mean_ecr: 0.0420 mean_entropies: 1.2999, took: 84.2214s
2022-10-10 08:47:54,875 [INFO] Process 4 - epoch 23: mean_policy_losses: 60.395, mean_net_lifetime: 3315.7666, mean_mc_travel_dist: 1274.7310, mean_entropies: 1.6763, m_net_lifetime_valid: 4312.8618, took: 1729.7115s, (154.6133 / 100 batches)

2022-10-10 08:47:59,570 [INFO] 	Process 2 - batch 28999: mean_policy_losses: 50.465, mean_net_lifetime: 4675.2007, mean_mc_travel_dist: 1422.8480, mean_rewards: 247.1615, total_rewards: 3284.1671, mean_steps: 18.0800, mean_ecr: 0.0402 mean_entropies: 0.7711, took: 90.1954s
2022-10-10 08:48:00,290 [INFO] 	Process 1 - batch 25099: mean_policy_losses: 26.374, mean_net_lifetime: 4654.9896, mean_mc_travel_dist: 1766.4685, mean_rewards: 226.3319, total_rewards: 2918.8901, mean_steps: 19.9300, mean_ecr: 0.0389 mean_entropies: 0.9874, took: 97.3934s
2022-10-10 08:48:01,402 [INFO] 	Process 6 - batch 43199: mean_policy_losses: -391.293, mean_net_lifetime: 3011.2393, mean_mc_travel_dist: 818.5468, mean_rewards: 312.7175, total_rewards: 2229.3550, mean_steps: 8.6500, mean_ecr: 0.0557 mean_entropies: 0.3747, took: 48.9790s
2022-10-10 08:48:14,336 [INFO] 	Process 3 - batch 29499: mean_policy_losses: 58.936, mean_net_lifetime: 4229.9119, mean_mc_travel_dist: 1137.3109, mean_rewards: 238.9115, total_rewards: 3112.5911, mean_steps: 16.7900, mean_ecr: 0.0488 mean_entropies: 0.7504, took: 84.5655s
2022-10-10 08:48:40,022 [INFO] 	Process 5 - batch 29599: mean_policy_losses: -264.964, mean_net_lifetime: 4888.6919, mean_mc_travel_dist: 1661.5175, mean_rewards: 267.4641, total_rewards: 3286.5325, mean_steps: 17.4800, mean_ecr: 0.0310 mean_entropies: 1.0100, took: 88.2219s
2022-10-10 08:48:47,479 [INFO] 	Process 6 - batch 43299: mean_policy_losses: -313.984, mean_net_lifetime: 2800.6610, mean_mc_travel_dist: 777.0234, mean_rewards: 309.0312, total_rewards: 2065.7912, mean_steps: 7.9700, mean_ecr: 0.0563 mean_entropies: 0.4427, took: 46.0761s
2022-10-10 08:49:07,385 [INFO] 	Process 4 - batch 34599: mean_policy_losses: 71.646, mean_net_lifetime: 3375.4683, mean_mc_travel_dist: 988.6674, mean_rewards: 231.1293, total_rewards: 2416.4039, mean_steps: 13.6900, mean_ecr: 0.0502 mean_entropies: 1.1260, took: 656.2454s
2022-10-10 08:49:30,111 [INFO] 	Process 2 - batch 29099: mean_policy_losses: 26.024, mean_net_lifetime: 4714.4493, mean_mc_travel_dist: 1423.6062, mean_rewards: 249.7906, total_rewards: 3317.0817, mean_steps: 18.0700, mean_ecr: 0.0402 mean_entropies: 0.7707, took: 90.5407s
2022-10-10 08:49:37,509 [INFO] 	Process 3 - batch 29599: mean_policy_losses: 16.286, mean_net_lifetime: 4295.4843, mean_mc_travel_dist: 1181.8114, mean_rewards: 252.4001, total_rewards: 3135.2735, mean_steps: 16.0900, mean_ecr: 0.0486 mean_entropies: 0.7729, took: 83.1722s
2022-10-10 08:49:38,109 [INFO] 	Process 6 - batch 43399: mean_policy_losses: -397.186, mean_net_lifetime: 3181.6067, mean_mc_travel_dist: 864.2642, mean_rewards: 320.9279, total_rewards: 2342.2539, mean_steps: 9.0200, mean_ecr: 0.0556 mean_entropies: 0.3797, took: 50.6302s
2022-10-10 08:49:42,711 [INFO] 	Process 1 - batch 25199: mean_policy_losses: 15.762, mean_net_lifetime: 4750.2259, mean_mc_travel_dist: 1718.2936, mean_rewards: 218.4944, total_rewards: 3056.2326, mean_steps: 21.3600, mean_ecr: 0.0392 mean_entropies: 1.0874, took: 102.4194s
2022-10-10 08:50:05,946 [INFO] 	Process 5 - batch 29699: mean_policy_losses: -324.217, mean_net_lifetime: 4739.5858, mean_mc_travel_dist: 1617.5145, mean_rewards: 261.5707, total_rewards: 3173.6711, mean_steps: 17.5600, mean_ecr: 0.0304 mean_entropies: 1.0317, took: 85.9243s
2022-10-10 08:50:22,128 [INFO] 	Process 4 - batch 34699: mean_policy_losses: 168.834, mean_net_lifetime: 3946.2059, mean_mc_travel_dist: 1123.4268, mean_rewards: 258.1865, total_rewards: 2850.2636, mean_steps: 14.3800, mean_ecr: 0.0496 mean_entropies: 1.0499, took: 74.7430s
2022-10-10 08:50:29,115 [INFO] 	Process 6 - batch 43499: mean_policy_losses: -252.830, mean_net_lifetime: 3359.5324, mean_mc_travel_dist: 904.9123, mean_rewards: 321.5611, total_rewards: 2482.7699, mean_steps: 9.5200, mean_ecr: 0.0557 mean_entropies: 0.3520, took: 51.0062s
2022-10-10 08:50:56,587 [INFO] 	Process 3 - batch 29699: mean_policy_losses: 14.038, mean_net_lifetime: 4286.9540, mean_mc_travel_dist: 1188.2383, mean_rewards: 260.2604, total_rewards: 3127.1304, mean_steps: 15.5700, mean_ecr: 0.0487 mean_entropies: 0.7934, took: 79.0792s
2022-10-10 08:50:58,028 [INFO] 	Process 2 - batch 29199: mean_policy_losses: 4.380, mean_net_lifetime: 4625.6959, mean_mc_travel_dist: 1385.5783, mean_rewards: 247.3341, total_rewards: 3271.4442, mean_steps: 17.8800, mean_ecr: 0.0404 mean_entropies: 0.7996, took: 87.9171s
2022-10-10 08:51:16,609 [INFO] 	Process 1 - batch 25299: mean_policy_losses: -24.282, mean_net_lifetime: 4740.1074, mean_mc_travel_dist: 1697.3586, mean_rewards: 231.5068, total_rewards: 3071.1969, mean_steps: 19.7600, mean_ecr: 0.0394 mean_entropies: 1.1303, took: 93.8986s
2022-10-10 08:51:31,386 [INFO] 	Process 5 - batch 29799: mean_policy_losses: -293.716, mean_net_lifetime: 4794.3680, mean_mc_travel_dist: 1644.8034, mean_rewards: 262.9181, total_rewards: 3207.9344, mean_steps: 17.5400, mean_ecr: 0.0304 mean_entropies: 1.0763, took: 85.4396s
2022-10-10 08:51:36,638 [INFO] 	Process 4 - batch 34799: mean_policy_losses: 150.508, mean_net_lifetime: 4069.4566, mean_mc_travel_dist: 1142.9924, mean_rewards: 261.1701, total_rewards: 2955.7579, mean_steps: 14.6200, mean_ecr: 0.0490 mean_entropies: 1.0652, took: 74.5098s
2022-10-10 08:52:14,209 [INFO] 	Process 3 - batch 29799: mean_policy_losses: 33.573, mean_net_lifetime: 4427.0125, mean_mc_travel_dist: 1225.3446, mean_rewards: 269.9381, total_rewards: 3232.9643, mean_steps: 15.4600, mean_ecr: 0.0485 mean_entropies: 0.8021, took: 77.6225s
2022-10-10 08:52:21,279 [INFO] 	Process 2 - batch 29299: mean_policy_losses: -12.686, mean_net_lifetime: 4656.9692, mean_mc_travel_dist: 1376.6558, mean_rewards: 256.2237, total_rewards: 3305.0273, mean_steps: 17.3700, mean_ecr: 0.0405 mean_entropies: 0.8095, took: 83.2513s
2022-10-10 08:52:46,396 [INFO] 	Process 4 - batch 34899: mean_policy_losses: 93.319, mean_net_lifetime: 3867.3847, mean_mc_travel_dist: 1097.7246, mean_rewards: 265.1902, total_rewards: 2798.8227, mean_steps: 13.6300, mean_ecr: 0.0495 mean_entropies: 1.0724, took: 69.7583s
2022-10-10 08:52:47,060 [INFO] 	Process 1 - batch 25399: mean_policy_losses: -92.078, mean_net_lifetime: 4719.4836, mean_mc_travel_dist: 1804.3073, mean_rewards: 240.7544, total_rewards: 2949.6404, mean_steps: 18.8800, mean_ecr: 0.0391 mean_entropies: 1.1239, took: 90.4509s
2022-10-10 08:52:56,843 [INFO] 	Process 5 - batch 29899: mean_policy_losses: -367.355, mean_net_lifetime: 4742.9550, mean_mc_travel_dist: 1632.2720, mean_rewards: 256.6685, total_rewards: 3175.5472, mean_steps: 17.9000, mean_ecr: 0.0302 mean_entropies: 1.0915, took: 85.4577s
2022-10-10 08:53:29,745 [INFO] 	Process 3 - batch 29899: mean_policy_losses: -3.015, mean_net_lifetime: 4311.4463, mean_mc_travel_dist: 1226.9665, mean_rewards: 269.6306, total_rewards: 3111.2149, mean_steps: 15.0700, mean_ecr: 0.0484 mean_entropies: 0.8318, took: 75.5359s
2022-10-10 08:53:47,307 [INFO] 	Process 2 - batch 29399: mean_policy_losses: -15.666, mean_net_lifetime: 4698.7941, mean_mc_travel_dist: 1410.1560, mean_rewards: 252.6390, total_rewards: 3311.4942, mean_steps: 17.7700, mean_ecr: 0.0403 mean_entropies: 0.8282, took: 86.0276s
2022-10-10 08:53:59,952 [INFO] 	Process 4 - batch 34999: mean_policy_losses: 164.384, mean_net_lifetime: 4195.1061, mean_mc_travel_dist: 1180.6648, mean_rewards: 270.6205, total_rewards: 3044.3930, mean_steps: 14.5500, mean_ecr: 0.0489 mean_entropies: 1.0476, took: 73.5557s
2022-10-10 08:54:20,024 [INFO] 	Process 1 - batch 25499: mean_policy_losses: -71.083, mean_net_lifetime: 4857.1561, mean_mc_travel_dist: 1766.1818, mean_rewards: 236.3435, total_rewards: 3117.3417, mean_steps: 19.7800, mean_ecr: 0.0392 mean_entropies: 1.1852, took: 92.9644s
2022-10-10 08:54:23,346 [INFO] 	Process 5 - batch 29999: mean_policy_losses: -373.262, mean_net_lifetime: 4880.0834, mean_mc_travel_dist: 1674.0944, mean_rewards: 266.3050, total_rewards: 3265.1429, mean_steps: 17.7900, mean_ecr: 0.0301 mean_entropies: 1.1077, took: 86.5024s
2022-10-10 08:54:42,821 [INFO] 	Process 3 - batch 29999: mean_policy_losses: -17.296, mean_net_lifetime: 4338.9423, mean_mc_travel_dist: 1228.8832, mean_rewards: 274.3668, total_rewards: 3134.8051, mean_steps: 14.8600, mean_ecr: 0.0484 mean_entropies: 0.8237, took: 73.0741s
2022-10-10 08:55:04,512 [INFO] 	Process 2 - batch 29499: mean_policy_losses: -66.674, mean_net_lifetime: 4636.9838, mean_mc_travel_dist: 1377.4887, mean_rewards: 261.3972, total_rewards: 3284.3729, mean_steps: 16.9100, mean_ecr: 0.0404 mean_entropies: 0.8305, took: 77.2047s
2022-10-10 08:55:08,070 [INFO] 	Process 4 - batch 35099: mean_policy_losses: 135.205, mean_net_lifetime: 4254.6264, mean_mc_travel_dist: 1198.2046, mean_rewards: 274.1014, total_rewards: 3088.7311, mean_steps: 14.5700, mean_ecr: 0.0487 mean_entropies: 1.0125, took: 68.1178s
2022-10-10 08:56:15,767 [INFO] 	Process 2 - batch 29599: mean_policy_losses: -132.674, mean_net_lifetime: 4493.7057, mean_mc_travel_dist: 1391.8677, mean_rewards: 262.7686, total_rewards: 3124.2474, mean_steps: 16.3400, mean_ecr: 0.0404 mean_entropies: 0.8137, took: 71.2555s
2022-10-10 08:56:16,701 [INFO] 	Process 4 - batch 35199: mean_policy_losses: 151.070, mean_net_lifetime: 4573.6246, mean_mc_travel_dist: 1301.2197, mean_rewards: 284.1700, total_rewards: 3293.2088, mean_steps: 15.1400, mean_ecr: 0.0480 mean_entropies: 0.9542, took: 68.6318s
2022-10-10 08:57:23,490 [INFO] 	Process 2 - batch 29699: mean_policy_losses: -218.546, mean_net_lifetime: 4310.5400, mean_mc_travel_dist: 1422.3273, mean_rewards: 262.0228, total_rewards: 2924.4026, mean_steps: 15.6100, mean_ecr: 0.0401 mean_entropies: 0.8664, took: 67.7229s
2022-10-10 08:57:26,049 [INFO] 	Process 4 - batch 35299: mean_policy_losses: 207.800, mean_net_lifetime: 4617.9856, mean_mc_travel_dist: 1298.0264, mean_rewards: 283.0589, total_rewards: 3347.7366, mean_steps: 15.3600, mean_ecr: 0.0482 mean_entropies: 0.9826, took: 69.3478s
2022-10-10 08:58:36,429 [INFO] 	Process 2 - batch 29799: mean_policy_losses: -167.331, mean_net_lifetime: 4545.8949, mean_mc_travel_dist: 1425.9715, mean_rewards: 255.9509, total_rewards: 3150.0806, mean_steps: 16.8800, mean_ecr: 0.0402 mean_entropies: 0.8383, took: 72.9389s
2022-10-10 08:58:36,441 [INFO] 	Process 4 - batch 35399: mean_policy_losses: 160.291, mean_net_lifetime: 4732.0524, mean_mc_travel_dist: 1347.0090, mean_rewards: 282.6783, total_rewards: 3417.8174, mean_steps: 15.7600, mean_ecr: 0.0474 mean_entropies: 0.9611, took: 70.3924s
2022-10-10 08:58:43,515 [INFO] Process 7 - epoch 20: mean_policy_losses: -94.708, mean_net_lifetime: 3890.4886, mean_mc_travel_dist: 1710.7420, mean_entropies: 1.9732, m_net_lifetime_valid: 4329.4478, took: 1912.8751s, (179.6634 / 100 batches)

2022-10-10 08:59:47,731 [INFO] 	Process 2 - batch 29899: mean_policy_losses: -143.276, mean_net_lifetime: 4421.5469, mean_mc_travel_dist: 1418.7644, mean_rewards: 264.5349, total_rewards: 3029.1868, mean_steps: 15.8800, mean_ecr: 0.0403 mean_entropies: 0.8314, took: 71.3025s
2022-10-10 08:59:52,164 [INFO] Process 6 - epoch 29: mean_policy_losses: -289.201, mean_net_lifetime: 2352.6940, mean_mc_travel_dist: 970.1544, mean_entropies: 1.1039, m_net_lifetime_valid: 4455.8296, took: 1282.8832s, (124.3895 / 100 batches)

2022-10-10 08:59:52,822 [INFO] 	Process 4 - batch 35499: mean_policy_losses: 217.920, mean_net_lifetime: 4875.0076, mean_mc_travel_dist: 1414.7828, mean_rewards: 280.0363, total_rewards: 3486.7549, mean_steps: 16.6100, mean_ecr: 0.0473 mean_entropies: 0.9582, took: 76.3802s
2022-10-10 09:00:05,933 [INFO] 	Process 7 - batch 30099: mean_policy_losses: -324.807, mean_net_lifetime: 4626.5100, mean_mc_travel_dist: 1622.6778, mean_rewards: 235.0627, total_rewards: 3055.2211, mean_steps: 18.9100, mean_ecr: 0.0412 mean_entropies: 1.5299, took: 732.3858s
2022-10-10 09:00:31,565 [INFO] 	Process 6 - batch 43599: mean_policy_losses: -372.721, mean_net_lifetime: 2658.1494, mean_mc_travel_dist: 729.8949, mean_rewards: 306.8615, total_rewards: 1970.9228, mean_steps: 7.5600, mean_ecr: 0.0562 mean_entropies: 0.3920, took: 602.4501s
2022-10-10 09:01:10,129 [INFO] 	Process 2 - batch 29999: mean_policy_losses: 9.775, mean_net_lifetime: 4586.4723, mean_mc_travel_dist: 1403.5735, mean_rewards: 250.2591, total_rewards: 3211.4426, mean_steps: 17.5400, mean_ecr: 0.0406 mean_entropies: 0.7800, took: 82.3979s
2022-10-10 09:01:10,492 [INFO] 	Process 4 - batch 35599: mean_policy_losses: 307.906, mean_net_lifetime: 4833.2878, mean_mc_travel_dist: 1382.1816, mean_rewards: 280.2161, total_rewards: 3482.0965, mean_steps: 16.3200, mean_ecr: 0.0474 mean_entropies: 0.9262, took: 77.6706s
2022-10-10 09:01:16,367 [INFO] 	Process 6 - batch 43699: mean_policy_losses: -377.207, mean_net_lifetime: 3026.4549, mean_mc_travel_dist: 811.5391, mean_rewards: 318.0731, total_rewards: 2249.5719, mean_steps: 8.5600, mean_ecr: 0.0557 mean_entropies: 0.3738, took: 44.8019s
2022-10-10 09:01:24,689 [INFO] 	Process 7 - batch 30199: mean_policy_losses: -405.207, mean_net_lifetime: 4305.4244, mean_mc_travel_dist: 1395.2183, mean_rewards: 239.3684, total_rewards: 2950.4886, mean_steps: 17.3000, mean_ecr: 0.0414 mean_entropies: 1.4813, took: 78.7561s
2022-10-10 09:02:06,297 [INFO] 	Process 6 - batch 43799: mean_policy_losses: -161.481, mean_net_lifetime: 3497.6728, mean_mc_travel_dist: 931.4446, mean_rewards: 306.8883, total_rewards: 2582.7282, mean_steps: 10.4600, mean_ecr: 0.0555 mean_entropies: 0.3211, took: 49.9296s
2022-10-10 09:02:21,899 [INFO] 	Process 4 - batch 35699: mean_policy_losses: 208.297, mean_net_lifetime: 4678.2690, mean_mc_travel_dist: 1350.2000, mean_rewards: 283.4794, total_rewards: 3352.3424, mean_steps: 15.5300, mean_ecr: 0.0476 mean_entropies: 0.8421, took: 71.4069s
2022-10-10 09:02:31,565 [INFO] 	Process 7 - batch 30299: mean_policy_losses: -564.460, mean_net_lifetime: 3798.6564, mean_mc_travel_dist: 1291.0103, mean_rewards: 243.7464, total_rewards: 2547.5974, mean_steps: 15.0700, mean_ecr: 0.0418 mean_entropies: 1.4439, took: 66.8760s
2022-10-10 09:02:44,658 [INFO] Process 3 - epoch 20: mean_policy_losses: 127.925, mean_net_lifetime: 3951.3914, mean_mc_travel_dist: 1521.7517, mean_entropies: 1.4118, m_net_lifetime_valid: 4056.5606, took: 1698.1264s, (181.0210 / 100 batches)

2022-10-10 09:02:55,553 [INFO] 	Process 6 - batch 43899: mean_policy_losses: -178.071, mean_net_lifetime: 3358.6254, mean_mc_travel_dist: 914.1721, mean_rewards: 309.4271, total_rewards: 2477.5926, mean_steps: 9.9100, mean_ecr: 0.0554 mean_entropies: 0.3135, took: 49.2560s
2022-10-10 09:02:57,430 [INFO] Process 1 - epoch 17: mean_policy_losses: 60.601, mean_net_lifetime: 4602.0932, mean_mc_travel_dist: 2205.1598, mean_entropies: 1.5744, m_net_lifetime_valid: 4259.5254, took: 1955.2512s, (212.7548 / 100 batches)

2022-10-10 09:03:10,854 [INFO] Process 5 - epoch 20: mean_policy_losses: -128.209, mean_net_lifetime: 4386.3028, mean_mc_travel_dist: 2148.0649, mean_entropies: 1.8183, m_net_lifetime_valid: 4198.4805, took: 1824.7556s, (180.9585 / 100 batches)

2022-10-10 09:03:47,160 [INFO] 	Process 6 - batch 43999: mean_policy_losses: -268.246, mean_net_lifetime: 3188.3172, mean_mc_travel_dist: 860.1379, mean_rewards: 309.4814, total_rewards: 2356.3546, mean_steps: 9.2700, mean_ecr: 0.0557 mean_entropies: 0.3324, took: 51.6079s
2022-10-10 09:03:50,708 [INFO] 	Process 4 - batch 35799: mean_policy_losses: 327.083, mean_net_lifetime: 5201.7270, mean_mc_travel_dist: 1490.0587, mean_rewards: 272.6130, total_rewards: 3735.6193, mean_steps: 18.2600, mean_ecr: 0.0464 mean_entropies: 0.8862, took: 88.8087s
2022-10-10 09:03:57,838 [INFO] 	Process 7 - batch 30399: mean_policy_losses: -352.556, mean_net_lifetime: 4295.1754, mean_mc_travel_dist: 1413.2733, mean_rewards: 225.9217, total_rewards: 2924.8261, mean_steps: 18.4600, mean_ecr: 0.0415 mean_entropies: 1.4579, took: 86.2732s
2022-10-10 09:04:09,728 [INFO] 	Process 3 - batch 30099: mean_policy_losses: 14.606, mean_net_lifetime: 4072.6945, mean_mc_travel_dist: 1115.5289, mean_rewards: 227.4999, total_rewards: 2985.2290, mean_steps: 17.0600, mean_ecr: 0.0491 mean_entropies: 0.6740, took: 566.9083s
2022-10-10 09:04:34,803 [INFO] 	Process 5 - batch 30099: mean_policy_losses: -372.005, mean_net_lifetime: 4299.3838, mean_mc_travel_dist: 1466.2958, mean_rewards: 251.8034, total_rewards: 2888.6637, mean_steps: 17.0400, mean_ecr: 0.0295 mean_entropies: 0.9526, took: 611.4574s
2022-10-10 09:04:39,775 [INFO] 	Process 6 - batch 44099: mean_policy_losses: -246.097, mean_net_lifetime: 3258.9753, mean_mc_travel_dist: 879.2793, mean_rewards: 320.4922, total_rewards: 2414.6076, mean_steps: 9.1900, mean_ecr: 0.0556 mean_entropies: 0.3226, took: 52.6149s
2022-10-10 09:04:41,942 [INFO] 	Process 1 - batch 25599: mean_policy_losses: -6.452, mean_net_lifetime: 4622.0489, mean_mc_travel_dist: 1739.2772, mean_rewards: 203.9605, total_rewards: 2924.6360, mean_steps: 22.2500, mean_ecr: 0.0392 mean_entropies: 0.9956, took: 621.9180s
2022-10-10 09:05:21,137 [INFO] 	Process 4 - batch 35899: mean_policy_losses: 265.719, mean_net_lifetime: 4897.7583, mean_mc_travel_dist: 1412.8753, mean_rewards: 265.2633, total_rewards: 3517.9669, mean_steps: 17.7500, mean_ecr: 0.0469 mean_entropies: 0.9675, took: 90.4289s
2022-10-10 09:05:29,325 [INFO] 	Process 6 - batch 44199: mean_policy_losses: -246.264, mean_net_lifetime: 3084.5198, mean_mc_travel_dist: 857.8869, mean_rewards: 310.9186, total_rewards: 2279.1739, mean_steps: 8.8700, mean_ecr: 0.0558 mean_entropies: 0.3647, took: 49.5494s
2022-10-10 09:05:35,682 [INFO] 	Process 3 - batch 30199: mean_policy_losses: 51.825, mean_net_lifetime: 4316.3547, mean_mc_travel_dist: 1177.2091, mean_rewards: 238.6695, total_rewards: 3163.3330, mean_steps: 17.1600, mean_ecr: 0.0487 mean_entropies: 0.6933, took: 85.9540s
2022-10-10 09:05:37,291 [INFO] 	Process 7 - batch 30499: mean_policy_losses: -214.896, mean_net_lifetime: 4642.4680, mean_mc_travel_dist: 1533.9719, mean_rewards: 222.1320, total_rewards: 3151.6821, mean_steps: 20.4500, mean_ecr: 0.0413 mean_entropies: 1.4532, took: 99.4524s
2022-10-10 09:06:07,200 [INFO] 	Process 5 - batch 30199: mean_policy_losses: -238.130, mean_net_lifetime: 4847.5092, mean_mc_travel_dist: 1677.0718, mean_rewards: 249.9140, total_rewards: 3227.1374, mean_steps: 18.7100, mean_ecr: 0.0298 mean_entropies: 0.9831, took: 92.3971s
2022-10-10 09:06:18,193 [INFO] 	Process 6 - batch 44299: mean_policy_losses: -328.045, mean_net_lifetime: 3139.1507, mean_mc_travel_dist: 853.3119, mean_rewards: 322.5016, total_rewards: 2317.1775, mean_steps: 8.7600, mean_ecr: 0.0559 mean_entropies: 0.3514, took: 48.8677s
2022-10-10 09:06:25,884 [INFO] 	Process 1 - batch 25699: mean_policy_losses: -5.175, mean_net_lifetime: 4697.7834, mean_mc_travel_dist: 1715.5374, mean_rewards: 213.6215, total_rewards: 3010.4718, mean_steps: 21.6200, mean_ecr: 0.0392 mean_entropies: 1.0526, took: 103.9418s
2022-10-10 09:06:42,449 [INFO] 	Process 4 - batch 35999: mean_policy_losses: 181.420, mean_net_lifetime: 4225.4556, mean_mc_travel_dist: 1226.3741, mean_rewards: 256.0895, total_rewards: 3039.2911, mean_steps: 15.7600, mean_ecr: 0.0485 mean_entropies: 1.0336, took: 81.3122s
2022-10-10 09:06:58,696 [INFO] 	Process 3 - batch 30299: mean_policy_losses: 55.178, mean_net_lifetime: 4300.7695, mean_mc_travel_dist: 1174.1050, mean_rewards: 248.7861, total_rewards: 3155.1339, mean_steps: 16.3600, mean_ecr: 0.0487 mean_entropies: 0.7540, took: 83.0146s
2022-10-10 09:07:03,849 [INFO] 	Process 6 - batch 44399: mean_policy_losses: -363.298, mean_net_lifetime: 2883.6516, mean_mc_travel_dist: 790.4701, mean_rewards: 321.1566, total_rewards: 2130.8063, mean_steps: 7.9900, mean_ecr: 0.0560 mean_entropies: 0.3488, took: 45.6567s
2022-10-10 09:07:07,886 [INFO] 	Process 7 - batch 30599: mean_policy_losses: -211.198, mean_net_lifetime: 4418.2862, mean_mc_travel_dist: 1486.4032, mean_rewards: 225.3185, total_rewards: 2982.0497, mean_steps: 18.7400, mean_ecr: 0.0415 mean_entropies: 1.4542, took: 90.5954s
2022-10-10 09:07:33,901 [INFO] 	Process 5 - batch 30299: mean_policy_losses: -173.961, mean_net_lifetime: 4835.1116, mean_mc_travel_dist: 1613.0567, mean_rewards: 263.4726, total_rewards: 3278.8969, mean_steps: 17.6700, mean_ecr: 0.0309 mean_entropies: 1.0182, took: 86.7005s
2022-10-10 09:07:45,570 [INFO] 	Process 6 - batch 44499: mean_policy_losses: -379.822, mean_net_lifetime: 2610.4825, mean_mc_travel_dist: 729.1907, mean_rewards: 308.7371, total_rewards: 1930.9692, mean_steps: 7.3300, mean_ecr: 0.0567 mean_entropies: 0.3926, took: 41.7209s
2022-10-10 09:08:06,978 [INFO] 	Process 1 - batch 25799: mean_policy_losses: 20.582, mean_net_lifetime: 4697.1477, mean_mc_travel_dist: 1712.9261, mean_rewards: 216.5208, total_rewards: 3012.4242, mean_steps: 21.2400, mean_ecr: 0.0392 mean_entropies: 1.0669, took: 101.0935s
2022-10-10 09:08:20,166 [INFO] 	Process 3 - batch 30399: mean_policy_losses: 60.315, mean_net_lifetime: 4311.9693, mean_mc_travel_dist: 1201.2277, mean_rewards: 246.4396, total_rewards: 3138.9423, mean_steps: 16.5900, mean_ecr: 0.0486 mean_entropies: 0.7353, took: 81.4699s
2022-10-10 09:08:34,128 [INFO] 	Process 6 - batch 44599: mean_policy_losses: -248.593, mean_net_lifetime: 3256.6270, mean_mc_travel_dist: 873.0656, mean_rewards: 321.5960, total_rewards: 2406.9729, mean_steps: 9.1700, mean_ecr: 0.0558 mean_entropies: 0.3148, took: 48.5579s
2022-10-10 09:08:47,533 [INFO] 	Process 7 - batch 30699: mean_policy_losses: -104.595, mean_net_lifetime: 4866.7952, mean_mc_travel_dist: 1619.2950, mean_rewards: 215.8167, total_rewards: 3287.9659, mean_steps: 21.7200, mean_ecr: 0.0409 mean_entropies: 1.4056, took: 99.6461s
2022-10-10 09:09:00,018 [INFO] 	Process 5 - batch 30399: mean_policy_losses: -215.967, mean_net_lifetime: 4678.3603, mean_mc_travel_dist: 1575.1281, mean_rewards: 257.6074, total_rewards: 3158.2839, mean_steps: 17.5600, mean_ecr: 0.0310 mean_entropies: 0.9465, took: 86.1168s
2022-10-10 09:09:23,356 [INFO] 	Process 6 - batch 44699: mean_policy_losses: -222.946, mean_net_lifetime: 3250.7716, mean_mc_travel_dist: 882.0094, mean_rewards: 322.0232, total_rewards: 2398.2463, mean_steps: 9.1300, mean_ecr: 0.0557 mean_entropies: 0.3412, took: 49.2281s
2022-10-10 09:09:44,153 [INFO] 	Process 3 - batch 30499: mean_policy_losses: 41.491, mean_net_lifetime: 4219.7375, mean_mc_travel_dist: 1152.6350, mean_rewards: 241.1736, total_rewards: 3095.2099, mean_steps: 16.6000, mean_ecr: 0.0489 mean_entropies: 0.7126, took: 83.9831s
2022-10-10 09:09:46,101 [INFO] 	Process 1 - batch 25899: mean_policy_losses: 8.320, mean_net_lifetime: 4782.7182, mean_mc_travel_dist: 1782.2595, mean_rewards: 223.3427, total_rewards: 3033.5673, mean_steps: 20.8700, mean_ecr: 0.0390 mean_entropies: 1.0509, took: 99.1233s
2022-10-10 09:10:14,422 [INFO] 	Process 7 - batch 30799: mean_policy_losses: -253.932, mean_net_lifetime: 4247.0730, mean_mc_travel_dist: 1421.6856, mean_rewards: 219.1638, total_rewards: 2875.6527, mean_steps: 18.5800, mean_ecr: 0.0415 mean_entropies: 1.4273, took: 86.8896s
2022-10-10 09:10:15,116 [INFO] 	Process 6 - batch 44799: mean_policy_losses: -223.918, mean_net_lifetime: 3442.3892, mean_mc_travel_dist: 930.5170, mean_rewards: 323.2107, total_rewards: 2537.6678, mean_steps: 9.7000, mean_ecr: 0.0555 mean_entropies: 0.3560, took: 51.7598s
2022-10-10 09:10:25,260 [INFO] 	Process 5 - batch 30499: mean_policy_losses: -178.736, mean_net_lifetime: 4865.7380, mean_mc_travel_dist: 1633.3182, mean_rewards: 264.7952, total_rewards: 3295.5569, mean_steps: 17.6800, mean_ecr: 0.0313 mean_entropies: 0.9752, took: 85.2430s
2022-10-10 09:10:59,407 [INFO] 	Process 6 - batch 44899: mean_policy_losses: -430.522, mean_net_lifetime: 2828.7134, mean_mc_travel_dist: 781.7652, mean_rewards: 316.8633, total_rewards: 2089.5661, mean_steps: 7.8800, mean_ecr: 0.0564 mean_entropies: 0.4005, took: 44.2911s
2022-10-10 09:11:02,319 [INFO] Process 2 - epoch 20: mean_policy_losses: 16.165, mean_net_lifetime: 4007.7200, mean_mc_travel_dist: 1731.2880, mean_entropies: 1.4731, m_net_lifetime_valid: 4172.6944, took: 1832.8059s, (182.3104 / 100 batches)

2022-10-10 09:11:04,365 [INFO] 	Process 3 - batch 30599: mean_policy_losses: 53.725, mean_net_lifetime: 4321.9939, mean_mc_travel_dist: 1191.9616, mean_rewards: 251.9676, total_rewards: 3156.4195, mean_steps: 16.2500, mean_ecr: 0.0487 mean_entropies: 0.7653, took: 80.2154s
2022-10-10 09:11:19,181 [INFO] 	Process 1 - batch 25999: mean_policy_losses: 14.606, mean_net_lifetime: 4782.5738, mean_mc_travel_dist: 1772.5692, mean_rewards: 233.9487, total_rewards: 3035.8419, mean_steps: 19.7800, mean_ecr: 0.0390 mean_entropies: 1.0694, took: 93.0800s
2022-10-10 09:11:44,844 [INFO] 	Process 7 - batch 30899: mean_policy_losses: -258.978, mean_net_lifetime: 4256.0205, mean_mc_travel_dist: 1363.9593, mean_rewards: 213.8325, total_rewards: 2930.7304, mean_steps: 18.9000, mean_ecr: 0.0417 mean_entropies: 1.3917, took: 90.4219s
2022-10-10 09:11:47,840 [INFO] 	Process 6 - batch 44999: mean_policy_losses: -333.749, mean_net_lifetime: 3103.9169, mean_mc_travel_dist: 844.9306, mean_rewards: 323.4437, total_rewards: 2284.0267, mean_steps: 8.6200, mean_ecr: 0.0557 mean_entropies: 0.3619, took: 48.4331s
2022-10-10 09:11:59,438 [INFO] 	Process 5 - batch 30599: mean_policy_losses: -123.392, mean_net_lifetime: 5208.5071, mean_mc_travel_dist: 1764.3423, mean_rewards: 256.8003, total_rewards: 3487.3923, mean_steps: 19.3900, mean_ecr: 0.0313 mean_entropies: 1.0172, took: 94.1775s
2022-10-10 09:12:27,237 [INFO] 	Process 3 - batch 30699: mean_policy_losses: 53.920, mean_net_lifetime: 4368.8683, mean_mc_travel_dist: 1215.6896, mean_rewards: 258.4553, total_rewards: 3180.8093, mean_steps: 15.9700, mean_ecr: 0.0485 mean_entropies: 0.7853, took: 82.8719s
2022-10-10 09:12:30,000 [INFO] 	Process 2 - batch 30099: mean_policy_losses: 28.836, mean_net_lifetime: 4708.4561, mean_mc_travel_dist: 1405.5770, mean_rewards: 252.8547, total_rewards: 3333.4162, mean_steps: 17.8100, mean_ecr: 0.0402 mean_entropies: 0.7692, took: 679.8713s
2022-10-10 09:12:52,134 [INFO] 	Process 1 - batch 26099: mean_policy_losses: 19.131, mean_net_lifetime: 4800.9190, mean_mc_travel_dist: 1774.2437, mean_rewards: 238.1410, total_rewards: 3056.0235, mean_steps: 19.4500, mean_ecr: 0.0391 mean_entropies: 1.0584, took: 92.9537s
2022-10-10 09:13:08,361 [INFO] 	Process 7 - batch 30999: mean_policy_losses: -386.468, mean_net_lifetime: 3726.5323, mean_mc_travel_dist: 1226.3316, mean_rewards: 199.8337, total_rewards: 2536.4847, mean_steps: 17.6000, mean_ecr: 0.0420 mean_entropies: 1.2852, took: 83.5176s
2022-10-10 09:13:31,526 [INFO] 	Process 5 - batch 30699: mean_policy_losses: -251.010, mean_net_lifetime: 5123.6074, mean_mc_travel_dist: 1739.5878, mean_rewards: 252.6875, total_rewards: 3430.8464, mean_steps: 19.3300, mean_ecr: 0.0313 mean_entropies: 0.9159, took: 92.0881s
2022-10-10 09:13:46,539 [INFO] 	Process 3 - batch 30799: mean_policy_losses: 80.114, mean_net_lifetime: 4375.3230, mean_mc_travel_dist: 1220.9171, mean_rewards: 257.5693, total_rewards: 3180.5830, mean_steps: 16.0500, mean_ecr: 0.0483 mean_entropies: 0.7847, took: 79.3026s
2022-10-10 09:13:56,592 [INFO] 	Process 2 - batch 30199: mean_policy_losses: 49.937, mean_net_lifetime: 4723.0315, mean_mc_travel_dist: 1441.1822, mean_rewards: 253.7067, total_rewards: 3310.3708, mean_steps: 17.7700, mean_ecr: 0.0401 mean_entropies: 0.8213, took: 86.5915s
2022-10-10 09:14:30,411 [INFO] 	Process 1 - batch 26199: mean_policy_losses: 36.155, mean_net_lifetime: 4815.2441, mean_mc_travel_dist: 1747.1948, mean_rewards: 224.8406, total_rewards: 3097.6541, mean_steps: 20.8300, mean_ecr: 0.0391 mean_entropies: 1.0556, took: 98.2771s
2022-10-10 09:14:33,510 [INFO] 	Process 7 - batch 31099: mean_policy_losses: -409.290, mean_net_lifetime: 3766.6209, mean_mc_travel_dist: 1229.4424, mean_rewards: 197.7046, total_rewards: 2580.1964, mean_steps: 18.0200, mean_ecr: 0.0420 mean_entropies: 1.3178, took: 85.1486s
2022-10-10 09:15:05,704 [INFO] 	Process 5 - batch 30799: mean_policy_losses: -271.058, mean_net_lifetime: 5035.8583, mean_mc_travel_dist: 1727.9230, mean_rewards: 248.5513, total_rewards: 3360.5944, mean_steps: 19.3700, mean_ecr: 0.0312 mean_entropies: 0.9362, took: 94.1778s
2022-10-10 09:15:05,858 [INFO] 	Process 3 - batch 30899: mean_policy_losses: 95.273, mean_net_lifetime: 4492.7237, mean_mc_travel_dist: 1257.9826, mean_rewards: 266.8494, total_rewards: 3265.9654, mean_steps: 15.9300, mean_ecr: 0.0478 mean_entropies: 0.7825, took: 79.3183s
2022-10-10 09:15:20,246 [INFO] 	Process 2 - batch 30299: mean_policy_losses: 5.615, mean_net_lifetime: 4683.6885, mean_mc_travel_dist: 1507.7958, mean_rewards: 256.9016, total_rewards: 3203.8390, mean_steps: 17.3500, mean_ecr: 0.0397 mean_entropies: 0.8469, took: 83.6542s
2022-10-10 09:16:05,593 [INFO] 	Process 1 - batch 26299: mean_policy_losses: -10.195, mean_net_lifetime: 4632.2206, mean_mc_travel_dist: 1705.4153, mean_rewards: 222.8303, total_rewards: 2954.5626, mean_steps: 20.2600, mean_ecr: 0.0393 mean_entropies: 0.9884, took: 95.1818s
2022-10-10 09:16:09,924 [INFO] 	Process 7 - batch 31199: mean_policy_losses: -171.849, mean_net_lifetime: 4466.6118, mean_mc_travel_dist: 1414.8349, mean_rewards: 210.1698, total_rewards: 3096.0809, mean_steps: 20.4400, mean_ecr: 0.0417 mean_entropies: 1.3917, took: 96.4135s
2022-10-10 09:16:19,967 [INFO] Process 4 - epoch 24: mean_policy_losses: 65.688, mean_net_lifetime: 3361.8969, mean_mc_travel_dist: 1274.2683, mean_entropies: 1.6478, m_net_lifetime_valid: 4193.2497, took: 1705.0908s, (152.9294 / 100 batches)

2022-10-10 09:16:27,727 [INFO] 	Process 3 - batch 30999: mean_policy_losses: 68.616, mean_net_lifetime: 4439.7862, mean_mc_travel_dist: 1228.3995, mean_rewards: 257.3191, total_rewards: 3245.2994, mean_steps: 16.3400, mean_ecr: 0.0483 mean_entropies: 0.7602, took: 81.8689s
2022-10-10 09:16:34,706 [INFO] 	Process 5 - batch 30899: mean_policy_losses: -299.135, mean_net_lifetime: 4905.3237, mean_mc_travel_dist: 1652.1189, mean_rewards: 255.7275, total_rewards: 3304.9771, mean_steps: 18.3600, mean_ecr: 0.0311 mean_entropies: 0.9489, took: 89.0025s
2022-10-10 09:16:46,715 [INFO] 	Process 2 - batch 30399: mean_policy_losses: 13.261, mean_net_lifetime: 4711.2580, mean_mc_travel_dist: 1444.3940, mean_rewards: 254.3177, total_rewards: 3282.6750, mean_steps: 17.7100, mean_ecr: 0.0401 mean_entropies: 0.7629, took: 86.4685s
2022-10-10 09:17:32,558 [INFO] 	Process 4 - batch 36099: mean_policy_losses: 85.520, mean_net_lifetime: 3540.7687, mean_mc_travel_dist: 1014.2505, mean_rewards: 244.3217, total_rewards: 2553.4393, mean_steps: 13.6200, mean_ecr: 0.0500 mean_entropies: 1.0147, took: 650.1088s
2022-10-10 09:17:39,672 [INFO] 	Process 7 - batch 31299: mean_policy_losses: -329.129, mean_net_lifetime: 4178.1159, mean_mc_travel_dist: 1341.5693, mean_rewards: 216.9428, total_rewards: 2889.2664, mean_steps: 18.4800, mean_ecr: 0.0417 mean_entropies: 1.4115, took: 89.7485s
2022-10-10 09:17:43,761 [INFO] 	Process 1 - batch 26399: mean_policy_losses: -17.120, mean_net_lifetime: 4688.5474, mean_mc_travel_dist: 1739.9164, mean_rewards: 228.2366, total_rewards: 2972.7110, mean_steps: 20.0600, mean_ecr: 0.0392 mean_entropies: 1.0498, took: 98.1684s
2022-10-10 09:17:47,626 [INFO] 	Process 3 - batch 31099: mean_policy_losses: 65.889, mean_net_lifetime: 4449.6499, mean_mc_travel_dist: 1223.0502, mean_rewards: 268.0632, total_rewards: 3260.8098, mean_steps: 15.6700, mean_ecr: 0.0484 mean_entropies: 0.7761, took: 79.8992s
2022-10-10 09:18:04,907 [INFO] 	Process 5 - batch 30999: mean_policy_losses: -273.670, mean_net_lifetime: 4979.7036, mean_mc_travel_dist: 1727.4915, mean_rewards: 261.2642, total_rewards: 3316.0503, mean_steps: 18.2000, mean_ecr: 0.0302 mean_entropies: 1.0016, took: 90.2005s
2022-10-10 09:18:14,748 [INFO] 	Process 2 - batch 30499: mean_policy_losses: 4.842, mean_net_lifetime: 4691.1387, mean_mc_travel_dist: 1446.4690, mean_rewards: 255.2115, total_rewards: 3265.6541, mean_steps: 17.5700, mean_ecr: 0.0402 mean_entropies: 0.7865, took: 88.0336s
2022-10-10 09:18:53,279 [INFO] 	Process 4 - batch 36199: mean_policy_losses: 173.656, mean_net_lifetime: 4064.7267, mean_mc_travel_dist: 1191.4963, mean_rewards: 244.9754, total_rewards: 2902.5486, mean_steps: 15.6200, mean_ecr: 0.0490 mean_entropies: 1.0508, took: 80.7210s
2022-10-10 09:19:10,684 [INFO] 	Process 3 - batch 31199: mean_policy_losses: 45.023, mean_net_lifetime: 4524.2607, mean_mc_travel_dist: 1255.4888, mean_rewards: 266.5642, total_rewards: 3296.2081, mean_steps: 16.0600, mean_ecr: 0.0481 mean_entropies: 0.7704, took: 83.0580s
2022-10-10 09:19:14,691 [INFO] 	Process 7 - batch 31399: mean_policy_losses: -286.644, mean_net_lifetime: 4398.9025, mean_mc_travel_dist: 1413.4409, mean_rewards: 219.4131, total_rewards: 3017.3996, mean_steps: 19.4500, mean_ecr: 0.0416 mean_entropies: 1.4816, took: 95.0184s
2022-10-10 09:19:24,711 [INFO] 	Process 1 - batch 26499: mean_policy_losses: -47.950, mean_net_lifetime: 4731.6678, mean_mc_travel_dist: 1722.0516, mean_rewards: 224.2490, total_rewards: 3045.8073, mean_steps: 20.4700, mean_ecr: 0.0393 mean_entropies: 1.1234, took: 100.9500s
2022-10-10 09:19:40,653 [INFO] 	Process 5 - batch 31099: mean_policy_losses: -233.101, mean_net_lifetime: 5106.1728, mean_mc_travel_dist: 1746.0972, mean_rewards: 255.4682, total_rewards: 3415.5557, mean_steps: 19.0900, mean_ecr: 0.0305 mean_entropies: 1.0632, took: 95.7459s
2022-10-10 09:19:42,442 [INFO] 	Process 2 - batch 30599: mean_policy_losses: -19.470, mean_net_lifetime: 4654.0877, mean_mc_travel_dist: 1417.3513, mean_rewards: 256.0231, total_rewards: 3266.4805, mean_steps: 17.3500, mean_ecr: 0.0402 mean_entropies: 0.8135, took: 87.6932s
2022-10-10 09:20:16,338 [INFO] 	Process 4 - batch 36299: mean_policy_losses: 251.969, mean_net_lifetime: 4420.4286, mean_mc_travel_dist: 1250.7227, mean_rewards: 266.8246, total_rewards: 3199.3719, mean_steps: 15.6700, mean_ecr: 0.0482 mean_entropies: 1.0150, took: 83.0594s
2022-10-10 09:20:34,435 [INFO] 	Process 3 - batch 31299: mean_policy_losses: 24.360, mean_net_lifetime: 4437.7949, mean_mc_travel_dist: 1246.7248, mean_rewards: 267.3530, total_rewards: 3217.8906, mean_steps: 15.6400, mean_ecr: 0.0483 mean_entropies: 0.7835, took: 83.7505s
2022-10-10 09:20:39,913 [INFO] 	Process 7 - batch 31499: mean_policy_losses: -417.769, mean_net_lifetime: 4138.0466, mean_mc_travel_dist: 1398.0514, mean_rewards: 234.0699, total_rewards: 2785.3009, mean_steps: 16.9300, mean_ecr: 0.0418 mean_entropies: 1.5340, took: 85.2224s
2022-10-10 09:21:03,063 [INFO] 	Process 1 - batch 26599: mean_policy_losses: -34.725, mean_net_lifetime: 4855.4635, mean_mc_travel_dist: 1770.4320, mean_rewards: 238.3809, total_rewards: 3122.6850, mean_steps: 19.5700, mean_ecr: 0.0392 mean_entropies: 1.1146, took: 98.3510s
2022-10-10 09:21:08,027 [INFO] 	Process 2 - batch 30699: mean_policy_losses: -9.762, mean_net_lifetime: 4700.7240, mean_mc_travel_dist: 1421.0954, mean_rewards: 260.3389, total_rewards: 3296.7583, mean_steps: 17.2500, mean_ecr: 0.0402 mean_entropies: 0.8119, took: 85.5855s
2022-10-10 09:21:12,517 [INFO] 	Process 5 - batch 31199: mean_policy_losses: -326.169, mean_net_lifetime: 4840.9078, mean_mc_travel_dist: 1634.1887, mean_rewards: 265.6821, total_rewards: 3264.7547, mean_steps: 17.6500, mean_ecr: 0.0305 mean_entropies: 1.0588, took: 91.8639s
2022-10-10 09:21:34,555 [INFO] 	Process 4 - batch 36399: mean_policy_losses: 222.260, mean_net_lifetime: 4390.9715, mean_mc_travel_dist: 1229.2255, mean_rewards: 269.4720, total_rewards: 3196.1593, mean_steps: 15.3400, mean_ecr: 0.0485 mean_entropies: 1.0346, took: 78.2155s
2022-10-10 09:21:44,140 [INFO] Process 6 - epoch 30: mean_policy_losses: -289.296, mean_net_lifetime: 2377.8007, mean_mc_travel_dist: 965.9706, mean_entropies: 1.0789, m_net_lifetime_valid: 4158.9761, took: 1311.9745s, (123.0877 / 100 batches)

2022-10-10 09:21:54,474 [INFO] 	Process 3 - batch 31399: mean_policy_losses: -1.220, mean_net_lifetime: 4379.0043, mean_mc_travel_dist: 1234.3060, mean_rewards: 273.7238, total_rewards: 3172.3071, mean_steps: 15.0500, mean_ecr: 0.0484 mean_entropies: 0.8070, took: 80.0401s
2022-10-10 09:22:29,766 [INFO] 	Process 6 - batch 45099: mean_policy_losses: -532.150, mean_net_lifetime: 2695.7922, mean_mc_travel_dist: 753.7468, mean_rewards: 320.0387, total_rewards: 1977.9958, mean_steps: 7.5200, mean_ecr: 0.0559 mean_entropies: 0.4356, took: 641.9258s
2022-10-10 09:22:30,003 [INFO] 	Process 2 - batch 30799: mean_policy_losses: 4.892, mean_net_lifetime: 4659.2488, mean_mc_travel_dist: 1390.1613, mean_rewards: 267.3513, total_rewards: 3292.8892, mean_steps: 16.5700, mean_ecr: 0.0404 mean_entropies: 0.8219, took: 81.9763s
2022-10-10 09:22:37,092 [INFO] 	Process 1 - batch 26699: mean_policy_losses: -55.602, mean_net_lifetime: 4728.8543, mean_mc_travel_dist: 1792.5390, mean_rewards: 244.5692, total_rewards: 2961.8514, mean_steps: 18.6400, mean_ecr: 0.0391 mean_entropies: 1.0839, took: 94.0301s
2022-10-10 09:22:41,148 [INFO] 	Process 5 - batch 31299: mean_policy_losses: -324.759, mean_net_lifetime: 4648.4369, mean_mc_travel_dist: 1578.3690, mean_rewards: 264.9411, total_rewards: 3130.1331, mean_steps: 17.0900, mean_ecr: 0.0304 mean_entropies: 1.0723, took: 88.6318s
2022-10-10 09:22:49,034 [INFO] 	Process 4 - batch 36499: mean_policy_losses: 206.100, mean_net_lifetime: 4043.0377, mean_mc_travel_dist: 1162.0751, mean_rewards: 263.3750, total_rewards: 2912.6245, mean_steps: 14.3600, mean_ecr: 0.0490 mean_entropies: 1.0578, took: 74.4799s
2022-10-10 09:23:18,266 [INFO] 	Process 3 - batch 31499: mean_policy_losses: 65.524, mean_net_lifetime: 4434.4373, mean_mc_travel_dist: 1234.4058, mean_rewards: 270.2829, total_rewards: 3219.8459, mean_steps: 15.4800, mean_ecr: 0.0484 mean_entropies: 0.7869, took: 83.7908s
2022-10-10 09:23:19,122 [INFO] 	Process 6 - batch 45199: mean_policy_losses: -427.555, mean_net_lifetime: 2984.6413, mean_mc_travel_dist: 806.0869, mean_rewards: 327.9062, total_rewards: 2207.7826, mean_steps: 8.1600, mean_ecr: 0.0560 mean_entropies: 0.3633, took: 49.3555s
2022-10-10 09:23:56,779 [INFO] 	Process 2 - batch 30899: mean_policy_losses: 13.606, mean_net_lifetime: 4658.3751, mean_mc_travel_dist: 1394.0827, mean_rewards: 252.2646, total_rewards: 3299.3604, mean_steps: 17.6600, mean_ecr: 0.0404 mean_entropies: 0.7546, took: 86.7757s
2022-10-10 09:24:04,316 [INFO] 	Process 4 - batch 36599: mean_policy_losses: 251.051, mean_net_lifetime: 4345.3471, mean_mc_travel_dist: 1229.3705, mean_rewards: 273.3189, total_rewards: 3150.3031, mean_steps: 14.9200, mean_ecr: 0.0488 mean_entropies: 0.9931, took: 75.2826s
2022-10-10 09:24:07,900 [INFO] 	Process 5 - batch 31399: mean_policy_losses: -382.336, mean_net_lifetime: 4504.8539, mean_mc_travel_dist: 1523.6800, mean_rewards: 259.7877, total_rewards: 3034.3881, mean_steps: 16.9200, mean_ecr: 0.0301 mean_entropies: 1.0138, took: 86.7519s
2022-10-10 09:24:08,734 [INFO] 	Process 6 - batch 45299: mean_policy_losses: -340.677, mean_net_lifetime: 3182.3530, mean_mc_travel_dist: 865.0148, mean_rewards: 317.9085, total_rewards: 2348.0044, mean_steps: 9.0100, mean_ecr: 0.0560 mean_entropies: 0.3552, took: 49.6127s
2022-10-10 09:24:12,536 [INFO] 	Process 1 - batch 26799: mean_policy_losses: 8.268, mean_net_lifetime: 4745.2149, mean_mc_travel_dist: 1716.1431, mean_rewards: 236.1097, total_rewards: 3047.5280, mean_steps: 19.3500, mean_ecr: 0.0394 mean_entropies: 1.0935, took: 95.4440s
2022-10-10 09:24:53,987 [INFO] 	Process 6 - batch 45399: mean_policy_losses: -321.625, mean_net_lifetime: 2956.5393, mean_mc_travel_dist: 807.6864, mean_rewards: 321.5965, total_rewards: 2192.5609, mean_steps: 8.2000, mean_ecr: 0.0561 mean_entropies: 0.3900, took: 45.2530s
2022-10-10 09:25:18,980 [INFO] 	Process 2 - batch 30999: mean_policy_losses: 35.578, mean_net_lifetime: 4654.0460, mean_mc_travel_dist: 1369.7774, mean_rewards: 259.7877, total_rewards: 3311.9357, mean_steps: 17.0200, mean_ecr: 0.0404 mean_entropies: 0.7625, took: 82.2008s
2022-10-10 09:25:21,205 [INFO] 	Process 4 - batch 36699: mean_policy_losses: 263.382, mean_net_lifetime: 4464.0881, mean_mc_travel_dist: 1250.8877, mean_rewards: 272.2131, total_rewards: 3242.3872, mean_steps: 15.4500, mean_ecr: 0.0481 mean_entropies: 1.0198, took: 76.8883s
2022-10-10 09:25:32,777 [INFO] 	Process 5 - batch 31499: mean_policy_losses: -349.098, mean_net_lifetime: 4658.3347, mean_mc_travel_dist: 1602.7886, mean_rewards: 258.7049, total_rewards: 3121.5760, mean_steps: 17.3600, mean_ecr: 0.0300 mean_entropies: 1.0440, took: 84.8758s
2022-10-10 09:25:40,143 [INFO] 	Process 6 - batch 45499: mean_policy_losses: -356.524, mean_net_lifetime: 3074.7941, mean_mc_travel_dist: 840.1061, mean_rewards: 321.6787, total_rewards: 2267.6672, mean_steps: 8.5100, mean_ecr: 0.0559 mean_entropies: 0.3768, took: 46.1548s
2022-10-10 09:25:42,007 [INFO] 	Process 1 - batch 26899: mean_policy_losses: -20.034, mean_net_lifetime: 4713.4961, mean_mc_travel_dist: 1729.8002, mean_rewards: 236.9324, total_rewards: 3006.5418, mean_steps: 19.1000, mean_ecr: 0.0393 mean_entropies: 1.0761, took: 89.4703s
2022-10-10 09:26:21,899 [INFO] 	Process 6 - batch 45599: mean_policy_losses: -452.342, mean_net_lifetime: 2809.3975, mean_mc_travel_dist: 788.3775, mean_rewards: 317.5216, total_rewards: 2060.3142, mean_steps: 7.8100, mean_ecr: 0.0564 mean_entropies: 0.3929, took: 41.7570s
2022-10-10 09:26:32,767 [INFO] 	Process 4 - batch 36799: mean_policy_losses: 222.389, mean_net_lifetime: 4370.2114, mean_mc_travel_dist: 1224.3540, mean_rewards: 276.9415, total_rewards: 3172.4636, mean_steps: 14.8000, mean_ecr: 0.0483 mean_entropies: 0.9828, took: 71.5626s
2022-10-10 09:26:40,652 [INFO] 	Process 2 - batch 31099: mean_policy_losses: 6.449, mean_net_lifetime: 4624.5284, mean_mc_travel_dist: 1370.8935, mean_rewards: 253.4966, total_rewards: 3281.5874, mean_steps: 17.4700, mean_ecr: 0.0406 mean_entropies: 0.7352, took: 81.6718s
2022-10-10 09:27:08,459 [INFO] 	Process 6 - batch 45699: mean_policy_losses: -307.952, mean_net_lifetime: 3158.0769, mean_mc_travel_dist: 862.0068, mean_rewards: 319.5877, total_rewards: 2329.9918, mean_steps: 8.9100, mean_ecr: 0.0559 mean_entropies: 0.3627, took: 46.5603s
2022-10-10 09:27:14,989 [INFO] 	Process 1 - batch 26999: mean_policy_losses: -20.086, mean_net_lifetime: 4799.5908, mean_mc_travel_dist: 1780.7578, mean_rewards: 225.1511, total_rewards: 3048.0247, mean_steps: 20.7100, mean_ecr: 0.0391 mean_entropies: 1.0594, took: 92.9826s
2022-10-10 09:27:44,066 [INFO] 	Process 4 - batch 36899: mean_policy_losses: 165.410, mean_net_lifetime: 4316.2683, mean_mc_travel_dist: 1219.0165, mean_rewards: 276.4405, total_rewards: 3119.6742, mean_steps: 14.6100, mean_ecr: 0.0487 mean_entropies: 0.9495, took: 71.2988s
2022-10-10 09:27:54,649 [INFO] 	Process 6 - batch 45799: mean_policy_losses: -288.809, mean_net_lifetime: 3226.3134, mean_mc_travel_dist: 868.3322, mean_rewards: 320.8000, total_rewards: 2381.8498, mean_steps: 9.1200, mean_ecr: 0.0559 mean_entropies: 0.2983, took: 46.1892s
2022-10-10 09:28:02,066 [INFO] 	Process 2 - batch 31199: mean_policy_losses: -6.650, mean_net_lifetime: 4607.9378, mean_mc_travel_dist: 1354.6470, mean_rewards: 249.9668, total_rewards: 3279.2734, mean_steps: 17.5700, mean_ecr: 0.0405 mean_entropies: 0.7166, took: 81.4134s
2022-10-10 09:28:43,183 [INFO] 	Process 6 - batch 45899: mean_policy_losses: -359.826, mean_net_lifetime: 3291.5359, mean_mc_travel_dist: 889.0467, mean_rewards: 312.7518, total_rewards: 2426.5992, mean_steps: 9.6100, mean_ecr: 0.0558 mean_entropies: 0.3080, took: 48.5340s
2022-10-10 09:28:59,877 [INFO] 	Process 4 - batch 36999: mean_policy_losses: 243.483, mean_net_lifetime: 4817.2010, mean_mc_travel_dist: 1369.8243, mean_rewards: 286.6045, total_rewards: 3474.5499, mean_steps: 15.9000, mean_ecr: 0.0473 mean_entropies: 0.8860, took: 75.8107s
2022-10-10 09:29:23,840 [INFO] 	Process 2 - batch 31299: mean_policy_losses: -40.280, mean_net_lifetime: 4502.8263, mean_mc_travel_dist: 1328.4197, mean_rewards: 240.9404, total_rewards: 3199.7764, mean_steps: 17.8400, mean_ecr: 0.0407 mean_entropies: 0.6651, took: 81.7749s
2022-10-10 09:29:31,416 [INFO] 	Process 6 - batch 45999: mean_policy_losses: -233.039, mean_net_lifetime: 3344.9733, mean_mc_travel_dist: 908.1282, mean_rewards: 317.3388, total_rewards: 2471.5355, mean_steps: 9.5700, mean_ecr: 0.0556 mean_entropies: 0.3269, took: 48.2335s
2022-10-10 09:30:18,169 [INFO] 	Process 4 - batch 37099: mean_policy_losses: 251.447, mean_net_lifetime: 4931.6389, mean_mc_travel_dist: 1397.7060, mean_rewards: 281.2373, total_rewards: 3567.5925, mean_steps: 16.6200, mean_ecr: 0.0470 mean_entropies: 0.8760, took: 78.2922s
2022-10-10 09:30:18,266 [INFO] 	Process 6 - batch 46099: mean_policy_losses: -273.571, mean_net_lifetime: 3273.7446, mean_mc_travel_dist: 891.4065, mean_rewards: 320.3457, total_rewards: 2408.6904, mean_steps: 9.2400, mean_ecr: 0.0556 mean_entropies: 0.3308, took: 46.8503s
2022-10-10 09:30:42,323 [INFO] Process 7 - epoch 21: mean_policy_losses: -105.092, mean_net_lifetime: 3908.8185, mean_mc_travel_dist: 1696.4881, mean_entropies: 1.9474, m_net_lifetime_valid: 4256.7091, took: 1918.8061s, (177.3577 / 100 batches)

2022-10-10 09:30:46,385 [INFO] 	Process 2 - batch 31399: mean_policy_losses: -23.902, mean_net_lifetime: 4560.4122, mean_mc_travel_dist: 1358.7336, mean_rewards: 244.0960, total_rewards: 3226.0820, mean_steps: 17.8400, mean_ecr: 0.0407 mean_entropies: 0.6660, took: 82.5451s
2022-10-10 09:31:06,377 [INFO] 	Process 6 - batch 46199: mean_policy_losses: -356.850, mean_net_lifetime: 3303.8901, mean_mc_travel_dist: 886.6220, mean_rewards: 313.5570, total_rewards: 2446.8346, mean_steps: 9.5400, mean_ecr: 0.0558 mean_entropies: 0.2995, took: 48.1108s
2022-10-10 09:31:35,718 [INFO] 	Process 4 - batch 37199: mean_policy_losses: 206.279, mean_net_lifetime: 4721.9671, mean_mc_travel_dist: 1332.0227, mean_rewards: 282.4474, total_rewards: 3427.6426, mean_steps: 15.7800, mean_ecr: 0.0475 mean_entropies: 0.8879, took: 77.5492s
2022-10-10 09:31:52,206 [INFO] 	Process 6 - batch 46299: mean_policy_losses: -321.399, mean_net_lifetime: 3113.8476, mean_mc_travel_dist: 849.5977, mean_rewards: 318.5510, total_rewards: 2294.1696, mean_steps: 8.7900, mean_ecr: 0.0560 mean_entropies: 0.3163, took: 45.8293s
2022-10-10 09:31:59,698 [INFO] 	Process 7 - batch 31599: mean_policy_losses: -492.986, mean_net_lifetime: 4063.4700, mean_mc_travel_dist: 1404.5325, mean_rewards: 239.7464, total_rewards: 2697.9414, mean_steps: 16.4000, mean_ecr: 0.0418 mean_entropies: 1.4890, took: 679.7857s
2022-10-10 09:32:10,313 [INFO] 	Process 2 - batch 31499: mean_policy_losses: 5.645, mean_net_lifetime: 4643.3456, mean_mc_travel_dist: 1348.2284, mean_rewards: 248.7680, total_rewards: 3322.0138, mean_steps: 17.7900, mean_ecr: 0.0407 mean_entropies: 0.6180, took: 83.9282s
2022-10-10 09:32:41,632 [INFO] 	Process 6 - batch 46399: mean_policy_losses: -197.116, mean_net_lifetime: 3401.3092, mean_mc_travel_dist: 910.6166, mean_rewards: 314.8326, total_rewards: 2516.5068, mean_steps: 9.8400, mean_ecr: 0.0555 mean_entropies: 0.3018, took: 49.4246s
2022-10-10 09:32:43,401 [INFO] Process 3 - epoch 21: mean_policy_losses: 124.292, mean_net_lifetime: 3970.9929, mean_mc_travel_dist: 1506.8417, mean_entropies: 1.3807, m_net_lifetime_valid: 4120.2372, took: 1798.7410s, (177.8569 / 100 batches)

2022-10-10 09:32:53,937 [INFO] 	Process 4 - batch 37299: mean_policy_losses: 238.359, mean_net_lifetime: 4914.0466, mean_mc_travel_dist: 1385.9907, mean_rewards: 283.0444, total_rewards: 3558.8111, mean_steps: 16.4700, mean_ecr: 0.0470 mean_entropies: 0.8747, took: 78.2190s
2022-10-10 09:33:16,006 [INFO] 	Process 7 - batch 31699: mean_policy_losses: -435.549, mean_net_lifetime: 4243.4180, mean_mc_travel_dist: 1433.2692, mean_rewards: 242.9967, total_rewards: 2848.0349, mean_steps: 16.9700, mean_ecr: 0.0412 mean_entropies: 1.4517, took: 76.3077s
2022-10-10 09:33:35,174 [INFO] 	Process 6 - batch 46499: mean_policy_losses: -107.526, mean_net_lifetime: 3599.7542, mean_mc_travel_dist: 961.4857, mean_rewards: 312.5899, total_rewards: 2662.2972, mean_steps: 10.4900, mean_ecr: 0.0551 mean_entropies: 0.3058, took: 53.5417s
2022-10-10 09:34:02,426 [INFO] 	Process 3 - batch 31599: mean_policy_losses: -54.166, mean_net_lifetime: 4083.0022, mean_mc_travel_dist: 1104.6743, mean_rewards: 229.0544, total_rewards: 3002.8610, mean_steps: 16.8800, mean_ecr: 0.0492 mean_entropies: 0.6144, took: 644.1604s
2022-10-10 09:34:14,075 [INFO] 	Process 4 - batch 37399: mean_policy_losses: 184.235, mean_net_lifetime: 5057.3822, mean_mc_travel_dist: 1449.4876, mean_rewards: 284.8799, total_rewards: 3633.5810, mean_steps: 16.9300, mean_ecr: 0.0464 mean_entropies: 0.8355, took: 80.1370s
2022-10-10 09:34:39,032 [INFO] 	Process 7 - batch 31799: mean_policy_losses: -429.882, mean_net_lifetime: 4572.3663, mean_mc_travel_dist: 1540.6333, mean_rewards: 232.9404, total_rewards: 3072.5800, mean_steps: 18.9500, mean_ecr: 0.0408 mean_entropies: 1.4217, took: 83.0255s
2022-10-10 09:34:58,116 [INFO] Process 5 - epoch 21: mean_policy_losses: -134.842, mean_net_lifetime: 4407.7100, mean_mc_travel_dist: 2124.0664, mean_entropies: 1.7792, m_net_lifetime_valid: 4384.7720, took: 1907.2601s, (178.2847 / 100 batches)

2022-10-10 09:35:21,866 [INFO] 	Process 3 - batch 31699: mean_policy_losses: -59.408, mean_net_lifetime: 4265.1478, mean_mc_travel_dist: 1171.6514, mean_rewards: 241.0334, total_rewards: 3120.4285, mean_steps: 16.7700, mean_ecr: 0.0488 mean_entropies: 0.6505, took: 79.4404s
2022-10-10 09:35:47,184 [INFO] 	Process 4 - batch 37499: mean_policy_losses: 197.434, mean_net_lifetime: 5585.9364, mean_mc_travel_dist: 1625.9553, mean_rewards: 279.5512, total_rewards: 3982.5976, mean_steps: 19.6400, mean_ecr: 0.0456 mean_entropies: 0.8859, took: 93.1098s
2022-10-10 09:36:11,148 [INFO] 	Process 7 - batch 31899: mean_policy_losses: -362.879, mean_net_lifetime: 4896.2228, mean_mc_travel_dist: 1658.0438, mean_rewards: 232.6735, total_rewards: 3280.3464, mean_steps: 20.6400, mean_ecr: 0.0409 mean_entropies: 1.4723, took: 92.1161s
2022-10-10 09:36:27,991 [INFO] 	Process 5 - batch 31599: mean_policy_losses: -474.527, mean_net_lifetime: 4707.9242, mean_mc_travel_dist: 1680.3835, mean_rewards: 253.3675, total_rewards: 3082.1350, mean_steps: 18.6300, mean_ecr: 0.0290 mean_entropies: 0.9253, took: 655.2149s
2022-10-10 09:36:34,230 [INFO] Process 1 - epoch 18: mean_policy_losses: 56.826, mean_net_lifetime: 4609.7305, mean_mc_travel_dist: 2179.6919, mean_entropies: 1.5460, m_net_lifetime_valid: 4339.3587, took: 2016.7979s, (208.2664 / 100 batches)

2022-10-10 09:36:39,906 [INFO] 	Process 3 - batch 31799: mean_policy_losses: 36.981, mean_net_lifetime: 4440.0337, mean_mc_travel_dist: 1234.3512, mean_rewards: 264.3417, total_rewards: 3228.0760, mean_steps: 15.9000, mean_ecr: 0.0484 mean_entropies: 0.6875, took: 78.0399s
2022-10-10 09:37:34,025 [INFO] 	Process 7 - batch 31999: mean_policy_losses: -304.896, mean_net_lifetime: 4401.2604, mean_mc_travel_dist: 1458.9415, mean_rewards: 229.4209, total_rewards: 2984.3729, mean_steps: 18.4000, mean_ecr: 0.0416 mean_entropies: 1.5385, took: 82.8765s
2022-10-10 09:37:50,978 [INFO] 	Process 5 - batch 31699: mean_policy_losses: -251.222, mean_net_lifetime: 4930.9790, mean_mc_travel_dist: 1672.3390, mean_rewards: 269.5391, total_rewards: 3301.6343, mean_steps: 17.7700, mean_ecr: 0.0306 mean_entropies: 1.0110, took: 82.9867s
2022-10-10 09:37:53,517 [INFO] 	Process 3 - batch 31899: mean_policy_losses: 86.372, mean_net_lifetime: 4501.6410, mean_mc_travel_dist: 1278.8415, mean_rewards: 277.6931, total_rewards: 3247.5914, mean_steps: 15.2700, mean_ecr: 0.0480 mean_entropies: 0.7451, took: 73.6109s
2022-10-10 09:38:17,497 [INFO] 	Process 1 - batch 27099: mean_policy_losses: -34.577, mean_net_lifetime: 4750.5058, mean_mc_travel_dist: 1673.1582, mean_rewards: 204.4858, total_rewards: 3102.7314, mean_steps: 22.7000, mean_ecr: 0.0393 mean_entropies: 0.9894, took: 662.5079s
2022-10-10 09:39:08,231 [INFO] 	Process 7 - batch 32099: mean_policy_losses: -149.114, mean_net_lifetime: 4834.4804, mean_mc_travel_dist: 1607.3900, mean_rewards: 222.5609, total_rewards: 3264.3622, mean_steps: 20.8100, mean_ecr: 0.0410 mean_entropies: 1.5088, took: 94.2068s
2022-10-10 09:39:10,305 [INFO] 	Process 3 - batch 31999: mean_policy_losses: 62.969, mean_net_lifetime: 4454.0643, mean_mc_travel_dist: 1252.2279, mean_rewards: 269.7214, total_rewards: 3241.5834, mean_steps: 15.6000, mean_ecr: 0.0481 mean_entropies: 0.7287, took: 76.7884s
2022-10-10 09:39:15,342 [INFO] 	Process 5 - batch 31799: mean_policy_losses: -176.560, mean_net_lifetime: 5127.5790, mean_mc_travel_dist: 1720.4072, mean_rewards: 271.2870, total_rewards: 3457.3287, mean_steps: 18.0400, mean_ecr: 0.0309 mean_entropies: 0.9826, took: 84.3641s
2022-10-10 09:40:07,483 [INFO] 	Process 1 - batch 27199: mean_policy_losses: -47.427, mean_net_lifetime: 4729.8448, mean_mc_travel_dist: 1673.9317, mean_rewards: 191.8843, total_rewards: 3080.2084, mean_steps: 24.3600, mean_ecr: 0.0394 mean_entropies: 0.9719, took: 109.9855s
2022-10-10 09:40:29,483 [INFO] 	Process 3 - batch 32099: mean_policy_losses: 44.782, mean_net_lifetime: 4515.5272, mean_mc_travel_dist: 1259.0543, mean_rewards: 264.9240, total_rewards: 3295.9933, mean_steps: 16.1200, mean_ecr: 0.0480 mean_entropies: 0.7118, took: 79.1780s
2022-10-10 09:40:45,277 [INFO] 	Process 5 - batch 31899: mean_policy_losses: -140.652, mean_net_lifetime: 5385.8876, mean_mc_travel_dist: 1818.3323, mean_rewards: 273.0271, total_rewards: 3620.3338, mean_steps: 18.8800, mean_ecr: 0.0309 mean_entropies: 0.9811, took: 89.9343s
2022-10-10 09:40:51,153 [INFO] 	Process 7 - batch 32199: mean_policy_losses: -119.623, mean_net_lifetime: 4977.9639, mean_mc_travel_dist: 1650.3563, mean_rewards: 214.5110, total_rewards: 3367.5132, mean_steps: 22.4900, mean_ecr: 0.0411 mean_entropies: 1.4801, took: 102.9174s
2022-10-10 09:41:44,211 [INFO] 	Process 1 - batch 27299: mean_policy_losses: -14.406, mean_net_lifetime: 4668.0934, mean_mc_travel_dist: 1696.5719, mean_rewards: 219.4698, total_rewards: 3004.7366, mean_steps: 20.9500, mean_ecr: 0.0394 mean_entropies: 0.9811, took: 96.7285s
2022-10-10 09:41:46,067 [INFO] 	Process 3 - batch 32199: mean_policy_losses: 40.207, mean_net_lifetime: 4259.2718, mean_mc_travel_dist: 1194.4044, mean_rewards: 257.7894, total_rewards: 3091.0210, mean_steps: 15.5500, mean_ecr: 0.0487 mean_entropies: 0.7267, took: 76.5834s
2022-10-10 09:42:07,990 [INFO] Process 2 - epoch 21: mean_policy_losses: 15.613, mean_net_lifetime: 4038.4099, mean_mc_travel_dist: 1715.5086, mean_entropies: 1.4390, m_net_lifetime_valid: 4271.9931, took: 1865.6702s, (179.5430 / 100 batches)

2022-10-10 09:42:09,822 [INFO] 	Process 5 - batch 31999: mean_policy_losses: -183.094, mean_net_lifetime: 4861.6431, mean_mc_travel_dist: 1616.6323, mean_rewards: 265.5251, total_rewards: 3293.9352, mean_steps: 17.5900, mean_ecr: 0.0313 mean_entropies: 0.9533, took: 84.5459s
2022-10-10 09:42:10,512 [INFO] 	Process 7 - batch 32299: mean_policy_losses: -373.418, mean_net_lifetime: 4000.2344, mean_mc_travel_dist: 1298.4091, mean_rewards: 236.8748, total_rewards: 2738.0203, mean_steps: 16.0000, mean_ecr: 0.0420 mean_entropies: 1.5178, took: 79.3637s
2022-10-10 09:43:08,866 [INFO] 	Process 3 - batch 32299: mean_policy_losses: 69.629, mean_net_lifetime: 4538.1280, mean_mc_travel_dist: 1297.4530, mean_rewards: 270.5250, total_rewards: 3280.3851, mean_steps: 15.8500, mean_ecr: 0.0479 mean_entropies: 0.7782, took: 82.7997s
2022-10-10 09:43:30,334 [INFO] Process 6 - epoch 31: mean_policy_losses: -290.452, mean_net_lifetime: 2403.0694, mean_mc_travel_dist: 962.5269, mean_entropies: 1.0552, m_net_lifetime_valid: 4011.3677, took: 1306.1921s, (121.9311 / 100 batches)

2022-10-10 09:43:37,906 [INFO] 	Process 2 - batch 31599: mean_policy_losses: 3.317, mean_net_lifetime: 4782.1629, mean_mc_travel_dist: 1526.0302, mean_rewards: 252.6988, total_rewards: 3279.5784, mean_steps: 18.0700, mean_ecr: 0.0395 mean_entropies: 0.8956, took: 687.5931s
2022-10-10 09:43:39,609 [INFO] 	Process 1 - batch 27399: mean_policy_losses: 14.839, mean_net_lifetime: 4971.6504, mean_mc_travel_dist: 1759.5644, mean_rewards: 207.7164, total_rewards: 3247.5909, mean_steps: 23.7300, mean_ecr: 0.0391 mean_entropies: 1.0540, took: 115.3989s
2022-10-10 09:43:43,789 [INFO] 	Process 5 - batch 32099: mean_policy_losses: -111.179, mean_net_lifetime: 5378.7814, mean_mc_travel_dist: 1778.4491, mean_rewards: 272.6721, total_rewards: 3648.5677, mean_steps: 18.8100, mean_ecr: 0.0312 mean_entropies: 1.0704, took: 93.9665s
2022-10-10 09:43:51,962 [INFO] 	Process 7 - batch 32399: mean_policy_losses: -167.993, mean_net_lifetime: 4638.5855, mean_mc_travel_dist: 1521.4336, mean_rewards: 215.1945, total_rewards: 3154.0330, mean_steps: 20.7100, mean_ecr: 0.0415 mean_entropies: 1.4996, took: 101.4494s
2022-10-10 09:43:59,511 [INFO] 	Process 6 - batch 46599: mean_policy_losses: -327.296, mean_net_lifetime: 1502.0126, mean_mc_travel_dist: 433.3310, mean_rewards: 280.6262, total_rewards: 1108.7145, mean_steps: 4.3200, mean_ecr: 0.0577 mean_entropies: 0.3763, took: 624.3384s
2022-10-10 09:44:34,233 [INFO] 	Process 3 - batch 32399: mean_policy_losses: 128.019, mean_net_lifetime: 4581.1130, mean_mc_travel_dist: 1292.4423, mean_rewards: 263.9537, total_rewards: 3324.9757, mean_steps: 16.3800, mean_ecr: 0.0480 mean_entropies: 0.7694, took: 85.3669s
2022-10-10 09:44:47,777 [INFO] 	Process 6 - batch 46699: mean_policy_losses: -360.228, mean_net_lifetime: 2948.9701, mean_mc_travel_dist: 801.9551, mean_rewards: 320.7398, total_rewards: 2179.9450, mean_steps: 8.1600, mean_ecr: 0.0560 mean_entropies: 0.3718, took: 48.2659s
2022-10-10 09:45:08,976 [INFO] 	Process 2 - batch 31699: mean_policy_losses: 93.228, mean_net_lifetime: 4707.2907, mean_mc_travel_dist: 1410.1818, mean_rewards: 254.0377, total_rewards: 3325.9105, mean_steps: 17.6700, mean_ecr: 0.0402 mean_entropies: 0.7616, took: 91.0688s
2022-10-10 09:45:13,627 [INFO] 	Process 7 - batch 32499: mean_policy_losses: -466.834, mean_net_lifetime: 3872.0534, mean_mc_travel_dist: 1339.3777, mean_rewards: 233.1967, total_rewards: 2579.0246, mean_steps: 15.9600, mean_ecr: 0.0419 mean_entropies: 1.4614, took: 81.6660s
2022-10-10 09:45:14,063 [INFO] 	Process 5 - batch 32199: mean_policy_losses: -153.226, mean_net_lifetime: 4844.2238, mean_mc_travel_dist: 1630.2482, mean_rewards: 261.3287, total_rewards: 3271.9886, mean_steps: 17.7200, mean_ecr: 0.0313 mean_entropies: 0.9575, took: 90.2746s
2022-10-10 09:45:21,191 [INFO] 	Process 1 - batch 27499: mean_policy_losses: 73.653, mean_net_lifetime: 4787.6377, mean_mc_travel_dist: 1723.5077, mean_rewards: 223.8201, total_rewards: 3086.7436, mean_steps: 20.7200, mean_ecr: 0.0392 mean_entropies: 1.0881, took: 101.5809s
2022-10-10 09:45:22,181 [INFO] Process 4 - epoch 25: mean_policy_losses: 71.495, mean_net_lifetime: 3408.7117, mean_mc_travel_dist: 1274.8506, mean_entropies: 1.6202, m_net_lifetime_valid: 4029.0890, took: 1742.2123s, (151.4688 / 100 batches)

2022-10-10 09:45:41,307 [INFO] 	Process 6 - batch 46799: mean_policy_losses: -245.731, mean_net_lifetime: 3335.8271, mean_mc_travel_dist: 897.0839, mean_rewards: 324.0751, total_rewards: 2467.9647, mean_steps: 9.3100, mean_ecr: 0.0556 mean_entropies: 0.3428, took: 53.5301s
2022-10-10 09:45:56,996 [INFO] 	Process 3 - batch 32499: mean_policy_losses: 2.084, mean_net_lifetime: 4118.4300, mean_mc_travel_dist: 1138.6768, mean_rewards: 248.7707, total_rewards: 3006.8417, mean_steps: 15.5900, mean_ecr: 0.0489 mean_entropies: 0.7164, took: 82.7626s
2022-10-10 09:46:32,679 [INFO] 	Process 6 - batch 46899: mean_policy_losses: -317.430, mean_net_lifetime: 3096.4426, mean_mc_travel_dist: 850.2555, mean_rewards: 319.9211, total_rewards: 2284.8787, mean_steps: 8.6300, mean_ecr: 0.0560 mean_entropies: 0.3545, took: 51.3723s
2022-10-10 09:46:42,385 [INFO] 	Process 2 - batch 31799: mean_policy_losses: 17.893, mean_net_lifetime: 4739.4979, mean_mc_travel_dist: 1412.8637, mean_rewards: 255.4413, total_rewards: 3352.5403, mean_steps: 17.7100, mean_ecr: 0.0403 mean_entropies: 0.6867, took: 93.4094s
2022-10-10 09:46:42,873 [INFO] 	Process 5 - batch 32299: mean_policy_losses: -322.512, mean_net_lifetime: 4570.6724, mean_mc_travel_dist: 1521.4153, mean_rewards: 260.4544, total_rewards: 3092.4908, mean_steps: 16.9800, mean_ecr: 0.0309 mean_entropies: 0.9399, took: 88.8097s
2022-10-10 09:46:45,918 [INFO] 	Process 4 - batch 37599: mean_policy_losses: 148.184, mean_net_lifetime: 4152.7385, mean_mc_travel_dist: 1182.8842, mean_rewards: 256.1377, total_rewards: 2996.3865, mean_steps: 15.2700, mean_ecr: 0.0487 mean_entropies: 0.9905, took: 658.7338s
2022-10-10 09:46:52,514 [INFO] 	Process 7 - batch 32599: mean_policy_losses: -229.389, mean_net_lifetime: 4517.3193, mean_mc_travel_dist: 1475.3151, mean_rewards: 229.3388, total_rewards: 3075.0912, mean_steps: 19.0800, mean_ecr: 0.0414 mean_entropies: 1.4330, took: 98.8869s
2022-10-10 09:47:12,648 [INFO] 	Process 1 - batch 27599: mean_policy_losses: 29.497, mean_net_lifetime: 4929.4132, mean_mc_travel_dist: 1756.3708, mean_rewards: 216.2957, total_rewards: 3203.5608, mean_steps: 22.2700, mean_ecr: 0.0390 mean_entropies: 1.0593, took: 111.4568s
2022-10-10 09:47:16,294 [INFO] 	Process 6 - batch 46999: mean_policy_losses: -335.057, mean_net_lifetime: 2528.5897, mean_mc_travel_dist: 707.9360, mean_rewards: 304.2041, total_rewards: 1868.1274, mean_steps: 7.0900, mean_ecr: 0.0569 mean_entropies: 0.3432, took: 43.6150s
2022-10-10 09:47:24,335 [INFO] 	Process 3 - batch 32599: mean_policy_losses: 35.505, mean_net_lifetime: 4409.8457, mean_mc_travel_dist: 1217.3435, mean_rewards: 255.3229, total_rewards: 3214.7529, mean_steps: 16.3400, mean_ecr: 0.0485 mean_entropies: 0.7088, took: 87.3389s
2022-10-10 09:48:06,923 [INFO] 	Process 6 - batch 47099: mean_policy_losses: -361.994, mean_net_lifetime: 3123.0755, mean_mc_travel_dist: 849.8917, mean_rewards: 328.7922, total_rewards: 2294.1899, mean_steps: 8.5400, mean_ecr: 0.0560 mean_entropies: 0.3397, took: 50.6285s
2022-10-10 09:48:12,316 [INFO] 	Process 4 - batch 37699: mean_policy_losses: 194.123, mean_net_lifetime: 4375.3655, mean_mc_travel_dist: 1237.0561, mean_rewards: 261.2498, total_rewards: 3163.5045, mean_steps: 15.8800, mean_ecr: 0.0482 mean_entropies: 0.9816, took: 86.3986s
2022-10-10 09:48:13,959 [INFO] 	Process 2 - batch 31899: mean_policy_losses: 18.631, mean_net_lifetime: 4677.6488, mean_mc_travel_dist: 1374.9984, mean_rewards: 256.5509, total_rewards: 3323.3514, mean_steps: 17.3800, mean_ecr: 0.0404 mean_entropies: 0.7035, took: 91.5734s
2022-10-10 09:48:15,076 [INFO] 	Process 5 - batch 32399: mean_policy_losses: -258.514, mean_net_lifetime: 4680.1280, mean_mc_travel_dist: 1553.4556, mean_rewards: 258.9736, total_rewards: 3185.6966, mean_steps: 17.7800, mean_ecr: 0.0308 mean_entropies: 0.9485, took: 92.2026s
2022-10-10 09:48:19,568 [INFO] 	Process 7 - batch 32699: mean_policy_losses: -377.447, mean_net_lifetime: 4208.4402, mean_mc_travel_dist: 1376.2818, mean_rewards: 234.5300, total_rewards: 2868.7425, mean_steps: 17.0600, mean_ecr: 0.0417 mean_entropies: 1.4653, took: 87.0532s
2022-10-10 09:48:49,416 [INFO] 	Process 3 - batch 32699: mean_policy_losses: 33.128, mean_net_lifetime: 4377.1282, mean_mc_travel_dist: 1213.7572, mean_rewards: 255.7727, total_rewards: 3184.4069, mean_steps: 16.1700, mean_ecr: 0.0486 mean_entropies: 0.7215, took: 85.0814s
2022-10-10 09:48:51,169 [INFO] 	Process 1 - batch 27699: mean_policy_losses: 2.957, mean_net_lifetime: 4738.7107, mean_mc_travel_dist: 1775.2514, mean_rewards: 234.8348, total_rewards: 2988.3261, mean_steps: 19.5500, mean_ecr: 0.0390 mean_entropies: 1.0047, took: 98.5214s
2022-10-10 09:48:52,943 [INFO] 	Process 6 - batch 47199: mean_policy_losses: -445.293, mean_net_lifetime: 2862.4618, mean_mc_travel_dist: 796.0928, mean_rewards: 323.2511, total_rewards: 2106.3798, mean_steps: 7.8300, mean_ecr: 0.0564 mean_entropies: 0.3620, took: 46.0199s
2022-10-10 09:49:35,837 [INFO] 	Process 4 - batch 37799: mean_policy_losses: 151.531, mean_net_lifetime: 4245.5829, mean_mc_travel_dist: 1221.8013, mean_rewards: 263.8969, total_rewards: 3055.9683, mean_steps: 15.1600, mean_ecr: 0.0488 mean_entropies: 0.9624, took: 83.5208s
2022-10-10 09:49:44,327 [INFO] 	Process 2 - batch 31999: mean_policy_losses: 20.789, mean_net_lifetime: 4709.9502, mean_mc_travel_dist: 1394.7431, mean_rewards: 259.4186, total_rewards: 3337.4924, mean_steps: 17.3200, mean_ecr: 0.0404 mean_entropies: 0.6928, took: 90.3690s
2022-10-10 09:49:45,407 [INFO] 	Process 5 - batch 32499: mean_policy_losses: -256.582, mean_net_lifetime: 4686.2497, mean_mc_travel_dist: 1564.4578, mean_rewards: 254.6871, total_rewards: 3172.0701, mean_steps: 17.6600, mean_ecr: 0.0308 mean_entropies: 0.9570, took: 90.3318s
2022-10-10 09:49:45,618 [INFO] 	Process 6 - batch 47299: mean_policy_losses: -235.087, mean_net_lifetime: 3277.1190, mean_mc_travel_dist: 886.5396, mean_rewards: 325.0783, total_rewards: 2405.6044, mean_steps: 9.0800, mean_ecr: 0.0559 mean_entropies: 0.3273, took: 52.6751s
2022-10-10 09:49:52,664 [INFO] 	Process 7 - batch 32799: mean_policy_losses: -250.930, mean_net_lifetime: 4516.9989, mean_mc_travel_dist: 1475.5438, mean_rewards: 234.0112, total_rewards: 3086.8867, mean_steps: 18.3900, mean_ecr: 0.0413 mean_entropies: 1.4758, took: 93.0961s
2022-10-10 09:50:13,197 [INFO] 	Process 3 - batch 32799: mean_policy_losses: 14.059, mean_net_lifetime: 4267.4986, mean_mc_travel_dist: 1170.7286, mean_rewards: 254.5437, total_rewards: 3130.0270, mean_steps: 15.8200, mean_ecr: 0.0487 mean_entropies: 0.7348, took: 83.7802s
2022-10-10 09:50:30,653 [INFO] 	Process 1 - batch 27799: mean_policy_losses: -21.460, mean_net_lifetime: 4682.6396, mean_mc_travel_dist: 1758.8036, mean_rewards: 229.8392, total_rewards: 2957.7163, mean_steps: 19.8000, mean_ecr: 0.0392 mean_entropies: 1.0288, took: 99.4835s
2022-10-10 09:50:34,499 [INFO] 	Process 6 - batch 47399: mean_policy_losses: -300.447, mean_net_lifetime: 3067.9313, mean_mc_travel_dist: 840.2633, mean_rewards: 325.4726, total_rewards: 2260.2715, mean_steps: 8.3800, mean_ecr: 0.0561 mean_entropies: 0.3406, took: 48.8808s
2022-10-10 09:51:02,422 [INFO] 	Process 4 - batch 37899: mean_policy_losses: 230.802, mean_net_lifetime: 4590.1613, mean_mc_travel_dist: 1294.0676, mean_rewards: 269.7454, total_rewards: 3324.5488, mean_steps: 16.1100, mean_ecr: 0.0479 mean_entropies: 0.9284, took: 86.5855s
2022-10-10 09:51:14,738 [INFO] 	Process 2 - batch 32099: mean_policy_losses: 26.106, mean_net_lifetime: 4701.2931, mean_mc_travel_dist: 1377.0897, mean_rewards: 260.1672, total_rewards: 3350.5940, mean_steps: 17.2000, mean_ecr: 0.0405 mean_entropies: 0.6980, took: 90.4106s
2022-10-10 09:51:20,226 [INFO] 	Process 5 - batch 32599: mean_policy_losses: -211.203, mean_net_lifetime: 4868.9628, mean_mc_travel_dist: 1674.9074, mean_rewards: 255.6180, total_rewards: 3258.8417, mean_steps: 18.4900, mean_ecr: 0.0302 mean_entropies: 0.9578, took: 94.8183s
2022-10-10 09:51:21,808 [INFO] 	Process 6 - batch 47499: mean_policy_losses: -388.663, mean_net_lifetime: 2937.5035, mean_mc_travel_dist: 807.1921, mean_rewards: 328.3040, total_rewards: 2166.9346, mean_steps: 7.9300, mean_ecr: 0.0564 mean_entropies: 0.3649, took: 47.3089s
2022-10-10 09:51:21,954 [INFO] 	Process 7 - batch 32899: mean_policy_losses: -347.379, mean_net_lifetime: 4209.1453, mean_mc_travel_dist: 1406.6415, mean_rewards: 231.4675, total_rewards: 2843.0847, mean_steps: 17.4600, mean_ecr: 0.0415 mean_entropies: 1.4680, took: 89.2900s
2022-10-10 09:51:34,812 [INFO] 	Process 3 - batch 32899: mean_policy_losses: 39.338, mean_net_lifetime: 4406.4402, mean_mc_travel_dist: 1209.5261, mean_rewards: 266.2124, total_rewards: 3220.1039, mean_steps: 15.6400, mean_ecr: 0.0485 mean_entropies: 0.7280, took: 81.6121s
2022-10-10 09:52:10,588 [INFO] 	Process 1 - batch 27899: mean_policy_losses: -31.152, mean_net_lifetime: 4700.2486, mean_mc_travel_dist: 1777.2060, mean_rewards: 228.7502, total_rewards: 2959.7528, mean_steps: 20.0300, mean_ecr: 0.0391 mean_entropies: 0.9714, took: 99.9352s
2022-10-10 09:52:16,283 [INFO] 	Process 6 - batch 47599: mean_policy_losses: -133.362, mean_net_lifetime: 3459.5817, mean_mc_travel_dist: 941.6561, mean_rewards: 326.7026, total_rewards: 2548.9028, mean_steps: 9.6000, mean_ecr: 0.0559 mean_entropies: 0.3106, took: 54.4759s
2022-10-10 09:52:29,927 [INFO] 	Process 4 - batch 37999: mean_policy_losses: 236.120, mean_net_lifetime: 4605.4137, mean_mc_travel_dist: 1296.5228, mean_rewards: 266.1263, total_rewards: 3340.3276, mean_steps: 16.3700, mean_ecr: 0.0477 mean_entropies: 0.9397, took: 87.5030s
2022-10-10 09:52:45,491 [INFO] 	Process 7 - batch 32999: mean_policy_losses: -400.731, mean_net_lifetime: 4014.6718, mean_mc_travel_dist: 1366.5840, mean_rewards: 236.9633, total_rewards: 2694.0353, mean_steps: 16.3000, mean_ecr: 0.0418 mean_entropies: 1.4682, took: 83.5367s
2022-10-10 09:52:46,133 [INFO] 	Process 2 - batch 32199: mean_policy_losses: 16.091, mean_net_lifetime: 4630.6356, mean_mc_travel_dist: 1363.1736, mean_rewards: 255.2885, total_rewards: 3290.4256, mean_steps: 17.2800, mean_ecr: 0.0405 mean_entropies: 0.6650, took: 91.3950s
2022-10-10 09:52:50,309 [INFO] 	Process 5 - batch 32699: mean_policy_losses: -313.531, mean_net_lifetime: 4561.7615, mean_mc_travel_dist: 1542.4564, mean_rewards: 251.9173, total_rewards: 3074.2415, mean_steps: 17.6300, mean_ecr: 0.0303 mean_entropies: 0.9405, took: 90.0827s
2022-10-10 09:52:59,782 [INFO] 	Process 3 - batch 32999: mean_policy_losses: 57.132, mean_net_lifetime: 4404.0781, mean_mc_travel_dist: 1212.9626, mean_rewards: 257.0525, total_rewards: 3215.2896, mean_steps: 16.2000, mean_ecr: 0.0485 mean_entropies: 0.7004, took: 84.9735s
2022-10-10 09:53:03,211 [INFO] 	Process 6 - batch 47699: mean_policy_losses: -250.704, mean_net_lifetime: 2969.7490, mean_mc_travel_dist: 821.7867, mean_rewards: 327.0274, total_rewards: 2187.9740, mean_steps: 8.1600, mean_ecr: 0.0558 mean_entropies: 0.3588, took: 46.9272s
2022-10-10 09:53:45,099 [INFO] 	Process 1 - batch 27999: mean_policy_losses: -30.535, mean_net_lifetime: 4748.6978, mean_mc_travel_dist: 1802.8428, mean_rewards: 236.4419, total_rewards: 2981.6538, mean_steps: 19.4900, mean_ecr: 0.0390 mean_entropies: 0.9761, took: 94.5113s
2022-10-10 09:53:49,328 [INFO] 	Process 4 - batch 38099: mean_policy_losses: 210.892, mean_net_lifetime: 4356.1734, mean_mc_travel_dist: 1243.0775, mean_rewards: 265.2949, total_rewards: 3146.2639, mean_steps: 15.5400, mean_ecr: 0.0484 mean_entropies: 0.9724, took: 79.4023s
2022-10-10 09:53:50,345 [INFO] 	Process 6 - batch 47799: mean_policy_losses: -408.902, mean_net_lifetime: 3057.5556, mean_mc_travel_dist: 829.6955, mean_rewards: 323.0943, total_rewards: 2252.5047, mean_steps: 8.5800, mean_ecr: 0.0560 mean_entropies: 0.3373, took: 47.1348s
2022-10-10 09:54:10,112 [INFO] 	Process 2 - batch 32299: mean_policy_losses: 31.023, mean_net_lifetime: 4710.1515, mean_mc_travel_dist: 1392.4458, mean_rewards: 264.2644, total_rewards: 3344.7179, mean_steps: 16.9500, mean_ecr: 0.0403 mean_entropies: 0.7265, took: 83.9792s
2022-10-10 09:54:18,071 [INFO] 	Process 5 - batch 32799: mean_policy_losses: -251.533, mean_net_lifetime: 4890.3713, mean_mc_travel_dist: 1644.6211, mean_rewards: 259.9879, total_rewards: 3298.6382, mean_steps: 18.2300, mean_ecr: 0.0308 mean_entropies: 0.9828, took: 87.7624s
2022-10-10 09:54:37,618 [INFO] 	Process 6 - batch 47899: mean_policy_losses: -273.287, mean_net_lifetime: 3095.7061, mean_mc_travel_dist: 844.3283, mean_rewards: 325.0474, total_rewards: 2280.3442, mean_steps: 8.5700, mean_ecr: 0.0559 mean_entropies: 0.3205, took: 47.2724s
2022-10-10 09:55:06,413 [INFO] 	Process 4 - batch 38199: mean_policy_losses: 218.919, mean_net_lifetime: 4366.3734, mean_mc_travel_dist: 1233.3014, mean_rewards: 272.0309, total_rewards: 3157.6302, mean_steps: 15.1400, mean_ecr: 0.0484 mean_entropies: 0.9655, took: 77.0853s
2022-10-10 09:55:24,346 [INFO] 	Process 1 - batch 28099: mean_policy_losses: 16.371, mean_net_lifetime: 4850.5803, mean_mc_travel_dist: 1796.2151, mean_rewards: 225.0212, total_rewards: 3088.3886, mean_steps: 20.9400, mean_ecr: 0.0391 mean_entropies: 1.0142, took: 99.2470s
2022-10-10 09:55:26,695 [INFO] 	Process 6 - batch 47999: mean_policy_losses: -227.986, mean_net_lifetime: 3218.7832, mean_mc_travel_dist: 868.6876, mean_rewards: 327.1692, total_rewards: 2380.6435, mean_steps: 8.9900, mean_ecr: 0.0555 mean_entropies: 0.3452, took: 49.0770s
2022-10-10 09:55:33,027 [INFO] 	Process 2 - batch 32399: mean_policy_losses: 12.551, mean_net_lifetime: 4687.1044, mean_mc_travel_dist: 1359.2241, mean_rewards: 263.9601, total_rewards: 3343.1166, mean_steps: 16.9200, mean_ecr: 0.0406 mean_entropies: 0.7087, took: 82.9156s
2022-10-10 09:55:41,773 [INFO] 	Process 5 - batch 32899: mean_policy_losses: -415.349, mean_net_lifetime: 4661.7543, mean_mc_travel_dist: 1594.1626, mean_rewards: 260.4497, total_rewards: 3150.8988, mean_steps: 17.4800, mean_ecr: 0.0302 mean_entropies: 0.9655, took: 83.7018s
2022-10-10 09:56:19,535 [INFO] 	Process 4 - batch 38299: mean_policy_losses: 132.007, mean_net_lifetime: 4283.8052, mean_mc_travel_dist: 1213.9962, mean_rewards: 267.1921, total_rewards: 3099.5688, mean_steps: 15.0400, mean_ecr: 0.0487 mean_entropies: 0.9736, took: 73.1214s
2022-10-10 09:56:51,804 [INFO] 	Process 2 - batch 32499: mean_policy_losses: -5.560, mean_net_lifetime: 4695.7615, mean_mc_travel_dist: 1378.6507, mean_rewards: 267.6049, total_rewards: 3339.8681, mean_steps: 16.6800, mean_ecr: 0.0405 mean_entropies: 0.7644, took: 78.7768s
2022-10-10 09:56:54,209 [INFO] 	Process 1 - batch 28199: mean_policy_losses: -33.441, mean_net_lifetime: 4899.2852, mean_mc_travel_dist: 1795.6890, mean_rewards: 239.8512, total_rewards: 3136.2097, mean_steps: 19.6700, mean_ecr: 0.0391 mean_entropies: 1.0704, took: 89.8626s
2022-10-10 09:57:06,002 [INFO] 	Process 5 - batch 32999: mean_policy_losses: -329.040, mean_net_lifetime: 4830.3007, mean_mc_travel_dist: 1629.6019, mean_rewards: 260.7013, total_rewards: 3260.1959, mean_steps: 17.9300, mean_ecr: 0.0304 mean_entropies: 1.0354, took: 84.2287s
2022-10-10 09:57:31,656 [INFO] 	Process 4 - batch 38399: mean_policy_losses: 156.018, mean_net_lifetime: 4339.1968, mean_mc_travel_dist: 1236.3606, mean_rewards: 275.9754, total_rewards: 3138.8658, mean_steps: 14.7000, mean_ecr: 0.0488 mean_entropies: 0.9789, took: 72.1216s
2022-10-10 09:58:08,296 [INFO] 	Process 2 - batch 32599: mean_policy_losses: -31.933, mean_net_lifetime: 4704.2600, mean_mc_travel_dist: 1414.5190, mean_rewards: 266.7663, total_rewards: 3315.1415, mean_steps: 16.8100, mean_ecr: 0.0403 mean_entropies: 0.7900, took: 76.4921s
2022-10-10 09:58:23,268 [INFO] 	Process 1 - batch 28299: mean_policy_losses: -54.156, mean_net_lifetime: 4929.9482, mean_mc_travel_dist: 1789.8247, mean_rewards: 236.2226, total_rewards: 3169.5699, mean_steps: 20.4600, mean_ecr: 0.0391 mean_entropies: 1.0812, took: 89.0589s
2022-10-10 09:58:43,908 [INFO] 	Process 4 - batch 38499: mean_policy_losses: 152.990, mean_net_lifetime: 4511.7172, mean_mc_travel_dist: 1277.9253, mean_rewards: 279.6213, total_rewards: 3266.9774, mean_steps: 15.1500, mean_ecr: 0.0481 mean_entropies: 0.9566, took: 72.2518s
2022-10-10 09:59:26,167 [INFO] 	Process 2 - batch 32699: mean_policy_losses: -36.289, mean_net_lifetime: 4701.7776, mean_mc_travel_dist: 1363.4471, mean_rewards: 268.6978, total_rewards: 3363.7149, mean_steps: 16.5900, mean_ecr: 0.0405 mean_entropies: 0.7711, took: 77.8712s
2022-10-10 09:59:51,958 [INFO] 	Process 1 - batch 28399: mean_policy_losses: -98.471, mean_net_lifetime: 4917.4923, mean_mc_travel_dist: 1831.0380, mean_rewards: 246.5359, total_rewards: 3115.9609, mean_steps: 19.1600, mean_ecr: 0.0390 mean_entropies: 1.1119, took: 88.6905s
2022-10-10 10:00:02,252 [INFO] 	Process 4 - batch 38599: mean_policy_losses: 152.441, mean_net_lifetime: 4655.6060, mean_mc_travel_dist: 1317.0516, mean_rewards: 276.3427, total_rewards: 3366.0235, mean_steps: 15.9200, mean_ecr: 0.0479 mean_entropies: 0.9569, took: 78.3440s
2022-10-10 10:00:45,929 [INFO] 	Process 2 - batch 32799: mean_policy_losses: -33.810, mean_net_lifetime: 4719.4173, mean_mc_travel_dist: 1364.1815, mean_rewards: 271.0945, total_rewards: 3385.4777, mean_steps: 16.5300, mean_ecr: 0.0406 mean_entropies: 0.7598, took: 79.7607s
2022-10-10 10:01:20,563 [INFO] 	Process 4 - batch 38699: mean_policy_losses: 170.657, mean_net_lifetime: 4825.1252, mean_mc_travel_dist: 1384.3596, mean_rewards: 287.4924, total_rewards: 3462.7535, mean_steps: 15.8800, mean_ecr: 0.0473 mean_entropies: 0.8848, took: 78.3110s
2022-10-10 10:01:34,503 [INFO] 	Process 1 - batch 28499: mean_policy_losses: -66.617, mean_net_lifetime: 4871.3707, mean_mc_travel_dist: 1786.7591, mean_rewards: 241.3978, total_rewards: 3116.8036, mean_steps: 19.4700, mean_ecr: 0.0391 mean_entropies: 1.0780, took: 102.5419s
2022-10-10 10:02:03,919 [INFO] 	Process 2 - batch 32899: mean_policy_losses: -52.284, mean_net_lifetime: 4673.0329, mean_mc_travel_dist: 1383.8636, mean_rewards: 262.5679, total_rewards: 3317.5330, mean_steps: 16.9700, mean_ecr: 0.0404 mean_entropies: 0.7553, took: 77.9905s
2022-10-10 10:02:21,166 [INFO] Process 3 - epoch 22: mean_policy_losses: 120.269, mean_net_lifetime: 3989.3458, mean_mc_travel_dist: 1493.6462, mean_entropies: 1.3504, m_net_lifetime_valid: 4163.1177, took: 1777.7632s, (175.1791 / 100 batches)

2022-10-10 10:02:37,003 [INFO] 	Process 4 - batch 38799: mean_policy_losses: 163.613, mean_net_lifetime: 4926.0163, mean_mc_travel_dist: 1443.2104, mean_rewards: 281.7960, total_rewards: 3515.3429, mean_steps: 16.6400, mean_ecr: 0.0472 mean_entropies: 0.8906, took: 76.4399s
2022-10-10 10:03:07,362 [INFO] Process 7 - epoch 22: mean_policy_losses: -115.191, mean_net_lifetime: 3931.0438, mean_mc_travel_dist: 1686.0803, mean_entropies: 1.9260, m_net_lifetime_valid: 4214.8484, took: 1945.0370s, (175.1378 / 100 batches)

2022-10-10 10:03:18,385 [INFO] 	Process 2 - batch 32999: mean_policy_losses: -70.795, mean_net_lifetime: 4677.1835, mean_mc_travel_dist: 1381.6573, mean_rewards: 272.2542, total_rewards: 3328.8917, mean_steps: 16.3200, mean_ecr: 0.0404 mean_entropies: 0.7698, took: 74.4657s
2022-10-10 10:03:42,740 [INFO] 	Process 3 - batch 33099: mean_policy_losses: -47.332, mean_net_lifetime: 4428.3490, mean_mc_travel_dist: 1248.2158, mean_rewards: 272.0359, total_rewards: 3207.6955, mean_steps: 15.3200, mean_ecr: 0.0484 mean_entropies: 0.7495, took: 642.9582s
2022-10-10 10:03:57,027 [INFO] 	Process 4 - batch 38899: mean_policy_losses: 217.726, mean_net_lifetime: 5169.8823, mean_mc_travel_dist: 1488.7966, mean_rewards: 283.6040, total_rewards: 3708.2771, mean_steps: 17.5400, mean_ecr: 0.0463 mean_entropies: 0.8663, took: 80.0242s
2022-10-10 10:04:14,853 [INFO] 	Process 7 - batch 33099: mean_policy_losses: -692.909, mean_net_lifetime: 3908.5766, mean_mc_travel_dist: 1327.7623, mean_rewards: 251.8890, total_rewards: 2630.6524, mean_steps: 14.8800, mean_ecr: 0.0418 mean_entropies: 1.4935, took: 689.3620s
2022-10-10 10:05:03,918 [INFO] 	Process 3 - batch 33199: mean_policy_losses: -54.203, mean_net_lifetime: 4404.2662, mean_mc_travel_dist: 1229.5954, mean_rewards: 267.6759, total_rewards: 3196.1751, mean_steps: 15.4900, mean_ecr: 0.0484 mean_entropies: 0.7050, took: 81.1727s
2022-10-10 10:05:18,664 [INFO] 	Process 4 - batch 38999: mean_policy_losses: 134.940, mean_net_lifetime: 5098.9203, mean_mc_travel_dist: 1472.6006, mean_rewards: 278.2578, total_rewards: 3650.1205, mean_steps: 17.5700, mean_ecr: 0.0467 mean_entropies: 0.8913, took: 81.6369s
2022-10-10 10:05:33,465 [INFO] 	Process 7 - batch 33199: mean_policy_losses: -590.262, mean_net_lifetime: 4337.2752, mean_mc_travel_dist: 1471.2553, mean_rewards: 232.8979, total_rewards: 2913.1172, mean_steps: 18.0900, mean_ecr: 0.0416 mean_entropies: 1.4946, took: 78.6121s
2022-10-10 10:05:47,484 [INFO] Process 6 - epoch 32: mean_policy_losses: -290.983, mean_net_lifetime: 2420.6429, mean_mc_travel_dist: 957.8161, mean_entropies: 1.0330, m_net_lifetime_valid: 4661.2868, took: 1337.1479s, (120.8553 / 100 batches)

2022-10-10 10:06:23,894 [INFO] 	Process 3 - batch 33299: mean_policy_losses: -11.614, mean_net_lifetime: 4352.8907, mean_mc_travel_dist: 1223.3587, mean_rewards: 263.3242, total_rewards: 3164.0232, mean_steps: 15.6100, mean_ecr: 0.0485 mean_entropies: 0.6877, took: 79.9810s
2022-10-10 10:06:33,263 [INFO] 	Process 6 - batch 48099: mean_policy_losses: -259.242, mean_net_lifetime: 2815.0198, mean_mc_travel_dist: 778.2980, mean_rewards: 320.4695, total_rewards: 2074.2741, mean_steps: 7.7400, mean_ecr: 0.0564 mean_entropies: 0.3103, took: 666.5672s
2022-10-10 10:06:47,381 [INFO] 	Process 7 - batch 33299: mean_policy_losses: -305.670, mean_net_lifetime: 4262.9325, mean_mc_travel_dist: 1494.4810, mean_rewards: 238.4248, total_rewards: 2816.3981, mean_steps: 17.2300, mean_ecr: 0.0414 mean_entropies: 1.4380, took: 73.9162s
2022-10-10 10:07:14,765 [INFO] Process 5 - epoch 22: mean_policy_losses: -140.376, mean_net_lifetime: 4428.5330, mean_mc_travel_dist: 2102.1903, mean_entropies: 1.7426, m_net_lifetime_valid: 4577.7798, took: 1936.6469s, (175.9250 / 100 batches)

2022-10-10 10:07:27,805 [INFO] 	Process 6 - batch 48199: mean_policy_losses: -239.887, mean_net_lifetime: 3368.4941, mean_mc_travel_dist: 904.6105, mean_rewards: 320.1013, total_rewards: 2482.4642, mean_steps: 9.5300, mean_ecr: 0.0557 mean_entropies: 0.2830, took: 54.5427s
2022-10-10 10:07:47,233 [INFO] 	Process 3 - batch 33399: mean_policy_losses: 7.151, mean_net_lifetime: 4021.4755, mean_mc_travel_dist: 1111.1103, mean_rewards: 241.8817, total_rewards: 2939.1747, mean_steps: 15.6700, mean_ecr: 0.0493 mean_entropies: 0.6704, took: 83.3380s
2022-10-10 10:08:10,414 [INFO] 	Process 7 - batch 33399: mean_policy_losses: -142.855, mean_net_lifetime: 4509.8491, mean_mc_travel_dist: 1493.7334, mean_rewards: 233.4344, total_rewards: 3056.2842, mean_steps: 18.6000, mean_ecr: 0.0413 mean_entropies: 1.4063, took: 83.0330s
2022-10-10 10:08:23,939 [INFO] 	Process 6 - batch 48299: mean_policy_losses: -297.499, mean_net_lifetime: 3308.3850, mean_mc_travel_dist: 884.8635, mean_rewards: 321.1695, total_rewards: 2447.2187, mean_steps: 9.3200, mean_ecr: 0.0559 mean_entropies: 0.2651, took: 56.1335s
2022-10-10 10:08:36,712 [INFO] 	Process 5 - batch 33099: mean_policy_losses: -346.290, mean_net_lifetime: 4048.3785, mean_mc_travel_dist: 1308.6335, mean_rewards: 255.9811, total_rewards: 2790.2853, mean_steps: 15.4400, mean_ecr: 0.0306 mean_entropies: 0.8514, took: 690.7099s
2022-10-10 10:09:17,000 [INFO] 	Process 3 - batch 33499: mean_policy_losses: 13.879, mean_net_lifetime: 4001.4890, mean_mc_travel_dist: 1092.3708, mean_rewards: 228.5510, total_rewards: 2930.9992, mean_steps: 16.6400, mean_ecr: 0.0493 mean_entropies: 0.6337, took: 89.7675s
2022-10-10 10:09:21,884 [INFO] 	Process 6 - batch 48399: mean_policy_losses: -125.738, mean_net_lifetime: 3456.7495, mean_mc_travel_dist: 934.0817, mean_rewards: 320.0654, total_rewards: 2557.1198, mean_steps: 9.8100, mean_ecr: 0.0558 mean_entropies: 0.2810, took: 57.9451s
2022-10-10 10:09:38,766 [INFO] 	Process 7 - batch 33499: mean_policy_losses: -122.462, mean_net_lifetime: 4548.6165, mean_mc_travel_dist: 1490.3108, mean_rewards: 222.4315, total_rewards: 3101.0856, mean_steps: 19.6100, mean_ecr: 0.0412 mean_entropies: 1.3717, took: 88.3528s
2022-10-10 10:10:00,115 [INFO] 	Process 5 - batch 33199: mean_policy_losses: -374.461, mean_net_lifetime: 4118.2266, mean_mc_travel_dist: 1372.5990, mean_rewards: 255.0914, total_rewards: 2805.5161, mean_steps: 15.7700, mean_ecr: 0.0304 mean_entropies: 0.8446, took: 83.4028s
2022-10-10 10:10:18,606 [INFO] 	Process 6 - batch 48499: mean_policy_losses: -195.952, mean_net_lifetime: 3417.7684, mean_mc_travel_dist: 916.7612, mean_rewards: 322.6729, total_rewards: 2527.7892, mean_steps: 9.6400, mean_ecr: 0.0557 mean_entropies: 0.2767, took: 56.7213s
2022-10-10 10:10:47,122 [INFO] 	Process 3 - batch 33599: mean_policy_losses: 10.811, mean_net_lifetime: 4021.2049, mean_mc_travel_dist: 1090.5463, mean_rewards: 225.4017, total_rewards: 2961.5149, mean_steps: 16.9200, mean_ecr: 0.0493 mean_entropies: 0.6236, took: 90.1212s
2022-10-10 10:11:12,963 [INFO] 	Process 7 - batch 33599: mean_policy_losses: -63.509, mean_net_lifetime: 4760.0509, mean_mc_travel_dist: 1585.4764, mean_rewards: 220.2174, total_rewards: 3210.9809, mean_steps: 21.1500, mean_ecr: 0.0410 mean_entropies: 1.3547, took: 94.1953s
2022-10-10 10:11:15,614 [INFO] 	Process 6 - batch 48599: mean_policy_losses: -156.745, mean_net_lifetime: 3362.8584, mean_mc_travel_dist: 913.4319, mean_rewards: 323.3530, total_rewards: 2482.2345, mean_steps: 9.3700, mean_ecr: 0.0558 mean_entropies: 0.2894, took: 57.0079s
2022-10-10 10:11:38,818 [INFO] 	Process 5 - batch 33299: mean_policy_losses: -127.018, mean_net_lifetime: 5144.9759, mean_mc_travel_dist: 1733.6843, mean_rewards: 259.6867, total_rewards: 3456.1943, mean_steps: 19.0300, mean_ecr: 0.0312 mean_entropies: 0.8467, took: 98.7033s
2022-10-10 10:11:48,818 [INFO] Process 1 - epoch 19: mean_policy_losses: 52.800, mean_net_lifetime: 4620.3627, mean_mc_travel_dist: 2157.5914, mean_entropies: 1.5189, m_net_lifetime_valid: 4123.6515, took: 2114.5866s, (204.5444 / 100 batches)

2022-10-10 10:12:14,352 [INFO] 	Process 6 - batch 48699: mean_policy_losses: -96.116, mean_net_lifetime: 3538.6749, mean_mc_travel_dist: 942.2369, mean_rewards: 330.0432, total_rewards: 2616.4435, mean_steps: 9.7600, mean_ecr: 0.0556 mean_entropies: 0.2943, took: 58.7395s
2022-10-10 10:12:15,446 [INFO] 	Process 3 - batch 33699: mean_policy_losses: 13.381, mean_net_lifetime: 4136.5430, mean_mc_travel_dist: 1140.8178, mean_rewards: 241.1870, total_rewards: 3019.3137, mean_steps: 16.2300, mean_ecr: 0.0490 mean_entropies: 0.7020, took: 88.3251s
2022-10-10 10:12:22,195 [INFO] Process 2 - epoch 22: mean_policy_losses: 14.931, mean_net_lifetime: 4068.5342, mean_mc_travel_dist: 1700.8554, mean_entropies: 1.4073, m_net_lifetime_valid: 4243.3094, took: 1814.2039s, (177.0504 / 100 batches)

2022-10-10 10:12:39,502 [INFO] 	Process 7 - batch 33699: mean_policy_losses: -269.616, mean_net_lifetime: 4145.0513, mean_mc_travel_dist: 1387.9245, mean_rewards: 218.6459, total_rewards: 2800.4116, mean_steps: 18.1800, mean_ecr: 0.0416 mean_entropies: 1.3995, took: 86.5392s
2022-10-10 10:13:04,328 [INFO] 	Process 6 - batch 48799: mean_policy_losses: -232.766, mean_net_lifetime: 3270.5697, mean_mc_travel_dist: 888.0887, mean_rewards: 327.1503, total_rewards: 2413.9493, mean_steps: 9.0200, mean_ecr: 0.0556 mean_entropies: 0.3526, took: 49.9763s
2022-10-10 10:13:15,385 [INFO] 	Process 5 - batch 33399: mean_policy_losses: -95.966, mean_net_lifetime: 5176.5167, mean_mc_travel_dist: 1756.1662, mean_rewards: 263.8699, total_rewards: 3472.0366, mean_steps: 18.7100, mean_ecr: 0.0315 mean_entropies: 0.8916, took: 96.5670s
2022-10-10 10:13:37,612 [INFO] 	Process 3 - batch 33799: mean_policy_losses: 23.614, mean_net_lifetime: 4298.6222, mean_mc_travel_dist: 1191.6407, mean_rewards: 252.0716, total_rewards: 3136.8717, mean_steps: 16.0900, mean_ecr: 0.0486 mean_entropies: 0.7095, took: 82.1669s
2022-10-10 10:13:39,995 [INFO] 	Process 1 - batch 28599: mean_policy_losses: 95.331, mean_net_lifetime: 5062.1117, mean_mc_travel_dist: 1770.7012, mean_rewards: 220.2534, total_rewards: 3315.0823, mean_steps: 22.5000, mean_ecr: 0.0390 mean_entropies: 1.0295, took: 725.4949s
2022-10-10 10:13:50,486 [INFO] 	Process 2 - batch 33099: mean_policy_losses: 17.377, mean_net_lifetime: 4716.7711, mean_mc_travel_dist: 1397.8052, mean_rewards: 258.6904, total_rewards: 3339.4549, mean_steps: 17.4200, mean_ecr: 0.0402 mean_entropies: 0.7102, took: 632.1021s
2022-10-10 10:13:50,951 [INFO] 	Process 6 - batch 48899: mean_policy_losses: -257.744, mean_net_lifetime: 3008.3353, mean_mc_travel_dist: 822.4612, mean_rewards: 324.9835, total_rewards: 2225.9157, mean_steps: 8.1900, mean_ecr: 0.0564 mean_entropies: 0.3535, took: 46.6225s
2022-10-10 10:14:17,233 [INFO] 	Process 7 - batch 33799: mean_policy_losses: -128.221, mean_net_lifetime: 4773.8384, mean_mc_travel_dist: 1589.9084, mean_rewards: 227.2466, total_rewards: 3219.1209, mean_steps: 20.3400, mean_ecr: 0.0413 mean_entropies: 1.4066, took: 97.7318s
2022-10-10 10:14:25,830 [INFO] Process 4 - epoch 26: mean_policy_losses: 75.594, mean_net_lifetime: 3453.2538, mean_mc_travel_dist: 1275.9282, mean_entropies: 1.5941, m_net_lifetime_valid: 4078.6168, took: 1743.6475s, (150.1886 / 100 batches)

2022-10-10 10:14:39,519 [INFO] 	Process 6 - batch 48999: mean_policy_losses: -361.446, mean_net_lifetime: 3091.5953, mean_mc_travel_dist: 841.6316, mean_rewards: 327.8366, total_rewards: 2275.3981, mean_steps: 8.4300, mean_ecr: 0.0561 mean_entropies: 0.3348, took: 48.5671s
2022-10-10 10:14:52,317 [INFO] 	Process 5 - batch 33499: mean_policy_losses: -103.804, mean_net_lifetime: 5305.4974, mean_mc_travel_dist: 1787.9706, mean_rewards: 262.4510, total_rewards: 3570.9347, mean_steps: 19.3800, mean_ecr: 0.0312 mean_entropies: 0.9315, took: 96.9328s
2022-10-10 10:14:57,864 [INFO] 	Process 3 - batch 33899: mean_policy_losses: 19.346, mean_net_lifetime: 4241.5537, mean_mc_travel_dist: 1183.9494, mean_rewards: 259.5698, total_rewards: 3085.5192, mean_steps: 15.4100, mean_ecr: 0.0488 mean_entropies: 0.7304, took: 80.2516s
2022-10-10 10:15:19,867 [INFO] 	Process 2 - batch 33199: mean_policy_losses: 2.726, mean_net_lifetime: 4649.6265, mean_mc_travel_dist: 1358.4172, mean_rewards: 253.3820, total_rewards: 3313.6984, mean_steps: 17.4600, mean_ecr: 0.0405 mean_entropies: 0.6798, took: 89.3802s
2022-10-10 10:15:20,749 [INFO] 	Process 1 - batch 28699: mean_policy_losses: 39.089, mean_net_lifetime: 4880.8754, mean_mc_travel_dist: 1777.5287, mean_rewards: 232.0253, total_rewards: 3129.0049, mean_steps: 20.3000, mean_ecr: 0.0391 mean_entropies: 1.0412, took: 100.7544s
2022-10-10 10:15:35,444 [INFO] 	Process 6 - batch 49099: mean_policy_losses: -224.083, mean_net_lifetime: 3436.4092, mean_mc_travel_dist: 920.7094, mean_rewards: 321.9440, total_rewards: 2535.8295, mean_steps: 9.6900, mean_ecr: 0.0559 mean_entropies: 0.2795, took: 55.9255s
2022-10-10 10:15:44,474 [INFO] 	Process 4 - batch 39099: mean_policy_losses: 114.873, mean_net_lifetime: 3996.8603, mean_mc_travel_dist: 1134.6035, mean_rewards: 261.7123, total_rewards: 2892.6938, mean_steps: 14.3200, mean_ecr: 0.0488 mean_entropies: 0.9678, took: 625.8106s
2022-10-10 10:15:50,094 [INFO] 	Process 7 - batch 33899: mean_policy_losses: -270.354, mean_net_lifetime: 4405.6007, mean_mc_travel_dist: 1487.4742, mean_rewards: 231.9742, total_rewards: 2954.1678, mean_steps: 18.3500, mean_ecr: 0.0414 mean_entropies: 1.3772, took: 92.8617s
2022-10-10 10:16:20,221 [INFO] 	Process 3 - batch 33999: mean_policy_losses: 10.272, mean_net_lifetime: 4264.4708, mean_mc_travel_dist: 1173.1885, mean_rewards: 260.0078, total_rewards: 3108.7316, mean_steps: 15.4600, mean_ecr: 0.0489 mean_entropies: 0.6865, took: 82.3573s
2022-10-10 10:16:23,793 [INFO] 	Process 6 - batch 49199: mean_policy_losses: -310.306, mean_net_lifetime: 3020.5231, mean_mc_travel_dist: 835.1510, mean_rewards: 331.2762, total_rewards: 2221.5066, mean_steps: 8.0900, mean_ecr: 0.0563 mean_entropies: 0.3440, took: 48.3497s
2022-10-10 10:16:28,446 [INFO] 	Process 5 - batch 33599: mean_policy_losses: -190.928, mean_net_lifetime: 4984.2106, mean_mc_travel_dist: 1713.9766, mean_rewards: 256.2635, total_rewards: 3321.5450, mean_steps: 18.7000, mean_ecr: 0.0303 mean_entropies: 0.8893, took: 96.1294s
2022-10-10 10:16:49,158 [INFO] 	Process 2 - batch 33299: mean_policy_losses: 17.452, mean_net_lifetime: 4715.8599, mean_mc_travel_dist: 1366.2865, mean_rewards: 266.9847, total_rewards: 3371.3195, mean_steps: 16.8300, mean_ecr: 0.0405 mean_entropies: 0.6499, took: 89.2913s
2022-10-10 10:17:03,440 [INFO] 	Process 1 - batch 28799: mean_policy_losses: -28.626, mean_net_lifetime: 4728.4051, mean_mc_travel_dist: 1748.7148, mean_rewards: 226.1491, total_rewards: 3008.4061, mean_steps: 20.2600, mean_ecr: 0.0391 mean_entropies: 0.9650, took: 102.6914s
2022-10-10 10:17:10,408 [INFO] 	Process 4 - batch 39199: mean_policy_losses: 178.202, mean_net_lifetime: 4417.3368, mean_mc_travel_dist: 1273.6109, mean_rewards: 265.7940, total_rewards: 3168.9227, mean_steps: 15.6900, mean_ecr: 0.0482 mean_entropies: 0.9439, took: 85.9334s
2022-10-10 10:17:15,318 [INFO] 	Process 6 - batch 49299: mean_policy_losses: -253.169, mean_net_lifetime: 3211.1893, mean_mc_travel_dist: 874.5209, mean_rewards: 330.1873, total_rewards: 2364.6790, mean_steps: 8.7900, mean_ecr: 0.0561 mean_entropies: 0.3261, took: 51.5253s
2022-10-10 10:17:29,783 [INFO] 	Process 7 - batch 33999: mean_policy_losses: -237.833, mean_net_lifetime: 4697.9424, mean_mc_travel_dist: 1544.6922, mean_rewards: 232.5685, total_rewards: 3174.2295, mean_steps: 19.5100, mean_ecr: 0.0412 mean_entropies: 1.4212, took: 99.6880s
2022-10-10 10:17:42,834 [INFO] 	Process 3 - batch 34099: mean_policy_losses: 24.925, mean_net_lifetime: 4365.6933, mean_mc_travel_dist: 1212.6321, mean_rewards: 266.8378, total_rewards: 3180.8024, mean_steps: 15.4200, mean_ecr: 0.0486 mean_entropies: 0.6979, took: 82.6129s
2022-10-10 10:18:04,190 [INFO] 	Process 5 - batch 33699: mean_policy_losses: -271.741, mean_net_lifetime: 4871.9555, mean_mc_travel_dist: 1674.2921, mean_rewards: 257.9571, total_rewards: 3244.8586, mean_steps: 18.3600, mean_ecr: 0.0300 mean_entropies: 0.9305, took: 95.7435s
2022-10-10 10:18:06,097 [INFO] 	Process 6 - batch 49399: mean_policy_losses: -274.100, mean_net_lifetime: 3158.1830, mean_mc_travel_dist: 856.3535, mean_rewards: 322.4679, total_rewards: 2334.1617, mean_steps: 8.8100, mean_ecr: 0.0559 mean_entropies: 0.3360, took: 50.7780s
2022-10-10 10:18:18,689 [INFO] 	Process 2 - batch 33399: mean_policy_losses: -9.799, mean_net_lifetime: 4638.2770, mean_mc_travel_dist: 1349.3179, mean_rewards: 260.6466, total_rewards: 3307.8417, mean_steps: 16.9600, mean_ecr: 0.0406 mean_entropies: 0.6403, took: 89.5311s
2022-10-10 10:18:34,679 [INFO] 	Process 4 - batch 39299: mean_policy_losses: 236.403, mean_net_lifetime: 4555.9910, mean_mc_travel_dist: 1286.6067, mean_rewards: 276.9077, total_rewards: 3302.1270, mean_steps: 15.5300, mean_ecr: 0.0481 mean_entropies: 0.9306, took: 84.2711s
2022-10-10 10:18:52,809 [INFO] 	Process 1 - batch 28899: mean_policy_losses: 11.796, mean_net_lifetime: 4839.3171, mean_mc_travel_dist: 1764.1348, mean_rewards: 217.2181, total_rewards: 3099.2411, mean_steps: 21.9300, mean_ecr: 0.0391 mean_entropies: 1.0195, took: 109.3682s
2022-10-10 10:19:00,392 [INFO] 	Process 6 - batch 49499: mean_policy_losses: -187.856, mean_net_lifetime: 3385.3914, mean_mc_travel_dist: 901.0971, mean_rewards: 326.6806, total_rewards: 2505.6085, mean_steps: 9.4300, mean_ecr: 0.0557 mean_entropies: 0.3061, took: 54.2961s
2022-10-10 10:19:05,896 [INFO] 	Process 3 - batch 34199: mean_policy_losses: 10.673, mean_net_lifetime: 4275.7788, mean_mc_travel_dist: 1170.0165, mean_rewards: 256.8860, total_rewards: 3131.4416, mean_steps: 15.6900, mean_ecr: 0.0489 mean_entropies: 0.6817, took: 83.0603s
2022-10-10 10:19:06,034 [INFO] 	Process 7 - batch 34099: mean_policy_losses: -274.239, mean_net_lifetime: 4474.7976, mean_mc_travel_dist: 1537.2412, mean_rewards: 231.8264, total_rewards: 2988.8643, mean_steps: 18.6200, mean_ecr: 0.0412 mean_entropies: 1.4420, took: 96.2512s
2022-10-10 10:19:38,107 [INFO] 	Process 5 - batch 33799: mean_policy_losses: -280.891, mean_net_lifetime: 4771.9111, mean_mc_travel_dist: 1654.9143, mean_rewards: 253.3991, total_rewards: 3167.1938, mean_steps: 18.4500, mean_ecr: 0.0299 mean_entropies: 0.9027, took: 93.9169s
2022-10-10 10:19:47,916 [INFO] 	Process 2 - batch 33499: mean_policy_losses: -8.897, mean_net_lifetime: 4687.9966, mean_mc_travel_dist: 1365.2113, mean_rewards: 259.1183, total_rewards: 3341.0252, mean_steps: 17.2300, mean_ecr: 0.0405 mean_entropies: 0.6622, took: 89.2270s
2022-10-10 10:20:03,689 [INFO] 	Process 4 - batch 39399: mean_policy_losses: 216.401, mean_net_lifetime: 4818.0893, mean_mc_travel_dist: 1370.8046, mean_rewards: 272.7380, total_rewards: 3483.0207, mean_steps: 16.7500, mean_ecr: 0.0473 mean_entropies: 0.9129, took: 89.0095s
2022-10-10 10:20:23,198 [INFO] 	Process 3 - batch 34299: mean_policy_losses: 39.729, mean_net_lifetime: 4386.4903, mean_mc_travel_dist: 1255.0377, mean_rewards: 274.7550, total_rewards: 3161.4940, mean_steps: 15.0300, mean_ecr: 0.0483 mean_entropies: 0.7229, took: 77.3031s
2022-10-10 10:20:25,835 [INFO] 	Process 7 - batch 34199: mean_policy_losses: -518.939, mean_net_lifetime: 3957.0953, mean_mc_travel_dist: 1369.2642, mean_rewards: 240.3310, total_rewards: 2622.8903, mean_steps: 15.7500, mean_ecr: 0.0415 mean_entropies: 1.4305, took: 79.8003s
2022-10-10 10:20:30,941 [INFO] 	Process 1 - batch 28999: mean_policy_losses: -36.234, mean_net_lifetime: 4684.6250, mean_mc_travel_dist: 1753.0875, mean_rewards: 228.0415, total_rewards: 2956.4587, mean_steps: 19.9500, mean_ecr: 0.0392 mean_entropies: 0.9812, took: 98.1316s
2022-10-10 10:20:42,826 [INFO] 	Process 5 - batch 33899: mean_policy_losses: -533.725, mean_net_lifetime: 3722.4976, mean_mc_travel_dist: 1319.9891, mean_rewards: 295.5069, total_rewards: 2457.3158, mean_steps: 12.5200, mean_ecr: 0.0297 mean_entropies: 0.8436, took: 64.7191s
2022-10-10 10:21:11,668 [INFO] 	Process 2 - batch 33599: mean_policy_losses: -0.469, mean_net_lifetime: 4686.6647, mean_mc_travel_dist: 1480.1240, mean_rewards: 270.9411, total_rewards: 3233.9168, mean_steps: 16.4700, mean_ecr: 0.0400 mean_entropies: 0.6985, took: 83.7521s
2022-10-10 10:21:32,541 [INFO] 	Process 4 - batch 39499: mean_policy_losses: 271.721, mean_net_lifetime: 4910.0555, mean_mc_travel_dist: 1400.9768, mean_rewards: 275.1360, total_rewards: 3542.2094, mean_steps: 16.9700, mean_ecr: 0.0470 mean_entropies: 0.9234, took: 88.8527s
2022-10-10 10:21:40,246 [INFO] 	Process 3 - batch 34399: mean_policy_losses: 30.427, mean_net_lifetime: 4403.2254, mean_mc_travel_dist: 1244.9336, mean_rewards: 278.8405, total_rewards: 3195.2999, mean_steps: 14.8400, mean_ecr: 0.0484 mean_entropies: 0.7017, took: 77.0484s
2022-10-10 10:21:43,837 [INFO] 	Process 7 - batch 34299: mean_policy_losses: -526.853, mean_net_lifetime: 3939.5238, mean_mc_travel_dist: 1395.9646, mean_rewards: 241.8267, total_rewards: 2580.3493, mean_steps: 15.5300, mean_ecr: 0.0416 mean_entropies: 1.4619, took: 78.0024s
2022-10-10 10:22:10,782 [INFO] 	Process 5 - batch 33999: mean_policy_losses: -372.092, mean_net_lifetime: 4800.7722, mean_mc_travel_dist: 1670.8154, mean_rewards: 272.2388, total_rewards: 3174.2996, mean_steps: 17.5300, mean_ecr: 0.0298 mean_entropies: 0.9250, took: 87.9562s
2022-10-10 10:22:11,727 [INFO] 	Process 1 - batch 29099: mean_policy_losses: 16.390, mean_net_lifetime: 4933.4368, mean_mc_travel_dist: 1785.1242, mean_rewards: 228.6789, total_rewards: 3176.3907, mean_steps: 20.9300, mean_ecr: 0.0391 mean_entropies: 1.0101, took: 100.7855s
2022-10-10 10:22:39,818 [INFO] 	Process 2 - batch 33699: mean_policy_losses: -28.728, mean_net_lifetime: 4689.4734, mean_mc_travel_dist: 1378.6116, mean_rewards: 264.9758, total_rewards: 3338.9371, mean_steps: 16.9000, mean_ecr: 0.0405 mean_entropies: 0.7152, took: 88.1501s
2022-10-10 10:22:59,467 [INFO] 	Process 4 - batch 39599: mean_policy_losses: 180.389, mean_net_lifetime: 4738.9296, mean_mc_travel_dist: 1339.8499, mean_rewards: 274.1435, total_rewards: 3427.0490, mean_steps: 16.4200, mean_ecr: 0.0475 mean_entropies: 0.9229, took: 86.9259s
2022-10-10 10:23:00,113 [INFO] 	Process 3 - batch 34499: mean_policy_losses: 22.509, mean_net_lifetime: 4529.4728, mean_mc_travel_dist: 1278.3318, mean_rewards: 278.4703, total_rewards: 3280.3717, mean_steps: 15.3300, mean_ecr: 0.0481 mean_entropies: 0.7064, took: 79.8673s
2022-10-10 10:23:12,977 [INFO] 	Process 7 - batch 34399: mean_policy_losses: -366.540, mean_net_lifetime: 4461.4723, mean_mc_travel_dist: 1469.4894, mean_rewards: 239.3934, total_rewards: 3035.3427, mean_steps: 17.8900, mean_ecr: 0.0414 mean_entropies: 1.4931, took: 89.1399s
2022-10-10 10:23:42,413 [INFO] 	Process 5 - batch 34099: mean_policy_losses: -325.531, mean_net_lifetime: 4969.9903, mean_mc_travel_dist: 1694.9051, mean_rewards: 258.2926, total_rewards: 3329.1181, mean_steps: 18.7200, mean_ecr: 0.0300 mean_entropies: 0.9199, took: 91.6304s
2022-10-10 10:23:54,130 [INFO] 	Process 1 - batch 29199: mean_policy_losses: 8.067, mean_net_lifetime: 4979.9418, mean_mc_travel_dist: 1796.4395, mean_rewards: 223.4798, total_rewards: 3219.0338, mean_steps: 21.6400, mean_ecr: 0.0390 mean_entropies: 1.0494, took: 102.4035s
2022-10-10 10:24:04,664 [INFO] 	Process 2 - batch 33799: mean_policy_losses: -9.703, mean_net_lifetime: 4680.2934, mean_mc_travel_dist: 1357.6444, mean_rewards: 264.9543, total_rewards: 3343.1682, mean_steps: 16.8300, mean_ecr: 0.0406 mean_entropies: 0.6876, took: 84.8459s
2022-10-10 10:24:21,431 [INFO] 	Process 4 - batch 39699: mean_policy_losses: 191.461, mean_net_lifetime: 4605.1860, mean_mc_travel_dist: 1302.2542, mean_rewards: 270.0153, total_rewards: 3335.8516, mean_steps: 16.1500, mean_ecr: 0.0479 mean_entropies: 0.8950, took: 81.9626s
2022-10-10 10:24:24,441 [INFO] 	Process 7 - batch 34499: mean_policy_losses: -639.774, mean_net_lifetime: 3630.1484, mean_mc_travel_dist: 1234.0009, mean_rewards: 244.9072, total_rewards: 2449.6807, mean_steps: 14.3900, mean_ecr: 0.0422 mean_entropies: 1.4570, took: 71.4632s
2022-10-10 10:25:09,227 [INFO] 	Process 5 - batch 34199: mean_policy_losses: -267.341, mean_net_lifetime: 4888.0555, mean_mc_travel_dist: 1649.1411, mean_rewards: 260.9008, total_rewards: 3286.1946, mean_steps: 18.1000, mean_ecr: 0.0307 mean_entropies: 0.9180, took: 86.8146s
2022-10-10 10:25:25,774 [INFO] 	Process 2 - batch 33899: mean_policy_losses: -2.261, mean_net_lifetime: 4725.3848, mean_mc_travel_dist: 1370.0707, mean_rewards: 269.1498, total_rewards: 3379.8941, mean_steps: 16.6700, mean_ecr: 0.0405 mean_entropies: 0.7166, took: 81.1098s
2022-10-10 10:25:28,240 [INFO] 	Process 1 - batch 29299: mean_policy_losses: -0.259, mean_net_lifetime: 5000.4923, mean_mc_travel_dist: 1791.8261, mean_rewards: 237.2995, total_rewards: 3232.7973, mean_steps: 20.3300, mean_ecr: 0.0390 mean_entropies: 1.0689, took: 94.1106s
2022-10-10 10:25:40,260 [INFO] 	Process 4 - batch 39799: mean_policy_losses: 120.803, mean_net_lifetime: 4500.1930, mean_mc_travel_dist: 1259.2008, mean_rewards: 270.2756, total_rewards: 3260.8676, mean_steps: 15.7000, mean_ecr: 0.0480 mean_entropies: 0.9465, took: 78.8305s
2022-10-10 10:26:22,584 [INFO] 	Process 5 - batch 34299: mean_policy_losses: -495.643, mean_net_lifetime: 4244.1764, mean_mc_travel_dist: 1403.7389, mean_rewards: 265.3765, total_rewards: 2895.3367, mean_steps: 15.5200, mean_ecr: 0.0305 mean_entropies: 0.9255, took: 73.3560s
2022-10-10 10:26:43,620 [INFO] 	Process 2 - batch 33999: mean_policy_losses: -2.251, mean_net_lifetime: 4687.7767, mean_mc_travel_dist: 1344.1479, mean_rewards: 270.8943, total_rewards: 3365.7185, mean_steps: 16.4000, mean_ecr: 0.0406 mean_entropies: 0.7267, took: 77.8461s
2022-10-10 10:26:54,318 [INFO] 	Process 4 - batch 39899: mean_policy_losses: 134.571, mean_net_lifetime: 4462.6799, mean_mc_travel_dist: 1247.8364, mean_rewards: 275.4519, total_rewards: 3243.9473, mean_steps: 15.2100, mean_ecr: 0.0485 mean_entropies: 0.9399, took: 74.0577s
2022-10-10 10:26:55,127 [INFO] 	Process 1 - batch 29399: mean_policy_losses: 8.956, mean_net_lifetime: 5027.4025, mean_mc_travel_dist: 1829.9976, mean_rewards: 252.8001, total_rewards: 3230.2674, mean_steps: 19.0500, mean_ecr: 0.0390 mean_entropies: 1.0849, took: 86.8859s
2022-10-10 10:27:39,945 [INFO] 	Process 5 - batch 34399: mean_policy_losses: -472.225, mean_net_lifetime: 4393.9161, mean_mc_travel_dist: 1457.6536, mean_rewards: 261.8025, total_rewards: 2989.8902, mean_steps: 16.4800, mean_ecr: 0.0305 mean_entropies: 0.9670, took: 77.3618s
2022-10-10 10:28:00,138 [INFO] 	Process 2 - batch 34099: mean_policy_losses: -12.653, mean_net_lifetime: 4682.1334, mean_mc_travel_dist: 1343.1049, mean_rewards: 270.9124, total_rewards: 3368.3708, mean_steps: 16.4400, mean_ecr: 0.0406 mean_entropies: 0.7706, took: 76.5182s
2022-10-10 10:28:05,874 [INFO] 	Process 4 - batch 39999: mean_policy_losses: 108.650, mean_net_lifetime: 4306.2136, mean_mc_travel_dist: 1231.5009, mean_rewards: 274.7725, total_rewards: 3099.7924, mean_steps: 14.7100, mean_ecr: 0.0486 mean_entropies: 0.9774, took: 71.5563s
2022-10-10 10:28:23,242 [INFO] 	Process 1 - batch 29499: mean_policy_losses: -5.591, mean_net_lifetime: 5078.4808, mean_mc_travel_dist: 1876.4786, mean_rewards: 250.9613, total_rewards: 3234.7291, mean_steps: 19.3900, mean_ecr: 0.0389 mean_entropies: 1.1611, took: 88.1159s
2022-10-10 10:28:52,390 [INFO] Process 6 - epoch 33: mean_policy_losses: -289.180, mean_net_lifetime: 2445.9772, mean_mc_travel_dist: 955.4869, mean_entropies: 1.0111, m_net_lifetime_valid: 4325.4006, took: 1384.9031s, (120.0506 / 100 batches)

2022-10-10 10:28:57,618 [INFO] 	Process 5 - batch 34499: mean_policy_losses: -469.514, mean_net_lifetime: 4357.9076, mean_mc_travel_dist: 1460.5744, mean_rewards: 253.7058, total_rewards: 2959.9580, mean_steps: 16.7900, mean_ecr: 0.0306 mean_entropies: 1.0029, took: 77.6726s
2022-10-10 10:29:16,169 [INFO] 	Process 2 - batch 34199: mean_policy_losses: -14.562, mean_net_lifetime: 4700.9689, mean_mc_travel_dist: 1354.3107, mean_rewards: 275.6878, total_rewards: 3372.6675, mean_steps: 16.1600, mean_ecr: 0.0405 mean_entropies: 0.8064, took: 76.0303s
2022-10-10 10:29:18,529 [INFO] 	Process 4 - batch 40099: mean_policy_losses: 124.245, mean_net_lifetime: 4387.1039, mean_mc_travel_dist: 1239.5070, mean_rewards: 270.7939, total_rewards: 3179.1513, mean_steps: 15.1700, mean_ecr: 0.0488 mean_entropies: 0.9848, took: 72.6544s
2022-10-10 10:29:39,549 [INFO] 	Process 6 - batch 49599: mean_policy_losses: -337.024, mean_net_lifetime: 3200.9603, mean_mc_travel_dist: 863.8385, mean_rewards: 321.2551, total_rewards: 2363.5699, mean_steps: 8.9500, mean_ecr: 0.0560 mean_entropies: 0.3070, took: 639.1563s
2022-10-10 10:29:57,022 [INFO] 	Process 1 - batch 29599: mean_policy_losses: 45.237, mean_net_lifetime: 5092.9321, mean_mc_travel_dist: 1828.5519, mean_rewards: 239.7978, total_rewards: 3298.8387, mean_steps: 20.5500, mean_ecr: 0.0390 mean_entropies: 1.1294, took: 93.7803s
2022-10-10 10:30:26,783 [INFO] 	Process 6 - batch 49699: mean_policy_losses: -316.485, mean_net_lifetime: 3240.6922, mean_mc_travel_dist: 872.3661, mean_rewards: 326.6887, total_rewards: 2382.8174, mean_steps: 8.9100, mean_ecr: 0.0563 mean_entropies: 0.2851, took: 47.2336s
2022-10-10 10:30:33,726 [INFO] 	Process 4 - batch 40199: mean_policy_losses: 186.443, mean_net_lifetime: 4753.4015, mean_mc_travel_dist: 1350.9072, mean_rewards: 280.2662, total_rewards: 3431.0231, mean_steps: 15.9800, mean_ecr: 0.0475 mean_entropies: 0.8692, took: 75.1976s
2022-10-10 10:30:35,550 [INFO] 	Process 2 - batch 34299: mean_policy_losses: 4.996, mean_net_lifetime: 4691.4057, mean_mc_travel_dist: 1348.1469, mean_rewards: 263.8314, total_rewards: 3361.4989, mean_steps: 16.9200, mean_ecr: 0.0405 mean_entropies: 0.6644, took: 79.3813s
2022-10-10 10:31:13,087 [INFO] 	Process 6 - batch 49799: mean_policy_losses: -235.837, mean_net_lifetime: 3266.7814, mean_mc_travel_dist: 887.0311, mean_rewards: 334.1702, total_rewards: 2397.5538, mean_steps: 8.8500, mean_ecr: 0.0557 mean_entropies: 0.3100, took: 46.3046s
2022-10-10 10:31:27,619 [INFO] 	Process 1 - batch 29699: mean_policy_losses: -22.804, mean_net_lifetime: 4833.0023, mean_mc_travel_dist: 1779.0844, mean_rewards: 231.2761, total_rewards: 3080.8285, mean_steps: 20.3000, mean_ecr: 0.0390 mean_entropies: 1.0296, took: 90.5957s
2022-10-10 10:31:50,342 [INFO] 	Process 4 - batch 40299: mean_policy_losses: 179.646, mean_net_lifetime: 4660.1094, mean_mc_travel_dist: 1319.7179, mean_rewards: 277.8007, total_rewards: 3374.3826, mean_steps: 15.8100, mean_ecr: 0.0477 mean_entropies: 0.8777, took: 76.6155s
2022-10-10 10:31:52,942 [INFO] 	Process 2 - batch 34399: mean_policy_losses: 15.212, mean_net_lifetime: 4694.1474, mean_mc_travel_dist: 1362.3142, mean_rewards: 266.7593, total_rewards: 3355.7353, mean_steps: 16.7200, mean_ecr: 0.0405 mean_entropies: 0.6623, took: 77.3922s
2022-10-10 10:32:02,304 [INFO] Process 3 - epoch 23: mean_policy_losses: 115.369, mean_net_lifetime: 4001.7845, mean_mc_travel_dist: 1480.4318, mean_entropies: 1.3219, m_net_lifetime_valid: 4145.6163, took: 1781.1350s, (172.7879 / 100 batches)

2022-10-10 10:32:04,620 [INFO] 	Process 6 - batch 49899: mean_policy_losses: -124.213, mean_net_lifetime: 3536.5814, mean_mc_travel_dist: 940.1061, mean_rewards: 322.4184, total_rewards: 2619.5417, mean_steps: 9.9900, mean_ecr: 0.0558 mean_entropies: 0.2874, took: 51.5332s
2022-10-10 10:32:53,589 [INFO] 	Process 6 - batch 49999: mean_policy_losses: -226.334, mean_net_lifetime: 3279.0487, mean_mc_travel_dist: 885.4796, mean_rewards: 325.6219, total_rewards: 2416.6460, mean_steps: 9.1000, mean_ecr: 0.0560 mean_entropies: 0.3009, took: 48.9680s
2022-10-10 10:32:59,619 [INFO] 	Process 1 - batch 29799: mean_policy_losses: -39.561, mean_net_lifetime: 4906.7337, mean_mc_travel_dist: 1811.5429, mean_rewards: 239.6020, total_rewards: 3125.5538, mean_steps: 19.7400, mean_ecr: 0.0391 mean_entropies: 1.0346, took: 92.0006s
2022-10-10 10:33:09,849 [INFO] 	Process 4 - batch 40399: mean_policy_losses: 169.076, mean_net_lifetime: 4808.5672, mean_mc_travel_dist: 1365.7518, mean_rewards: 279.2188, total_rewards: 3469.9616, mean_steps: 16.2600, mean_ecr: 0.0474 mean_entropies: 0.8838, took: 79.5075s
2022-10-10 10:33:12,894 [INFO] 	Process 2 - batch 34499: mean_policy_losses: 13.331, mean_net_lifetime: 4706.5793, mean_mc_travel_dist: 1354.6181, mean_rewards: 267.8127, total_rewards: 3378.0470, mean_steps: 16.7000, mean_ecr: 0.0405 mean_entropies: 0.6876, took: 79.9518s
2022-10-10 10:33:17,769 [INFO] 	Process 3 - batch 34599: mean_policy_losses: 12.570, mean_net_lifetime: 4299.2044, mean_mc_travel_dist: 1217.0391, mean_rewards: 266.4426, total_rewards: 3107.7045, mean_steps: 15.2100, mean_ecr: 0.0486 mean_entropies: 0.7142, took: 617.6561s
2022-10-10 10:33:39,457 [INFO] 	Process 6 - batch 50099: mean_policy_losses: -243.875, mean_net_lifetime: 3172.8817, mean_mc_travel_dist: 870.2068, mean_rewards: 333.9754, total_rewards: 2335.0567, mean_steps: 8.5300, mean_ecr: 0.0560 mean_entropies: 0.3145, took: 45.8692s
2022-10-10 10:33:46,492 [INFO] Process 7 - epoch 23: mean_policy_losses: -125.111, mean_net_lifetime: 3947.9920, mean_mc_travel_dist: 1676.1898, mean_entropies: 1.9045, m_net_lifetime_valid: 4256.8485, took: 1839.1279s, (173.0335 / 100 batches)

2022-10-10 10:34:26,863 [INFO] 	Process 6 - batch 50199: mean_policy_losses: -164.978, mean_net_lifetime: 3272.8501, mean_mc_travel_dist: 909.2401, mean_rewards: 333.0930, total_rewards: 2402.2792, mean_steps: 8.8600, mean_ecr: 0.0559 mean_entropies: 0.3122, took: 47.4060s
2022-10-10 10:34:31,513 [INFO] 	Process 1 - batch 29899: mean_policy_losses: -64.294, mean_net_lifetime: 4712.0775, mean_mc_travel_dist: 1767.8225, mean_rewards: 232.4924, total_rewards: 2979.9332, mean_steps: 19.7300, mean_ecr: 0.0391 mean_entropies: 0.9989, took: 91.8941s
2022-10-10 10:34:34,469 [INFO] 	Process 3 - batch 34699: mean_policy_losses: 62.693, mean_net_lifetime: 4482.8677, mean_mc_travel_dist: 1247.1972, mean_rewards: 268.4311, total_rewards: 3262.4142, mean_steps: 15.7500, mean_ecr: 0.0483 mean_entropies: 0.6822, took: 76.7003s
2022-10-10 10:34:35,285 [INFO] 	Process 4 - batch 40499: mean_policy_losses: 221.577, mean_net_lifetime: 5102.1143, mean_mc_travel_dist: 1474.0657, mean_rewards: 280.9680, total_rewards: 3662.1988, mean_steps: 17.3200, mean_ecr: 0.0469 mean_entropies: 0.8426, took: 85.4357s
2022-10-10 10:35:02,722 [INFO] 	Process 7 - batch 34599: mean_policy_losses: -435.720, mean_net_lifetime: 4042.7115, mean_mc_travel_dist: 1395.7733, mean_rewards: 247.8612, total_rewards: 2691.4479, mean_steps: 15.8800, mean_ecr: 0.0417 mean_entropies: 1.4732, took: 638.2822s
2022-10-10 10:35:13,134 [INFO] 	Process 6 - batch 50299: mean_policy_losses: -211.034, mean_net_lifetime: 3143.1236, mean_mc_travel_dist: 858.2402, mean_rewards: 327.6455, total_rewards: 2319.9304, mean_steps: 8.6200, mean_ecr: 0.0561 mean_entropies: 0.3149, took: 46.2708s
2022-10-10 10:35:50,657 [INFO] 	Process 3 - batch 34799: mean_policy_losses: 50.016, mean_net_lifetime: 4355.4631, mean_mc_travel_dist: 1211.9016, mean_rewards: 258.3380, total_rewards: 3176.5398, mean_steps: 15.9000, mean_ecr: 0.0486 mean_entropies: 0.6874, took: 76.1876s
2022-10-10 10:36:02,193 [INFO] 	Process 6 - batch 50399: mean_policy_losses: -229.032, mean_net_lifetime: 3367.0103, mean_mc_travel_dist: 909.1108, mean_rewards: 327.2627, total_rewards: 2477.3354, mean_steps: 9.3100, mean_ecr: 0.0558 mean_entropies: 0.3082, took: 49.0589s
2022-10-10 10:36:02,333 [INFO] 	Process 1 - batch 29999: mean_policy_losses: 2.104, mean_net_lifetime: 4778.8385, mean_mc_travel_dist: 1788.6618, mean_rewards: 231.5672, total_rewards: 3017.5428, mean_steps: 20.0300, mean_ecr: 0.0390 mean_entropies: 0.9655, took: 90.8190s
2022-10-10 10:36:10,403 [INFO] 	Process 7 - batch 34699: mean_policy_losses: -628.420, mean_net_lifetime: 3781.3710, mean_mc_travel_dist: 1292.3057, mean_rewards: 246.4178, total_rewards: 2536.0267, mean_steps: 14.5600, mean_ecr: 0.0419 mean_entropies: 1.4360, took: 67.6811s
2022-10-10 10:36:50,962 [INFO] 	Process 6 - batch 50499: mean_policy_losses: -149.480, mean_net_lifetime: 3523.6246, mean_mc_travel_dist: 947.4682, mean_rewards: 322.4935, total_rewards: 2603.6825, mean_steps: 9.9200, mean_ecr: 0.0558 mean_entropies: 0.2754, took: 48.7693s
2022-10-10 10:37:03,822 [INFO] 	Process 3 - batch 34899: mean_policy_losses: 37.130, mean_net_lifetime: 4196.8837, mean_mc_travel_dist: 1153.7665, mean_rewards: 248.2747, total_rewards: 3067.6020, mean_steps: 15.9500, mean_ecr: 0.0490 mean_entropies: 0.6672, took: 73.1657s
2022-10-10 10:37:21,537 [INFO] 	Process 7 - batch 34799: mean_policy_losses: -466.773, mean_net_lifetime: 3952.2733, mean_mc_travel_dist: 1390.7234, mean_rewards: 244.2296, total_rewards: 2605.0913, mean_steps: 15.5900, mean_ecr: 0.0418 mean_entropies: 1.4201, took: 71.1332s
2022-10-10 10:37:37,775 [INFO] 	Process 6 - batch 50599: mean_policy_losses: -140.096, mean_net_lifetime: 3457.9850, mean_mc_travel_dist: 933.8098, mean_rewards: 329.2862, total_rewards: 2541.8688, mean_steps: 9.5200, mean_ecr: 0.0558 mean_entropies: 0.2842, took: 46.8132s
2022-10-10 10:38:07,275 [INFO] Process 5 - epoch 23: mean_policy_losses: -147.974, mean_net_lifetime: 4438.3040, mean_mc_travel_dist: 2079.3677, mean_entropies: 1.7062, m_net_lifetime_valid: 4649.0167, took: 1852.5058s, (173.8231 / 100 batches)

2022-10-10 10:38:16,381 [INFO] 	Process 3 - batch 34999: mean_policy_losses: 35.016, mean_net_lifetime: 4294.4274, mean_mc_travel_dist: 1175.9396, mean_rewards: 258.2817, total_rewards: 3135.4071, mean_steps: 15.7000, mean_ecr: 0.0489 mean_entropies: 0.6920, took: 72.5577s
2022-10-10 10:38:25,575 [INFO] 	Process 6 - batch 50699: mean_policy_losses: -136.336, mean_net_lifetime: 3428.5665, mean_mc_travel_dist: 926.9963, mean_rewards: 328.1055, total_rewards: 2518.3624, mean_steps: 9.4800, mean_ecr: 0.0558 mean_entropies: 0.2820, took: 47.7992s
2022-10-10 10:38:34,106 [INFO] 	Process 7 - batch 34899: mean_policy_losses: -448.765, mean_net_lifetime: 4019.7074, mean_mc_travel_dist: 1314.6018, mean_rewards: 243.5697, total_rewards: 2739.9230, mean_steps: 15.8600, mean_ecr: 0.0418 mean_entropies: 1.4368, took: 72.5694s
2022-10-10 10:39:15,901 [INFO] 	Process 6 - batch 50799: mean_policy_losses: -99.347, mean_net_lifetime: 3507.9208, mean_mc_travel_dist: 948.1037, mean_rewards: 327.5867, total_rewards: 2582.1777, mean_steps: 9.7100, mean_ecr: 0.0559 mean_entropies: 0.2722, took: 50.3263s
2022-10-10 10:39:22,616 [INFO] 	Process 5 - batch 34599: mean_policy_losses: -414.370, mean_net_lifetime: 4147.9760, mean_mc_travel_dist: 1397.9082, mean_rewards: 251.0503, total_rewards: 2811.4049, mean_steps: 16.1500, mean_ecr: 0.0300 mean_entropies: 0.8674, took: 624.9985s
2022-10-10 10:39:31,956 [INFO] 	Process 3 - batch 35099: mean_policy_losses: 41.223, mean_net_lifetime: 4244.4429, mean_mc_travel_dist: 1162.4352, mean_rewards: 250.8522, total_rewards: 3106.6579, mean_steps: 15.9800, mean_ecr: 0.0488 mean_entropies: 0.6740, took: 75.5754s
2022-10-10 10:39:56,056 [INFO] 	Process 7 - batch 34999: mean_policy_losses: -285.118, mean_net_lifetime: 4319.8080, mean_mc_travel_dist: 1470.6013, mean_rewards: 230.2129, total_rewards: 2897.1522, mean_steps: 17.8800, mean_ecr: 0.0413 mean_entropies: 1.3841, took: 81.9507s
2022-10-10 10:40:08,050 [INFO] 	Process 6 - batch 50899: mean_policy_losses: -116.684, mean_net_lifetime: 3612.4122, mean_mc_travel_dist: 965.8470, mean_rewards: 326.6260, total_rewards: 2668.4420, mean_steps: 10.1300, mean_ecr: 0.0556 mean_entropies: 0.2557, took: 52.1483s
2022-10-10 10:40:42,211 [INFO] 	Process 5 - batch 34699: mean_policy_losses: -254.825, mean_net_lifetime: 4568.8097, mean_mc_travel_dist: 1526.5515, mean_rewards: 256.7591, total_rewards: 3093.0863, mean_steps: 17.1300, mean_ecr: 0.0310 mean_entropies: 0.8205, took: 79.5940s
2022-10-10 10:40:51,619 [INFO] 	Process 3 - batch 35199: mean_policy_losses: 33.372, mean_net_lifetime: 4241.4653, mean_mc_travel_dist: 1157.4329, mean_rewards: 242.0055, total_rewards: 3116.5669, mean_steps: 16.6000, mean_ecr: 0.0489 mean_entropies: 0.6435, took: 79.6626s
2022-10-10 10:40:58,827 [INFO] 	Process 6 - batch 50999: mean_policy_losses: -97.657, mean_net_lifetime: 3564.9549, mean_mc_travel_dist: 958.5230, mean_rewards: 325.6655, total_rewards: 2634.0742, mean_steps: 9.9500, mean_ecr: 0.0557 mean_entropies: 0.2587, took: 50.7771s
2022-10-10 10:41:20,685 [INFO] 	Process 7 - batch 35099: mean_policy_losses: -221.644, mean_net_lifetime: 4324.0889, mean_mc_travel_dist: 1412.6256, mean_rewards: 220.4023, total_rewards: 2947.8274, mean_steps: 18.8500, mean_ecr: 0.0416 mean_entropies: 1.3463, took: 84.6286s
2022-10-10 10:42:07,038 [INFO] 	Process 5 - batch 34799: mean_policy_losses: -191.255, mean_net_lifetime: 4975.2566, mean_mc_travel_dist: 1663.5729, mean_rewards: 256.1354, total_rewards: 3366.9402, mean_steps: 18.6300, mean_ecr: 0.0313 mean_entropies: 0.8621, took: 84.8263s
2022-10-10 10:42:07,696 [INFO] 	Process 3 - batch 35299: mean_policy_losses: 55.147, mean_net_lifetime: 4469.2085, mean_mc_travel_dist: 1234.9131, mean_rewards: 261.1522, total_rewards: 3269.8363, mean_steps: 16.1900, mean_ecr: 0.0483 mean_entropies: 0.6795, took: 76.0767s
2022-10-10 10:42:36,898 [INFO] Process 2 - epoch 23: mean_policy_losses: 14.229, mean_net_lifetime: 4095.5642, mean_mc_travel_dist: 1686.4128, mean_entropies: 1.3765, m_net_lifetime_valid: 4330.7829, took: 1814.7009s, (174.5612 / 100 batches)

2022-10-10 10:42:56,894 [INFO] 	Process 7 - batch 35199: mean_policy_losses: -223.092, mean_net_lifetime: 4748.0857, mean_mc_travel_dist: 1532.3340, mean_rewards: 207.6888, total_rewards: 3257.6290, mean_steps: 22.0000, mean_ecr: 0.0411 mean_entropies: 1.3635, took: 96.2091s
2022-10-10 10:43:21,972 [INFO] 	Process 3 - batch 35399: mean_policy_losses: 24.124, mean_net_lifetime: 4457.8396, mean_mc_travel_dist: 1240.9709, mean_rewards: 268.0446, total_rewards: 3246.6648, mean_steps: 15.6900, mean_ecr: 0.0482 mean_entropies: 0.6664, took: 74.2757s
2022-10-10 10:43:21,994 [INFO] Process 4 - epoch 27: mean_policy_losses: 79.299, mean_net_lifetime: 3495.7822, mean_mc_travel_dist: 1277.0597, mean_entropies: 1.5692, m_net_lifetime_valid: 4215.2002, took: 1736.1631s, (148.9664 / 100 batches)

2022-10-10 10:43:35,419 [INFO] 	Process 5 - batch 34899: mean_policy_losses: -162.171, mean_net_lifetime: 5240.3038, mean_mc_travel_dist: 1749.8614, mean_rewards: 263.8579, total_rewards: 3543.8635, mean_steps: 18.9900, mean_ecr: 0.0313 mean_entropies: 0.8568, took: 88.3819s
2022-10-10 10:44:01,534 [INFO] 	Process 2 - batch 34599: mean_policy_losses: -4.193, mean_net_lifetime: 4712.1361, mean_mc_travel_dist: 1424.2438, mean_rewards: 256.6935, total_rewards: 3312.1877, mean_steps: 17.5400, mean_ecr: 0.0402 mean_entropies: 0.6461, took: 648.6399s
2022-10-10 10:44:29,809 [INFO] 	Process 7 - batch 35299: mean_policy_losses: -369.977, mean_net_lifetime: 4436.4197, mean_mc_travel_dist: 1475.7886, mean_rewards: 221.5628, total_rewards: 3002.4619, mean_steps: 19.5300, mean_ecr: 0.0413 mean_entropies: 1.3735, took: 92.9141s
2022-10-10 10:44:41,123 [INFO] 	Process 3 - batch 35499: mean_policy_losses: 6.795, mean_net_lifetime: 4353.0758, mean_mc_travel_dist: 1211.7149, mean_rewards: 256.8335, total_rewards: 3175.2256, mean_steps: 15.9900, mean_ecr: 0.0486 mean_entropies: 0.6424, took: 79.1516s
2022-10-10 10:44:43,372 [INFO] 	Process 4 - batch 40599: mean_policy_losses: 120.699, mean_net_lifetime: 4285.4906, mean_mc_travel_dist: 1223.5063, mean_rewards: 258.5194, total_rewards: 3099.0944, mean_steps: 15.5700, mean_ecr: 0.0484 mean_entropies: 0.8854, took: 608.0863s
2022-10-10 10:45:00,633 [INFO] 	Process 5 - batch 34999: mean_policy_losses: -335.785, mean_net_lifetime: 4519.0389, mean_mc_travel_dist: 1533.1718, mean_rewards: 252.9515, total_rewards: 3051.2446, mean_steps: 17.3800, mean_ecr: 0.0304 mean_entropies: 0.8435, took: 85.2140s
2022-10-10 10:45:07,263 [INFO] Process 1 - epoch 20: mean_policy_losses: 50.259, mean_net_lifetime: 4634.4735, mean_mc_travel_dist: 2139.2775, mean_entropies: 1.4949, m_net_lifetime_valid: 4290.1212, took: 1998.4428s, (201.2210 / 100 batches)

2022-10-10 10:45:27,868 [INFO] 	Process 2 - batch 34699: mean_policy_losses: -8.013, mean_net_lifetime: 4697.6498, mean_mc_travel_dist: 1355.1468, mean_rewards: 265.6505, total_rewards: 3365.0374, mean_steps: 16.7900, mean_ecr: 0.0406 mean_entropies: 0.6141, took: 86.3344s
2022-10-10 10:46:01,643 [INFO] 	Process 3 - batch 35599: mean_policy_losses: 15.300, mean_net_lifetime: 4421.8065, mean_mc_travel_dist: 1234.1194, mean_rewards: 269.9102, total_rewards: 3229.3451, mean_steps: 15.4500, mean_ecr: 0.0484 mean_entropies: 0.6712, took: 80.5207s
2022-10-10 10:46:02,430 [INFO] 	Process 7 - batch 35399: mean_policy_losses: -321.463, mean_net_lifetime: 4468.1892, mean_mc_travel_dist: 1513.4299, mean_rewards: 227.9642, total_rewards: 2994.4452, mean_steps: 18.8000, mean_ecr: 0.0414 mean_entropies: 1.4147, took: 92.6219s
2022-10-10 10:46:10,702 [INFO] 	Process 4 - batch 40699: mean_policy_losses: 184.603, mean_net_lifetime: 4627.6517, mean_mc_travel_dist: 1311.1650, mean_rewards: 265.6700, total_rewards: 3347.6117, mean_steps: 16.5000, mean_ecr: 0.0479 mean_entropies: 0.8929, took: 87.3305s
2022-10-10 10:46:34,252 [INFO] 	Process 5 - batch 35099: mean_policy_losses: -309.431, mean_net_lifetime: 4780.6860, mean_mc_travel_dist: 1642.7613, mean_rewards: 247.2670, total_rewards: 3185.5919, mean_steps: 18.7200, mean_ecr: 0.0304 mean_entropies: 0.8887, took: 93.6183s
2022-10-10 10:46:50,417 [INFO] 	Process 1 - batch 30099: mean_policy_losses: 17.765, mean_net_lifetime: 4907.9829, mean_mc_travel_dist: 1747.9650, mean_rewards: 228.1380, total_rewards: 3188.2693, mean_steps: 21.0000, mean_ecr: 0.0393 mean_entropies: 1.0283, took: 648.0847s
2022-10-10 10:46:55,272 [INFO] 	Process 2 - batch 34799: mean_policy_losses: -4.755, mean_net_lifetime: 4688.3903, mean_mc_travel_dist: 1366.5315, mean_rewards: 268.0991, total_rewards: 3347.0667, mean_steps: 16.6100, mean_ecr: 0.0405 mean_entropies: 0.6541, took: 87.4035s
2022-10-10 10:47:20,672 [INFO] 	Process 3 - batch 35699: mean_policy_losses: 8.992, mean_net_lifetime: 4440.7736, mean_mc_travel_dist: 1228.3133, mean_rewards: 273.0984, total_rewards: 3234.8454, mean_steps: 15.3300, mean_ecr: 0.0486 mean_entropies: 0.6936, took: 79.0287s
2022-10-10 10:47:27,614 [INFO] 	Process 7 - batch 35499: mean_policy_losses: -578.754, mean_net_lifetime: 3982.4287, mean_mc_travel_dist: 1380.4575, mean_rewards: 229.1862, total_rewards: 2635.0986, mean_steps: 16.5400, mean_ecr: 0.0418 mean_entropies: 1.4618, took: 85.1827s
2022-10-10 10:47:35,490 [INFO] 	Process 4 - batch 40799: mean_policy_losses: 173.734, mean_net_lifetime: 4595.4550, mean_mc_travel_dist: 1286.3245, mean_rewards: 272.1697, total_rewards: 3340.6520, mean_steps: 15.8700, mean_ecr: 0.0480 mean_entropies: 0.8917, took: 84.7882s
2022-10-10 10:48:05,901 [INFO] 	Process 5 - batch 35199: mean_policy_losses: -291.723, mean_net_lifetime: 4828.0339, mean_mc_travel_dist: 1616.5242, mean_rewards: 250.8744, total_rewards: 3277.6667, mean_steps: 18.5800, mean_ecr: 0.0306 mean_entropies: 0.9050, took: 91.6495s
2022-10-10 10:48:21,497 [INFO] 	Process 2 - batch 34899: mean_policy_losses: -13.572, mean_net_lifetime: 4694.5070, mean_mc_travel_dist: 1364.0227, mean_rewards: 272.9296, total_rewards: 3348.9502, mean_steps: 16.3700, mean_ecr: 0.0406 mean_entropies: 0.7064, took: 86.2256s
2022-10-10 10:48:26,979 [INFO] 	Process 1 - batch 30199: mean_policy_losses: 15.694, mean_net_lifetime: 4982.9800, mean_mc_travel_dist: 1825.0849, mean_rewards: 241.8888, total_rewards: 3180.2982, mean_steps: 19.9500, mean_ecr: 0.0390 mean_entropies: 1.0913, took: 96.5633s
2022-10-10 10:48:37,452 [INFO] 	Process 3 - batch 35799: mean_policy_losses: 4.912, mean_net_lifetime: 4419.1449, mean_mc_travel_dist: 1236.2386, mean_rewards: 278.0359, total_rewards: 3217.3628, mean_steps: 14.9400, mean_ecr: 0.0484 mean_entropies: 0.6953, took: 76.7800s
2022-10-10 10:48:52,376 [INFO] 	Process 7 - batch 35599: mean_policy_losses: -618.271, mean_net_lifetime: 4022.9746, mean_mc_travel_dist: 1385.2200, mean_rewards: 230.7717, total_rewards: 2675.8458, mean_steps: 16.8100, mean_ecr: 0.0418 mean_entropies: 1.4812, took: 84.7625s
2022-10-10 10:49:06,161 [INFO] 	Process 4 - batch 40899: mean_policy_losses: 207.954, mean_net_lifetime: 4898.7062, mean_mc_travel_dist: 1407.3363, mean_rewards: 271.2329, total_rewards: 3522.8915, mean_steps: 17.2700, mean_ecr: 0.0473 mean_entropies: 0.8928, took: 90.6715s
2022-10-10 10:49:35,402 [INFO] 	Process 5 - batch 35299: mean_policy_losses: -359.866, mean_net_lifetime: 4781.9680, mean_mc_travel_dist: 1623.3509, mean_rewards: 260.8652, total_rewards: 3207.1198, mean_steps: 17.8600, mean_ecr: 0.0301 mean_entropies: 0.9033, took: 89.5011s
2022-10-10 10:49:47,604 [INFO] 	Process 2 - batch 34999: mean_policy_losses: -18.990, mean_net_lifetime: 4701.0956, mean_mc_travel_dist: 1369.1418, mean_rewards: 273.6142, total_rewards: 3361.0482, mean_steps: 16.3300, mean_ecr: 0.0405 mean_entropies: 0.6805, took: 86.1068s
2022-10-10 10:49:57,256 [INFO] 	Process 3 - batch 35899: mean_policy_losses: 20.133, mean_net_lifetime: 4500.2424, mean_mc_travel_dist: 1249.3620, mean_rewards: 279.0711, total_rewards: 3284.1245, mean_steps: 15.1700, mean_ecr: 0.0483 mean_entropies: 0.6787, took: 79.7967s
2022-10-10 10:50:06,147 [INFO] 	Process 1 - batch 30299: mean_policy_losses: -48.650, mean_net_lifetime: 4782.4041, mean_mc_travel_dist: 1759.1569, mean_rewards: 230.6190, total_rewards: 3060.4201, mean_steps: 20.3600, mean_ecr: 0.0391 mean_entropies: 1.0062, took: 99.1674s
2022-10-10 10:50:16,471 [INFO] 	Process 7 - batch 35699: mean_policy_losses: -531.537, mean_net_lifetime: 4018.9865, mean_mc_travel_dist: 1383.9677, mean_rewards: 234.3584, total_rewards: 2676.0320, mean_steps: 16.4900, mean_ecr: 0.0417 mean_entropies: 1.4335, took: 84.0959s
2022-10-10 10:50:35,297 [INFO] 	Process 4 - batch 40999: mean_policy_losses: 233.600, mean_net_lifetime: 4766.9578, mean_mc_travel_dist: 1352.5833, mean_rewards: 274.5196, total_rewards: 3443.8828, mean_steps: 16.4200, mean_ecr: 0.0476 mean_entropies: 0.8890, took: 89.1353s
2022-10-10 10:50:57,616 [INFO] 	Process 5 - batch 35399: mean_policy_losses: -378.679, mean_net_lifetime: 4327.8822, mean_mc_travel_dist: 1453.8057, mean_rewards: 260.4992, total_rewards: 2941.4935, mean_steps: 16.2400, mean_ecr: 0.0302 mean_entropies: 0.8839, took: 82.2144s
2022-10-10 10:51:14,177 [INFO] 	Process 2 - batch 35099: mean_policy_losses: 4.380, mean_net_lifetime: 4708.5148, mean_mc_travel_dist: 1379.7113, mean_rewards: 267.7639, total_rewards: 3350.1240, mean_steps: 16.6900, mean_ecr: 0.0404 mean_entropies: 0.7023, took: 86.5730s
2022-10-10 10:51:15,920 [INFO] 	Process 3 - batch 35999: mean_policy_losses: 20.737, mean_net_lifetime: 4431.8661, mean_mc_travel_dist: 1254.2305, mean_rewards: 275.5360, total_rewards: 3205.9276, mean_steps: 15.1700, mean_ecr: 0.0482 mean_entropies: 0.6955, took: 78.6711s
2022-10-10 10:51:22,896 [INFO] Process 6 - epoch 34: mean_policy_losses: -286.221, mean_net_lifetime: 2473.2042, mean_mc_travel_dist: 954.2008, mean_entropies: 0.9899, m_net_lifetime_valid: 4426.3572, took: 1350.5040s, (119.1067 / 100 batches)

2022-10-10 10:51:26,714 [INFO] 	Process 7 - batch 35799: mean_policy_losses: -741.571, mean_net_lifetime: 3454.2194, mean_mc_travel_dist: 1202.5078, mean_rewards: 242.4836, total_rewards: 2294.8587, mean_steps: 13.4500, mean_ecr: 0.0422 mean_entropies: 1.4678, took: 70.2418s
2022-10-10 10:51:41,684 [INFO] 	Process 1 - batch 30399: mean_policy_losses: 34.380, mean_net_lifetime: 4858.8341, mean_mc_travel_dist: 1765.8627, mean_rewards: 241.5510, total_rewards: 3124.7342, mean_steps: 19.4000, mean_ecr: 0.0391 mean_entropies: 1.0534, took: 95.5364s
2022-10-10 10:52:00,725 [INFO] 	Process 4 - batch 41099: mean_policy_losses: 208.513, mean_net_lifetime: 4661.2659, mean_mc_travel_dist: 1301.7410, mean_rewards: 274.2705, total_rewards: 3386.3141, mean_steps: 16.0100, mean_ecr: 0.0479 mean_entropies: 0.9036, took: 85.4281s
2022-10-10 10:52:09,910 [INFO] 	Process 6 - batch 51099: mean_policy_losses: -319.020, mean_net_lifetime: 2992.9859, mean_mc_travel_dist: 820.3525, mean_rewards: 324.3690, total_rewards: 2201.5802, mean_steps: 8.3200, mean_ecr: 0.0562 mean_entropies: 0.3006, took: 671.0833s
2022-10-10 10:52:21,979 [INFO] 	Process 5 - batch 35499: mean_policy_losses: -374.185, mean_net_lifetime: 4460.6352, mean_mc_travel_dist: 1486.4200, mean_rewards: 255.9127, total_rewards: 3035.5632, mean_steps: 16.8300, mean_ecr: 0.0308 mean_entropies: 0.8663, took: 84.3626s
2022-10-10 10:52:39,334 [INFO] 	Process 2 - batch 35199: mean_policy_losses: 34.701, mean_net_lifetime: 4697.5741, mean_mc_travel_dist: 1364.0112, mean_rewards: 271.1817, total_rewards: 3366.1550, mean_steps: 16.4400, mean_ecr: 0.0405 mean_entropies: 0.7000, took: 85.1574s
2022-10-10 10:52:42,950 [INFO] 	Process 7 - batch 35899: mean_policy_losses: -510.019, mean_net_lifetime: 3841.8932, mean_mc_travel_dist: 1352.4673, mean_rewards: 247.0315, total_rewards: 2539.7307, mean_steps: 14.7100, mean_ecr: 0.0418 mean_entropies: 1.4100, took: 76.2375s
2022-10-10 10:53:04,545 [INFO] 	Process 6 - batch 51199: mean_policy_losses: -224.971, mean_net_lifetime: 3407.2627, mean_mc_travel_dist: 926.9268, mean_rewards: 312.6052, total_rewards: 2512.8657, mean_steps: 9.9600, mean_ecr: 0.0559 mean_entropies: 0.2682, took: 54.6351s
2022-10-10 10:53:14,937 [INFO] 	Process 1 - batch 30499: mean_policy_losses: 39.483, mean_net_lifetime: 4860.4234, mean_mc_travel_dist: 1795.8948, mean_rewards: 246.1297, total_rewards: 3096.0388, mean_steps: 19.0300, mean_ecr: 0.0391 mean_entropies: 1.0035, took: 93.2533s
2022-10-10 10:53:25,783 [INFO] 	Process 4 - batch 41199: mean_policy_losses: 232.814, mean_net_lifetime: 4743.5247, mean_mc_travel_dist: 1341.8624, mean_rewards: 280.8048, total_rewards: 3430.0958, mean_steps: 16.0400, mean_ecr: 0.0475 mean_entropies: 0.8223, took: 85.0587s
2022-10-10 10:53:42,086 [INFO] 	Process 5 - batch 35599: mean_policy_losses: -514.270, mean_net_lifetime: 4028.1702, mean_mc_travel_dist: 1362.2436, mean_rewards: 251.5376, total_rewards: 2723.4547, mean_steps: 15.7300, mean_ecr: 0.0300 mean_entropies: 0.8343, took: 80.1077s
2022-10-10 10:53:55,441 [INFO] 	Process 6 - batch 51299: mean_policy_losses: -271.890, mean_net_lifetime: 3266.9760, mean_mc_travel_dist: 889.6993, mean_rewards: 323.4107, total_rewards: 2400.9844, mean_steps: 9.2100, mean_ecr: 0.0558 mean_entropies: 0.2928, took: 50.8962s
2022-10-10 10:54:01,462 [INFO] 	Process 7 - batch 35999: mean_policy_losses: -545.457, mean_net_lifetime: 3864.6161, mean_mc_travel_dist: 1370.4992, mean_rewards: 235.0249, total_rewards: 2547.0303, mean_steps: 15.6700, mean_ecr: 0.0418 mean_entropies: 1.4037, took: 78.5114s
2022-10-10 10:54:03,704 [INFO] 	Process 2 - batch 35299: mean_policy_losses: 16.212, mean_net_lifetime: 4708.2179, mean_mc_travel_dist: 1335.8651, mean_rewards: 269.7857, total_rewards: 3392.2146, mean_steps: 16.5600, mean_ecr: 0.0407 mean_entropies: 0.6415, took: 84.3695s
2022-10-10 10:54:44,965 [INFO] 	Process 6 - batch 51399: mean_policy_losses: -295.122, mean_net_lifetime: 3292.3008, mean_mc_travel_dist: 889.6138, mean_rewards: 322.6339, total_rewards: 2428.2748, mean_steps: 9.2200, mean_ecr: 0.0561 mean_entropies: 0.2648, took: 49.5243s
2022-10-10 10:54:47,298 [INFO] 	Process 4 - batch 41299: mean_policy_losses: 196.547, mean_net_lifetime: 4556.4509, mean_mc_travel_dist: 1284.8445, mean_rewards: 272.0232, total_rewards: 3297.4979, mean_steps: 15.8000, mean_ecr: 0.0481 mean_entropies: 0.8662, took: 81.5146s
2022-10-10 10:54:55,888 [INFO] 	Process 1 - batch 30599: mean_policy_losses: 54.426, mean_net_lifetime: 5022.2964, mean_mc_travel_dist: 1803.4436, mean_rewards: 227.2464, total_rewards: 3249.8092, mean_steps: 21.3800, mean_ecr: 0.0390 mean_entropies: 1.0545, took: 100.9507s
2022-10-10 10:55:10,820 [INFO] 	Process 5 - batch 35699: mean_policy_losses: -345.659, mean_net_lifetime: 4763.5962, mean_mc_travel_dist: 1598.0838, mean_rewards: 253.9582, total_rewards: 3222.8166, mean_steps: 18.3500, mean_ecr: 0.0306 mean_entropies: 0.8663, took: 88.7342s
2022-10-10 10:55:26,551 [INFO] 	Process 2 - batch 35399: mean_policy_losses: 8.023, mean_net_lifetime: 4691.3992, mean_mc_travel_dist: 1326.2820, mean_rewards: 267.3553, total_rewards: 3384.3238, mean_steps: 16.6500, mean_ecr: 0.0407 mean_entropies: 0.6240, took: 82.8471s
2022-10-10 10:55:37,169 [INFO] 	Process 6 - batch 51499: mean_policy_losses: -209.132, mean_net_lifetime: 3488.7300, mean_mc_travel_dist: 937.1610, mean_rewards: 324.0878, total_rewards: 2572.5022, mean_steps: 9.8200, mean_ecr: 0.0558 mean_entropies: 0.2619, took: 52.2032s
2022-10-10 10:56:05,445 [INFO] 	Process 4 - batch 41399: mean_policy_losses: 172.930, mean_net_lifetime: 4536.8544, mean_mc_travel_dist: 1271.8246, mean_rewards: 276.5960, total_rewards: 3295.8552, mean_steps: 15.4000, mean_ecr: 0.0481 mean_entropies: 0.8386, took: 78.1468s
2022-10-10 10:56:26,001 [INFO] 	Process 6 - batch 51599: mean_policy_losses: -228.077, mean_net_lifetime: 3273.0572, mean_mc_travel_dist: 887.2202, mean_rewards: 326.7068, total_rewards: 2412.6490, mean_steps: 9.0600, mean_ecr: 0.0558 mean_entropies: 0.2767, took: 48.8324s
2022-10-10 10:56:33,722 [INFO] 	Process 5 - batch 35799: mean_policy_losses: -364.478, mean_net_lifetime: 4334.5799, mean_mc_travel_dist: 1479.9541, mean_rewards: 246.9823, total_rewards: 2923.3208, mean_steps: 17.2600, mean_ecr: 0.0302 mean_entropies: 0.8275, took: 82.9010s
2022-10-10 10:56:34,780 [INFO] 	Process 1 - batch 30699: mean_policy_losses: 25.369, mean_net_lifetime: 4971.3257, mean_mc_travel_dist: 1796.7863, mean_rewards: 227.6280, total_rewards: 3202.5047, mean_steps: 21.2100, mean_ecr: 0.0390 mean_entropies: 1.0459, took: 98.8917s
2022-10-10 10:56:49,876 [INFO] 	Process 2 - batch 35499: mean_policy_losses: 9.456, mean_net_lifetime: 4719.2770, mean_mc_travel_dist: 1360.8859, mean_rewards: 264.9107, total_rewards: 3383.8605, mean_steps: 16.9600, mean_ecr: 0.0405 mean_entropies: 0.6123, took: 83.3253s
2022-10-10 10:57:20,693 [INFO] 	Process 6 - batch 51699: mean_policy_losses: -163.675, mean_net_lifetime: 3570.5574, mean_mc_travel_dist: 951.2387, mean_rewards: 318.5097, total_rewards: 2637.8063, mean_steps: 10.2400, mean_ecr: 0.0557 mean_entropies: 0.2605, took: 54.6924s
2022-10-10 10:57:24,665 [INFO] 	Process 4 - batch 41499: mean_policy_losses: 174.006, mean_net_lifetime: 4741.8984, mean_mc_travel_dist: 1371.3172, mean_rewards: 283.2878, total_rewards: 3390.9238, mean_steps: 15.8200, mean_ecr: 0.0475 mean_entropies: 0.8376, took: 79.2201s
2022-10-10 10:57:53,519 [INFO] 	Process 5 - batch 35899: mean_policy_losses: -436.166, mean_net_lifetime: 4192.4081, mean_mc_travel_dist: 1418.6701, mean_rewards: 249.4101, total_rewards: 2837.3988, mean_steps: 16.4800, mean_ecr: 0.0300 mean_entropies: 0.8536, took: 79.7976s
2022-10-10 10:58:10,709 [INFO] 	Process 1 - batch 30799: mean_policy_losses: 28.435, mean_net_lifetime: 5033.2469, mean_mc_travel_dist: 1821.7424, mean_rewards: 236.3947, total_rewards: 3243.0826, mean_steps: 20.5000, mean_ecr: 0.0389 mean_entropies: 1.0645, took: 95.9299s
2022-10-10 10:58:10,846 [INFO] 	Process 2 - batch 35599: mean_policy_losses: -1.472, mean_net_lifetime: 4690.7292, mean_mc_travel_dist: 1326.0927, mean_rewards: 272.4890, total_rewards: 3379.9436, mean_steps: 16.3000, mean_ecr: 0.0408 mean_entropies: 0.6340, took: 80.9692s
2022-10-10 10:58:11,048 [INFO] 	Process 6 - batch 51799: mean_policy_losses: -332.271, mean_net_lifetime: 3346.6055, mean_mc_travel_dist: 900.2250, mean_rewards: 327.8578, total_rewards: 2462.1431, mean_steps: 9.3300, mean_ecr: 0.0557 mean_entropies: 0.2550, took: 50.3547s
2022-10-10 10:58:45,717 [INFO] 	Process 4 - batch 41599: mean_policy_losses: 180.672, mean_net_lifetime: 4675.5099, mean_mc_travel_dist: 1334.0073, mean_rewards: 280.8792, total_rewards: 3370.0234, mean_steps: 15.7400, mean_ecr: 0.0478 mean_entropies: 0.8366, took: 81.0521s
2022-10-10 10:59:02,264 [INFO] 	Process 6 - batch 51899: mean_policy_losses: -302.056, mean_net_lifetime: 3401.6016, mean_mc_travel_dist: 905.3496, mean_rewards: 319.4779, total_rewards: 2515.4497, mean_steps: 9.7200, mean_ecr: 0.0559 mean_entropies: 0.2437, took: 51.2152s
2022-10-10 10:59:18,121 [INFO] 	Process 5 - batch 35999: mean_policy_losses: -431.459, mean_net_lifetime: 4473.7463, mean_mc_travel_dist: 1519.3796, mean_rewards: 247.3271, total_rewards: 3007.6583, mean_steps: 17.7000, mean_ecr: 0.0302 mean_entropies: 0.8767, took: 84.6017s
2022-10-10 10:59:31,605 [INFO] 	Process 2 - batch 35699: mean_policy_losses: 1.056, mean_net_lifetime: 4696.0030, mean_mc_travel_dist: 1321.5182, mean_rewards: 271.5714, total_rewards: 3398.5998, mean_steps: 16.3700, mean_ecr: 0.0408 mean_entropies: 0.6010, took: 80.7589s
2022-10-10 10:59:41,228 [INFO] 	Process 1 - batch 30899: mean_policy_losses: 14.316, mean_net_lifetime: 4885.7468, mean_mc_travel_dist: 1739.0493, mean_rewards: 239.6678, total_rewards: 3177.2809, mean_steps: 19.6000, mean_ecr: 0.0393 mean_entropies: 1.0743, took: 90.5175s
2022-10-10 10:59:56,787 [INFO] 	Process 6 - batch 51999: mean_policy_losses: -189.146, mean_net_lifetime: 3641.9230, mean_mc_travel_dist: 972.1821, mean_rewards: 317.3014, total_rewards: 2685.4610, mean_steps: 10.5800, mean_ecr: 0.0556 mean_entropies: 0.2597, took: 54.5235s
2022-10-10 11:00:04,663 [INFO] 	Process 4 - batch 41699: mean_policy_losses: 152.443, mean_net_lifetime: 4745.4436, mean_mc_travel_dist: 1351.7812, mean_rewards: 279.4028, total_rewards: 3426.6212, mean_steps: 16.0500, mean_ecr: 0.0477 mean_entropies: 0.8292, took: 78.9461s
2022-10-10 11:00:14,692 [INFO] Process 3 - epoch 24: mean_policy_losses: 111.751, mean_net_lifetime: 4017.2899, mean_mc_travel_dist: 1469.3460, mean_entropies: 1.2951, m_net_lifetime_valid: 4219.6559, took: 1692.3866s, (170.3059 / 100 batches)

2022-10-10 11:00:48,984 [INFO] 	Process 6 - batch 52099: mean_policy_losses: -192.889, mean_net_lifetime: 3483.1987, mean_mc_travel_dist: 941.6549, mean_rewards: 321.4333, total_rewards: 2568.7812, mean_steps: 9.8500, mean_ecr: 0.0559 mean_entropies: 0.2684, took: 52.1966s
2022-10-10 11:00:52,994 [INFO] 	Process 2 - batch 35799: mean_policy_losses: -12.167, mean_net_lifetime: 4672.9095, mean_mc_travel_dist: 1333.4123, mean_rewards: 266.4225, total_rewards: 3366.1740, mean_steps: 16.6600, mean_ecr: 0.0407 mean_entropies: 0.5876, took: 81.3893s
2022-10-10 11:01:14,283 [INFO] 	Process 1 - batch 30999: mean_policy_losses: 20.304, mean_net_lifetime: 4912.8943, mean_mc_travel_dist: 1734.2062, mean_rewards: 233.1027, total_rewards: 3202.0498, mean_steps: 20.2700, mean_ecr: 0.0393 mean_entropies: 1.0194, took: 93.0558s
2022-10-10 11:01:26,008 [INFO] 	Process 4 - batch 41799: mean_policy_losses: 174.137, mean_net_lifetime: 4791.7615, mean_mc_travel_dist: 1364.6917, mean_rewards: 280.5635, total_rewards: 3455.2445, mean_steps: 16.1400, mean_ecr: 0.0474 mean_entropies: 0.8304, took: 81.3449s
2022-10-10 11:01:31,753 [INFO] 	Process 3 - batch 36099: mean_policy_losses: 3.632, mean_net_lifetime: 4302.9893, mean_mc_travel_dist: 1192.2193, mean_rewards: 263.2886, total_rewards: 3137.4923, mean_steps: 15.3800, mean_ecr: 0.0487 mean_entropies: 0.6715, took: 615.8337s
2022-10-10 11:01:37,812 [INFO] 	Process 6 - batch 52199: mean_policy_losses: -238.437, mean_net_lifetime: 3298.6724, mean_mc_travel_dist: 895.6343, mean_rewards: 329.1592, total_rewards: 2426.0061, mean_steps: 9.0200, mean_ecr: 0.0561 mean_entropies: 0.2791, took: 48.8282s
2022-10-10 11:02:14,914 [INFO] 	Process 2 - batch 35899: mean_policy_losses: -16.091, mean_net_lifetime: 4701.8418, mean_mc_travel_dist: 1362.0548, mean_rewards: 266.6244, total_rewards: 3364.5229, mean_steps: 16.7800, mean_ecr: 0.0405 mean_entropies: 0.6227, took: 81.9199s
2022-10-10 11:02:25,703 [INFO] 	Process 6 - batch 52299: mean_policy_losses: -196.506, mean_net_lifetime: 3204.9535, mean_mc_travel_dist: 878.6611, mean_rewards: 329.3210, total_rewards: 2351.9182, mean_steps: 8.7200, mean_ecr: 0.0560 mean_entropies: 0.2657, took: 47.8905s
2022-10-10 11:02:49,172 [INFO] 	Process 3 - batch 36199: mean_policy_losses: 15.617, mean_net_lifetime: 4386.0310, mean_mc_travel_dist: 1222.6882, mean_rewards: 267.9473, total_rewards: 3191.8141, mean_steps: 15.4100, mean_ecr: 0.0486 mean_entropies: 0.6751, took: 77.4187s
2022-10-10 11:02:54,527 [INFO] 	Process 4 - batch 41899: mean_policy_losses: 207.797, mean_net_lifetime: 5181.4451, mean_mc_travel_dist: 1472.6745, mean_rewards: 279.8724, total_rewards: 3733.8815, mean_steps: 17.6000, mean_ecr: 0.0464 mean_entropies: 0.8294, took: 88.5191s
2022-10-10 11:02:55,059 [INFO] 	Process 1 - batch 31099: mean_policy_losses: -22.491, mean_net_lifetime: 4942.9987, mean_mc_travel_dist: 1785.0965, mean_rewards: 225.2092, total_rewards: 3188.2705, mean_steps: 21.4500, mean_ecr: 0.0390 mean_entropies: 1.0187, took: 100.7758s
2022-10-10 11:03:17,431 [INFO] 	Process 6 - batch 52399: mean_policy_losses: -143.651, mean_net_lifetime: 3496.7844, mean_mc_travel_dist: 947.9560, mean_rewards: 328.1552, total_rewards: 2576.8651, mean_steps: 9.7100, mean_ecr: 0.0557 mean_entropies: 0.2677, took: 51.7287s
2022-10-10 11:03:35,423 [INFO] 	Process 2 - batch 35999: mean_policy_losses: -10.622, mean_net_lifetime: 4706.4060, mean_mc_travel_dist: 1337.8901, mean_rewards: 274.5113, total_rewards: 3393.1765, mean_steps: 16.2600, mean_ecr: 0.0406 mean_entropies: 0.6125, took: 80.5093s
2022-10-10 11:04:01,327 [INFO] Process 7 - epoch 24: mean_policy_losses: -139.138, mean_net_lifetime: 3953.7083, mean_mc_travel_dist: 1664.3300, mean_entropies: 1.8843, m_net_lifetime_valid: 4216.6457, took: 1814.8336s, (170.7662 / 100 batches)

2022-10-10 11:04:06,565 [INFO] 	Process 6 - batch 52499: mean_policy_losses: -235.174, mean_net_lifetime: 3320.6054, mean_mc_travel_dist: 902.8046, mean_rewards: 328.1489, total_rewards: 2445.1422, mean_steps: 9.1600, mean_ecr: 0.0559 mean_entropies: 0.2676, took: 49.1341s
2022-10-10 11:04:06,729 [INFO] 	Process 3 - batch 36299: mean_policy_losses: 6.202, mean_net_lifetime: 4358.7542, mean_mc_travel_dist: 1210.0903, mean_rewards: 264.1751, total_rewards: 3172.7171, mean_steps: 15.5600, mean_ecr: 0.0486 mean_entropies: 0.6517, took: 77.5574s
2022-10-10 11:04:16,359 [INFO] 	Process 4 - batch 41999: mean_policy_losses: 192.405, mean_net_lifetime: 4975.0314, mean_mc_travel_dist: 1404.0370, mean_rewards: 282.1353, total_rewards: 3606.4907, mean_steps: 16.7200, mean_ecr: 0.0472 mean_entropies: 0.8259, took: 81.8322s
2022-10-10 11:04:27,291 [INFO] 	Process 1 - batch 31199: mean_policy_losses: -37.416, mean_net_lifetime: 4873.4956, mean_mc_travel_dist: 1774.4221, mean_rewards: 235.9171, total_rewards: 3126.9933, mean_steps: 19.9800, mean_ecr: 0.0390 mean_entropies: 1.0043, took: 92.2323s
2022-10-10 11:05:18,149 [INFO] 	Process 7 - batch 36099: mean_policy_losses: -580.175, mean_net_lifetime: 4179.1661, mean_mc_travel_dist: 1462.2874, mean_rewards: 235.8409, total_rewards: 2755.0821, mean_steps: 16.9000, mean_ecr: 0.0415 mean_entropies: 1.4691, took: 676.6861s
2022-10-10 11:05:19,966 [INFO] 	Process 3 - batch 36399: mean_policy_losses: 10.420, mean_net_lifetime: 4431.1516, mean_mc_travel_dist: 1233.7973, mean_rewards: 268.9022, total_rewards: 3226.3571, mean_steps: 15.5500, mean_ecr: 0.0483 mean_entropies: 0.6544, took: 73.2363s
2022-10-10 11:05:56,106 [INFO] 	Process 1 - batch 31299: mean_policy_losses: -17.455, mean_net_lifetime: 4942.2540, mean_mc_travel_dist: 1759.5051, mean_rewards: 237.6514, total_rewards: 3210.3337, mean_steps: 20.1900, mean_ecr: 0.0391 mean_entropies: 1.0824, took: 88.8159s
2022-10-10 11:06:32,283 [INFO] 	Process 3 - batch 36499: mean_policy_losses: 28.357, mean_net_lifetime: 4470.3305, mean_mc_travel_dist: 1253.9375, mean_rewards: 272.5498, total_rewards: 3257.1396, mean_steps: 15.4900, mean_ecr: 0.0483 mean_entropies: 0.6952, took: 72.3176s
2022-10-10 11:06:35,492 [INFO] 	Process 7 - batch 36199: mean_policy_losses: -549.657, mean_net_lifetime: 4041.2223, mean_mc_travel_dist: 1381.8367, mean_rewards: 231.7996, total_rewards: 2704.5223, mean_steps: 16.4700, mean_ecr: 0.0419 mean_entropies: 1.5008, took: 77.3442s
2022-10-10 11:07:26,336 [INFO] 	Process 1 - batch 31399: mean_policy_losses: -22.276, mean_net_lifetime: 5007.3819, mean_mc_travel_dist: 1745.2270, mean_rewards: 235.9268, total_rewards: 3293.7042, mean_steps: 20.7000, mean_ecr: 0.0392 mean_entropies: 1.0620, took: 90.2293s
2022-10-10 11:07:45,629 [INFO] 	Process 3 - batch 36599: mean_policy_losses: 30.917, mean_net_lifetime: 4556.9173, mean_mc_travel_dist: 1270.4360, mean_rewards: 270.5429, total_rewards: 3326.3138, mean_steps: 15.9300, mean_ecr: 0.0480 mean_entropies: 0.6523, took: 73.3450s
2022-10-10 11:08:04,204 [INFO] 	Process 7 - batch 36299: mean_policy_losses: -427.000, mean_net_lifetime: 4509.5062, mean_mc_travel_dist: 1591.5081, mean_rewards: 220.8340, total_rewards: 2964.7096, mean_steps: 19.5700, mean_ecr: 0.0414 mean_entropies: 1.4532, took: 88.7117s
2022-10-10 11:08:34,625 [INFO] Process 5 - epoch 24: mean_policy_losses: -156.154, mean_net_lifetime: 4443.4388, mean_mc_travel_dist: 2056.8169, mean_entropies: 1.6711, m_net_lifetime_valid: 4434.9369, took: 1827.3483s, (171.6435 / 100 batches)

2022-10-10 11:08:56,668 [INFO] 	Process 1 - batch 31499: mean_policy_losses: 6.462, mean_net_lifetime: 5097.5178, mean_mc_travel_dist: 1814.0808, mean_rewards: 243.2205, total_rewards: 3311.7070, mean_steps: 20.4700, mean_ecr: 0.0389 mean_entropies: 1.0272, took: 90.3321s
2022-10-10 11:08:58,727 [INFO] 	Process 3 - batch 36699: mean_policy_losses: 28.141, mean_net_lifetime: 4483.9524, mean_mc_travel_dist: 1242.5420, mean_rewards: 274.0941, total_rewards: 3267.4461, mean_steps: 15.4500, mean_ecr: 0.0483 mean_entropies: 0.6782, took: 73.0984s
2022-10-10 11:09:26,661 [INFO] 	Process 7 - batch 36399: mean_policy_losses: -403.564, mean_net_lifetime: 4362.4036, mean_mc_travel_dist: 1492.6379, mean_rewards: 230.3348, total_rewards: 2909.5804, mean_steps: 17.9600, mean_ecr: 0.0416 mean_entropies: 1.4561, took: 82.4576s
2022-10-10 11:10:01,230 [INFO] 	Process 5 - batch 36099: mean_policy_losses: -177.312, mean_net_lifetime: 5085.9852, mean_mc_travel_dist: 1703.9687, mean_rewards: 253.4242, total_rewards: 3432.2076, mean_steps: 19.1300, mean_ecr: 0.0312 mean_entropies: 0.8498, took: 643.1096s
2022-10-10 11:10:10,458 [INFO] 	Process 3 - batch 36799: mean_policy_losses: 68.308, mean_net_lifetime: 4370.2870, mean_mc_travel_dist: 1202.2394, mean_rewards: 267.4851, total_rewards: 3182.7518, mean_steps: 15.3900, mean_ecr: 0.0487 mean_entropies: 0.6854, took: 71.7307s
2022-10-10 11:10:33,307 [INFO] 	Process 7 - batch 36499: mean_policy_losses: -532.712, mean_net_lifetime: 3675.8691, mean_mc_travel_dist: 1238.7524, mean_rewards: 236.7677, total_rewards: 2480.9993, mean_steps: 14.5100, mean_ecr: 0.0421 mean_entropies: 1.4365, took: 66.6460s
2022-10-10 11:11:22,213 [INFO] 	Process 3 - batch 36899: mean_policy_losses: 54.946, mean_net_lifetime: 4505.7108, mean_mc_travel_dist: 1290.2383, mean_rewards: 274.7051, total_rewards: 3263.2685, mean_steps: 15.4700, mean_ecr: 0.0481 mean_entropies: 0.6909, took: 71.7556s
2022-10-10 11:11:24,188 [INFO] 	Process 5 - batch 36199: mean_policy_losses: -197.134, mean_net_lifetime: 5095.3594, mean_mc_travel_dist: 1711.6989, mean_rewards: 261.0760, total_rewards: 3442.3711, mean_steps: 18.6200, mean_ecr: 0.0311 mean_entropies: 0.8734, took: 82.9582s
2022-10-10 11:12:02,584 [INFO] 	Process 7 - batch 36599: mean_policy_losses: -250.267, mean_net_lifetime: 4574.9627, mean_mc_travel_dist: 1537.1045, mean_rewards: 220.7493, total_rewards: 3090.0917, mean_steps: 19.6600, mean_ecr: 0.0414 mean_entropies: 1.4324, took: 89.2757s
2022-10-10 11:12:33,776 [INFO] 	Process 3 - batch 36999: mean_policy_losses: 54.264, mean_net_lifetime: 4502.2829, mean_mc_travel_dist: 1251.5346, mean_rewards: 271.6599, total_rewards: 3284.2183, mean_steps: 15.6500, mean_ecr: 0.0481 mean_entropies: 0.6511, took: 71.5628s
2022-10-10 11:12:51,846 [INFO] 	Process 5 - batch 36299: mean_policy_losses: -114.112, mean_net_lifetime: 5377.8440, mean_mc_travel_dist: 1810.7691, mean_rewards: 262.3343, total_rewards: 3610.1463, mean_steps: 19.7000, mean_ecr: 0.0312 mean_entropies: 0.8554, took: 87.6572s
2022-10-10 11:12:56,847 [INFO] Process 2 - epoch 24: mean_policy_losses: 13.591, mean_net_lifetime: 4120.7119, mean_mc_travel_dist: 1672.6089, mean_entropies: 1.3459, m_net_lifetime_valid: 4381.2418, took: 1819.9482s, (172.3565 / 100 batches)

2022-10-10 11:13:02,420 [INFO] Process 6 - epoch 35: mean_policy_losses: -284.790, mean_net_lifetime: 2498.7054, mean_mc_travel_dist: 952.9316, mean_entropies: 0.9693, m_net_lifetime_valid: 3986.4988, took: 1299.5225s, (118.3484 / 100 batches)

2022-10-10 11:13:30,033 [INFO] Process 4 - epoch 28: mean_policy_losses: 83.164, mean_net_lifetime: 3539.4649, mean_mc_travel_dist: 1279.2592, mean_entropies: 1.5438, m_net_lifetime_valid: 4279.4510, took: 1808.0380s, (147.8894 / 100 batches)

2022-10-10 11:13:32,921 [INFO] 	Process 7 - batch 36699: mean_policy_losses: -278.305, mean_net_lifetime: 4422.4332, mean_mc_travel_dist: 1479.9214, mean_rewards: 220.6599, total_rewards: 2980.1774, mean_steps: 19.2700, mean_ecr: 0.0416 mean_entropies: 1.3853, took: 90.3368s
2022-10-10 11:13:46,069 [INFO] 	Process 6 - batch 52599: mean_policy_losses: -240.581, mean_net_lifetime: 2884.6570, mean_mc_travel_dist: 794.8197, mean_rewards: 326.4338, total_rewards: 2125.1491, mean_steps: 7.7500, mean_ecr: 0.0567 mean_entropies: 0.2780, took: 579.5040s
2022-10-10 11:13:53,026 [INFO] 	Process 3 - batch 37099: mean_policy_losses: 34.942, mean_net_lifetime: 4402.8431, mean_mc_travel_dist: 1210.5757, mean_rewards: 257.5588, total_rewards: 3227.1814, mean_steps: 16.1600, mean_ecr: 0.0485 mean_entropies: 0.6411, took: 79.2505s
2022-10-10 11:14:22,763 [INFO] 	Process 2 - batch 36099: mean_policy_losses: 17.127, mean_net_lifetime: 4700.7499, mean_mc_travel_dist: 1376.2186, mean_rewards: 263.7468, total_rewards: 3345.6361, mean_steps: 16.9400, mean_ecr: 0.0404 mean_entropies: 0.5954, took: 647.3407s
2022-10-10 11:14:24,294 [INFO] 	Process 5 - batch 36399: mean_policy_losses: -145.932, mean_net_lifetime: 5090.0753, mean_mc_travel_dist: 1702.0697, mean_rewards: 255.7806, total_rewards: 3434.7220, mean_steps: 19.1200, mean_ecr: 0.0311 mean_entropies: 0.8009, took: 92.4480s
2022-10-10 11:14:37,929 [INFO] 	Process 6 - batch 52699: mean_policy_losses: -267.295, mean_net_lifetime: 3342.9127, mean_mc_travel_dist: 899.0979, mean_rewards: 320.6696, total_rewards: 2463.7921, mean_steps: 9.4000, mean_ecr: 0.0559 mean_entropies: 0.2458, took: 51.8596s
2022-10-10 11:14:58,862 [INFO] 	Process 4 - batch 42099: mean_policy_losses: 191.481, mean_net_lifetime: 4620.2756, mean_mc_travel_dist: 1300.5351, mean_rewards: 261.9524, total_rewards: 3347.4685, mean_steps: 16.6800, mean_ecr: 0.0478 mean_entropies: 0.8169, took: 642.5030s
2022-10-10 11:15:11,285 [INFO] 	Process 7 - batch 36799: mean_policy_losses: -247.934, mean_net_lifetime: 4611.9251, mean_mc_travel_dist: 1557.8015, mean_rewards: 221.7243, total_rewards: 3103.6199, mean_steps: 20.1100, mean_ecr: 0.0411 mean_entropies: 1.3337, took: 98.3651s
2022-10-10 11:15:15,783 [INFO] 	Process 3 - batch 37199: mean_policy_losses: -6.720, mean_net_lifetime: 4217.1814, mean_mc_travel_dist: 1160.3575, mean_rewards: 245.9261, total_rewards: 3089.1123, mean_steps: 16.2000, mean_ecr: 0.0490 mean_entropies: 0.6282, took: 82.7567s
2022-10-10 11:15:32,112 [INFO] 	Process 6 - batch 52799: mean_policy_losses: -154.481, mean_net_lifetime: 3468.0558, mean_mc_travel_dist: 933.4708, mean_rewards: 328.7372, total_rewards: 2552.0475, mean_steps: 9.5700, mean_ecr: 0.0558 mean_entropies: 0.2624, took: 54.1826s
2022-10-10 11:15:48,335 [INFO] 	Process 2 - batch 36199: mean_policy_losses: -5.976, mean_net_lifetime: 4695.4088, mean_mc_travel_dist: 1347.9376, mean_rewards: 266.0190, total_rewards: 3370.9440, mean_steps: 16.7500, mean_ecr: 0.0406 mean_entropies: 0.5922, took: 85.5713s
2022-10-10 11:15:53,112 [INFO] 	Process 5 - batch 36499: mean_policy_losses: -288.130, mean_net_lifetime: 4676.0180, mean_mc_travel_dist: 1566.0085, mean_rewards: 252.3959, total_rewards: 3153.6657, mean_steps: 17.8800, mean_ecr: 0.0309 mean_entropies: 0.8344, took: 88.8183s
2022-10-10 11:16:24,168 [INFO] 	Process 4 - batch 42199: mean_policy_losses: 199.440, mean_net_lifetime: 4684.0379, mean_mc_travel_dist: 1321.3086, mean_rewards: 273.0206, total_rewards: 3390.3990, mean_steps: 16.2600, mean_ecr: 0.0481 mean_entropies: 0.8240, took: 85.3050s
2022-10-10 11:16:25,848 [INFO] 	Process 6 - batch 52899: mean_policy_losses: -186.264, mean_net_lifetime: 3493.9025, mean_mc_travel_dist: 927.4970, mean_rewards: 328.0826, total_rewards: 2577.2400, mean_steps: 9.6600, mean_ecr: 0.0559 mean_entropies: 0.2475, took: 53.7361s
2022-10-10 11:16:35,541 [INFO] 	Process 7 - batch 36899: mean_policy_losses: -414.572, mean_net_lifetime: 4314.4353, mean_mc_travel_dist: 1443.0186, mean_rewards: 241.1468, total_rewards: 2915.3078, mean_steps: 17.1300, mean_ecr: 0.0414 mean_entropies: 1.3812, took: 84.2553s
2022-10-10 11:16:37,484 [INFO] 	Process 3 - batch 37299: mean_policy_losses: 23.842, mean_net_lifetime: 4377.8580, mean_mc_travel_dist: 1192.3681, mean_rewards: 259.3884, total_rewards: 3216.6206, mean_steps: 15.9200, mean_ecr: 0.0489 mean_entropies: 0.6357, took: 81.7007s
2022-10-10 11:17:13,185 [INFO] 	Process 2 - batch 36299: mean_policy_losses: 7.486, mean_net_lifetime: 4705.9473, mean_mc_travel_dist: 1327.0101, mean_rewards: 269.9213, total_rewards: 3400.4311, mean_steps: 16.5400, mean_ecr: 0.0407 mean_entropies: 0.5866, took: 84.8499s
2022-10-10 11:17:17,407 [INFO] 	Process 6 - batch 52999: mean_policy_losses: -224.994, mean_net_lifetime: 3343.5171, mean_mc_travel_dist: 892.3085, mean_rewards: 333.1810, total_rewards: 2461.4647, mean_steps: 9.0800, mean_ecr: 0.0560 mean_entropies: 0.2521, took: 51.5591s
2022-10-10 11:17:25,761 [INFO] 	Process 5 - batch 36599: mean_policy_losses: -263.666, mean_net_lifetime: 4680.3144, mean_mc_travel_dist: 1598.2555, mean_rewards: 245.6798, total_rewards: 3139.8321, mean_steps: 18.5100, mean_ecr: 0.0306 mean_entropies: 0.7998, took: 92.6495s
2022-10-10 11:17:51,915 [INFO] 	Process 4 - batch 42299: mean_policy_losses: 204.724, mean_net_lifetime: 4922.9495, mean_mc_travel_dist: 1422.1876, mean_rewards: 275.1359, total_rewards: 3531.9728, mean_steps: 16.9200, mean_ecr: 0.0472 mean_entropies: 0.7866, took: 87.7476s
2022-10-10 11:17:52,525 [INFO] Process 1 - epoch 21: mean_policy_losses: 48.209, mean_net_lifetime: 4648.9645, mean_mc_travel_dist: 2122.0660, mean_entropies: 1.4733, m_net_lifetime_valid: 4283.7520, took: 1965.2552s, (197.9173 / 100 batches)

2022-10-10 11:17:59,771 [INFO] 	Process 3 - batch 37399: mean_policy_losses: 16.024, mean_net_lifetime: 4327.9445, mean_mc_travel_dist: 1183.6124, mean_rewards: 253.1748, total_rewards: 3165.8818, mean_steps: 16.1700, mean_ecr: 0.0487 mean_entropies: 0.6161, took: 82.2867s
2022-10-10 11:18:03,998 [INFO] 	Process 7 - batch 36999: mean_policy_losses: -419.985, mean_net_lifetime: 4321.1127, mean_mc_travel_dist: 1581.6954, mean_rewards: 236.7888, total_rewards: 2777.9498, mean_steps: 17.8100, mean_ecr: 0.0416 mean_entropies: 1.3605, took: 88.4578s
2022-10-10 11:18:09,705 [INFO] 	Process 6 - batch 53099: mean_policy_losses: -144.174, mean_net_lifetime: 3416.2404, mean_mc_travel_dist: 913.2359, mean_rewards: 335.2064, total_rewards: 2521.9350, mean_steps: 9.2400, mean_ecr: 0.0562 mean_entropies: 0.2393, took: 52.2972s
2022-10-10 11:18:38,883 [INFO] 	Process 2 - batch 36399: mean_policy_losses: 6.994, mean_net_lifetime: 4695.1596, mean_mc_travel_dist: 1350.9099, mean_rewards: 266.6938, total_rewards: 3373.5338, mean_steps: 16.7300, mean_ecr: 0.0406 mean_entropies: 0.6201, took: 85.6978s
2022-10-10 11:18:58,608 [INFO] 	Process 5 - batch 36699: mean_policy_losses: -339.965, mean_net_lifetime: 4675.3181, mean_mc_travel_dist: 1589.4289, mean_rewards: 253.1675, total_rewards: 3129.4354, mean_steps: 18.1800, mean_ecr: 0.0303 mean_entropies: 0.8224, took: 92.8466s
2022-10-10 11:19:00,261 [INFO] 	Process 6 - batch 53199: mean_policy_losses: -275.660, mean_net_lifetime: 3181.6030, mean_mc_travel_dist: 862.0989, mean_rewards: 333.7410, total_rewards: 2335.5519, mean_steps: 8.6200, mean_ecr: 0.0558 mean_entropies: 0.2825, took: 50.5571s
2022-10-10 11:19:17,819 [INFO] 	Process 4 - batch 42399: mean_policy_losses: 141.909, mean_net_lifetime: 4566.6581, mean_mc_travel_dist: 1305.5768, mean_rewards: 268.8852, total_rewards: 3291.9362, mean_steps: 16.0100, mean_ecr: 0.0480 mean_entropies: 0.8609, took: 85.9034s
2022-10-10 11:19:22,469 [INFO] 	Process 3 - batch 37499: mean_policy_losses: 27.949, mean_net_lifetime: 4381.2770, mean_mc_travel_dist: 1219.5876, mean_rewards: 263.5012, total_rewards: 3188.5663, mean_steps: 15.7000, mean_ecr: 0.0486 mean_entropies: 0.6410, took: 82.6983s
2022-10-10 11:19:26,734 [INFO] 	Process 7 - batch 37099: mean_policy_losses: -585.694, mean_net_lifetime: 3878.9798, mean_mc_travel_dist: 1340.3417, mean_rewards: 236.0772, total_rewards: 2588.4643, mean_steps: 15.7300, mean_ecr: 0.0419 mean_entropies: 1.4019, took: 82.7356s
2022-10-10 11:19:33,299 [INFO] 	Process 1 - batch 31599: mean_policy_losses: 24.986, mean_net_lifetime: 4920.6654, mean_mc_travel_dist: 1778.1619, mean_rewards: 240.5804, total_rewards: 3165.6058, mean_steps: 19.8500, mean_ecr: 0.0390 mean_entropies: 1.0163, took: 636.6307s
2022-10-10 11:19:57,448 [INFO] 	Process 6 - batch 53299: mean_policy_losses: -147.796, mean_net_lifetime: 3611.0110, mean_mc_travel_dist: 963.1141, mean_rewards: 321.5890, total_rewards: 2665.7047, mean_steps: 10.2500, mean_ecr: 0.0560 mean_entropies: 0.2259, took: 57.1863s
2022-10-10 11:20:08,873 [INFO] 	Process 2 - batch 36499: mean_policy_losses: -8.284, mean_net_lifetime: 4683.6472, mean_mc_travel_dist: 1337.3421, mean_rewards: 262.7780, total_rewards: 3372.3129, mean_steps: 16.9600, mean_ecr: 0.0407 mean_entropies: 0.5969, took: 89.9908s
2022-10-10 11:20:27,790 [INFO] 	Process 5 - batch 36799: mean_policy_losses: -378.768, mean_net_lifetime: 4511.1986, mean_mc_travel_dist: 1499.9349, mean_rewards: 246.6861, total_rewards: 3065.2996, mean_steps: 17.7100, mean_ecr: 0.0308 mean_entropies: 0.7933, took: 89.1802s
2022-10-10 11:20:39,354 [INFO] 	Process 4 - batch 42499: mean_policy_losses: 102.498, mean_net_lifetime: 4353.0499, mean_mc_travel_dist: 1212.3551, mean_rewards: 271.4176, total_rewards: 3179.3487, mean_steps: 15.0100, mean_ecr: 0.0487 mean_entropies: 0.8378, took: 81.5348s
2022-10-10 11:20:52,924 [INFO] 	Process 6 - batch 53399: mean_policy_losses: -236.346, mean_net_lifetime: 3525.3968, mean_mc_travel_dist: 939.7107, mean_rewards: 323.1994, total_rewards: 2600.9854, mean_steps: 9.9000, mean_ecr: 0.0559 mean_entropies: 0.2386, took: 55.4760s
2022-10-10 11:20:55,178 [INFO] 	Process 7 - batch 37199: mean_policy_losses: -458.783, mean_net_lifetime: 4291.2911, mean_mc_travel_dist: 1439.1128, mean_rewards: 233.9776, total_rewards: 2895.2017, mean_steps: 17.5300, mean_ecr: 0.0415 mean_entropies: 1.3679, took: 88.4440s
2022-10-10 11:21:13,221 [INFO] 	Process 1 - batch 31699: mean_policy_losses: 51.757, mean_net_lifetime: 5100.1912, mean_mc_travel_dist: 1842.8808, mean_rewards: 244.9093, total_rewards: 3286.1047, mean_steps: 20.1500, mean_ecr: 0.0388 mean_entropies: 0.9848, took: 99.9228s
2022-10-10 11:21:34,636 [INFO] 	Process 2 - batch 36599: mean_policy_losses: 4.388, mean_net_lifetime: 4710.1114, mean_mc_travel_dist: 1320.0572, mean_rewards: 272.3309, total_rewards: 3411.1534, mean_steps: 16.3700, mean_ecr: 0.0407 mean_entropies: 0.5621, took: 85.7616s
2022-10-10 11:21:45,717 [INFO] 	Process 6 - batch 53499: mean_policy_losses: -161.550, mean_net_lifetime: 3425.3419, mean_mc_travel_dist: 910.9509, mean_rewards: 327.2179, total_rewards: 2532.1424, mean_steps: 9.5200, mean_ecr: 0.0558 mean_entropies: 0.2678, took: 52.7937s
2022-10-10 11:22:01,140 [INFO] 	Process 5 - batch 36899: mean_policy_losses: -219.048, mean_net_lifetime: 4882.6639, mean_mc_travel_dist: 1635.2880, mean_rewards: 246.3727, total_rewards: 3284.3412, mean_steps: 18.9900, mean_ecr: 0.0308 mean_entropies: 0.8199, took: 93.3515s
2022-10-10 11:22:07,034 [INFO] 	Process 4 - batch 42599: mean_policy_losses: 155.454, mean_net_lifetime: 4541.2396, mean_mc_travel_dist: 1303.0525, mean_rewards: 263.5818, total_rewards: 3269.1279, mean_steps: 16.2600, mean_ecr: 0.0480 mean_entropies: 0.8709, took: 87.6802s
2022-10-10 11:22:30,255 [INFO] 	Process 6 - batch 53599: mean_policy_losses: -257.570, mean_net_lifetime: 2851.6021, mean_mc_travel_dist: 760.6090, mean_rewards: 326.0073, total_rewards: 2125.9692, mean_steps: 7.7400, mean_ecr: 0.0566 mean_entropies: 0.3030, took: 44.5376s
2022-10-10 11:22:30,368 [INFO] 	Process 7 - batch 37299: mean_policy_losses: -331.432, mean_net_lifetime: 4442.9176, mean_mc_travel_dist: 1483.2288, mean_rewards: 227.1029, total_rewards: 3012.3799, mean_steps: 18.7800, mean_ecr: 0.0414 mean_entropies: 1.3842, took: 95.1899s
2022-10-10 11:22:56,212 [INFO] 	Process 1 - batch 31799: mean_policy_losses: 21.103, mean_net_lifetime: 4891.1470, mean_mc_travel_dist: 1732.7121, mean_rewards: 224.8089, total_rewards: 3190.2004, mean_steps: 21.4400, mean_ecr: 0.0392 mean_entropies: 1.0294, took: 102.9902s
2022-10-10 11:23:02,063 [INFO] 	Process 2 - batch 36699: mean_policy_losses: 5.439, mean_net_lifetime: 4696.2883, mean_mc_travel_dist: 1358.8710, mean_rewards: 266.0299, total_rewards: 3357.2809, mean_steps: 16.8000, mean_ecr: 0.0406 mean_entropies: 0.5818, took: 87.4280s
2022-10-10 11:23:24,085 [INFO] 	Process 6 - batch 53699: mean_policy_losses: -279.350, mean_net_lifetime: 3410.4370, mean_mc_travel_dist: 915.6564, mean_rewards: 324.0722, total_rewards: 2508.9915, mean_steps: 9.5200, mean_ecr: 0.0557 mean_entropies: 0.2331, took: 53.8295s
2022-10-10 11:23:33,868 [INFO] 	Process 4 - batch 42699: mean_policy_losses: 187.330, mean_net_lifetime: 4745.0924, mean_mc_travel_dist: 1338.8981, mean_rewards: 273.7520, total_rewards: 3433.1771, mean_steps: 16.4300, mean_ecr: 0.0478 mean_entropies: 0.8077, took: 86.8352s
2022-10-10 11:23:38,921 [INFO] 	Process 5 - batch 36999: mean_policy_losses: -215.971, mean_net_lifetime: 4999.3615, mean_mc_travel_dist: 1698.4269, mean_rewards: 245.4242, total_rewards: 3354.4570, mean_steps: 19.8300, mean_ecr: 0.0306 mean_entropies: 0.8046, took: 97.7808s
2022-10-10 11:23:56,341 [INFO] 	Process 7 - batch 37399: mean_policy_losses: -455.716, mean_net_lifetime: 4297.1935, mean_mc_travel_dist: 1458.5395, mean_rewards: 240.1903, total_rewards: 2877.6641, mean_steps: 17.3200, mean_ecr: 0.0416 mean_entropies: 1.3642, took: 85.9733s
2022-10-10 11:24:21,432 [INFO] 	Process 6 - batch 53799: mean_policy_losses: -142.999, mean_net_lifetime: 3645.6092, mean_mc_travel_dist: 969.2764, mean_rewards: 324.9326, total_rewards: 2692.1952, mean_steps: 10.2400, mean_ecr: 0.0557 mean_entropies: 0.2304, took: 57.3473s
2022-10-10 11:24:28,646 [INFO] 	Process 2 - batch 36799: mean_policy_losses: -6.120, mean_net_lifetime: 4687.8952, mean_mc_travel_dist: 1328.9886, mean_rewards: 267.0978, total_rewards: 3383.7802, mean_steps: 16.6800, mean_ecr: 0.0407 mean_entropies: 0.5492, took: 86.5827s
2022-10-10 11:24:39,494 [INFO] 	Process 1 - batch 31899: mean_policy_losses: 8.682, mean_net_lifetime: 4927.1142, mean_mc_travel_dist: 1770.8187, mean_rewards: 227.9929, total_rewards: 3188.5098, mean_steps: 20.9700, mean_ecr: 0.0391 mean_entropies: 1.0462, took: 103.2832s
2022-10-10 11:24:58,683 [INFO] 	Process 4 - batch 42799: mean_policy_losses: 147.525, mean_net_lifetime: 4744.2719, mean_mc_travel_dist: 1334.4665, mean_rewards: 276.4389, total_rewards: 3435.1294, mean_steps: 16.2600, mean_ecr: 0.0476 mean_entropies: 0.7866, took: 84.8136s
2022-10-10 11:25:08,238 [INFO] 	Process 5 - batch 37099: mean_policy_losses: -342.123, mean_net_lifetime: 4459.1207, mean_mc_travel_dist: 1500.9038, mean_rewards: 244.2748, total_rewards: 3014.5937, mean_steps: 17.7900, mean_ecr: 0.0304 mean_entropies: 0.7805, took: 89.3176s
2022-10-10 11:25:17,957 [INFO] 	Process 6 - batch 53899: mean_policy_losses: -209.216, mean_net_lifetime: 3578.6582, mean_mc_travel_dist: 951.5255, mean_rewards: 322.4246, total_rewards: 2647.5658, mean_steps: 10.1400, mean_ecr: 0.0556 mean_entropies: 0.2253, took: 56.5255s
2022-10-10 11:25:24,302 [INFO] 	Process 7 - batch 37499: mean_policy_losses: -514.388, mean_net_lifetime: 4246.0384, mean_mc_travel_dist: 1450.6195, mean_rewards: 232.1112, total_rewards: 2846.4581, mean_steps: 17.6600, mean_ecr: 0.0415 mean_entropies: 1.3370, took: 87.9614s
2022-10-10 11:25:53,658 [INFO] 	Process 2 - batch 36899: mean_policy_losses: -7.709, mean_net_lifetime: 4686.9762, mean_mc_travel_dist: 1309.6901, mean_rewards: 266.5329, total_rewards: 3405.4440, mean_steps: 16.6700, mean_ecr: 0.0408 mean_entropies: 0.5573, took: 85.0129s
2022-10-10 11:26:13,858 [INFO] 	Process 6 - batch 53999: mean_policy_losses: -155.694, mean_net_lifetime: 3646.5045, mean_mc_travel_dist: 970.8695, mean_rewards: 317.4685, total_rewards: 2702.1213, mean_steps: 10.5300, mean_ecr: 0.0557 mean_entropies: 0.2186, took: 55.9011s
2022-10-10 11:26:20,342 [INFO] 	Process 1 - batch 31999: mean_policy_losses: 65.971, mean_net_lifetime: 5087.3164, mean_mc_travel_dist: 1829.6940, mean_rewards: 235.0337, total_rewards: 3283.7937, mean_steps: 21.0100, mean_ecr: 0.0389 mean_entropies: 1.0284, took: 100.8476s
2022-10-10 11:26:22,209 [INFO] 	Process 4 - batch 42899: mean_policy_losses: 166.087, mean_net_lifetime: 4774.0874, mean_mc_travel_dist: 1327.8850, mean_rewards: 277.6141, total_rewards: 3473.9603, mean_steps: 16.2400, mean_ecr: 0.0477 mean_entropies: 0.7609, took: 83.5268s
2022-10-10 11:26:27,704 [INFO] 	Process 5 - batch 37199: mean_policy_losses: -453.038, mean_net_lifetime: 4025.8011, mean_mc_travel_dist: 1336.5593, mean_rewards: 241.6634, total_rewards: 2748.1686, mean_steps: 16.3700, mean_ecr: 0.0306 mean_entropies: 0.7518, took: 79.4656s
2022-10-10 11:27:14,144 [INFO] 	Process 2 - batch 36999: mean_policy_losses: -11.864, mean_net_lifetime: 4679.9237, mean_mc_travel_dist: 1321.3316, mean_rewards: 265.3094, total_rewards: 3383.4226, mean_steps: 16.7500, mean_ecr: 0.0407 mean_entropies: 0.5417, took: 80.4842s
2022-10-10 11:27:43,518 [INFO] 	Process 4 - batch 42999: mean_policy_losses: 149.142, mean_net_lifetime: 4735.4487, mean_mc_travel_dist: 1322.6397, mean_rewards: 278.7506, total_rewards: 3450.7350, mean_steps: 16.0500, mean_ecr: 0.0478 mean_entropies: 0.7781, took: 81.3087s
2022-10-10 11:27:47,283 [INFO] 	Process 5 - batch 37299: mean_policy_losses: -410.601, mean_net_lifetime: 4340.2868, mean_mc_travel_dist: 1446.7810, mean_rewards: 251.9408, total_rewards: 2948.9821, mean_steps: 16.9200, mean_ecr: 0.0305 mean_entropies: 0.7808, took: 79.5794s
2022-10-10 11:27:49,427 [INFO] 	Process 1 - batch 32099: mean_policy_losses: 14.710, mean_net_lifetime: 4990.1998, mean_mc_travel_dist: 1833.0390, mean_rewards: 245.6514, total_rewards: 3184.3049, mean_steps: 19.5900, mean_ecr: 0.0389 mean_entropies: 1.0204, took: 89.0842s
2022-10-10 11:28:32,742 [INFO] 	Process 2 - batch 37099: mean_policy_losses: -4.584, mean_net_lifetime: 4690.1092, mean_mc_travel_dist: 1331.3007, mean_rewards: 273.4987, total_rewards: 3380.9810, mean_steps: 16.2300, mean_ecr: 0.0406 mean_entropies: 0.5979, took: 78.5997s
2022-10-10 11:29:02,408 [INFO] 	Process 4 - batch 43099: mean_policy_losses: 75.691, mean_net_lifetime: 4575.6878, mean_mc_travel_dist: 1291.2030, mean_rewards: 273.9993, total_rewards: 3306.7936, mean_steps: 15.7300, mean_ecr: 0.0481 mean_entropies: 0.8200, took: 78.8902s
2022-10-10 11:29:06,310 [INFO] 	Process 5 - batch 37399: mean_policy_losses: -403.198, mean_net_lifetime: 4421.9690, mean_mc_travel_dist: 1488.8683, mean_rewards: 257.4165, total_rewards: 2999.7988, mean_steps: 16.9400, mean_ecr: 0.0305 mean_entropies: 0.8033, took: 79.0269s
2022-10-10 11:29:10,018 [INFO] Process 3 - epoch 25: mean_policy_losses: 108.339, mean_net_lifetime: 4032.7997, mean_mc_travel_dist: 1459.4688, mean_entropies: 1.2696, m_net_lifetime_valid: 4042.2440, took: 1735.3245s, (167.9973 / 100 batches)

2022-10-10 11:29:19,937 [INFO] 	Process 1 - batch 32199: mean_policy_losses: 36.196, mean_net_lifetime: 5167.1138, mean_mc_travel_dist: 1848.7078, mean_rewards: 252.3303, total_rewards: 3340.3796, mean_steps: 19.8000, mean_ecr: 0.0388 mean_entropies: 1.0912, took: 90.5103s
2022-10-10 11:29:52,573 [INFO] 	Process 2 - batch 37199: mean_policy_losses: -16.202, mean_net_lifetime: 4719.1347, mean_mc_travel_dist: 1355.2098, mean_rewards: 274.8579, total_rewards: 3389.6358, mean_steps: 16.2900, mean_ecr: 0.0404 mean_entropies: 0.6551, took: 79.8298s
2022-10-10 11:30:24,901 [INFO] 	Process 4 - batch 43199: mean_policy_losses: 112.167, mean_net_lifetime: 4767.5165, mean_mc_travel_dist: 1375.1870, mean_rewards: 272.9281, total_rewards: 3412.0873, mean_steps: 16.5400, mean_ecr: 0.0476 mean_entropies: 0.8335, took: 82.4937s
2022-10-10 11:30:27,026 [INFO] 	Process 3 - batch 37599: mean_policy_losses: 3.597, mean_net_lifetime: 4417.9167, mean_mc_travel_dist: 1244.5408, mean_rewards: 275.3376, total_rewards: 3207.0724, mean_steps: 15.0900, mean_ecr: 0.0484 mean_entropies: 0.6577, took: 664.5578s
2022-10-10 11:30:34,774 [INFO] 	Process 5 - batch 37499: mean_policy_losses: -381.850, mean_net_lifetime: 4801.7747, mean_mc_travel_dist: 1637.5631, mean_rewards: 252.5171, total_rewards: 3214.9271, mean_steps: 18.3500, mean_ecr: 0.0303 mean_entropies: 0.8674, took: 88.4645s
2022-10-10 11:31:00,760 [INFO] 	Process 1 - batch 32299: mean_policy_losses: -2.554, mean_net_lifetime: 5159.3848, mean_mc_travel_dist: 1787.7749, mean_rewards: 236.0525, total_rewards: 3398.5099, mean_steps: 21.2600, mean_ecr: 0.0391 mean_entropies: 1.1055, took: 100.8233s
2022-10-10 11:31:10,189 [INFO] 	Process 2 - batch 37299: mean_policy_losses: -34.133, mean_net_lifetime: 4716.4609, mean_mc_travel_dist: 1332.7884, mean_rewards: 273.3580, total_rewards: 3402.5811, mean_steps: 16.3600, mean_ecr: 0.0407 mean_entropies: 0.6103, took: 77.6170s
2022-10-10 11:31:40,590 [INFO] 	Process 3 - batch 37699: mean_policy_losses: -18.520, mean_net_lifetime: 4449.3021, mean_mc_travel_dist: 1230.8703, mean_rewards: 277.0172, total_rewards: 3246.7231, mean_steps: 15.1200, mean_ecr: 0.0485 mean_entropies: 0.6543, took: 73.5640s
2022-10-10 11:31:45,029 [INFO] 	Process 4 - batch 43299: mean_policy_losses: 125.585, mean_net_lifetime: 5027.4938, mean_mc_travel_dist: 1449.5385, mean_rewards: 281.8392, total_rewards: 3611.6659, mean_steps: 16.9200, mean_ecr: 0.0471 mean_entropies: 0.7622, took: 80.1277s
2022-10-10 11:32:25,413 [INFO] 	Process 2 - batch 37399: mean_policy_losses: -46.876, mean_net_lifetime: 4688.6922, mean_mc_travel_dist: 1341.3101, mean_rewards: 276.7783, total_rewards: 3365.7682, mean_steps: 16.0800, mean_ecr: 0.0407 mean_entropies: 0.6111, took: 75.2234s
2022-10-10 11:32:38,081 [INFO] 	Process 1 - batch 32399: mean_policy_losses: -42.756, mean_net_lifetime: 5063.3147, mean_mc_travel_dist: 1784.7660, mean_rewards: 234.6263, total_rewards: 3317.1597, mean_steps: 21.1000, mean_ecr: 0.0391 mean_entropies: 1.0504, took: 97.3212s
2022-10-10 11:32:55,272 [INFO] 	Process 3 - batch 37799: mean_policy_losses: 10.179, mean_net_lifetime: 4508.8484, mean_mc_travel_dist: 1240.7672, mean_rewards: 277.6707, total_rewards: 3299.5719, mean_steps: 15.3000, mean_ecr: 0.0482 mean_entropies: 0.6291, took: 74.6815s
2022-10-10 11:33:08,989 [INFO] 	Process 4 - batch 43399: mean_policy_losses: 111.559, mean_net_lifetime: 5062.5613, mean_mc_travel_dist: 1489.1629, mean_rewards: 274.9424, total_rewards: 3601.3751, mean_steps: 17.5400, mean_ecr: 0.0467 mean_entropies: 0.8015, took: 83.9591s
2022-10-10 11:33:41,272 [INFO] 	Process 2 - batch 37499: mean_policy_losses: -25.499, mean_net_lifetime: 4727.3715, mean_mc_travel_dist: 1370.3065, mean_rewards: 278.1172, total_rewards: 3377.2337, mean_steps: 16.1300, mean_ecr: 0.0405 mean_entropies: 0.6361, took: 75.8593s
2022-10-10 11:34:07,791 [INFO] 	Process 3 - batch 37899: mean_policy_losses: -22.044, mean_net_lifetime: 4392.5094, mean_mc_travel_dist: 1240.2091, mean_rewards: 272.9682, total_rewards: 3185.8669, mean_steps: 15.1600, mean_ecr: 0.0483 mean_entropies: 0.6556, took: 72.5193s
2022-10-10 11:34:09,347 [INFO] 	Process 1 - batch 32499: mean_policy_losses: -68.702, mean_net_lifetime: 4869.9349, mean_mc_travel_dist: 1703.8680, mean_rewards: 229.5049, total_rewards: 3192.0768, mean_steps: 20.5600, mean_ecr: 0.0393 mean_entropies: 1.1206, took: 91.2660s
2022-10-10 11:34:27,743 [INFO] 	Process 4 - batch 43499: mean_policy_losses: 96.201, mean_net_lifetime: 4908.7378, mean_mc_travel_dist: 1397.5098, mean_rewards: 275.4261, total_rewards: 3546.2078, mean_steps: 16.8800, mean_ecr: 0.0474 mean_entropies: 0.8103, took: 78.7545s
2022-10-10 11:35:14,959 [INFO] 	Process 3 - batch 37999: mean_policy_losses: -24.255, mean_net_lifetime: 4332.9099, mean_mc_travel_dist: 1222.5933, mean_rewards: 273.3949, total_rewards: 3139.4808, mean_steps: 14.9000, mean_ecr: 0.0486 mean_entropies: 0.6612, took: 67.1681s
2022-10-10 11:35:18,388 [INFO] Process 7 - epoch 25: mean_policy_losses: -150.773, mean_net_lifetime: 3966.6786, mean_mc_travel_dist: 1656.2592, mean_entropies: 1.8651, m_net_lifetime_valid: 4091.4516, took: 1877.0599s, (168.9613 / 100 batches)

2022-10-10 11:35:31,696 [INFO] 	Process 1 - batch 32599: mean_policy_losses: -44.486, mean_net_lifetime: 5014.7728, mean_mc_travel_dist: 1826.7603, mean_rewards: 244.2239, total_rewards: 3219.3013, mean_steps: 19.7000, mean_ecr: 0.0390 mean_entropies: 1.0626, took: 82.3484s
2022-10-10 11:35:37,045 [INFO] Process 6 - epoch 36: mean_policy_losses: -282.590, mean_net_lifetime: 2523.4181, mean_mc_travel_dist: 951.6543, mean_entropies: 0.9493, m_net_lifetime_valid: 3964.0368, took: 1354.6212s, (117.5205 / 100 batches)

2022-10-10 11:36:24,898 [INFO] 	Process 6 - batch 54099: mean_policy_losses: -253.231, mean_net_lifetime: 3298.8354, mean_mc_travel_dist: 888.4510, mean_rewards: 333.7683, total_rewards: 2428.7635, mean_steps: 8.8900, mean_ecr: 0.0560 mean_entropies: 0.2595, took: 611.0393s
2022-10-10 11:36:27,188 [INFO] 	Process 3 - batch 38099: mean_policy_losses: 41.479, mean_net_lifetime: 4408.0841, mean_mc_travel_dist: 1210.9642, mean_rewards: 269.1893, total_rewards: 3226.2792, mean_steps: 15.4200, mean_ecr: 0.0487 mean_entropies: 0.6422, took: 72.2289s
2022-10-10 11:36:28,484 [INFO] 	Process 7 - batch 37599: mean_policy_losses: -656.939, mean_net_lifetime: 3923.9192, mean_mc_travel_dist: 1399.2728, mean_rewards: 242.2517, total_rewards: 2576.1026, mean_steps: 15.5300, mean_ecr: 0.0418 mean_entropies: 1.4423, took: 664.1815s
2022-10-10 11:37:04,993 [INFO] 	Process 6 - batch 54199: mean_policy_losses: -342.617, mean_net_lifetime: 2812.0675, mean_mc_travel_dist: 775.7765, mean_rewards: 330.0185, total_rewards: 2079.9369, mean_steps: 7.4800, mean_ecr: 0.0566 mean_entropies: 0.3164, took: 40.0956s
2022-10-10 11:37:09,506 [INFO] 	Process 1 - batch 32699: mean_policy_losses: 94.302, mean_net_lifetime: 5185.4259, mean_mc_travel_dist: 1818.1808, mean_rewards: 231.9263, total_rewards: 3392.0248, mean_steps: 21.8400, mean_ecr: 0.0389 mean_entropies: 1.0781, took: 97.8107s
2022-10-10 11:37:42,160 [INFO] 	Process 3 - batch 38199: mean_policy_losses: 65.384, mean_net_lifetime: 4519.1383, mean_mc_travel_dist: 1238.4059, mean_rewards: 271.4072, total_rewards: 3306.9280, mean_steps: 15.6900, mean_ecr: 0.0484 mean_entropies: 0.6250, took: 74.9719s
2022-10-10 11:37:45,784 [INFO] 	Process 7 - batch 37699: mean_policy_losses: -512.012, mean_net_lifetime: 4110.0894, mean_mc_travel_dist: 1442.1958, mean_rewards: 230.3316, total_rewards: 2722.5258, mean_steps: 16.9800, mean_ecr: 0.0417 mean_entropies: 1.4553, took: 77.3000s
2022-10-10 11:37:52,763 [INFO] 	Process 6 - batch 54299: mean_policy_losses: -242.466, mean_net_lifetime: 3216.6705, mean_mc_travel_dist: 878.0657, mean_rewards: 331.2511, total_rewards: 2375.6301, mean_steps: 8.7400, mean_ecr: 0.0559 mean_entropies: 0.2736, took: 47.7701s
2022-10-10 11:38:35,744 [INFO] 	Process 6 - batch 54399: mean_policy_losses: -336.127, mean_net_lifetime: 2926.1498, mean_mc_travel_dist: 791.2465, mean_rewards: 332.7481, total_rewards: 2154.6570, mean_steps: 7.8400, mean_ecr: 0.0563 mean_entropies: 0.2891, took: 42.9812s
2022-10-10 11:38:46,367 [INFO] 	Process 1 - batch 32799: mean_policy_losses: 87.854, mean_net_lifetime: 5128.1449, mean_mc_travel_dist: 1751.6018, mean_rewards: 232.5786, total_rewards: 3411.3434, mean_steps: 21.5000, mean_ecr: 0.0392 mean_entropies: 1.0530, took: 96.8608s
2022-10-10 11:38:59,182 [INFO] 	Process 3 - batch 38299: mean_policy_losses: 33.915, mean_net_lifetime: 4400.3813, mean_mc_travel_dist: 1199.0835, mean_rewards: 262.4936, total_rewards: 3228.5454, mean_steps: 15.8200, mean_ecr: 0.0486 mean_entropies: 0.6394, took: 77.0224s
2022-10-10 11:39:05,822 [INFO] 	Process 7 - batch 37799: mean_policy_losses: -525.375, mean_net_lifetime: 4196.9975, mean_mc_travel_dist: 1450.7043, mean_rewards: 225.7329, total_rewards: 2793.3598, mean_steps: 17.7500, mean_ecr: 0.0416 mean_entropies: 1.3734, took: 80.0384s
2022-10-10 11:39:28,672 [INFO] 	Process 6 - batch 54499: mean_policy_losses: -126.965, mean_net_lifetime: 3661.9715, mean_mc_travel_dist: 978.9138, mean_rewards: 324.9099, total_rewards: 2699.4383, mean_steps: 10.2800, mean_ecr: 0.0557 mean_entropies: 0.2122, took: 52.9283s
2022-10-10 11:39:59,231 [INFO] Process 5 - epoch 25: mean_policy_losses: -161.457, mean_net_lifetime: 4455.3628, mean_mc_travel_dist: 2038.3483, mean_entropies: 1.6369, m_net_lifetime_valid: 4312.4677, took: 1884.6036s, (169.7871 / 100 batches)

2022-10-10 11:40:17,144 [INFO] 	Process 3 - batch 38399: mean_policy_losses: 3.226, mean_net_lifetime: 4232.1015, mean_mc_travel_dist: 1162.1866, mean_rewards: 255.0891, total_rewards: 3099.4962, mean_steps: 15.6500, mean_ecr: 0.0490 mean_entropies: 0.6331, took: 77.9616s
2022-10-10 11:40:19,433 [INFO] 	Process 6 - batch 54599: mean_policy_losses: -177.705, mean_net_lifetime: 3501.1472, mean_mc_travel_dist: 935.6173, mean_rewards: 331.8533, total_rewards: 2574.5699, mean_steps: 9.6100, mean_ecr: 0.0558 mean_entropies: 0.2211, took: 50.7608s
2022-10-10 11:40:25,068 [INFO] 	Process 1 - batch 32899: mean_policy_losses: 82.420, mean_net_lifetime: 5246.3971, mean_mc_travel_dist: 1851.4750, mean_rewards: 233.0783, total_rewards: 3420.2324, mean_steps: 21.8600, mean_ecr: 0.0388 mean_entropies: 1.0377, took: 98.7002s
2022-10-10 11:40:28,167 [INFO] 	Process 7 - batch 37899: mean_policy_losses: -443.503, mean_net_lifetime: 4298.1730, mean_mc_travel_dist: 1487.0129, mean_rewards: 232.0791, total_rewards: 2854.7522, mean_steps: 17.7300, mean_ecr: 0.0415 mean_entropies: 1.3673, took: 82.3436s
2022-10-10 11:41:14,238 [INFO] 	Process 6 - batch 54699: mean_policy_losses: -102.112, mean_net_lifetime: 3671.6988, mean_mc_travel_dist: 974.5463, mean_rewards: 331.1430, total_rewards: 2703.6419, mean_steps: 10.1200, mean_ecr: 0.0558 mean_entropies: 0.2094, took: 54.8043s
2022-10-10 11:41:35,179 [INFO] 	Process 5 - batch 37599: mean_policy_losses: -187.320, mean_net_lifetime: 5010.2593, mean_mc_travel_dist: 1693.2313, mean_rewards: 246.3265, total_rewards: 3369.2217, mean_steps: 19.6300, mean_ecr: 0.0313 mean_entropies: 0.7827, took: 660.4042s
2022-10-10 11:41:37,831 [INFO] 	Process 3 - batch 38499: mean_policy_losses: 31.715, mean_net_lifetime: 4351.0490, mean_mc_travel_dist: 1195.0221, mean_rewards: 255.8853, total_rewards: 3180.8334, mean_steps: 16.0500, mean_ecr: 0.0488 mean_entropies: 0.6229, took: 80.6872s
2022-10-10 11:41:56,138 [INFO] 	Process 7 - batch 37999: mean_policy_losses: -312.283, mean_net_lifetime: 4492.8017, mean_mc_travel_dist: 1548.5571, mean_rewards: 228.4211, total_rewards: 2991.6465, mean_steps: 18.8000, mean_ecr: 0.0413 mean_entropies: 1.3473, took: 87.9720s
2022-10-10 11:41:58,920 [INFO] 	Process 1 - batch 32999: mean_policy_losses: 33.244, mean_net_lifetime: 4909.5841, mean_mc_travel_dist: 1764.1161, mean_rewards: 242.3683, total_rewards: 3179.8466, mean_steps: 19.4900, mean_ecr: 0.0392 mean_entropies: 1.0154, took: 93.8526s
2022-10-10 11:42:09,660 [INFO] 	Process 6 - batch 54799: mean_policy_losses: -89.203, mean_net_lifetime: 3684.6261, mean_mc_travel_dist: 986.2775, mean_rewards: 327.4124, total_rewards: 2711.9373, mean_steps: 10.2800, mean_ecr: 0.0558 mean_entropies: 0.2118, took: 55.4225s
2022-10-10 11:42:14,679 [INFO] Process 2 - epoch 25: mean_policy_losses: 12.712, mean_net_lifetime: 4143.8404, mean_mc_travel_dist: 1659.3293, mean_entropies: 1.3158, m_net_lifetime_valid: 4261.4156, took: 1757.8297s, (170.2834 / 100 batches)

2022-10-10 11:42:54,629 [INFO] 	Process 3 - batch 38599: mean_policy_losses: 25.557, mean_net_lifetime: 4356.7998, mean_mc_travel_dist: 1200.3633, mean_rewards: 261.8776, total_rewards: 3181.0054, mean_steps: 15.6800, mean_ecr: 0.0486 mean_entropies: 0.6241, took: 76.7980s
2022-10-10 11:42:59,367 [INFO] Process 4 - epoch 29: mean_policy_losses: 85.278, mean_net_lifetime: 3580.6997, mean_mc_travel_dist: 1281.5641, mean_entropies: 1.5185, m_net_lifetime_valid: 4198.9566, took: 1769.3322s, (146.9560 / 100 batches)

2022-10-10 11:43:04,384 [INFO] 	Process 6 - batch 54899: mean_policy_losses: -174.095, mean_net_lifetime: 3595.0539, mean_mc_travel_dist: 957.8663, mean_rewards: 325.4878, total_rewards: 2653.8910, mean_steps: 10.0800, mean_ecr: 0.0556 mean_entropies: 0.2260, took: 54.7237s
2022-10-10 11:43:05,875 [INFO] 	Process 5 - batch 37699: mean_policy_losses: -220.029, mean_net_lifetime: 4930.8118, mean_mc_travel_dist: 1650.7360, mean_rewards: 250.7460, total_rewards: 3331.5576, mean_steps: 18.9900, mean_ecr: 0.0309 mean_entropies: 0.7688, took: 90.6958s
2022-10-10 11:43:15,906 [INFO] 	Process 7 - batch 38099: mean_policy_losses: -481.094, mean_net_lifetime: 4223.8824, mean_mc_travel_dist: 1438.5497, mean_rewards: 237.0799, total_rewards: 2826.9456, mean_steps: 17.0200, mean_ecr: 0.0417 mean_entropies: 1.3214, took: 79.7674s
2022-10-10 11:43:37,981 [INFO] 	Process 2 - batch 37599: mean_policy_losses: -8.556, mean_net_lifetime: 4665.9598, mean_mc_travel_dist: 1321.2569, mean_rewards: 265.1368, total_rewards: 3367.5172, mean_steps: 16.6900, mean_ecr: 0.0408 mean_entropies: 0.5084, took: 596.7090s
2022-10-10 11:44:00,911 [INFO] 	Process 6 - batch 54999: mean_policy_losses: -99.672, mean_net_lifetime: 3685.3716, mean_mc_travel_dist: 979.2176, mean_rewards: 324.2655, total_rewards: 2721.3295, mean_steps: 10.3800, mean_ecr: 0.0557 mean_entropies: 0.2133, took: 56.5268s
2022-10-10 11:44:15,400 [INFO] 	Process 3 - batch 38699: mean_policy_losses: 10.380, mean_net_lifetime: 4310.4929, mean_mc_travel_dist: 1180.9429, mean_rewards: 256.1364, total_rewards: 3160.3234, mean_steps: 15.8800, mean_ecr: 0.0488 mean_entropies: 0.6124, took: 80.7709s
2022-10-10 11:44:27,103 [INFO] 	Process 4 - batch 43599: mean_policy_losses: 177.092, mean_net_lifetime: 4892.2955, mean_mc_travel_dist: 1386.3600, mean_rewards: 274.6656, total_rewards: 3531.4343, mean_steps: 16.8800, mean_ecr: 0.0471 mean_entropies: 0.7665, took: 599.3599s
2022-10-10 11:44:31,529 [INFO] 	Process 5 - batch 37799: mean_policy_losses: -398.165, mean_net_lifetime: 4283.8119, mean_mc_travel_dist: 1451.0326, mean_rewards: 248.4262, total_rewards: 2886.1643, mean_steps: 17.1200, mean_ecr: 0.0304 mean_entropies: 0.7406, took: 85.6541s
2022-10-10 11:44:40,087 [INFO] 	Process 7 - batch 38199: mean_policy_losses: -518.231, mean_net_lifetime: 4251.6709, mean_mc_travel_dist: 1493.5962, mean_rewards: 237.8264, total_rewards: 2813.9632, mean_steps: 17.1400, mean_ecr: 0.0413 mean_entropies: 1.2792, took: 84.1812s
2022-10-10 11:44:58,878 [INFO] 	Process 6 - batch 55099: mean_policy_losses: -59.259, mean_net_lifetime: 3768.1316, mean_mc_travel_dist: 1006.1206, mean_rewards: 322.5001, total_rewards: 2785.6783, mean_steps: 10.7300, mean_ecr: 0.0557 mean_entropies: 0.2076, took: 57.9672s
2022-10-10 11:45:01,627 [INFO] 	Process 2 - batch 37699: mean_policy_losses: -11.818, mean_net_lifetime: 4712.7431, mean_mc_travel_dist: 1348.7642, mean_rewards: 267.7510, total_rewards: 3390.0717, mean_steps: 16.7000, mean_ecr: 0.0406 mean_entropies: 0.5449, took: 83.6459s
2022-10-10 11:45:37,691 [INFO] 	Process 3 - batch 38799: mean_policy_losses: -3.846, mean_net_lifetime: 4246.0541, mean_mc_travel_dist: 1164.3817, mean_rewards: 249.7984, total_rewards: 3110.6438, mean_steps: 16.0700, mean_ecr: 0.0490 mean_entropies: 0.6013, took: 82.2907s
2022-10-10 11:45:51,807 [INFO] 	Process 4 - batch 43699: mean_policy_losses: 171.077, mean_net_lifetime: 4856.7158, mean_mc_travel_dist: 1361.0668, mean_rewards: 280.2248, total_rewards: 3519.8996, mean_steps: 16.4000, mean_ecr: 0.0475 mean_entropies: 0.7325, took: 84.7039s
2022-10-10 11:45:56,434 [INFO] 	Process 6 - batch 55199: mean_policy_losses: -74.399, mean_net_lifetime: 3707.6925, mean_mc_travel_dist: 984.7371, mean_rewards: 320.5303, total_rewards: 2743.3634, mean_steps: 10.6000, mean_ecr: 0.0556 mean_entropies: 0.2110, took: 57.5562s
2022-10-10 11:45:58,421 [INFO] 	Process 5 - batch 37899: mean_policy_losses: -486.962, mean_net_lifetime: 4264.3271, mean_mc_travel_dist: 1427.1438, mean_rewards: 247.9239, total_rewards: 2890.8005, mean_steps: 17.0200, mean_ecr: 0.0303 mean_entropies: 0.7329, took: 86.8926s
2022-10-10 11:46:09,627 [INFO] 	Process 7 - batch 38299: mean_policy_losses: -415.997, mean_net_lifetime: 4360.2542, mean_mc_travel_dist: 1515.6036, mean_rewards: 231.5230, total_rewards: 2885.3139, mean_steps: 18.1100, mean_ecr: 0.0415 mean_entropies: 1.2928, took: 89.5400s
2022-10-10 11:46:27,924 [INFO] 	Process 2 - batch 37799: mean_policy_losses: -25.338, mean_net_lifetime: 4635.4824, mean_mc_travel_dist: 1323.3211, mean_rewards: 258.1341, total_rewards: 3336.8624, mean_steps: 17.0600, mean_ecr: 0.0408 mean_entropies: 0.5099, took: 86.2972s
2022-10-10 11:46:52,850 [INFO] 	Process 6 - batch 55299: mean_policy_losses: -154.954, mean_net_lifetime: 3536.9116, mean_mc_travel_dist: 942.9515, mean_rewards: 319.2002, total_rewards: 2620.0092, mean_steps: 10.1200, mean_ecr: 0.0559 mean_entropies: 0.2233, took: 56.4161s
2022-10-10 11:47:00,117 [INFO] 	Process 3 - batch 38899: mean_policy_losses: -3.022, mean_net_lifetime: 4247.3124, mean_mc_travel_dist: 1174.9269, mean_rewards: 254.1695, total_rewards: 3094.1111, mean_steps: 15.7500, mean_ecr: 0.0489 mean_entropies: 0.6040, took: 82.4263s
2022-10-10 11:47:17,044 [INFO] 	Process 4 - batch 43799: mean_policy_losses: 154.476, mean_net_lifetime: 4902.2722, mean_mc_travel_dist: 1415.6541, mean_rewards: 284.9957, total_rewards: 3517.4242, mean_steps: 16.3100, mean_ecr: 0.0471 mean_entropies: 0.7221, took: 85.2377s
2022-10-10 11:47:29,599 [INFO] 	Process 5 - batch 37999: mean_policy_losses: -410.207, mean_net_lifetime: 4439.9990, mean_mc_travel_dist: 1548.9194, mean_rewards: 240.4856, total_rewards: 2950.1733, mean_steps: 18.5300, mean_ecr: 0.0295 mean_entropies: 0.7514, took: 91.1773s
2022-10-10 11:47:33,212 [INFO] 	Process 7 - batch 38399: mean_policy_losses: -510.297, mean_net_lifetime: 4202.9010, mean_mc_travel_dist: 1465.0780, mean_rewards: 234.1004, total_rewards: 2779.2637, mean_steps: 17.2200, mean_ecr: 0.0414 mean_entropies: 1.2952, took: 83.5850s
2022-10-10 11:47:52,027 [INFO] 	Process 6 - batch 55399: mean_policy_losses: -127.550, mean_net_lifetime: 3697.0096, mean_mc_travel_dist: 988.0253, mean_rewards: 319.4222, total_rewards: 2730.2096, mean_steps: 10.5900, mean_ecr: 0.0556 mean_entropies: 0.2186, took: 59.1757s
2022-10-10 11:47:53,579 [INFO] 	Process 2 - batch 37899: mean_policy_losses: -9.602, mean_net_lifetime: 4687.9613, mean_mc_travel_dist: 1351.6092, mean_rewards: 261.6054, total_rewards: 3365.3057, mean_steps: 17.0300, mean_ecr: 0.0406 mean_entropies: 0.5319, took: 85.6543s
2022-10-10 11:48:19,737 [INFO] 	Process 3 - batch 38999: mean_policy_losses: 26.208, mean_net_lifetime: 4375.6057, mean_mc_travel_dist: 1194.1223, mean_rewards: 266.0256, total_rewards: 3201.8911, mean_steps: 15.4900, mean_ecr: 0.0489 mean_entropies: 0.5977, took: 79.6192s
2022-10-10 11:48:40,183 [INFO] 	Process 4 - batch 43899: mean_policy_losses: 184.017, mean_net_lifetime: 4910.0090, mean_mc_travel_dist: 1378.7555, mean_rewards: 279.9552, total_rewards: 3558.9361, mean_steps: 16.5800, mean_ecr: 0.0472 mean_entropies: 0.7373, took: 83.1386s
2022-10-10 11:48:47,360 [INFO] 	Process 6 - batch 55499: mean_policy_losses: -156.534, mean_net_lifetime: 3584.8399, mean_mc_travel_dist: 956.2206, mean_rewards: 321.1210, total_rewards: 2646.9862, mean_steps: 10.1900, mean_ecr: 0.0558 mean_entropies: 0.2138, took: 55.3342s
2022-10-10 11:48:51,464 [INFO] 	Process 7 - batch 38499: mean_policy_losses: -584.799, mean_net_lifetime: 4000.3657, mean_mc_travel_dist: 1398.5018, mean_rewards: 237.8942, total_rewards: 2642.5233, mean_steps: 16.3500, mean_ecr: 0.0417 mean_entropies: 1.3359, took: 78.2526s
2022-10-10 11:49:01,422 [INFO] 	Process 5 - batch 38099: mean_policy_losses: -309.667, mean_net_lifetime: 4709.8881, mean_mc_travel_dist: 1653.7910, mean_rewards: 242.7624, total_rewards: 3118.8638, mean_steps: 19.2100, mean_ecr: 0.0297 mean_entropies: 0.7373, took: 91.8241s
2022-10-10 11:49:15,231 [INFO] 	Process 2 - batch 37999: mean_policy_losses: 0.065, mean_net_lifetime: 4710.1076, mean_mc_travel_dist: 1327.9378, mean_rewards: 269.5160, total_rewards: 3405.3367, mean_steps: 16.5700, mean_ecr: 0.0407 mean_entropies: 0.5299, took: 81.6522s
2022-10-10 11:50:00,028 [INFO] 	Process 4 - batch 43999: mean_policy_losses: 187.629, mean_net_lifetime: 4899.8526, mean_mc_travel_dist: 1390.6239, mean_rewards: 281.7759, total_rewards: 3545.5313, mean_steps: 16.4700, mean_ecr: 0.0473 mean_entropies: 0.7562, took: 79.8453s
2022-10-10 11:50:16,865 [INFO] 	Process 7 - batch 38599: mean_policy_losses: -404.520, mean_net_lifetime: 4525.0215, mean_mc_travel_dist: 1579.6714, mean_rewards: 231.1844, total_rewards: 2987.8256, mean_steps: 18.8800, mean_ecr: 0.0410 mean_entropies: 1.3545, took: 85.4010s
2022-10-10 11:50:33,106 [INFO] 	Process 2 - batch 38099: mean_policy_losses: -8.422, mean_net_lifetime: 4691.0862, mean_mc_travel_dist: 1336.6751, mean_rewards: 274.5922, total_rewards: 3377.0341, mean_steps: 16.1600, mean_ecr: 0.0406 mean_entropies: 0.5945, took: 77.8757s
2022-10-10 11:50:34,570 [INFO] 	Process 5 - batch 38199: mean_policy_losses: -255.392, mean_net_lifetime: 5237.4882, mean_mc_travel_dist: 1862.2087, mean_rewards: 248.0485, total_rewards: 3419.1268, mean_steps: 20.5000, mean_ecr: 0.0296 mean_entropies: 0.7636, took: 93.1473s
2022-10-10 11:51:22,887 [INFO] 	Process 4 - batch 44099: mean_policy_losses: 144.235, mean_net_lifetime: 4894.1866, mean_mc_travel_dist: 1387.1348, mean_rewards: 274.2587, total_rewards: 3536.2941, mean_steps: 16.9000, mean_ecr: 0.0472 mean_entropies: 0.7904, took: 82.8584s
2022-10-10 11:51:34,843 [INFO] 	Process 7 - batch 38699: mean_policy_losses: -640.879, mean_net_lifetime: 4150.4054, mean_mc_travel_dist: 1460.9429, mean_rewards: 238.4450, total_rewards: 2731.0546, mean_steps: 16.8500, mean_ecr: 0.0414 mean_entropies: 1.3803, took: 77.9775s
2022-10-10 11:51:44,250 [INFO] Process 1 - epoch 22: mean_policy_losses: 47.117, mean_net_lifetime: 4666.9228, mean_mc_travel_dist: 2107.1980, mean_entropies: 1.4540, m_net_lifetime_valid: 4334.6354, took: 2031.7244s, (194.9369 / 100 batches)

2022-10-10 11:51:50,002 [INFO] 	Process 2 - batch 38199: mean_policy_losses: 1.398, mean_net_lifetime: 4719.3823, mean_mc_travel_dist: 1356.4012, mean_rewards: 275.5871, total_rewards: 3385.1796, mean_steps: 16.2100, mean_ecr: 0.0405 mean_entropies: 0.5838, took: 76.8951s
2022-10-10 11:51:57,144 [INFO] 	Process 5 - batch 38299: mean_policy_losses: -347.871, mean_net_lifetime: 4712.9769, mean_mc_travel_dist: 1632.1888, mean_rewards: 255.3523, total_rewards: 3135.9104, mean_steps: 17.9900, mean_ecr: 0.0301 mean_entropies: 0.7662, took: 82.5739s
2022-10-10 11:52:43,720 [INFO] 	Process 4 - batch 44199: mean_policy_losses: 134.134, mean_net_lifetime: 4681.8390, mean_mc_travel_dist: 1319.0238, mean_rewards: 280.8084, total_rewards: 3391.5466, mean_steps: 15.7500, mean_ecr: 0.0478 mean_entropies: 0.7808, took: 80.8327s
2022-10-10 11:52:56,955 [INFO] 	Process 7 - batch 38799: mean_policy_losses: -622.707, mean_net_lifetime: 4107.1755, mean_mc_travel_dist: 1484.0567, mean_rewards: 235.9243, total_rewards: 2679.7947, mean_steps: 16.9200, mean_ecr: 0.0416 mean_entropies: 1.3729, took: 82.1122s
2022-10-10 11:53:11,045 [INFO] 	Process 2 - batch 38299: mean_policy_losses: 1.664, mean_net_lifetime: 4711.6336, mean_mc_travel_dist: 1330.5717, mean_rewards: 275.8872, total_rewards: 3408.2136, mean_steps: 16.2000, mean_ecr: 0.0406 mean_entropies: 0.5794, took: 81.0431s
2022-10-10 11:53:22,207 [INFO] 	Process 1 - batch 33099: mean_policy_losses: 1.968, mean_net_lifetime: 4932.3258, mean_mc_travel_dist: 1790.8055, mean_rewards: 236.2265, total_rewards: 3160.7920, mean_steps: 20.2700, mean_ecr: 0.0391 mean_entropies: 1.0089, took: 683.2867s
2022-10-10 11:53:26,598 [INFO] 	Process 5 - batch 38399: mean_policy_losses: -312.743, mean_net_lifetime: 4779.9791, mean_mc_travel_dist: 1648.3636, mean_rewards: 253.1165, total_rewards: 3181.2581, mean_steps: 18.6500, mean_ecr: 0.0300 mean_entropies: 0.7596, took: 89.4538s
2022-10-10 11:54:05,749 [INFO] 	Process 4 - batch 44299: mean_policy_losses: 112.273, mean_net_lifetime: 4686.5751, mean_mc_travel_dist: 1337.3957, mean_rewards: 276.2822, total_rewards: 3382.7404, mean_steps: 15.9900, mean_ecr: 0.0477 mean_entropies: 0.7710, took: 82.0294s
2022-10-10 11:54:13,412 [INFO] 	Process 7 - batch 38899: mean_policy_losses: -604.334, mean_net_lifetime: 4032.5717, mean_mc_travel_dist: 1407.6393, mean_rewards: 244.7016, total_rewards: 2669.2164, mean_steps: 15.5500, mean_ecr: 0.0417 mean_entropies: 1.3531, took: 76.4571s
2022-10-10 11:54:34,207 [INFO] 	Process 2 - batch 38399: mean_policy_losses: 1.457, mean_net_lifetime: 4700.9252, mean_mc_travel_dist: 1333.0955, mean_rewards: 271.3569, total_rewards: 3392.6278, mean_steps: 16.4400, mean_ecr: 0.0406 mean_entropies: 0.5852, took: 83.1620s
2022-10-10 11:54:48,582 [INFO] 	Process 5 - batch 38499: mean_policy_losses: -418.215, mean_net_lifetime: 4251.8205, mean_mc_travel_dist: 1429.7340, mean_rewards: 252.7740, total_rewards: 2884.5343, mean_steps: 16.6700, mean_ecr: 0.0305 mean_entropies: 0.7978, took: 81.9841s
2022-10-10 11:54:56,645 [INFO] 	Process 1 - batch 33199: mean_policy_losses: 61.935, mean_net_lifetime: 4986.9882, mean_mc_travel_dist: 1794.1278, mean_rewards: 242.7623, total_rewards: 3222.6922, mean_steps: 19.8300, mean_ecr: 0.0391 mean_entropies: 1.0831, took: 94.4381s
2022-10-10 11:55:23,136 [INFO] 	Process 7 - batch 38999: mean_policy_losses: -684.284, mean_net_lifetime: 3489.8861, mean_mc_travel_dist: 1234.2046, mean_rewards: 238.2973, total_rewards: 2306.5675, mean_steps: 14.0400, mean_ecr: 0.0423 mean_entropies: 1.3116, took: 69.7239s
2022-10-10 11:55:23,622 [INFO] 	Process 4 - batch 44399: mean_policy_losses: 102.477, mean_net_lifetime: 4392.0947, mean_mc_travel_dist: 1236.2050, mean_rewards: 269.4460, total_rewards: 3183.8200, mean_steps: 15.2700, mean_ecr: 0.0486 mean_entropies: 0.8145, took: 77.8727s
2022-10-10 11:55:53,952 [INFO] 	Process 2 - batch 38499: mean_policy_losses: 4.947, mean_net_lifetime: 4718.2478, mean_mc_travel_dist: 1328.4240, mean_rewards: 276.2416, total_rewards: 3411.7747, mean_steps: 16.1900, mean_ecr: 0.0406 mean_entropies: 0.6130, took: 79.7448s
2022-10-10 11:56:20,369 [INFO] 	Process 5 - batch 38599: mean_policy_losses: -267.314, mean_net_lifetime: 5152.4126, mean_mc_travel_dist: 1769.7205, mean_rewards: 250.2294, total_rewards: 3435.1376, mean_steps: 19.8500, mean_ecr: 0.0304 mean_entropies: 0.8092, took: 91.7869s
2022-10-10 11:56:34,270 [INFO] 	Process 1 - batch 33299: mean_policy_losses: 72.678, mean_net_lifetime: 5292.2011, mean_mc_travel_dist: 1832.9705, mean_rewards: 241.6522, total_rewards: 3490.9163, mean_steps: 21.1300, mean_ecr: 0.0389 mean_entropies: 1.1008, took: 97.6247s
2022-10-10 11:56:43,822 [INFO] 	Process 4 - batch 44499: mean_policy_losses: 80.563, mean_net_lifetime: 4709.9699, mean_mc_travel_dist: 1347.5463, mean_rewards: 273.4236, total_rewards: 3391.2990, mean_steps: 16.3300, mean_ecr: 0.0478 mean_entropies: 0.8020, took: 80.1999s
2022-10-10 11:57:09,672 [INFO] 	Process 2 - batch 38599: mean_policy_losses: -12.005, mean_net_lifetime: 4757.7194, mean_mc_travel_dist: 1348.0150, mean_rewards: 282.2184, total_rewards: 3437.2808, mean_steps: 15.9500, mean_ecr: 0.0405 mean_entropies: 0.6641, took: 75.7206s
2022-10-10 11:57:43,899 [INFO] 	Process 5 - batch 38699: mean_policy_losses: -376.497, mean_net_lifetime: 4902.3640, mean_mc_travel_dist: 1655.6525, mean_rewards: 265.1146, total_rewards: 3302.6596, mean_steps: 18.0600, mean_ecr: 0.0304 mean_entropies: 0.8309, took: 83.5304s
2022-10-10 11:58:02,186 [INFO] 	Process 4 - batch 44599: mean_policy_losses: 48.609, mean_net_lifetime: 4535.6786, mean_mc_travel_dist: 1290.1054, mean_rewards: 274.4350, total_rewards: 3272.9555, mean_steps: 15.5300, mean_ecr: 0.0482 mean_entropies: 0.8156, took: 78.3641s
2022-10-10 11:58:05,494 [INFO] Process 3 - epoch 26: mean_policy_losses: 104.634, mean_net_lifetime: 4045.7651, mean_mc_travel_dist: 1449.7440, mean_entropies: 1.2450, m_net_lifetime_valid: 4008.3047, took: 1735.4741s, (165.9955 / 100 batches)

2022-10-10 11:58:05,812 [INFO] 	Process 1 - batch 33399: mean_policy_losses: 10.803, mean_net_lifetime: 5169.8959, mean_mc_travel_dist: 1816.9068, mean_rewards: 247.0091, total_rewards: 3379.0112, mean_steps: 20.2000, mean_ecr: 0.0391 mean_entropies: 1.1004, took: 91.5421s
2022-10-10 11:58:08,748 [INFO] Process 6 - epoch 37: mean_policy_losses: -279.488, mean_net_lifetime: 2549.5387, mean_mc_travel_dist: 951.2024, mean_entropies: 0.9300, m_net_lifetime_valid: 4026.2821, took: 1351.7006s, (116.7843 / 100 batches)

2022-10-10 11:58:29,987 [INFO] 	Process 2 - batch 38699: mean_policy_losses: 7.239, mean_net_lifetime: 4772.8773, mean_mc_travel_dist: 1361.5162, mean_rewards: 280.0537, total_rewards: 3442.5048, mean_steps: 16.1900, mean_ecr: 0.0405 mean_entropies: 0.6554, took: 80.3147s
2022-10-10 11:58:49,063 [INFO] 	Process 5 - batch 38799: mean_policy_losses: -666.021, mean_net_lifetime: 3620.8990, mean_mc_travel_dist: 1170.0232, mean_rewards: 278.8842, total_rewards: 2502.8986, mean_steps: 13.0900, mean_ecr: 0.0303 mean_entropies: 0.7868, took: 65.1639s
2022-10-10 11:59:02,999 [INFO] 	Process 6 - batch 55599: mean_policy_losses: -179.848, mean_net_lifetime: 3399.0793, mean_mc_travel_dist: 910.4196, mean_rewards: 323.0367, total_rewards: 2503.9330, mean_steps: 9.5200, mean_ecr: 0.0562 mean_entropies: 0.2298, took: 615.6382s
2022-10-10 11:59:22,091 [INFO] 	Process 3 - batch 39099: mean_policy_losses: 22.595, mean_net_lifetime: 4324.9910, mean_mc_travel_dist: 1231.0207, mean_rewards: 272.9052, total_rewards: 3119.9925, mean_steps: 14.9000, mean_ecr: 0.0486 mean_entropies: 0.6462, took: 662.3544s
2022-10-10 11:59:24,940 [INFO] 	Process 4 - batch 44699: mean_policy_losses: 103.995, mean_net_lifetime: 4740.9283, mean_mc_travel_dist: 1377.3069, mean_rewards: 278.9304, total_rewards: 3397.7607, mean_steps: 16.0100, mean_ecr: 0.0475 mean_entropies: 0.7609, took: 82.7541s
2022-10-10 11:59:44,884 [INFO] 	Process 1 - batch 33499: mean_policy_losses: -16.839, mean_net_lifetime: 4978.2032, mean_mc_travel_dist: 1844.4323, mean_rewards: 242.7126, total_rewards: 3159.1068, mean_steps: 19.8000, mean_ecr: 0.0389 mean_entropies: 0.9569, took: 99.0726s
2022-10-10 11:59:54,000 [INFO] 	Process 2 - batch 38799: mean_policy_losses: 0.660, mean_net_lifetime: 4716.4807, mean_mc_travel_dist: 1335.4419, mean_rewards: 275.9743, total_rewards: 3404.7777, mean_steps: 16.1900, mean_ecr: 0.0406 mean_entropies: 0.5782, took: 84.0129s
2022-10-10 11:59:57,178 [INFO] 	Process 6 - batch 55699: mean_policy_losses: -265.259, mean_net_lifetime: 3448.6187, mean_mc_travel_dist: 925.2371, mean_rewards: 324.3089, total_rewards: 2542.5967, mean_steps: 9.6600, mean_ecr: 0.0558 mean_entropies: 0.2329, took: 54.1793s
2022-10-10 12:00:19,843 [INFO] 	Process 5 - batch 38899: mean_policy_losses: -404.589, mean_net_lifetime: 4710.0083, mean_mc_travel_dist: 1604.7942, mean_rewards: 263.2782, total_rewards: 3155.7440, mean_steps: 18.1000, mean_ecr: 0.0300 mean_entropies: 0.7558, took: 90.7791s
2022-10-10 12:00:41,110 [INFO] 	Process 3 - batch 39199: mean_policy_losses: 17.660, mean_net_lifetime: 4328.7428, mean_mc_travel_dist: 1218.2236, mean_rewards: 270.5146, total_rewards: 3137.2764, mean_steps: 15.0400, mean_ecr: 0.0486 mean_entropies: 0.6478, took: 79.0196s
2022-10-10 12:00:49,534 [INFO] 	Process 4 - batch 44799: mean_policy_losses: 112.343, mean_net_lifetime: 4742.1333, mean_mc_travel_dist: 1348.8373, mean_rewards: 278.1529, total_rewards: 3427.3548, mean_steps: 16.1300, mean_ecr: 0.0478 mean_entropies: 0.7629, took: 84.5942s
2022-10-10 12:00:51,759 [INFO] 	Process 6 - batch 55799: mean_policy_losses: -187.680, mean_net_lifetime: 3483.7592, mean_mc_travel_dist: 938.6180, mean_rewards: 328.1951, total_rewards: 2571.0167, mean_steps: 9.6500, mean_ecr: 0.0560 mean_entropies: 0.2272, took: 54.5817s
2022-10-10 12:01:16,170 [INFO] 	Process 2 - batch 38899: mean_policy_losses: 8.925, mean_net_lifetime: 4749.2097, mean_mc_travel_dist: 1325.2822, mean_rewards: 277.3957, total_rewards: 3449.0749, mean_steps: 16.1900, mean_ecr: 0.0407 mean_entropies: 0.5771, took: 82.1697s
2022-10-10 12:01:22,453 [INFO] 	Process 1 - batch 33599: mean_policy_losses: -34.654, mean_net_lifetime: 4904.6482, mean_mc_travel_dist: 1815.5245, mean_rewards: 240.3206, total_rewards: 3125.9918, mean_steps: 19.6900, mean_ecr: 0.0390 mean_entropies: 0.9777, took: 97.5688s
2022-10-10 12:01:43,796 [INFO] 	Process 6 - batch 55899: mean_policy_losses: -244.183, mean_net_lifetime: 3432.1453, mean_mc_travel_dist: 925.5104, mean_rewards: 331.8351, total_rewards: 2520.5904, mean_steps: 9.4000, mean_ecr: 0.0558 mean_entropies: 0.2428, took: 52.0359s
2022-10-10 12:01:51,485 [INFO] 	Process 5 - batch 38999: mean_policy_losses: -409.245, mean_net_lifetime: 4669.5996, mean_mc_travel_dist: 1606.8460, mean_rewards: 249.1735, total_rewards: 3124.2862, mean_steps: 18.1100, mean_ecr: 0.0300 mean_entropies: 0.7943, took: 91.6430s
2022-10-10 12:02:00,348 [INFO] 	Process 3 - batch 39299: mean_policy_losses: 51.556, mean_net_lifetime: 4495.6997, mean_mc_travel_dist: 1265.3897, mean_rewards: 275.4886, total_rewards: 3258.4711, mean_steps: 15.3700, mean_ecr: 0.0483 mean_entropies: 0.6143, took: 79.2381s
2022-10-10 12:02:11,984 [INFO] 	Process 4 - batch 44899: mean_policy_losses: 108.016, mean_net_lifetime: 4796.2731, mean_mc_travel_dist: 1372.7910, mean_rewards: 277.5676, total_rewards: 3453.5802, mean_steps: 16.3300, mean_ecr: 0.0475 mean_entropies: 0.7670, took: 82.4506s
2022-10-10 12:02:32,692 [INFO] 	Process 6 - batch 55999: mean_policy_losses: -208.872, mean_net_lifetime: 3237.6315, mean_mc_travel_dist: 876.7158, mean_rewards: 329.3285, total_rewards: 2389.8764, mean_steps: 8.8700, mean_ecr: 0.0559 mean_entropies: 0.2449, took: 48.8970s
2022-10-10 12:02:36,833 [INFO] 	Process 2 - batch 38999: mean_policy_losses: -6.156, mean_net_lifetime: 4709.2456, mean_mc_travel_dist: 1345.8428, mean_rewards: 271.8823, total_rewards: 3382.5625, mean_steps: 16.4200, mean_ecr: 0.0406 mean_entropies: 0.5597, took: 80.6633s
2022-10-10 12:02:58,587 [INFO] 	Process 1 - batch 33699: mean_policy_losses: 3.941, mean_net_lifetime: 5055.4251, mean_mc_travel_dist: 1810.3242, mean_rewards: 238.8773, total_rewards: 3275.2140, mean_steps: 20.4500, mean_ecr: 0.0390 mean_entropies: 1.0308, took: 96.1337s
2022-10-10 12:03:17,174 [INFO] 	Process 3 - batch 39399: mean_policy_losses: -6.115, mean_net_lifetime: 4297.7253, mean_mc_travel_dist: 1197.2316, mean_rewards: 263.1405, total_rewards: 3120.3770, mean_steps: 15.3800, mean_ecr: 0.0488 mean_entropies: 0.6265, took: 76.8251s
2022-10-10 12:03:26,859 [INFO] 	Process 6 - batch 56099: mean_policy_losses: -135.865, mean_net_lifetime: 3615.0301, mean_mc_travel_dist: 961.9163, mean_rewards: 324.9481, total_rewards: 2665.2936, mean_steps: 10.1500, mean_ecr: 0.0558 mean_entropies: 0.2247, took: 54.1674s
2022-10-10 12:03:29,328 [INFO] 	Process 4 - batch 44999: mean_policy_losses: 128.889, mean_net_lifetime: 4930.6180, mean_mc_travel_dist: 1400.4039, mean_rewards: 285.5272, total_rewards: 3552.4182, mean_steps: 16.3300, mean_ecr: 0.0474 mean_entropies: 0.7490, took: 77.3430s
2022-10-10 12:04:14,407 [INFO] 	Process 6 - batch 56199: mean_policy_losses: -197.589, mean_net_lifetime: 3416.2064, mean_mc_travel_dist: 925.8048, mean_rewards: 324.8405, total_rewards: 2511.8024, mean_steps: 9.5700, mean_ecr: 0.0560 mean_entropies: 0.2180, took: 47.5474s
2022-10-10 12:04:28,379 [INFO] 	Process 1 - batch 33799: mean_policy_losses: 0.264, mean_net_lifetime: 5000.5718, mean_mc_travel_dist: 1789.8619, mean_rewards: 238.6330, total_rewards: 3238.7982, mean_steps: 20.2400, mean_ecr: 0.0391 mean_entropies: 1.0053, took: 89.7918s
2022-10-10 12:04:31,083 [INFO] 	Process 3 - batch 39499: mean_policy_losses: 34.113, mean_net_lifetime: 4461.6923, mean_mc_travel_dist: 1252.9214, mean_rewards: 269.3623, total_rewards: 3244.8998, mean_steps: 15.6200, mean_ecr: 0.0482 mean_entropies: 0.6062, took: 73.9094s
2022-10-10 12:05:07,190 [INFO] 	Process 6 - batch 56299: mean_policy_losses: -167.776, mean_net_lifetime: 3612.1368, mean_mc_travel_dist: 962.1008, mean_rewards: 323.1830, total_rewards: 2667.1699, mean_steps: 10.2200, mean_ecr: 0.0557 mean_entropies: 0.2126, took: 52.7827s
2022-10-10 12:05:12,844 [INFO] Process 7 - epoch 26: mean_policy_losses: -165.275, mean_net_lifetime: 3974.0271, mean_mc_travel_dist: 1648.4687, mean_entropies: 1.8454, m_net_lifetime_valid: 4183.9664, took: 1794.4537s, (167.0800 / 100 batches)

2022-10-10 12:05:44,396 [INFO] 	Process 3 - batch 39599: mean_policy_losses: 17.776, mean_net_lifetime: 4370.4634, mean_mc_travel_dist: 1199.4783, mean_rewards: 259.8757, total_rewards: 3185.7713, mean_steps: 15.8400, mean_ecr: 0.0487 mean_entropies: 0.5960, took: 73.3131s
2022-10-10 12:05:56,807 [INFO] 	Process 1 - batch 33899: mean_policy_losses: -15.563, mean_net_lifetime: 4853.4885, mean_mc_travel_dist: 1817.8080, mean_rewards: 242.7053, total_rewards: 3066.4315, mean_steps: 19.1600, mean_ecr: 0.0390 mean_entropies: 0.9281, took: 88.4282s
2022-10-10 12:06:01,739 [INFO] 	Process 6 - batch 56399: mean_policy_losses: -157.855, mean_net_lifetime: 3639.2737, mean_mc_travel_dist: 968.9170, mean_rewards: 318.9560, total_rewards: 2690.3561, mean_steps: 10.4000, mean_ecr: 0.0557 mean_entropies: 0.2054, took: 54.5495s
2022-10-10 12:06:23,078 [INFO] 	Process 7 - batch 39099: mean_policy_losses: -666.823, mean_net_lifetime: 3466.4833, mean_mc_travel_dist: 1376.0171, mean_rewards: 222.7824, total_rewards: 2128.2526, mean_steps: 15.2900, mean_ecr: 0.0420 mean_entropies: 1.2213, took: 659.9418s
2022-10-10 12:06:55,525 [INFO] 	Process 6 - batch 56499: mean_policy_losses: -131.171, mean_net_lifetime: 3678.8484, mean_mc_travel_dist: 981.0890, mean_rewards: 325.7653, total_rewards: 2713.2229, mean_steps: 10.3100, mean_ecr: 0.0556 mean_entropies: 0.2058, took: 53.7864s
2022-10-10 12:07:00,900 [INFO] 	Process 3 - batch 39699: mean_policy_losses: 33.706, mean_net_lifetime: 4403.4135, mean_mc_travel_dist: 1206.6238, mean_rewards: 259.0726, total_rewards: 3224.9744, mean_steps: 16.0800, mean_ecr: 0.0487 mean_entropies: 0.5923, took: 76.5045s
2022-10-10 12:07:33,497 [INFO] 	Process 1 - batch 33999: mean_policy_losses: 19.501, mean_net_lifetime: 4988.8914, mean_mc_travel_dist: 1805.6899, mean_rewards: 226.5451, total_rewards: 3211.0647, mean_steps: 21.2900, mean_ecr: 0.0389 mean_entropies: 0.9557, took: 96.6907s
2022-10-10 12:07:42,954 [INFO] 	Process 6 - batch 56599: mean_policy_losses: -138.049, mean_net_lifetime: 3279.9844, mean_mc_travel_dist: 865.5506, mean_rewards: 330.6338, total_rewards: 2435.4448, mean_steps: 8.9000, mean_ecr: 0.0562 mean_entropies: 0.2516, took: 47.4278s
2022-10-10 12:07:46,048 [INFO] 	Process 7 - batch 39199: mean_policy_losses: -387.717, mean_net_lifetime: 4439.6305, mean_mc_travel_dist: 1466.3657, mean_rewards: 234.9326, total_rewards: 3023.2040, mean_steps: 18.2600, mean_ecr: 0.0417 mean_entropies: 1.3265, took: 82.9701s
2022-10-10 12:08:21,416 [INFO] 	Process 3 - batch 39799: mean_policy_losses: 35.558, mean_net_lifetime: 4403.6816, mean_mc_travel_dist: 1213.0295, mean_rewards: 256.6354, total_rewards: 3221.9798, mean_steps: 16.2100, mean_ecr: 0.0485 mean_entropies: 0.5748, took: 80.5161s
2022-10-10 12:08:37,502 [INFO] 	Process 6 - batch 56699: mean_policy_losses: -140.426, mean_net_lifetime: 3683.4765, mean_mc_travel_dist: 981.3999, mean_rewards: 323.9940, total_rewards: 2719.9734, mean_steps: 10.3900, mean_ecr: 0.0556 mean_entropies: 0.1946, took: 54.5483s
2022-10-10 12:09:02,125 [INFO] 	Process 1 - batch 34099: mean_policy_losses: -3.627, mean_net_lifetime: 4884.7178, mean_mc_travel_dist: 1826.8242, mean_rewards: 248.5250, total_rewards: 3083.0785, mean_steps: 18.8500, mean_ecr: 0.0389 mean_entropies: 0.8804, took: 88.6275s
2022-10-10 12:09:12,173 [INFO] 	Process 7 - batch 39299: mean_policy_losses: -441.000, mean_net_lifetime: 4302.4714, mean_mc_travel_dist: 1461.9019, mean_rewards: 218.4227, total_rewards: 2882.5315, mean_steps: 18.9800, mean_ecr: 0.0415 mean_entropies: 1.2205, took: 86.1249s
2022-10-10 12:09:31,687 [INFO] 	Process 6 - batch 56799: mean_policy_losses: -144.439, mean_net_lifetime: 3625.1711, mean_mc_travel_dist: 963.0164, mean_rewards: 321.0680, total_rewards: 2677.1028, mean_steps: 10.2900, mean_ecr: 0.0558 mean_entropies: 0.1745, took: 54.1855s
2022-10-10 12:09:38,880 [INFO] 	Process 3 - batch 39899: mean_policy_losses: -2.359, mean_net_lifetime: 4207.9537, mean_mc_travel_dist: 1150.5085, mean_rewards: 245.0022, total_rewards: 3075.3220, mean_steps: 16.2000, mean_ecr: 0.0490 mean_entropies: 0.5765, took: 77.4636s
2022-10-10 12:10:27,050 [INFO] 	Process 6 - batch 56899: mean_policy_losses: -58.407, mean_net_lifetime: 3733.7118, mean_mc_travel_dist: 995.5120, mean_rewards: 327.9803, total_rewards: 2755.5095, mean_steps: 10.4400, mean_ecr: 0.0558 mean_entropies: 0.1860, took: 55.3623s
2022-10-10 12:10:31,694 [INFO] 	Process 1 - batch 34199: mean_policy_losses: 1.417, mean_net_lifetime: 4853.5083, mean_mc_travel_dist: 1819.3744, mean_rewards: 243.6976, total_rewards: 3064.9202, mean_steps: 19.2100, mean_ecr: 0.0389 mean_entropies: 0.8952, took: 89.5687s
2022-10-10 12:10:32,800 [INFO] 	Process 7 - batch 39399: mean_policy_losses: -659.523, mean_net_lifetime: 3810.0205, mean_mc_travel_dist: 1293.9035, mean_rewards: 216.1706, total_rewards: 2559.5457, mean_steps: 16.8600, mean_ecr: 0.0419 mean_entropies: 1.2470, took: 80.6266s
2022-10-10 12:10:59,269 [INFO] 	Process 3 - batch 39999: mean_policy_losses: 17.898, mean_net_lifetime: 4401.6314, mean_mc_travel_dist: 1200.5726, mean_rewards: 250.7188, total_rewards: 3228.5645, mean_steps: 16.6200, mean_ecr: 0.0487 mean_entropies: 0.5751, took: 80.3882s
2022-10-10 12:11:21,248 [INFO] 	Process 6 - batch 56999: mean_policy_losses: -72.284, mean_net_lifetime: 3690.6207, mean_mc_travel_dist: 984.8035, mean_rewards: 328.9008, total_rewards: 2726.8831, mean_steps: 10.2900, mean_ecr: 0.0556 mean_entropies: 0.2055, took: 54.1986s
2022-10-10 12:11:48,374 [INFO] Process 5 - epoch 26: mean_policy_losses: -169.273, mean_net_lifetime: 4462.6608, mean_mc_travel_dist: 2020.9872, mean_entropies: 1.6036, m_net_lifetime_valid: 4347.5785, took: 1909.1403s, (168.0733 / 100 batches)

2022-10-10 12:12:02,247 [INFO] 	Process 1 - batch 34299: mean_policy_losses: -3.483, mean_net_lifetime: 4968.9956, mean_mc_travel_dist: 1775.4218, mean_rewards: 242.1542, total_rewards: 3218.1233, mean_steps: 19.8300, mean_ecr: 0.0390 mean_entropies: 0.9408, took: 90.5533s
2022-10-10 12:12:04,792 [INFO] 	Process 7 - batch 39499: mean_policy_losses: -529.476, mean_net_lifetime: 4337.3510, mean_mc_travel_dist: 1458.0373, mean_rewards: 223.3052, total_rewards: 2931.1363, mean_steps: 18.8700, mean_ecr: 0.0414 mean_entropies: 1.2834, took: 91.9916s
2022-10-10 12:12:18,019 [INFO] 	Process 3 - batch 40099: mean_policy_losses: 30.384, mean_net_lifetime: 4494.6081, mean_mc_travel_dist: 1225.5988, mean_rewards: 263.9712, total_rewards: 3299.2851, mean_steps: 16.1100, mean_ecr: 0.0485 mean_entropies: 0.5975, took: 78.7510s
2022-10-10 12:12:32,780 [INFO] Process 4 - epoch 30: mean_policy_losses: 86.768, mean_net_lifetime: 3620.3907, mean_mc_travel_dist: 1284.0658, mean_entropies: 1.4935, m_net_lifetime_valid: 4120.1020, took: 1773.4107s, (145.9299 / 100 batches)

2022-10-10 12:12:46,790 [INFO] Process 2 - epoch 26: mean_policy_losses: 12.081, mean_net_lifetime: 4165.6390, mean_mc_travel_dist: 1646.9811, mean_entropies: 1.2873, m_net_lifetime_valid: 4265.6923, took: 1832.1101s, (168.1896 / 100 batches)

2022-10-10 12:13:17,903 [INFO] 	Process 5 - batch 39099: mean_policy_losses: -319.021, mean_net_lifetime: 4698.5051, mean_mc_travel_dist: 1582.9006, mean_rewards: 248.3871, total_rewards: 3167.6851, mean_steps: 18.3200, mean_ecr: 0.0308 mean_entropies: 0.7692, took: 686.4179s
2022-10-10 12:13:32,473 [INFO] 	Process 7 - batch 39599: mean_policy_losses: -581.806, mean_net_lifetime: 4016.0431, mean_mc_travel_dist: 1353.0040, mean_rewards: 229.5351, total_rewards: 2710.2135, mean_steps: 16.6800, mean_ecr: 0.0417 mean_entropies: 1.3520, took: 87.6812s
2022-10-10 12:13:37,995 [INFO] 	Process 3 - batch 40199: mean_policy_losses: 45.443, mean_net_lifetime: 4447.3673, mean_mc_travel_dist: 1213.1706, mean_rewards: 270.6259, total_rewards: 3254.0560, mean_steps: 15.4900, mean_ecr: 0.0485 mean_entropies: 0.6063, took: 79.9757s
2022-10-10 12:13:40,091 [INFO] 	Process 1 - batch 34399: mean_policy_losses: 35.732, mean_net_lifetime: 5011.0038, mean_mc_travel_dist: 1811.1473, mean_rewards: 242.2537, total_rewards: 3232.8433, mean_steps: 20.0600, mean_ecr: 0.0389 mean_entropies: 0.9539, took: 97.8436s
2022-10-10 12:14:05,278 [INFO] 	Process 4 - batch 45099: mean_policy_losses: 69.945, mean_net_lifetime: 4516.3191, mean_mc_travel_dist: 1295.7107, mean_rewards: 262.8623, total_rewards: 3253.6878, mean_steps: 16.1800, mean_ecr: 0.0481 mean_entropies: 0.7952, took: 635.9501s
2022-10-10 12:14:18,922 [INFO] 	Process 2 - batch 39099: mean_policy_losses: -13.668, mean_net_lifetime: 4709.6679, mean_mc_travel_dist: 1356.8206, mean_rewards: 270.5832, total_rewards: 3376.1586, mean_steps: 16.5300, mean_ecr: 0.0405 mean_entropies: 0.5620, took: 702.0893s
2022-10-10 12:14:57,588 [INFO] 	Process 5 - batch 39199: mean_policy_losses: -262.288, mean_net_lifetime: 5120.2910, mean_mc_travel_dist: 1753.4393, mean_rewards: 253.3076, total_rewards: 3416.7083, mean_steps: 19.5400, mean_ecr: 0.0305 mean_entropies: 0.7769, took: 99.6853s
2022-10-10 12:14:59,017 [INFO] 	Process 3 - batch 40299: mean_policy_losses: 35.645, mean_net_lifetime: 4549.9746, mean_mc_travel_dist: 1269.1924, mean_rewards: 282.2287, total_rewards: 3310.4478, mean_steps: 15.1700, mean_ecr: 0.0482 mean_entropies: 0.5940, took: 81.0219s
2022-10-10 12:15:05,242 [INFO] 	Process 7 - batch 39699: mean_policy_losses: -604.955, mean_net_lifetime: 4168.2852, mean_mc_travel_dist: 1421.2807, mean_rewards: 232.2074, total_rewards: 2785.9153, mean_steps: 17.3100, mean_ecr: 0.0416 mean_entropies: 1.3924, took: 92.7696s
2022-10-10 12:15:26,824 [INFO] 	Process 1 - batch 34499: mean_policy_losses: 53.977, mean_net_lifetime: 5240.0836, mean_mc_travel_dist: 1820.7255, mean_rewards: 236.8067, total_rewards: 3452.1435, mean_steps: 21.5300, mean_ecr: 0.0389 mean_entropies: 0.9972, took: 106.7336s
2022-10-10 12:15:39,261 [INFO] 	Process 4 - batch 45199: mean_policy_losses: 103.285, mean_net_lifetime: 4688.5870, mean_mc_travel_dist: 1330.5264, mean_rewards: 270.7724, total_rewards: 3386.7107, mean_steps: 16.4000, mean_ecr: 0.0478 mean_entropies: 0.8285, took: 93.9827s
2022-10-10 12:15:48,334 [INFO] 	Process 2 - batch 39199: mean_policy_losses: -19.386, mean_net_lifetime: 4717.7952, mean_mc_travel_dist: 1375.5819, mean_rewards: 275.6865, total_rewards: 3368.8577, mean_steps: 16.2200, mean_ecr: 0.0405 mean_entropies: 0.5781, took: 89.4118s
2022-10-10 12:16:19,569 [INFO] 	Process 3 - batch 40399: mean_policy_losses: 27.623, mean_net_lifetime: 4479.6991, mean_mc_travel_dist: 1251.5913, mean_rewards: 272.8708, total_rewards: 3261.9047, mean_steps: 15.5100, mean_ecr: 0.0484 mean_entropies: 0.5930, took: 80.5517s
2022-10-10 12:16:31,516 [INFO] 	Process 5 - batch 39299: mean_policy_losses: -272.538, mean_net_lifetime: 4830.4855, mean_mc_travel_dist: 1676.5904, mean_rewards: 248.6463, total_rewards: 3205.4405, mean_steps: 18.7100, mean_ecr: 0.0298 mean_entropies: 0.7435, took: 93.9271s
2022-10-10 12:16:33,769 [INFO] 	Process 7 - batch 39799: mean_policy_losses: -632.447, mean_net_lifetime: 4011.2100, mean_mc_travel_dist: 1489.8033, mean_rewards: 229.4138, total_rewards: 2559.9715, mean_steps: 17.1600, mean_ecr: 0.0418 mean_entropies: 1.3708, took: 88.5252s
2022-10-10 12:17:07,787 [INFO] 	Process 4 - batch 45299: mean_policy_losses: 120.773, mean_net_lifetime: 4761.6088, mean_mc_travel_dist: 1353.5866, mean_rewards: 274.0054, total_rewards: 3439.4267, mean_steps: 16.3600, mean_ecr: 0.0475 mean_entropies: 0.7570, took: 88.5267s
2022-10-10 12:17:17,457 [INFO] 	Process 2 - batch 39299: mean_policy_losses: -2.068, mean_net_lifetime: 4720.8704, mean_mc_travel_dist: 1338.9254, mean_rewards: 270.3873, total_rewards: 3401.7772, mean_steps: 16.5800, mean_ecr: 0.0407 mean_entropies: 0.5289, took: 89.1225s
2022-10-10 12:17:40,083 [INFO] 	Process 3 - batch 40499: mean_policy_losses: 21.551, mean_net_lifetime: 4424.6650, mean_mc_travel_dist: 1244.5889, mean_rewards: 266.1407, total_rewards: 3203.7275, mean_steps: 15.6700, mean_ecr: 0.0483 mean_entropies: 0.6103, took: 80.5147s
2022-10-10 12:18:01,580 [INFO] 	Process 5 - batch 39399: mean_policy_losses: -368.677, mean_net_lifetime: 4811.1882, mean_mc_travel_dist: 1640.2836, mean_rewards: 252.8985, total_rewards: 3222.1082, mean_steps: 18.4800, mean_ecr: 0.0304 mean_entropies: 0.7475, took: 90.0647s
2022-10-10 12:18:09,661 [INFO] 	Process 7 - batch 39899: mean_policy_losses: -455.395, mean_net_lifetime: 4514.2173, mean_mc_travel_dist: 1524.5901, mean_rewards: 233.5446, total_rewards: 3029.2702, mean_steps: 18.8300, mean_ecr: 0.0412 mean_entropies: 1.3114, took: 95.8926s
2022-10-10 12:18:35,716 [INFO] 	Process 4 - batch 45399: mean_policy_losses: 109.223, mean_net_lifetime: 4709.8630, mean_mc_travel_dist: 1328.7746, mean_rewards: 272.9728, total_rewards: 3409.5279, mean_steps: 16.3300, mean_ecr: 0.0477 mean_entropies: 0.7614, took: 87.9285s
2022-10-10 12:18:44,174 [INFO] 	Process 2 - batch 39399: mean_policy_losses: -1.172, mean_net_lifetime: 4716.2616, mean_mc_travel_dist: 1346.3344, mean_rewards: 270.4573, total_rewards: 3396.4009, mean_steps: 16.5400, mean_ecr: 0.0406 mean_entropies: 0.5141, took: 86.7181s
2022-10-10 12:19:34,414 [INFO] 	Process 5 - batch 39499: mean_policy_losses: -287.637, mean_net_lifetime: 5055.2211, mean_mc_travel_dist: 1748.9026, mean_rewards: 253.9204, total_rewards: 3361.4160, mean_steps: 19.3000, mean_ecr: 0.0301 mean_entropies: 0.7318, took: 92.8344s
2022-10-10 12:19:49,510 [INFO] 	Process 7 - batch 39999: mean_policy_losses: -404.492, mean_net_lifetime: 4709.3062, mean_mc_travel_dist: 1641.0845, mean_rewards: 227.4341, total_rewards: 3116.8426, mean_steps: 20.1500, mean_ecr: 0.0410 mean_entropies: 1.3557, took: 99.8500s
2022-10-10 12:20:10,587 [INFO] 	Process 2 - batch 39499: mean_policy_losses: -13.647, mean_net_lifetime: 4701.3160, mean_mc_travel_dist: 1359.8769, mean_rewards: 267.8761, total_rewards: 3364.2717, mean_steps: 16.6700, mean_ecr: 0.0406 mean_entropies: 0.5151, took: 86.4115s
2022-10-10 12:20:10,985 [INFO] 	Process 4 - batch 45499: mean_policy_losses: 170.072, mean_net_lifetime: 5298.0105, mean_mc_travel_dist: 1509.0552, mean_rewards: 280.4735, total_rewards: 3815.9390, mean_steps: 18.1100, mean_ecr: 0.0461 mean_entropies: 0.7351, took: 95.2697s
2022-10-10 12:21:03,271 [INFO] 	Process 5 - batch 39599: mean_policy_losses: -362.679, mean_net_lifetime: 4582.3508, mean_mc_travel_dist: 1610.2649, mean_rewards: 246.4806, total_rewards: 3032.6647, mean_steps: 18.5900, mean_ecr: 0.0295 mean_entropies: 0.7194, took: 88.8553s
2022-10-10 12:21:18,659 [INFO] 	Process 7 - batch 40099: mean_policy_losses: -508.550, mean_net_lifetime: 4378.2185, mean_mc_travel_dist: 1526.9026, mean_rewards: 240.2896, total_rewards: 2906.0687, mean_steps: 17.9100, mean_ecr: 0.0412 mean_entropies: 1.3611, took: 89.1478s
2022-10-10 12:21:26,344 [INFO] Process 6 - epoch 38: mean_policy_losses: -276.395, mean_net_lifetime: 2575.3854, mean_mc_travel_dist: 951.0245, mean_entropies: 0.9112, m_net_lifetime_valid: 4089.6036, took: 1397.5937s, (116.0875 / 100 batches)

2022-10-10 12:21:37,015 [INFO] 	Process 2 - batch 39599: mean_policy_losses: 5.364, mean_net_lifetime: 4713.6028, mean_mc_travel_dist: 1341.5243, mean_rewards: 268.7222, total_rewards: 3396.1532, mean_steps: 16.6500, mean_ecr: 0.0407 mean_entropies: 0.5088, took: 86.4287s
2022-10-10 12:21:37,319 [INFO] 	Process 4 - batch 45599: mean_policy_losses: 140.123, mean_net_lifetime: 4913.9230, mean_mc_travel_dist: 1383.0779, mean_rewards: 287.3601, total_rewards: 3552.8676, mean_steps: 16.1600, mean_ecr: 0.0470 mean_entropies: 0.6940, took: 86.3322s
2022-10-10 12:22:20,788 [INFO] 	Process 6 - batch 57099: mean_policy_losses: -169.316, mean_net_lifetime: 3481.1691, mean_mc_travel_dist: 930.2270, mean_rewards: 324.2039, total_rewards: 2564.6228, mean_steps: 9.7900, mean_ecr: 0.0557 mean_entropies: 0.2060, took: 659.5396s
2022-10-10 12:22:31,821 [INFO] 	Process 5 - batch 39699: mean_policy_losses: -387.600, mean_net_lifetime: 4652.0434, mean_mc_travel_dist: 1589.9436, mean_rewards: 253.9291, total_rewards: 3115.8715, mean_steps: 18.2200, mean_ecr: 0.0298 mean_entropies: 0.7588, took: 88.5516s
2022-10-10 12:22:45,061 [INFO] 	Process 7 - batch 40199: mean_policy_losses: -439.951, mean_net_lifetime: 4331.8624, mean_mc_travel_dist: 1494.8930, mean_rewards: 250.3492, total_rewards: 2877.7398, mean_steps: 16.7400, mean_ecr: 0.0414 mean_entropies: 1.3532, took: 86.4037s
2022-10-10 12:23:06,856 [INFO] 	Process 2 - batch 39699: mean_policy_losses: 7.448, mean_net_lifetime: 4715.7622, mean_mc_travel_dist: 1337.9554, mean_rewards: 266.0345, total_rewards: 3400.7748, mean_steps: 16.8500, mean_ecr: 0.0407 mean_entropies: 0.5034, took: 89.8415s
2022-10-10 12:23:07,850 [INFO] 	Process 4 - batch 45699: mean_policy_losses: 151.431, mean_net_lifetime: 4973.8636, mean_mc_travel_dist: 1405.3155, mean_rewards: 284.0758, total_rewards: 3600.9585, mean_steps: 16.6600, mean_ecr: 0.0471 mean_entropies: 0.7131, took: 90.5316s
2022-10-10 12:23:16,552 [INFO] 	Process 6 - batch 57199: mean_policy_losses: -185.440, mean_net_lifetime: 3596.1803, mean_mc_travel_dist: 955.2551, mean_rewards: 319.2516, total_rewards: 2657.1011, mean_steps: 10.2500, mean_ecr: 0.0558 mean_entropies: 0.2126, took: 55.7637s
2022-10-10 12:23:47,719 [INFO] 	Process 5 - batch 39799: mean_policy_losses: -594.684, mean_net_lifetime: 3973.0574, mean_mc_travel_dist: 1301.9305, mean_rewards: 266.0696, total_rewards: 2721.2823, mean_steps: 15.0000, mean_ecr: 0.0301 mean_entropies: 0.7642, took: 75.8977s
2022-10-10 12:24:07,837 [INFO] 	Process 7 - batch 40299: mean_policy_losses: -671.111, mean_net_lifetime: 3969.6238, mean_mc_travel_dist: 1408.7508, mean_rewards: 245.4937, total_rewards: 2609.3801, mean_steps: 15.7500, mean_ecr: 0.0417 mean_entropies: 1.3769, took: 82.7760s
2022-10-10 12:24:12,092 [INFO] 	Process 6 - batch 57299: mean_policy_losses: -170.919, mean_net_lifetime: 3607.5861, mean_mc_travel_dist: 957.2671, mean_rewards: 322.8169, total_rewards: 2664.0188, mean_steps: 10.2100, mean_ecr: 0.0557 mean_entropies: 0.1974, took: 55.5395s
2022-10-10 12:24:34,076 [INFO] 	Process 4 - batch 45799: mean_policy_losses: 120.860, mean_net_lifetime: 4832.4455, mean_mc_travel_dist: 1371.5043, mean_rewards: 282.3108, total_rewards: 3489.8625, mean_steps: 16.1500, mean_ecr: 0.0471 mean_entropies: 0.7154, took: 86.2271s
2022-10-10 12:24:36,345 [INFO] 	Process 2 - batch 39799: mean_policy_losses: -3.924, mean_net_lifetime: 4705.9811, mean_mc_travel_dist: 1330.6376, mean_rewards: 264.2408, total_rewards: 3398.9523, mean_steps: 16.9100, mean_ecr: 0.0407 mean_entropies: 0.4645, took: 89.4894s
2022-10-10 12:24:47,982 [INFO] Process 1 - epoch 23: mean_policy_losses: 45.614, mean_net_lifetime: 4681.7550, mean_mc_travel_dist: 2094.3399, mean_entropies: 1.4338, m_net_lifetime_valid: 4347.2372, took: 1983.7301s, (192.2891 / 100 batches)

2022-10-10 12:25:09,323 [INFO] 	Process 6 - batch 57399: mean_policy_losses: -145.712, mean_net_lifetime: 3669.6781, mean_mc_travel_dist: 978.8135, mean_rewards: 323.5233, total_rewards: 2704.4505, mean_steps: 10.4200, mean_ecr: 0.0557 mean_entropies: 0.1815, took: 57.2320s
2022-10-10 12:25:20,001 [INFO] 	Process 5 - batch 39899: mean_policy_losses: -353.987, mean_net_lifetime: 4696.3644, mean_mc_travel_dist: 1641.7504, mean_rewards: 247.9357, total_rewards: 3110.4399, mean_steps: 18.7500, mean_ecr: 0.0296 mean_entropies: 0.7039, took: 92.2808s
2022-10-10 12:25:44,543 [INFO] 	Process 7 - batch 40399: mean_policy_losses: -381.165, mean_net_lifetime: 4676.9745, mean_mc_travel_dist: 1583.8244, mean_rewards: 232.1736, total_rewards: 3137.9740, mean_steps: 19.7100, mean_ecr: 0.0410 mean_entropies: 1.2967, took: 96.7060s
2022-10-10 12:26:03,233 [INFO] 	Process 4 - batch 45899: mean_policy_losses: 166.452, mean_net_lifetime: 5161.0407, mean_mc_travel_dist: 1443.9531, mean_rewards: 284.0856, total_rewards: 3747.3633, mean_steps: 17.3200, mean_ecr: 0.0462 mean_entropies: 0.6932, took: 89.1569s
2022-10-10 12:26:04,665 [INFO] 	Process 2 - batch 39899: mean_policy_losses: -12.230, mean_net_lifetime: 4678.6542, mean_mc_travel_dist: 1326.4884, mean_rewards: 259.7584, total_rewards: 3376.1968, mean_steps: 17.1200, mean_ecr: 0.0407 mean_entropies: 0.4564, took: 88.3190s
2022-10-10 12:26:06,490 [INFO] 	Process 6 - batch 57499: mean_policy_losses: -139.409, mean_net_lifetime: 3627.2519, mean_mc_travel_dist: 972.4340, mean_rewards: 320.6397, total_rewards: 2675.5664, mean_steps: 10.3800, mean_ecr: 0.0558 mean_entropies: 0.1948, took: 57.1672s
2022-10-10 12:26:38,555 [INFO] 	Process 1 - batch 34599: mean_policy_losses: 27.483, mean_net_lifetime: 5061.6096, mean_mc_travel_dist: 1840.3712, mean_rewards: 215.6408, total_rewards: 3249.6052, mean_steps: 23.2100, mean_ecr: 0.0388 mean_entropies: 0.8710, took: 671.7308s
2022-10-10 12:26:52,070 [INFO] 	Process 5 - batch 39999: mean_policy_losses: -327.004, mean_net_lifetime: 4753.7778, mean_mc_travel_dist: 1652.2360, mean_rewards: 254.1118, total_rewards: 3162.5434, mean_steps: 18.5200, mean_ecr: 0.0296 mean_entropies: 0.7047, took: 92.0694s
2022-10-10 12:27:05,132 [INFO] 	Process 6 - batch 57599: mean_policy_losses: -133.373, mean_net_lifetime: 3738.3339, mean_mc_travel_dist: 1003.9236, mean_rewards: 320.5340, total_rewards: 2755.8746, mean_steps: 10.7100, mean_ecr: 0.0555 mean_entropies: 0.1886, took: 58.6418s
2022-10-10 12:27:12,377 [INFO] 	Process 7 - batch 40499: mean_policy_losses: -541.181, mean_net_lifetime: 4242.9910, mean_mc_travel_dist: 1485.9349, mean_rewards: 236.6175, total_rewards: 2806.3028, mean_steps: 17.3500, mean_ecr: 0.0415 mean_entropies: 1.3612, took: 87.8344s
2022-10-10 12:27:24,332 [INFO] Process 3 - epoch 27: mean_policy_losses: 101.704, mean_net_lifetime: 4059.1128, mean_mc_travel_dist: 1441.3316, mean_entropies: 1.2213, m_net_lifetime_valid: 4201.9429, took: 1758.8362s, (164.1985 / 100 batches)

2022-10-10 12:27:30,800 [INFO] 	Process 4 - batch 45999: mean_policy_losses: 153.047, mean_net_lifetime: 4938.8248, mean_mc_travel_dist: 1397.4112, mean_rewards: 282.5337, total_rewards: 3570.0396, mean_steps: 16.5600, mean_ecr: 0.0471 mean_entropies: 0.7088, took: 87.5675s
2022-10-10 12:27:32,684 [INFO] 	Process 2 - batch 39999: mean_policy_losses: -8.521, mean_net_lifetime: 4691.7666, mean_mc_travel_dist: 1331.2491, mean_rewards: 262.1069, total_rewards: 3381.4166, mean_steps: 17.0000, mean_ecr: 0.0407 mean_entropies: 0.4692, took: 88.0198s
2022-10-10 12:28:02,351 [INFO] 	Process 6 - batch 57699: mean_policy_losses: -160.863, mean_net_lifetime: 3633.0338, mean_mc_travel_dist: 967.9391, mean_rewards: 316.3222, total_rewards: 2690.2441, mean_steps: 10.5600, mean_ecr: 0.0558 mean_entropies: 0.2063, took: 57.2185s
2022-10-10 12:28:18,368 [INFO] 	Process 5 - batch 40099: mean_policy_losses: -462.704, mean_net_lifetime: 4353.5740, mean_mc_travel_dist: 1475.9226, mean_rewards: 251.1226, total_rewards: 2933.6071, mean_steps: 17.4400, mean_ecr: 0.0297 mean_entropies: 0.6919, took: 86.2979s
2022-10-10 12:28:23,052 [INFO] 	Process 1 - batch 34699: mean_policy_losses: 9.371, mean_net_lifetime: 5052.6666, mean_mc_travel_dist: 1838.0171, mean_rewards: 225.4142, total_rewards: 3241.6318, mean_steps: 21.9500, mean_ecr: 0.0387 mean_entropies: 0.9634, took: 104.4955s
2022-10-10 12:28:44,732 [INFO] 	Process 3 - batch 40599: mean_policy_losses: -1.348, mean_net_lifetime: 4211.6013, mean_mc_travel_dist: 1168.6782, mean_rewards: 252.7572, total_rewards: 3071.8388, mean_steps: 15.7200, mean_ecr: 0.0489 mean_entropies: 0.5406, took: 664.6483s
2022-10-10 12:28:57,931 [INFO] 	Process 6 - batch 57799: mean_policy_losses: -100.842, mean_net_lifetime: 3545.8518, mean_mc_travel_dist: 945.1779, mean_rewards: 323.1531, total_rewards: 2619.5274, mean_steps: 10.0800, mean_ecr: 0.0557 mean_entropies: 0.1999, took: 55.5802s
2022-10-10 12:28:58,398 [INFO] 	Process 2 - batch 40099: mean_policy_losses: -4.181, mean_net_lifetime: 4709.8132, mean_mc_travel_dist: 1329.2275, mean_rewards: 265.6742, total_rewards: 3406.7758, mean_steps: 16.8400, mean_ecr: 0.0408 mean_entropies: 0.4643, took: 85.7141s
2022-10-10 12:28:58,952 [INFO] 	Process 4 - batch 46099: mean_policy_losses: 137.331, mean_net_lifetime: 4991.0251, mean_mc_travel_dist: 1412.4183, mean_rewards: 288.2980, total_rewards: 3601.1510, mean_steps: 16.4000, mean_ecr: 0.0470 mean_entropies: 0.7321, took: 88.1513s
2022-10-10 12:29:45,733 [INFO] 	Process 5 - batch 40199: mean_policy_losses: -404.213, mean_net_lifetime: 4573.2416, mean_mc_travel_dist: 1592.6428, mean_rewards: 258.3325, total_rewards: 3033.1214, mean_steps: 17.5000, mean_ecr: 0.0298 mean_entropies: 0.7310, took: 87.3650s
2022-10-10 12:29:49,054 [INFO] 	Process 6 - batch 57899: mean_policy_losses: -119.603, mean_net_lifetime: 3357.0282, mean_mc_travel_dist: 920.7921, mean_rewards: 332.2521, total_rewards: 2470.0024, mean_steps: 9.1800, mean_ecr: 0.0561 mean_entropies: 0.2118, took: 51.1232s
2022-10-10 12:30:05,493 [INFO] 	Process 3 - batch 40699: mean_policy_losses: 31.792, mean_net_lifetime: 4402.8571, mean_mc_travel_dist: 1234.3787, mean_rewards: 263.5862, total_rewards: 3201.2142, mean_steps: 15.7500, mean_ecr: 0.0485 mean_entropies: 0.5859, took: 80.7612s
2022-10-10 12:30:06,694 [INFO] 	Process 1 - batch 34799: mean_policy_losses: 19.824, mean_net_lifetime: 4994.2962, mean_mc_travel_dist: 1824.2298, mean_rewards: 225.9853, total_rewards: 3193.5668, mean_steps: 21.7100, mean_ecr: 0.0388 mean_entropies: 0.9017, took: 103.6431s
2022-10-10 12:30:23,706 [INFO] 	Process 2 - batch 40199: mean_policy_losses: 5.985, mean_net_lifetime: 4717.8559, mean_mc_travel_dist: 1368.9998, mean_rewards: 267.0576, total_rewards: 3373.6511, mean_steps: 16.7900, mean_ecr: 0.0404 mean_entropies: 0.5199, took: 85.3074s
2022-10-10 12:30:32,852 [INFO] 	Process 4 - batch 46199: mean_policy_losses: 203.428, mean_net_lifetime: 5425.7693, mean_mc_travel_dist: 1520.6162, mean_rewards: 283.6878, total_rewards: 3934.1475, mean_steps: 18.3300, mean_ecr: 0.0460 mean_entropies: 0.7321, took: 93.9008s
2022-10-10 12:30:35,004 [INFO] 	Process 6 - batch 57999: mean_policy_losses: -202.423, mean_net_lifetime: 3046.7402, mean_mc_travel_dist: 828.0144, mean_rewards: 333.3727, total_rewards: 2246.7686, mean_steps: 8.1400, mean_ecr: 0.0565 mean_entropies: 0.2510, took: 45.9499s
2022-10-10 12:31:15,776 [INFO] 	Process 5 - batch 40299: mean_policy_losses: -349.673, mean_net_lifetime: 4901.4498, mean_mc_travel_dist: 1662.1159, mean_rewards: 262.2854, total_rewards: 3293.0702, mean_steps: 18.2000, mean_ecr: 0.0301 mean_entropies: 0.7563, took: 90.0435s
2022-10-10 12:31:25,719 [INFO] 	Process 3 - batch 40799: mean_policy_losses: 13.933, mean_net_lifetime: 4351.1115, mean_mc_travel_dist: 1211.4761, mean_rewards: 263.7426, total_rewards: 3163.7970, mean_steps: 15.5600, mean_ecr: 0.0486 mean_entropies: 0.5762, took: 80.2259s
2022-10-10 12:31:30,067 [INFO] 	Process 6 - batch 58099: mean_policy_losses: -205.665, mean_net_lifetime: 3515.3466, mean_mc_travel_dist: 941.4121, mean_rewards: 326.6178, total_rewards: 2593.6000, mean_steps: 9.7900, mean_ecr: 0.0557 mean_entropies: 0.2259, took: 55.0638s
2022-10-10 12:31:51,908 [INFO] 	Process 2 - batch 40299: mean_policy_losses: -15.382, mean_net_lifetime: 4716.6311, mean_mc_travel_dist: 1338.6963, mean_rewards: 266.2515, total_rewards: 3402.6847, mean_steps: 16.8300, mean_ecr: 0.0405 mean_entropies: 0.5095, took: 88.2021s
2022-10-10 12:31:57,337 [INFO] 	Process 4 - batch 46299: mean_policy_losses: 126.117, mean_net_lifetime: 4886.2107, mean_mc_travel_dist: 1368.5141, mean_rewards: 283.5613, total_rewards: 3552.1992, mean_steps: 16.3100, mean_ecr: 0.0474 mean_entropies: 0.7704, took: 84.4839s
2022-10-10 12:31:58,304 [INFO] 	Process 1 - batch 34899: mean_policy_losses: 70.264, mean_net_lifetime: 5349.0837, mean_mc_travel_dist: 1867.6206, mean_rewards: 225.5049, total_rewards: 3506.3526, mean_steps: 23.3500, mean_ecr: 0.0386 mean_entropies: 0.9683, took: 111.6090s
2022-10-10 12:32:25,871 [INFO] 	Process 6 - batch 58199: mean_policy_losses: -121.459, mean_net_lifetime: 3606.2517, mean_mc_travel_dist: 961.2059, mean_rewards: 324.4128, total_rewards: 2662.5808, mean_steps: 10.1400, mean_ecr: 0.0558 mean_entropies: 0.2101, took: 55.8031s
2022-10-10 12:32:45,628 [INFO] 	Process 5 - batch 40399: mean_policy_losses: -324.402, mean_net_lifetime: 4778.3662, mean_mc_travel_dist: 1640.6701, mean_rewards: 258.2138, total_rewards: 3195.3542, mean_steps: 18.1500, mean_ecr: 0.0302 mean_entropies: 0.7341, took: 89.8528s
2022-10-10 12:32:46,835 [INFO] 	Process 3 - batch 40899: mean_policy_losses: 14.293, mean_net_lifetime: 4362.2224, mean_mc_travel_dist: 1210.0405, mean_rewards: 262.5528, total_rewards: 3182.6108, mean_steps: 15.6600, mean_ecr: 0.0488 mean_entropies: 0.5766, took: 81.1161s
2022-10-10 12:33:17,223 [INFO] 	Process 6 - batch 58299: mean_policy_losses: -178.867, mean_net_lifetime: 3376.4981, mean_mc_travel_dist: 907.3195, mean_rewards: 332.6134, total_rewards: 2489.1131, mean_steps: 9.1700, mean_ecr: 0.0563 mean_entropies: 0.2202, took: 51.3526s
2022-10-10 12:33:17,488 [INFO] 	Process 2 - batch 40399: mean_policy_losses: -5.596, mean_net_lifetime: 4749.6069, mean_mc_travel_dist: 1366.2240, mean_rewards: 270.4023, total_rewards: 3406.6803, mean_steps: 16.6600, mean_ecr: 0.0404 mean_entropies: 0.5191, took: 85.5800s
2022-10-10 12:33:21,617 [INFO] 	Process 4 - batch 46399: mean_policy_losses: 140.751, mean_net_lifetime: 4923.7582, mean_mc_travel_dist: 1383.1384, mean_rewards: 289.6059, total_rewards: 3571.7973, mean_steps: 16.1100, mean_ecr: 0.0473 mean_entropies: 0.7821, took: 84.2806s
2022-10-10 12:33:48,155 [INFO] 	Process 1 - batch 34999: mean_policy_losses: 58.044, mean_net_lifetime: 5318.5419, mean_mc_travel_dist: 1860.9592, mean_rewards: 228.2734, total_rewards: 3485.0768, mean_steps: 22.9200, mean_ecr: 0.0388 mean_entropies: 0.9797, took: 109.8524s
2022-10-10 12:34:07,051 [INFO] 	Process 3 - batch 40999: mean_policy_losses: 25.824, mean_net_lifetime: 4473.0058, mean_mc_travel_dist: 1228.2744, mean_rewards: 268.4312, total_rewards: 3272.8923, mean_steps: 15.7300, mean_ecr: 0.0485 mean_entropies: 0.5658, took: 80.2152s
2022-10-10 12:34:12,341 [INFO] 	Process 6 - batch 58399: mean_policy_losses: -175.277, mean_net_lifetime: 3606.1046, mean_mc_travel_dist: 965.5922, mean_rewards: 329.8436, total_rewards: 2659.4250, mean_steps: 10.0000, mean_ecr: 0.0557 mean_entropies: 0.2064, took: 55.1175s
2022-10-10 12:34:15,039 [INFO] 	Process 5 - batch 40499: mean_policy_losses: -348.290, mean_net_lifetime: 4787.8202, mean_mc_travel_dist: 1644.4653, mean_rewards: 255.8752, total_rewards: 3205.1469, mean_steps: 18.1000, mean_ecr: 0.0301 mean_entropies: 0.7583, took: 89.4107s
2022-10-10 12:34:41,267 [INFO] 	Process 2 - batch 40499: mean_policy_losses: -10.785, mean_net_lifetime: 4721.2924, mean_mc_travel_dist: 1341.6777, mean_rewards: 274.8936, total_rewards: 3396.8297, mean_steps: 16.2600, mean_ecr: 0.0406 mean_entropies: 0.5236, took: 83.7794s
2022-10-10 12:34:45,667 [INFO] 	Process 4 - batch 46499: mean_policy_losses: 122.897, mean_net_lifetime: 4980.4516, mean_mc_travel_dist: 1425.8033, mean_rewards: 284.6290, total_rewards: 3586.3254, mean_steps: 16.6200, mean_ecr: 0.0472 mean_entropies: 0.7852, took: 84.0502s
2022-10-10 12:34:59,844 [INFO] 	Process 6 - batch 58499: mean_policy_losses: -121.864, mean_net_lifetime: 3306.3259, mean_mc_travel_dist: 896.4251, mean_rewards: 331.8098, total_rewards: 2439.9350, mean_steps: 8.9600, mean_ecr: 0.0563 mean_entropies: 0.2337, took: 47.5027s
2022-10-10 12:35:20,586 [INFO] 	Process 3 - batch 41099: mean_policy_losses: 13.169, mean_net_lifetime: 4433.2506, mean_mc_travel_dist: 1220.0147, mean_rewards: 269.0030, total_rewards: 3238.7412, mean_steps: 15.5300, mean_ecr: 0.0485 mean_entropies: 0.5867, took: 73.5356s
2022-10-10 12:35:29,480 [INFO] 	Process 1 - batch 35099: mean_policy_losses: 49.146, mean_net_lifetime: 5423.0079, mean_mc_travel_dist: 1890.0333, mean_rewards: 232.9324, total_rewards: 3564.3925, mean_steps: 22.7800, mean_ecr: 0.0386 mean_entropies: 1.0054, took: 101.3244s
2022-10-10 12:36:34,252 [INFO] 	Process 3 - batch 41199: mean_policy_losses: -26.538, mean_net_lifetime: 4327.5029, mean_mc_travel_dist: 1207.7962, mean_rewards: 265.2202, total_rewards: 3141.8325, mean_steps: 15.3800, mean_ecr: 0.0487 mean_entropies: 0.6039, took: 73.6658s
2022-10-10 12:36:58,680 [INFO] 	Process 1 - batch 35199: mean_policy_losses: -30.792, mean_net_lifetime: 5128.1048, mean_mc_travel_dist: 1887.5148, mean_rewards: 249.4347, total_rewards: 3274.0604, mean_steps: 19.8200, mean_ecr: 0.0387 mean_entropies: 0.9551, took: 89.1994s
2022-10-10 12:37:46,553 [INFO] 	Process 3 - batch 41299: mean_policy_losses: 5.946, mean_net_lifetime: 4579.2033, mean_mc_travel_dist: 1282.1644, mean_rewards: 283.3019, total_rewards: 3320.0756, mean_steps: 15.2200, mean_ecr: 0.0480 mean_entropies: 0.6238, took: 72.3008s
2022-10-10 12:38:21,917 [INFO] Process 7 - epoch 27: mean_policy_losses: -178.673, mean_net_lifetime: 3983.3216, mean_mc_travel_dist: 1641.7014, mean_entropies: 1.8260, m_net_lifetime_valid: 4048.4153, took: 1989.0708s, (165.6096 / 100 batches)

2022-10-10 12:38:33,992 [INFO] 	Process 1 - batch 35299: mean_policy_losses: -43.868, mean_net_lifetime: 5363.7838, mean_mc_travel_dist: 1853.1970, mean_rewards: 245.9509, total_rewards: 3543.8973, mean_steps: 21.2100, mean_ecr: 0.0389 mean_entropies: 1.0354, took: 95.3126s
2022-10-10 12:39:02,133 [INFO] 	Process 3 - batch 41399: mean_policy_losses: 15.444, mean_net_lifetime: 4606.4322, mean_mc_travel_dist: 1314.1133, mean_rewards: 284.8154, total_rewards: 3330.3160, mean_steps: 15.2700, mean_ecr: 0.0479 mean_entropies: 0.6333, took: 75.5804s
2022-10-10 12:39:32,984 [INFO] 	Process 7 - batch 40599: mean_policy_losses: -802.724, mean_net_lifetime: 3977.1846, mean_mc_travel_dist: 1366.2338, mean_rewards: 237.0800, total_rewards: 2662.1677, mean_steps: 15.9200, mean_ecr: 0.0419 mean_entropies: 1.5071, took: 740.6065s
2022-10-10 12:40:21,541 [INFO] 	Process 3 - batch 41499: mean_policy_losses: 15.654, mean_net_lifetime: 4683.2630, mean_mc_travel_dist: 1329.8387, mean_rewards: 280.4296, total_rewards: 3385.4975, mean_steps: 15.7700, mean_ecr: 0.0476 mean_entropies: 0.5926, took: 79.4080s
2022-10-10 12:40:25,948 [INFO] 	Process 1 - batch 35399: mean_policy_losses: 24.327, mean_net_lifetime: 5438.5910, mean_mc_travel_dist: 1870.3387, mean_rewards: 225.3230, total_rewards: 3599.1319, mean_steps: 23.9800, mean_ecr: 0.0387 mean_entropies: 0.9743, took: 111.9558s
2022-10-10 12:40:57,971 [INFO] 	Process 7 - batch 40699: mean_policy_losses: -494.121, mean_net_lifetime: 4754.0911, mean_mc_travel_dist: 1586.5461, mean_rewards: 237.1040, total_rewards: 3209.7626, mean_steps: 19.4700, mean_ecr: 0.0412 mean_entropies: 1.4294, took: 84.9864s
2022-10-10 12:41:39,557 [INFO] 	Process 3 - batch 41599: mean_policy_losses: 14.004, mean_net_lifetime: 4597.0741, mean_mc_travel_dist: 1292.8761, mean_rewards: 279.4662, total_rewards: 3346.3662, mean_steps: 15.4900, mean_ecr: 0.0478 mean_entropies: 0.6047, took: 78.0167s
2022-10-10 12:42:06,790 [INFO] 	Process 7 - batch 40799: mean_policy_losses: -818.507, mean_net_lifetime: 3739.1609, mean_mc_travel_dist: 1286.8057, mean_rewards: 234.2033, total_rewards: 2500.1126, mean_steps: 15.0400, mean_ecr: 0.0422 mean_entropies: 1.4093, took: 68.8187s
2022-10-10 12:42:10,971 [INFO] 	Process 1 - batch 35499: mean_policy_losses: 43.400, mean_net_lifetime: 5438.6834, mean_mc_travel_dist: 1881.0835, mean_rewards: 239.6294, total_rewards: 3580.5990, mean_steps: 22.0000, mean_ecr: 0.0387 mean_entropies: 1.0000, took: 105.0239s
2022-10-10 12:42:59,392 [INFO] 	Process 3 - batch 41699: mean_policy_losses: 4.433, mean_net_lifetime: 4542.5045, mean_mc_travel_dist: 1235.5825, mean_rewards: 269.4881, total_rewards: 3336.8341, mean_steps: 15.9100, mean_ecr: 0.0484 mean_entropies: 0.5645, took: 79.8334s
2022-10-10 12:43:21,550 [INFO] 	Process 7 - batch 40899: mean_policy_losses: -633.119, mean_net_lifetime: 4216.5651, mean_mc_travel_dist: 1484.8822, mean_rewards: 239.9061, total_rewards: 2773.1061, mean_steps: 16.9000, mean_ecr: 0.0416 mean_entropies: 1.4328, took: 74.7610s
2022-10-10 12:43:31,958 [INFO] Process 4 - epoch 31: mean_policy_losses: 88.347, mean_net_lifetime: 3662.7473, mean_mc_travel_dist: 1287.6538, mean_entropies: 1.4694, m_net_lifetime_valid: 4217.9650, took: 1859.1768s, (145.2591 / 100 batches)

2022-10-10 12:43:56,001 [INFO] 	Process 1 - batch 35599: mean_policy_losses: 35.307, mean_net_lifetime: 5278.8586, mean_mc_travel_dist: 1836.4308, mean_rewards: 232.4847, total_rewards: 3474.3176, mean_steps: 22.1100, mean_ecr: 0.0388 mean_entropies: 0.9975, took: 105.0293s
2022-10-10 12:44:03,084 [INFO] Process 2 - epoch 27: mean_policy_losses: 11.407, mean_net_lifetime: 4185.8916, mean_mc_travel_dist: 1635.8342, mean_entropies: 1.2585, m_net_lifetime_valid: 4401.6042, took: 1876.2914s, (166.7157 / 100 batches)

2022-10-10 12:44:07,975 [INFO] Process 5 - epoch 27: mean_policy_losses: -176.400, mean_net_lifetime: 4471.6184, mean_mc_travel_dist: 2005.9236, mean_entropies: 1.5716, m_net_lifetime_valid: 4444.7948, took: 1939.6001s, (166.6508 / 100 batches)

2022-10-10 12:44:21,950 [INFO] 	Process 3 - batch 41799: mean_policy_losses: 0.216, mean_net_lifetime: 4454.5681, mean_mc_travel_dist: 1206.3740, mean_rewards: 261.9989, total_rewards: 3278.0552, mean_steps: 16.0800, mean_ecr: 0.0485 mean_entropies: 0.5543, took: 82.5591s
2022-10-10 12:44:40,736 [INFO] 	Process 7 - batch 40999: mean_policy_losses: -715.289, mean_net_lifetime: 4089.1992, mean_mc_travel_dist: 1479.6203, mean_rewards: 235.1144, total_rewards: 2650.4811, mean_steps: 16.5500, mean_ecr: 0.0417 mean_entropies: 1.4389, took: 79.1862s
2022-10-10 12:44:56,969 [INFO] Process 6 - epoch 39: mean_policy_losses: -273.293, mean_net_lifetime: 2599.4582, mean_mc_travel_dist: 950.7962, mean_entropies: 0.8932, m_net_lifetime_valid: 4414.5072, took: 1410.6221s, (115.5368 / 100 batches)

2022-10-10 12:44:59,926 [INFO] 	Process 4 - batch 46599: mean_policy_losses: 128.109, mean_net_lifetime: 5078.0632, mean_mc_travel_dist: 1443.4317, mean_rewards: 280.6157, total_rewards: 3664.3119, mean_steps: 17.2600, mean_ecr: 0.0470 mean_entropies: 0.7913, took: 614.2586s
2022-10-10 12:45:27,847 [INFO] 	Process 2 - batch 40599: mean_policy_losses: -20.831, mean_net_lifetime: 4714.3197, mean_mc_travel_dist: 1340.5583, mean_rewards: 273.8434, total_rewards: 3396.8135, mean_steps: 16.3100, mean_ecr: 0.0406 mean_entropies: 0.5380, took: 646.5802s
2022-10-10 12:45:45,596 [INFO] 	Process 5 - batch 40599: mean_policy_losses: -431.037, mean_net_lifetime: 4608.5262, mean_mc_travel_dist: 1569.6758, mean_rewards: 254.3481, total_rewards: 3102.9477, mean_steps: 17.8000, mean_ecr: 0.0302 mean_entropies: 0.7600, took: 690.5553s
2022-10-10 12:45:45,718 [INFO] 	Process 1 - batch 35699: mean_policy_losses: 29.973, mean_net_lifetime: 5176.9299, mean_mc_travel_dist: 1853.2486, mean_rewards: 244.0639, total_rewards: 3352.7352, mean_steps: 20.5800, mean_ecr: 0.0386 mean_entropies: 0.9977, took: 109.7155s
2022-10-10 12:45:51,521 [INFO] 	Process 3 - batch 41899: mean_policy_losses: 32.984, mean_net_lifetime: 4507.8496, mean_mc_travel_dist: 1231.1024, mean_rewards: 268.6782, total_rewards: 3302.2152, mean_steps: 15.8400, mean_ecr: 0.0484 mean_entropies: 0.5885, took: 89.5709s
2022-10-10 12:45:56,180 [INFO] 	Process 6 - batch 58599: mean_policy_losses: -129.625, mean_net_lifetime: 3447.8582, mean_mc_travel_dist: 930.7451, mean_rewards: 328.1939, total_rewards: 2539.5258, mean_steps: 9.5200, mean_ecr: 0.0560 mean_entropies: 0.2326, took: 656.3364s
2022-10-10 12:45:58,593 [INFO] 	Process 7 - batch 41099: mean_policy_losses: -701.905, mean_net_lifetime: 3816.2398, mean_mc_travel_dist: 1354.7524, mean_rewards: 244.5854, total_rewards: 2504.6829, mean_steps: 14.9000, mean_ecr: 0.0418 mean_entropies: 1.3679, took: 77.8570s
2022-10-10 12:46:26,576 [INFO] 	Process 4 - batch 46699: mean_policy_losses: 118.125, mean_net_lifetime: 4822.9912, mean_mc_travel_dist: 1386.1805, mean_rewards: 282.3163, total_rewards: 3472.4841, mean_steps: 16.1200, mean_ecr: 0.0472 mean_entropies: 0.7692, took: 86.6502s
2022-10-10 12:46:52,463 [INFO] 	Process 6 - batch 58699: mean_policy_losses: -198.031, mean_net_lifetime: 3258.9776, mean_mc_travel_dist: 879.7148, mean_rewards: 330.9398, total_rewards: 2401.0038, mean_steps: 8.8200, mean_ecr: 0.0563 mean_entropies: 0.2424, took: 56.2829s
2022-10-10 12:46:53,494 [INFO] 	Process 2 - batch 40699: mean_policy_losses: 0.642, mean_net_lifetime: 4718.2498, mean_mc_travel_dist: 1326.4269, mean_rewards: 277.1899, total_rewards: 3415.3984, mean_steps: 16.1000, mean_ecr: 0.0407 mean_entropies: 0.5357, took: 85.6465s
2022-10-10 12:47:22,991 [INFO] 	Process 3 - batch 41999: mean_policy_losses: 41.637, mean_net_lifetime: 4515.2204, mean_mc_travel_dist: 1230.2928, mean_rewards: 267.3203, total_rewards: 3317.8227, mean_steps: 15.9600, mean_ecr: 0.0485 mean_entropies: 0.5572, took: 91.4703s
2022-10-10 12:47:25,304 [INFO] 	Process 5 - batch 40699: mean_policy_losses: -475.718, mean_net_lifetime: 4514.9931, mean_mc_travel_dist: 1534.1628, mean_rewards: 251.8276, total_rewards: 3040.4062, mean_steps: 17.7700, mean_ecr: 0.0300 mean_entropies: 0.7538, took: 99.7095s
2022-10-10 12:47:25,384 [INFO] 	Process 7 - batch 41199: mean_policy_losses: -656.611, mean_net_lifetime: 4074.2522, mean_mc_travel_dist: 1400.0364, mean_rewards: 235.1849, total_rewards: 2719.5270, mean_steps: 16.7600, mean_ecr: 0.0417 mean_entropies: 1.4164, took: 86.7911s
2022-10-10 12:47:39,250 [INFO] 	Process 1 - batch 35799: mean_policy_losses: 88.672, mean_net_lifetime: 5292.0864, mean_mc_travel_dist: 1871.5957, mean_rewards: 242.9506, total_rewards: 3444.1494, mean_steps: 21.0800, mean_ecr: 0.0387 mean_entropies: 0.9904, took: 113.5343s
2022-10-10 12:47:50,100 [INFO] 	Process 6 - batch 58799: mean_policy_losses: -215.811, mean_net_lifetime: 3378.9471, mean_mc_travel_dist: 913.9488, mean_rewards: 326.8987, total_rewards: 2487.2130, mean_steps: 9.3300, mean_ecr: 0.0559 mean_entropies: 0.2201, took: 57.6373s
2022-10-10 12:47:55,922 [INFO] 	Process 4 - batch 46799: mean_policy_losses: 127.617, mean_net_lifetime: 4843.7625, mean_mc_travel_dist: 1363.7435, mean_rewards: 277.2038, total_rewards: 3501.2918, mean_steps: 16.5600, mean_ecr: 0.0475 mean_entropies: 0.7606, took: 89.3455s
2022-10-10 12:48:20,875 [INFO] 	Process 2 - batch 40799: mean_policy_losses: -3.869, mean_net_lifetime: 4713.6607, mean_mc_travel_dist: 1320.8443, mean_rewards: 269.7083, total_rewards: 3409.3682, mean_steps: 16.5700, mean_ecr: 0.0407 mean_entropies: 0.5130, took: 87.3815s
2022-10-10 12:48:52,943 [INFO] 	Process 6 - batch 58899: mean_policy_losses: -123.388, mean_net_lifetime: 3693.8816, mean_mc_travel_dist: 986.0959, mean_rewards: 324.9626, total_rewards: 2722.7856, mean_steps: 10.3600, mean_ecr: 0.0558 mean_entropies: 0.1722, took: 62.8415s
2022-10-10 12:48:53,840 [INFO] 	Process 7 - batch 41299: mean_policy_losses: -506.324, mean_net_lifetime: 4303.0641, mean_mc_travel_dist: 1459.1899, mean_rewards: 231.0521, total_rewards: 2889.4931, mean_steps: 17.7400, mean_ecr: 0.0414 mean_entropies: 1.3533, took: 88.4549s
2022-10-10 12:48:55,870 [INFO] 	Process 5 - batch 40799: mean_policy_losses: -485.503, mean_net_lifetime: 4037.5651, mean_mc_travel_dist: 1363.3555, mean_rewards: 236.7056, total_rewards: 2733.6312, mean_steps: 16.4100, mean_ecr: 0.0306 mean_entropies: 0.7139, took: 90.5649s
2022-10-10 12:49:17,627 [INFO] 	Process 1 - batch 35899: mean_policy_losses: 18.998, mean_net_lifetime: 4934.2830, mean_mc_travel_dist: 1839.3424, mean_rewards: 257.6164, total_rewards: 3121.5223, mean_steps: 18.3300, mean_ecr: 0.0388 mean_entropies: 0.8854, took: 98.3759s
2022-10-10 12:49:27,983 [INFO] 	Process 4 - batch 46899: mean_policy_losses: 123.947, mean_net_lifetime: 5092.7672, mean_mc_travel_dist: 1442.0930, mean_rewards: 277.1388, total_rewards: 3672.9764, mean_steps: 17.5600, mean_ecr: 0.0466 mean_entropies: 0.7153, took: 92.0612s
2022-10-10 12:49:46,980 [INFO] 	Process 2 - batch 40899: mean_policy_losses: -3.107, mean_net_lifetime: 4720.0126, mean_mc_travel_dist: 1341.0467, mean_rewards: 266.7734, total_rewards: 3404.3058, mean_steps: 16.8100, mean_ecr: 0.0406 mean_entropies: 0.4874, took: 86.1053s
2022-10-10 12:49:53,995 [INFO] 	Process 6 - batch 58999: mean_policy_losses: -82.836, mean_net_lifetime: 3658.1720, mean_mc_travel_dist: 976.9575, mean_rewards: 329.4580, total_rewards: 2692.9893, mean_steps: 10.1300, mean_ecr: 0.0558 mean_entropies: 0.2002, took: 61.0529s
2022-10-10 12:50:21,371 [INFO] 	Process 7 - batch 41399: mean_policy_losses: -570.751, mean_net_lifetime: 4279.5591, mean_mc_travel_dist: 1450.2341, mean_rewards: 236.6244, total_rewards: 2867.9771, mean_steps: 17.5000, mean_ecr: 0.0415 mean_entropies: 1.2868, took: 87.5318s
2022-10-10 12:50:32,761 [INFO] 	Process 5 - batch 40899: mean_policy_losses: -333.174, mean_net_lifetime: 4596.2129, mean_mc_travel_dist: 1541.6726, mean_rewards: 247.2066, total_rewards: 3100.5839, mean_steps: 18.0100, mean_ecr: 0.0307 mean_entropies: 0.7115, took: 96.8920s
2022-10-10 12:50:54,295 [INFO] 	Process 6 - batch 59099: mean_policy_losses: -160.935, mean_net_lifetime: 3600.5933, mean_mc_travel_dist: 953.3990, mean_rewards: 322.4826, total_rewards: 2662.5636, mean_steps: 10.1500, mean_ecr: 0.0558 mean_entropies: 0.1894, took: 60.3011s
2022-10-10 12:50:54,853 [INFO] 	Process 1 - batch 35999: mean_policy_losses: -2.930, mean_net_lifetime: 4943.4384, mean_mc_travel_dist: 1894.1513, mean_rewards: 259.0796, total_rewards: 3080.0036, mean_steps: 18.3300, mean_ecr: 0.0386 mean_entropies: 0.8291, took: 97.2265s
2022-10-10 12:50:56,366 [INFO] 	Process 4 - batch 46999: mean_policy_losses: 133.325, mean_net_lifetime: 4888.2870, mean_mc_travel_dist: 1368.7788, mean_rewards: 276.7942, total_rewards: 3544.5919, mean_steps: 16.7400, mean_ecr: 0.0472 mean_entropies: 0.7377, took: 88.3830s
2022-10-10 12:51:12,799 [INFO] 	Process 2 - batch 40999: mean_policy_losses: -7.256, mean_net_lifetime: 4695.2099, mean_mc_travel_dist: 1333.3705, mean_rewards: 264.3131, total_rewards: 3381.3066, mean_steps: 16.8600, mean_ecr: 0.0406 mean_entropies: 0.5422, took: 85.8184s
2022-10-10 12:51:34,798 [INFO] 	Process 7 - batch 41499: mean_policy_losses: -797.851, mean_net_lifetime: 3568.9303, mean_mc_travel_dist: 1230.1582, mean_rewards: 234.6038, total_rewards: 2381.6047, mean_steps: 14.4800, mean_ecr: 0.0420 mean_entropies: 1.3169, took: 73.4265s
2022-10-10 12:51:50,188 [INFO] 	Process 5 - batch 40999: mean_policy_losses: -550.003, mean_net_lifetime: 3595.9979, mean_mc_travel_dist: 1182.4461, mean_rewards: 248.7352, total_rewards: 2466.8532, mean_steps: 14.6000, mean_ecr: 0.0301 mean_entropies: 0.6769, took: 77.4273s
2022-10-10 12:51:53,981 [INFO] 	Process 6 - batch 59199: mean_policy_losses: -111.914, mean_net_lifetime: 3714.3826, mean_mc_travel_dist: 993.7822, mean_rewards: 321.5423, total_rewards: 2738.8171, mean_steps: 10.5600, mean_ecr: 0.0557 mean_entropies: 0.1844, took: 59.6857s
2022-10-10 12:52:18,551 [INFO] 	Process 4 - batch 47099: mean_policy_losses: 143.416, mean_net_lifetime: 4943.7643, mean_mc_travel_dist: 1403.7478, mean_rewards: 284.7850, total_rewards: 3565.3586, mean_steps: 16.4400, mean_ecr: 0.0471 mean_entropies: 0.7019, took: 82.1846s
2022-10-10 12:52:37,632 [INFO] 	Process 2 - batch 41099: mean_policy_losses: 0.019, mean_net_lifetime: 4701.8465, mean_mc_travel_dist: 1328.0002, mean_rewards: 263.6585, total_rewards: 3397.3406, mean_steps: 16.9500, mean_ecr: 0.0406 mean_entropies: 0.4869, took: 84.8331s
2022-10-10 12:52:53,080 [INFO] 	Process 6 - batch 59299: mean_policy_losses: -133.393, mean_net_lifetime: 3618.3187, mean_mc_travel_dist: 965.4442, mean_rewards: 322.2180, total_rewards: 2673.1370, mean_steps: 10.2000, mean_ecr: 0.0559 mean_entropies: 0.1835, took: 59.0985s
2022-10-10 12:52:54,290 [INFO] 	Process 7 - batch 41599: mean_policy_losses: -599.058, mean_net_lifetime: 3911.5767, mean_mc_travel_dist: 1434.0804, mean_rewards: 227.8341, total_rewards: 2522.2150, mean_steps: 16.7000, mean_ecr: 0.0419 mean_entropies: 1.2706, took: 79.4923s
2022-10-10 12:53:18,194 [INFO] 	Process 5 - batch 41099: mean_policy_losses: -477.600, mean_net_lifetime: 4187.8788, mean_mc_travel_dist: 1417.3167, mean_rewards: 245.3553, total_rewards: 2825.3981, mean_steps: 17.0700, mean_ecr: 0.0300 mean_entropies: 0.6872, took: 88.0063s
2022-10-10 12:53:46,529 [INFO] 	Process 4 - batch 47199: mean_policy_losses: 140.592, mean_net_lifetime: 4969.1079, mean_mc_travel_dist: 1388.2857, mean_rewards: 280.5170, total_rewards: 3608.6099, mean_steps: 16.7800, mean_ecr: 0.0472 mean_entropies: 0.7241, took: 87.9786s
2022-10-10 12:53:49,458 [INFO] 	Process 6 - batch 59399: mean_policy_losses: -118.463, mean_net_lifetime: 3697.7651, mean_mc_travel_dist: 980.4089, mean_rewards: 323.4502, total_rewards: 2727.7866, mean_steps: 10.4600, mean_ecr: 0.0557 mean_entropies: 0.1795, took: 56.3788s
2022-10-10 12:54:02,652 [INFO] 	Process 2 - batch 41199: mean_policy_losses: -3.321, mean_net_lifetime: 4712.8123, mean_mc_travel_dist: 1346.0129, mean_rewards: 265.1392, total_rewards: 3391.2964, mean_steps: 16.9300, mean_ecr: 0.0405 mean_entropies: 0.4761, took: 85.0196s
2022-10-10 12:54:18,321 [INFO] 	Process 7 - batch 41699: mean_policy_losses: -595.891, mean_net_lifetime: 4116.9366, mean_mc_travel_dist: 1391.2343, mean_rewards: 228.2419, total_rewards: 2766.3175, mean_steps: 17.4300, mean_ecr: 0.0416 mean_entropies: 1.2514, took: 84.0309s
2022-10-10 12:54:43,356 [INFO] 	Process 5 - batch 41199: mean_policy_losses: -416.114, mean_net_lifetime: 4418.4790, mean_mc_travel_dist: 1504.4226, mean_rewards: 245.1523, total_rewards: 2966.2861, mean_steps: 17.7700, mean_ecr: 0.0300 mean_entropies: 0.6763, took: 85.1611s
2022-10-10 12:54:45,388 [INFO] 	Process 6 - batch 59499: mean_policy_losses: -94.069, mean_net_lifetime: 3774.8841, mean_mc_travel_dist: 1004.1185, mean_rewards: 324.9656, total_rewards: 2782.5054, mean_steps: 10.6400, mean_ecr: 0.0555 mean_entropies: 0.1837, took: 55.9298s
2022-10-10 12:55:13,058 [INFO] 	Process 4 - batch 47299: mean_policy_losses: 136.281, mean_net_lifetime: 5086.6619, mean_mc_travel_dist: 1451.9486, mean_rewards: 280.6965, total_rewards: 3663.8104, mean_steps: 17.2900, mean_ecr: 0.0467 mean_entropies: 0.6985, took: 86.5292s
2022-10-10 12:55:24,801 [INFO] 	Process 2 - batch 41299: mean_policy_losses: -11.694, mean_net_lifetime: 4708.0313, mean_mc_travel_dist: 1342.0729, mean_rewards: 268.4008, total_rewards: 3395.2711, mean_steps: 16.6800, mean_ecr: 0.0406 mean_entropies: 0.4801, took: 82.1489s
2022-10-10 12:55:41,428 [INFO] 	Process 6 - batch 59599: mean_policy_losses: -83.472, mean_net_lifetime: 3758.0184, mean_mc_travel_dist: 997.4034, mean_rewards: 322.4147, total_rewards: 2775.0281, mean_steps: 10.6500, mean_ecr: 0.0557 mean_entropies: 0.1853, took: 56.0397s
2022-10-10 12:55:43,751 [INFO] 	Process 7 - batch 41799: mean_policy_losses: -505.644, mean_net_lifetime: 4304.4273, mean_mc_travel_dist: 1473.4531, mean_rewards: 228.9601, total_rewards: 2874.2443, mean_steps: 18.1400, mean_ecr: 0.0413 mean_entropies: 1.2707, took: 85.4302s
2022-10-10 12:56:15,665 [INFO] 	Process 5 - batch 41299: mean_policy_losses: -332.892, mean_net_lifetime: 4854.5457, mean_mc_travel_dist: 1670.8867, mean_rewards: 246.9795, total_rewards: 3239.2048, mean_steps: 19.3100, mean_ecr: 0.0302 mean_entropies: 0.6975, took: 92.3096s
2022-10-10 12:56:38,500 [INFO] 	Process 4 - batch 47399: mean_policy_losses: 115.916, mean_net_lifetime: 4896.5475, mean_mc_travel_dist: 1385.9376, mean_rewards: 277.2576, total_rewards: 3536.5189, mean_steps: 16.8300, mean_ecr: 0.0474 mean_entropies: 0.7382, took: 85.4418s
2022-10-10 12:56:38,777 [INFO] 	Process 6 - batch 59699: mean_policy_losses: -53.030, mean_net_lifetime: 3827.5205, mean_mc_travel_dist: 1014.0940, mean_rewards: 324.9059, total_rewards: 2828.6165, mean_steps: 10.8300, mean_ecr: 0.0555 mean_entropies: 0.1860, took: 57.3489s
2022-10-10 12:56:47,676 [INFO] 	Process 2 - batch 41399: mean_policy_losses: -11.565, mean_net_lifetime: 4712.3786, mean_mc_travel_dist: 1322.2458, mean_rewards: 267.9170, total_rewards: 3408.8809, mean_steps: 16.6800, mean_ecr: 0.0406 mean_entropies: 0.4949, took: 82.8747s
2022-10-10 12:57:05,739 [INFO] 	Process 7 - batch 41899: mean_policy_losses: -565.119, mean_net_lifetime: 4136.7274, mean_mc_travel_dist: 1368.2275, mean_rewards: 231.9508, total_rewards: 2819.9409, mean_steps: 16.9100, mean_ecr: 0.0417 mean_entropies: 1.3190, took: 81.9878s
2022-10-10 12:57:14,315 [INFO] Process 3 - epoch 28: mean_policy_losses: 98.552, mean_net_lifetime: 4073.7818, mean_mc_travel_dist: 1434.1484, mean_entropies: 1.1985, m_net_lifetime_valid: 4157.0487, took: 1789.9815s, (162.5832 / 100 batches)

2022-10-10 12:57:32,702 [INFO] 	Process 6 - batch 59799: mean_policy_losses: -142.055, mean_net_lifetime: 3651.4364, mean_mc_travel_dist: 973.8125, mean_rewards: 327.3994, total_rewards: 2689.5447, mean_steps: 10.1500, mean_ecr: 0.0557 mean_entropies: 0.1829, took: 53.9252s
2022-10-10 12:57:52,744 [INFO] 	Process 5 - batch 41399: mean_policy_losses: -310.954, mean_net_lifetime: 5063.7665, mean_mc_travel_dist: 1769.2249, mean_rewards: 243.1263, total_rewards: 3353.3148, mean_steps: 20.2300, mean_ecr: 0.0299 mean_entropies: 0.7213, took: 97.0784s
2022-10-10 12:58:06,687 [INFO] 	Process 4 - batch 47499: mean_policy_losses: 109.374, mean_net_lifetime: 4971.3172, mean_mc_travel_dist: 1411.3070, mean_rewards: 277.9117, total_rewards: 3592.7430, mean_steps: 16.9700, mean_ecr: 0.0468 mean_entropies: 0.7401, took: 88.1873s
2022-10-10 12:58:10,192 [INFO] 	Process 2 - batch 41499: mean_policy_losses: -0.154, mean_net_lifetime: 4758.5763, mean_mc_travel_dist: 1361.6443, mean_rewards: 271.5030, total_rewards: 3416.7919, mean_steps: 16.6300, mean_ecr: 0.0405 mean_entropies: 0.5276, took: 82.5171s
2022-10-10 12:58:24,359 [INFO] 	Process 6 - batch 59899: mean_policy_losses: -89.671, mean_net_lifetime: 3415.3159, mean_mc_travel_dist: 930.6778, mean_rewards: 332.3971, total_rewards: 2514.8078, mean_steps: 9.2800, mean_ecr: 0.0561 mean_entropies: 0.2212, took: 51.6575s
2022-10-10 12:58:31,956 [INFO] 	Process 7 - batch 41999: mean_policy_losses: -553.806, mean_net_lifetime: 4077.5778, mean_mc_travel_dist: 1446.5508, mean_rewards: 229.3640, total_rewards: 2671.3632, mean_steps: 17.5200, mean_ecr: 0.0419 mean_entropies: 1.3320, took: 86.2178s
2022-10-10 12:58:35,225 [INFO] 	Process 3 - batch 42099: mean_policy_losses: 39.047, mean_net_lifetime: 4448.5596, mean_mc_travel_dist: 1244.3174, mean_rewards: 263.5832, total_rewards: 3228.0182, mean_steps: 15.9500, mean_ecr: 0.0483 mean_entropies: 0.5862, took: 672.2334s
2022-10-10 12:59:21,095 [INFO] 	Process 6 - batch 59999: mean_policy_losses: -97.786, mean_net_lifetime: 3781.6424, mean_mc_travel_dist: 1007.2645, mean_rewards: 324.9397, total_rewards: 2787.4770, mean_steps: 10.6700, mean_ecr: 0.0556 mean_entropies: 0.1971, took: 56.7360s
2022-10-10 12:59:21,300 [INFO] 	Process 4 - batch 47599: mean_policy_losses: -93.054, mean_net_lifetime: 3976.2420, mean_mc_travel_dist: 1146.7421, mean_rewards: 261.3103, total_rewards: 2858.9427, mean_steps: 14.1200, mean_ecr: 0.0492 mean_entropies: 0.8507, took: 74.6126s
2022-10-10 12:59:27,024 [INFO] 	Process 5 - batch 41499: mean_policy_losses: -280.043, mean_net_lifetime: 5025.0740, mean_mc_travel_dist: 1712.9064, mean_rewards: 249.8133, total_rewards: 3361.8133, mean_steps: 19.5800, mean_ecr: 0.0303 mean_entropies: 0.7154, took: 94.2802s
2022-10-10 12:59:32,666 [INFO] 	Process 2 - batch 41599: mean_policy_losses: 11.501, mean_net_lifetime: 4761.0749, mean_mc_travel_dist: 1361.2815, mean_rewards: 270.3395, total_rewards: 3427.9255, mean_steps: 16.7200, mean_ecr: 0.0404 mean_entropies: 0.5300, took: 82.4727s
2022-10-10 12:59:51,133 [INFO] 	Process 3 - batch 42199: mean_policy_losses: 13.785, mean_net_lifetime: 4361.3626, mean_mc_travel_dist: 1212.1586, mean_rewards: 264.2607, total_rewards: 3178.9099, mean_steps: 15.5500, mean_ecr: 0.0487 mean_entropies: 0.5749, took: 75.9088s
2022-10-10 13:00:41,918 [INFO] 	Process 4 - batch 47699: mean_policy_losses: 93.272, mean_net_lifetime: 5059.0106, mean_mc_travel_dist: 1434.9788, mean_rewards: 284.5176, total_rewards: 3656.1914, mean_steps: 16.9000, mean_ecr: 0.0469 mean_entropies: 0.7136, took: 80.6185s
2022-10-10 13:00:51,749 [INFO] Process 1 - epoch 24: mean_policy_losses: 44.817, mean_net_lifetime: 4703.8873, mean_mc_travel_dist: 2084.5984, mean_entropies: 1.4139, m_net_lifetime_valid: 4481.5264, took: 2163.7654s, (190.1941 / 100 batches)

2022-10-10 13:00:52,148 [INFO] 	Process 2 - batch 41699: mean_policy_losses: -24.699, mean_net_lifetime: 4711.6988, mean_mc_travel_dist: 1339.3672, mean_rewards: 276.1938, total_rewards: 3393.2367, mean_steps: 16.1500, mean_ecr: 0.0406 mean_entropies: 0.5344, took: 79.4832s
2022-10-10 13:00:54,737 [INFO] 	Process 5 - batch 41599: mean_policy_losses: -409.708, mean_net_lifetime: 4843.2135, mean_mc_travel_dist: 1674.3630, mean_rewards: 251.1335, total_rewards: 3222.6979, mean_steps: 19.0300, mean_ecr: 0.0299 mean_entropies: 0.7443, took: 87.7129s
2022-10-10 13:01:06,557 [INFO] 	Process 3 - batch 42299: mean_policy_losses: 18.907, mean_net_lifetime: 4514.9679, mean_mc_travel_dist: 1265.5356, mean_rewards: 274.8631, total_rewards: 3278.8043, mean_steps: 15.4800, mean_ecr: 0.0483 mean_entropies: 0.5845, took: 75.4229s
2022-10-10 13:02:08,294 [INFO] 	Process 4 - batch 47799: mean_policy_losses: 63.175, mean_net_lifetime: 4852.8118, mean_mc_travel_dist: 1417.7346, mean_rewards: 272.7499, total_rewards: 3461.4350, mean_steps: 16.9300, mean_ecr: 0.0474 mean_entropies: 0.7418, took: 86.3743s
2022-10-10 13:02:09,552 [INFO] 	Process 5 - batch 41699: mean_policy_losses: -504.618, mean_net_lifetime: 4135.3844, mean_mc_travel_dist: 1429.7620, mean_rewards: 273.1911, total_rewards: 2753.7546, mean_steps: 15.3400, mean_ecr: 0.0299 mean_entropies: 0.6952, took: 74.8155s
2022-10-10 13:02:13,512 [INFO] 	Process 2 - batch 41799: mean_policy_losses: -3.604, mean_net_lifetime: 4696.8107, mean_mc_travel_dist: 1415.5455, mean_rewards: 279.8052, total_rewards: 3308.4398, mean_steps: 15.8700, mean_ecr: 0.0401 mean_entropies: 0.5715, took: 81.3639s
2022-10-10 13:02:21,481 [INFO] 	Process 1 - batch 36099: mean_policy_losses: -57.085, mean_net_lifetime: 4813.9534, mean_mc_travel_dist: 1853.8842, mean_rewards: 247.6688, total_rewards: 2990.0672, mean_steps: 18.7700, mean_ecr: 0.0389 mean_entropies: 0.8138, took: 686.6277s
2022-10-10 13:02:23,603 [INFO] 	Process 3 - batch 42399: mean_policy_losses: 65.700, mean_net_lifetime: 4511.2916, mean_mc_travel_dist: 1288.6502, mean_rewards: 278.4248, total_rewards: 3257.0291, mean_steps: 15.2900, mean_ecr: 0.0481 mean_entropies: 0.5729, took: 77.0470s
2022-10-10 13:03:33,623 [INFO] 	Process 2 - batch 41899: mean_policy_losses: -21.533, mean_net_lifetime: 4732.7008, mean_mc_travel_dist: 1380.8301, mean_rewards: 277.8581, total_rewards: 3372.7666, mean_steps: 16.1500, mean_ecr: 0.0404 mean_entropies: 0.5766, took: 80.1107s
2022-10-10 13:03:33,897 [INFO] 	Process 4 - batch 47899: mean_policy_losses: 80.957, mean_net_lifetime: 4979.0152, mean_mc_travel_dist: 1435.6476, mean_rewards: 288.4783, total_rewards: 3573.2859, mean_steps: 16.3800, mean_ecr: 0.0470 mean_entropies: 0.7012, took: 85.6044s
2022-10-10 13:03:39,477 [INFO] 	Process 5 - batch 41799: mean_policy_losses: -412.522, mean_net_lifetime: 4699.4392, mean_mc_travel_dist: 1634.7697, mean_rewards: 247.7363, total_rewards: 3120.0945, mean_steps: 18.6700, mean_ecr: 0.0297 mean_entropies: 0.7083, took: 89.9248s
2022-10-10 13:03:40,942 [INFO] 	Process 3 - batch 42499: mean_policy_losses: 40.164, mean_net_lifetime: 4622.3652, mean_mc_travel_dist: 1285.1296, mean_rewards: 276.2365, total_rewards: 3375.5148, mean_steps: 15.7800, mean_ecr: 0.0481 mean_entropies: 0.5699, took: 77.3393s
2022-10-10 13:04:00,438 [INFO] 	Process 1 - batch 36199: mean_policy_losses: -30.947, mean_net_lifetime: 4952.9344, mean_mc_travel_dist: 1806.1710, mean_rewards: 228.4368, total_rewards: 3180.7291, mean_steps: 21.1300, mean_ecr: 0.0390 mean_entropies: 0.9057, took: 98.9570s
2022-10-10 13:04:56,968 [INFO] 	Process 2 - batch 41999: mean_policy_losses: -11.756, mean_net_lifetime: 4717.0582, mean_mc_travel_dist: 1331.6323, mean_rewards: 273.0605, total_rewards: 3409.5836, mean_steps: 16.3700, mean_ecr: 0.0406 mean_entropies: 0.4978, took: 83.3448s
2022-10-10 13:04:58,815 [INFO] 	Process 3 - batch 42599: mean_policy_losses: 16.236, mean_net_lifetime: 4428.6807, mean_mc_travel_dist: 1216.4662, mean_rewards: 267.4658, total_rewards: 3234.6115, mean_steps: 15.6300, mean_ecr: 0.0487 mean_entropies: 0.5527, took: 77.8719s
2022-10-10 13:05:00,780 [INFO] 	Process 4 - batch 47999: mean_policy_losses: 106.100, mean_net_lifetime: 5147.9480, mean_mc_travel_dist: 1494.7042, mean_rewards: 289.3287, total_rewards: 3691.4468, mean_steps: 16.9100, mean_ecr: 0.0464 mean_entropies: 0.6767, took: 86.8833s
2022-10-10 13:05:03,396 [INFO] 	Process 5 - batch 41899: mean_policy_losses: -491.497, mean_net_lifetime: 4270.3972, mean_mc_travel_dist: 1483.3952, mean_rewards: 243.1151, total_rewards: 2842.6211, mean_steps: 17.5500, mean_ecr: 0.0295 mean_entropies: 0.6995, took: 83.9197s
2022-10-10 13:05:36,000 [INFO] 	Process 1 - batch 36299: mean_policy_losses: -1.536, mean_net_lifetime: 5085.7653, mean_mc_travel_dist: 1842.9603, mean_rewards: 237.2017, total_rewards: 3265.1264, mean_steps: 20.8100, mean_ecr: 0.0388 mean_entropies: 0.9364, took: 95.5630s
2022-10-10 13:06:08,852 [INFO] 	Process 3 - batch 42699: mean_policy_losses: 65.210, mean_net_lifetime: 4473.2373, mean_mc_travel_dist: 1254.3141, mean_rewards: 285.2862, total_rewards: 3245.2985, mean_steps: 14.7200, mean_ecr: 0.0482 mean_entropies: 0.6034, took: 70.0382s
2022-10-10 13:06:25,175 [INFO] 	Process 5 - batch 41999: mean_policy_losses: -292.068, mean_net_lifetime: 4996.0706, mean_mc_travel_dist: 1704.5900, mean_rewards: 265.6140, total_rewards: 3355.3255, mean_steps: 18.1300, mean_ecr: 0.0305 mean_entropies: 0.7520, took: 81.7789s
2022-10-10 13:07:06,116 [INFO] 	Process 1 - batch 36399: mean_policy_losses: -60.130, mean_net_lifetime: 5074.2243, mean_mc_travel_dist: 1859.0488, mean_rewards: 235.4905, total_rewards: 3238.4282, mean_steps: 21.0900, mean_ecr: 0.0388 mean_entropies: 0.8830, took: 90.1157s
2022-10-10 13:07:18,581 [INFO] 	Process 3 - batch 42799: mean_policy_losses: 5.258, mean_net_lifetime: 4597.5417, mean_mc_travel_dist: 1336.9530, mean_rewards: 285.1861, total_rewards: 3295.8701, mean_steps: 15.1800, mean_ecr: 0.0474 mean_entropies: 0.6084, took: 69.7288s
2022-10-10 13:07:56,806 [INFO] Process 7 - epoch 28: mean_policy_losses: -194.951, mean_net_lifetime: 3987.1685, mean_mc_travel_dist: 1633.5740, mean_entropies: 1.8093, m_net_lifetime_valid: 4443.9147, took: 1774.8877s, (164.1736 / 100 batches)

2022-10-10 13:08:30,249 [INFO] 	Process 3 - batch 42899: mean_policy_losses: 11.019, mean_net_lifetime: 4587.4771, mean_mc_travel_dist: 1301.0597, mean_rewards: 288.6737, total_rewards: 3319.4764, mean_steps: 14.9600, mean_ecr: 0.0481 mean_entropies: 0.6270, took: 71.6669s
2022-10-10 13:08:36,968 [INFO] Process 6 - epoch 40: mean_policy_losses: -269.518, mean_net_lifetime: 2624.9346, mean_mc_travel_dist: 951.2060, mean_entropies: 0.8758, m_net_lifetime_valid: 4342.9126, took: 1419.9969s, (115.0845 / 100 batches)

2022-10-10 13:08:42,214 [INFO] 	Process 1 - batch 36499: mean_policy_losses: -25.925, mean_net_lifetime: 5470.3470, mean_mc_travel_dist: 1933.0840, mean_rewards: 240.7880, total_rewards: 3569.1444, mean_steps: 22.0200, mean_ecr: 0.0385 mean_entropies: 0.9428, took: 96.0978s
2022-10-10 13:09:11,259 [INFO] 	Process 7 - batch 42099: mean_policy_losses: -727.337, mean_net_lifetime: 3881.4958, mean_mc_travel_dist: 1411.9441, mean_rewards: 224.1788, total_rewards: 2516.1465, mean_steps: 16.2400, mean_ecr: 0.0421 mean_entropies: 1.3482, took: 639.3022s
2022-10-10 13:09:27,852 [INFO] 	Process 6 - batch 60099: mean_policy_losses: -204.237, mean_net_lifetime: 3525.1628, mean_mc_travel_dist: 944.4080, mean_rewards: 325.8536, total_rewards: 2593.5556, mean_steps: 9.8100, mean_ecr: 0.0560 mean_entropies: 0.2023, took: 606.7563s
2022-10-10 13:09:46,598 [INFO] 	Process 3 - batch 42999: mean_policy_losses: 13.320, mean_net_lifetime: 4427.6005, mean_mc_travel_dist: 1238.7712, mean_rewards: 261.4040, total_rewards: 3218.1910, mean_steps: 15.9900, mean_ecr: 0.0485 mean_entropies: 0.5906, took: 76.3494s
2022-10-10 13:10:18,646 [INFO] 	Process 6 - batch 60199: mean_policy_losses: -181.648, mean_net_lifetime: 3513.4601, mean_mc_travel_dist: 944.9551, mean_rewards: 326.8709, total_rewards: 2584.1185, mean_steps: 9.7300, mean_ecr: 0.0561 mean_entropies: 0.1957, took: 50.7940s
2022-10-10 13:10:21,837 [INFO] 	Process 1 - batch 36599: mean_policy_losses: 86.508, mean_net_lifetime: 5391.9090, mean_mc_travel_dist: 1886.8790, mean_rewards: 238.1174, total_rewards: 3536.6521, mean_steps: 21.9900, mean_ecr: 0.0387 mean_entropies: 0.9698, took: 99.6229s
2022-10-10 13:10:44,206 [INFO] 	Process 7 - batch 42199: mean_policy_losses: -436.667, mean_net_lifetime: 4603.7950, mean_mc_travel_dist: 1561.8516, mean_rewards: 227.7386, total_rewards: 3079.1465, mean_steps: 19.4000, mean_ecr: 0.0413 mean_entropies: 1.3225, took: 92.9475s
2022-10-10 13:11:04,798 [INFO] 	Process 3 - batch 43099: mean_policy_losses: 9.212, mean_net_lifetime: 4416.1993, mean_mc_travel_dist: 1219.4283, mean_rewards: 250.7342, total_rewards: 3233.2622, mean_steps: 16.6700, mean_ecr: 0.0485 mean_entropies: 0.5671, took: 78.2008s
2022-10-10 13:11:08,929 [INFO] 	Process 6 - batch 60299: mean_policy_losses: -169.577, mean_net_lifetime: 3509.5353, mean_mc_travel_dist: 937.8279, mean_rewards: 326.4968, total_rewards: 2590.4868, mean_steps: 9.7100, mean_ecr: 0.0559 mean_entropies: 0.2029, took: 50.2830s
2022-10-10 13:12:03,398 [INFO] 	Process 1 - batch 36699: mean_policy_losses: 104.790, mean_net_lifetime: 5371.2797, mean_mc_travel_dist: 1919.2747, mean_rewards: 229.8569, total_rewards: 3490.6297, mean_steps: 22.8000, mean_ecr: 0.0385 mean_entropies: 0.9179, took: 101.5600s
2022-10-10 13:12:04,462 [INFO] 	Process 6 - batch 60399: mean_policy_losses: -87.171, mean_net_lifetime: 3738.7185, mean_mc_travel_dist: 989.7274, mean_rewards: 312.3492, total_rewards: 2771.6736, mean_steps: 10.9600, mean_ecr: 0.0556 mean_entropies: 0.1784, took: 55.5324s
2022-10-10 13:12:14,310 [INFO] 	Process 7 - batch 42299: mean_policy_losses: -367.353, mean_net_lifetime: 4650.0445, mean_mc_travel_dist: 1555.3510, mean_rewards: 223.9747, total_rewards: 3142.3749, mean_steps: 20.0500, mean_ecr: 0.0411 mean_entropies: 1.2514, took: 90.1034s
2022-10-10 13:12:24,044 [INFO] 	Process 3 - batch 43199: mean_policy_losses: -27.605, mean_net_lifetime: 3917.1559, mean_mc_travel_dist: 1050.1498, mean_rewards: 220.9813, total_rewards: 2890.8408, mean_steps: 16.8000, mean_ecr: 0.0496 mean_entropies: 0.4707, took: 79.2457s
2022-10-10 13:13:00,884 [INFO] 	Process 6 - batch 60499: mean_policy_losses: -40.854, mean_net_lifetime: 3798.2166, mean_mc_travel_dist: 1007.7622, mean_rewards: 313.0371, total_rewards: 2815.4742, mean_steps: 11.1600, mean_ecr: 0.0556 mean_entropies: 0.1990, took: 56.4229s
2022-10-10 13:13:29,904 [INFO] 	Process 1 - batch 36799: mean_policy_losses: 15.715, mean_net_lifetime: 4868.1174, mean_mc_travel_dist: 1865.7760, mean_rewards: 246.0747, total_rewards: 3028.1881, mean_steps: 19.0400, mean_ecr: 0.0386 mean_entropies: 0.7961, took: 86.5068s
2022-10-10 13:13:34,609 [INFO] Process 4 - epoch 32: mean_policy_losses: 88.768, mean_net_lifetime: 3701.6371, mean_mc_travel_dist: 1291.1131, mean_entropies: 1.4465, m_net_lifetime_valid: 4378.7033, took: 1802.6495s, (144.5028 / 100 batches)

2022-10-10 13:13:38,551 [INFO] 	Process 7 - batch 42399: mean_policy_losses: -497.170, mean_net_lifetime: 4300.8371, mean_mc_travel_dist: 1463.4565, mean_rewards: 225.8402, total_rewards: 2884.0858, mean_steps: 18.6100, mean_ecr: 0.0412 mean_entropies: 1.1936, took: 84.2412s
2022-10-10 13:13:45,192 [INFO] 	Process 3 - batch 43299: mean_policy_losses: 4.220, mean_net_lifetime: 4262.1140, mean_mc_travel_dist: 1154.6411, mean_rewards: 235.9497, total_rewards: 3126.9085, mean_steps: 17.1200, mean_ecr: 0.0490 mean_entropies: 0.5135, took: 81.1482s
2022-10-10 13:13:56,248 [INFO] 	Process 6 - batch 60599: mean_policy_losses: -92.580, mean_net_lifetime: 3737.1573, mean_mc_travel_dist: 992.8744, mean_rewards: 322.8564, total_rewards: 2760.8933, mean_steps: 10.6200, mean_ecr: 0.0557 mean_entropies: 0.1973, took: 55.3642s
2022-10-10 13:13:56,638 [INFO] Process 2 - epoch 28: mean_policy_losses: 10.735, mean_net_lifetime: 4204.9061, mean_mc_travel_dist: 1625.4851, mean_entropies: 1.2321, m_net_lifetime_valid: 4354.6913, took: 1793.5528s, (165.0885 / 100 batches)

2022-10-10 13:14:49,513 [INFO] 	Process 6 - batch 60699: mean_policy_losses: -69.752, mean_net_lifetime: 3487.8653, mean_mc_travel_dist: 949.5473, mean_rewards: 331.9970, total_rewards: 2566.2083, mean_steps: 9.5300, mean_ecr: 0.0559 mean_entropies: 0.2264, took: 53.2637s
2022-10-10 13:15:03,240 [INFO] 	Process 1 - batch 36899: mean_policy_losses: 33.521, mean_net_lifetime: 4996.3075, mean_mc_travel_dist: 1833.5370, mean_rewards: 246.4612, total_rewards: 3188.9910, mean_steps: 19.5100, mean_ecr: 0.0388 mean_entropies: 0.9039, took: 93.3362s
2022-10-10 13:15:04,294 [INFO] 	Process 7 - batch 42499: mean_policy_losses: -620.739, mean_net_lifetime: 4103.6069, mean_mc_travel_dist: 1379.3842, mean_rewards: 231.7658, total_rewards: 2769.7965, mean_steps: 17.3100, mean_ecr: 0.0414 mean_entropies: 1.2754, took: 85.7439s
2022-10-10 13:15:05,667 [INFO] 	Process 4 - batch 48099: mean_policy_losses: 125.089, mean_net_lifetime: 5082.9367, mean_mc_travel_dist: 1435.2371, mean_rewards: 277.7515, total_rewards: 3673.7222, mean_steps: 17.4600, mean_ecr: 0.0467 mean_entropies: 0.7204, took: 604.8868s
2022-10-10 13:15:08,203 [INFO] 	Process 3 - batch 43399: mean_policy_losses: 12.231, mean_net_lifetime: 4361.0996, mean_mc_travel_dist: 1174.2759, mean_rewards: 254.0266, total_rewards: 3215.5848, mean_steps: 16.2100, mean_ecr: 0.0487 mean_entropies: 0.5327, took: 83.0109s
2022-10-10 13:15:22,094 [INFO] Process 5 - epoch 28: mean_policy_losses: -184.870, mean_net_lifetime: 4473.4595, mean_mc_travel_dist: 1989.5048, mean_entropies: 1.5410, m_net_lifetime_valid: 4889.3994, took: 1874.1174s, (165.2977 / 100 batches)

2022-10-10 13:15:22,730 [INFO] 	Process 2 - batch 42099: mean_policy_losses: -16.244, mean_net_lifetime: 4695.3696, mean_mc_travel_dist: 1342.9289, mean_rewards: 264.3928, total_rewards: 3375.1328, mean_steps: 16.8600, mean_ecr: 0.0406 mean_entropies: 0.4776, took: 625.7625s
2022-10-10 13:15:44,913 [INFO] 	Process 6 - batch 60799: mean_policy_losses: -146.871, mean_net_lifetime: 3561.2560, mean_mc_travel_dist: 954.0568, mean_rewards: 325.5032, total_rewards: 2624.4120, mean_steps: 9.9500, mean_ecr: 0.0558 mean_entropies: 0.1965, took: 55.3973s
2022-10-10 13:16:25,734 [INFO] 	Process 7 - batch 42599: mean_policy_losses: -731.042, mean_net_lifetime: 3907.7112, mean_mc_travel_dist: 1348.8083, mean_rewards: 240.8316, total_rewards: 2616.3437, mean_steps: 15.6100, mean_ecr: 0.0415 mean_entropies: 1.3452, took: 81.4400s
2022-10-10 13:16:30,765 [INFO] 	Process 3 - batch 43499: mean_policy_losses: 59.727, mean_net_lifetime: 4566.5119, mean_mc_travel_dist: 1237.2059, mean_rewards: 276.8523, total_rewards: 3355.5188, mean_steps: 15.5400, mean_ecr: 0.0482 mean_entropies: 0.5519, took: 82.5623s
2022-10-10 13:16:33,732 [INFO] 	Process 4 - batch 48199: mean_policy_losses: 93.458, mean_net_lifetime: 4865.7925, mean_mc_travel_dist: 1365.8698, mean_rewards: 282.5814, total_rewards: 3533.5618, mean_steps: 16.2700, mean_ecr: 0.0473 mean_entropies: 0.7376, took: 88.0645s
2022-10-10 13:16:39,036 [INFO] 	Process 6 - batch 60899: mean_policy_losses: -229.408, mean_net_lifetime: 3427.4270, mean_mc_travel_dist: 925.1328, mean_rewards: 331.0804, total_rewards: 2518.5339, mean_steps: 9.3600, mean_ecr: 0.0560 mean_entropies: 0.2175, took: 54.1265s
2022-10-10 13:16:44,888 [INFO] 	Process 1 - batch 36999: mean_policy_losses: 70.387, mean_net_lifetime: 5217.6363, mean_mc_travel_dist: 1872.0609, mean_rewards: 244.3296, total_rewards: 3378.0412, mean_steps: 20.7200, mean_ecr: 0.0388 mean_entropies: 0.9608, took: 101.6480s
2022-10-10 13:16:51,382 [INFO] 	Process 2 - batch 42199: mean_policy_losses: -0.173, mean_net_lifetime: 4699.3228, mean_mc_travel_dist: 1322.6532, mean_rewards: 271.5637, total_rewards: 3396.4016, mean_steps: 16.4200, mean_ecr: 0.0406 mean_entropies: 0.5013, took: 88.6514s
2022-10-10 13:16:56,090 [INFO] 	Process 5 - batch 42099: mean_policy_losses: -425.686, mean_net_lifetime: 4718.4030, mean_mc_travel_dist: 1630.6984, mean_rewards: 246.6540, total_rewards: 3161.3214, mean_steps: 18.6500, mean_ecr: 0.0301 mean_entropies: 0.7290, took: 630.9151s
2022-10-10 13:17:34,525 [INFO] 	Process 6 - batch 60999: mean_policy_losses: -134.074, mean_net_lifetime: 3626.0963, mean_mc_travel_dist: 966.0101, mean_rewards: 325.7515, total_rewards: 2669.8328, mean_steps: 10.1600, mean_ecr: 0.0558 mean_entropies: 0.1950, took: 55.4890s
2022-10-10 13:17:39,544 [INFO] 	Process 7 - batch 42699: mean_policy_losses: -779.909, mean_net_lifetime: 3752.9737, mean_mc_travel_dist: 1267.8172, mean_rewards: 253.6912, total_rewards: 2520.2081, mean_steps: 14.2300, mean_ecr: 0.0419 mean_entropies: 1.3433, took: 73.8097s
2022-10-10 13:17:58,019 [INFO] 	Process 4 - batch 48299: mean_policy_losses: 65.664, mean_net_lifetime: 4701.4613, mean_mc_travel_dist: 1318.8941, mean_rewards: 278.8385, total_rewards: 3410.9229, mean_steps: 15.8900, mean_ecr: 0.0475 mean_entropies: 0.7182, took: 84.2874s
2022-10-10 13:18:16,143 [INFO] 	Process 2 - batch 42299: mean_policy_losses: -7.853, mean_net_lifetime: 4706.5587, mean_mc_travel_dist: 1323.5348, mean_rewards: 269.2934, total_rewards: 3406.4071, mean_steps: 16.5700, mean_ecr: 0.0407 mean_entropies: 0.4781, took: 84.7619s
2022-10-10 13:18:26,513 [INFO] 	Process 5 - batch 42199: mean_policy_losses: -438.917, mean_net_lifetime: 4491.3810, mean_mc_travel_dist: 1514.6840, mean_rewards: 247.3706, total_rewards: 3031.7174, mean_steps: 17.9800, mean_ecr: 0.0301 mean_entropies: 0.7008, took: 90.4225s
2022-10-10 13:18:33,006 [INFO] 	Process 1 - batch 37099: mean_policy_losses: 138.976, mean_net_lifetime: 5445.3432, mean_mc_travel_dist: 1891.7598, mean_rewards: 238.1433, total_rewards: 3589.7860, mean_steps: 22.1600, mean_ecr: 0.0386 mean_entropies: 0.9658, took: 108.1176s
2022-10-10 13:18:34,250 [INFO] 	Process 6 - batch 61099: mean_policy_losses: -52.641, mean_net_lifetime: 3810.3905, mean_mc_travel_dist: 1014.8074, mean_rewards: 320.5911, total_rewards: 2818.7316, mean_steps: 10.8900, mean_ecr: 0.0556 mean_entropies: 0.1957, took: 59.7248s
2022-10-10 13:18:50,574 [INFO] 	Process 7 - batch 42799: mean_policy_losses: -816.527, mean_net_lifetime: 3565.8219, mean_mc_travel_dist: 1190.3929, mean_rewards: 243.0847, total_rewards: 2412.5438, mean_steps: 14.0500, mean_ecr: 0.0421 mean_entropies: 1.3636, took: 71.0293s
2022-10-10 13:19:21,326 [INFO] 	Process 4 - batch 48399: mean_policy_losses: 44.086, mean_net_lifetime: 4578.6398, mean_mc_travel_dist: 1292.4535, mean_rewards: 278.6418, total_rewards: 3325.2773, mean_steps: 15.4300, mean_ecr: 0.0479 mean_entropies: 0.7519, took: 83.3070s
2022-10-10 13:19:33,026 [INFO] 	Process 6 - batch 61199: mean_policy_losses: -58.134, mean_net_lifetime: 3799.3605, mean_mc_travel_dist: 1015.5925, mean_rewards: 321.4095, total_rewards: 2802.8534, mean_steps: 10.8500, mean_ecr: 0.0556 mean_entropies: 0.1857, took: 58.7768s
2022-10-10 13:19:40,433 [INFO] 	Process 2 - batch 42399: mean_policy_losses: -4.425, mean_net_lifetime: 4694.2298, mean_mc_travel_dist: 1324.0768, mean_rewards: 269.6349, total_rewards: 3387.0958, mean_steps: 16.5000, mean_ecr: 0.0408 mean_entropies: 0.4560, took: 84.2896s
2022-10-10 13:20:01,438 [INFO] 	Process 5 - batch 42299: mean_policy_losses: -345.125, mean_net_lifetime: 4877.0166, mean_mc_travel_dist: 1667.1325, mean_rewards: 248.3490, total_rewards: 3268.1587, mean_steps: 19.0800, mean_ecr: 0.0302 mean_entropies: 0.7029, took: 94.9247s
2022-10-10 13:20:08,650 [INFO] 	Process 7 - batch 42899: mean_policy_losses: -728.983, mean_net_lifetime: 3860.2451, mean_mc_travel_dist: 1312.3402, mean_rewards: 235.5368, total_rewards: 2589.2510, mean_steps: 15.7300, mean_ecr: 0.0419 mean_entropies: 1.3469, took: 78.0758s
2022-10-10 13:20:21,622 [INFO] 	Process 1 - batch 37199: mean_policy_losses: 110.131, mean_net_lifetime: 5348.3361, mean_mc_travel_dist: 1849.3313, mean_rewards: 233.6630, total_rewards: 3526.1864, mean_steps: 22.4200, mean_ecr: 0.0388 mean_entropies: 0.9919, took: 108.6167s
2022-10-10 13:20:33,501 [INFO] 	Process 6 - batch 61299: mean_policy_losses: -108.632, mean_net_lifetime: 3744.0906, mean_mc_travel_dist: 1009.9888, mean_rewards: 308.2217, total_rewards: 2763.9956, mean_steps: 11.2100, mean_ecr: 0.0556 mean_entropies: 0.1487, took: 60.4746s
2022-10-10 13:20:45,519 [INFO] 	Process 4 - batch 48499: mean_policy_losses: 81.658, mean_net_lifetime: 4824.3968, mean_mc_travel_dist: 1359.6431, mean_rewards: 279.1788, total_rewards: 3500.3020, mean_steps: 16.2800, mean_ecr: 0.0473 mean_entropies: 0.7290, took: 84.1931s
2022-10-10 13:21:03,851 [INFO] 	Process 2 - batch 42499: mean_policy_losses: -0.828, mean_net_lifetime: 4707.1448, mean_mc_travel_dist: 1314.6933, mean_rewards: 270.8664, total_rewards: 3411.9794, mean_steps: 16.4500, mean_ecr: 0.0407 mean_entropies: 0.4852, took: 83.4180s
2022-10-10 13:21:30,310 [INFO] 	Process 7 - batch 42999: mean_policy_losses: -626.584, mean_net_lifetime: 4033.9938, mean_mc_travel_dist: 1353.1791, mean_rewards: 237.5155, total_rewards: 2717.2782, mean_steps: 16.4100, mean_ecr: 0.0418 mean_entropies: 1.3055, took: 81.6598s
2022-10-10 13:21:32,057 [INFO] 	Process 6 - batch 61399: mean_policy_losses: -158.433, mean_net_lifetime: 3622.0660, mean_mc_travel_dist: 978.2714, mean_rewards: 307.6128, total_rewards: 2682.3803, mean_steps: 10.8100, mean_ecr: 0.0558 mean_entropies: 0.1464, took: 58.5563s
2022-10-10 13:21:35,391 [INFO] 	Process 5 - batch 42399: mean_policy_losses: -322.239, mean_net_lifetime: 4783.5560, mean_mc_travel_dist: 1632.6041, mean_rewards: 250.5384, total_rewards: 3218.4362, mean_steps: 18.7400, mean_ecr: 0.0303 mean_entropies: 0.6937, took: 93.9534s
2022-10-10 13:22:04,859 [INFO] 	Process 1 - batch 37299: mean_policy_losses: 101.334, mean_net_lifetime: 5326.1164, mean_mc_travel_dist: 1850.6101, mean_rewards: 241.7248, total_rewards: 3494.5282, mean_steps: 21.3500, mean_ecr: 0.0387 mean_entropies: 0.9826, took: 103.2366s
2022-10-10 13:22:10,749 [INFO] 	Process 4 - batch 48599: mean_policy_losses: 65.415, mean_net_lifetime: 4719.8381, mean_mc_travel_dist: 1329.6243, mean_rewards: 279.9696, total_rewards: 3422.5579, mean_steps: 15.9000, mean_ecr: 0.0475 mean_entropies: 0.7468, took: 85.2292s
2022-10-10 13:22:27,982 [INFO] 	Process 6 - batch 61499: mean_policy_losses: -135.016, mean_net_lifetime: 3551.4653, mean_mc_travel_dist: 951.7911, mean_rewards: 319.7326, total_rewards: 2625.9993, mean_steps: 10.1400, mean_ecr: 0.0558 mean_entropies: 0.1933, took: 55.9251s
2022-10-10 13:22:29,339 [INFO] 	Process 2 - batch 42599: mean_policy_losses: -3.431, mean_net_lifetime: 4706.7287, mean_mc_travel_dist: 1317.9841, mean_rewards: 273.5836, total_rewards: 3412.2817, mean_steps: 16.3000, mean_ecr: 0.0407 mean_entropies: 0.4819, took: 85.4883s
2022-10-10 13:22:43,109 [INFO] 	Process 7 - batch 43099: mean_policy_losses: -754.610, mean_net_lifetime: 3691.3687, mean_mc_travel_dist: 1255.7625, mean_rewards: 238.5078, total_rewards: 2484.5219, mean_steps: 14.6700, mean_ecr: 0.0420 mean_entropies: 1.3348, took: 72.8007s
2022-10-10 13:23:08,435 [INFO] 	Process 5 - batch 42499: mean_policy_losses: -307.582, mean_net_lifetime: 5075.3686, mean_mc_travel_dist: 1717.3060, mean_rewards: 260.1720, total_rewards: 3406.0961, mean_steps: 19.0600, mean_ecr: 0.0306 mean_entropies: 0.7527, took: 93.0426s
2022-10-10 13:23:26,714 [INFO] 	Process 4 - batch 48699: mean_policy_losses: 39.443, mean_net_lifetime: 4437.1017, mean_mc_travel_dist: 1261.1869, mean_rewards: 277.5125, total_rewards: 3202.9109, mean_steps: 15.0300, mean_ecr: 0.0481 mean_entropies: 0.7667, took: 75.9658s
2022-10-10 13:23:41,302 [INFO] 	Process 1 - batch 37399: mean_policy_losses: 122.964, mean_net_lifetime: 5361.0650, mean_mc_travel_dist: 1862.3454, mean_rewards: 253.0429, total_rewards: 3517.7673, mean_steps: 20.3500, mean_ecr: 0.0387 mean_entropies: 1.0519, took: 96.4433s
2022-10-10 13:23:54,071 [INFO] 	Process 2 - batch 42699: mean_policy_losses: 10.642, mean_net_lifetime: 4727.3566, mean_mc_travel_dist: 1329.8580, mean_rewards: 271.6325, total_rewards: 3421.0689, mean_steps: 16.4900, mean_ecr: 0.0407 mean_entropies: 0.5148, took: 84.7315s
2022-10-10 13:23:54,330 [INFO] 	Process 7 - batch 43199: mean_policy_losses: -752.259, mean_net_lifetime: 3533.8149, mean_mc_travel_dist: 1281.4641, mean_rewards: 233.7919, total_rewards: 2296.8428, mean_steps: 14.4300, mean_ecr: 0.0422 mean_entropies: 1.2278, took: 71.2209s
2022-10-10 13:24:22,109 [INFO] 	Process 5 - batch 42599: mean_policy_losses: -545.146, mean_net_lifetime: 3691.5133, mean_mc_travel_dist: 1214.9479, mean_rewards: 247.0116, total_rewards: 2536.6851, mean_steps: 15.0100, mean_ecr: 0.0302 mean_entropies: 0.6767, took: 73.6751s
2022-10-10 13:24:46,298 [INFO] 	Process 4 - batch 48799: mean_policy_losses: 89.713, mean_net_lifetime: 4742.1994, mean_mc_travel_dist: 1370.4264, mean_rewards: 282.6923, total_rewards: 3403.5137, mean_steps: 15.7600, mean_ecr: 0.0472 mean_entropies: 0.6487, took: 79.5838s
2022-10-10 13:24:59,692 [INFO] 	Process 7 - batch 43299: mean_policy_losses: -742.524, mean_net_lifetime: 3211.5863, mean_mc_travel_dist: 1166.1783, mean_rewards: 230.3907, total_rewards: 2089.9054, mean_steps: 13.3300, mean_ecr: 0.0425 mean_entropies: 1.2013, took: 65.3609s
2022-10-10 13:25:10,760 [INFO] 	Process 1 - batch 37499: mean_policy_losses: 125.736, mean_net_lifetime: 5159.7869, mean_mc_travel_dist: 1868.9371, mean_rewards: 262.9006, total_rewards: 3317.2124, mean_steps: 18.7100, mean_ecr: 0.0388 mean_entropies: 0.9869, took: 89.4580s
2022-10-10 13:25:16,897 [INFO] 	Process 2 - batch 42799: mean_policy_losses: 19.043, mean_net_lifetime: 4666.7959, mean_mc_travel_dist: 1309.7475, mean_rewards: 265.1009, total_rewards: 3382.9264, mean_steps: 16.7100, mean_ecr: 0.0408 mean_entropies: 0.5026, took: 82.8264s
2022-10-10 13:25:34,621 [INFO] Process 3 - epoch 29: mean_policy_losses: 95.950, mean_net_lifetime: 4086.1713, mean_mc_travel_dist: 1427.1756, mean_entropies: 1.1767, m_net_lifetime_valid: 4209.7672, took: 1700.3047s, (160.9984 / 100 batches)

2022-10-10 13:25:42,464 [INFO] 	Process 5 - batch 42699: mean_policy_losses: -390.359, mean_net_lifetime: 4475.5465, mean_mc_travel_dist: 1494.3343, mean_rewards: 257.1270, total_rewards: 3032.2965, mean_steps: 16.7900, mean_ecr: 0.0305 mean_entropies: 0.7138, took: 80.3545s
2022-10-10 13:26:06,523 [INFO] 	Process 4 - batch 48899: mean_policy_losses: 31.310, mean_net_lifetime: 4562.7521, mean_mc_travel_dist: 1293.4633, mean_rewards: 271.5693, total_rewards: 3295.5564, mean_steps: 15.9300, mean_ecr: 0.0480 mean_entropies: 0.7622, took: 80.2256s
2022-10-10 13:26:13,969 [INFO] 	Process 7 - batch 43399: mean_policy_losses: -760.884, mean_net_lifetime: 3798.8320, mean_mc_travel_dist: 1294.2774, mean_rewards: 241.8468, total_rewards: 2550.6755, mean_steps: 15.4000, mean_ecr: 0.0419 mean_entropies: 1.3687, took: 74.2775s
2022-10-10 13:26:37,138 [INFO] 	Process 2 - batch 42899: mean_policy_losses: -9.990, mean_net_lifetime: 4723.2834, mean_mc_travel_dist: 1363.9455, mean_rewards: 279.3340, total_rewards: 3386.1550, mean_steps: 16.0400, mean_ecr: 0.0404 mean_entropies: 0.5587, took: 80.2400s
2022-10-10 13:26:51,225 [INFO] 	Process 3 - batch 43599: mean_policy_losses: 38.647, mean_net_lifetime: 4554.6159, mean_mc_travel_dist: 1274.0011, mean_rewards: 280.9635, total_rewards: 3314.7447, mean_steps: 15.2500, mean_ecr: 0.0483 mean_entropies: 0.5728, took: 620.4595s
2022-10-10 13:27:15,397 [INFO] 	Process 5 - batch 42799: mean_policy_losses: -310.509, mean_net_lifetime: 4938.5649, mean_mc_travel_dist: 1689.9285, mean_rewards: 250.0434, total_rewards: 3298.5952, mean_steps: 19.1400, mean_ecr: 0.0300 mean_entropies: 0.6981, took: 92.9329s
2022-10-10 13:27:32,913 [INFO] 	Process 4 - batch 48999: mean_policy_losses: 127.052, mean_net_lifetime: 5146.7954, mean_mc_travel_dist: 1473.6921, mean_rewards: 282.7831, total_rewards: 3706.5819, mean_steps: 17.3900, mean_ecr: 0.0467 mean_entropies: 0.6952, took: 86.3892s
2022-10-10 13:27:36,691 [INFO] 	Process 7 - batch 43499: mean_policy_losses: -698.350, mean_net_lifetime: 4026.3909, mean_mc_travel_dist: 1511.0105, mean_rewards: 234.5530, total_rewards: 2564.6098, mean_steps: 17.1800, mean_ecr: 0.0416 mean_entropies: 1.2920, took: 82.7223s
2022-10-10 13:27:56,868 [INFO] 	Process 2 - batch 42999: mean_policy_losses: -19.218, mean_net_lifetime: 4702.0589, mean_mc_travel_dist: 1320.5194, mean_rewards: 277.0539, total_rewards: 3398.4093, mean_steps: 16.0500, mean_ecr: 0.0407 mean_entropies: 0.5122, took: 79.7310s
2022-10-10 13:28:07,389 [INFO] 	Process 3 - batch 43699: mean_policy_losses: 8.269, mean_net_lifetime: 4457.4877, mean_mc_travel_dist: 1233.8979, mean_rewards: 269.5550, total_rewards: 3246.8536, mean_steps: 15.5900, mean_ecr: 0.0486 mean_entropies: 0.5591, took: 76.1640s
2022-10-10 13:28:47,446 [INFO] 	Process 5 - batch 42899: mean_policy_losses: -400.162, mean_net_lifetime: 4955.7011, mean_mc_travel_dist: 1690.1721, mean_rewards: 246.1368, total_rewards: 3316.0201, mean_steps: 19.6600, mean_ecr: 0.0300 mean_entropies: 0.7214, took: 92.0500s
2022-10-10 13:28:55,661 [INFO] 	Process 4 - batch 49099: mean_policy_losses: 61.450, mean_net_lifetime: 5092.7375, mean_mc_travel_dist: 1455.2776, mean_rewards: 284.1337, total_rewards: 3669.9871, mean_steps: 17.0600, mean_ecr: 0.0466 mean_entropies: 0.6950, took: 82.7477s
2022-10-10 13:29:13,381 [INFO] 	Process 2 - batch 43099: mean_policy_losses: -24.648, mean_net_lifetime: 4708.2434, mean_mc_travel_dist: 1333.6507, mean_rewards: 285.2724, total_rewards: 3399.6087, mean_steps: 15.6000, mean_ecr: 0.0407 mean_entropies: 0.5517, took: 76.5121s
2022-10-10 13:29:20,140 [INFO] 	Process 3 - batch 43799: mean_policy_losses: 5.982, mean_net_lifetime: 4579.8976, mean_mc_travel_dist: 1283.7261, mean_rewards: 283.1203, total_rewards: 3327.6602, mean_steps: 15.2400, mean_ecr: 0.0483 mean_entropies: 0.5537, took: 72.7509s
2022-10-10 13:30:12,249 [INFO] 	Process 5 - batch 42999: mean_policy_losses: -471.946, mean_net_lifetime: 4634.3099, mean_mc_travel_dist: 1602.9056, mean_rewards: 250.0897, total_rewards: 3076.8169, mean_steps: 18.5600, mean_ecr: 0.0296 mean_entropies: 0.7060, took: 84.8023s
2022-10-10 13:30:19,393 [INFO] 	Process 4 - batch 49199: mean_policy_losses: 112.663, mean_net_lifetime: 5284.3982, mean_mc_travel_dist: 1480.8891, mean_rewards: 292.0628, total_rewards: 3833.1153, mean_steps: 17.1700, mean_ecr: 0.0463 mean_entropies: 0.6829, took: 83.7322s
2022-10-10 13:30:31,857 [INFO] 	Process 2 - batch 43199: mean_policy_losses: -16.260, mean_net_lifetime: 4732.4116, mean_mc_travel_dist: 1329.2744, mean_rewards: 280.6780, total_rewards: 3428.4493, mean_steps: 15.9800, mean_ecr: 0.0407 mean_entropies: 0.5513, took: 78.4715s
2022-10-10 13:30:32,869 [INFO] 	Process 3 - batch 43899: mean_policy_losses: -5.328, mean_net_lifetime: 4441.3736, mean_mc_travel_dist: 1236.7440, mean_rewards: 276.7495, total_rewards: 3228.4939, mean_steps: 15.0900, mean_ecr: 0.0485 mean_entropies: 0.5734, took: 72.7288s
2022-10-10 13:31:33,925 [INFO] 	Process 5 - batch 43099: mean_policy_losses: -524.826, mean_net_lifetime: 4355.7732, mean_mc_travel_dist: 1478.1352, mean_rewards: 246.4718, total_rewards: 2935.6447, mean_steps: 17.4500, mean_ecr: 0.0299 mean_entropies: 0.7288, took: 81.6763s
2022-10-10 13:31:38,640 [INFO] 	Process 4 - batch 49299: mean_policy_losses: 66.331, mean_net_lifetime: 4887.1750, mean_mc_travel_dist: 1383.1588, mean_rewards: 291.9067, total_rewards: 3538.1532, mean_steps: 15.7900, mean_ecr: 0.0474 mean_entropies: 0.6889, took: 79.2461s
2022-10-10 13:31:47,597 [INFO] 	Process 3 - batch 43999: mean_policy_losses: -2.987, mean_net_lifetime: 4446.0337, mean_mc_travel_dist: 1229.9328, mean_rewards: 272.1696, total_rewards: 3244.2508, mean_steps: 15.3900, mean_ecr: 0.0485 mean_entropies: 0.5699, took: 74.7274s
2022-10-10 13:31:50,536 [INFO] 	Process 2 - batch 43299: mean_policy_losses: -9.900, mean_net_lifetime: 4770.7995, mean_mc_travel_dist: 1336.8839, mean_rewards: 279.3840, total_rewards: 3458.7793, mean_steps: 16.1800, mean_ecr: 0.0406 mean_entropies: 0.5729, took: 78.6846s
2022-10-10 13:31:56,389 [INFO] Process 6 - epoch 41: mean_policy_losses: -265.983, mean_net_lifetime: 2649.4521, mean_mc_travel_dist: 951.7177, mean_entropies: 0.8592, m_net_lifetime_valid: 4531.9009, took: 1399.4190s, (114.5336 / 100 batches)

2022-10-10 13:32:45,363 [INFO] 	Process 6 - batch 61599: mean_policy_losses: -205.241, mean_net_lifetime: 3260.0877, mean_mc_travel_dist: 884.2341, mean_rewards: 323.5942, total_rewards: 2403.4706, mean_steps: 9.1100, mean_ecr: 0.0562 mean_entropies: 0.2567, took: 617.3808s
2022-10-10 13:32:58,186 [INFO] 	Process 5 - batch 43199: mean_policy_losses: -416.348, mean_net_lifetime: 4600.0295, mean_mc_travel_dist: 1550.6132, mean_rewards: 254.3891, total_rewards: 3107.4518, mean_steps: 17.8000, mean_ecr: 0.0304 mean_entropies: 0.7281, took: 84.2617s
2022-10-10 13:33:02,523 [INFO] 	Process 4 - batch 49399: mean_policy_losses: 88.752, mean_net_lifetime: 4989.0471, mean_mc_travel_dist: 1405.9005, mean_rewards: 285.2788, total_rewards: 3619.7086, mean_steps: 16.5400, mean_ecr: 0.0469 mean_entropies: 0.7404, took: 83.8844s
2022-10-10 13:33:05,359 [INFO] 	Process 3 - batch 44099: mean_policy_losses: 24.992, mean_net_lifetime: 4556.0103, mean_mc_travel_dist: 1280.3449, mean_rewards: 273.8227, total_rewards: 3304.6991, mean_steps: 15.7100, mean_ecr: 0.0481 mean_entropies: 0.5836, took: 77.7624s
2022-10-10 13:33:13,709 [INFO] 	Process 2 - batch 43399: mean_policy_losses: 27.534, mean_net_lifetime: 4923.0103, mean_mc_travel_dist: 1409.5771, mean_rewards: 283.8125, total_rewards: 3538.3558, mean_steps: 16.4500, mean_ecr: 0.0403 mean_entropies: 0.6144, took: 83.1724s
2022-10-10 13:33:38,680 [INFO] 	Process 6 - batch 61699: mean_policy_losses: -126.593, mean_net_lifetime: 3546.2449, mean_mc_travel_dist: 955.0274, mean_rewards: 321.0143, total_rewards: 2617.1737, mean_steps: 10.1500, mean_ecr: 0.0558 mean_entropies: 0.2055, took: 53.3168s
2022-10-10 13:34:13,739 [INFO] Process 1 - epoch 25: mean_policy_losses: 44.982, mean_net_lifetime: 4723.4202, mean_mc_travel_dist: 2075.8695, mean_entropies: 1.3947, m_net_lifetime_valid: 4363.2880, took: 2001.9876s, (188.0744 / 100 batches)

2022-10-10 13:34:15,105 [INFO] 	Process 5 - batch 43299: mean_policy_losses: -562.206, mean_net_lifetime: 4030.2639, mean_mc_travel_dist: 1331.7161, mean_rewards: 255.9958, total_rewards: 2749.5229, mean_steps: 15.7300, mean_ecr: 0.0303 mean_entropies: 0.7035, took: 76.9182s
2022-10-10 13:34:23,234 [INFO] 	Process 3 - batch 44199: mean_policy_losses: 9.343, mean_net_lifetime: 4427.3497, mean_mc_travel_dist: 1220.2982, mean_rewards: 267.1219, total_rewards: 3239.3463, mean_steps: 15.6300, mean_ecr: 0.0487 mean_entropies: 0.5624, took: 77.8759s
2022-10-10 13:34:24,886 [INFO] 	Process 4 - batch 49499: mean_policy_losses: 45.685, mean_net_lifetime: 4947.1981, mean_mc_travel_dist: 1406.6413, mean_rewards: 285.8355, total_rewards: 3571.6984, mean_steps: 16.3600, mean_ecr: 0.0470 mean_entropies: 0.6801, took: 82.3613s
2022-10-10 13:34:32,408 [INFO] 	Process 6 - batch 61799: mean_policy_losses: -143.247, mean_net_lifetime: 3585.6369, mean_mc_travel_dist: 959.7875, mean_rewards: 325.4147, total_rewards: 2642.6373, mean_steps: 10.0300, mean_ecr: 0.0558 mean_entropies: 0.1908, took: 53.7277s
2022-10-10 13:34:33,446 [INFO] 	Process 2 - batch 43499: mean_policy_losses: -2.327, mean_net_lifetime: 4725.5053, mean_mc_travel_dist: 1332.1159, mean_rewards: 279.7302, total_rewards: 3419.3712, mean_steps: 15.9800, mean_ecr: 0.0406 mean_entropies: 0.5430, took: 79.7371s
2022-10-10 13:35:23,310 [INFO] 	Process 6 - batch 61899: mean_policy_losses: -174.847, mean_net_lifetime: 3542.0488, mean_mc_travel_dist: 946.5298, mean_rewards: 325.9918, total_rewards: 2610.7631, mean_steps: 9.8800, mean_ecr: 0.0559 mean_entropies: 0.1833, took: 50.9027s
2022-10-10 13:35:37,606 [INFO] 	Process 5 - batch 43399: mean_policy_losses: -360.303, mean_net_lifetime: 4427.3871, mean_mc_travel_dist: 1503.6485, mean_rewards: 241.8240, total_rewards: 2994.3206, mean_steps: 17.7300, mean_ecr: 0.0304 mean_entropies: 0.6946, took: 82.5018s
2022-10-10 13:35:41,008 [INFO] 	Process 3 - batch 44299: mean_policy_losses: 22.760, mean_net_lifetime: 4476.1399, mean_mc_travel_dist: 1236.1998, mean_rewards: 263.7152, total_rewards: 3271.2842, mean_steps: 16.0200, mean_ecr: 0.0486 mean_entropies: 0.5535, took: 77.7743s
2022-10-10 13:35:56,561 [INFO] 	Process 1 - batch 37599: mean_policy_losses: 101.295, mean_net_lifetime: 5342.9875, mean_mc_travel_dist: 1858.1042, mean_rewards: 227.3858, total_rewards: 3515.2069, mean_steps: 22.8100, mean_ecr: 0.0388 mean_entropies: 0.9607, took: 645.8010s
2022-10-10 13:36:13,790 [INFO] 	Process 6 - batch 61999: mean_policy_losses: -184.043, mean_net_lifetime: 3483.7933, mean_mc_travel_dist: 934.0356, mean_rewards: 331.0801, total_rewards: 2565.7520, mean_steps: 9.5500, mean_ecr: 0.0558 mean_entropies: 0.2001, took: 50.4794s
2022-10-10 13:36:55,860 [INFO] 	Process 3 - batch 44399: mean_policy_losses: 20.834, mean_net_lifetime: 4460.2296, mean_mc_travel_dist: 1240.9240, mean_rewards: 273.2346, total_rewards: 3248.2933, mean_steps: 15.3700, mean_ecr: 0.0484 mean_entropies: 0.5883, took: 74.8505s
2022-10-10 13:37:04,236 [INFO] 	Process 6 - batch 62099: mean_policy_losses: -124.699, mean_net_lifetime: 3538.9822, mean_mc_travel_dist: 945.8991, mean_rewards: 330.4068, total_rewards: 2609.0889, mean_steps: 9.7300, mean_ecr: 0.0559 mean_entropies: 0.2155, took: 50.4465s
2022-10-10 13:37:06,059 [INFO] 	Process 5 - batch 43499: mean_policy_losses: -290.334, mean_net_lifetime: 5245.1886, mean_mc_travel_dist: 1762.5890, mean_rewards: 261.4165, total_rewards: 3520.6036, mean_steps: 19.3300, mean_ecr: 0.0309 mean_entropies: 0.7329, took: 88.4529s
2022-10-10 13:37:32,343 [INFO] 	Process 1 - batch 37699: mean_policy_losses: 74.924, mean_net_lifetime: 5408.0366, mean_mc_travel_dist: 1901.5633, mean_rewards: 243.5779, total_rewards: 3536.9773, mean_steps: 21.5100, mean_ecr: 0.0387 mean_entropies: 0.9751, took: 95.7815s
2022-10-10 13:37:54,016 [INFO] 	Process 6 - batch 62199: mean_policy_losses: -133.608, mean_net_lifetime: 3591.8526, mean_mc_travel_dist: 963.8139, mean_rewards: 326.2721, total_rewards: 2642.0796, mean_steps: 10.0200, mean_ecr: 0.0558 mean_entropies: 0.1781, took: 49.7791s
2022-10-10 13:38:05,334 [INFO] Process 7 - epoch 29: mean_policy_losses: -211.311, mean_net_lifetime: 3985.1340, mean_mc_travel_dist: 1624.0329, mean_entropies: 1.7918, m_net_lifetime_valid: 4175.7280, took: 1808.5258s, (162.5271 / 100 batches)

2022-10-10 13:38:07,583 [INFO] 	Process 3 - batch 44499: mean_policy_losses: 16.159, mean_net_lifetime: 4382.8417, mean_mc_travel_dist: 1210.0993, mean_rewards: 269.8659, total_rewards: 3201.3581, mean_steps: 15.2800, mean_ecr: 0.0487 mean_entropies: 0.6128, took: 71.7241s
2022-10-10 13:38:45,413 [INFO] 	Process 6 - batch 62299: mean_policy_losses: -173.244, mean_net_lifetime: 3622.5352, mean_mc_travel_dist: 973.3534, mean_rewards: 323.4741, total_rewards: 2668.8406, mean_steps: 10.2000, mean_ecr: 0.0559 mean_entropies: 0.1708, took: 51.3981s
2022-10-10 13:39:03,686 [INFO] 	Process 1 - batch 37799: mean_policy_losses: 14.807, mean_net_lifetime: 5255.6351, mean_mc_travel_dist: 1869.7398, mean_rewards: 247.1791, total_rewards: 3410.7212, mean_steps: 20.6000, mean_ecr: 0.0387 mean_entropies: 0.9003, took: 91.3428s
2022-10-10 13:39:17,002 [INFO] 	Process 7 - batch 43599: mean_policy_losses: -810.643, mean_net_lifetime: 3676.0718, mean_mc_travel_dist: 1221.4492, mean_rewards: 232.5118, total_rewards: 2490.2714, mean_steps: 15.1700, mean_ecr: 0.0419 mean_entropies: 1.2869, took: 700.3098s
2022-10-10 13:39:24,001 [INFO] 	Process 3 - batch 44599: mean_policy_losses: 34.105, mean_net_lifetime: 4450.9144, mean_mc_travel_dist: 1201.1008, mean_rewards: 264.6751, total_rewards: 3279.3370, mean_steps: 15.8500, mean_ecr: 0.0487 mean_entropies: 0.5657, took: 76.4184s
2022-10-10 13:39:38,190 [INFO] 	Process 6 - batch 62399: mean_policy_losses: -77.569, mean_net_lifetime: 3679.5273, mean_mc_travel_dist: 987.4561, mean_rewards: 327.9630, total_rewards: 2712.4377, mean_steps: 10.2500, mean_ecr: 0.0557 mean_entropies: 0.1976, took: 52.7764s
2022-10-10 13:40:34,851 [INFO] 	Process 6 - batch 62499: mean_policy_losses: -78.506, mean_net_lifetime: 3755.3628, mean_mc_travel_dist: 998.9268, mean_rewards: 318.8048, total_rewards: 2773.7914, mean_steps: 10.8000, mean_ecr: 0.0556 mean_entropies: 0.1807, took: 56.6615s
2022-10-10 13:40:37,859 [INFO] 	Process 1 - batch 37899: mean_policy_losses: 41.374, mean_net_lifetime: 5184.8507, mean_mc_travel_dist: 1865.7150, mean_rewards: 244.8961, total_rewards: 3344.7645, mean_steps: 20.5800, mean_ecr: 0.0387 mean_entropies: 0.9007, took: 94.1733s
2022-10-10 13:40:38,696 [INFO] 	Process 7 - batch 43699: mean_policy_losses: -554.589, mean_net_lifetime: 4160.7311, mean_mc_travel_dist: 1345.6508, mean_rewards: 228.3720, total_rewards: 2845.0945, mean_steps: 17.7600, mean_ecr: 0.0416 mean_entropies: 1.2143, took: 81.6952s
2022-10-10 13:40:43,898 [INFO] 	Process 3 - batch 44699: mean_policy_losses: 5.881, mean_net_lifetime: 4261.8354, mean_mc_travel_dist: 1152.6514, mean_rewards: 244.7985, total_rewards: 3132.7157, mean_steps: 16.4300, mean_ecr: 0.0490 mean_entropies: 0.5149, took: 79.8968s
2022-10-10 13:41:30,927 [INFO] 	Process 6 - batch 62599: mean_policy_losses: -31.702, mean_net_lifetime: 3811.8481, mean_mc_travel_dist: 1013.2121, mean_rewards: 318.3158, total_rewards: 2823.8371, mean_steps: 11.0300, mean_ecr: 0.0555 mean_entropies: 0.2104, took: 56.0756s
2022-10-10 13:41:41,443 [INFO] 	Process 7 - batch 43799: mean_policy_losses: -807.902, mean_net_lifetime: 3327.9338, mean_mc_travel_dist: 1171.2097, mean_rewards: 237.7040, total_rewards: 2206.7284, mean_steps: 13.2200, mean_ecr: 0.0424 mean_entropies: 1.3447, took: 62.7461s
2022-10-10 13:42:01,065 [INFO] 	Process 3 - batch 44799: mean_policy_losses: 17.319, mean_net_lifetime: 4149.4058, mean_mc_travel_dist: 1126.9580, mean_rewards: 241.8359, total_rewards: 3042.3862, mean_steps: 16.2100, mean_ecr: 0.0492 mean_entropies: 0.5605, took: 77.1669s
2022-10-10 13:42:11,208 [INFO] 	Process 1 - batch 37999: mean_policy_losses: 69.453, mean_net_lifetime: 5105.0988, mean_mc_travel_dist: 1841.4785, mean_rewards: 241.0151, total_rewards: 3292.5798, mean_steps: 20.6000, mean_ecr: 0.0388 mean_entropies: 0.9269, took: 93.3496s
2022-10-10 13:42:23,961 [INFO] 	Process 6 - batch 62699: mean_policy_losses: -133.004, mean_net_lifetime: 3616.2281, mean_mc_travel_dist: 964.4318, mean_rewards: 325.0129, total_rewards: 2671.3701, mean_steps: 10.1600, mean_ecr: 0.0557 mean_entropies: 0.1990, took: 53.0337s
2022-10-10 13:42:43,954 [INFO] 	Process 7 - batch 43899: mean_policy_losses: -824.157, mean_net_lifetime: 3200.5526, mean_mc_travel_dist: 1088.3361, mean_rewards: 229.6035, total_rewards: 2160.2584, mean_steps: 13.2800, mean_ecr: 0.0424 mean_entropies: 1.3444, took: 62.5112s
2022-10-10 13:43:16,667 [INFO] 	Process 3 - batch 44899: mean_policy_losses: -12.257, mean_net_lifetime: 3942.7071, mean_mc_travel_dist: 1071.4170, mean_rewards: 236.3335, total_rewards: 2889.7042, mean_steps: 15.7300, mean_ecr: 0.0495 mean_entropies: 0.6116, took: 75.6012s
2022-10-10 13:43:18,125 [INFO] 	Process 6 - batch 62799: mean_policy_losses: -141.219, mean_net_lifetime: 3637.5227, mean_mc_travel_dist: 962.6942, mean_rewards: 316.2072, total_rewards: 2692.3131, mean_steps: 10.5200, mean_ecr: 0.0557 mean_entropies: 0.1912, took: 54.1637s
2022-10-10 13:43:22,633 [INFO] Process 4 - epoch 33: mean_policy_losses: 88.376, mean_net_lifetime: 3736.6632, mean_mc_travel_dist: 1293.6700, mean_entropies: 1.4244, m_net_lifetime_valid: 4249.7056, took: 1788.0228s, (143.6894 / 100 batches)

2022-10-10 13:43:49,816 [INFO] 	Process 1 - batch 38099: mean_policy_losses: 138.263, mean_net_lifetime: 5284.0175, mean_mc_travel_dist: 1882.7925, mean_rewards: 236.7879, total_rewards: 3427.4478, mean_steps: 21.7000, mean_ecr: 0.0386 mean_entropies: 0.9240, took: 98.6072s
2022-10-10 13:43:51,493 [INFO] 	Process 7 - batch 43999: mean_policy_losses: -801.869, mean_net_lifetime: 3079.8164, mean_mc_travel_dist: 1217.9005, mean_rewards: 215.7951, total_rewards: 1908.9768, mean_steps: 13.6600, mean_ecr: 0.0427 mean_entropies: 1.3371, took: 67.5400s
2022-10-10 13:44:02,888 [INFO] Process 2 - epoch 29: mean_policy_losses: 10.231, mean_net_lifetime: 4222.8721, mean_mc_travel_dist: 1615.4372, mean_entropies: 1.2075, m_net_lifetime_valid: 4248.3136, took: 1806.2475s, (163.4833 / 100 batches)

2022-10-10 13:44:13,684 [INFO] 	Process 6 - batch 62899: mean_policy_losses: -61.712, mean_net_lifetime: 3717.1066, mean_mc_travel_dist: 998.0236, mean_rewards: 324.5990, total_rewards: 2741.6319, mean_steps: 10.4700, mean_ecr: 0.0557 mean_entropies: 0.2086, took: 55.5596s
2022-10-10 13:44:37,339 [INFO] 	Process 3 - batch 44999: mean_policy_losses: 29.690, mean_net_lifetime: 4387.9319, mean_mc_travel_dist: 1179.1453, mean_rewards: 257.2957, total_rewards: 3235.7432, mean_steps: 16.1100, mean_ecr: 0.0490 mean_entropies: 0.5640, took: 80.6725s
2022-10-10 13:44:39,350 [INFO] 	Process 4 - batch 49599: mean_policy_losses: -79.870, mean_net_lifetime: 4043.2054, mean_mc_travel_dist: 1159.9503, mean_rewards: 258.5464, total_rewards: 2909.2236, mean_steps: 14.5700, mean_ecr: 0.0491 mean_entropies: 0.8399, took: 614.4647s
2022-10-10 13:45:04,299 [INFO] 	Process 7 - batch 44099: mean_policy_losses: -733.090, mean_net_lifetime: 3379.4814, mean_mc_travel_dist: 1176.7277, mean_rewards: 229.2231, total_rewards: 2241.0824, mean_steps: 14.5100, mean_ecr: 0.0424 mean_entropies: 1.2692, took: 72.8057s
2022-10-10 13:45:09,124 [INFO] 	Process 6 - batch 62999: mean_policy_losses: -136.178, mean_net_lifetime: 3649.1903, mean_mc_travel_dist: 969.1747, mean_rewards: 318.3405, total_rewards: 2693.4177, mean_steps: 10.4900, mean_ecr: 0.0557 mean_entropies: 0.1935, took: 55.4401s
2022-10-10 13:45:30,902 [INFO] 	Process 2 - batch 43599: mean_policy_losses: -9.450, mean_net_lifetime: 4656.6410, mean_mc_travel_dist: 1310.1077, mean_rewards: 257.6309, total_rewards: 3371.8128, mean_steps: 17.1800, mean_ecr: 0.0407 mean_entropies: 0.4527, took: 657.4547s
2022-10-10 13:45:32,837 [INFO] 	Process 1 - batch 38199: mean_policy_losses: 99.701, mean_net_lifetime: 5310.3119, mean_mc_travel_dist: 1888.0294, mean_rewards: 232.0083, total_rewards: 3451.8144, mean_steps: 22.1600, mean_ecr: 0.0387 mean_entropies: 0.9061, took: 103.0209s
2022-10-10 13:45:58,751 [INFO] 	Process 4 - batch 49699: mean_policy_losses: 14.716, mean_net_lifetime: 4534.6063, mean_mc_travel_dist: 1287.0653, mean_rewards: 276.0965, total_rewards: 3275.6137, mean_steps: 15.4800, mean_ecr: 0.0480 mean_entropies: 0.7009, took: 79.4017s
2022-10-10 13:46:08,795 [INFO] 	Process 7 - batch 44199: mean_policy_losses: -742.278, mean_net_lifetime: 3412.3734, mean_mc_travel_dist: 1142.8673, mean_rewards: 239.5072, total_rewards: 2313.9606, mean_steps: 13.4900, mean_ecr: 0.0422 mean_entropies: 1.2146, took: 64.4959s
2022-10-10 13:46:28,111 [INFO] Process 5 - epoch 29: mean_policy_losses: -192.545, mean_net_lifetime: 4478.5126, mean_mc_travel_dist: 1974.8815, mean_entropies: 1.5124, m_net_lifetime_valid: 4772.5440, took: 1866.0153s, (163.8331 / 100 batches)

2022-10-10 13:46:51,978 [INFO] 	Process 2 - batch 43699: mean_policy_losses: 17.170, mean_net_lifetime: 4660.0798, mean_mc_travel_dist: 1288.4744, mean_rewards: 260.4473, total_rewards: 3397.9643, mean_steps: 16.9800, mean_ecr: 0.0409 mean_entropies: 0.4696, took: 81.0776s
2022-10-10 13:47:02,380 [INFO] 	Process 7 - batch 44299: mean_policy_losses: -863.550, mean_net_lifetime: 2699.2285, mean_mc_travel_dist: 1043.4419, mean_rewards: 239.8114, total_rewards: 1708.4063, mean_steps: 10.7200, mean_ecr: 0.0428 mean_entropies: 1.1632, took: 53.5847s
2022-10-10 13:47:03,296 [INFO] 	Process 1 - batch 38299: mean_policy_losses: 110.686, mean_net_lifetime: 5158.3882, mean_mc_travel_dist: 1892.6081, mean_rewards: 255.9805, total_rewards: 3295.0098, mean_steps: 19.3000, mean_ecr: 0.0387 mean_entropies: 0.9047, took: 90.4594s
2022-10-10 13:47:14,350 [INFO] 	Process 4 - batch 49799: mean_policy_losses: 95.921, mean_net_lifetime: 4522.9683, mean_mc_travel_dist: 1297.9077, mean_rewards: 283.7719, total_rewards: 3250.7295, mean_steps: 14.9500, mean_ecr: 0.0479 mean_entropies: 0.6942, took: 75.5989s
2022-10-10 13:47:23,396 [INFO] 	Process 5 - batch 43599: mean_policy_losses: -550.371, mean_net_lifetime: 2996.3541, mean_mc_travel_dist: 946.9490, mean_rewards: 270.2271, total_rewards: 2103.5262, mean_steps: 10.8700, mean_ecr: 0.0305 mean_entropies: 0.6047, took: 617.3366s
2022-10-10 13:48:02,434 [INFO] 	Process 7 - batch 44399: mean_policy_losses: -783.048, mean_net_lifetime: 3077.0144, mean_mc_travel_dist: 1086.4439, mean_rewards: 243.6974, total_rewards: 2043.8094, mean_steps: 11.7100, mean_ecr: 0.0424 mean_entropies: 1.2668, took: 60.0540s
2022-10-10 13:48:14,533 [INFO] 	Process 2 - batch 43799: mean_policy_losses: 41.811, mean_net_lifetime: 4680.4096, mean_mc_travel_dist: 1310.7872, mean_rewards: 269.2772, total_rewards: 3400.6241, mean_steps: 16.4800, mean_ecr: 0.0408 mean_entropies: 0.4763, took: 82.5549s
2022-10-10 13:48:30,170 [INFO] 	Process 5 - batch 43699: mean_policy_losses: -463.987, mean_net_lifetime: 3604.2938, mean_mc_travel_dist: 1151.5876, mean_rewards: 258.8142, total_rewards: 2507.2226, mean_steps: 13.4400, mean_ecr: 0.0310 mean_entropies: 0.6276, took: 66.7731s
2022-10-10 13:48:36,034 [INFO] 	Process 1 - batch 38399: mean_policy_losses: 135.877, mean_net_lifetime: 5256.7190, mean_mc_travel_dist: 1921.3950, mean_rewards: 257.2861, total_rewards: 3363.2590, mean_steps: 19.6400, mean_ecr: 0.0386 mean_entropies: 0.9472, took: 92.7372s
2022-10-10 13:48:36,488 [INFO] 	Process 4 - batch 49899: mean_policy_losses: 117.665, mean_net_lifetime: 4763.6722, mean_mc_travel_dist: 1355.6876, mean_rewards: 273.8443, total_rewards: 3436.1799, mean_steps: 16.4200, mean_ecr: 0.0474 mean_entropies: 0.6979, took: 82.1384s
2022-10-10 13:49:04,619 [INFO] 	Process 7 - batch 44499: mean_policy_losses: -862.830, mean_net_lifetime: 3012.0199, mean_mc_travel_dist: 1090.0603, mean_rewards: 239.3408, total_rewards: 1970.9948, mean_steps: 11.8300, mean_ecr: 0.0428 mean_entropies: 1.2904, took: 62.1852s
2022-10-10 13:49:37,889 [INFO] 	Process 2 - batch 43899: mean_policy_losses: 24.605, mean_net_lifetime: 4698.7362, mean_mc_travel_dist: 1296.4662, mean_rewards: 272.3511, total_rewards: 3427.8826, mean_steps: 16.3400, mean_ecr: 0.0408 mean_entropies: 0.5022, took: 83.3557s
2022-10-10 13:49:49,244 [INFO] 	Process 5 - batch 43799: mean_policy_losses: -336.429, mean_net_lifetime: 4418.8266, mean_mc_travel_dist: 1457.3035, mean_rewards: 254.7954, total_rewards: 3026.7387, mean_steps: 16.5600, mean_ecr: 0.0314 mean_entropies: 0.6573, took: 79.0749s
2022-10-10 13:49:52,253 [INFO] 	Process 4 - batch 49999: mean_policy_losses: 15.552, mean_net_lifetime: 4323.6563, mean_mc_travel_dist: 1222.1761, mean_rewards: 271.8423, total_rewards: 3128.0070, mean_steps: 14.8900, mean_ecr: 0.0487 mean_entropies: 0.7623, took: 75.7650s
2022-10-10 13:50:05,405 [INFO] 	Process 7 - batch 44599: mean_policy_losses: -848.272, mean_net_lifetime: 3038.8423, mean_mc_travel_dist: 1089.9386, mean_rewards: 240.5799, total_rewards: 1989.1810, mean_steps: 11.9700, mean_ecr: 0.0427 mean_entropies: 1.2821, took: 60.7856s
2022-10-10 13:50:12,994 [INFO] 	Process 1 - batch 38499: mean_policy_losses: 149.303, mean_net_lifetime: 5297.4031, mean_mc_travel_dist: 1837.5149, mean_rewards: 249.3303, total_rewards: 3493.6965, mean_steps: 20.4300, mean_ecr: 0.0390 mean_entropies: 1.0205, took: 96.9596s
2022-10-10 13:50:58,860 [INFO] 	Process 2 - batch 43999: mean_policy_losses: 24.250, mean_net_lifetime: 4698.3864, mean_mc_travel_dist: 1306.7807, mean_rewards: 275.2331, total_rewards: 3414.0899, mean_steps: 16.1400, mean_ecr: 0.0408 mean_entropies: 0.4985, took: 80.9710s
2022-10-10 13:51:05,123 [INFO] 	Process 5 - batch 43899: mean_policy_losses: -444.349, mean_net_lifetime: 4051.0460, mean_mc_travel_dist: 1316.1387, mean_rewards: 256.2312, total_rewards: 2790.2490, mean_steps: 15.4100, mean_ecr: 0.0311 mean_entropies: 0.7006, took: 75.8794s
2022-10-10 13:51:14,122 [INFO] 	Process 7 - batch 44699: mean_policy_losses: -633.768, mean_net_lifetime: 3475.2797, mean_mc_travel_dist: 1186.6773, mean_rewards: 231.8881, total_rewards: 2340.9511, mean_steps: 14.0600, mean_ecr: 0.0421 mean_entropies: 1.2578, took: 68.7178s
2022-10-10 13:51:14,175 [INFO] 	Process 4 - batch 50099: mean_policy_losses: 49.728, mean_net_lifetime: 4520.6840, mean_mc_travel_dist: 1294.4841, mean_rewards: 269.8654, total_rewards: 3257.8153, mean_steps: 15.8000, mean_ecr: 0.0481 mean_entropies: 0.7275, took: 81.9212s
2022-10-10 13:51:51,164 [INFO] 	Process 1 - batch 38599: mean_policy_losses: 82.626, mean_net_lifetime: 5217.5580, mean_mc_travel_dist: 1820.1117, mean_rewards: 240.7955, total_rewards: 3430.5106, mean_steps: 21.0000, mean_ecr: 0.0388 mean_entropies: 0.9622, took: 98.1712s
2022-10-10 13:52:18,358 [INFO] 	Process 2 - batch 44099: mean_policy_losses: 7.600, mean_net_lifetime: 4705.1043, mean_mc_travel_dist: 1313.1302, mean_rewards: 277.3140, total_rewards: 3418.4064, mean_steps: 16.0400, mean_ecr: 0.0408 mean_entropies: 0.4982, took: 79.4979s
2022-10-10 13:52:26,817 [INFO] 	Process 7 - batch 44799: mean_policy_losses: -623.452, mean_net_lifetime: 3722.7913, mean_mc_travel_dist: 1231.7875, mean_rewards: 241.8237, total_rewards: 2528.8972, mean_steps: 14.6500, mean_ecr: 0.0420 mean_entropies: 1.2444, took: 72.6941s
2022-10-10 13:52:29,296 [INFO] 	Process 5 - batch 43999: mean_policy_losses: -419.847, mean_net_lifetime: 4510.7050, mean_mc_travel_dist: 1505.5731, mean_rewards: 250.4367, total_rewards: 3072.2989, mean_steps: 17.4900, mean_ecr: 0.0308 mean_entropies: 0.7146, took: 84.1725s
2022-10-10 13:52:39,759 [INFO] 	Process 4 - batch 50199: mean_policy_losses: 62.507, mean_net_lifetime: 4714.8912, mean_mc_travel_dist: 1350.0468, mean_rewards: 270.6208, total_rewards: 3396.7731, mean_steps: 16.5100, mean_ecr: 0.0476 mean_entropies: 0.7232, took: 85.5840s
2022-10-10 13:53:30,822 [INFO] 	Process 1 - batch 38699: mean_policy_losses: 110.707, mean_net_lifetime: 5357.5101, mean_mc_travel_dist: 1866.4395, mean_rewards: 244.3666, total_rewards: 3520.5203, mean_steps: 21.1200, mean_ecr: 0.0387 mean_entropies: 0.9963, took: 99.6579s
2022-10-10 13:53:40,396 [INFO] 	Process 2 - batch 44199: mean_policy_losses: 0.010, mean_net_lifetime: 4712.1280, mean_mc_travel_dist: 1321.6723, mean_rewards: 276.0042, total_rewards: 3411.6079, mean_steps: 16.1600, mean_ecr: 0.0408 mean_entropies: 0.5163, took: 82.0385s
2022-10-10 13:53:44,577 [INFO] 	Process 7 - batch 44899: mean_policy_losses: -568.824, mean_net_lifetime: 3875.6866, mean_mc_travel_dist: 1402.2037, mean_rewards: 229.6011, total_rewards: 2528.2377, mean_steps: 16.3900, mean_ecr: 0.0419 mean_entropies: 1.2279, took: 77.7605s
2022-10-10 13:53:56,399 [INFO] 	Process 5 - batch 44099: mean_policy_losses: -374.721, mean_net_lifetime: 4704.1818, mean_mc_travel_dist: 1569.1840, mean_rewards: 255.3897, total_rewards: 3186.9173, mean_steps: 18.1100, mean_ecr: 0.0309 mean_entropies: 0.7049, took: 87.1027s
2022-10-10 13:53:59,643 [INFO] 	Process 4 - batch 50299: mean_policy_losses: 33.317, mean_net_lifetime: 4588.0971, mean_mc_travel_dist: 1304.4793, mean_rewards: 276.6620, total_rewards: 3313.6974, mean_steps: 15.7100, mean_ecr: 0.0482 mean_entropies: 0.7234, took: 79.8847s
2022-10-10 13:54:11,085 [INFO] Process 3 - epoch 30: mean_policy_losses: 93.226, mean_net_lifetime: 4096.5762, mean_mc_travel_dist: 1419.9974, mean_entropies: 1.1565, m_net_lifetime_valid: 4097.5709, took: 1716.4630s, (159.3833 / 100 batches)

2022-10-10 13:54:43,937 [INFO] Process 6 - epoch 42: mean_policy_losses: -262.707, mean_net_lifetime: 2672.1444, mean_mc_travel_dist: 952.0047, mean_entropies: 0.8434, m_net_lifetime_valid: 4030.9404, took: 1367.5459s, (113.9681 / 100 batches)

2022-10-10 13:54:51,468 [INFO] 	Process 7 - batch 44999: mean_policy_losses: -752.467, mean_net_lifetime: 3462.1000, mean_mc_travel_dist: 1220.2170, mean_rewards: 249.4467, total_rewards: 2286.1656, mean_steps: 13.1700, mean_ecr: 0.0422 mean_entropies: 1.2123, took: 66.8910s
2022-10-10 13:55:00,099 [INFO] 	Process 2 - batch 44299: mean_policy_losses: 25.563, mean_net_lifetime: 4713.0641, mean_mc_travel_dist: 1307.5254, mean_rewards: 287.3858, total_rewards: 3428.4913, mean_steps: 15.4700, mean_ecr: 0.0408 mean_entropies: 0.5640, took: 79.7026s
2022-10-10 13:55:04,970 [INFO] 	Process 1 - batch 38799: mean_policy_losses: 45.467, mean_net_lifetime: 5039.2327, mean_mc_travel_dist: 1789.3833, mean_rewards: 248.0101, total_rewards: 3273.3522, mean_steps: 19.4700, mean_ecr: 0.0391 mean_entropies: 0.9586, took: 94.1482s
2022-10-10 13:55:16,771 [INFO] 	Process 5 - batch 44199: mean_policy_losses: -477.110, mean_net_lifetime: 4388.9534, mean_mc_travel_dist: 1450.3422, mean_rewards: 260.8422, total_rewards: 2985.4398, mean_steps: 16.3200, mean_ecr: 0.0311 mean_entropies: 0.7406, took: 80.3731s
2022-10-10 13:55:22,052 [INFO] 	Process 4 - batch 50399: mean_policy_losses: 26.599, mean_net_lifetime: 4544.2917, mean_mc_travel_dist: 1289.5597, mean_rewards: 269.6854, total_rewards: 3285.6470, mean_steps: 15.8500, mean_ecr: 0.0481 mean_entropies: 0.7325, took: 82.4089s
2022-10-10 13:55:26,790 [INFO] 	Process 3 - batch 45099: mean_policy_losses: 18.478, mean_net_lifetime: 4279.2847, mean_mc_travel_dist: 1238.5723, mean_rewards: 277.9047, total_rewards: 3066.7863, mean_steps: 14.4800, mean_ecr: 0.0483 mean_entropies: 0.6058, took: 649.4509s
2022-10-10 13:55:36,926 [INFO] 	Process 6 - batch 63099: mean_policy_losses: -213.743, mean_net_lifetime: 3389.7167, mean_mc_travel_dist: 915.1864, mean_rewards: 323.1211, total_rewards: 2491.1238, mean_steps: 9.4800, mean_ecr: 0.0561 mean_entropies: 0.2146, took: 627.8020s
2022-10-10 13:56:23,173 [INFO] 	Process 2 - batch 44399: mean_policy_losses: -2.647, mean_net_lifetime: 4706.9103, mean_mc_travel_dist: 1313.2711, mean_rewards: 273.9893, total_rewards: 3417.1495, mean_steps: 16.2800, mean_ecr: 0.0409 mean_entropies: 0.4905, took: 83.0740s
2022-10-10 13:56:29,731 [INFO] 	Process 6 - batch 63199: mean_policy_losses: -178.787, mean_net_lifetime: 3486.3603, mean_mc_travel_dist: 938.8501, mean_rewards: 328.0593, total_rewards: 2562.3571, mean_steps: 9.6600, mean_ecr: 0.0559 mean_entropies: 0.2012, took: 52.8053s
2022-10-10 13:56:39,933 [INFO] 	Process 5 - batch 44299: mean_policy_losses: -447.732, mean_net_lifetime: 4298.4617, mean_mc_travel_dist: 1426.8708, mean_rewards: 247.7869, total_rewards: 2929.4135, mean_steps: 16.8800, mean_ecr: 0.0308 mean_entropies: 0.6942, took: 83.1615s
2022-10-10 13:56:40,292 [INFO] 	Process 1 - batch 38899: mean_policy_losses: 24.283, mean_net_lifetime: 5024.3041, mean_mc_travel_dist: 1783.4674, mean_rewards: 246.4889, total_rewards: 3268.8869, mean_steps: 19.6100, mean_ecr: 0.0391 mean_entropies: 0.9635, took: 95.3219s
2022-10-10 13:56:44,986 [INFO] 	Process 3 - batch 45199: mean_policy_losses: 26.924, mean_net_lifetime: 4395.5847, mean_mc_travel_dist: 1227.8075, mean_rewards: 275.2070, total_rewards: 3194.9074, mean_steps: 15.0300, mean_ecr: 0.0486 mean_entropies: 0.5957, took: 78.1952s
2022-10-10 13:56:48,938 [INFO] 	Process 4 - batch 50499: mean_policy_losses: 90.198, mean_net_lifetime: 4941.7921, mean_mc_travel_dist: 1401.3822, mean_rewards: 276.4899, total_rewards: 3564.5877, mean_steps: 16.9400, mean_ecr: 0.0472 mean_entropies: 0.6978, took: 86.8864s
2022-10-10 13:57:23,340 [INFO] 	Process 6 - batch 63299: mean_policy_losses: -229.103, mean_net_lifetime: 3463.2674, mean_mc_travel_dist: 933.2946, mean_rewards: 323.1145, total_rewards: 2544.3957, mean_steps: 9.6900, mean_ecr: 0.0562 mean_entropies: 0.1985, took: 53.6082s
2022-10-10 13:57:46,862 [INFO] 	Process 2 - batch 44499: mean_policy_losses: -3.892, mean_net_lifetime: 4703.4342, mean_mc_travel_dist: 1313.2890, mean_rewards: 275.2556, total_rewards: 3412.9519, mean_steps: 16.1500, mean_ecr: 0.0408 mean_entropies: 0.4848, took: 83.6892s
2022-10-10 13:58:03,880 [INFO] 	Process 3 - batch 45299: mean_policy_losses: 32.144, mean_net_lifetime: 4431.0354, mean_mc_travel_dist: 1215.6220, mean_rewards: 274.6906, total_rewards: 3243.3398, mean_steps: 15.1800, mean_ecr: 0.0485 mean_entropies: 0.5858, took: 78.8946s
2022-10-10 13:58:08,555 [INFO] 	Process 5 - batch 44399: mean_policy_losses: -446.016, mean_net_lifetime: 4364.8726, mean_mc_travel_dist: 1485.7645, mean_rewards: 240.5460, total_rewards: 2939.5813, mean_steps: 17.8000, mean_ecr: 0.0305 mean_entropies: 0.6608, took: 88.6217s
2022-10-10 13:58:13,693 [INFO] 	Process 4 - batch 50599: mean_policy_losses: 80.605, mean_net_lifetime: 4959.3510, mean_mc_travel_dist: 1429.9184, mean_rewards: 283.6131, total_rewards: 3559.4909, mean_steps: 16.5300, mean_ecr: 0.0472 mean_entropies: 0.6555, took: 84.7542s
2022-10-10 13:58:16,632 [INFO] 	Process 1 - batch 38999: mean_policy_losses: 21.877, mean_net_lifetime: 5235.6402, mean_mc_travel_dist: 1893.2674, mean_rewards: 254.5169, total_rewards: 3367.4376, mean_steps: 19.8200, mean_ecr: 0.0387 mean_entropies: 0.9230, took: 96.3399s
2022-10-10 13:58:16,810 [INFO] 	Process 6 - batch 63399: mean_policy_losses: -161.676, mean_net_lifetime: 3495.6488, mean_mc_travel_dist: 935.8845, mean_rewards: 327.9598, total_rewards: 2572.1208, mean_steps: 9.6800, mean_ecr: 0.0558 mean_entropies: 0.2064, took: 53.4701s
2022-10-10 13:59:05,183 [INFO] 	Process 2 - batch 44599: mean_policy_losses: 0.159, mean_net_lifetime: 4713.6667, mean_mc_travel_dist: 1313.6998, mean_rewards: 283.1367, total_rewards: 3421.6452, mean_steps: 15.7200, mean_ecr: 0.0407 mean_entropies: 0.5009, took: 78.3208s
2022-10-10 13:59:07,995 [INFO] 	Process 6 - batch 63499: mean_policy_losses: -275.227, mean_net_lifetime: 3426.3694, mean_mc_travel_dist: 923.6303, mean_rewards: 328.4171, total_rewards: 2516.2611, mean_steps: 9.4600, mean_ecr: 0.0560 mean_entropies: 0.2112, took: 51.1851s
2022-10-10 13:59:18,168 [INFO] 	Process 3 - batch 45399: mean_policy_losses: 32.318, mean_net_lifetime: 4433.2831, mean_mc_travel_dist: 1242.0332, mean_rewards: 282.1346, total_rewards: 3220.2693, mean_steps: 14.7500, mean_ecr: 0.0484 mean_entropies: 0.5793, took: 74.2889s
2022-10-10 13:59:26,745 [INFO] 	Process 5 - batch 44499: mean_policy_losses: -561.663, mean_net_lifetime: 4158.3962, mean_mc_travel_dist: 1367.7784, mean_rewards: 256.4792, total_rewards: 2845.2969, mean_steps: 16.0600, mean_ecr: 0.0308 mean_entropies: 0.7200, took: 78.1900s
2022-10-10 13:59:37,292 [INFO] 	Process 4 - batch 50699: mean_policy_losses: 66.534, mean_net_lifetime: 4898.1750, mean_mc_travel_dist: 1409.9680, mean_rewards: 282.6979, total_rewards: 3514.9512, mean_steps: 16.3800, mean_ecr: 0.0472 mean_entropies: 0.6944, took: 83.5989s
2022-10-10 14:00:02,630 [INFO] 	Process 6 - batch 63599: mean_policy_losses: -129.191, mean_net_lifetime: 3631.8899, mean_mc_travel_dist: 968.8804, mean_rewards: 321.2267, total_rewards: 2677.4788, mean_steps: 10.3100, mean_ecr: 0.0558 mean_entropies: 0.1973, took: 54.6350s
2022-10-10 14:00:25,942 [INFO] 	Process 2 - batch 44699: mean_policy_losses: -1.910, mean_net_lifetime: 4707.9730, mean_mc_travel_dist: 1323.0644, mean_rewards: 272.4230, total_rewards: 3416.5503, mean_steps: 16.3800, mean_ecr: 0.0407 mean_entropies: 0.4862, took: 80.7591s
2022-10-10 14:00:34,683 [INFO] 	Process 3 - batch 45499: mean_policy_losses: -1.095, mean_net_lifetime: 4283.2386, mean_mc_travel_dist: 1186.1395, mean_rewards: 262.2624, total_rewards: 3123.9253, mean_steps: 15.3800, mean_ecr: 0.0488 mean_entropies: 0.5559, took: 76.5143s
2022-10-10 14:00:44,144 [INFO] 	Process 5 - batch 44599: mean_policy_losses: -485.109, mean_net_lifetime: 3941.5554, mean_mc_travel_dist: 1289.7019, mean_rewards: 239.4400, total_rewards: 2709.6681, mean_steps: 16.0500, mean_ecr: 0.0307 mean_entropies: 0.6481, took: 77.3997s
2022-10-10 14:00:59,306 [INFO] 	Process 6 - batch 63699: mean_policy_losses: -94.819, mean_net_lifetime: 3748.8693, mean_mc_travel_dist: 1001.8191, mean_rewards: 317.4455, total_rewards: 2771.1693, mean_steps: 10.8200, mean_ecr: 0.0557 mean_entropies: 0.1901, took: 56.6769s
2022-10-10 14:01:00,416 [INFO] 	Process 4 - batch 50799: mean_policy_losses: 89.403, mean_net_lifetime: 5033.8950, mean_mc_travel_dist: 1430.1973, mean_rewards: 285.3360, total_rewards: 3633.7369, mean_steps: 16.7200, mean_ecr: 0.0469 mean_entropies: 0.6564, took: 83.1243s
2022-10-10 14:01:46,831 [INFO] 	Process 2 - batch 44799: mean_policy_losses: -4.835, mean_net_lifetime: 4689.5361, mean_mc_travel_dist: 1298.5397, mean_rewards: 273.5878, total_rewards: 3419.0643, mean_steps: 16.2300, mean_ecr: 0.0408 mean_entropies: 0.4503, took: 80.8887s
2022-10-10 14:01:51,309 [INFO] 	Process 3 - batch 45599: mean_policy_losses: 19.306, mean_net_lifetime: 4432.1582, mean_mc_travel_dist: 1208.7193, mean_rewards: 267.5248, total_rewards: 3249.0482, mean_steps: 15.5900, mean_ecr: 0.0487 mean_entropies: 0.5468, took: 76.6257s
2022-10-10 14:01:53,331 [INFO] 	Process 6 - batch 63799: mean_policy_losses: -177.036, mean_net_lifetime: 3559.5729, mean_mc_travel_dist: 954.8795, mean_rewards: 320.0044, total_rewards: 2623.1584, mean_steps: 10.1700, mean_ecr: 0.0559 mean_entropies: 0.1922, took: 54.0249s
2022-10-10 14:02:11,254 [INFO] 	Process 5 - batch 44699: mean_policy_losses: -357.808, mean_net_lifetime: 4554.3136, mean_mc_travel_dist: 1537.1158, mean_rewards: 243.9993, total_rewards: 3081.1928, mean_steps: 18.2800, mean_ecr: 0.0308 mean_entropies: 0.6480, took: 87.1100s
2022-10-10 14:02:24,401 [INFO] 	Process 4 - batch 50899: mean_policy_losses: 59.920, mean_net_lifetime: 4882.7530, mean_mc_travel_dist: 1393.8357, mean_rewards: 277.1760, total_rewards: 3514.5458, mean_steps: 16.6400, mean_ecr: 0.0472 mean_entropies: 0.6919, took: 83.9850s
2022-10-10 14:02:46,744 [INFO] 	Process 6 - batch 63899: mean_policy_losses: -126.598, mean_net_lifetime: 3635.0446, mean_mc_travel_dist: 971.8485, mean_rewards: 326.4990, total_rewards: 2682.1134, mean_steps: 10.1500, mean_ecr: 0.0559 mean_entropies: 0.2026, took: 53.4126s
2022-10-10 14:03:07,071 [INFO] 	Process 2 - batch 44899: mean_policy_losses: 2.524, mean_net_lifetime: 4709.5248, mean_mc_travel_dist: 1322.4115, mean_rewards: 279.8418, total_rewards: 3414.4122, mean_steps: 15.9200, mean_ecr: 0.0407 mean_entropies: 0.4852, took: 80.2401s
2022-10-10 14:03:07,465 [INFO] 	Process 3 - batch 45699: mean_policy_losses: 29.092, mean_net_lifetime: 4461.5850, mean_mc_travel_dist: 1236.9563, mean_rewards: 272.1753, total_rewards: 3257.2770, mean_steps: 15.4400, mean_ecr: 0.0484 mean_entropies: 0.5537, took: 76.1559s
2022-10-10 14:03:36,819 [INFO] 	Process 6 - batch 63999: mean_policy_losses: -169.347, mean_net_lifetime: 3431.6340, mean_mc_travel_dist: 924.7888, mean_rewards: 332.0150, total_rewards: 2523.4922, mean_steps: 9.3400, mean_ecr: 0.0560 mean_entropies: 0.2255, took: 50.0750s
2022-10-10 14:03:38,164 [INFO] 	Process 5 - batch 44799: mean_policy_losses: -343.891, mean_net_lifetime: 4720.6589, mean_mc_travel_dist: 1569.4019, mean_rewards: 252.6205, total_rewards: 3197.7994, mean_steps: 18.2200, mean_ecr: 0.0308 mean_entropies: 0.6917, took: 86.9097s
2022-10-10 14:03:48,837 [INFO] 	Process 4 - batch 50999: mean_policy_losses: 46.529, mean_net_lifetime: 4845.7276, mean_mc_travel_dist: 1386.4834, mean_rewards: 276.7315, total_rewards: 3490.6903, mean_steps: 16.5400, mean_ecr: 0.0473 mean_entropies: 0.7037, took: 84.4359s
2022-10-10 14:04:21,329 [INFO] 	Process 3 - batch 45799: mean_policy_losses: 43.435, mean_net_lifetime: 4574.8558, mean_mc_travel_dist: 1257.7221, mean_rewards: 282.9141, total_rewards: 3339.6055, mean_steps: 15.2200, mean_ecr: 0.0484 mean_entropies: 0.5708, took: 73.8643s
2022-10-10 14:04:24,757 [INFO] 	Process 2 - batch 44999: mean_policy_losses: 2.135, mean_net_lifetime: 4718.6722, mean_mc_travel_dist: 1327.1390, mean_rewards: 280.6653, total_rewards: 3413.2651, mean_steps: 15.8900, mean_ecr: 0.0406 mean_entropies: 0.5142, took: 77.6857s
2022-10-10 14:04:27,282 [INFO] 	Process 6 - batch 64099: mean_policy_losses: -116.282, mean_net_lifetime: 3579.4695, mean_mc_travel_dist: 964.9438, mean_rewards: 330.4072, total_rewards: 2630.8409, mean_steps: 9.8800, mean_ecr: 0.0558 mean_entropies: 0.2084, took: 50.4625s
2022-10-10 14:04:58,023 [INFO] 	Process 5 - batch 44899: mean_policy_losses: -335.768, mean_net_lifetime: 4620.8740, mean_mc_travel_dist: 1542.3238, mean_rewards: 257.8956, total_rewards: 3138.1775, mean_steps: 17.5100, mean_ecr: 0.0308 mean_entropies: 0.6793, took: 79.8586s
2022-10-10 14:05:08,135 [INFO] Process 7 - epoch 30: mean_policy_losses: -229.180, mean_net_lifetime: 3964.7404, mean_mc_travel_dist: 1609.2649, mean_entropies: 1.7742, m_net_lifetime_valid: 4568.3223, took: 1622.7988s, (160.7463 / 100 batches)

2022-10-10 14:05:18,292 [INFO] 	Process 6 - batch 64199: mean_policy_losses: -135.343, mean_net_lifetime: 3647.0806, mean_mc_travel_dist: 976.3935, mean_rewards: 319.8027, total_rewards: 2695.3064, mean_steps: 10.4400, mean_ecr: 0.0558 mean_entropies: 0.2066, took: 51.0094s
2022-10-10 14:05:34,827 [INFO] 	Process 3 - batch 45899: mean_policy_losses: 38.691, mean_net_lifetime: 4422.8943, mean_mc_travel_dist: 1207.5021, mean_rewards: 266.3700, total_rewards: 3237.2147, mean_steps: 15.6300, mean_ecr: 0.0487 mean_entropies: 0.5754, took: 73.4980s
2022-10-10 14:06:13,186 [INFO] 	Process 6 - batch 64299: mean_policy_losses: -44.548, mean_net_lifetime: 3805.8423, mean_mc_travel_dist: 1021.0590, mean_rewards: 322.8878, total_rewards: 2807.6534, mean_steps: 10.8100, mean_ecr: 0.0557 mean_entropies: 0.1928, took: 54.8935s
2022-10-10 14:06:24,009 [INFO] 	Process 5 - batch 44999: mean_policy_losses: -282.839, mean_net_lifetime: 4974.2512, mean_mc_travel_dist: 1686.1987, mean_rewards: 254.4243, total_rewards: 3344.5700, mean_steps: 18.8800, mean_ecr: 0.0311 mean_entropies: 0.6762, took: 85.9866s
2022-10-10 14:06:32,433 [INFO] 	Process 7 - batch 45099: mean_policy_losses: -468.454, mean_net_lifetime: 4412.7728, mean_mc_travel_dist: 1567.2295, mean_rewards: 227.8249, total_rewards: 2891.6981, mean_steps: 18.5700, mean_ecr: 0.0415 mean_entropies: 1.2737, took: 700.9654s
2022-10-10 14:06:40,281 [INFO] Process 1 - epoch 26: mean_policy_losses: 46.382, mean_net_lifetime: 4742.9750, mean_mc_travel_dist: 2067.5966, mean_entropies: 1.3774, m_net_lifetime_valid: 4370.6041, took: 1946.5410s, (185.9382 / 100 batches)

2022-10-10 14:06:49,859 [INFO] 	Process 3 - batch 45999: mean_policy_losses: 56.768, mean_net_lifetime: 4526.8791, mean_mc_travel_dist: 1244.0079, mean_rewards: 270.9132, total_rewards: 3311.7204, mean_steps: 15.7500, mean_ecr: 0.0484 mean_entropies: 0.5696, took: 75.0317s
2022-10-10 14:07:04,447 [INFO] 	Process 6 - batch 64399: mean_policy_losses: -119.953, mean_net_lifetime: 3594.8536, mean_mc_travel_dist: 964.8119, mean_rewards: 330.2990, total_rewards: 2645.3074, mean_steps: 9.9500, mean_ecr: 0.0559 mean_entropies: 0.1776, took: 51.2619s
2022-10-10 14:07:52,994 [INFO] 	Process 7 - batch 45199: mean_policy_losses: -483.189, mean_net_lifetime: 4332.3985, mean_mc_travel_dist: 1493.2862, mean_rewards: 232.9958, total_rewards: 2884.5912, mean_steps: 17.6000, mean_ecr: 0.0414 mean_entropies: 1.2754, took: 80.5601s
2022-10-10 14:07:58,957 [INFO] 	Process 6 - batch 64499: mean_policy_losses: -148.439, mean_net_lifetime: 3654.2688, mean_mc_travel_dist: 975.3924, mean_rewards: 314.7005, total_rewards: 2703.5002, mean_steps: 10.6500, mean_ecr: 0.0558 mean_entropies: 0.1847, took: 54.5105s
2022-10-10 14:08:06,298 [INFO] 	Process 3 - batch 46099: mean_policy_losses: 14.265, mean_net_lifetime: 4336.4170, mean_mc_travel_dist: 1181.8298, mean_rewards: 258.9003, total_rewards: 3179.2169, mean_steps: 15.7700, mean_ecr: 0.0489 mean_entropies: 0.5487, took: 76.4394s
2022-10-10 14:08:06,361 [INFO] 	Process 1 - batch 39099: mean_policy_losses: -0.893, mean_net_lifetime: 5014.9911, mean_mc_travel_dist: 1852.8310, mean_rewards: 256.8196, total_rewards: 3190.9871, mean_steps: 18.6400, mean_ecr: 0.0388 mean_entropies: 0.8553, took: 589.7295s
2022-10-10 14:09:19,238 [INFO] 	Process 3 - batch 46199: mean_policy_losses: 1.861, mean_net_lifetime: 4530.4305, mean_mc_travel_dist: 1221.9149, mean_rewards: 274.5924, total_rewards: 3344.5952, mean_steps: 15.5600, mean_ecr: 0.0484 mean_entropies: 0.5206, took: 72.9403s
2022-10-10 14:09:25,682 [INFO] 	Process 7 - batch 45299: mean_policy_losses: -420.270, mean_net_lifetime: 4873.2587, mean_mc_travel_dist: 1700.9490, mean_rewards: 222.6209, total_rewards: 3210.9749, mean_steps: 21.1800, mean_ecr: 0.0408 mean_entropies: 1.2622, took: 92.6889s
2022-10-10 14:09:34,175 [INFO] 	Process 1 - batch 39199: mean_policy_losses: -52.845, mean_net_lifetime: 5003.0545, mean_mc_travel_dist: 1834.8912, mean_rewards: 247.7714, total_rewards: 3194.0461, mean_steps: 19.5300, mean_ecr: 0.0388 mean_entropies: 0.8565, took: 87.8137s
2022-10-10 14:10:31,305 [INFO] 	Process 3 - batch 46299: mean_policy_losses: 19.519, mean_net_lifetime: 4553.1789, mean_mc_travel_dist: 1258.8018, mean_rewards: 278.8911, total_rewards: 3316.9247, mean_steps: 15.3800, mean_ecr: 0.0484 mean_entropies: 0.5518, took: 72.0669s
2022-10-10 14:10:55,918 [INFO] 	Process 7 - batch 45399: mean_policy_losses: -499.972, mean_net_lifetime: 4588.7665, mean_mc_travel_dist: 1492.1385, mean_rewards: 219.5463, total_rewards: 3131.0809, mean_steps: 20.3300, mean_ecr: 0.0414 mean_entropies: 1.2538, took: 90.2354s
2022-10-10 14:11:01,103 [INFO] 	Process 1 - batch 39299: mean_policy_losses: -20.129, mean_net_lifetime: 5106.4719, mean_mc_travel_dist: 1888.5001, mean_rewards: 250.8908, total_rewards: 3246.4932, mean_steps: 19.7700, mean_ecr: 0.0386 mean_entropies: 0.7915, took: 86.9282s
2022-10-10 14:11:44,366 [INFO] 	Process 3 - batch 46399: mean_policy_losses: 14.081, mean_net_lifetime: 4661.1964, mean_mc_travel_dist: 1251.4684, mean_rewards: 276.5595, total_rewards: 3430.8293, mean_steps: 15.9100, mean_ecr: 0.0484 mean_entropies: 0.5445, took: 73.0609s
2022-10-10 14:11:59,013 [INFO] Process 4 - epoch 34: mean_policy_losses: 87.286, mean_net_lifetime: 3764.2471, mean_mc_travel_dist: 1294.8623, mean_entropies: 1.4035, m_net_lifetime_valid: 4598.4840, took: 1716.3778s, (142.9235 / 100 batches)

2022-10-10 14:12:21,253 [INFO] 	Process 7 - batch 45499: mean_policy_losses: -523.249, mean_net_lifetime: 4272.0107, mean_mc_travel_dist: 1355.0024, mean_rewards: 222.5542, total_rewards: 2959.7396, mean_steps: 18.6100, mean_ecr: 0.0417 mean_entropies: 1.2519, took: 85.3348s
2022-10-10 14:12:25,000 [INFO] 	Process 1 - batch 39399: mean_policy_losses: 7.176, mean_net_lifetime: 5172.4055, mean_mc_travel_dist: 1900.3820, mean_rewards: 262.7981, total_rewards: 3300.3601, mean_steps: 18.8400, mean_ecr: 0.0386 mean_entropies: 0.8313, took: 83.8971s
2022-10-10 14:12:58,808 [INFO] 	Process 3 - batch 46499: mean_policy_losses: 40.882, mean_net_lifetime: 4465.6454, mean_mc_travel_dist: 1213.7033, mean_rewards: 268.0127, total_rewards: 3280.0034, mean_steps: 15.6900, mean_ecr: 0.0488 mean_entropies: 0.5615, took: 74.4420s
2022-10-10 14:13:10,176 [INFO] 	Process 4 - batch 51099: mean_policy_losses: -83.124, mean_net_lifetime: 3695.9309, mean_mc_travel_dist: 1077.0979, mean_rewards: 241.2932, total_rewards: 2653.7274, mean_steps: 14.4000, mean_ecr: 0.0499 mean_entropies: 0.8425, took: 561.3390s
2022-10-10 14:13:15,014 [INFO] Process 2 - epoch 30: mean_policy_losses: 10.163, mean_net_lifetime: 4238.7192, mean_mc_travel_dist: 1605.2923, mean_entropies: 1.1837, m_net_lifetime_valid: 4464.9579, took: 1752.1244s, (162.0178 / 100 batches)

2022-10-10 14:13:51,502 [INFO] 	Process 7 - batch 45599: mean_policy_losses: -550.718, mean_net_lifetime: 4281.4002, mean_mc_travel_dist: 1515.6520, mean_rewards: 218.5103, total_rewards: 2810.4252, mean_steps: 19.6900, mean_ecr: 0.0416 mean_entropies: 1.2725, took: 90.2490s
2022-10-10 14:13:54,589 [INFO] 	Process 1 - batch 39499: mean_policy_losses: 36.081, mean_net_lifetime: 5194.9460, mean_mc_travel_dist: 1868.0443, mean_rewards: 252.2095, total_rewards: 3358.9872, mean_steps: 19.9100, mean_ecr: 0.0387 mean_entropies: 0.9251, took: 89.5888s
2022-10-10 14:14:33,057 [INFO] 	Process 2 - batch 45099: mean_policy_losses: -12.048, mean_net_lifetime: 4715.2936, mean_mc_travel_dist: 1324.8670, mean_rewards: 275.9193, total_rewards: 3413.7893, mean_steps: 16.1800, mean_ecr: 0.0407 mean_entropies: 0.4770, took: 608.3007s
2022-10-10 14:14:35,063 [INFO] 	Process 4 - batch 51199: mean_policy_losses: 85.582, mean_net_lifetime: 5028.7136, mean_mc_travel_dist: 1450.2991, mean_rewards: 273.8384, total_rewards: 3606.7436, mean_steps: 17.4900, mean_ecr: 0.0468 mean_entropies: 0.7032, took: 84.8875s
2022-10-10 14:15:15,884 [INFO] 	Process 7 - batch 45699: mean_policy_losses: -704.591, mean_net_lifetime: 4009.7208, mean_mc_travel_dist: 1616.7463, mean_rewards: 218.9155, total_rewards: 2442.6183, mean_steps: 18.4100, mean_ecr: 0.0416 mean_entropies: 1.2376, took: 84.3821s
2022-10-10 14:15:28,041 [INFO] 	Process 1 - batch 39599: mean_policy_losses: 31.496, mean_net_lifetime: 5244.1570, mean_mc_travel_dist: 1855.3320, mean_rewards: 250.6235, total_rewards: 3405.8584, mean_steps: 20.3000, mean_ecr: 0.0387 mean_entropies: 0.9651, took: 93.4520s
2022-10-10 14:15:33,032 [INFO] Process 5 - epoch 30: mean_policy_losses: -200.188, mean_net_lifetime: 4472.1349, mean_mc_travel_dist: 1956.3904, mean_entropies: 1.4846, m_net_lifetime_valid: 4576.2291, took: 1744.9181s, (162.2820 / 100 batches)

2022-10-10 14:15:52,665 [INFO] 	Process 2 - batch 45199: mean_policy_losses: -9.803, mean_net_lifetime: 4706.4311, mean_mc_travel_dist: 1313.0455, mean_rewards: 277.8011, total_rewards: 3417.0012, mean_steps: 16.0200, mean_ecr: 0.0408 mean_entropies: 0.4841, took: 79.6080s
2022-10-10 14:15:56,748 [INFO] 	Process 4 - batch 51299: mean_policy_losses: 91.338, mean_net_lifetime: 4936.4822, mean_mc_travel_dist: 1395.6435, mean_rewards: 284.4020, total_rewards: 3574.1311, mean_steps: 16.5100, mean_ecr: 0.0474 mean_entropies: 0.6965, took: 81.6838s
2022-10-10 14:16:28,393 [INFO] 	Process 7 - batch 45799: mean_policy_losses: -635.115, mean_net_lifetime: 3875.8513, mean_mc_travel_dist: 1357.6469, mean_rewards: 240.2212, total_rewards: 2566.5207, mean_steps: 15.3200, mean_ecr: 0.0418 mean_entropies: 1.2622, took: 72.5088s
2022-10-10 14:16:51,390 [INFO] Process 6 - epoch 43: mean_policy_losses: -260.194, mean_net_lifetime: 2693.0246, mean_mc_travel_dist: 952.1467, mean_entropies: 0.8285, m_net_lifetime_valid: 4147.8960, took: 1327.4510s, (113.4422 / 100 batches)

2022-10-10 14:16:58,512 [INFO] 	Process 5 - batch 45099: mean_policy_losses: -305.730, mean_net_lifetime: 4814.2128, mean_mc_travel_dist: 1605.5688, mean_rewards: 261.2923, total_rewards: 3256.0063, mean_steps: 17.9400, mean_ecr: 0.0311 mean_entropies: 0.7147, took: 634.5034s
2022-10-10 14:17:03,099 [INFO] 	Process 1 - batch 39699: mean_policy_losses: 110.615, mean_net_lifetime: 5384.7395, mean_mc_travel_dist: 1917.7786, mean_rewards: 260.0327, total_rewards: 3492.3656, mean_steps: 19.9000, mean_ecr: 0.0387 mean_entropies: 0.9874, took: 95.0582s
2022-10-10 14:17:11,982 [INFO] 	Process 4 - batch 51399: mean_policy_losses: -26.903, mean_net_lifetime: 4058.3733, mean_mc_travel_dist: 1178.8368, mean_rewards: 260.1844, total_rewards: 2915.5831, mean_steps: 14.5600, mean_ecr: 0.0490 mean_entropies: 0.8414, took: 75.2349s
2022-10-10 14:17:15,097 [INFO] 	Process 2 - batch 45299: mean_policy_losses: 18.775, mean_net_lifetime: 4715.1868, mean_mc_travel_dist: 1315.5356, mean_rewards: 280.7296, total_rewards: 3422.4558, mean_steps: 15.8700, mean_ecr: 0.0408 mean_entropies: 0.5252, took: 82.4323s
2022-10-10 14:17:46,864 [INFO] 	Process 6 - batch 64599: mean_policy_losses: -117.392, mean_net_lifetime: 3620.1527, mean_mc_travel_dist: 972.7701, mean_rewards: 321.6981, total_rewards: 2675.9933, mean_steps: 10.2800, mean_ecr: 0.0558 mean_entropies: 0.2024, took: 587.9064s
2022-10-10 14:17:55,857 [INFO] 	Process 7 - batch 45899: mean_policy_losses: -555.510, mean_net_lifetime: 4117.8340, mean_mc_travel_dist: 1440.4713, mean_rewards: 228.1282, total_rewards: 2724.9543, mean_steps: 17.3700, mean_ecr: 0.0416 mean_entropies: 1.3379, took: 87.4642s
2022-10-10 14:18:16,645 [INFO] 	Process 5 - batch 45199: mean_policy_losses: -464.420, mean_net_lifetime: 3910.1085, mean_mc_travel_dist: 1272.1091, mean_rewards: 249.2794, total_rewards: 2706.9324, mean_steps: 15.1100, mean_ecr: 0.0308 mean_entropies: 0.6585, took: 78.1323s
2022-10-10 14:18:37,037 [INFO] 	Process 4 - batch 51499: mean_policy_losses: 63.665, mean_net_lifetime: 4694.5924, mean_mc_travel_dist: 1325.6652, mean_rewards: 282.3772, total_rewards: 3403.8389, mean_steps: 15.6900, mean_ecr: 0.0476 mean_entropies: 0.6919, took: 85.0536s
2022-10-10 14:18:41,126 [INFO] 	Process 2 - batch 45399: mean_policy_losses: -10.226, mean_net_lifetime: 4672.4231, mean_mc_travel_dist: 1287.0936, mean_rewards: 271.9748, total_rewards: 3401.2712, mean_steps: 16.2400, mean_ecr: 0.0409 mean_entropies: 0.4571, took: 86.0283s
2022-10-10 14:18:41,312 [INFO] 	Process 1 - batch 39799: mean_policy_losses: 106.054, mean_net_lifetime: 5377.7952, mean_mc_travel_dist: 1900.8652, mean_rewards: 261.9404, total_rewards: 3508.1997, mean_steps: 19.6000, mean_ecr: 0.0387 mean_entropies: 0.9802, took: 98.2132s
2022-10-10 14:18:49,474 [INFO] 	Process 6 - batch 64699: mean_policy_losses: -79.978, mean_net_lifetime: 3723.1737, mean_mc_travel_dist: 994.8043, mean_rewards: 315.3848, total_rewards: 2752.4824, mean_steps: 10.8900, mean_ecr: 0.0556 mean_entropies: 0.1897, took: 62.6109s
2022-10-10 14:19:27,782 [INFO] 	Process 7 - batch 45999: mean_policy_losses: -529.141, mean_net_lifetime: 4304.1373, mean_mc_travel_dist: 1494.3422, mean_rewards: 231.5628, total_rewards: 2848.4783, mean_steps: 18.0900, mean_ecr: 0.0414 mean_entropies: 1.2911, took: 91.9255s
2022-10-10 14:19:42,540 [INFO] 	Process 5 - batch 45299: mean_policy_losses: -376.776, mean_net_lifetime: 4406.2319, mean_mc_travel_dist: 1467.9106, mean_rewards: 248.9712, total_rewards: 3006.2180, mean_steps: 17.1000, mean_ecr: 0.0310 mean_entropies: 0.6440, took: 85.8946s
2022-10-10 14:19:45,774 [INFO] 	Process 6 - batch 64799: mean_policy_losses: -151.534, mean_net_lifetime: 3667.9717, mean_mc_travel_dist: 980.9427, mean_rewards: 318.1045, total_rewards: 2713.6187, mean_steps: 10.5800, mean_ecr: 0.0557 mean_entropies: 0.1856, took: 56.2994s
2022-10-10 14:20:06,034 [INFO] 	Process 4 - batch 51599: mean_policy_losses: 84.391, mean_net_lifetime: 4809.1812, mean_mc_travel_dist: 1342.6500, mean_rewards: 275.3812, total_rewards: 3498.2878, mean_steps: 16.5400, mean_ecr: 0.0474 mean_entropies: 0.6949, took: 88.9979s
2022-10-10 14:20:06,176 [INFO] 	Process 2 - batch 45499: mean_policy_losses: -5.085, mean_net_lifetime: 4713.6429, mean_mc_travel_dist: 1312.8000, mean_rewards: 270.1797, total_rewards: 3420.4524, mean_steps: 16.5500, mean_ecr: 0.0408 mean_entropies: 0.4312, took: 85.0501s
2022-10-10 14:20:25,638 [INFO] 	Process 1 - batch 39899: mean_policy_losses: 79.432, mean_net_lifetime: 5362.8186, mean_mc_travel_dist: 1904.3328, mean_rewards: 245.8636, total_rewards: 3490.7413, mean_steps: 21.1600, mean_ecr: 0.0385 mean_entropies: 0.9525, took: 104.3260s
2022-10-10 14:20:46,348 [INFO] 	Process 6 - batch 64899: mean_policy_losses: -66.312, mean_net_lifetime: 3804.7194, mean_mc_travel_dist: 1015.3517, mean_rewards: 313.6086, total_rewards: 2820.6035, mean_steps: 11.1500, mean_ecr: 0.0557 mean_entropies: 0.1808, took: 60.5740s
2022-10-10 14:21:08,313 [INFO] 	Process 7 - batch 46099: mean_policy_losses: -446.300, mean_net_lifetime: 4683.5528, mean_mc_travel_dist: 1672.4354, mean_rewards: 220.1369, total_rewards: 3052.5965, mean_steps: 21.0200, mean_ecr: 0.0410 mean_entropies: 1.2336, took: 100.5312s
2022-10-10 14:21:10,479 [INFO] 	Process 5 - batch 45399: mean_policy_losses: -391.009, mean_net_lifetime: 4404.1955, mean_mc_travel_dist: 1478.5739, mean_rewards: 248.1114, total_rewards: 2976.6513, mean_steps: 17.5000, mean_ecr: 0.0306 mean_entropies: 0.6152, took: 87.9395s
2022-10-10 14:21:25,827 [INFO] 	Process 2 - batch 45599: mean_policy_losses: 5.441, mean_net_lifetime: 4714.8630, mean_mc_travel_dist: 1294.2675, mean_rewards: 280.3978, total_rewards: 3441.1915, mean_steps: 15.9200, mean_ecr: 0.0408 mean_entropies: 0.4557, took: 79.6517s
2022-10-10 14:21:30,864 [INFO] 	Process 4 - batch 51699: mean_policy_losses: 91.783, mean_net_lifetime: 4868.5593, mean_mc_travel_dist: 1366.4913, mean_rewards: 278.8322, total_rewards: 3529.1188, mean_steps: 16.5200, mean_ecr: 0.0472 mean_entropies: 0.6941, took: 84.8304s
2022-10-10 14:21:43,900 [INFO] 	Process 6 - batch 64999: mean_policy_losses: -46.094, mean_net_lifetime: 3747.8580, mean_mc_travel_dist: 1000.6332, mean_rewards: 325.6208, total_rewards: 2764.9691, mean_steps: 10.5600, mean_ecr: 0.0557 mean_entropies: 0.1852, took: 57.5526s
2022-10-10 14:22:02,534 [INFO] 	Process 1 - batch 39999: mean_policy_losses: 48.128, mean_net_lifetime: 5258.5528, mean_mc_travel_dist: 1892.3742, mean_rewards: 256.8820, total_rewards: 3391.3760, mean_steps: 19.6600, mean_ecr: 0.0387 mean_entropies: 0.9297, took: 96.8950s
2022-10-10 14:22:09,665 [INFO] Process 3 - epoch 31: mean_policy_losses: 91.050, mean_net_lifetime: 4108.0580, mean_mc_travel_dist: 1413.7454, mean_entropies: 1.1374, m_net_lifetime_valid: 4276.2468, took: 1678.5776s, (157.9041 / 100 batches)

2022-10-10 14:22:34,108 [INFO] 	Process 7 - batch 46199: mean_policy_losses: -645.878, mean_net_lifetime: 4067.1975, mean_mc_travel_dist: 1484.1721, mean_rewards: 232.0505, total_rewards: 2624.9187, mean_steps: 17.3800, mean_ecr: 0.0416 mean_entropies: 1.2739, took: 85.7942s
2022-10-10 14:22:41,769 [INFO] 	Process 5 - batch 45499: mean_policy_losses: -423.566, mean_net_lifetime: 4416.4711, mean_mc_travel_dist: 1494.1106, mean_rewards: 244.2868, total_rewards: 2969.9004, mean_steps: 18.0200, mean_ecr: 0.0301 mean_entropies: 0.6710, took: 91.2901s
2022-10-10 14:22:42,732 [INFO] 	Process 6 - batch 65099: mean_policy_losses: -71.025, mean_net_lifetime: 3674.0746, mean_mc_travel_dist: 976.0724, mean_rewards: 317.9758, total_rewards: 2721.2961, mean_steps: 10.5900, mean_ecr: 0.0558 mean_entropies: 0.1913, took: 58.8312s
2022-10-10 14:22:48,190 [INFO] 	Process 2 - batch 45699: mean_policy_losses: -4.655, mean_net_lifetime: 4713.6149, mean_mc_travel_dist: 1308.9986, mean_rewards: 277.6519, total_rewards: 3429.2264, mean_steps: 16.0400, mean_ecr: 0.0408 mean_entropies: 0.4526, took: 82.3622s
2022-10-10 14:23:01,028 [INFO] 	Process 4 - batch 51799: mean_policy_losses: 121.597, mean_net_lifetime: 5220.3956, mean_mc_travel_dist: 1478.8510, mean_rewards: 287.6969, total_rewards: 3776.8609, mean_steps: 17.3500, mean_ecr: 0.0463 mean_entropies: 0.6582, took: 90.1641s
2022-10-10 14:23:30,693 [INFO] 	Process 3 - batch 46599: mean_policy_losses: 37.817, mean_net_lifetime: 4501.2498, mean_mc_travel_dist: 1225.6388, mean_rewards: 279.0829, total_rewards: 3304.1891, mean_steps: 15.1800, mean_ecr: 0.0486 mean_entropies: 0.5465, took: 631.8848s
2022-10-10 14:23:40,233 [INFO] 	Process 6 - batch 65199: mean_policy_losses: -134.527, mean_net_lifetime: 3631.0257, mean_mc_travel_dist: 976.7608, mean_rewards: 323.1259, total_rewards: 2677.5134, mean_steps: 10.2600, mean_ecr: 0.0557 mean_entropies: 0.1988, took: 57.5015s
2022-10-10 14:23:44,238 [INFO] 	Process 1 - batch 40099: mean_policy_losses: 8.960, mean_net_lifetime: 5118.7957, mean_mc_travel_dist: 1904.6361, mean_rewards: 249.4951, total_rewards: 3239.9575, mean_steps: 19.8600, mean_ecr: 0.0386 mean_entropies: 0.8531, took: 101.7049s
2022-10-10 14:23:58,693 [INFO] 	Process 7 - batch 46299: mean_policy_losses: -677.501, mean_net_lifetime: 4071.7707, mean_mc_travel_dist: 1415.2500, mean_rewards: 236.2523, total_rewards: 2704.6928, mean_steps: 16.7100, mean_ecr: 0.0415 mean_entropies: 1.2736, took: 84.5855s
2022-10-10 14:24:11,461 [INFO] 	Process 2 - batch 45799: mean_policy_losses: -10.619, mean_net_lifetime: 4706.3334, mean_mc_travel_dist: 1305.7335, mean_rewards: 278.2018, total_rewards: 3419.9907, mean_steps: 16.0300, mean_ecr: 0.0407 mean_entropies: 0.4794, took: 83.2716s
2022-10-10 14:24:16,819 [INFO] 	Process 5 - batch 45599: mean_policy_losses: -379.328, mean_net_lifetime: 4727.0757, mean_mc_travel_dist: 1598.6810, mean_rewards: 251.8280, total_rewards: 3188.3548, mean_steps: 18.4000, mean_ecr: 0.0305 mean_entropies: 0.6484, took: 95.0501s
2022-10-10 14:24:28,726 [INFO] 	Process 4 - batch 51899: mean_policy_losses: 117.491, mean_net_lifetime: 5011.1363, mean_mc_travel_dist: 1411.1491, mean_rewards: 287.9242, total_rewards: 3629.7116, mean_steps: 16.4900, mean_ecr: 0.0469 mean_entropies: 0.6773, took: 87.6981s
2022-10-10 14:24:37,592 [INFO] 	Process 6 - batch 65299: mean_policy_losses: -190.574, mean_net_lifetime: 3470.9997, mean_mc_travel_dist: 930.7142, mean_rewards: 317.9189, total_rewards: 2560.9440, mean_steps: 9.9400, mean_ecr: 0.0560 mean_entropies: 0.1902, took: 57.3595s
2022-10-10 14:24:55,922 [INFO] 	Process 3 - batch 46699: mean_policy_losses: 19.667, mean_net_lifetime: 4366.4136, mean_mc_travel_dist: 1200.7005, mean_rewards: 260.3908, total_rewards: 3189.6975, mean_steps: 15.8000, mean_ecr: 0.0487 mean_entropies: 0.5191, took: 85.2291s
2022-10-10 14:25:26,311 [INFO] 	Process 1 - batch 40199: mean_policy_losses: 32.874, mean_net_lifetime: 5151.9447, mean_mc_travel_dist: 1885.8263, mean_rewards: 247.0900, total_rewards: 3296.3273, mean_steps: 20.2000, mean_ecr: 0.0385 mean_entropies: 0.9043, took: 102.0723s
2022-10-10 14:25:26,387 [INFO] 	Process 7 - batch 46399: mean_policy_losses: -528.448, mean_net_lifetime: 4359.6507, mean_mc_travel_dist: 1470.0762, mean_rewards: 239.4115, total_rewards: 2936.2014, mean_steps: 17.5600, mean_ecr: 0.0413 mean_entropies: 1.2472, took: 87.6935s
2022-10-10 14:25:37,384 [INFO] 	Process 6 - batch 65399: mean_policy_losses: -129.926, mean_net_lifetime: 3607.7524, mean_mc_travel_dist: 972.2385, mean_rewards: 306.5018, total_rewards: 2668.5840, mean_steps: 10.8000, mean_ecr: 0.0558 mean_entropies: 0.1546, took: 59.7915s
2022-10-10 14:25:37,972 [INFO] 	Process 2 - batch 45899: mean_policy_losses: -2.427, mean_net_lifetime: 4711.3272, mean_mc_travel_dist: 1317.8016, mean_rewards: 267.0124, total_rewards: 3417.8750, mean_steps: 16.7200, mean_ecr: 0.0407 mean_entropies: 0.4202, took: 86.5102s
2022-10-10 14:25:38,614 [INFO] 	Process 5 - batch 45699: mean_policy_losses: -438.596, mean_net_lifetime: 3996.5244, mean_mc_travel_dist: 1326.4632, mean_rewards: 248.4742, total_rewards: 2735.5182, mean_steps: 15.8400, mean_ecr: 0.0306 mean_entropies: 0.6097, took: 81.7949s
2022-10-10 14:25:56,421 [INFO] 	Process 4 - batch 51999: mean_policy_losses: 113.934, mean_net_lifetime: 5006.6427, mean_mc_travel_dist: 1394.2608, mean_rewards: 288.3823, total_rewards: 3632.1471, mean_steps: 16.4400, mean_ecr: 0.0471 mean_entropies: 0.6361, took: 87.6935s
2022-10-10 14:26:19,548 [INFO] 	Process 3 - batch 46799: mean_policy_losses: 14.741, mean_net_lifetime: 4349.0365, mean_mc_travel_dist: 1187.2604, mean_rewards: 258.7112, total_rewards: 3187.4462, mean_steps: 15.8500, mean_ecr: 0.0488 mean_entropies: 0.5097, took: 83.6263s
2022-10-10 14:26:33,838 [INFO] 	Process 6 - batch 65499: mean_policy_losses: -106.979, mean_net_lifetime: 3540.2161, mean_mc_travel_dist: 952.3548, mean_rewards: 319.7593, total_rewards: 2621.6780, mean_steps: 10.1900, mean_ecr: 0.0558 mean_entropies: 0.1844, took: 56.4538s
2022-10-10 14:26:52,132 [INFO] 	Process 7 - batch 46499: mean_policy_losses: -611.865, mean_net_lifetime: 4201.5841, mean_mc_travel_dist: 1481.4415, mean_rewards: 237.6609, total_rewards: 2763.7257, mean_steps: 17.1100, mean_ecr: 0.0415 mean_entropies: 1.2689, took: 85.7448s
2022-10-10 14:27:03,044 [INFO] 	Process 2 - batch 45999: mean_policy_losses: -0.317, mean_net_lifetime: 4719.5322, mean_mc_travel_dist: 1321.5276, mean_rewards: 274.9362, total_rewards: 3418.4033, mean_steps: 16.2500, mean_ecr: 0.0407 mean_entropies: 0.4541, took: 85.0726s
2022-10-10 14:27:08,781 [INFO] 	Process 5 - batch 45799: mean_policy_losses: -419.879, mean_net_lifetime: 4580.5443, mean_mc_travel_dist: 1547.5474, mean_rewards: 253.2531, total_rewards: 3096.7196, mean_steps: 17.7100, mean_ecr: 0.0305 mean_entropies: 0.6635, took: 90.1662s
2022-10-10 14:27:09,326 [INFO] 	Process 1 - batch 40299: mean_policy_losses: 110.778, mean_net_lifetime: 5427.6535, mean_mc_travel_dist: 1890.0914, mean_rewards: 257.5416, total_rewards: 3569.8757, mean_steps: 20.3100, mean_ecr: 0.0387 mean_entropies: 0.9505, took: 103.0153s
2022-10-10 14:27:22,205 [INFO] 	Process 4 - batch 52099: mean_policy_losses: 48.092, mean_net_lifetime: 4735.5126, mean_mc_travel_dist: 1362.7314, mean_rewards: 272.4219, total_rewards: 3407.1032, mean_steps: 16.4500, mean_ecr: 0.0478 mean_entropies: 0.6971, took: 85.7851s
2022-10-10 14:27:32,269 [INFO] 	Process 6 - batch 65599: mean_policy_losses: -141.498, mean_net_lifetime: 3575.8354, mean_mc_travel_dist: 961.7055, mean_rewards: 310.9162, total_rewards: 2645.0051, mean_steps: 10.5500, mean_ecr: 0.0558 mean_entropies: 0.1778, took: 58.4316s
2022-10-10 14:27:37,883 [INFO] 	Process 3 - batch 46899: mean_policy_losses: 13.947, mean_net_lifetime: 4374.0759, mean_mc_travel_dist: 1221.9496, mean_rewards: 270.5075, total_rewards: 3174.3082, mean_steps: 15.2200, mean_ecr: 0.0486 mean_entropies: 0.5618, took: 78.3350s
2022-10-10 14:28:23,498 [INFO] 	Process 2 - batch 46099: mean_policy_losses: -5.623, mean_net_lifetime: 4725.5183, mean_mc_travel_dist: 1309.7291, mean_rewards: 281.4684, total_rewards: 3437.7416, mean_steps: 15.8600, mean_ecr: 0.0406 mean_entropies: 0.4952, took: 80.4536s
2022-10-10 14:28:26,127 [INFO] 	Process 6 - batch 65699: mean_policy_losses: -192.234, mean_net_lifetime: 3441.3144, mean_mc_travel_dist: 924.7568, mean_rewards: 319.9128, total_rewards: 2535.7762, mean_steps: 9.8400, mean_ecr: 0.0561 mean_entropies: 0.1962, took: 53.8571s
2022-10-10 14:28:43,507 [INFO] 	Process 5 - batch 45899: mean_policy_losses: -350.501, mean_net_lifetime: 4908.3644, mean_mc_travel_dist: 1641.4818, mean_rewards: 255.7371, total_rewards: 3323.3004, mean_steps: 18.6000, mean_ecr: 0.0310 mean_entropies: 0.6991, took: 94.7267s
2022-10-10 14:28:45,077 [INFO] 	Process 4 - batch 52199: mean_policy_losses: 50.992, mean_net_lifetime: 4836.9104, mean_mc_travel_dist: 1351.8743, mean_rewards: 281.1759, total_rewards: 3513.0110, mean_steps: 16.2400, mean_ecr: 0.0475 mean_entropies: 0.7167, took: 82.8723s
2022-10-10 14:28:49,713 [INFO] 	Process 1 - batch 40399: mean_policy_losses: 70.200, mean_net_lifetime: 5541.7484, mean_mc_travel_dist: 1940.5409, mean_rewards: 258.5608, total_rewards: 3618.8020, mean_steps: 20.5700, mean_ecr: 0.0386 mean_entropies: 0.9750, took: 100.3864s
2022-10-10 14:28:55,898 [INFO] 	Process 3 - batch 46999: mean_policy_losses: 9.666, mean_net_lifetime: 4441.9138, mean_mc_travel_dist: 1234.2484, mean_rewards: 275.9919, total_rewards: 3239.3383, mean_steps: 15.1400, mean_ecr: 0.0486 mean_entropies: 0.5718, took: 78.0150s
2022-10-10 14:29:23,418 [INFO] 	Process 6 - batch 65799: mean_policy_losses: -118.642, mean_net_lifetime: 3653.8970, mean_mc_travel_dist: 987.3556, mean_rewards: 314.0346, total_rewards: 2705.2933, mean_steps: 10.7200, mean_ecr: 0.0558 mean_entropies: 0.1864, took: 57.2921s
2022-10-10 14:29:46,607 [INFO] 	Process 2 - batch 46199: mean_policy_losses: -2.105, mean_net_lifetime: 4743.6499, mean_mc_travel_dist: 1333.5936, mean_rewards: 276.3542, total_rewards: 3433.1660, mean_steps: 16.3100, mean_ecr: 0.0406 mean_entropies: 0.5033, took: 83.1098s
2022-10-10 14:30:08,758 [INFO] 	Process 4 - batch 52299: mean_policy_losses: 84.145, mean_net_lifetime: 4980.8954, mean_mc_travel_dist: 1395.5792, mean_rewards: 287.1339, total_rewards: 3608.6312, mean_steps: 16.4400, mean_ecr: 0.0474 mean_entropies: 0.7093, took: 83.6810s
2022-10-10 14:30:09,224 [INFO] 	Process 5 - batch 45999: mean_policy_losses: -477.882, mean_net_lifetime: 4448.2764, mean_mc_travel_dist: 1494.1371, mean_rewards: 255.7284, total_rewards: 3013.0617, mean_steps: 17.2200, mean_ecr: 0.0304 mean_entropies: 0.6712, took: 85.7161s
2022-10-10 14:30:15,428 [INFO] 	Process 6 - batch 65899: mean_policy_losses: -212.105, mean_net_lifetime: 3309.3402, mean_mc_travel_dist: 896.5142, mean_rewards: 324.4447, total_rewards: 2443.3383, mean_steps: 9.2400, mean_ecr: 0.0562 mean_entropies: 0.2218, took: 52.0092s
2022-10-10 14:30:15,734 [INFO] 	Process 3 - batch 47099: mean_policy_losses: 13.357, mean_net_lifetime: 4473.6760, mean_mc_travel_dist: 1248.2686, mean_rewards: 276.3600, total_rewards: 3255.9493, mean_steps: 15.2400, mean_ecr: 0.0483 mean_entropies: 0.5514, took: 79.8358s
2022-10-10 14:30:28,828 [INFO] 	Process 1 - batch 40499: mean_policy_losses: 43.462, mean_net_lifetime: 5408.7252, mean_mc_travel_dist: 1903.5240, mean_rewards: 256.2480, total_rewards: 3530.5397, mean_steps: 20.2600, mean_ecr: 0.0386 mean_entropies: 0.9711, took: 99.1153s
2022-10-10 14:31:05,457 [INFO] 	Process 2 - batch 46299: mean_policy_losses: -1.343, mean_net_lifetime: 4756.7469, mean_mc_travel_dist: 1338.9115, mean_rewards: 280.4449, total_rewards: 3446.3126, mean_steps: 16.0600, mean_ecr: 0.0405 mean_entropies: 0.5278, took: 78.8494s
2022-10-10 14:31:09,414 [INFO] 	Process 6 - batch 65999: mean_policy_losses: -100.017, mean_net_lifetime: 3556.2662, mean_mc_travel_dist: 958.3871, mean_rewards: 323.3575, total_rewards: 2622.1049, mean_steps: 10.0400, mean_ecr: 0.0560 mean_entropies: 0.1831, took: 53.9864s
2022-10-10 14:31:28,509 [INFO] 	Process 4 - batch 52399: mean_policy_losses: 43.456, mean_net_lifetime: 4867.4659, mean_mc_travel_dist: 1357.3983, mean_rewards: 285.4836, total_rewards: 3537.6746, mean_steps: 16.1300, mean_ecr: 0.0476 mean_entropies: 0.7542, took: 79.7507s
2022-10-10 14:31:30,282 [INFO] 	Process 3 - batch 47199: mean_policy_losses: 12.266, mean_net_lifetime: 4501.9589, mean_mc_travel_dist: 1245.4360, mean_rewards: 281.8821, total_rewards: 3292.2352, mean_steps: 15.0300, mean_ecr: 0.0484 mean_entropies: 0.5613, took: 74.5482s
2022-10-10 14:31:39,451 [INFO] 	Process 5 - batch 46099: mean_policy_losses: -348.353, mean_net_lifetime: 4984.5474, mean_mc_travel_dist: 1689.4792, mean_rewards: 260.8076, total_rewards: 3341.1685, mean_steps: 18.7600, mean_ecr: 0.0308 mean_entropies: 0.7294, took: 90.2279s
2022-10-10 14:32:20,047 [INFO] 	Process 2 - batch 46399: mean_policy_losses: -23.590, mean_net_lifetime: 4734.7947, mean_mc_travel_dist: 1338.2613, mean_rewards: 278.5922, total_rewards: 3417.5313, mean_steps: 16.1100, mean_ecr: 0.0405 mean_entropies: 0.4975, took: 74.5906s
2022-10-10 14:32:45,332 [INFO] 	Process 3 - batch 47299: mean_policy_losses: -13.484, mean_net_lifetime: 4416.4583, mean_mc_travel_dist: 1207.9082, mean_rewards: 265.3266, total_rewards: 3227.3780, mean_steps: 15.6800, mean_ecr: 0.0486 mean_entropies: 0.5288, took: 75.0495s
2022-10-10 14:32:47,252 [INFO] 	Process 4 - batch 52499: mean_policy_losses: 39.089, mean_net_lifetime: 4947.2859, mean_mc_travel_dist: 1418.1616, mean_rewards: 286.3228, total_rewards: 3568.2489, mean_steps: 16.4300, mean_ecr: 0.0470 mean_entropies: 0.6826, took: 78.7432s
2022-10-10 14:33:05,669 [INFO] 	Process 5 - batch 46199: mean_policy_losses: -371.651, mean_net_lifetime: 4661.9278, mean_mc_travel_dist: 1606.9233, mean_rewards: 247.1916, total_rewards: 3104.9429, mean_steps: 18.6100, mean_ecr: 0.0301 mean_entropies: 0.6485, took: 86.2174s
2022-10-10 14:33:34,064 [INFO] 	Process 2 - batch 46499: mean_policy_losses: -2.663, mean_net_lifetime: 4698.6894, mean_mc_travel_dist: 1300.3064, mean_rewards: 278.0637, total_rewards: 3413.1575, mean_steps: 15.9600, mean_ecr: 0.0408 mean_entropies: 0.4591, took: 74.0167s
2022-10-10 14:33:54,425 [INFO] 	Process 3 - batch 47399: mean_policy_losses: 25.805, mean_net_lifetime: 4460.2247, mean_mc_travel_dist: 1216.8114, mean_rewards: 273.6182, total_rewards: 3272.5992, mean_steps: 15.3500, mean_ecr: 0.0487 mean_entropies: 0.5163, took: 69.0940s
2022-10-10 14:34:24,024 [INFO] 	Process 5 - batch 46299: mean_policy_losses: -377.350, mean_net_lifetime: 4650.0757, mean_mc_travel_dist: 1578.6321, mean_rewards: 253.2330, total_rewards: 3121.5678, mean_steps: 17.8900, mean_ecr: 0.0303 mean_entropies: 0.6960, took: 78.3544s
2022-10-10 14:35:00,499 [INFO] 	Process 3 - batch 47499: mean_policy_losses: 31.795, mean_net_lifetime: 4453.6482, mean_mc_travel_dist: 1247.8348, mean_rewards: 283.9102, total_rewards: 3236.6857, mean_steps: 14.7300, mean_ecr: 0.0483 mean_entropies: 0.5384, took: 66.0733s
2022-10-10 14:35:36,293 [INFO] 	Process 5 - batch 46399: mean_policy_losses: -294.344, mean_net_lifetime: 4636.8615, mean_mc_travel_dist: 1548.7952, mean_rewards: 266.1545, total_rewards: 3145.8240, mean_steps: 16.8300, mean_ecr: 0.0306 mean_entropies: 0.7245, took: 72.2696s
2022-10-10 14:36:05,843 [INFO] 	Process 3 - batch 47599: mean_policy_losses: 3.116, mean_net_lifetime: 4422.0189, mean_mc_travel_dist: 1237.2543, mean_rewards: 282.5242, total_rewards: 3215.2263, mean_steps: 14.7100, mean_ecr: 0.0484 mean_entropies: 0.5303, took: 65.3431s
2022-10-10 14:36:19,754 [INFO] Process 7 - epoch 31: mean_policy_losses: -239.594, mean_net_lifetime: 3975.4518, mean_mc_travel_dist: 1605.8625, mean_entropies: 1.7579, m_net_lifetime_valid: 4263.1338, took: 1871.6172s, (159.6937 / 100 batches)

2022-10-10 14:37:04,238 [INFO] 	Process 5 - batch 46499: mean_policy_losses: -175.621, mean_net_lifetime: 5427.2680, mean_mc_travel_dist: 1846.1762, mean_rewards: 262.3488, total_rewards: 3628.1811, mean_steps: 19.9400, mean_ecr: 0.0303 mean_entropies: 0.7047, took: 87.9457s
2022-10-10 14:37:15,404 [INFO] 	Process 3 - batch 47699: mean_policy_losses: 30.006, mean_net_lifetime: 4504.9081, mean_mc_travel_dist: 1253.9583, mean_rewards: 282.0530, total_rewards: 3282.1756, mean_steps: 15.0400, mean_ecr: 0.0482 mean_entropies: 0.5433, took: 69.5620s
2022-10-10 14:37:32,023 [INFO] 	Process 7 - batch 46599: mean_policy_losses: -817.518, mean_net_lifetime: 4157.7386, mean_mc_travel_dist: 1382.9482, mean_rewards: 239.0961, total_rewards: 2827.3013, mean_steps: 16.6700, mean_ecr: 0.0416 mean_entropies: 1.4327, took: 639.8916s
2022-10-10 14:38:24,559 [INFO] 	Process 3 - batch 47799: mean_policy_losses: 18.237, mean_net_lifetime: 4585.3954, mean_mc_travel_dist: 1289.4449, mean_rewards: 282.6693, total_rewards: 3341.8106, mean_steps: 15.2600, mean_ecr: 0.0479 mean_entropies: 0.5536, took: 69.1549s
2022-10-10 14:38:40,957 [INFO] 	Process 7 - batch 46699: mean_policy_losses: -772.373, mean_net_lifetime: 4111.0718, mean_mc_travel_dist: 1444.6576, mean_rewards: 242.9755, total_rewards: 2713.7915, mean_steps: 16.3700, mean_ecr: 0.0416 mean_entropies: 1.3949, took: 68.9343s
2022-10-10 14:39:04,192 [INFO] Process 1 - epoch 27: mean_policy_losses: 46.174, mean_net_lifetime: 4761.8001, mean_mc_travel_dist: 2060.9942, mean_entropies: 1.3603, m_net_lifetime_valid: 4425.1202, took: 1943.9099s, (183.8277 / 100 batches)

2022-10-10 14:39:33,341 [INFO] 	Process 3 - batch 47899: mean_policy_losses: 20.906, mean_net_lifetime: 4539.3427, mean_mc_travel_dist: 1241.9683, mean_rewards: 279.6513, total_rewards: 3325.3508, mean_steps: 15.2900, mean_ecr: 0.0482 mean_entropies: 0.5415, took: 68.7825s
2022-10-10 14:39:46,823 [INFO] Process 6 - epoch 44: mean_policy_losses: -257.097, mean_net_lifetime: 2713.6750, mean_mc_travel_dist: 952.4788, mean_entropies: 0.8140, m_net_lifetime_valid: 4805.7208, took: 1375.4300s, (112.9715 / 100 batches)

2022-10-10 14:39:50,028 [INFO] 	Process 7 - batch 46799: mean_policy_losses: -862.171, mean_net_lifetime: 3916.0565, mean_mc_travel_dist: 1321.1448, mean_rewards: 240.7452, total_rewards: 2636.7853, mean_steps: 15.9100, mean_ecr: 0.0417 mean_entropies: 1.3631, took: 69.0703s
2022-10-10 14:40:31,809 [INFO] 	Process 6 - batch 66099: mean_policy_losses: -113.854, mean_net_lifetime: 3144.6748, mean_mc_travel_dist: 864.8390, mean_rewards: 330.1194, total_rewards: 2314.8460, mean_steps: 8.5100, mean_ecr: 0.0564 mean_entropies: 0.2018, took: 562.3948s
2022-10-10 14:40:42,427 [INFO] 	Process 1 - batch 40599: mean_policy_losses: 116.350, mean_net_lifetime: 5531.9198, mean_mc_travel_dist: 1882.9486, mean_rewards: 241.0836, total_rewards: 3681.4399, mean_steps: 22.2000, mean_ecr: 0.0387 mean_entropies: 0.9576, took: 613.5996s
2022-10-10 14:40:48,150 [INFO] 	Process 3 - batch 47999: mean_policy_losses: 45.317, mean_net_lifetime: 4489.2430, mean_mc_travel_dist: 1221.1788, mean_rewards: 265.1186, total_rewards: 3302.7738, mean_steps: 15.9700, mean_ecr: 0.0486 mean_entropies: 0.5401, took: 74.8088s
2022-10-10 14:40:53,874 [INFO] 	Process 7 - batch 46899: mean_policy_losses: -819.560, mean_net_lifetime: 3549.1298, mean_mc_travel_dist: 1205.0986, mean_rewards: 243.2416, total_rewards: 2387.6238, mean_steps: 13.8400, mean_ecr: 0.0418 mean_entropies: 1.3499, took: 63.8464s
2022-10-10 14:41:21,620 [INFO] Process 4 - epoch 35: mean_policy_losses: 86.555, mean_net_lifetime: 3793.2650, mean_mc_travel_dist: 1296.5456, mean_entropies: 1.3838, m_net_lifetime_valid: 4600.2136, took: 1762.6061s, (142.1527 / 100 batches)

2022-10-10 14:41:21,703 [INFO] 	Process 6 - batch 66199: mean_policy_losses: -136.955, mean_net_lifetime: 3425.5930, mean_mc_travel_dist: 918.7564, mean_rewards: 310.5121, total_rewards: 2538.0705, mean_steps: 10.1200, mean_ecr: 0.0560 mean_entropies: 0.1796, took: 49.8940s
2022-10-10 14:41:54,024 [INFO] 	Process 7 - batch 46999: mean_policy_losses: -837.297, mean_net_lifetime: 3358.8115, mean_mc_travel_dist: 1195.6048, mean_rewards: 244.3616, total_rewards: 2210.6125, mean_steps: 12.9900, mean_ecr: 0.0422 mean_entropies: 1.2367, took: 60.1503s
2022-10-10 14:42:12,691 [INFO] 	Process 1 - batch 40699: mean_policy_losses: 89.360, mean_net_lifetime: 5319.2689, mean_mc_travel_dist: 1893.4676, mean_rewards: 256.4083, total_rewards: 3456.7024, mean_steps: 19.8700, mean_ecr: 0.0387 mean_entropies: 0.9411, took: 90.2638s
2022-10-10 14:42:16,519 [INFO] 	Process 6 - batch 66299: mean_policy_losses: -165.543, mean_net_lifetime: 3579.3310, mean_mc_travel_dist: 958.2819, mean_rewards: 304.3767, total_rewards: 2651.8587, mean_steps: 10.8000, mean_ecr: 0.0557 mean_entropies: 0.1466, took: 54.8150s
2022-10-10 14:42:23,695 [INFO] Process 2 - epoch 31: mean_policy_losses: 9.693, mean_net_lifetime: 4254.1326, mean_mc_travel_dist: 1595.9226, mean_entropies: 1.1608, m_net_lifetime_valid: 4318.7142, took: 1748.6792s, (160.5565 / 100 batches)

2022-10-10 14:42:37,676 [INFO] 	Process 4 - batch 52599: mean_policy_losses: 87.187, mean_net_lifetime: 4750.5414, mean_mc_travel_dist: 1361.1939, mean_rewards: 287.2375, total_rewards: 3414.2685, mean_steps: 15.6200, mean_ecr: 0.0476 mean_entropies: 0.6800, took: 590.4235s
2022-10-10 14:42:50,266 [INFO] 	Process 7 - batch 47099: mean_policy_losses: -1001.474, mean_net_lifetime: 3125.8215, mean_mc_travel_dist: 1166.7209, mean_rewards: 254.1420, total_rewards: 2008.2502, mean_steps: 11.6900, mean_ecr: 0.0423 mean_entropies: 1.2449, took: 56.2416s
2022-10-10 14:43:09,827 [INFO] 	Process 6 - batch 66399: mean_policy_losses: -107.870, mean_net_lifetime: 3488.8354, mean_mc_travel_dist: 939.0872, mean_rewards: 318.8804, total_rewards: 2574.2712, mean_steps: 9.9800, mean_ecr: 0.0560 mean_entropies: 0.1614, took: 53.3084s
2022-10-10 14:43:42,943 [INFO] 	Process 2 - batch 46599: mean_policy_losses: 8.739, mean_net_lifetime: 4698.1460, mean_mc_travel_dist: 1315.2649, mean_rewards: 273.8044, total_rewards: 3403.5172, mean_steps: 16.2300, mean_ecr: 0.0407 mean_entropies: 0.4379, took: 608.8787s
2022-10-10 14:43:46,627 [INFO] 	Process 1 - batch 40799: mean_policy_losses: 81.002, mean_net_lifetime: 5304.8528, mean_mc_travel_dist: 1846.3771, mean_rewards: 258.0028, total_rewards: 3486.3956, mean_steps: 19.7200, mean_ecr: 0.0389 mean_entropies: 0.9522, took: 93.9365s
2022-10-10 14:43:58,980 [INFO] 	Process 7 - batch 47199: mean_policy_losses: -783.917, mean_net_lifetime: 3580.0027, mean_mc_travel_dist: 1392.8465, mean_rewards: 244.6095, total_rewards: 2233.4908, mean_steps: 14.2200, mean_ecr: 0.0417 mean_entropies: 1.2426, took: 68.7135s
2022-10-10 14:44:02,126 [INFO] 	Process 6 - batch 66499: mean_policy_losses: -125.764, mean_net_lifetime: 3439.5358, mean_mc_travel_dist: 917.9021, mean_rewards: 325.4205, total_rewards: 2539.4707, mean_steps: 9.6300, mean_ecr: 0.0562 mean_entropies: 0.1752, took: 52.2994s
2022-10-10 14:44:02,253 [INFO] 	Process 4 - batch 52699: mean_policy_losses: 85.479, mean_net_lifetime: 4909.0587, mean_mc_travel_dist: 1414.2998, mean_rewards: 274.1302, total_rewards: 3529.7303, mean_steps: 16.9600, mean_ecr: 0.0471 mean_entropies: 0.6510, took: 84.5772s
2022-10-10 14:44:56,135 [INFO] 	Process 6 - batch 66599: mean_policy_losses: -96.441, mean_net_lifetime: 3556.9297, mean_mc_travel_dist: 958.1939, mean_rewards: 312.0485, total_rewards: 2629.4396, mean_steps: 10.4400, mean_ecr: 0.0559 mean_entropies: 0.1758, took: 54.0089s
2022-10-10 14:45:00,894 [INFO] 	Process 7 - batch 47299: mean_policy_losses: -904.288, mean_net_lifetime: 3310.1761, mean_mc_travel_dist: 1256.5885, mean_rewards: 250.3490, total_rewards: 2102.5560, mean_steps: 12.6400, mean_ecr: 0.0421 mean_entropies: 1.2047, took: 61.9145s
2022-10-10 14:45:01,593 [INFO] 	Process 2 - batch 46699: mean_policy_losses: 2.445, mean_net_lifetime: 4699.5194, mean_mc_travel_dist: 1313.8517, mean_rewards: 276.2273, total_rewards: 3407.8932, mean_steps: 16.1200, mean_ecr: 0.0408 mean_entropies: 0.4383, took: 78.6504s
2022-10-10 14:45:21,498 [INFO] 	Process 1 - batch 40899: mean_policy_losses: 53.602, mean_net_lifetime: 5333.1446, mean_mc_travel_dist: 1904.8722, mean_rewards: 254.3807, total_rewards: 3449.7665, mean_steps: 20.1700, mean_ecr: 0.0385 mean_entropies: 0.9246, took: 94.8706s
2022-10-10 14:45:22,231 [INFO] 	Process 4 - batch 52799: mean_policy_losses: 83.702, mean_net_lifetime: 4643.3687, mean_mc_travel_dist: 1327.8530, mean_rewards: 276.1216, total_rewards: 3352.4431, mean_steps: 15.8600, mean_ecr: 0.0482 mean_entropies: 0.6411, took: 79.9778s
2022-10-10 14:45:47,531 [INFO] 	Process 6 - batch 66699: mean_policy_losses: -185.176, mean_net_lifetime: 3369.4731, mean_mc_travel_dist: 903.3979, mean_rewards: 314.4246, total_rewards: 2493.0235, mean_steps: 9.7700, mean_ecr: 0.0563 mean_entropies: 0.1827, took: 51.3960s
2022-10-10 14:45:56,997 [INFO] 	Process 7 - batch 47399: mean_policy_losses: -882.195, mean_net_lifetime: 3093.2569, mean_mc_travel_dist: 1252.7663, mean_rewards: 255.5868, total_rewards: 1894.8557, mean_steps: 11.2800, mean_ecr: 0.0420 mean_entropies: 1.0732, took: 56.1028s
2022-10-10 14:46:20,038 [INFO] 	Process 2 - batch 46799: mean_policy_losses: -2.088, mean_net_lifetime: 4667.6348, mean_mc_travel_dist: 1344.4199, mean_rewards: 275.0576, total_rewards: 3347.5900, mean_steps: 16.0600, mean_ecr: 0.0405 mean_entropies: 0.4559, took: 78.4442s
2022-10-10 14:46:34,524 [INFO] Process 5 - epoch 31: mean_policy_losses: -205.763, mean_net_lifetime: 4476.2009, mean_mc_travel_dist: 1943.1661, mean_entropies: 1.4584, m_net_lifetime_valid: 4812.4400, took: 1861.4893s, (161.0073 / 100 batches)

2022-10-10 14:46:40,725 [INFO] 	Process 6 - batch 66799: mean_policy_losses: -145.350, mean_net_lifetime: 3406.8341, mean_mc_travel_dist: 914.3257, mean_rewards: 321.8451, total_rewards: 2523.1624, mean_steps: 9.6600, mean_ecr: 0.0560 mean_entropies: 0.1721, took: 53.1941s
2022-10-10 14:46:44,022 [INFO] 	Process 4 - batch 52899: mean_policy_losses: 85.563, mean_net_lifetime: 4799.3637, mean_mc_travel_dist: 1418.0621, mean_rewards: 277.4078, total_rewards: 3412.1204, mean_steps: 16.3600, mean_ecr: 0.0474 mean_entropies: 0.5785, took: 81.7911s
2022-10-10 14:46:50,823 [INFO] 	Process 1 - batch 40999: mean_policy_losses: -0.032, mean_net_lifetime: 4974.6512, mean_mc_travel_dist: 1910.9268, mean_rewards: 258.4634, total_rewards: 3092.7896, mean_steps: 18.5100, mean_ecr: 0.0386 mean_entropies: 0.7816, took: 89.3244s
2022-10-10 14:47:04,155 [INFO] 	Process 7 - batch 47499: mean_policy_losses: -561.717, mean_net_lifetime: 3607.8569, mean_mc_travel_dist: 1413.8875, mean_rewards: 260.2105, total_rewards: 2248.0531, mean_steps: 13.4700, mean_ecr: 0.0416 mean_entropies: 1.0966, took: 67.1589s
2022-10-10 14:47:32,155 [INFO] 	Process 6 - batch 66899: mean_policy_losses: -114.686, mean_net_lifetime: 3256.6146, mean_mc_travel_dist: 882.4674, mean_rewards: 325.3164, total_rewards: 2402.4332, mean_steps: 9.0400, mean_ecr: 0.0563 mean_entropies: 0.1724, took: 51.4297s
2022-10-10 14:47:40,243 [INFO] 	Process 2 - batch 46899: mean_policy_losses: 15.691, mean_net_lifetime: 4694.5179, mean_mc_travel_dist: 1337.5089, mean_rewards: 275.1223, total_rewards: 3375.5082, mean_steps: 16.1600, mean_ecr: 0.0406 mean_entropies: 0.4112, took: 80.2055s
2022-10-10 14:47:46,933 [INFO] 	Process 5 - batch 46599: mean_policy_losses: -424.586, mean_net_lifetime: 3682.0711, mean_mc_travel_dist: 1233.0088, mean_rewards: 275.1288, total_rewards: 2497.7655, mean_steps: 13.8000, mean_ecr: 0.0302 mean_entropies: 0.5836, took: 642.6945s
2022-10-10 14:48:11,197 [INFO] 	Process 4 - batch 52999: mean_policy_losses: 179.142, mean_net_lifetime: 5097.9900, mean_mc_travel_dist: 1465.6312, mean_rewards: 285.7023, total_rewards: 3666.9786, mean_steps: 17.0100, mean_ecr: 0.0467 mean_entropies: 0.6348, took: 87.1752s
2022-10-10 14:48:27,240 [INFO] 	Process 7 - batch 47599: mean_policy_losses: -530.825, mean_net_lifetime: 4202.3704, mean_mc_travel_dist: 1560.0295, mean_rewards: 244.1535, total_rewards: 2700.1470, mean_steps: 16.9200, mean_ecr: 0.0412 mean_entropies: 1.2182, took: 83.0844s
2022-10-10 14:48:29,980 [INFO] 	Process 6 - batch 66999: mean_policy_losses: -128.734, mean_net_lifetime: 3556.3793, mean_mc_travel_dist: 951.7440, mean_rewards: 311.0108, total_rewards: 2630.7059, mean_steps: 10.5500, mean_ecr: 0.0557 mean_entropies: 0.1683, took: 57.8251s
2022-10-10 14:48:33,575 [INFO] 	Process 1 - batch 41099: mean_policy_losses: 40.201, mean_net_lifetime: 5056.3884, mean_mc_travel_dist: 1811.2252, mean_rewards: 229.5747, total_rewards: 3282.3555, mean_steps: 21.2700, mean_ecr: 0.0390 mean_entropies: 0.8651, took: 102.7520s
2022-10-10 14:49:02,941 [INFO] 	Process 5 - batch 46699: mean_policy_losses: -417.006, mean_net_lifetime: 3721.3950, mean_mc_travel_dist: 1211.5486, mean_rewards: 245.9293, total_rewards: 2561.3217, mean_steps: 14.9700, mean_ecr: 0.0306 mean_entropies: 0.6278, took: 76.0088s
2022-10-10 14:49:04,797 [INFO] 	Process 2 - batch 46999: mean_policy_losses: 11.953, mean_net_lifetime: 4693.8381, mean_mc_travel_dist: 1324.9830, mean_rewards: 265.2155, total_rewards: 3394.8778, mean_steps: 16.8100, mean_ecr: 0.0407 mean_entropies: 0.4171, took: 84.5542s
2022-10-10 14:49:29,666 [INFO] 	Process 7 - batch 47699: mean_policy_losses: -809.233, mean_net_lifetime: 3349.3333, mean_mc_travel_dist: 1279.2168, mean_rewards: 265.5296, total_rewards: 2120.9507, mean_steps: 12.3700, mean_ecr: 0.0420 mean_entropies: 1.2524, took: 62.4264s
2022-10-10 14:49:29,785 [INFO] 	Process 6 - batch 67099: mean_policy_losses: -66.875, mean_net_lifetime: 3644.2059, mean_mc_travel_dist: 977.9223, mean_rewards: 307.4807, total_rewards: 2687.2149, mean_steps: 10.9100, mean_ecr: 0.0560 mean_entropies: 0.1782, took: 59.8051s
2022-10-10 14:49:33,227 [INFO] 	Process 4 - batch 53099: mean_policy_losses: 109.677, mean_net_lifetime: 4873.9564, mean_mc_travel_dist: 1438.1019, mean_rewards: 287.0836, total_rewards: 3466.9197, mean_steps: 16.0400, mean_ecr: 0.0469 mean_entropies: 0.6041, took: 82.0298s
2022-10-10 14:49:59,037 [INFO] Process 3 - epoch 32: mean_policy_losses: 88.794, mean_net_lifetime: 4119.0136, mean_mc_travel_dist: 1408.0656, mean_entropies: 1.1188, m_net_lifetime_valid: 4189.5592, took: 1669.3702s, (156.4504 / 100 batches)

2022-10-10 14:50:19,159 [INFO] 	Process 1 - batch 41199: mean_policy_losses: 99.726, mean_net_lifetime: 5298.0193, mean_mc_travel_dist: 1843.2247, mean_rewards: 243.1423, total_rewards: 3490.9439, mean_steps: 21.0300, mean_ecr: 0.0388 mean_entropies: 0.9406, took: 105.5850s
2022-10-10 14:50:21,133 [INFO] 	Process 5 - batch 46799: mean_policy_losses: -341.262, mean_net_lifetime: 4148.1742, mean_mc_travel_dist: 1357.9839, mean_rewards: 255.6540, total_rewards: 2847.0039, mean_steps: 15.6300, mean_ecr: 0.0311 mean_entropies: 0.6530, took: 78.1915s
2022-10-10 14:50:26,123 [INFO] 	Process 2 - batch 47099: mean_policy_losses: 3.156, mean_net_lifetime: 4694.1804, mean_mc_travel_dist: 1291.8855, mean_rewards: 278.5997, total_rewards: 3422.1894, mean_steps: 15.9400, mean_ecr: 0.0409 mean_entropies: 0.4564, took: 81.3259s
2022-10-10 14:50:28,252 [INFO] 	Process 6 - batch 67199: mean_policy_losses: -128.871, mean_net_lifetime: 3596.8849, mean_mc_travel_dist: 967.6434, mean_rewards: 316.0620, total_rewards: 2657.2718, mean_steps: 10.4400, mean_ecr: 0.0556 mean_entropies: 0.1645, took: 58.4665s
2022-10-10 14:50:40,119 [INFO] 	Process 7 - batch 47799: mean_policy_losses: -858.081, mean_net_lifetime: 3570.2838, mean_mc_travel_dist: 1319.3000, mean_rewards: 249.7972, total_rewards: 2298.8477, mean_steps: 13.8900, mean_ecr: 0.0420 mean_entropies: 1.3006, took: 70.4526s
2022-10-10 14:50:58,150 [INFO] 	Process 4 - batch 53199: mean_policy_losses: 141.860, mean_net_lifetime: 4848.3465, mean_mc_travel_dist: 1369.8303, mean_rewards: 284.5414, total_rewards: 3506.5706, mean_steps: 16.1100, mean_ecr: 0.0475 mean_entropies: 0.6921, took: 84.9236s
2022-10-10 14:51:20,916 [INFO] 	Process 3 - batch 48099: mean_policy_losses: 8.482, mean_net_lifetime: 4330.4496, mean_mc_travel_dist: 1180.2158, mean_rewards: 264.0378, total_rewards: 3171.6168, mean_steps: 15.4500, mean_ecr: 0.0488 mean_entropies: 0.5185, took: 632.7653s
2022-10-10 14:51:24,087 [INFO] 	Process 6 - batch 67299: mean_policy_losses: -79.923, mean_net_lifetime: 3515.7631, mean_mc_travel_dist: 940.4081, mean_rewards: 326.7832, total_rewards: 2595.9823, mean_steps: 9.8100, mean_ecr: 0.0561 mean_entropies: 0.1858, took: 55.8353s
2022-10-10 14:51:49,747 [INFO] 	Process 2 - batch 47199: mean_policy_losses: 0.328, mean_net_lifetime: 4724.1248, mean_mc_travel_dist: 1314.5353, mean_rewards: 278.5813, total_rewards: 3431.7313, mean_steps: 16.0600, mean_ecr: 0.0407 mean_entropies: 0.4668, took: 83.6244s
2022-10-10 14:51:49,778 [INFO] 	Process 5 - batch 46899: mean_policy_losses: -323.271, mean_net_lifetime: 4546.0543, mean_mc_travel_dist: 1517.5754, mean_rewards: 254.9309, total_rewards: 3088.5778, mean_steps: 17.1500, mean_ecr: 0.0307 mean_entropies: 0.6554, took: 88.6451s
2022-10-10 14:52:01,879 [INFO] 	Process 7 - batch 47899: mean_policy_losses: -637.072, mean_net_lifetime: 4108.4865, mean_mc_travel_dist: 1449.3417, mean_rewards: 246.9741, total_rewards: 2704.6027, mean_steps: 16.1300, mean_ecr: 0.0416 mean_entropies: 1.3039, took: 81.7599s
2022-10-10 14:52:06,905 [INFO] 	Process 1 - batch 41299: mean_policy_losses: 93.890, mean_net_lifetime: 5499.0216, mean_mc_travel_dist: 1905.3807, mean_rewards: 246.8323, total_rewards: 3622.9317, mean_steps: 21.4300, mean_ecr: 0.0387 mean_entropies: 1.0043, took: 107.7462s
2022-10-10 14:52:18,207 [INFO] 	Process 6 - batch 67399: mean_policy_losses: -142.516, mean_net_lifetime: 3420.2245, mean_mc_travel_dist: 921.5040, mean_rewards: 324.7757, total_rewards: 2529.2000, mean_steps: 9.5900, mean_ecr: 0.0560 mean_entropies: 0.2016, took: 54.1212s
2022-10-10 14:52:21,349 [INFO] 	Process 4 - batch 53299: mean_policy_losses: 64.049, mean_net_lifetime: 4471.8556, mean_mc_travel_dist: 1303.7550, mean_rewards: 272.3901, total_rewards: 3204.0672, mean_steps: 15.4800, mean_ecr: 0.0480 mean_entropies: 0.7760, took: 83.1992s
2022-10-10 14:52:41,724 [INFO] 	Process 3 - batch 48199: mean_policy_losses: 17.357, mean_net_lifetime: 4390.8131, mean_mc_travel_dist: 1210.1118, mean_rewards: 271.1169, total_rewards: 3203.7415, mean_steps: 15.2500, mean_ecr: 0.0487 mean_entropies: 0.5528, took: 80.8083s
2022-10-10 14:53:11,570 [INFO] 	Process 2 - batch 47299: mean_policy_losses: -5.271, mean_net_lifetime: 4712.1788, mean_mc_travel_dist: 1306.4837, mean_rewards: 283.7954, total_rewards: 3424.1171, mean_steps: 15.6800, mean_ecr: 0.0407 mean_entropies: 0.4806, took: 81.8223s
2022-10-10 14:53:12,934 [INFO] 	Process 6 - batch 67499: mean_policy_losses: -167.426, mean_net_lifetime: 3423.9020, mean_mc_travel_dist: 912.0579, mean_rewards: 325.7319, total_rewards: 2533.7347, mean_steps: 9.5600, mean_ecr: 0.0561 mean_entropies: 0.2048, took: 54.7257s
2022-10-10 14:53:15,917 [INFO] 	Process 7 - batch 47999: mean_policy_losses: -672.560, mean_net_lifetime: 3733.7278, mean_mc_travel_dist: 1355.9680, mean_rewards: 246.9760, total_rewards: 2425.5555, mean_steps: 14.4300, mean_ecr: 0.0418 mean_entropies: 1.1854, took: 74.0380s
2022-10-10 14:53:20,464 [INFO] 	Process 5 - batch 46999: mean_policy_losses: -358.783, mean_net_lifetime: 4637.5913, mean_mc_travel_dist: 1562.9071, mean_rewards: 257.5128, total_rewards: 3136.3639, mean_steps: 17.7500, mean_ecr: 0.0309 mean_entropies: 0.6887, took: 90.6861s
2022-10-10 14:53:44,669 [INFO] 	Process 4 - batch 53399: mean_policy_losses: 104.824, mean_net_lifetime: 4723.9465, mean_mc_travel_dist: 1383.6303, mean_rewards: 281.3511, total_rewards: 3369.7289, mean_steps: 15.8500, mean_ecr: 0.0478 mean_entropies: 0.6698, took: 83.3196s
2022-10-10 14:53:44,784 [INFO] 	Process 1 - batch 41399: mean_policy_losses: 25.302, mean_net_lifetime: 5328.1877, mean_mc_travel_dist: 1916.8485, mean_rewards: 263.6485, total_rewards: 3440.2108, mean_steps: 19.3800, mean_ecr: 0.0387 mean_entropies: 0.9116, took: 97.8780s
2022-10-10 14:53:59,872 [INFO] 	Process 3 - batch 48299: mean_policy_losses: 21.531, mean_net_lifetime: 4414.9005, mean_mc_travel_dist: 1219.1949, mean_rewards: 268.0505, total_rewards: 3224.6198, mean_steps: 15.5200, mean_ecr: 0.0487 mean_entropies: 0.5539, took: 78.1482s
2022-10-10 14:54:27,110 [INFO] 	Process 5 - batch 47099: mean_policy_losses: -592.558, mean_net_lifetime: 3352.8896, mean_mc_travel_dist: 1093.7338, mean_rewards: 243.0819, total_rewards: 2311.9139, mean_steps: 13.5000, mean_ecr: 0.0302 mean_entropies: 0.6591, took: 66.6462s
2022-10-10 14:54:29,907 [INFO] 	Process 2 - batch 47399: mean_policy_losses: -17.349, mean_net_lifetime: 4707.2201, mean_mc_travel_dist: 1323.4955, mean_rewards: 276.9669, total_rewards: 3410.5327, mean_steps: 16.1000, mean_ecr: 0.0407 mean_entropies: 0.4678, took: 78.3376s
2022-10-10 14:55:01,950 [INFO] 	Process 4 - batch 53499: mean_policy_losses: 58.069, mean_net_lifetime: 4642.2997, mean_mc_travel_dist: 1357.8891, mean_rewards: 282.3348, total_rewards: 3314.9759, mean_steps: 15.4900, mean_ecr: 0.0478 mean_entropies: 0.6496, took: 77.2810s
2022-10-10 14:55:15,787 [INFO] 	Process 3 - batch 48399: mean_policy_losses: 8.712, mean_net_lifetime: 4421.3259, mean_mc_travel_dist: 1225.8901, mean_rewards: 276.3053, total_rewards: 3220.1138, mean_steps: 15.0600, mean_ecr: 0.0486 mean_entropies: 0.5530, took: 75.9152s
2022-10-10 14:55:19,194 [INFO] 	Process 1 - batch 41499: mean_policy_losses: 25.226, mean_net_lifetime: 5410.6875, mean_mc_travel_dist: 1957.3108, mean_rewards: 263.0172, total_rewards: 3485.9672, mean_steps: 19.7200, mean_ecr: 0.0385 mean_entropies: 0.9059, took: 94.4107s
2022-10-10 14:55:48,206 [INFO] 	Process 2 - batch 47499: mean_policy_losses: -17.959, mean_net_lifetime: 4713.2234, mean_mc_travel_dist: 1297.2727, mean_rewards: 281.9636, total_rewards: 3439.6115, mean_steps: 15.8000, mean_ecr: 0.0408 mean_entropies: 0.4837, took: 78.2982s
2022-10-10 14:55:49,128 [INFO] 	Process 5 - batch 47199: mean_policy_losses: -352.321, mean_net_lifetime: 4474.8065, mean_mc_travel_dist: 1462.2006, mean_rewards: 259.4916, total_rewards: 3063.5533, mean_steps: 17.0100, mean_ecr: 0.0309 mean_entropies: 0.6857, took: 82.0170s
2022-10-10 14:56:25,849 [INFO] 	Process 4 - batch 53599: mean_policy_losses: 68.868, mean_net_lifetime: 4698.4037, mean_mc_travel_dist: 1365.4297, mean_rewards: 276.8260, total_rewards: 3354.0529, mean_steps: 16.0000, mean_ecr: 0.0479 mean_entropies: 0.6929, took: 83.8986s
2022-10-10 14:56:31,163 [INFO] 	Process 3 - batch 48499: mean_policy_losses: 6.720, mean_net_lifetime: 4492.0499, mean_mc_travel_dist: 1239.0198, mean_rewards: 283.2835, total_rewards: 3276.6847, mean_steps: 14.9000, mean_ecr: 0.0484 mean_entropies: 0.5468, took: 75.3754s
2022-10-10 14:56:54,432 [INFO] 	Process 1 - batch 41599: mean_policy_losses: -0.255, mean_net_lifetime: 5432.2570, mean_mc_travel_dist: 1917.9675, mean_rewards: 262.6445, total_rewards: 3539.0111, mean_steps: 19.7900, mean_ecr: 0.0388 mean_entropies: 0.9711, took: 95.2380s
2022-10-10 14:57:10,188 [INFO] 	Process 2 - batch 47599: mean_policy_losses: -29.329, mean_net_lifetime: 4708.7297, mean_mc_travel_dist: 1309.1675, mean_rewards: 281.7008, total_rewards: 3420.9355, mean_steps: 15.8000, mean_ecr: 0.0406 mean_entropies: 0.5270, took: 81.9821s
2022-10-10 14:57:22,826 [INFO] 	Process 5 - batch 47299: mean_policy_losses: -289.179, mean_net_lifetime: 5018.9362, mean_mc_travel_dist: 1655.3705, mean_rewards: 252.5224, total_rewards: 3410.3169, mean_steps: 19.4800, mean_ecr: 0.0310 mean_entropies: 0.7049, took: 93.6994s
2022-10-10 14:57:47,092 [INFO] 	Process 4 - batch 53699: mean_policy_losses: 86.971, mean_net_lifetime: 4730.0542, mean_mc_travel_dist: 1355.3500, mean_rewards: 288.0609, total_rewards: 3401.1391, mean_steps: 15.4800, mean_ecr: 0.0478 mean_entropies: 0.6873, took: 81.2436s
2022-10-10 14:57:49,032 [INFO] 	Process 3 - batch 48599: mean_policy_losses: 6.025, mean_net_lifetime: 4450.4763, mean_mc_travel_dist: 1236.9831, mean_rewards: 272.2150, total_rewards: 3245.6760, mean_steps: 15.4100, mean_ecr: 0.0486 mean_entropies: 0.5540, took: 77.8680s
2022-10-10 14:58:30,729 [INFO] 	Process 1 - batch 41699: mean_policy_losses: 36.025, mean_net_lifetime: 5397.5934, mean_mc_travel_dist: 1859.5175, mean_rewards: 255.9497, total_rewards: 3566.5088, mean_steps: 20.2200, mean_ecr: 0.0388 mean_entropies: 1.0034, took: 96.2966s
2022-10-10 14:58:32,083 [INFO] 	Process 2 - batch 47699: mean_policy_losses: -34.970, mean_net_lifetime: 4712.5190, mean_mc_travel_dist: 1302.5325, mean_rewards: 278.6425, total_rewards: 3427.4865, mean_steps: 16.0000, mean_ecr: 0.0408 mean_entropies: 0.4673, took: 81.8949s
2022-10-10 14:58:47,792 [INFO] 	Process 5 - batch 47399: mean_policy_losses: -453.187, mean_net_lifetime: 4440.9734, mean_mc_travel_dist: 1468.7094, mean_rewards: 256.1136, total_rewards: 3034.4001, mean_steps: 17.4300, mean_ecr: 0.0302 mean_entropies: 0.6818, took: 84.9652s
2022-10-10 14:59:05,473 [INFO] 	Process 3 - batch 48699: mean_policy_losses: 9.003, mean_net_lifetime: 4556.9823, mean_mc_travel_dist: 1253.3894, mean_rewards: 281.9268, total_rewards: 3333.8622, mean_steps: 15.2300, mean_ecr: 0.0484 mean_entropies: 0.5348, took: 76.4422s
2022-10-10 14:59:11,679 [INFO] 	Process 4 - batch 53799: mean_policy_losses: 87.976, mean_net_lifetime: 4912.7483, mean_mc_travel_dist: 1404.8132, mean_rewards: 294.8560, total_rewards: 3537.0896, mean_steps: 15.7200, mean_ecr: 0.0474 mean_entropies: 0.6438, took: 84.5867s
2022-10-10 14:59:56,386 [INFO] 	Process 2 - batch 47799: mean_policy_losses: -31.488, mean_net_lifetime: 4714.2420, mean_mc_travel_dist: 1308.2529, mean_rewards: 280.9270, total_rewards: 3422.8469, mean_steps: 15.8500, mean_ecr: 0.0407 mean_entropies: 0.4822, took: 84.3030s
2022-10-10 15:00:10,153 [INFO] 	Process 1 - batch 41799: mean_policy_losses: 44.409, mean_net_lifetime: 5669.8341, mean_mc_travel_dist: 1939.2844, mean_rewards: 259.3672, total_rewards: 3756.0236, mean_steps: 21.0000, mean_ecr: 0.0386 mean_entropies: 0.9668, took: 99.4236s
2022-10-10 15:00:13,135 [INFO] 	Process 5 - batch 47499: mean_policy_losses: -420.232, mean_net_lifetime: 4537.7279, mean_mc_travel_dist: 1505.6158, mean_rewards: 257.3580, total_rewards: 3082.4032, mean_steps: 17.6100, mean_ecr: 0.0306 mean_entropies: 0.6940, took: 85.3433s
2022-10-10 15:00:22,080 [INFO] 	Process 3 - batch 48799: mean_policy_losses: 3.051, mean_net_lifetime: 4502.6038, mean_mc_travel_dist: 1255.0974, mean_rewards: 276.5079, total_rewards: 3284.7108, mean_steps: 15.3600, mean_ecr: 0.0485 mean_entropies: 0.5651, took: 76.6075s
2022-10-10 15:00:38,804 [INFO] 	Process 4 - batch 53899: mean_policy_losses: 83.674, mean_net_lifetime: 4912.4973, mean_mc_travel_dist: 1386.7031, mean_rewards: 280.2958, total_rewards: 3550.3232, mean_steps: 16.5500, mean_ecr: 0.0473 mean_entropies: 0.6991, took: 87.1247s
2022-10-10 15:01:19,583 [INFO] 	Process 2 - batch 47899: mean_policy_losses: -19.810, mean_net_lifetime: 4719.6649, mean_mc_travel_dist: 1333.1817, mean_rewards: 283.2643, total_rewards: 3414.5239, mean_steps: 15.7400, mean_ecr: 0.0406 mean_entropies: 0.5125, took: 83.1974s
2022-10-10 15:01:33,178 [INFO] 	Process 5 - batch 47599: mean_policy_losses: -377.328, mean_net_lifetime: 4508.8039, mean_mc_travel_dist: 1485.5608, mean_rewards: 272.3016, total_rewards: 3068.9288, mean_steps: 16.4800, mean_ecr: 0.0307 mean_entropies: 0.6913, took: 80.0435s
2022-10-10 15:01:39,913 [INFO] 	Process 3 - batch 48899: mean_policy_losses: 18.261, mean_net_lifetime: 4634.7331, mean_mc_travel_dist: 1291.0281, mean_rewards: 281.5744, total_rewards: 3376.1710, mean_steps: 15.5300, mean_ecr: 0.0481 mean_entropies: 0.5523, took: 77.8327s
2022-10-10 15:01:49,079 [INFO] 	Process 1 - batch 41899: mean_policy_losses: -39.841, mean_net_lifetime: 5482.8112, mean_mc_travel_dist: 1951.0035, mean_rewards: 249.7998, total_rewards: 3555.4158, mean_steps: 21.3000, mean_ecr: 0.0384 mean_entropies: 0.9019, took: 98.9260s
2022-10-10 15:02:04,202 [INFO] 	Process 4 - batch 53999: mean_policy_losses: 51.908, mean_net_lifetime: 4690.4628, mean_mc_travel_dist: 1368.5541, mean_rewards: 273.3021, total_rewards: 3356.6879, mean_steps: 16.1800, mean_ecr: 0.0478 mean_entropies: 0.6645, took: 85.3987s
2022-10-10 15:02:38,556 [INFO] 	Process 2 - batch 47999: mean_policy_losses: -16.347, mean_net_lifetime: 4730.1210, mean_mc_travel_dist: 1354.2405, mean_rewards: 280.7955, total_rewards: 3402.6856, mean_steps: 15.9600, mean_ecr: 0.0404 mean_entropies: 0.5344, took: 78.9724s
2022-10-10 15:02:42,687 [INFO] Process 6 - epoch 45: mean_policy_losses: -254.208, mean_net_lifetime: 2730.1491, mean_mc_travel_dist: 951.9475, mean_entropies: 0.7998, m_net_lifetime_valid: 4513.0459, took: 1375.8617s, (112.4226 / 100 batches)

2022-10-10 15:02:51,619 [INFO] 	Process 5 - batch 47699: mean_policy_losses: -404.965, mean_net_lifetime: 4466.8058, mean_mc_travel_dist: 1494.7840, mean_rewards: 265.6333, total_rewards: 3031.2103, mean_steps: 16.7000, mean_ecr: 0.0304 mean_entropies: 0.6955, took: 78.4406s
2022-10-10 15:02:53,867 [INFO] 	Process 3 - batch 48999: mean_policy_losses: 26.033, mean_net_lifetime: 4540.0606, mean_mc_travel_dist: 1272.4349, mean_rewards: 284.1489, total_rewards: 3302.4410, mean_steps: 15.0600, mean_ecr: 0.0483 mean_entropies: 0.5355, took: 73.9532s
2022-10-10 15:03:22,748 [INFO] 	Process 1 - batch 41999: mean_policy_losses: 15.811, mean_net_lifetime: 5500.4524, mean_mc_travel_dist: 1916.9116, mean_rewards: 252.7883, total_rewards: 3625.7241, mean_steps: 20.9500, mean_ecr: 0.0386 mean_entropies: 0.9182, took: 93.6693s
2022-10-10 15:03:28,940 [INFO] 	Process 6 - batch 67599: mean_policy_losses: -204.189, mean_net_lifetime: 3209.9674, mean_mc_travel_dist: 869.7445, mean_rewards: 329.3251, total_rewards: 2355.2112, mean_steps: 8.7400, mean_ecr: 0.0562 mean_entropies: 0.2215, took: 616.0063s
2022-10-10 15:04:07,202 [INFO] 	Process 3 - batch 49099: mean_policy_losses: 31.120, mean_net_lifetime: 4481.2445, mean_mc_travel_dist: 1244.2084, mean_rewards: 272.9514, total_rewards: 3271.7588, mean_steps: 15.4700, mean_ecr: 0.0484 mean_entropies: 0.5752, took: 73.3361s
2022-10-10 15:04:13,177 [INFO] Process 7 - epoch 32: mean_policy_losses: -256.587, mean_net_lifetime: 3965.3317, mean_mc_travel_dist: 1597.3379, mean_entropies: 1.7423, m_net_lifetime_valid: 4780.0898, took: 1673.4211s, (158.0063 / 100 batches)

2022-10-10 15:04:15,468 [INFO] 	Process 6 - batch 67699: mean_policy_losses: -310.594, mean_net_lifetime: 3354.7452, mean_mc_travel_dist: 898.0328, mean_rewards: 322.2048, total_rewards: 2465.7880, mean_steps: 9.4100, mean_ecr: 0.0562 mean_entropies: 0.1866, took: 46.5282s
2022-10-10 15:04:19,614 [INFO] 	Process 5 - batch 47799: mean_policy_losses: -188.479, mean_net_lifetime: 5315.8823, mean_mc_travel_dist: 1764.6894, mean_rewards: 261.0866, total_rewards: 3611.0954, mean_steps: 19.9800, mean_ecr: 0.0312 mean_entropies: 0.6774, took: 87.9947s
2022-10-10 15:05:06,375 [INFO] 	Process 6 - batch 67799: mean_policy_losses: -127.364, mean_net_lifetime: 3601.7478, mean_mc_travel_dist: 962.4352, mean_rewards: 320.5124, total_rewards: 2660.4113, mean_steps: 10.2400, mean_ecr: 0.0558 mean_entropies: 0.1858, took: 50.9066s
2022-10-10 15:05:22,385 [INFO] 	Process 3 - batch 49199: mean_policy_losses: 52.269, mean_net_lifetime: 4477.6600, mean_mc_travel_dist: 1222.5780, mean_rewards: 268.5867, total_rewards: 3280.5707, mean_steps: 15.7500, mean_ecr: 0.0485 mean_entropies: 0.5451, took: 75.1829s
2022-10-10 15:05:33,360 [INFO] 	Process 7 - batch 48099: mean_policy_losses: -578.185, mean_net_lifetime: 4085.2061, mean_mc_travel_dist: 1379.0417, mean_rewards: 226.2665, total_rewards: 2755.7332, mean_steps: 17.0000, mean_ecr: 0.0417 mean_entropies: 1.2666, took: 737.4427s
2022-10-10 15:05:45,912 [INFO] 	Process 5 - batch 47899: mean_policy_losses: -226.941, mean_net_lifetime: 5066.4712, mean_mc_travel_dist: 1674.0768, mean_rewards: 264.7373, total_rewards: 3442.5808, mean_steps: 18.8400, mean_ecr: 0.0311 mean_entropies: 0.6657, took: 86.2981s
2022-10-10 15:05:57,994 [INFO] 	Process 6 - batch 67899: mean_policy_losses: -143.994, mean_net_lifetime: 3530.9132, mean_mc_travel_dist: 948.6931, mean_rewards: 323.9807, total_rewards: 2599.6080, mean_steps: 9.9300, mean_ecr: 0.0558 mean_entropies: 0.1761, took: 51.6191s
2022-10-10 15:06:36,953 [INFO] 	Process 3 - batch 49299: mean_policy_losses: 31.465, mean_net_lifetime: 4441.7130, mean_mc_travel_dist: 1226.8764, mean_rewards: 269.1353, total_rewards: 3239.5289, mean_steps: 15.5700, mean_ecr: 0.0484 mean_entropies: 0.5476, took: 74.5677s
2022-10-10 15:06:47,307 [INFO] 	Process 6 - batch 67999: mean_policy_losses: -167.731, mean_net_lifetime: 3425.8940, mean_mc_travel_dist: 920.7118, mean_rewards: 325.0305, total_rewards: 2523.2895, mean_steps: 9.5600, mean_ecr: 0.0560 mean_entropies: 0.1921, took: 49.3128s
2022-10-10 15:07:00,071 [INFO] 	Process 7 - batch 48199: mean_policy_losses: -483.237, mean_net_lifetime: 4410.9243, mean_mc_travel_dist: 1479.9750, mean_rewards: 229.8463, total_rewards: 2972.8398, mean_steps: 18.1800, mean_ecr: 0.0415 mean_entropies: 1.3109, took: 86.7107s
2022-10-10 15:07:20,858 [INFO] 	Process 5 - batch 47999: mean_policy_losses: -103.195, mean_net_lifetime: 5619.2947, mean_mc_travel_dist: 1893.7838, mean_rewards: 258.3576, total_rewards: 3775.0562, mean_steps: 20.9600, mean_ecr: 0.0314 mean_entropies: 0.6520, took: 94.9454s
2022-10-10 15:07:38,987 [INFO] 	Process 6 - batch 68099: mean_policy_losses: -111.369, mean_net_lifetime: 3637.1116, mean_mc_travel_dist: 973.2498, mean_rewards: 319.8394, total_rewards: 2691.2499, mean_steps: 10.4100, mean_ecr: 0.0558 mean_entropies: 0.1784, took: 51.6801s
2022-10-10 15:07:51,831 [INFO] 	Process 3 - batch 49399: mean_policy_losses: 30.413, mean_net_lifetime: 4458.9548, mean_mc_travel_dist: 1225.7020, mean_rewards: 270.6395, total_rewards: 3258.9880, mean_steps: 15.5400, mean_ecr: 0.0486 mean_entropies: 0.5321, took: 74.8778s
2022-10-10 15:08:24,830 [INFO] 	Process 7 - batch 48299: mean_policy_losses: -412.114, mean_net_lifetime: 4620.0359, mean_mc_travel_dist: 1567.1491, mean_rewards: 229.2000, total_rewards: 3105.4491, mean_steps: 19.2200, mean_ecr: 0.0409 mean_entropies: 1.2733, took: 84.7591s
2022-10-10 15:08:27,621 [INFO] 	Process 6 - batch 68199: mean_policy_losses: -172.541, mean_net_lifetime: 3633.0736, mean_mc_travel_dist: 967.0601, mean_rewards: 327.5250, total_rewards: 2672.7884, mean_steps: 10.1100, mean_ecr: 0.0557 mean_entropies: 0.1693, took: 48.6341s
2022-10-10 15:09:06,271 [INFO] 	Process 3 - batch 49499: mean_policy_losses: 13.405, mean_net_lifetime: 4431.7389, mean_mc_travel_dist: 1206.5317, mean_rewards: 258.2262, total_rewards: 3253.2053, mean_steps: 16.2300, mean_ecr: 0.0487 mean_entropies: 0.4987, took: 74.4410s
2022-10-10 15:09:18,729 [INFO] 	Process 6 - batch 68299: mean_policy_losses: -177.367, mean_net_lifetime: 3609.3327, mean_mc_travel_dist: 958.9650, mean_rewards: 320.5532, total_rewards: 2672.0451, mean_steps: 10.3300, mean_ecr: 0.0557 mean_entropies: 0.1738, took: 51.1085s
2022-10-10 15:09:44,942 [INFO] 	Process 7 - batch 48399: mean_policy_losses: -431.895, mean_net_lifetime: 4417.9465, mean_mc_travel_dist: 1526.1162, mean_rewards: 223.9694, total_rewards: 2930.7506, mean_steps: 19.1100, mean_ecr: 0.0412 mean_entropies: 1.1962, took: 80.1117s
2022-10-10 15:10:11,625 [INFO] 	Process 6 - batch 68399: mean_policy_losses: -8.951, mean_net_lifetime: 3893.4701, mean_mc_travel_dist: 1032.6282, mean_rewards: 315.2221, total_rewards: 2893.7096, mean_steps: 11.3800, mean_ecr: 0.0554 mean_entropies: 0.1784, took: 52.8955s
2022-10-10 15:10:21,857 [INFO] Process 4 - epoch 36: mean_policy_losses: 86.704, mean_net_lifetime: 3820.6834, mean_mc_travel_dist: 1298.9029, mean_entropies: 1.3638, m_net_lifetime_valid: 4325.1442, took: 1740.2352s, (141.4589 / 100 batches)

2022-10-10 15:11:04,438 [INFO] 	Process 6 - batch 68499: mean_policy_losses: -119.804, mean_net_lifetime: 3718.0198, mean_mc_travel_dist: 989.4075, mean_rewards: 317.4481, total_rewards: 2750.3356, mean_steps: 10.7500, mean_ecr: 0.0557 mean_entropies: 0.1635, took: 52.8135s
2022-10-10 15:11:12,304 [INFO] 	Process 7 - batch 48499: mean_policy_losses: -354.652, mean_net_lifetime: 4814.5399, mean_mc_travel_dist: 1626.6327, mean_rewards: 224.4323, total_rewards: 3234.3276, mean_steps: 20.8500, mean_ecr: 0.0406 mean_entropies: 1.1635, took: 87.3621s
2022-10-10 15:11:25,718 [INFO] Process 2 - epoch 32: mean_policy_losses: 9.114, mean_net_lifetime: 4268.2532, mean_mc_travel_dist: 1587.2523, mean_entropies: 1.1392, m_net_lifetime_valid: 4769.7578, took: 1742.0216s, (159.1764 / 100 batches)

2022-10-10 15:11:40,624 [INFO] 	Process 4 - batch 54099: mean_policy_losses: 153.546, mean_net_lifetime: 5155.1035, mean_mc_travel_dist: 1478.9433, mean_rewards: 281.9164, total_rewards: 3700.0187, mean_steps: 17.3200, mean_ecr: 0.0463 mean_entropies: 0.5906, took: 576.4223s
2022-10-10 15:11:55,203 [INFO] 	Process 6 - batch 68599: mean_policy_losses: -89.645, mean_net_lifetime: 3549.4994, mean_mc_travel_dist: 953.4443, mean_rewards: 319.5389, total_rewards: 2626.7861, mean_steps: 10.1300, mean_ecr: 0.0556 mean_entropies: 0.1973, took: 50.7648s
2022-10-10 15:11:59,008 [INFO] Process 1 - epoch 28: mean_policy_losses: 46.146, mean_net_lifetime: 4783.4956, mean_mc_travel_dist: 2055.1426, mean_entropies: 1.3449, m_net_lifetime_valid: 4466.9809, took: 1974.8136s, (181.9666 / 100 batches)

2022-10-10 15:12:42,514 [INFO] 	Process 7 - batch 48599: mean_policy_losses: -536.752, mean_net_lifetime: 4573.8662, mean_mc_travel_dist: 1588.3701, mean_rewards: 226.1011, total_rewards: 3017.2874, mean_steps: 20.0200, mean_ecr: 0.0408 mean_entropies: 1.2128, took: 90.2094s
2022-10-10 15:12:46,663 [INFO] 	Process 2 - batch 48099: mean_policy_losses: -8.152, mean_net_lifetime: 4699.9282, mean_mc_travel_dist: 1313.9327, mean_rewards: 266.4940, total_rewards: 3403.0488, mean_steps: 16.7300, mean_ecr: 0.0408 mean_entropies: 0.3785, took: 608.1079s
2022-10-10 15:12:49,314 [INFO] 	Process 6 - batch 68699: mean_policy_losses: -106.107, mean_net_lifetime: 3666.4081, mean_mc_travel_dist: 983.1770, mean_rewards: 324.3271, total_rewards: 2705.4400, mean_steps: 10.3600, mean_ecr: 0.0557 mean_entropies: 0.1832, took: 54.1111s
2022-10-10 15:13:02,340 [INFO] 	Process 4 - batch 54199: mean_policy_losses: 127.566, mean_net_lifetime: 4869.1402, mean_mc_travel_dist: 1374.7786, mean_rewards: 279.6690, total_rewards: 3521.5688, mean_steps: 16.5000, mean_ecr: 0.0473 mean_entropies: 0.6334, took: 81.7151s
2022-10-10 15:13:28,034 [INFO] 	Process 1 - batch 42099: mean_policy_losses: -62.501, mean_net_lifetime: 5011.4108, mean_mc_travel_dist: 1861.5053, mean_rewards: 252.4481, total_rewards: 3184.6386, mean_steps: 19.0100, mean_ecr: 0.0388 mean_entropies: 0.7982, took: 605.2859s
2022-10-10 15:13:42,495 [INFO] 	Process 6 - batch 68799: mean_policy_losses: -116.230, mean_net_lifetime: 3630.9505, mean_mc_travel_dist: 964.8122, mean_rewards: 326.0076, total_rewards: 2685.7972, mean_steps: 10.1900, mean_ecr: 0.0555 mean_entropies: 0.1712, took: 53.1807s
2022-10-10 15:14:08,147 [INFO] 	Process 2 - batch 48199: mean_policy_losses: -9.717, mean_net_lifetime: 4696.3909, mean_mc_travel_dist: 1318.6571, mean_rewards: 265.8623, total_rewards: 3400.8262, mean_steps: 16.7600, mean_ecr: 0.0408 mean_entropies: 0.3735, took: 81.4834s
2022-10-10 15:14:11,803 [INFO] 	Process 7 - batch 48699: mean_policy_losses: -641.292, mean_net_lifetime: 4255.8349, mean_mc_travel_dist: 1494.0616, mean_rewards: 224.5630, total_rewards: 2797.7899, mean_steps: 18.9200, mean_ecr: 0.0410 mean_entropies: 1.2119, took: 89.2893s
2022-10-10 15:14:25,106 [INFO] 	Process 4 - batch 54299: mean_policy_losses: 133.869, mean_net_lifetime: 5028.0178, mean_mc_travel_dist: 1411.5407, mean_rewards: 286.1414, total_rewards: 3645.8154, mean_steps: 16.6700, mean_ecr: 0.0469 mean_entropies: 0.6073, took: 82.7659s
2022-10-10 15:14:39,615 [INFO] 	Process 6 - batch 68899: mean_policy_losses: -79.057, mean_net_lifetime: 3766.2666, mean_mc_travel_dist: 996.2320, mean_rewards: 312.6707, total_rewards: 2789.5352, mean_steps: 11.0900, mean_ecr: 0.0555 mean_entropies: 0.1811, took: 57.1205s
2022-10-10 15:15:01,972 [INFO] 	Process 1 - batch 42199: mean_policy_losses: -13.425, mean_net_lifetime: 5079.7376, mean_mc_travel_dist: 1882.3447, mean_rewards: 247.2998, total_rewards: 3221.4238, mean_steps: 19.7900, mean_ecr: 0.0386 mean_entropies: 0.8226, took: 93.9381s
2022-10-10 15:15:26,380 [INFO] 	Process 7 - batch 48799: mean_policy_losses: -876.673, mean_net_lifetime: 3684.4716, mean_mc_travel_dist: 1417.5903, mean_rewards: 234.5838, total_rewards: 2312.6688, mean_steps: 15.2700, mean_ecr: 0.0416 mean_entropies: 1.2155, took: 74.5772s
2022-10-10 15:15:29,276 [INFO] 	Process 2 - batch 48299: mean_policy_losses: -9.512, mean_net_lifetime: 4673.1460, mean_mc_travel_dist: 1293.9656, mean_rewards: 268.2326, total_rewards: 3403.6860, mean_steps: 16.5100, mean_ecr: 0.0408 mean_entropies: 0.3974, took: 81.1290s
2022-10-10 15:15:30,977 [INFO] 	Process 6 - batch 68999: mean_policy_losses: -77.417, mean_net_lifetime: 3486.9175, mean_mc_travel_dist: 923.4551, mean_rewards: 328.2904, total_rewards: 2587.2889, mean_steps: 9.6500, mean_ecr: 0.0558 mean_entropies: 0.1787, took: 51.3616s
2022-10-10 15:15:50,020 [INFO] 	Process 4 - batch 54399: mean_policy_losses: 125.111, mean_net_lifetime: 5156.2612, mean_mc_travel_dist: 1464.1250, mean_rewards: 289.8767, total_rewards: 3723.5392, mean_steps: 16.9100, mean_ecr: 0.0463 mean_entropies: 0.6081, took: 84.9149s
2022-10-10 15:16:26,512 [INFO] 	Process 7 - batch 48899: mean_policy_losses: -913.483, mean_net_lifetime: 3251.0768, mean_mc_travel_dist: 1269.0470, mean_rewards: 258.4497, total_rewards: 2034.3454, mean_steps: 12.1300, mean_ecr: 0.0419 mean_entropies: 1.1768, took: 60.1335s
2022-10-10 15:16:30,871 [INFO] 	Process 1 - batch 42299: mean_policy_losses: 7.605, mean_net_lifetime: 5189.7191, mean_mc_travel_dist: 1910.5401, mean_rewards: 256.3890, total_rewards: 3303.5042, mean_steps: 19.5400, mean_ecr: 0.0386 mean_entropies: 0.8646, took: 88.8993s
2022-10-10 15:16:41,694 [INFO] Process 5 - epoch 32: mean_policy_losses: -210.319, mean_net_lifetime: 4477.0235, mean_mc_travel_dist: 1929.0704, mean_entropies: 1.4337, m_net_lifetime_valid: 4720.4382, took: 1807.1682s, (159.7631 / 100 batches)

2022-10-10 15:16:46,836 [INFO] 	Process 2 - batch 48399: mean_policy_losses: -13.735, mean_net_lifetime: 4639.9937, mean_mc_travel_dist: 1354.4470, mean_rewards: 275.8224, total_rewards: 3317.5530, mean_steps: 15.9200, mean_ecr: 0.0403 mean_entropies: 0.4677, took: 77.5604s
2022-10-10 15:17:04,015 [INFO] 	Process 4 - batch 54499: mean_policy_losses: 80.480, mean_net_lifetime: 4398.5342, mean_mc_travel_dist: 1331.7715, mean_rewards: 278.6086, total_rewards: 3095.4552, mean_steps: 14.7000, mean_ecr: 0.0481 mean_entropies: 0.5689, took: 73.9942s
2022-10-10 15:17:22,131 [INFO] 	Process 7 - batch 48999: mean_policy_losses: -597.176, mean_net_lifetime: 3079.8297, mean_mc_travel_dist: 1187.5435, mean_rewards: 261.6984, total_rewards: 1929.2206, mean_steps: 10.9900, mean_ecr: 0.0422 mean_entropies: 1.0106, took: 55.6184s
2022-10-10 15:17:44,357 [INFO] 	Process 5 - batch 48099: mean_policy_losses: -341.008, mean_net_lifetime: 3464.5167, mean_mc_travel_dist: 1126.5340, mean_rewards: 276.9445, total_rewards: 2390.6641, mean_steps: 12.5200, mean_ecr: 0.0302 mean_entropies: 0.6513, took: 623.4994s
2022-10-10 15:17:53,873 [INFO] 	Process 1 - batch 42399: mean_policy_losses: 59.746, mean_net_lifetime: 4912.6316, mean_mc_travel_dist: 2000.3163, mean_rewards: 271.1086, total_rewards: 2937.7336, mean_steps: 17.2800, mean_ecr: 0.0385 mean_entropies: 0.7172, took: 83.0020s
2022-10-10 15:18:04,106 [INFO] 	Process 2 - batch 48499: mean_policy_losses: 48.812, mean_net_lifetime: 4628.0839, mean_mc_travel_dist: 1395.0232, mean_rewards: 284.4264, total_rewards: 3261.7899, mean_steps: 15.3400, mean_ecr: 0.0401 mean_entropies: 0.4805, took: 77.2700s
2022-10-10 15:18:09,933 [INFO] Process 3 - epoch 33: mean_policy_losses: 86.677, mean_net_lifetime: 4129.6005, mean_mc_travel_dist: 1402.7894, mean_entropies: 1.1014, m_net_lifetime_valid: 4146.0328, took: 1690.8945s, (155.1427 / 100 batches)

2022-10-10 15:18:26,493 [INFO] 	Process 4 - batch 54599: mean_policy_losses: 159.712, mean_net_lifetime: 4854.3355, mean_mc_travel_dist: 1420.6084, mean_rewards: 280.4364, total_rewards: 3462.7487, mean_steps: 16.3600, mean_ecr: 0.0472 mean_entropies: 0.6224, took: 82.4785s
2022-10-10 15:18:32,189 [INFO] 	Process 7 - batch 49099: mean_policy_losses: -759.537, mean_net_lifetime: 3706.0793, mean_mc_travel_dist: 1375.7994, mean_rewards: 258.9363, total_rewards: 2378.1126, mean_steps: 14.2100, mean_ecr: 0.0414 mean_entropies: 1.2005, took: 70.0577s
2022-10-10 15:19:15,614 [INFO] 	Process 5 - batch 48199: mean_policy_losses: -361.617, mean_net_lifetime: 4840.1804, mean_mc_travel_dist: 1651.7297, mean_rewards: 263.4481, total_rewards: 3246.0587, mean_steps: 18.6600, mean_ecr: 0.0298 mean_entropies: 0.6367, took: 91.2568s
2022-10-10 15:19:27,758 [INFO] 	Process 3 - batch 49599: mean_policy_losses: 29.687, mean_net_lifetime: 4429.6276, mean_mc_travel_dist: 1211.7387, mean_rewards: 277.0189, total_rewards: 3244.0436, mean_steps: 15.0400, mean_ecr: 0.0485 mean_entropies: 0.5149, took: 621.4857s
2022-10-10 15:19:29,469 [INFO] 	Process 2 - batch 48599: mean_policy_losses: -22.099, mean_net_lifetime: 4705.8536, mean_mc_travel_dist: 1316.9110, mean_rewards: 279.6657, total_rewards: 3407.8896, mean_steps: 15.9100, mean_ecr: 0.0408 mean_entropies: 0.4462, took: 85.3625s
2022-10-10 15:19:35,010 [INFO] 	Process 1 - batch 42499: mean_policy_losses: -15.738, mean_net_lifetime: 5217.5884, mean_mc_travel_dist: 1935.7491, mean_rewards: 241.8035, total_rewards: 3304.7412, mean_steps: 20.9600, mean_ecr: 0.0385 mean_entropies: 0.7967, took: 101.1358s
2022-10-10 15:19:50,438 [INFO] 	Process 7 - batch 49199: mean_policy_losses: -784.437, mean_net_lifetime: 3762.2002, mean_mc_travel_dist: 1400.1729, mean_rewards: 254.2530, total_rewards: 2407.4450, mean_steps: 14.8500, mean_ecr: 0.0414 mean_entropies: 1.1676, took: 78.2490s
2022-10-10 15:19:54,785 [INFO] 	Process 4 - batch 54699: mean_policy_losses: 89.255, mean_net_lifetime: 4887.3630, mean_mc_travel_dist: 1420.0628, mean_rewards: 276.6327, total_rewards: 3495.8972, mean_steps: 16.7400, mean_ecr: 0.0471 mean_entropies: 0.5992, took: 88.2915s
2022-10-10 15:20:36,079 [INFO] 	Process 5 - batch 48299: mean_policy_losses: -397.028, mean_net_lifetime: 4318.5697, mean_mc_travel_dist: 1449.6192, mean_rewards: 274.2669, total_rewards: 2923.9062, mean_steps: 15.9000, mean_ecr: 0.0302 mean_entropies: 0.6519, took: 80.4653s
2022-10-10 15:20:44,513 [INFO] 	Process 3 - batch 49699: mean_policy_losses: 49.329, mean_net_lifetime: 4388.9373, mean_mc_travel_dist: 1221.0994, mean_rewards: 277.9580, total_rewards: 3199.6972, mean_steps: 14.8500, mean_ecr: 0.0486 mean_entropies: 0.5525, took: 76.7550s
2022-10-10 15:20:48,185 [INFO] 	Process 2 - batch 48699: mean_policy_losses: -7.178, mean_net_lifetime: 4700.9286, mean_mc_travel_dist: 1327.3042, mean_rewards: 284.4919, total_rewards: 3397.7034, mean_steps: 15.6100, mean_ecr: 0.0407 mean_entropies: 0.4689, took: 78.7160s
2022-10-10 15:21:02,609 [INFO] 	Process 7 - batch 49299: mean_policy_losses: -689.803, mean_net_lifetime: 3826.8516, mean_mc_travel_dist: 1453.4940, mean_rewards: 257.8745, total_rewards: 2414.9987, mean_steps: 14.4700, mean_ecr: 0.0414 mean_entropies: 1.1318, took: 72.1708s
2022-10-10 15:21:04,522 [INFO] 	Process 1 - batch 42599: mean_policy_losses: -81.094, mean_net_lifetime: 4963.6342, mean_mc_travel_dist: 1933.0948, mean_rewards: 260.4598, total_rewards: 3062.4815, mean_steps: 18.2000, mean_ecr: 0.0387 mean_entropies: 0.7772, took: 89.5126s
2022-10-10 15:21:17,652 [INFO] 	Process 4 - batch 54799: mean_policy_losses: 105.710, mean_net_lifetime: 4776.1476, mean_mc_travel_dist: 1396.8690, mean_rewards: 280.2366, total_rewards: 3407.3437, mean_steps: 16.0700, mean_ecr: 0.0475 mean_entropies: 0.6116, took: 82.8670s
2022-10-10 15:22:00,301 [INFO] 	Process 3 - batch 49799: mean_policy_losses: 34.564, mean_net_lifetime: 4416.2777, mean_mc_travel_dist: 1203.2152, mean_rewards: 285.0349, total_rewards: 3236.5691, mean_steps: 14.5200, mean_ecr: 0.0488 mean_entropies: 0.5382, took: 75.7884s
2022-10-10 15:22:01,090 [INFO] 	Process 5 - batch 48399: mean_policy_losses: -431.648, mean_net_lifetime: 4556.0692, mean_mc_travel_dist: 1537.1275, mean_rewards: 268.7497, total_rewards: 3074.7904, mean_steps: 17.1300, mean_ecr: 0.0300 mean_entropies: 0.6820, took: 85.0105s
2022-10-10 15:22:07,015 [INFO] 	Process 2 - batch 48799: mean_policy_losses: -18.292, mean_net_lifetime: 4705.2876, mean_mc_travel_dist: 1298.1423, mean_rewards: 284.3772, total_rewards: 3422.9073, mean_steps: 15.6300, mean_ecr: 0.0408 mean_entropies: 0.4751, took: 78.8303s
2022-10-10 15:22:23,551 [INFO] 	Process 7 - batch 49399: mean_policy_losses: -692.697, mean_net_lifetime: 4080.6622, mean_mc_travel_dist: 1451.2367, mean_rewards: 240.6989, total_rewards: 2674.8105, mean_steps: 16.4800, mean_ecr: 0.0415 mean_entropies: 1.2765, took: 80.9426s
2022-10-10 15:22:41,654 [INFO] 	Process 4 - batch 54899: mean_policy_losses: 77.498, mean_net_lifetime: 4735.7029, mean_mc_travel_dist: 1375.2488, mean_rewards: 275.2475, total_rewards: 3387.3772, mean_steps: 16.2600, mean_ecr: 0.0475 mean_entropies: 0.6520, took: 84.0023s
2022-10-10 15:22:47,553 [INFO] 	Process 1 - batch 42699: mean_policy_losses: -13.936, mean_net_lifetime: 5375.6863, mean_mc_travel_dist: 1963.6361, mean_rewards: 247.4681, total_rewards: 3442.7959, mean_steps: 20.9700, mean_ecr: 0.0384 mean_entropies: 0.8155, took: 103.0309s
2022-10-10 15:23:16,920 [INFO] 	Process 3 - batch 49899: mean_policy_losses: 30.746, mean_net_lifetime: 4512.5114, mean_mc_travel_dist: 1272.4336, mean_rewards: 290.0602, total_rewards: 3271.7947, mean_steps: 14.6100, mean_ecr: 0.0483 mean_entropies: 0.5500, took: 76.6180s
2022-10-10 15:23:25,578 [INFO] 	Process 2 - batch 48899: mean_policy_losses: -35.012, mean_net_lifetime: 4726.7683, mean_mc_travel_dist: 1347.6207, mean_rewards: 288.7596, total_rewards: 3405.8745, mean_steps: 15.4700, mean_ecr: 0.0405 mean_entropies: 0.5137, took: 78.5631s
2022-10-10 15:23:37,266 [INFO] 	Process 5 - batch 48499: mean_policy_losses: -319.482, mean_net_lifetime: 5312.4495, mean_mc_travel_dist: 1819.6582, mean_rewards: 266.4243, total_rewards: 3543.3702, mean_steps: 19.4200, mean_ecr: 0.0302 mean_entropies: 0.6912, took: 96.1765s
2022-10-10 15:23:46,382 [INFO] 	Process 7 - batch 49499: mean_policy_losses: -718.333, mean_net_lifetime: 4175.3937, mean_mc_travel_dist: 1518.6799, mean_rewards: 237.7710, total_rewards: 2707.2623, mean_steps: 16.9200, mean_ecr: 0.0413 mean_entropies: 1.2899, took: 82.8302s
2022-10-10 15:24:05,140 [INFO] 	Process 4 - batch 54999: mean_policy_losses: 108.262, mean_net_lifetime: 4946.1924, mean_mc_travel_dist: 1411.6116, mean_rewards: 284.7930, total_rewards: 3560.7146, mean_steps: 16.4600, mean_ecr: 0.0472 mean_entropies: 0.6537, took: 83.4862s
2022-10-10 15:24:25,180 [INFO] 	Process 1 - batch 42799: mean_policy_losses: -70.084, mean_net_lifetime: 5266.3810, mean_mc_travel_dist: 1943.5685, mean_rewards: 250.2777, total_rewards: 3352.6910, mean_steps: 20.4300, mean_ecr: 0.0386 mean_entropies: 0.7952, took: 97.6272s
2022-10-10 15:24:32,084 [INFO] 	Process 3 - batch 49999: mean_policy_losses: 28.230, mean_net_lifetime: 4504.5627, mean_mc_travel_dist: 1265.4300, mean_rewards: 285.9055, total_rewards: 3270.4868, mean_steps: 14.8000, mean_ecr: 0.0484 mean_entropies: 0.5349, took: 75.1656s
2022-10-10 15:24:42,367 [INFO] 	Process 2 - batch 48999: mean_policy_losses: -28.568, mean_net_lifetime: 4717.9776, mean_mc_travel_dist: 1324.3261, mean_rewards: 285.9131, total_rewards: 3421.1185, mean_steps: 15.6000, mean_ecr: 0.0406 mean_entropies: 0.4933, took: 76.7893s
2022-10-10 15:25:05,568 [INFO] 	Process 5 - batch 48599: mean_policy_losses: -369.971, mean_net_lifetime: 5033.3903, mean_mc_travel_dist: 1693.6406, mean_rewards: 274.8141, total_rewards: 3384.4424, mean_steps: 18.3600, mean_ecr: 0.0300 mean_entropies: 0.6913, took: 88.3024s
2022-10-10 15:25:11,901 [INFO] Process 6 - epoch 46: mean_policy_losses: -251.598, mean_net_lifetime: 2748.6449, mean_mc_travel_dist: 952.0385, mean_entropies: 0.7864, m_net_lifetime_valid: 4347.8209, took: 1349.2119s, (111.9185 / 100 batches)

2022-10-10 15:25:23,123 [INFO] 	Process 4 - batch 55099: mean_policy_losses: 84.374, mean_net_lifetime: 4782.5640, mean_mc_travel_dist: 1355.8296, mean_rewards: 286.7235, total_rewards: 3450.9816, mean_steps: 15.7200, mean_ecr: 0.0475 mean_entropies: 0.6498, took: 77.9832s
2022-10-10 15:25:45,318 [INFO] 	Process 3 - batch 50099: mean_policy_losses: 20.925, mean_net_lifetime: 4323.8624, mean_mc_travel_dist: 1218.9689, mean_rewards: 273.6518, total_rewards: 3132.5310, mean_steps: 14.8400, mean_ecr: 0.0488 mean_entropies: 0.5570, took: 73.2336s
2022-10-10 15:25:53,277 [INFO] 	Process 1 - batch 42899: mean_policy_losses: -31.405, mean_net_lifetime: 5210.0562, mean_mc_travel_dist: 1973.9233, mean_rewards: 270.1942, total_rewards: 3254.6987, mean_steps: 18.4400, mean_ecr: 0.0385 mean_entropies: 0.7915, took: 88.0972s
2022-10-10 15:26:01,305 [INFO] 	Process 2 - batch 49099: mean_policy_losses: -10.907, mean_net_lifetime: 4714.3122, mean_mc_travel_dist: 1301.9066, mean_rewards: 281.0225, total_rewards: 3433.9375, mean_steps: 15.8500, mean_ecr: 0.0408 mean_entropies: 0.4773, took: 78.9375s
2022-10-10 15:26:02,054 [INFO] 	Process 6 - batch 69099: mean_policy_losses: -181.833, mean_net_lifetime: 3264.9406, mean_mc_travel_dist: 882.5507, mean_rewards: 324.7995, total_rewards: 2402.9011, mean_steps: 9.0700, mean_ecr: 0.0566 mean_entropies: 0.1805, took: 631.0773s
2022-10-10 15:26:22,247 [INFO] 	Process 5 - batch 48699: mean_policy_losses: -494.758, mean_net_lifetime: 4047.3422, mean_mc_travel_dist: 1345.3976, mean_rewards: 257.0386, total_rewards: 2772.7315, mean_steps: 15.4600, mean_ecr: 0.0303 mean_entropies: 0.6983, took: 76.6792s
2022-10-10 15:26:47,312 [INFO] 	Process 4 - batch 55199: mean_policy_losses: 109.932, mean_net_lifetime: 4972.0503, mean_mc_travel_dist: 1413.0304, mean_rewards: 287.8174, total_rewards: 3587.5724, mean_steps: 16.3400, mean_ecr: 0.0470 mean_entropies: 0.6710, took: 84.1884s
2022-10-10 15:26:51,743 [INFO] 	Process 6 - batch 69199: mean_policy_losses: -171.089, mean_net_lifetime: 3333.0304, mean_mc_travel_dist: 902.3536, mean_rewards: 331.8037, total_rewards: 2449.5658, mean_steps: 9.1100, mean_ecr: 0.0561 mean_entropies: 0.1963, took: 49.6886s
2022-10-10 15:27:00,190 [INFO] 	Process 3 - batch 50199: mean_policy_losses: 40.912, mean_net_lifetime: 4475.1716, mean_mc_travel_dist: 1250.2553, mean_rewards: 289.6520, total_rewards: 3257.8485, mean_steps: 14.5000, mean_ecr: 0.0483 mean_entropies: 0.5555, took: 74.8718s
2022-10-10 15:27:19,361 [INFO] 	Process 2 - batch 49199: mean_policy_losses: 2.212, mean_net_lifetime: 4752.1010, mean_mc_travel_dist: 1334.7738, mean_rewards: 288.8979, total_rewards: 3444.3174, mean_steps: 15.5500, mean_ecr: 0.0406 mean_entropies: 0.4977, took: 78.0557s
2022-10-10 15:27:25,266 [INFO] 	Process 1 - batch 42999: mean_policy_losses: -48.237, mean_net_lifetime: 5334.5635, mean_mc_travel_dist: 2021.5205, mean_rewards: 267.4709, total_rewards: 3347.8337, mean_steps: 19.1500, mean_ecr: 0.0383 mean_entropies: 0.8009, took: 91.9891s
2022-10-10 15:27:40,238 [INFO] 	Process 6 - batch 69299: mean_policy_losses: -244.305, mean_net_lifetime: 3222.5908, mean_mc_travel_dist: 870.4384, mean_rewards: 329.5086, total_rewards: 2366.8558, mean_steps: 8.8000, mean_ecr: 0.0564 mean_entropies: 0.2086, took: 48.4957s
2022-10-10 15:27:51,013 [INFO] 	Process 5 - batch 48799: mean_policy_losses: -345.404, mean_net_lifetime: 4854.6890, mean_mc_travel_dist: 1607.4258, mean_rewards: 271.0966, total_rewards: 3286.8983, mean_steps: 17.8500, mean_ecr: 0.0303 mean_entropies: 0.7289, took: 88.7653s
2022-10-10 15:28:06,555 [INFO] 	Process 4 - batch 55299: mean_policy_losses: 45.568, mean_net_lifetime: 4637.4239, mean_mc_travel_dist: 1357.2604, mean_rewards: 281.1399, total_rewards: 3318.7307, mean_steps: 15.5400, mean_ecr: 0.0477 mean_entropies: 0.6722, took: 79.2430s
2022-10-10 15:28:13,493 [INFO] 	Process 3 - batch 50299: mean_policy_losses: 43.666, mean_net_lifetime: 4460.0822, mean_mc_travel_dist: 1248.1810, mean_rewards: 289.3200, total_rewards: 3240.7610, mean_steps: 14.4700, mean_ecr: 0.0483 mean_entropies: 0.5713, took: 73.3031s
2022-10-10 15:28:26,318 [INFO] 	Process 6 - batch 69399: mean_policy_losses: -272.774, mean_net_lifetime: 3047.9567, mean_mc_travel_dist: 825.6607, mean_rewards: 328.0897, total_rewards: 2241.5188, mean_steps: 8.2500, mean_ecr: 0.0565 mean_entropies: 0.2304, took: 46.0798s
2022-10-10 15:28:38,663 [INFO] 	Process 2 - batch 49299: mean_policy_losses: -7.663, mean_net_lifetime: 4708.6809, mean_mc_travel_dist: 1330.5803, mean_rewards: 283.1335, total_rewards: 3395.4231, mean_steps: 15.7300, mean_ecr: 0.0407 mean_entropies: 0.4850, took: 79.3021s
2022-10-10 15:28:57,598 [INFO] 	Process 1 - batch 43099: mean_policy_losses: -51.644, mean_net_lifetime: 5256.2471, mean_mc_travel_dist: 1972.6940, mean_rewards: 266.0536, total_rewards: 3305.5640, mean_steps: 18.9000, mean_ecr: 0.0384 mean_entropies: 0.7934, took: 92.3323s
2022-10-10 15:29:15,294 [INFO] 	Process 6 - batch 69499: mean_policy_losses: -223.133, mean_net_lifetime: 3193.4105, mean_mc_travel_dist: 864.2195, mean_rewards: 331.1167, total_rewards: 2348.0946, mean_steps: 8.6500, mean_ecr: 0.0562 mean_entropies: 0.2043, took: 48.9753s
2022-10-10 15:29:20,607 [INFO] 	Process 5 - batch 48899: mean_policy_losses: -305.240, mean_net_lifetime: 4897.3817, mean_mc_travel_dist: 1648.4983, mean_rewards: 260.2055, total_rewards: 3302.2677, mean_steps: 18.5200, mean_ecr: 0.0302 mean_entropies: 0.6909, took: 89.5939s
2022-10-10 15:29:26,533 [INFO] 	Process 4 - batch 55399: mean_policy_losses: 90.640, mean_net_lifetime: 4817.9673, mean_mc_travel_dist: 1390.6538, mean_rewards: 288.9457, total_rewards: 3461.4889, mean_steps: 15.7300, mean_ecr: 0.0473 mean_entropies: 0.6611, took: 79.9785s
2022-10-10 15:29:28,892 [INFO] 	Process 3 - batch 50399: mean_policy_losses: 50.628, mean_net_lifetime: 4534.8454, mean_mc_travel_dist: 1236.5986, mean_rewards: 284.2313, total_rewards: 3323.1839, mean_steps: 15.0000, mean_ecr: 0.0484 mean_entropies: 0.5322, took: 75.3992s
2022-10-10 15:29:57,792 [INFO] 	Process 2 - batch 49399: mean_policy_losses: -4.726, mean_net_lifetime: 4727.9010, mean_mc_travel_dist: 1329.0854, mean_rewards: 285.7536, total_rewards: 3433.5414, mean_steps: 15.6500, mean_ecr: 0.0406 mean_entropies: 0.5018, took: 79.1298s
2022-10-10 15:30:00,206 [INFO] 	Process 6 - batch 69599: mean_policy_losses: -198.610, mean_net_lifetime: 3035.8121, mean_mc_travel_dist: 828.9982, mean_rewards: 334.5992, total_rewards: 2243.7685, mean_steps: 8.0600, mean_ecr: 0.0563 mean_entropies: 0.2308, took: 44.9130s
2022-10-10 15:30:29,983 [INFO] 	Process 1 - batch 43199: mean_policy_losses: -55.812, mean_net_lifetime: 5246.4863, mean_mc_travel_dist: 1971.3118, mean_rewards: 264.6973, total_rewards: 3301.8588, mean_steps: 18.9500, mean_ecr: 0.0385 mean_entropies: 0.8081, took: 92.3854s
2022-10-10 15:30:40,817 [INFO] 	Process 6 - batch 69699: mean_policy_losses: -210.143, mean_net_lifetime: 2699.9217, mean_mc_travel_dist: 760.6234, mean_rewards: 336.2100, total_rewards: 1989.0398, mean_steps: 6.9800, mean_ecr: 0.0574 mean_entropies: 0.2161, took: 40.6093s
2022-10-10 15:30:44,259 [INFO] 	Process 3 - batch 50499: mean_policy_losses: 64.408, mean_net_lifetime: 4552.3889, mean_mc_travel_dist: 1281.4997, mean_rewards: 289.7857, total_rewards: 3306.9354, mean_steps: 14.7600, mean_ecr: 0.0481 mean_entropies: 0.5394, took: 75.3666s
2022-10-10 15:30:50,717 [INFO] 	Process 4 - batch 55499: mean_policy_losses: 60.710, mean_net_lifetime: 4764.6474, mean_mc_travel_dist: 1373.8076, mean_rewards: 274.5645, total_rewards: 3426.1410, mean_steps: 16.4100, mean_ecr: 0.0475 mean_entropies: 0.7264, took: 84.1839s
2022-10-10 15:30:53,957 [INFO] 	Process 5 - batch 48999: mean_policy_losses: -242.101, mean_net_lifetime: 5190.5961, mean_mc_travel_dist: 1762.9081, mean_rewards: 263.0405, total_rewards: 3483.9129, mean_steps: 19.1300, mean_ecr: 0.0304 mean_entropies: 0.7323, took: 93.3502s
2022-10-10 15:31:18,021 [INFO] 	Process 2 - batch 49499: mean_policy_losses: -3.924, mean_net_lifetime: 4719.0553, mean_mc_travel_dist: 1330.5250, mean_rewards: 281.8775, total_rewards: 3407.9301, mean_steps: 15.8200, mean_ecr: 0.0406 mean_entropies: 0.4801, took: 80.2288s
2022-10-10 15:31:28,657 [INFO] 	Process 6 - batch 69799: mean_policy_losses: -231.892, mean_net_lifetime: 3261.0116, mean_mc_travel_dist: 882.4726, mean_rewards: 328.3935, total_rewards: 2394.2890, mean_steps: 8.9200, mean_ecr: 0.0562 mean_entropies: 0.2189, took: 47.8396s
2022-10-10 15:31:52,494 [INFO] 	Process 1 - batch 43299: mean_policy_losses: -68.804, mean_net_lifetime: 5101.2796, mean_mc_travel_dist: 2020.3932, mean_rewards: 275.2918, total_rewards: 3110.6989, mean_steps: 17.6500, mean_ecr: 0.0384 mean_entropies: 0.7198, took: 82.5106s
2022-10-10 15:31:55,714 [INFO] 	Process 3 - batch 50599: mean_policy_losses: 52.298, mean_net_lifetime: 4428.2396, mean_mc_travel_dist: 1235.3779, mean_rewards: 284.0286, total_rewards: 3218.8961, mean_steps: 14.6300, mean_ecr: 0.0484 mean_entropies: 0.5459, took: 71.4552s
2022-10-10 15:32:13,534 [INFO] 	Process 6 - batch 69899: mean_policy_losses: -166.441, mean_net_lifetime: 3156.4049, mean_mc_travel_dist: 870.2351, mean_rewards: 329.2821, total_rewards: 2312.1063, mean_steps: 8.5400, mean_ecr: 0.0564 mean_entropies: 0.2095, took: 44.8786s
2022-10-10 15:32:18,997 [INFO] 	Process 5 - batch 49099: mean_policy_losses: -229.487, mean_net_lifetime: 4984.0923, mean_mc_travel_dist: 1662.6411, mean_rewards: 265.3849, total_rewards: 3378.9792, mean_steps: 18.3000, mean_ecr: 0.0310 mean_entropies: 0.6762, took: 85.0404s
2022-10-10 15:32:59,345 [INFO] 	Process 6 - batch 69999: mean_policy_losses: -172.807, mean_net_lifetime: 3235.8211, mean_mc_travel_dist: 892.0022, mean_rewards: 329.1289, total_rewards: 2373.9059, mean_steps: 8.8300, mean_ecr: 0.0561 mean_entropies: 0.2167, took: 45.8105s
2022-10-10 15:33:06,516 [INFO] 	Process 3 - batch 50699: mean_policy_losses: 65.937, mean_net_lifetime: 4449.5561, mean_mc_travel_dist: 1241.0188, mean_rewards: 284.0977, total_rewards: 3234.0652, mean_steps: 14.7300, mean_ecr: 0.0486 mean_entropies: 0.5296, took: 70.8021s
2022-10-10 15:33:13,632 [INFO] 	Process 1 - batch 43399: mean_policy_losses: -64.574, mean_net_lifetime: 4994.7930, mean_mc_travel_dist: 2020.7624, mean_rewards: 268.6160, total_rewards: 2991.2231, mean_steps: 17.7200, mean_ecr: 0.0383 mean_entropies: 0.6620, took: 81.1365s
2022-10-10 15:33:35,198 [INFO] Process 7 - epoch 33: mean_policy_losses: -267.943, mean_net_lifetime: 3967.8872, mean_mc_travel_dist: 1592.8426, mean_entropies: 1.7261, m_net_lifetime_valid: 4413.3865, took: 1762.0193s, (156.9184 / 100 batches)

2022-10-10 15:33:46,295 [INFO] 	Process 6 - batch 70099: mean_policy_losses: -105.992, mean_net_lifetime: 3304.7535, mean_mc_travel_dist: 904.9904, mean_rewards: 339.0666, total_rewards: 2434.5986, mean_steps: 8.7700, mean_ecr: 0.0562 mean_entropies: 0.2060, took: 46.9506s
2022-10-10 15:33:55,094 [INFO] 	Process 5 - batch 49199: mean_policy_losses: -129.202, mean_net_lifetime: 5784.1760, mean_mc_travel_dist: 1960.7927, mean_rewards: 266.0890, total_rewards: 3874.3626, mean_steps: 20.9100, mean_ecr: 0.0313 mean_entropies: 0.6203, took: 96.0965s
2022-10-10 15:34:22,542 [INFO] 	Process 3 - batch 50799: mean_policy_losses: 73.044, mean_net_lifetime: 4509.1796, mean_mc_travel_dist: 1239.6785, mean_rewards: 276.3618, total_rewards: 3295.4300, mean_steps: 15.3500, mean_ecr: 0.0485 mean_entropies: 0.5375, took: 76.0265s
2022-10-10 15:34:39,131 [INFO] 	Process 6 - batch 70199: mean_policy_losses: -79.198, mean_net_lifetime: 3578.9782, mean_mc_travel_dist: 955.8371, mean_rewards: 326.4025, total_rewards: 2642.6712, mean_steps: 9.9700, mean_ecr: 0.0560 mean_entropies: 0.1783, took: 52.8344s
2022-10-10 15:34:42,040 [INFO] 	Process 1 - batch 43499: mean_policy_losses: -27.824, mean_net_lifetime: 5196.5438, mean_mc_travel_dist: 2044.3631, mean_rewards: 264.8078, total_rewards: 3180.0257, mean_steps: 18.7800, mean_ecr: 0.0382 mean_entropies: 0.7203, took: 88.4086s
2022-10-10 15:35:03,386 [INFO] 	Process 7 - batch 49599: mean_policy_losses: -392.911, mean_net_lifetime: 4552.4457, mean_mc_travel_dist: 1551.6930, mean_rewards: 229.2688, total_rewards: 3052.3805, mean_steps: 18.9300, mean_ecr: 0.0413 mean_entropies: 1.2873, took: 677.0047s
2022-10-10 15:35:25,615 [INFO] 	Process 5 - batch 49299: mean_policy_losses: -180.948, mean_net_lifetime: 5309.2610, mean_mc_travel_dist: 1795.5054, mean_rewards: 260.2875, total_rewards: 3569.7347, mean_steps: 19.4200, mean_ecr: 0.0314 mean_entropies: 0.5832, took: 90.5204s
2022-10-10 15:35:34,433 [INFO] 	Process 6 - batch 70299: mean_policy_losses: -58.242, mean_net_lifetime: 3745.8787, mean_mc_travel_dist: 991.3463, mean_rewards: 313.2519, total_rewards: 2770.6374, mean_steps: 10.9900, mean_ecr: 0.0556 mean_entropies: 0.1568, took: 55.3029s
2022-10-10 15:35:40,263 [INFO] 	Process 3 - batch 50899: mean_policy_losses: 12.541, mean_net_lifetime: 4161.5287, mean_mc_travel_dist: 1146.4456, mean_rewards: 245.1822, total_rewards: 3045.4457, mean_steps: 16.0400, mean_ecr: 0.0491 mean_entropies: 0.5197, took: 77.7197s
2022-10-10 15:36:19,930 [INFO] 	Process 6 - batch 70399: mean_policy_losses: -182.088, mean_net_lifetime: 3168.4690, mean_mc_travel_dist: 872.9807, mean_rewards: 326.6513, total_rewards: 2333.6684, mean_steps: 8.6800, mean_ecr: 0.0563 mean_entropies: 0.2282, took: 45.4970s
2022-10-10 15:36:26,350 [INFO] 	Process 7 - batch 49699: mean_policy_losses: -448.959, mean_net_lifetime: 4344.2743, mean_mc_travel_dist: 1493.5448, mean_rewards: 224.5599, total_rewards: 2896.6597, mean_steps: 18.3800, mean_ecr: 0.0414 mean_entropies: 1.3066, took: 82.9637s
2022-10-10 15:36:55,652 [INFO] 	Process 5 - batch 49399: mean_policy_losses: -144.948, mean_net_lifetime: 5443.3899, mean_mc_travel_dist: 1840.8171, mean_rewards: 264.5385, total_rewards: 3646.1284, mean_steps: 19.6800, mean_ecr: 0.0314 mean_entropies: 0.6180, took: 90.0374s
2022-10-10 15:36:56,518 [INFO] 	Process 3 - batch 50999: mean_policy_losses: 44.217, mean_net_lifetime: 4441.9662, mean_mc_travel_dist: 1228.7685, mean_rewards: 264.2691, total_rewards: 3243.3165, mean_steps: 15.9000, mean_ecr: 0.0483 mean_entropies: 0.5313, took: 76.2566s
2022-10-10 15:37:09,385 [INFO] 	Process 6 - batch 70499: mean_policy_losses: -147.857, mean_net_lifetime: 3486.5482, mean_mc_travel_dist: 938.2233, mean_rewards: 327.6256, total_rewards: 2570.6147, mean_steps: 9.6700, mean_ecr: 0.0559 mean_entropies: 0.1716, took: 49.4552s
2022-10-10 15:37:59,046 [INFO] 	Process 7 - batch 49799: mean_policy_losses: -145.224, mean_net_lifetime: 5120.7832, mean_mc_travel_dist: 1722.4268, mean_rewards: 225.1734, total_rewards: 3431.9413, mean_steps: 21.8600, mean_ecr: 0.0407 mean_entropies: 1.2604, took: 92.6963s
2022-10-10 15:38:23,295 [INFO] 	Process 5 - batch 49499: mean_policy_losses: -61.429, mean_net_lifetime: 5687.0553, mean_mc_travel_dist: 1931.4283, mean_rewards: 264.5995, total_rewards: 3801.3827, mean_steps: 20.6900, mean_ecr: 0.0314 mean_entropies: 0.6182, took: 87.6423s
2022-10-10 15:39:02,662 [INFO] Process 4 - epoch 37: mean_policy_losses: 87.157, mean_net_lifetime: 3848.5594, mean_mc_travel_dist: 1301.5922, mean_entropies: 1.3441, m_net_lifetime_valid: 4274.6134, took: 1720.8025s, (140.7478 / 100 batches)

2022-10-10 15:39:10,564 [INFO] Process 2 - epoch 33: mean_policy_losses: 8.579, mean_net_lifetime: 4281.3696, mean_mc_travel_dist: 1579.3905, mean_entropies: 1.1187, m_net_lifetime_valid: 4428.6091, took: 1664.8439s, (157.8293 / 100 batches)

2022-10-10 15:39:24,819 [INFO] 	Process 7 - batch 49899: mean_policy_losses: -156.802, mean_net_lifetime: 4818.3144, mean_mc_travel_dist: 1609.1104, mean_rewards: 221.8720, total_rewards: 3258.9728, mean_steps: 20.8000, mean_ecr: 0.0410 mean_entropies: 1.2908, took: 85.7721s
2022-10-10 15:40:16,397 [INFO] 	Process 4 - batch 55599: mean_policy_losses: 80.436, mean_net_lifetime: 4551.5476, mean_mc_travel_dist: 1296.4753, mean_rewards: 270.2708, total_rewards: 3279.6575, mean_steps: 15.8600, mean_ecr: 0.0477 mean_entropies: 0.6902, took: 565.6800s
2022-10-10 15:40:24,919 [INFO] 	Process 2 - batch 49599: mean_policy_losses: -21.836, mean_net_lifetime: 4712.2150, mean_mc_travel_dist: 1300.1653, mean_rewards: 271.8865, total_rewards: 3432.9672, mean_steps: 16.4000, mean_ecr: 0.0408 mean_entropies: 0.3848, took: 546.8971s
2022-10-10 15:41:03,713 [INFO] 	Process 7 - batch 49999: mean_policy_losses: -335.474, mean_net_lifetime: 5186.9943, mean_mc_travel_dist: 1884.8192, mean_rewards: 219.0345, total_rewards: 3354.9202, mean_steps: 23.2800, mean_ecr: 0.0405 mean_entropies: 1.2199, took: 98.8946s
2022-10-10 15:41:38,597 [INFO] 	Process 4 - batch 55699: mean_policy_losses: 102.958, mean_net_lifetime: 5277.2387, mean_mc_travel_dist: 1534.9755, mean_rewards: 284.0993, total_rewards: 3768.1237, mean_steps: 17.9500, mean_ecr: 0.0461 mean_entropies: 0.6099, took: 82.2007s
2022-10-10 15:41:40,739 [INFO] 	Process 2 - batch 49699: mean_policy_losses: -19.436, mean_net_lifetime: 4718.8212, mean_mc_travel_dist: 1311.4425, mean_rewards: 273.5749, total_rewards: 3425.1315, mean_steps: 16.3300, mean_ecr: 0.0407 mean_entropies: 0.4037, took: 75.8212s
2022-10-10 15:42:23,463 [INFO] 	Process 7 - batch 50099: mean_policy_losses: -645.109, mean_net_lifetime: 4370.3963, mean_mc_travel_dist: 1598.3225, mean_rewards: 237.2921, total_rewards: 2820.0983, mean_steps: 18.2400, mean_ecr: 0.0409 mean_entropies: 1.2057, took: 79.7502s
2022-10-10 15:42:54,911 [INFO] 	Process 2 - batch 49799: mean_policy_losses: -21.236, mean_net_lifetime: 4708.3190, mean_mc_travel_dist: 1321.6502, mean_rewards: 277.6991, total_rewards: 3417.1856, mean_steps: 16.0400, mean_ecr: 0.0406 mean_entropies: 0.4725, took: 74.1715s
2022-10-10 15:42:55,970 [INFO] 	Process 4 - batch 55799: mean_policy_losses: 86.898, mean_net_lifetime: 5010.8137, mean_mc_travel_dist: 1446.4883, mean_rewards: 288.8347, total_rewards: 3601.1511, mean_steps: 16.4800, mean_ecr: 0.0468 mean_entropies: 0.6001, took: 77.3722s
2022-10-10 15:43:33,473 [INFO] 	Process 7 - batch 50199: mean_policy_losses: -873.633, mean_net_lifetime: 3761.3670, mean_mc_travel_dist: 1396.7509, mean_rewards: 246.6434, total_rewards: 2398.2762, mean_steps: 15.2900, mean_ecr: 0.0417 mean_entropies: 1.2355, took: 70.0096s
2022-10-10 15:44:08,191 [INFO] 	Process 2 - batch 49899: mean_policy_losses: -13.978, mean_net_lifetime: 4700.5775, mean_mc_travel_dist: 1309.3085, mean_rewards: 277.0928, total_rewards: 3414.1340, mean_steps: 16.0600, mean_ecr: 0.0408 mean_entropies: 0.4482, took: 73.2801s
2022-10-10 15:44:10,606 [INFO] Process 1 - epoch 29: mean_policy_losses: 43.318, mean_net_lifetime: 4796.3791, mean_mc_travel_dist: 2051.9899, mean_entropies: 1.3254, m_net_lifetime_valid: 4886.3105, took: 1931.5956s, (180.0166 / 100 batches)

2022-10-10 15:44:17,548 [INFO] 	Process 4 - batch 55899: mean_policy_losses: 114.513, mean_net_lifetime: 5324.7507, mean_mc_travel_dist: 1563.2793, mean_rewards: 286.5920, total_rewards: 3801.4105, mean_steps: 17.7700, mean_ecr: 0.0456 mean_entropies: 0.5649, took: 81.5776s
2022-10-10 15:44:51,662 [INFO] 	Process 7 - batch 50299: mean_policy_losses: -660.040, mean_net_lifetime: 4327.9072, mean_mc_travel_dist: 1562.7466, mean_rewards: 244.6137, total_rewards: 2801.8382, mean_steps: 17.5100, mean_ecr: 0.0410 mean_entropies: 1.2310, took: 78.1890s
2022-10-10 15:45:22,417 [INFO] 	Process 2 - batch 49999: mean_policy_losses: -12.500, mean_net_lifetime: 4716.7243, mean_mc_travel_dist: 1306.6192, mean_rewards: 281.2189, total_rewards: 3434.6135, mean_steps: 15.8400, mean_ecr: 0.0407 mean_entropies: 0.4763, took: 74.2253s
2022-10-10 15:45:24,506 [INFO] Process 3 - epoch 34: mean_policy_losses: 85.385, mean_net_lifetime: 4138.7078, mean_mc_travel_dist: 1397.8067, mean_entropies: 1.0849, m_net_lifetime_valid: 4322.3478, took: 1634.5718s, (153.8572 / 100 batches)

2022-10-10 15:45:39,096 [INFO] 	Process 4 - batch 55999: mean_policy_losses: 111.114, mean_net_lifetime: 5264.9300, mean_mc_travel_dist: 1556.5667, mean_rewards: 295.6192, total_rewards: 3742.2334, mean_steps: 17.0600, mean_ecr: 0.0459 mean_entropies: 0.5777, took: 81.5487s
2022-10-10 15:45:42,410 [INFO] 	Process 1 - batch 43599: mean_policy_losses: -14.815, mean_net_lifetime: 5168.9934, mean_mc_travel_dist: 1886.0662, mean_rewards: 246.3321, total_rewards: 3312.7150, mean_steps: 20.3000, mean_ecr: 0.0386 mean_entropies: 0.8636, took: 660.3708s
2022-10-10 15:46:09,162 [INFO] Process 6 - epoch 47: mean_policy_losses: -249.998, mean_net_lifetime: 2759.2915, mean_mc_travel_dist: 950.5667, mean_entropies: 0.7740, m_net_lifetime_valid: 4422.0321, took: 1257.2584s, (111.3797 / 100 batches)

2022-10-10 15:46:13,778 [INFO] 	Process 7 - batch 50399: mean_policy_losses: -703.521, mean_net_lifetime: 4244.3011, mean_mc_travel_dist: 1568.9653, mean_rewards: 242.4366, total_rewards: 2723.3827, mean_steps: 17.2700, mean_ecr: 0.0409 mean_entropies: 1.2453, took: 82.1157s
2022-10-10 15:46:39,997 [INFO] 	Process 2 - batch 50099: mean_policy_losses: -25.485, mean_net_lifetime: 4712.3528, mean_mc_travel_dist: 1310.9009, mean_rewards: 285.9575, total_rewards: 3424.3817, mean_steps: 15.5500, mean_ecr: 0.0407 mean_entropies: 0.4740, took: 77.5803s
2022-10-10 15:46:41,411 [INFO] 	Process 3 - batch 51099: mean_policy_losses: 29.791, mean_net_lifetime: 4491.8516, mean_mc_travel_dist: 1222.7538, mean_rewards: 275.7307, total_rewards: 3307.7740, mean_steps: 15.3300, mean_ecr: 0.0484 mean_entropies: 0.4958, took: 584.8914s
2022-10-10 15:46:59,735 [INFO] 	Process 6 - batch 70599: mean_policy_losses: -123.985, mean_net_lifetime: 3317.4440, mean_mc_travel_dist: 903.1194, mean_rewards: 330.0881, total_rewards: 2437.1145, mean_steps: 9.0900, mean_ecr: 0.0561 mean_entropies: 0.1965, took: 590.3498s
2022-10-10 15:47:05,419 [INFO] 	Process 4 - batch 56099: mean_policy_losses: 86.408, mean_net_lifetime: 5264.6590, mean_mc_travel_dist: 1566.3148, mean_rewards: 293.4317, total_rewards: 3732.6423, mean_steps: 17.1400, mean_ecr: 0.0459 mean_entropies: 0.5703, took: 86.3229s
2022-10-10 15:47:12,035 [INFO] Process 5 - epoch 33: mean_policy_losses: -212.742, mean_net_lifetime: 4490.2918, mean_mc_travel_dist: 1920.7829, mean_entropies: 1.4104, m_net_lifetime_valid: 4626.7718, took: 1830.3379s, (158.6864 / 100 batches)

2022-10-10 15:47:18,299 [INFO] 	Process 1 - batch 43699: mean_policy_losses: 10.769, mean_net_lifetime: 5201.7194, mean_mc_travel_dist: 1875.2267, mean_rewards: 250.1761, total_rewards: 3356.0775, mean_steps: 20.1200, mean_ecr: 0.0387 mean_entropies: 0.8676, took: 95.8882s
2022-10-10 15:47:32,917 [INFO] 	Process 7 - batch 50499: mean_policy_losses: -835.860, mean_net_lifetime: 3947.7669, mean_mc_travel_dist: 1446.0725, mean_rewards: 251.0120, total_rewards: 2533.4493, mean_steps: 15.6000, mean_ecr: 0.0415 mean_entropies: 1.2617, took: 79.1385s
2022-10-10 15:47:48,980 [INFO] 	Process 6 - batch 70699: mean_policy_losses: -283.514, mean_net_lifetime: 3167.6598, mean_mc_travel_dist: 864.4066, mean_rewards: 325.5310, total_rewards: 2324.8033, mean_steps: 8.7300, mean_ecr: 0.0563 mean_entropies: 0.2057, took: 49.2460s
2022-10-10 15:48:01,544 [INFO] 	Process 3 - batch 51199: mean_policy_losses: 33.806, mean_net_lifetime: 4513.1919, mean_mc_travel_dist: 1237.4482, mean_rewards: 276.9212, total_rewards: 3298.1673, mean_steps: 15.3600, mean_ecr: 0.0482 mean_entropies: 0.5060, took: 80.1343s
2022-10-10 15:48:04,315 [INFO] 	Process 2 - batch 50199: mean_policy_losses: -4.659, mean_net_lifetime: 4815.2091, mean_mc_travel_dist: 1343.7722, mean_rewards: 283.2591, total_rewards: 3493.4360, mean_steps: 16.0800, mean_ecr: 0.0406 mean_entropies: 0.4851, took: 84.3178s
2022-10-10 15:48:28,669 [INFO] 	Process 4 - batch 56199: mean_policy_losses: 72.568, mean_net_lifetime: 4723.5846, mean_mc_travel_dist: 1335.3660, mean_rewards: 287.0515, total_rewards: 3416.7488, mean_steps: 15.5600, mean_ecr: 0.0477 mean_entropies: 0.6857, took: 83.2500s
2022-10-10 15:48:30,919 [INFO] 	Process 5 - batch 49599: mean_policy_losses: -442.589, mean_net_lifetime: 4117.3906, mean_mc_travel_dist: 1333.6762, mean_rewards: 268.8976, total_rewards: 2849.5482, mean_steps: 15.2700, mean_ecr: 0.0306 mean_entropies: 0.6365, took: 607.6251s
2022-10-10 15:48:45,481 [INFO] 	Process 6 - batch 70799: mean_policy_losses: -160.717, mean_net_lifetime: 3503.6335, mean_mc_travel_dist: 936.9916, mean_rewards: 316.2773, total_rewards: 2593.1567, mean_steps: 10.1300, mean_ecr: 0.0559 mean_entropies: 0.1887, took: 56.4999s
2022-10-10 15:48:46,467 [INFO] 	Process 7 - batch 50599: mean_policy_losses: -878.319, mean_net_lifetime: 3538.2663, mean_mc_travel_dist: 1305.6440, mean_rewards: 239.1494, total_rewards: 2273.3830, mean_steps: 14.0000, mean_ecr: 0.0420 mean_entropies: 1.1884, took: 73.5510s
2022-10-10 15:48:55,168 [INFO] 	Process 1 - batch 43799: mean_policy_losses: 2.642, mean_net_lifetime: 5255.1318, mean_mc_travel_dist: 1933.8157, mean_rewards: 262.8075, total_rewards: 3352.2533, mean_steps: 19.1300, mean_ecr: 0.0386 mean_entropies: 0.8610, took: 96.8696s
2022-10-10 15:49:23,646 [INFO] 	Process 3 - batch 51299: mean_policy_losses: 44.367, mean_net_lifetime: 4448.3181, mean_mc_travel_dist: 1206.8677, mean_rewards: 269.0046, total_rewards: 3265.0723, mean_steps: 15.5500, mean_ecr: 0.0487 mean_entropies: 0.5198, took: 82.1024s
2022-10-10 15:49:28,017 [INFO] 	Process 2 - batch 50299: mean_policy_losses: -7.410, mean_net_lifetime: 4728.6651, mean_mc_travel_dist: 1329.2191, mean_rewards: 279.5041, total_rewards: 3424.1909, mean_steps: 16.0000, mean_ecr: 0.0406 mean_entropies: 0.4750, took: 83.7022s
2022-10-10 15:49:42,851 [INFO] 	Process 6 - batch 70899: mean_policy_losses: -144.267, mean_net_lifetime: 3562.9233, mean_mc_travel_dist: 963.0028, mean_rewards: 320.4580, total_rewards: 2634.2791, mean_steps: 10.2000, mean_ecr: 0.0559 mean_entropies: 0.1936, took: 57.3706s
2022-10-10 15:49:43,981 [INFO] 	Process 5 - batch 49699: mean_policy_losses: -460.517, mean_net_lifetime: 3614.4772, mean_mc_travel_dist: 1160.2497, mean_rewards: 250.5738, total_rewards: 2504.9584, mean_steps: 14.0100, mean_ecr: 0.0305 mean_entropies: 0.6445, took: 73.0619s
2022-10-10 15:49:51,903 [INFO] 	Process 4 - batch 56299: mean_policy_losses: 73.362, mean_net_lifetime: 4833.4661, mean_mc_travel_dist: 1402.3392, mean_rewards: 289.6456, total_rewards: 3457.0172, mean_steps: 15.7500, mean_ecr: 0.0473 mean_entropies: 0.6096, took: 83.2337s
2022-10-10 15:49:56,618 [INFO] 	Process 7 - batch 50699: mean_policy_losses: -861.930, mean_net_lifetime: 3502.9454, mean_mc_travel_dist: 1335.1308, mean_rewards: 246.9592, total_rewards: 2220.5829, mean_steps: 13.5100, mean_ecr: 0.0418 mean_entropies: 1.0935, took: 70.1513s
2022-10-10 15:50:30,412 [INFO] 	Process 1 - batch 43899: mean_policy_losses: -21.834, mean_net_lifetime: 5223.8758, mean_mc_travel_dist: 1952.1229, mean_rewards: 265.2118, total_rewards: 3305.4885, mean_steps: 18.8300, mean_ecr: 0.0386 mean_entropies: 0.8191, took: 95.2433s
2022-10-10 15:50:39,707 [INFO] 	Process 6 - batch 70999: mean_policy_losses: -156.807, mean_net_lifetime: 3572.9056, mean_mc_travel_dist: 958.5015, mean_rewards: 316.3547, total_rewards: 2635.7570, mean_steps: 10.3500, mean_ecr: 0.0559 mean_entropies: 0.1834, took: 56.8549s
2022-10-10 15:50:43,871 [INFO] 	Process 3 - batch 51399: mean_policy_losses: 47.255, mean_net_lifetime: 4520.2881, mean_mc_travel_dist: 1229.6234, mean_rewards: 280.8870, total_rewards: 3317.5924, mean_steps: 15.1400, mean_ecr: 0.0487 mean_entropies: 0.5261, took: 80.2243s
2022-10-10 15:50:51,824 [INFO] 	Process 2 - batch 50399: mean_policy_losses: -18.786, mean_net_lifetime: 4717.9869, mean_mc_travel_dist: 1314.7901, mean_rewards: 282.9054, total_rewards: 3434.0627, mean_steps: 15.7500, mean_ecr: 0.0407 mean_entropies: 0.4735, took: 83.8069s
2022-10-10 15:51:05,856 [INFO] 	Process 5 - batch 49799: mean_policy_losses: -424.390, mean_net_lifetime: 4218.3191, mean_mc_travel_dist: 1389.2622, mean_rewards: 261.2353, total_rewards: 2876.8756, mean_steps: 15.8100, mean_ecr: 0.0306 mean_entropies: 0.6526, took: 81.8749s
2022-10-10 15:51:17,344 [INFO] 	Process 4 - batch 56399: mean_policy_losses: 87.648, mean_net_lifetime: 4826.7870, mean_mc_travel_dist: 1376.5798, mean_rewards: 283.0456, total_rewards: 3472.1182, mean_steps: 16.1300, mean_ecr: 0.0475 mean_entropies: 0.6545, took: 85.4412s
2022-10-10 15:51:19,404 [INFO] 	Process 7 - batch 50799: mean_policy_losses: -631.558, mean_net_lifetime: 4083.6839, mean_mc_travel_dist: 1486.2570, mean_rewards: 239.1999, total_rewards: 2641.0277, mean_steps: 16.3700, mean_ecr: 0.0414 mean_entropies: 1.2019, took: 82.7864s
2022-10-10 15:51:34,694 [INFO] 	Process 6 - batch 71099: mean_policy_losses: -206.532, mean_net_lifetime: 3454.1516, mean_mc_travel_dist: 934.0986, mean_rewards: 323.2857, total_rewards: 2545.3674, mean_steps: 9.7200, mean_ecr: 0.0560 mean_entropies: 0.1900, took: 54.9880s
2022-10-10 15:52:04,424 [INFO] 	Process 3 - batch 51499: mean_policy_losses: 34.022, mean_net_lifetime: 4477.3640, mean_mc_travel_dist: 1237.1752, mean_rewards: 276.6672, total_rewards: 3266.8614, mean_steps: 15.2300, mean_ecr: 0.0483 mean_entropies: 0.5430, took: 80.5526s
2022-10-10 15:52:13,262 [INFO] 	Process 1 - batch 43999: mean_policy_losses: 12.519, mean_net_lifetime: 5438.2130, mean_mc_travel_dist: 1930.0018, mean_rewards: 255.9167, total_rewards: 3538.4027, mean_steps: 20.4300, mean_ecr: 0.0386 mean_entropies: 0.8761, took: 102.8503s
2022-10-10 15:52:15,193 [INFO] 	Process 2 - batch 50499: mean_policy_losses: -14.419, mean_net_lifetime: 4729.4914, mean_mc_travel_dist: 1310.1399, mean_rewards: 283.4792, total_rewards: 3438.5846, mean_steps: 15.7500, mean_ecr: 0.0407 mean_entropies: 0.4443, took: 83.3689s
2022-10-10 15:52:33,066 [INFO] 	Process 6 - batch 71199: mean_policy_losses: -99.603, mean_net_lifetime: 3624.1289, mean_mc_travel_dist: 961.3409, mean_rewards: 314.9222, total_rewards: 2680.9541, mean_steps: 10.5200, mean_ecr: 0.0558 mean_entropies: 0.1856, took: 58.3714s
2022-10-10 15:52:35,676 [INFO] 	Process 5 - batch 49899: mean_policy_losses: -351.479, mean_net_lifetime: 4642.9907, mean_mc_travel_dist: 1540.2481, mean_rewards: 258.7076, total_rewards: 3166.5768, mean_steps: 17.6100, mean_ecr: 0.0311 mean_entropies: 0.6581, took: 89.8205s
2022-10-10 15:52:39,163 [INFO] 	Process 4 - batch 56499: mean_policy_losses: 67.478, mean_net_lifetime: 4597.2880, mean_mc_travel_dist: 1283.2009, mean_rewards: 286.9271, total_rewards: 3344.1254, mean_steps: 15.0000, mean_ecr: 0.0480 mean_entropies: 0.6697, took: 81.8194s
2022-10-10 15:52:40,876 [INFO] 	Process 7 - batch 50899: mean_policy_losses: -683.718, mean_net_lifetime: 3875.2746, mean_mc_travel_dist: 1452.4239, mean_rewards: 235.3155, total_rewards: 2466.9695, mean_steps: 15.9400, mean_ecr: 0.0418 mean_entropies: 1.1465, took: 81.4718s
2022-10-10 15:53:22,772 [INFO] 	Process 3 - batch 51599: mean_policy_losses: 53.965, mean_net_lifetime: 4530.5404, mean_mc_travel_dist: 1257.7219, mean_rewards: 285.9516, total_rewards: 3304.0482, mean_steps: 14.8900, mean_ecr: 0.0482 mean_entropies: 0.5256, took: 78.3482s
2022-10-10 15:53:27,959 [INFO] 	Process 6 - batch 71299: mean_policy_losses: -164.170, mean_net_lifetime: 3468.1689, mean_mc_travel_dist: 935.9915, mean_rewards: 326.3721, total_rewards: 2554.6703, mean_steps: 9.7000, mean_ecr: 0.0558 mean_entropies: 0.1964, took: 54.8922s
2022-10-10 15:53:40,229 [INFO] 	Process 2 - batch 50599: mean_policy_losses: -14.561, mean_net_lifetime: 4733.4185, mean_mc_travel_dist: 1321.9712, mean_rewards: 282.4670, total_rewards: 3436.6117, mean_steps: 15.8600, mean_ecr: 0.0406 mean_entropies: 0.4758, took: 85.0358s
2022-10-10 15:53:58,126 [INFO] 	Process 1 - batch 44099: mean_policy_losses: 23.252, mean_net_lifetime: 5365.7877, mean_mc_travel_dist: 1913.9862, mean_rewards: 246.5101, total_rewards: 3481.4485, mean_steps: 21.0400, mean_ecr: 0.0386 mean_entropies: 0.8430, took: 104.8635s
2022-10-10 15:53:58,272 [INFO] 	Process 7 - batch 50999: mean_policy_losses: -724.032, mean_net_lifetime: 3846.4708, mean_mc_travel_dist: 1449.2577, mean_rewards: 259.0880, total_rewards: 2443.6969, mean_steps: 14.6900, mean_ecr: 0.0413 mean_entropies: 1.1603, took: 77.3962s
2022-10-10 15:53:59,255 [INFO] 	Process 5 - batch 49999: mean_policy_losses: -383.656, mean_net_lifetime: 4209.1670, mean_mc_travel_dist: 1397.3893, mean_rewards: 256.2387, total_rewards: 2875.4136, mean_steps: 16.2500, mean_ecr: 0.0302 mean_entropies: 0.6652, took: 83.5781s
2022-10-10 15:54:02,430 [INFO] 	Process 4 - batch 56599: mean_policy_losses: 102.343, mean_net_lifetime: 4932.9257, mean_mc_travel_dist: 1432.9653, mean_rewards: 298.0254, total_rewards: 3521.8145, mean_steps: 15.6700, mean_ecr: 0.0471 mean_entropies: 0.5841, took: 83.2665s
2022-10-10 15:54:20,192 [INFO] 	Process 6 - batch 71399: mean_policy_losses: -102.603, mean_net_lifetime: 3421.0302, mean_mc_travel_dist: 920.8997, mean_rewards: 330.5952, total_rewards: 2523.9784, mean_steps: 9.4000, mean_ecr: 0.0560 mean_entropies: 0.1867, took: 52.2347s
2022-10-10 15:54:41,612 [INFO] 	Process 3 - batch 51699: mean_policy_losses: 29.966, mean_net_lifetime: 4504.1225, mean_mc_travel_dist: 1237.3277, mean_rewards: 279.7845, total_rewards: 3298.1715, mean_steps: 15.1300, mean_ecr: 0.0486 mean_entropies: 0.4954, took: 78.8407s
2022-10-10 15:55:00,666 [INFO] 	Process 2 - batch 50699: mean_policy_losses: -17.728, mean_net_lifetime: 4732.1738, mean_mc_travel_dist: 1335.0416, mean_rewards: 281.4582, total_rewards: 3422.4458, mean_steps: 15.9100, mean_ecr: 0.0405 mean_entropies: 0.4581, took: 80.4373s
2022-10-10 15:55:12,809 [INFO] 	Process 6 - batch 71499: mean_policy_losses: -148.235, mean_net_lifetime: 3439.5517, mean_mc_travel_dist: 931.2035, mean_rewards: 327.1407, total_rewards: 2538.5957, mean_steps: 9.5500, mean_ecr: 0.0561 mean_entropies: 0.1719, took: 52.6166s
2022-10-10 15:55:24,469 [INFO] 	Process 4 - batch 56699: mean_policy_losses: 71.458, mean_net_lifetime: 4793.9338, mean_mc_travel_dist: 1402.0485, mean_rewards: 286.0708, total_rewards: 3416.8566, mean_steps: 15.8900, mean_ecr: 0.0474 mean_entropies: 0.6222, took: 82.0388s
2022-10-10 15:55:26,550 [INFO] 	Process 5 - batch 50099: mean_policy_losses: -276.877, mean_net_lifetime: 4665.8821, mean_mc_travel_dist: 1561.6338, mean_rewards: 255.0681, total_rewards: 3159.7085, mean_steps: 17.7600, mean_ecr: 0.0305 mean_entropies: 0.6365, took: 87.2957s
2022-10-10 15:55:45,950 [INFO] 	Process 1 - batch 44199: mean_policy_losses: 90.787, mean_net_lifetime: 5664.6143, mean_mc_travel_dist: 1920.8555, mean_rewards: 243.2614, total_rewards: 3767.4788, mean_steps: 22.5300, mean_ecr: 0.0385 mean_entropies: 0.8742, took: 107.8253s
2022-10-10 15:55:59,269 [INFO] 	Process 3 - batch 51799: mean_policy_losses: 12.693, mean_net_lifetime: 4423.2451, mean_mc_travel_dist: 1224.8511, mean_rewards: 274.8385, total_rewards: 3228.4495, mean_steps: 15.1500, mean_ecr: 0.0484 mean_entropies: 0.5180, took: 77.6562s
2022-10-10 15:56:07,220 [INFO] 	Process 6 - batch 71599: mean_policy_losses: -173.260, mean_net_lifetime: 3525.1286, mean_mc_travel_dist: 939.3015, mean_rewards: 322.2774, total_rewards: 2603.0970, mean_steps: 9.9500, mean_ecr: 0.0559 mean_entropies: 0.1812, took: 54.4109s
2022-10-10 15:56:20,157 [INFO] 	Process 2 - batch 50799: mean_policy_losses: -20.933, mean_net_lifetime: 4729.3374, mean_mc_travel_dist: 1310.9244, mean_rewards: 284.5855, total_rewards: 3436.2066, mean_steps: 15.7100, mean_ecr: 0.0405 mean_entropies: 0.4851, took: 79.4913s
2022-10-10 15:56:44,591 [INFO] 	Process 4 - batch 56799: mean_policy_losses: 43.280, mean_net_lifetime: 4534.1825, mean_mc_travel_dist: 1292.0396, mean_rewards: 282.1808, total_rewards: 3272.9713, mean_steps: 15.1000, mean_ecr: 0.0482 mean_entropies: 0.6503, took: 80.1225s
2022-10-10 15:56:45,570 [INFO] 	Process 5 - batch 50199: mean_policy_losses: -390.661, mean_net_lifetime: 4314.0054, mean_mc_travel_dist: 1431.7456, mean_rewards: 264.7735, total_rewards: 2944.2952, mean_steps: 15.9800, mean_ecr: 0.0309 mean_entropies: 0.6663, took: 79.0189s
2022-10-10 15:56:58,389 [INFO] 	Process 6 - batch 71699: mean_policy_losses: -185.521, mean_net_lifetime: 3392.6358, mean_mc_travel_dist: 910.1244, mean_rewards: 324.1243, total_rewards: 2503.1577, mean_steps: 9.5000, mean_ecr: 0.0560 mean_entropies: 0.2025, took: 51.1691s
2022-10-10 15:57:15,064 [INFO] 	Process 3 - batch 51899: mean_policy_losses: 43.427, mean_net_lifetime: 4489.4356, mean_mc_travel_dist: 1271.7375, mean_rewards: 285.4173, total_rewards: 3255.8264, mean_steps: 14.8000, mean_ecr: 0.0484 mean_entropies: 0.5475, took: 75.7953s
2022-10-10 15:57:17,016 [INFO] 	Process 1 - batch 44299: mean_policy_losses: -54.154, mean_net_lifetime: 5224.8933, mean_mc_travel_dist: 1951.7804, mean_rewards: 266.3693, total_rewards: 3292.8126, mean_steps: 18.8000, mean_ecr: 0.0387 mean_entropies: 0.8259, took: 91.0654s
2022-10-10 15:57:38,023 [INFO] 	Process 2 - batch 50899: mean_policy_losses: -33.467, mean_net_lifetime: 4687.3355, mean_mc_travel_dist: 1356.6997, mean_rewards: 294.0339, total_rewards: 3354.8838, mean_steps: 15.0300, mean_ecr: 0.0404 mean_entropies: 0.4813, took: 77.8658s
2022-10-10 15:57:48,190 [INFO] 	Process 6 - batch 71799: mean_policy_losses: -290.968, mean_net_lifetime: 3193.4034, mean_mc_travel_dist: 861.0705, mean_rewards: 325.8100, total_rewards: 2353.1058, mean_steps: 8.9000, mean_ecr: 0.0559 mean_entropies: 0.2144, took: 49.8009s
2022-10-10 15:58:03,822 [INFO] 	Process 5 - batch 50299: mean_policy_losses: -428.069, mean_net_lifetime: 4138.8321, mean_mc_travel_dist: 1348.5954, mean_rewards: 258.6328, total_rewards: 2839.8063, mean_steps: 15.6700, mean_ecr: 0.0306 mean_entropies: 0.6795, took: 78.2524s
2022-10-10 15:58:05,012 [INFO] 	Process 4 - batch 56899: mean_policy_losses: 91.680, mean_net_lifetime: 4806.4527, mean_mc_travel_dist: 1407.9920, mean_rewards: 290.2936, total_rewards: 3430.6799, mean_steps: 15.6200, mean_ecr: 0.0473 mean_entropies: 0.5855, took: 80.4207s
2022-10-10 15:58:31,123 [INFO] 	Process 3 - batch 51999: mean_policy_losses: 30.771, mean_net_lifetime: 4447.2547, mean_mc_travel_dist: 1236.8503, mean_rewards: 280.8082, total_rewards: 3243.8230, mean_steps: 14.9200, mean_ecr: 0.0486 mean_entropies: 0.5224, took: 76.0579s
2022-10-10 15:58:40,412 [INFO] 	Process 6 - batch 71899: mean_policy_losses: -172.867, mean_net_lifetime: 3366.6690, mean_mc_travel_dist: 901.0032, mean_rewards: 325.2832, total_rewards: 2490.2533, mean_steps: 9.4100, mean_ecr: 0.0560 mean_entropies: 0.1753, took: 52.2219s
2022-10-10 15:58:49,341 [INFO] 	Process 1 - batch 44399: mean_policy_losses: -13.998, mean_net_lifetime: 5159.6551, mean_mc_travel_dist: 1870.3175, mean_rewards: 260.2580, total_rewards: 3319.1629, mean_steps: 19.0800, mean_ecr: 0.0388 mean_entropies: 0.8828, took: 92.3254s
2022-10-10 15:58:58,894 [INFO] 	Process 2 - batch 50999: mean_policy_losses: -21.367, mean_net_lifetime: 4720.5747, mean_mc_travel_dist: 1301.2801, mean_rewards: 289.1584, total_rewards: 3441.6548, mean_steps: 15.4100, mean_ecr: 0.0407 mean_entropies: 0.4676, took: 80.8700s
2022-10-10 15:59:26,389 [INFO] 	Process 4 - batch 56999: mean_policy_losses: 92.831, mean_net_lifetime: 4829.1075, mean_mc_travel_dist: 1379.8550, mean_rewards: 286.3572, total_rewards: 3478.0209, mean_steps: 15.9600, mean_ecr: 0.0474 mean_entropies: 0.6171, took: 81.3779s
2022-10-10 15:59:28,392 [INFO] 	Process 6 - batch 71999: mean_policy_losses: -175.635, mean_net_lifetime: 3238.4126, mean_mc_travel_dist: 863.8161, mean_rewards: 331.0892, total_rewards: 2398.8502, mean_steps: 8.8100, mean_ecr: 0.0562 mean_entropies: 0.1723, took: 47.9802s
2022-10-10 15:59:30,097 [INFO] 	Process 5 - batch 50399: mean_policy_losses: -330.997, mean_net_lifetime: 4650.2564, mean_mc_travel_dist: 1563.2309, mean_rewards: 256.5810, total_rewards: 3136.0969, mean_steps: 17.7400, mean_ecr: 0.0304 mean_entropies: 0.6511, took: 86.2753s
2022-10-10 15:59:46,098 [INFO] 	Process 3 - batch 52099: mean_policy_losses: 34.706, mean_net_lifetime: 4540.7948, mean_mc_travel_dist: 1236.1206, mean_rewards: 281.4941, total_rewards: 3332.9813, mean_steps: 15.1800, mean_ecr: 0.0484 mean_entropies: 0.5146, took: 74.9758s
2022-10-10 16:00:19,717 [INFO] 	Process 1 - batch 44499: mean_policy_losses: -21.127, mean_net_lifetime: 5351.3286, mean_mc_travel_dist: 1872.7533, mean_rewards: 255.0519, total_rewards: 3499.9507, mean_steps: 20.1300, mean_ecr: 0.0388 mean_entropies: 0.9193, took: 90.3758s
2022-10-10 16:00:54,197 [INFO] 	Process 3 - batch 52199: mean_policy_losses: 1.016, mean_net_lifetime: 4561.0526, mean_mc_travel_dist: 1301.6494, mean_rewards: 291.5581, total_rewards: 3296.8993, mean_steps: 14.7000, mean_ecr: 0.0481 mean_entropies: 0.5533, took: 68.0998s
2022-10-10 16:00:56,976 [INFO] 	Process 5 - batch 50499: mean_policy_losses: -235.957, mean_net_lifetime: 5423.4792, mean_mc_travel_dist: 1826.3718, mean_rewards: 268.5018, total_rewards: 3642.9722, mean_steps: 19.6400, mean_ecr: 0.0308 mean_entropies: 0.6735, took: 86.8789s
2022-10-10 16:01:48,333 [INFO] 	Process 1 - batch 44599: mean_policy_losses: -31.253, mean_net_lifetime: 5548.1798, mean_mc_travel_dist: 2008.6823, mean_rewards: 263.0359, total_rewards: 3569.6952, mean_steps: 20.1900, mean_ecr: 0.0384 mean_entropies: 0.8811, took: 88.6156s
2022-10-10 16:02:03,431 [INFO] 	Process 3 - batch 52299: mean_policy_losses: 10.814, mean_net_lifetime: 4529.0263, mean_mc_travel_dist: 1289.2110, mean_rewards: 284.7898, total_rewards: 3272.4368, mean_steps: 14.9600, mean_ecr: 0.0480 mean_entropies: 0.5668, took: 69.2339s
2022-10-10 16:02:24,883 [INFO] 	Process 5 - batch 50599: mean_policy_losses: -200.682, mean_net_lifetime: 5657.6262, mean_mc_travel_dist: 1904.2328, mean_rewards: 273.0197, total_rewards: 3794.6134, mean_steps: 20.0700, mean_ecr: 0.0311 mean_entropies: 0.6684, took: 87.9071s
2022-10-10 16:03:15,112 [INFO] 	Process 3 - batch 52399: mean_policy_losses: 24.491, mean_net_lifetime: 4665.8833, mean_mc_travel_dist: 1317.1033, mean_rewards: 281.9330, total_rewards: 3384.0793, mean_steps: 15.5800, mean_ecr: 0.0478 mean_entropies: 0.5384, took: 71.6806s
2022-10-10 16:03:19,147 [INFO] 	Process 1 - batch 44699: mean_policy_losses: -55.984, mean_net_lifetime: 5465.3966, mean_mc_travel_dist: 1972.3670, mean_rewards: 254.3065, total_rewards: 3522.2442, mean_steps: 20.7400, mean_ecr: 0.0384 mean_entropies: 0.8258, took: 90.8145s
2022-10-10 16:03:54,889 [INFO] Process 7 - epoch 34: mean_policy_losses: -277.665, mean_net_lifetime: 3975.7360, mean_mc_travel_dist: 1590.8240, mean_entropies: 1.7113, m_net_lifetime_valid: 4489.1794, took: 1819.6888s, (155.8579 / 100 batches)

2022-10-10 16:03:57,428 [INFO] 	Process 5 - batch 50699: mean_policy_losses: -213.340, mean_net_lifetime: 5941.2398, mean_mc_travel_dist: 2023.9132, mean_rewards: 274.1824, total_rewards: 3969.4004, mean_steps: 20.8400, mean_ecr: 0.0309 mean_entropies: 0.7084, took: 92.5456s
2022-10-10 16:04:30,726 [INFO] 	Process 3 - batch 52499: mean_policy_losses: 47.934, mean_net_lifetime: 4760.4586, mean_mc_travel_dist: 1396.6855, mean_rewards: 280.9575, total_rewards: 3399.8751, mean_steps: 16.0000, mean_ecr: 0.0469 mean_entropies: 0.5619, took: 75.6141s
2022-10-10 16:05:05,679 [INFO] 	Process 1 - batch 44799: mean_policy_losses: 22.393, mean_net_lifetime: 5790.5578, mean_mc_travel_dist: 1972.2549, mean_rewards: 232.7408, total_rewards: 3850.2980, mean_steps: 24.0600, mean_ecr: 0.0386 mean_entropies: 0.9548, took: 106.5307s
2022-10-10 16:05:31,580 [INFO] 	Process 7 - batch 51099: mean_policy_losses: -258.765, mean_net_lifetime: 4931.3153, mean_mc_travel_dist: 1615.0930, mean_rewards: 216.6746, total_rewards: 3355.4168, mean_steps: 21.9900, mean_ecr: 0.0413 mean_entropies: 1.3459, took: 693.3073s
2022-10-10 16:05:32,983 [INFO] 	Process 5 - batch 50799: mean_policy_losses: -79.310, mean_net_lifetime: 6228.2266, mean_mc_travel_dist: 2107.7994, mean_rewards: 279.6964, total_rewards: 4180.3706, mean_steps: 21.5100, mean_ecr: 0.0310 mean_entropies: 0.7386, took: 95.5541s
2022-10-10 16:06:51,107 [INFO] 	Process 1 - batch 44899: mean_policy_losses: 94.748, mean_net_lifetime: 6068.7294, mean_mc_travel_dist: 2040.0747, mean_rewards: 238.9394, total_rewards: 4058.3657, mean_steps: 24.6400, mean_ecr: 0.0385 mean_entropies: 1.0399, took: 105.4290s
2022-10-10 16:06:59,489 [INFO] 	Process 7 - batch 51199: mean_policy_losses: -402.812, mean_net_lifetime: 4515.9048, mean_mc_travel_dist: 1510.4378, mean_rewards: 220.1963, total_rewards: 3054.7370, mean_steps: 19.7400, mean_ecr: 0.0416 mean_entropies: 1.3806, took: 87.9088s
2022-10-10 16:07:12,708 [INFO] 	Process 5 - batch 50899: mean_policy_losses: -37.400, mean_net_lifetime: 6541.2156, mean_mc_travel_dist: 2239.5670, mean_rewards: 277.0962, total_rewards: 4353.5885, mean_steps: 22.7700, mean_ecr: 0.0309 mean_entropies: 0.7819, took: 99.7254s
2022-10-10 16:07:46,140 [INFO] Process 2 - epoch 34: mean_policy_losses: 7.801, mean_net_lifetime: 4294.3944, mean_mc_travel_dist: 1571.7298, mean_entropies: 1.0994, m_net_lifetime_valid: 4393.3728, took: 1715.5741s, (156.4465 / 100 batches)

2022-10-10 16:07:46,565 [INFO] Process 4 - epoch 38: mean_policy_losses: 87.118, mean_net_lifetime: 3876.3546, mean_mc_travel_dist: 1304.6670, mean_entropies: 1.3251, m_net_lifetime_valid: 4401.0204, took: 1723.9011s, (140.0551 / 100 batches)

2022-10-10 16:07:51,146 [INFO] Process 6 - epoch 48: mean_policy_losses: -248.386, mean_net_lifetime: 2772.9838, mean_mc_travel_dist: 949.9089, mean_entropies: 0.7618, m_net_lifetime_valid: 4198.5813, took: 1301.9817s, (110.9197 / 100 batches)

2022-10-10 16:08:33,415 [INFO] 	Process 1 - batch 44999: mean_policy_losses: 112.893, mean_net_lifetime: 5905.7524, mean_mc_travel_dist: 1996.2356, mean_rewards: 254.6337, total_rewards: 3939.2402, mean_steps: 22.3800, mean_ecr: 0.0384 mean_entropies: 0.9831, took: 102.3081s
2022-10-10 16:08:35,835 [INFO] 	Process 7 - batch 51299: mean_policy_losses: -316.668, mean_net_lifetime: 4829.8139, mean_mc_travel_dist: 1676.3595, mean_rewards: 222.2220, total_rewards: 3194.4497, mean_steps: 21.1400, mean_ecr: 0.0412 mean_entropies: 1.2781, took: 96.3456s
2022-10-10 16:08:40,791 [INFO] 	Process 6 - batch 72099: mean_policy_losses: -119.375, mean_net_lifetime: 3309.3400, mean_mc_travel_dist: 881.3947, mean_rewards: 336.1074, total_rewards: 2448.5914, mean_steps: 8.8900, mean_ecr: 0.0562 mean_entropies: 0.1982, took: 552.3991s
2022-10-10 16:08:50,351 [INFO] 	Process 5 - batch 50999: mean_policy_losses: -73.134, mean_net_lifetime: 5796.8883, mean_mc_travel_dist: 1995.1160, mean_rewards: 267.4987, total_rewards: 3854.8720, mean_steps: 20.7100, mean_ecr: 0.0313 mean_entropies: 0.6834, took: 97.6424s
2022-10-10 16:09:01,206 [INFO] 	Process 4 - batch 57099: mean_policy_losses: 44.600, mean_net_lifetime: 3717.6120, mean_mc_travel_dist: 1145.9987, mean_rewards: 238.8016, total_rewards: 2606.1352, mean_steps: 14.5700, mean_ecr: 0.0497 mean_entropies: 0.8157, took: 574.8165s
2022-10-10 16:09:09,652 [INFO] 	Process 2 - batch 51099: mean_policy_losses: -12.670, mean_net_lifetime: 4885.1511, mean_mc_travel_dist: 1419.4778, mean_rewards: 271.8715, total_rewards: 3488.5579, mean_steps: 17.0900, mean_ecr: 0.0402 mean_entropies: 0.5542, took: 610.7586s
2022-10-10 16:09:27,612 [INFO] 	Process 6 - batch 72199: mean_policy_losses: -165.003, mean_net_lifetime: 3308.2438, mean_mc_travel_dist: 895.2915, mean_rewards: 332.4858, total_rewards: 2439.7409, mean_steps: 8.9900, mean_ecr: 0.0561 mean_entropies: 0.1939, took: 46.8203s
2022-10-10 16:10:08,764 [INFO] 	Process 7 - batch 51399: mean_policy_losses: -423.600, mean_net_lifetime: 4408.1759, mean_mc_travel_dist: 1723.3562, mean_rewards: 217.0906, total_rewards: 2728.5171, mean_steps: 20.8200, mean_ecr: 0.0412 mean_entropies: 1.1294, took: 92.9289s
2022-10-10 16:10:19,244 [INFO] 	Process 6 - batch 72299: mean_policy_losses: -124.807, mean_net_lifetime: 3549.9420, mean_mc_travel_dist: 944.9049, mean_rewards: 321.3368, total_rewards: 2630.5386, mean_steps: 10.1000, mean_ecr: 0.0558 mean_entropies: 0.1706, took: 51.6317s
2022-10-10 16:10:21,166 [INFO] 	Process 4 - batch 57199: mean_policy_losses: 122.171, mean_net_lifetime: 4811.6738, mean_mc_travel_dist: 1381.9815, mean_rewards: 281.8581, total_rewards: 3457.7444, mean_steps: 16.1900, mean_ecr: 0.0473 mean_entropies: 0.5980, took: 79.9596s
2022-10-10 16:10:27,109 [INFO] 	Process 2 - batch 51199: mean_policy_losses: -26.166, mean_net_lifetime: 4708.1976, mean_mc_travel_dist: 1320.1028, mean_rewards: 276.0029, total_rewards: 3408.3909, mean_steps: 16.1500, mean_ecr: 0.0406 mean_entropies: 0.4726, took: 77.4573s
2022-10-10 16:11:12,784 [INFO] 	Process 6 - batch 72399: mean_policy_losses: -144.841, mean_net_lifetime: 3641.2948, mean_mc_travel_dist: 964.9707, mean_rewards: 313.4749, total_rewards: 2703.1746, mean_steps: 10.6100, mean_ecr: 0.0558 mean_entropies: 0.1476, took: 53.5405s
2022-10-10 16:11:33,419 [INFO] 	Process 7 - batch 51499: mean_policy_losses: -535.492, mean_net_lifetime: 4424.1344, mean_mc_travel_dist: 1629.6152, mean_rewards: 234.0187, total_rewards: 2849.3922, mean_steps: 18.6800, mean_ecr: 0.0412 mean_entropies: 1.1297, took: 84.6555s
2022-10-10 16:11:39,736 [INFO] 	Process 4 - batch 57299: mean_policy_losses: 94.776, mean_net_lifetime: 4942.3171, mean_mc_travel_dist: 1420.6815, mean_rewards: 283.0175, total_rewards: 3548.0294, mean_steps: 16.5300, mean_ecr: 0.0469 mean_entropies: 0.5756, took: 78.5703s
2022-10-10 16:11:46,149 [INFO] 	Process 2 - batch 51299: mean_policy_losses: -30.808, mean_net_lifetime: 4714.5291, mean_mc_travel_dist: 1320.4674, mean_rewards: 267.2284, total_rewards: 3416.4575, mean_steps: 16.7400, mean_ecr: 0.0406 mean_entropies: 0.4242, took: 79.0397s
2022-10-10 16:12:08,731 [INFO] 	Process 6 - batch 72499: mean_policy_losses: -69.470, mean_net_lifetime: 3809.8077, mean_mc_travel_dist: 1004.1814, mean_rewards: 308.5484, total_rewards: 2825.6881, mean_steps: 11.3900, mean_ecr: 0.0557 mean_entropies: 0.1475, took: 55.9470s
2022-10-10 16:12:40,882 [INFO] 	Process 7 - batch 51599: mean_policy_losses: -768.122, mean_net_lifetime: 3684.3519, mean_mc_travel_dist: 1413.0701, mean_rewards: 248.4242, total_rewards: 2321.2350, mean_steps: 14.7500, mean_ecr: 0.0415 mean_entropies: 1.0832, took: 67.4632s
2022-10-10 16:12:58,152 [INFO] Process 3 - epoch 35: mean_policy_losses: 83.858, mean_net_lifetime: 4149.7977, mean_mc_travel_dist: 1393.8754, mean_entropies: 1.0690, m_net_lifetime_valid: 4632.5589, took: 1653.6439s, (152.6145 / 100 batches)

2022-10-10 16:12:58,304 [INFO] 	Process 4 - batch 57399: mean_policy_losses: 91.281, mean_net_lifetime: 5046.8747, mean_mc_travel_dist: 1464.6754, mean_rewards: 289.8222, total_rewards: 3601.9185, mean_steps: 16.4700, mean_ecr: 0.0467 mean_entropies: 0.5057, took: 78.5684s
2022-10-10 16:13:03,528 [INFO] 	Process 2 - batch 51399: mean_policy_losses: -26.235, mean_net_lifetime: 4715.7073, mean_mc_travel_dist: 1311.5855, mean_rewards: 273.4269, total_rewards: 3428.8249, mean_steps: 16.3300, mean_ecr: 0.0407 mean_entropies: 0.4226, took: 77.3790s
2022-10-10 16:13:04,046 [INFO] 	Process 6 - batch 72599: mean_policy_losses: -98.924, mean_net_lifetime: 3762.3997, mean_mc_travel_dist: 999.7692, mean_rewards: 312.7487, total_rewards: 2788.1849, mean_steps: 11.0600, mean_ecr: 0.0557 mean_entropies: 0.1502, took: 55.3153s
2022-10-10 16:13:56,781 [INFO] 	Process 6 - batch 72699: mean_policy_losses: -128.628, mean_net_lifetime: 3520.9439, mean_mc_travel_dist: 939.6388, mean_rewards: 321.6794, total_rewards: 2607.1446, mean_steps: 10.0300, mean_ecr: 0.0560 mean_entropies: 0.1525, took: 52.7352s
2022-10-10 16:13:57,313 [INFO] 	Process 7 - batch 51699: mean_policy_losses: -693.481, mean_net_lifetime: 4081.7925, mean_mc_travel_dist: 1468.9245, mean_rewards: 241.2500, total_rewards: 2656.9132, mean_steps: 16.2600, mean_ecr: 0.0414 mean_entropies: 1.1311, took: 76.4306s
2022-10-10 16:14:14,927 [INFO] 	Process 3 - batch 52599: mean_policy_losses: 22.306, mean_net_lifetime: 4430.0304, mean_mc_travel_dist: 1206.9411, mean_rewards: 267.4344, total_rewards: 3249.7661, mean_steps: 15.6200, mean_ecr: 0.0485 mean_entropies: 0.4597, took: 584.2010s
2022-10-10 16:14:21,578 [INFO] 	Process 4 - batch 57499: mean_policy_losses: 109.087, mean_net_lifetime: 5054.1839, mean_mc_travel_dist: 1479.1191, mean_rewards: 290.5840, total_rewards: 3603.9554, mean_steps: 16.5300, mean_ecr: 0.0466 mean_entropies: 0.5405, took: 83.2742s
2022-10-10 16:14:22,835 [INFO] 	Process 2 - batch 51499: mean_policy_losses: -20.175, mean_net_lifetime: 4714.2177, mean_mc_travel_dist: 1320.3131, mean_rewards: 277.0287, total_rewards: 3418.9760, mean_steps: 16.1000, mean_ecr: 0.0407 mean_entropies: 0.4514, took: 79.3077s
2022-10-10 16:14:46,435 [INFO] 	Process 6 - batch 72799: mean_policy_losses: -94.465, mean_net_lifetime: 3362.8562, mean_mc_travel_dist: 891.8797, mean_rewards: 331.8719, total_rewards: 2489.2707, mean_steps: 9.2100, mean_ecr: 0.0560 mean_entropies: 0.1631, took: 49.6533s
2022-10-10 16:15:12,023 [INFO] 	Process 7 - batch 51799: mean_policy_losses: -687.861, mean_net_lifetime: 3917.2045, mean_mc_travel_dist: 1477.7449, mean_rewards: 248.0721, total_rewards: 2493.3660, mean_steps: 15.8400, mean_ecr: 0.0413 mean_entropies: 1.1680, took: 74.7104s
2022-10-10 16:15:31,401 [INFO] 	Process 3 - batch 52699: mean_policy_losses: -5.593, mean_net_lifetime: 4242.4649, mean_mc_travel_dist: 1157.0521, mean_rewards: 257.4519, total_rewards: 3109.7865, mean_steps: 15.5500, mean_ecr: 0.0490 mean_entropies: 0.4706, took: 76.4738s
2022-10-10 16:15:40,676 [INFO] 	Process 6 - batch 72899: mean_policy_losses: -106.059, mean_net_lifetime: 3594.7697, mean_mc_travel_dist: 945.4535, mean_rewards: 315.4824, total_rewards: 2670.4043, mean_steps: 10.5000, mean_ecr: 0.0559 mean_entropies: 0.1463, took: 54.2414s
2022-10-10 16:15:41,688 [INFO] 	Process 4 - batch 57599: mean_policy_losses: 114.728, mean_net_lifetime: 5011.6710, mean_mc_travel_dist: 1428.8150, mean_rewards: 295.4533, total_rewards: 3609.7714, mean_steps: 16.0100, mean_ecr: 0.0469 mean_entropies: 0.5450, took: 80.1097s
2022-10-10 16:15:42,676 [INFO] 	Process 2 - batch 51599: mean_policy_losses: -14.398, mean_net_lifetime: 4705.3606, mean_mc_travel_dist: 1299.3198, mean_rewards: 273.9520, total_rewards: 3432.3205, mean_steps: 16.2600, mean_ecr: 0.0408 mean_entropies: 0.4131, took: 79.8414s
2022-10-10 16:16:26,785 [INFO] 	Process 6 - batch 72999: mean_policy_losses: -178.628, mean_net_lifetime: 3133.1398, mean_mc_travel_dist: 845.0665, mean_rewards: 323.9744, total_rewards: 2318.6277, mean_steps: 8.6300, mean_ecr: 0.0564 mean_entropies: 0.1894, took: 46.1090s
2022-10-10 16:16:43,735 [INFO] 	Process 7 - batch 51899: mean_policy_losses: -469.566, mean_net_lifetime: 4663.6136, mean_mc_travel_dist: 1628.6372, mean_rewards: 233.1918, total_rewards: 3077.9346, mean_steps: 19.6000, mean_ecr: 0.0410 mean_entropies: 1.2519, took: 91.7117s
2022-10-10 16:16:48,004 [INFO] 	Process 3 - batch 52799: mean_policy_losses: 47.662, mean_net_lifetime: 4477.2937, mean_mc_travel_dist: 1231.8990, mean_rewards: 274.2367, total_rewards: 3274.5888, mean_steps: 15.4500, mean_ecr: 0.0483 mean_entropies: 0.4800, took: 76.6026s
2022-10-10 16:17:01,069 [INFO] 	Process 2 - batch 51699: mean_policy_losses: 3.951, mean_net_lifetime: 4805.1272, mean_mc_travel_dist: 1365.9529, mean_rewards: 283.7102, total_rewards: 3463.0384, mean_steps: 16.0800, mean_ecr: 0.0404 mean_entropies: 0.4860, took: 78.3926s
2022-10-10 16:17:02,517 [INFO] Process 1 - epoch 30: mean_policy_losses: 42.223, mean_net_lifetime: 4818.3505, mean_mc_travel_dist: 2048.2493, mean_entropies: 1.3108, m_net_lifetime_valid: 4315.7102, took: 1971.9092s, (178.5335 / 100 batches)

2022-10-10 16:17:04,627 [INFO] 	Process 4 - batch 57699: mean_policy_losses: 119.313, mean_net_lifetime: 5086.6476, mean_mc_travel_dist: 1452.9448, mean_rewards: 286.3410, total_rewards: 3661.8356, mean_steps: 16.8400, mean_ecr: 0.0465 mean_entropies: 0.6371, took: 82.9386s
2022-10-10 16:17:08,319 [INFO] 	Process 6 - batch 73099: mean_policy_losses: -155.807, mean_net_lifetime: 2787.8629, mean_mc_travel_dist: 772.9044, mean_rewards: 330.7458, total_rewards: 2057.3953, mean_steps: 7.3900, mean_ecr: 0.0571 mean_entropies: 0.2007, took: 41.5339s
2022-10-10 16:17:57,251 [INFO] Process 5 - epoch 34: mean_policy_losses: -214.973, mean_net_lifetime: 4503.6362, mean_mc_travel_dist: 1912.9619, mean_entropies: 1.3888, m_net_lifetime_valid: 4395.3563, took: 1845.2140s, (157.6038 / 100 batches)

2022-10-10 16:18:01,255 [INFO] 	Process 6 - batch 73199: mean_policy_losses: -128.560, mean_net_lifetime: 3500.0297, mean_mc_travel_dist: 936.8043, mean_rewards: 330.8588, total_rewards: 2575.3044, mean_steps: 9.6300, mean_ecr: 0.0560 mean_entropies: 0.1757, took: 52.9361s
2022-10-10 16:18:05,790 [INFO] 	Process 3 - batch 52899: mean_policy_losses: 15.447, mean_net_lifetime: 4465.1186, mean_mc_travel_dist: 1223.7896, mean_rewards: 275.0514, total_rewards: 3258.3683, mean_steps: 15.3000, mean_ecr: 0.0486 mean_entropies: 0.4941, took: 77.7867s
2022-10-10 16:18:14,170 [INFO] 	Process 7 - batch 51999: mean_policy_losses: -591.706, mean_net_lifetime: 4429.7107, mean_mc_travel_dist: 1579.9797, mean_rewards: 230.8570, total_rewards: 2897.3330, mean_steps: 18.5500, mean_ecr: 0.0414 mean_entropies: 1.2574, took: 90.4356s
2022-10-10 16:18:24,671 [INFO] 	Process 2 - batch 51799: mean_policy_losses: -22.328, mean_net_lifetime: 4753.3412, mean_mc_travel_dist: 1330.7490, mean_rewards: 280.0846, total_rewards: 3448.0529, mean_steps: 16.0500, mean_ecr: 0.0406 mean_entropies: 0.4482, took: 83.6019s
2022-10-10 16:18:29,610 [INFO] 	Process 4 - batch 57799: mean_policy_losses: 58.938, mean_net_lifetime: 4858.5817, mean_mc_travel_dist: 1375.4773, mean_rewards: 282.9316, total_rewards: 3508.3022, mean_steps: 16.2200, mean_ecr: 0.0474 mean_entropies: 0.6333, took: 84.9832s
2022-10-10 16:18:46,508 [INFO] 	Process 1 - batch 45099: mean_policy_losses: 122.473, mean_net_lifetime: 5649.3574, mean_mc_travel_dist: 1924.6250, mean_rewards: 256.1941, total_rewards: 3741.8186, mean_steps: 21.2600, mean_ecr: 0.0385 mean_entropies: 0.9878, took: 613.0917s
2022-10-10 16:19:00,415 [INFO] 	Process 6 - batch 73299: mean_policy_losses: -99.174, mean_net_lifetime: 3665.1913, mean_mc_travel_dist: 975.7553, mean_rewards: 316.5424, total_rewards: 2712.8375, mean_steps: 10.6600, mean_ecr: 0.0558 mean_entropies: 0.1547, took: 59.1602s
2022-10-10 16:19:16,443 [INFO] 	Process 5 - batch 51099: mean_policy_losses: -383.331, mean_net_lifetime: 3892.5139, mean_mc_travel_dist: 1278.4303, mean_rewards: 251.4752, total_rewards: 2675.0448, mean_steps: 15.2900, mean_ecr: 0.0307 mean_entropies: 0.6108, took: 626.0925s
2022-10-10 16:19:26,611 [INFO] 	Process 3 - batch 52999: mean_policy_losses: 16.711, mean_net_lifetime: 4444.4548, mean_mc_travel_dist: 1221.2834, mean_rewards: 272.1785, total_rewards: 3253.8915, mean_steps: 15.3600, mean_ecr: 0.0486 mean_entropies: 0.4759, took: 80.8211s
2022-10-10 16:19:37,524 [INFO] 	Process 7 - batch 52099: mean_policy_losses: -769.767, mean_net_lifetime: 3993.4693, mean_mc_travel_dist: 1410.5803, mean_rewards: 241.7037, total_rewards: 2629.9239, mean_steps: 16.0600, mean_ecr: 0.0415 mean_entropies: 1.3031, took: 83.3536s
2022-10-10 16:19:48,092 [INFO] 	Process 2 - batch 51899: mean_policy_losses: -20.212, mean_net_lifetime: 4720.1781, mean_mc_travel_dist: 1322.2742, mean_rewards: 279.8999, total_rewards: 3422.8574, mean_steps: 15.9500, mean_ecr: 0.0406 mean_entropies: 0.4625, took: 83.4213s
2022-10-10 16:19:52,977 [INFO] 	Process 6 - batch 73399: mean_policy_losses: -109.658, mean_net_lifetime: 3403.3146, mean_mc_travel_dist: 914.2473, mean_rewards: 331.6318, total_rewards: 2506.9693, mean_steps: 9.2500, mean_ecr: 0.0562 mean_entropies: 0.1758, took: 52.5613s
2022-10-10 16:19:59,196 [INFO] 	Process 4 - batch 57899: mean_policy_losses: 93.473, mean_net_lifetime: 4926.1021, mean_mc_travel_dist: 1399.4676, mean_rewards: 282.1079, total_rewards: 3553.5928, mean_steps: 16.4800, mean_ecr: 0.0470 mean_entropies: 0.6385, took: 89.5863s
2022-10-10 16:20:34,778 [INFO] 	Process 1 - batch 45199: mean_policy_losses: 137.923, mean_net_lifetime: 5792.7466, mean_mc_travel_dist: 1963.6459, mean_rewards: 253.5869, total_rewards: 3856.8800, mean_steps: 22.0200, mean_ecr: 0.0384 mean_entropies: 0.9661, took: 108.2713s
2022-10-10 16:20:45,521 [INFO] 	Process 5 - batch 51199: mean_policy_losses: -312.695, mean_net_lifetime: 4630.8548, mean_mc_travel_dist: 1562.4864, mean_rewards: 259.2523, total_rewards: 3139.2763, mean_steps: 17.5200, mean_ecr: 0.0304 mean_entropies: 0.6310, took: 89.0782s
2022-10-10 16:20:46,714 [INFO] 	Process 3 - batch 53099: mean_policy_losses: 22.402, mean_net_lifetime: 4482.8746, mean_mc_travel_dist: 1228.7358, mean_rewards: 275.5662, total_rewards: 3282.4952, mean_steps: 15.3500, mean_ecr: 0.0486 mean_entropies: 0.4831, took: 80.1023s
2022-10-10 16:20:49,999 [INFO] 	Process 6 - batch 73499: mean_policy_losses: -174.293, mean_net_lifetime: 3551.6348, mean_mc_travel_dist: 948.8336, mean_rewards: 319.7366, total_rewards: 2621.7126, mean_steps: 10.1800, mean_ecr: 0.0557 mean_entropies: 0.1662, took: 57.0216s
2022-10-10 16:20:53,957 [INFO] 	Process 7 - batch 52199: mean_policy_losses: -837.879, mean_net_lifetime: 3810.0375, mean_mc_travel_dist: 1339.5316, mean_rewards: 252.7701, total_rewards: 2502.9237, mean_steps: 14.7300, mean_ecr: 0.0418 mean_entropies: 1.3126, took: 76.4332s
2022-10-10 16:21:12,357 [INFO] 	Process 2 - batch 51999: mean_policy_losses: -21.036, mean_net_lifetime: 4712.1440, mean_mc_travel_dist: 1295.6913, mean_rewards: 280.4745, total_rewards: 3438.0951, mean_steps: 15.8800, mean_ecr: 0.0408 mean_entropies: 0.4521, took: 84.2650s
2022-10-10 16:21:27,654 [INFO] 	Process 4 - batch 57999: mean_policy_losses: 115.666, mean_net_lifetime: 5244.0834, mean_mc_travel_dist: 1523.5562, mean_rewards: 299.5951, total_rewards: 3748.2127, mean_steps: 16.7500, mean_ecr: 0.0462 mean_entropies: 0.5682, took: 88.4573s
2022-10-10 16:22:05,067 [INFO] 	Process 3 - batch 53199: mean_policy_losses: 31.158, mean_net_lifetime: 4499.6599, mean_mc_travel_dist: 1246.5473, mean_rewards: 278.3168, total_rewards: 3283.8240, mean_steps: 15.2200, mean_ecr: 0.0485 mean_entropies: 0.5047, took: 78.3533s
2022-10-10 16:22:06,913 [INFO] 	Process 5 - batch 51299: mean_policy_losses: -474.079, mean_net_lifetime: 4358.0925, mean_mc_travel_dist: 1427.2335, mean_rewards: 264.1303, total_rewards: 2975.4058, mean_steps: 16.3200, mean_ecr: 0.0306 mean_entropies: 0.6510, took: 81.3924s
2022-10-10 16:22:07,447 [INFO] 	Process 7 - batch 52299: mean_policy_losses: -969.490, mean_net_lifetime: 3582.5532, mean_mc_travel_dist: 1361.9693, mean_rewards: 239.6825, total_rewards: 2262.5633, mean_steps: 14.6200, mean_ecr: 0.0417 mean_entropies: 1.3166, took: 73.4903s
2022-10-10 16:22:20,575 [INFO] 	Process 1 - batch 45299: mean_policy_losses: 84.460, mean_net_lifetime: 5527.7639, mean_mc_travel_dist: 1906.2887, mean_rewards: 244.5394, total_rewards: 3657.1945, mean_steps: 21.9000, mean_ecr: 0.0386 mean_entropies: 0.9669, took: 105.7956s
2022-10-10 16:22:33,896 [INFO] 	Process 2 - batch 52099: mean_policy_losses: -25.163, mean_net_lifetime: 4720.4628, mean_mc_travel_dist: 1329.5236, mean_rewards: 281.1950, total_rewards: 3416.1528, mean_steps: 15.8800, mean_ecr: 0.0405 mean_entropies: 0.4946, took: 81.5393s
2022-10-10 16:22:50,328 [INFO] 	Process 4 - batch 58099: mean_policy_losses: 40.498, mean_net_lifetime: 4727.9971, mean_mc_travel_dist: 1358.3496, mean_rewards: 287.5476, total_rewards: 3399.3673, mean_steps: 15.4900, mean_ecr: 0.0476 mean_entropies: 0.6626, took: 82.6746s
2022-10-10 16:23:19,879 [INFO] 	Process 7 - batch 52399: mean_policy_losses: -942.393, mean_net_lifetime: 3708.0406, mean_mc_travel_dist: 1288.1178, mean_rewards: 249.5794, total_rewards: 2455.2364, mean_steps: 14.2700, mean_ecr: 0.0419 mean_entropies: 1.3615, took: 72.4317s
2022-10-10 16:23:20,715 [INFO] 	Process 3 - batch 53299: mean_policy_losses: 23.119, mean_net_lifetime: 4537.4465, mean_mc_travel_dist: 1299.1921, mean_rewards: 288.4438, total_rewards: 3273.9082, mean_steps: 14.7700, mean_ecr: 0.0479 mean_entropies: 0.5318, took: 75.6477s
2022-10-10 16:23:39,576 [INFO] 	Process 5 - batch 51399: mean_policy_losses: -256.039, mean_net_lifetime: 5134.3873, mean_mc_travel_dist: 1721.5962, mean_rewards: 265.1901, total_rewards: 3463.3951, mean_steps: 18.7800, mean_ecr: 0.0308 mean_entropies: 0.6915, took: 92.6623s
2022-10-10 16:23:52,107 [INFO] 	Process 2 - batch 52199: mean_policy_losses: -24.978, mean_net_lifetime: 4763.7300, mean_mc_travel_dist: 1341.0352, mean_rewards: 295.7892, total_rewards: 3449.9564, mean_steps: 15.2000, mean_ecr: 0.0405 mean_entropies: 0.5447, took: 78.2102s
2022-10-10 16:24:03,594 [INFO] 	Process 1 - batch 45399: mean_policy_losses: 98.950, mean_net_lifetime: 5660.9231, mean_mc_travel_dist: 1888.4675, mean_rewards: 251.2684, total_rewards: 3796.4739, mean_steps: 21.6900, mean_ecr: 0.0387 mean_entropies: 1.0009, took: 103.0206s
2022-10-10 16:24:15,921 [INFO] 	Process 4 - batch 58199: mean_policy_losses: 105.564, mean_net_lifetime: 4950.8010, mean_mc_travel_dist: 1390.1388, mean_rewards: 290.9006, total_rewards: 3600.8740, mean_steps: 16.1200, mean_ecr: 0.0474 mean_entropies: 0.6332, took: 85.5927s
2022-10-10 16:24:33,711 [INFO] 	Process 7 - batch 52499: mean_policy_losses: -914.874, mean_net_lifetime: 3681.6017, mean_mc_travel_dist: 1275.0998, mean_rewards: 247.2816, total_rewards: 2452.3931, mean_steps: 14.4300, mean_ecr: 0.0418 mean_entropies: 1.3236, took: 73.8320s
2022-10-10 16:24:35,917 [INFO] 	Process 3 - batch 53399: mean_policy_losses: 39.074, mean_net_lifetime: 4537.0319, mean_mc_travel_dist: 1275.6596, mean_rewards: 288.6859, total_rewards: 3294.2510, mean_steps: 14.7700, mean_ecr: 0.0483 mean_entropies: 0.5122, took: 75.2020s
2022-10-10 16:25:04,295 [INFO] 	Process 5 - batch 51499: mean_policy_losses: -331.541, mean_net_lifetime: 4707.2146, mean_mc_travel_dist: 1559.6848, mean_rewards: 269.9274, total_rewards: 3202.8425, mean_steps: 17.2200, mean_ecr: 0.0309 mean_entropies: 0.6608, took: 84.7170s
2022-10-10 16:25:09,172 [INFO] 	Process 2 - batch 52299: mean_policy_losses: -27.847, mean_net_lifetime: 4734.2505, mean_mc_travel_dist: 1303.1725, mean_rewards: 293.5975, total_rewards: 3445.8104, mean_steps: 15.2100, mean_ecr: 0.0407 mean_entropies: 0.5119, took: 77.0648s
2022-10-10 16:25:36,495 [INFO] 	Process 1 - batch 45499: mean_policy_losses: 40.073, mean_net_lifetime: 5514.5303, mean_mc_travel_dist: 1927.3973, mean_rewards: 269.3372, total_rewards: 3613.1944, mean_steps: 19.5800, mean_ecr: 0.0386 mean_entropies: 0.9414, took: 92.9012s
2022-10-10 16:25:39,640 [INFO] 	Process 4 - batch 58299: mean_policy_losses: 29.360, mean_net_lifetime: 4685.5829, mean_mc_travel_dist: 1341.1238, mean_rewards: 274.2015, total_rewards: 3375.4354, mean_steps: 16.1300, mean_ecr: 0.0479 mean_entropies: 0.6422, took: 83.7186s
2022-10-10 16:25:47,233 [INFO] 	Process 3 - batch 53499: mean_policy_losses: 7.434, mean_net_lifetime: 4415.3454, mean_mc_travel_dist: 1253.4426, mean_rewards: 290.2496, total_rewards: 3186.7298, mean_steps: 14.2700, mean_ecr: 0.0485 mean_entropies: 0.5549, took: 71.3167s
2022-10-10 16:26:24,946 [INFO] 	Process 2 - batch 52399: mean_policy_losses: -34.581, mean_net_lifetime: 4726.8420, mean_mc_travel_dist: 1325.0408, mean_rewards: 293.9544, total_rewards: 3423.3427, mean_steps: 15.1800, mean_ecr: 0.0406 mean_entropies: 0.5324, took: 75.7746s
2022-10-10 16:26:31,855 [INFO] 	Process 5 - batch 51599: mean_policy_losses: -220.643, mean_net_lifetime: 5141.3247, mean_mc_travel_dist: 1729.8317, mean_rewards: 266.8500, total_rewards: 3473.6361, mean_steps: 18.5000, mean_ecr: 0.0312 mean_entropies: 0.6633, took: 87.5622s
2022-10-10 16:27:00,153 [INFO] 	Process 4 - batch 58399: mean_policy_losses: 23.910, mean_net_lifetime: 4722.8608, mean_mc_travel_dist: 1343.0820, mean_rewards: 280.8213, total_rewards: 3412.0158, mean_steps: 15.8400, mean_ecr: 0.0477 mean_entropies: 0.6351, took: 80.5136s
2022-10-10 16:27:02,012 [INFO] 	Process 3 - batch 53599: mean_policy_losses: 22.203, mean_net_lifetime: 4551.7543, mean_mc_travel_dist: 1262.6290, mean_rewards: 284.7122, total_rewards: 3319.9770, mean_steps: 15.0500, mean_ecr: 0.0484 mean_entropies: 0.5363, took: 74.7789s
2022-10-10 16:27:08,821 [INFO] 	Process 1 - batch 45599: mean_policy_losses: 2.025, mean_net_lifetime: 5422.1974, mean_mc_travel_dist: 1929.2796, mean_rewards: 265.3045, total_rewards: 3520.5219, mean_steps: 19.5800, mean_ecr: 0.0386 mean_entropies: 0.9255, took: 92.3257s
2022-10-10 16:27:42,189 [INFO] 	Process 2 - batch 52499: mean_policy_losses: -28.739, mean_net_lifetime: 4732.8826, mean_mc_travel_dist: 1322.3985, mean_rewards: 286.6216, total_rewards: 3437.7111, mean_steps: 15.6300, mean_ecr: 0.0407 mean_entropies: 0.5013, took: 77.2429s
2022-10-10 16:27:56,457 [INFO] 	Process 5 - batch 51699: mean_policy_losses: -406.720, mean_net_lifetime: 4815.8080, mean_mc_travel_dist: 1607.1981, mean_rewards: 263.1161, total_rewards: 3257.6091, mean_steps: 17.8700, mean_ecr: 0.0303 mean_entropies: 0.6897, took: 84.6019s
2022-10-10 16:28:14,889 [INFO] 	Process 3 - batch 53699: mean_policy_losses: 17.578, mean_net_lifetime: 4637.8030, mean_mc_travel_dist: 1309.1830, mean_rewards: 293.2101, total_rewards: 3364.4146, mean_steps: 14.8600, mean_ecr: 0.0475 mean_entropies: 0.5349, took: 72.8771s
2022-10-10 16:28:22,596 [INFO] 	Process 4 - batch 58499: mean_policy_losses: 44.448, mean_net_lifetime: 4936.0964, mean_mc_travel_dist: 1426.2788, mean_rewards: 279.8495, total_rewards: 3545.7783, mean_steps: 16.7500, mean_ecr: 0.0472 mean_entropies: 0.6696, took: 82.4429s
2022-10-10 16:28:43,519 [INFO] 	Process 1 - batch 45699: mean_policy_losses: -31.341, mean_net_lifetime: 5465.8010, mean_mc_travel_dist: 1892.9364, mean_rewards: 253.5582, total_rewards: 3600.6175, mean_steps: 20.7300, mean_ecr: 0.0386 mean_entropies: 0.9673, took: 94.6974s
2022-10-10 16:29:23,539 [INFO] 	Process 3 - batch 53799: mean_policy_losses: 28.138, mean_net_lifetime: 4478.6939, mean_mc_travel_dist: 1248.3930, mean_rewards: 285.6003, total_rewards: 3272.3283, mean_steps: 14.7200, mean_ecr: 0.0482 mean_entropies: 0.5063, took: 68.6499s
2022-10-10 16:29:23,559 [INFO] 	Process 5 - batch 51799: mean_policy_losses: -270.408, mean_net_lifetime: 5353.5358, mean_mc_travel_dist: 1822.9459, mean_rewards: 261.5345, total_rewards: 3596.6356, mean_steps: 19.6600, mean_ecr: 0.0302 mean_entropies: 0.6981, took: 87.1021s
2022-10-10 16:29:56,048 [INFO] Process 6 - epoch 49: mean_policy_losses: -245.898, mean_net_lifetime: 2787.0056, mean_mc_travel_dist: 949.3816, mean_entropies: 0.7497, m_net_lifetime_valid: 4181.2308, took: 1324.8998s, (110.4004 / 100 batches)

2022-10-10 16:30:12,613 [INFO] 	Process 1 - batch 45799: mean_policy_losses: 7.049, mean_net_lifetime: 5526.1283, mean_mc_travel_dist: 1976.4285, mean_rewards: 261.6723, total_rewards: 3573.0620, mean_steps: 20.4100, mean_ecr: 0.0384 mean_entropies: 0.8718, took: 89.0950s
2022-10-10 16:30:35,282 [INFO] 	Process 3 - batch 53899: mean_policy_losses: 23.981, mean_net_lifetime: 4487.3286, mean_mc_travel_dist: 1223.4923, mean_rewards: 279.8262, total_rewards: 3288.2234, mean_steps: 15.0800, mean_ecr: 0.0485 mean_entropies: 0.5332, took: 71.7424s
2022-10-10 16:30:42,407 [INFO] 	Process 6 - batch 73599: mean_policy_losses: -196.650, mean_net_lifetime: 3198.7971, mean_mc_travel_dist: 867.0121, mean_rewards: 319.6296, total_rewards: 2356.1360, mean_steps: 8.9800, mean_ecr: 0.0565 mean_entropies: 0.2120, took: 592.4086s
2022-10-10 16:30:48,071 [INFO] 	Process 5 - batch 51899: mean_policy_losses: -247.232, mean_net_lifetime: 5070.9523, mean_mc_travel_dist: 1694.8145, mean_rewards: 263.1924, total_rewards: 3430.5159, mean_steps: 18.5600, mean_ecr: 0.0311 mean_entropies: 0.6594, took: 84.5119s
2022-10-10 16:31:31,046 [INFO] 	Process 6 - batch 73699: mean_policy_losses: -240.473, mean_net_lifetime: 3348.4246, mean_mc_travel_dist: 899.7819, mean_rewards: 319.4527, total_rewards: 2473.5026, mean_steps: 9.4500, mean_ecr: 0.0561 mean_entropies: 0.1854, took: 48.6390s
2022-10-10 16:31:38,103 [INFO] 	Process 1 - batch 45899: mean_policy_losses: -4.173, mean_net_lifetime: 5303.0245, mean_mc_travel_dist: 1938.1521, mean_rewards: 269.7413, total_rewards: 3394.4194, mean_steps: 18.7600, mean_ecr: 0.0386 mean_entropies: 0.8541, took: 85.4895s
2022-10-10 16:31:48,481 [INFO] 	Process 3 - batch 53999: mean_policy_losses: 29.659, mean_net_lifetime: 4462.8981, mean_mc_travel_dist: 1230.0782, mean_rewards: 271.5597, total_rewards: 3257.8262, mean_steps: 15.4800, mean_ecr: 0.0487 mean_entropies: 0.5541, took: 73.1988s
2022-10-10 16:32:12,567 [INFO] 	Process 5 - batch 51999: mean_policy_losses: -221.079, mean_net_lifetime: 5265.6171, mean_mc_travel_dist: 1767.1688, mean_rewards: 278.5630, total_rewards: 3545.9581, mean_steps: 18.5400, mean_ecr: 0.0311 mean_entropies: 0.6120, took: 84.4967s
2022-10-10 16:32:17,045 [INFO] 	Process 6 - batch 73799: mean_policy_losses: -197.491, mean_net_lifetime: 3293.6744, mean_mc_travel_dist: 886.8173, mean_rewards: 327.3884, total_rewards: 2425.3671, mean_steps: 9.0200, mean_ecr: 0.0562 mean_entropies: 0.2000, took: 45.9988s
2022-10-10 16:33:03,848 [INFO] 	Process 6 - batch 73899: mean_policy_losses: -200.797, mean_net_lifetime: 3419.7638, mean_mc_travel_dist: 918.1004, mean_rewards: 328.7384, total_rewards: 2524.7355, mean_steps: 9.3800, mean_ecr: 0.0560 mean_entropies: 0.2151, took: 46.8037s
2022-10-10 16:33:07,435 [INFO] 	Process 1 - batch 45999: mean_policy_losses: 56.641, mean_net_lifetime: 5616.4536, mean_mc_travel_dist: 1954.2867, mean_rewards: 264.7211, total_rewards: 3687.3782, mean_steps: 20.3200, mean_ecr: 0.0386 mean_entropies: 0.9220, took: 89.3314s
2022-10-10 16:33:40,402 [INFO] Process 7 - epoch 35: mean_policy_losses: -287.984, mean_net_lifetime: 3981.4992, mean_mc_travel_dist: 1588.0357, mean_entropies: 1.6981, m_net_lifetime_valid: 4489.1546, took: 1785.5112s, (154.9028 / 100 batches)

2022-10-10 16:33:41,680 [INFO] 	Process 5 - batch 52099: mean_policy_losses: -142.173, mean_net_lifetime: 5793.5057, mean_mc_travel_dist: 1981.8615, mean_rewards: 274.0864, total_rewards: 3857.9787, mean_steps: 20.5200, mean_ecr: 0.0313 mean_entropies: 0.5766, took: 89.1121s
2022-10-10 16:33:52,011 [INFO] 	Process 6 - batch 73999: mean_policy_losses: -229.830, mean_net_lifetime: 3434.2401, mean_mc_travel_dist: 922.6565, mean_rewards: 323.9098, total_rewards: 2525.1004, mean_steps: 9.5500, mean_ecr: 0.0560 mean_entropies: 0.1875, took: 48.1625s
2022-10-10 16:34:37,696 [INFO] 	Process 1 - batch 46099: mean_policy_losses: 42.804, mean_net_lifetime: 5522.1332, mean_mc_travel_dist: 1962.5982, mean_rewards: 262.5552, total_rewards: 3580.2509, mean_steps: 20.1500, mean_ecr: 0.0384 mean_entropies: 0.9085, took: 90.2614s
2022-10-10 16:34:45,221 [INFO] 	Process 6 - batch 74099: mean_policy_losses: -149.954, mean_net_lifetime: 3612.6342, mean_mc_travel_dist: 964.8765, mean_rewards: 314.7276, total_rewards: 2675.1817, mean_steps: 10.4700, mean_ecr: 0.0560 mean_entropies: 0.1594, took: 53.2103s
2022-10-10 16:35:03,550 [INFO] 	Process 7 - batch 52599: mean_policy_losses: -404.066, mean_net_lifetime: 4368.9156, mean_mc_travel_dist: 1447.8491, mean_rewards: 227.7925, total_rewards: 2967.2756, mean_steps: 18.4300, mean_ecr: 0.0415 mean_entropies: 1.1875, took: 629.8385s
2022-10-10 16:35:06,058 [INFO] 	Process 5 - batch 52199: mean_policy_losses: -189.448, mean_net_lifetime: 5021.4944, mean_mc_travel_dist: 1689.8475, mean_rewards: 265.2614, total_rewards: 3384.5491, mean_steps: 18.1100, mean_ecr: 0.0313 mean_entropies: 0.5763, took: 84.3780s
2022-10-10 16:35:30,643 [INFO] 	Process 6 - batch 74199: mean_policy_losses: -132.547, mean_net_lifetime: 3165.8717, mean_mc_travel_dist: 861.9942, mean_rewards: 327.8137, total_rewards: 2334.3377, mean_steps: 8.5800, mean_ecr: 0.0564 mean_entropies: 0.1967, took: 45.4214s
2022-10-10 16:36:11,823 [INFO] 	Process 1 - batch 46199: mean_policy_losses: 77.562, mean_net_lifetime: 5532.6296, mean_mc_travel_dist: 1931.2849, mean_rewards: 257.7700, total_rewards: 3628.2735, mean_steps: 20.7100, mean_ecr: 0.0386 mean_entropies: 0.8639, took: 94.1275s
2022-10-10 16:36:17,837 [INFO] Process 2 - epoch 35: mean_policy_losses: 6.947, mean_net_lifetime: 4307.1491, mean_mc_travel_dist: 1564.7797, mean_entropies: 1.0816, m_net_lifetime_valid: 4602.3025, took: 1711.6945s, (155.2614 / 100 batches)

2022-10-10 16:36:22,160 [INFO] 	Process 6 - batch 74299: mean_policy_losses: -189.259, mean_net_lifetime: 3592.6426, mean_mc_travel_dist: 955.7224, mean_rewards: 324.8869, total_rewards: 2655.4091, mean_steps: 10.0500, mean_ecr: 0.0559 mean_entropies: 0.1660, took: 51.5179s
2022-10-10 16:36:38,006 [INFO] 	Process 5 - batch 52299: mean_policy_losses: -114.736, mean_net_lifetime: 5572.3745, mean_mc_travel_dist: 1898.4602, mean_rewards: 268.2305, total_rewards: 3721.2650, mean_steps: 19.8900, mean_ecr: 0.0313 mean_entropies: 0.5553, took: 91.9481s
2022-10-10 16:36:41,620 [INFO] 	Process 7 - batch 52699: mean_policy_losses: -236.490, mean_net_lifetime: 4817.6808, mean_mc_travel_dist: 1589.9449, mean_rewards: 214.7513, total_rewards: 3267.9898, mean_steps: 21.7700, mean_ecr: 0.0411 mean_entropies: 1.2006, took: 98.0700s
2022-10-10 16:37:06,383 [INFO] Process 4 - epoch 39: mean_policy_losses: 86.949, mean_net_lifetime: 3901.2739, mean_mc_travel_dist: 1306.9947, mean_entropies: 1.3070, m_net_lifetime_valid: 4468.4422, took: 1759.8157s, (139.4329 / 100 batches)

2022-10-10 16:37:21,591 [INFO] 	Process 6 - batch 74399: mean_policy_losses: -60.323, mean_net_lifetime: 3784.2918, mean_mc_travel_dist: 1002.8703, mean_rewards: 311.0092, total_rewards: 2806.0456, mean_steps: 11.2000, mean_ecr: 0.0556 mean_entropies: 0.1374, took: 59.4301s
2022-10-10 16:37:41,255 [INFO] 	Process 2 - batch 52599: mean_policy_losses: -31.428, mean_net_lifetime: 4684.6878, mean_mc_travel_dist: 1305.5339, mean_rewards: 263.8488, total_rewards: 3403.7860, mean_steps: 16.8600, mean_ecr: 0.0408 mean_entropies: 0.4032, took: 599.0655s
2022-10-10 16:37:55,576 [INFO] 	Process 1 - batch 46299: mean_policy_losses: 113.688, mean_net_lifetime: 5703.1221, mean_mc_travel_dist: 1966.2477, mean_rewards: 251.6042, total_rewards: 3765.4307, mean_steps: 21.8200, mean_ecr: 0.0384 mean_entropies: 0.9520, took: 103.7487s
2022-10-10 16:38:06,807 [INFO] 	Process 5 - batch 52399: mean_policy_losses: -162.889, mean_net_lifetime: 4787.4495, mean_mc_travel_dist: 1604.3518, mean_rewards: 255.7283, total_rewards: 3241.5659, mean_steps: 18.0400, mean_ecr: 0.0314 mean_entropies: 0.5508, took: 88.8013s
2022-10-10 16:38:18,165 [INFO] 	Process 6 - batch 74499: mean_policy_losses: -95.088, mean_net_lifetime: 3611.4349, mean_mc_travel_dist: 968.4019, mean_rewards: 319.2645, total_rewards: 2672.6017, mean_steps: 10.3800, mean_ecr: 0.0558 mean_entropies: 0.1509, took: 56.5748s
2022-10-10 16:38:22,212 [INFO] 	Process 4 - batch 58599: mean_policy_losses: 122.611, mean_net_lifetime: 4072.6296, mean_mc_travel_dist: 1156.8174, mean_rewards: 267.0839, total_rewards: 2952.0664, mean_steps: 14.3200, mean_ecr: 0.0488 mean_entropies: 0.7018, took: 599.6159s
2022-10-10 16:38:25,128 [INFO] 	Process 7 - batch 52799: mean_policy_losses: -294.449, mean_net_lifetime: 4950.1066, mean_mc_travel_dist: 1656.7997, mean_rewards: 221.8585, total_rewards: 3337.1262, mean_steps: 21.7000, mean_ecr: 0.0409 mean_entropies: 1.1802, took: 103.5078s
2022-10-10 16:39:03,056 [INFO] 	Process 2 - batch 52699: mean_policy_losses: -15.873, mean_net_lifetime: 4712.0719, mean_mc_travel_dist: 1295.0080, mean_rewards: 275.4137, total_rewards: 3441.2802, mean_steps: 16.1900, mean_ecr: 0.0408 mean_entropies: 0.4379, took: 81.8016s
2022-10-10 16:39:14,143 [INFO] 	Process 6 - batch 74599: mean_policy_losses: -58.522, mean_net_lifetime: 3664.3584, mean_mc_travel_dist: 966.7521, mean_rewards: 323.3789, total_rewards: 2715.1493, mean_steps: 10.3300, mean_ecr: 0.0558 mean_entropies: 0.1542, took: 55.9777s
2022-10-10 16:39:32,363 [INFO] 	Process 5 - batch 52499: mean_policy_losses: -270.100, mean_net_lifetime: 4513.6242, mean_mc_travel_dist: 1485.2614, mean_rewards: 257.0285, total_rewards: 3090.3508, mean_steps: 17.1600, mean_ecr: 0.0310 mean_entropies: 0.5830, took: 85.5567s
2022-10-10 16:39:35,974 [INFO] 	Process 1 - batch 46399: mean_policy_losses: 107.267, mean_net_lifetime: 5581.8991, mean_mc_travel_dist: 1904.3404, mean_rewards: 259.1356, total_rewards: 3706.7157, mean_steps: 20.6500, mean_ecr: 0.0386 mean_entropies: 0.9665, took: 100.4019s
2022-10-10 16:39:45,334 [INFO] 	Process 4 - batch 58699: mean_policy_losses: 176.129, mean_net_lifetime: 4892.0275, mean_mc_travel_dist: 1382.2364, mean_rewards: 284.3294, total_rewards: 3550.0299, mean_steps: 16.2400, mean_ecr: 0.0472 mean_entropies: 0.6232, took: 83.1211s
2022-10-10 16:39:51,857 [INFO] 	Process 7 - batch 52899: mean_policy_losses: -602.675, mean_net_lifetime: 4109.5286, mean_mc_travel_dist: 1478.0515, mean_rewards: 223.1303, total_rewards: 2685.0526, mean_steps: 17.7200, mean_ecr: 0.0414 mean_entropies: 1.2509, took: 86.7293s
2022-10-10 16:40:07,271 [INFO] 	Process 6 - batch 74699: mean_policy_losses: -187.038, mean_net_lifetime: 3550.9721, mean_mc_travel_dist: 944.8343, mean_rewards: 323.4982, total_rewards: 2615.1826, mean_steps: 9.9500, mean_ecr: 0.0560 mean_entropies: 0.1870, took: 53.1281s
2022-10-10 16:40:11,175 [INFO] Process 3 - epoch 36: mean_policy_losses: 82.160, mean_net_lifetime: 4158.8778, mean_mc_travel_dist: 1389.6350, mean_entropies: 1.0534, m_net_lifetime_valid: 4419.3666, took: 1633.0213s, (151.4103 / 100 batches)

2022-10-10 16:40:22,043 [INFO] 	Process 2 - batch 52799: mean_policy_losses: -25.912, mean_net_lifetime: 4706.7249, mean_mc_travel_dist: 1280.4838, mean_rewards: 280.5641, total_rewards: 3444.2860, mean_steps: 15.8400, mean_ecr: 0.0409 mean_entropies: 0.4475, took: 78.9867s
2022-10-10 16:41:00,118 [INFO] 	Process 6 - batch 74799: mean_policy_losses: -177.369, mean_net_lifetime: 3445.8731, mean_mc_travel_dist: 927.2070, mean_rewards: 323.6382, total_rewards: 2539.4816, mean_steps: 9.7400, mean_ecr: 0.0558 mean_entropies: 0.1774, took: 52.8468s
2022-10-10 16:41:05,451 [INFO] 	Process 4 - batch 58799: mean_policy_losses: 118.406, mean_net_lifetime: 4853.5793, mean_mc_travel_dist: 1397.7943, mean_rewards: 291.0820, total_rewards: 3491.9536, mean_steps: 15.7100, mean_ecr: 0.0471 mean_entropies: 0.5940, took: 80.1177s
2022-10-10 16:41:08,698 [INFO] 	Process 7 - batch 52999: mean_policy_losses: -719.305, mean_net_lifetime: 3857.0738, mean_mc_travel_dist: 1436.7181, mean_rewards: 243.3895, total_rewards: 2465.3440, mean_steps: 15.6200, mean_ecr: 0.0417 mean_entropies: 1.2133, took: 76.8410s
2022-10-10 16:41:13,503 [INFO] 	Process 1 - batch 46499: mean_policy_losses: 81.715, mean_net_lifetime: 5558.1158, mean_mc_travel_dist: 1933.8078, mean_rewards: 260.0276, total_rewards: 3658.6838, mean_steps: 20.5900, mean_ecr: 0.0385 mean_entropies: 0.9385, took: 97.5287s
2022-10-10 16:41:29,070 [INFO] 	Process 3 - batch 54099: mean_policy_losses: -17.930, mean_net_lifetime: 4143.7782, mean_mc_travel_dist: 1129.8937, mean_rewards: 255.1776, total_rewards: 3032.5327, mean_steps: 15.2900, mean_ecr: 0.0493 mean_entropies: 0.4859, took: 580.5901s
2022-10-10 16:41:45,714 [INFO] 	Process 2 - batch 52899: mean_policy_losses: -37.292, mean_net_lifetime: 4595.4749, mean_mc_travel_dist: 1280.7094, mean_rewards: 262.8219, total_rewards: 3350.6134, mean_steps: 16.5700, mean_ecr: 0.0410 mean_entropies: 0.3965, took: 83.6710s
2022-10-10 16:41:57,412 [INFO] 	Process 6 - batch 74899: mean_policy_losses: -76.157, mean_net_lifetime: 3745.8555, mean_mc_travel_dist: 993.6984, mean_rewards: 314.5610, total_rewards: 2774.5707, mean_steps: 10.9500, mean_ecr: 0.0556 mean_entropies: 0.1599, took: 57.2941s
2022-10-10 16:42:26,251 [INFO] 	Process 7 - batch 53099: mean_policy_losses: -760.484, mean_net_lifetime: 3898.5489, mean_mc_travel_dist: 1394.1155, mean_rewards: 238.0433, total_rewards: 2550.4814, mean_steps: 16.0400, mean_ecr: 0.0417 mean_entropies: 1.2882, took: 77.5528s
2022-10-10 16:42:27,817 [INFO] 	Process 4 - batch 58899: mean_policy_losses: 140.394, mean_net_lifetime: 5189.1551, mean_mc_travel_dist: 1477.7563, mean_rewards: 293.3057, total_rewards: 3742.4434, mean_steps: 16.7800, mean_ecr: 0.0462 mean_entropies: 0.5664, took: 82.3663s
2022-10-10 16:42:47,435 [INFO] 	Process 3 - batch 54199: mean_policy_losses: -9.394, mean_net_lifetime: 4176.9334, mean_mc_travel_dist: 1127.7707, mean_rewards: 244.2939, total_rewards: 3071.4843, mean_steps: 16.1300, mean_ecr: 0.0492 mean_entropies: 0.4442, took: 78.3644s
2022-10-10 16:42:52,435 [INFO] 	Process 6 - batch 74999: mean_policy_losses: -147.799, mean_net_lifetime: 3640.0535, mean_mc_travel_dist: 971.5590, mean_rewards: 316.1230, total_rewards: 2690.3668, mean_steps: 10.5500, mean_ecr: 0.0558 mean_entropies: 0.1692, took: 55.0224s
2022-10-10 16:43:07,514 [INFO] 	Process 2 - batch 52999: mean_policy_losses: -23.048, mean_net_lifetime: 4682.1468, mean_mc_travel_dist: 1293.1820, mean_rewards: 269.5964, total_rewards: 3411.1564, mean_steps: 16.4700, mean_ecr: 0.0410 mean_entropies: 0.3855, took: 81.7995s
2022-10-10 16:43:34,090 [INFO] 	Process 7 - batch 53199: mean_policy_losses: -865.869, mean_net_lifetime: 3642.9290, mean_mc_travel_dist: 1278.9697, mean_rewards: 244.1675, total_rewards: 2399.6671, mean_steps: 14.4500, mean_ecr: 0.0420 mean_entropies: 1.2658, took: 67.8391s
2022-10-10 16:43:47,532 [INFO] 	Process 4 - batch 58999: mean_policy_losses: 100.476, mean_net_lifetime: 5025.1482, mean_mc_travel_dist: 1452.9020, mean_rewards: 285.8742, total_rewards: 3607.3797, mean_steps: 16.6900, mean_ecr: 0.0465 mean_entropies: 0.6014, took: 79.7155s
2022-10-10 16:44:00,114 [INFO] 	Process 3 - batch 54299: mean_policy_losses: 2.109, mean_net_lifetime: 4359.5058, mean_mc_travel_dist: 1199.3586, mean_rewards: 269.2761, total_rewards: 3179.6131, mean_steps: 15.2100, mean_ecr: 0.0488 mean_entropies: 0.5094, took: 72.6791s
2022-10-10 16:44:24,124 [INFO] 	Process 2 - batch 53099: mean_policy_losses: -27.333, mean_net_lifetime: 4711.0403, mean_mc_travel_dist: 1290.9539, mean_rewards: 282.6720, total_rewards: 3441.1592, mean_steps: 15.7400, mean_ecr: 0.0408 mean_entropies: 0.4386, took: 76.6106s
2022-10-10 16:44:41,123 [INFO] 	Process 7 - batch 53299: mean_policy_losses: -937.661, mean_net_lifetime: 3805.1542, mean_mc_travel_dist: 1374.4998, mean_rewards: 258.3331, total_rewards: 2476.3357, mean_steps: 14.1500, mean_ecr: 0.0415 mean_entropies: 1.3045, took: 67.0329s
2022-10-10 16:45:08,189 [INFO] 	Process 4 - batch 59099: mean_policy_losses: 124.981, mean_net_lifetime: 5180.9157, mean_mc_travel_dist: 1504.2592, mean_rewards: 292.8710, total_rewards: 3718.7387, mean_steps: 16.7800, mean_ecr: 0.0462 mean_entropies: 0.5930, took: 80.6568s
2022-10-10 16:45:14,085 [INFO] 	Process 3 - batch 54399: mean_policy_losses: 27.613, mean_net_lifetime: 4576.4759, mean_mc_travel_dist: 1245.3823, mean_rewards: 279.4659, total_rewards: 3360.9562, mean_steps: 15.4000, mean_ecr: 0.0484 mean_entropies: 0.4809, took: 73.9710s
2022-10-10 16:45:41,384 [INFO] 	Process 2 - batch 53199: mean_policy_losses: -29.743, mean_net_lifetime: 4717.0349, mean_mc_travel_dist: 1304.3183, mean_rewards: 284.7392, total_rewards: 3437.3314, mean_steps: 15.6500, mean_ecr: 0.0407 mean_entropies: 0.4413, took: 77.2597s
2022-10-10 16:45:54,127 [INFO] 	Process 7 - batch 53399: mean_policy_losses: -884.525, mean_net_lifetime: 4041.3897, mean_mc_travel_dist: 1444.7837, mean_rewards: 249.9264, total_rewards: 2641.6400, mean_steps: 15.9800, mean_ecr: 0.0412 mean_entropies: 1.3148, took: 73.0042s
2022-10-10 16:46:27,324 [INFO] 	Process 3 - batch 54499: mean_policy_losses: 14.929, mean_net_lifetime: 4520.9448, mean_mc_travel_dist: 1231.1541, mean_rewards: 278.4670, total_rewards: 3314.4230, mean_steps: 15.2600, mean_ecr: 0.0485 mean_entropies: 0.4646, took: 73.2383s
2022-10-10 16:46:31,304 [INFO] 	Process 4 - batch 59199: mean_policy_losses: 96.567, mean_net_lifetime: 5279.6714, mean_mc_travel_dist: 1536.1662, mean_rewards: 293.2935, total_rewards: 3776.2525, mean_steps: 17.1000, mean_ecr: 0.0459 mean_entropies: 0.5738, took: 83.1143s
2022-10-10 16:47:01,041 [INFO] 	Process 2 - batch 53299: mean_policy_losses: -33.654, mean_net_lifetime: 4715.5205, mean_mc_travel_dist: 1316.2359, mean_rewards: 275.4027, total_rewards: 3427.0453, mean_steps: 16.1900, mean_ecr: 0.0408 mean_entropies: 0.4042, took: 79.6573s
2022-10-10 16:47:13,277 [INFO] 	Process 7 - batch 53499: mean_policy_losses: -810.389, mean_net_lifetime: 4048.2389, mean_mc_travel_dist: 1434.6764, mean_rewards: 234.2036, total_rewards: 2651.0340, mean_steps: 17.3400, mean_ecr: 0.0413 mean_entropies: 1.2442, took: 79.1501s
2022-10-10 16:47:42,643 [INFO] 	Process 3 - batch 54599: mean_policy_losses: 2.163, mean_net_lifetime: 4373.5149, mean_mc_travel_dist: 1194.2219, mean_rewards: 259.8628, total_rewards: 3201.8328, mean_steps: 15.8700, mean_ecr: 0.0489 mean_entropies: 0.4664, took: 75.3198s
2022-10-10 16:47:47,427 [INFO] 	Process 4 - batch 59299: mean_policy_losses: 75.137, mean_net_lifetime: 4949.6817, mean_mc_travel_dist: 1416.1419, mean_rewards: 298.6763, total_rewards: 3558.3704, mean_steps: 15.7100, mean_ecr: 0.0469 mean_entropies: 0.5516, took: 76.1238s
2022-10-10 16:48:13,045 [INFO] Process 5 - epoch 35: mean_policy_losses: -216.456, mean_net_lifetime: 4516.0251, mean_mc_travel_dist: 1905.6033, mean_entropies: 1.3671, m_net_lifetime_valid: 4203.5228, took: 1815.7921s, (156.6113 / 100 batches)

2022-10-10 16:48:19,047 [INFO] 	Process 2 - batch 53399: mean_policy_losses: -17.594, mean_net_lifetime: 4703.3847, mean_mc_travel_dist: 1322.2899, mean_rewards: 271.7554, total_rewards: 3400.4554, mean_steps: 16.3800, mean_ecr: 0.0408 mean_entropies: 0.3979, took: 78.0049s
2022-10-10 16:48:37,491 [INFO] 	Process 7 - batch 53599: mean_policy_losses: -714.462, mean_net_lifetime: 4178.3787, mean_mc_travel_dist: 1561.8609, mean_rewards: 230.7788, total_rewards: 2665.7064, mean_steps: 18.4600, mean_ecr: 0.0415 mean_entropies: 1.2711, took: 84.2136s
2022-10-10 16:48:56,634 [INFO] 	Process 3 - batch 54699: mean_policy_losses: 29.681, mean_net_lifetime: 4542.0753, mean_mc_travel_dist: 1266.4979, mean_rewards: 284.1134, total_rewards: 3310.7284, mean_steps: 15.0300, mean_ecr: 0.0482 mean_entropies: 0.4696, took: 73.9901s
2022-10-10 16:49:14,367 [INFO] 	Process 4 - batch 59399: mean_policy_losses: 95.495, mean_net_lifetime: 5193.1281, mean_mc_travel_dist: 1558.1880, mean_rewards: 286.7688, total_rewards: 3656.7337, mean_steps: 17.3700, mean_ecr: 0.0463 mean_entropies: 0.6117, took: 86.9400s
2022-10-10 16:49:37,624 [INFO] 	Process 2 - batch 53499: mean_policy_losses: -28.492, mean_net_lifetime: 4718.3550, mean_mc_travel_dist: 1356.3245, mean_rewards: 287.5030, total_rewards: 3390.8110, mean_steps: 15.5200, mean_ecr: 0.0405 mean_entropies: 0.4961, took: 78.5774s
2022-10-10 16:49:39,408 [INFO] 	Process 5 - batch 52599: mean_policy_losses: -235.659, mean_net_lifetime: 5066.2522, mean_mc_travel_dist: 1699.6044, mean_rewards: 273.6492, total_rewards: 3411.0034, mean_steps: 18.1800, mean_ecr: 0.0305 mean_entropies: 0.6797, took: 607.0442s
2022-10-10 16:49:49,023 [INFO] Process 1 - epoch 31: mean_policy_losses: 42.876, mean_net_lifetime: 4842.2249, mean_mc_travel_dist: 2044.5418, mean_entropies: 1.2987, m_net_lifetime_valid: 4128.3368, took: 1966.5042s, (176.9929 / 100 batches)

2022-10-10 16:49:57,828 [INFO] 	Process 7 - batch 53699: mean_policy_losses: -865.769, mean_net_lifetime: 4082.0144, mean_mc_travel_dist: 1468.2238, mean_rewards: 241.0564, total_rewards: 2651.8675, mean_steps: 16.3100, mean_ecr: 0.0413 mean_entropies: 1.3605, took: 80.3376s
2022-10-10 16:50:12,380 [INFO] 	Process 3 - batch 54799: mean_policy_losses: 31.376, mean_net_lifetime: 4535.3446, mean_mc_travel_dist: 1257.3968, mean_rewards: 283.8638, total_rewards: 3306.3959, mean_steps: 15.0200, mean_ecr: 0.0483 mean_entropies: 0.4836, took: 75.7458s
2022-10-10 16:50:39,536 [INFO] 	Process 4 - batch 59499: mean_policy_losses: 126.310, mean_net_lifetime: 5145.8234, mean_mc_travel_dist: 1498.4058, mean_rewards: 291.0834, total_rewards: 3689.2647, mean_steps: 16.7800, mean_ecr: 0.0464 mean_entropies: 0.6364, took: 85.1684s
2022-10-10 16:50:58,868 [INFO] 	Process 2 - batch 53599: mean_policy_losses: -37.302, mean_net_lifetime: 4716.9440, mean_mc_travel_dist: 1313.7641, mean_rewards: 283.6578, total_rewards: 3421.7884, mean_steps: 15.7000, mean_ecr: 0.0407 mean_entropies: 0.4687, took: 81.2446s
2022-10-10 16:51:04,104 [INFO] 	Process 5 - batch 52699: mean_policy_losses: -384.226, mean_net_lifetime: 4720.3205, mean_mc_travel_dist: 1579.9036, mean_rewards: 270.3253, total_rewards: 3196.4775, mean_steps: 17.2400, mean_ecr: 0.0303 mean_entropies: 0.6578, took: 84.6965s
2022-10-10 16:51:22,755 [INFO] 	Process 7 - batch 53799: mean_policy_losses: -689.970, mean_net_lifetime: 4324.6771, mean_mc_travel_dist: 1508.7058, mean_rewards: 239.9659, total_rewards: 2862.5851, mean_steps: 17.5100, mean_ecr: 0.0412 mean_entropies: 1.3200, took: 84.9261s
2022-10-10 16:51:30,339 [INFO] 	Process 3 - batch 54899: mean_policy_losses: 22.292, mean_net_lifetime: 4617.4472, mean_mc_travel_dist: 1282.9283, mean_rewards: 286.3588, total_rewards: 3361.0666, mean_steps: 15.1600, mean_ecr: 0.0482 mean_entropies: 0.4832, took: 77.9593s
2022-10-10 16:51:42,828 [INFO] 	Process 1 - batch 46599: mean_policy_losses: 59.960, mean_net_lifetime: 5685.4421, mean_mc_travel_dist: 1921.6803, mean_rewards: 232.9218, total_rewards: 3797.3690, mean_steps: 23.8100, mean_ecr: 0.0386 mean_entropies: 0.9143, took: 629.3253s
2022-10-10 16:51:58,190 [INFO] Process 6 - epoch 50: mean_policy_losses: -244.099, mean_net_lifetime: 2801.2773, mean_mc_travel_dist: 949.1304, mean_entropies: 0.7383, m_net_lifetime_valid: 4373.0360, took: 1322.1398s, (109.9563 / 100 batches)

2022-10-10 16:52:08,001 [INFO] 	Process 4 - batch 59599: mean_policy_losses: 53.515, mean_net_lifetime: 4951.0792, mean_mc_travel_dist: 1468.1537, mean_rewards: 275.3538, total_rewards: 3518.5696, mean_steps: 17.1800, mean_ecr: 0.0472 mean_entropies: 0.6853, took: 88.4646s
2022-10-10 16:52:20,475 [INFO] 	Process 2 - batch 53699: mean_policy_losses: -41.421, mean_net_lifetime: 4717.5936, mean_mc_travel_dist: 1325.3766, mean_rewards: 283.1819, total_rewards: 3408.3254, mean_steps: 15.7300, mean_ecr: 0.0407 mean_entropies: 0.4744, took: 81.6072s
2022-10-10 16:52:36,771 [INFO] 	Process 5 - batch 52799: mean_policy_losses: -295.908, mean_net_lifetime: 4932.9215, mean_mc_travel_dist: 1648.6992, mean_rewards: 265.7751, total_rewards: 3342.0160, mean_steps: 18.1200, mean_ecr: 0.0305 mean_entropies: 0.6662, took: 92.6658s
2022-10-10 16:52:51,604 [INFO] 	Process 3 - batch 54999: mean_policy_losses: 26.463, mean_net_lifetime: 4551.4525, mean_mc_travel_dist: 1265.5071, mean_rewards: 279.1012, total_rewards: 3313.1334, mean_steps: 15.3600, mean_ecr: 0.0484 mean_entropies: 0.5080, took: 81.2654s
2022-10-10 16:52:52,341 [INFO] 	Process 6 - batch 75099: mean_policy_losses: -207.501, mean_net_lifetime: 3349.0564, mean_mc_travel_dist: 910.2169, mean_rewards: 319.0194, total_rewards: 2469.1111, mean_steps: 9.5900, mean_ecr: 0.0561 mean_entropies: 0.1925, took: 599.9073s
2022-10-10 16:52:53,377 [INFO] 	Process 7 - batch 53899: mean_policy_losses: -618.176, mean_net_lifetime: 4573.2029, mean_mc_travel_dist: 1586.5506, mean_rewards: 241.5229, total_rewards: 3029.8852, mean_steps: 18.4800, mean_ecr: 0.0409 mean_entropies: 1.2978, took: 90.6223s
2022-10-10 16:53:26,763 [INFO] 	Process 1 - batch 46699: mean_policy_losses: 71.558, mean_net_lifetime: 5501.4022, mean_mc_travel_dist: 1885.5977, mean_rewards: 253.7770, total_rewards: 3643.7413, mean_steps: 20.9200, mean_ecr: 0.0387 mean_entropies: 0.9453, took: 103.9354s
2022-10-10 16:53:36,896 [INFO] 	Process 4 - batch 59699: mean_policy_losses: 129.165, mean_net_lifetime: 5153.1897, mean_mc_travel_dist: 1489.1065, mean_rewards: 288.2168, total_rewards: 3695.6134, mean_steps: 17.0800, mean_ecr: 0.0466 mean_entropies: 0.6164, took: 88.8954s
2022-10-10 16:53:41,472 [INFO] 	Process 2 - batch 53799: mean_policy_losses: -9.058, mean_net_lifetime: 4708.6864, mean_mc_travel_dist: 1282.9311, mean_rewards: 286.2070, total_rewards: 3448.7353, mean_steps: 15.5300, mean_ecr: 0.0409 mean_entropies: 0.4436, took: 80.9966s
2022-10-10 16:53:48,649 [INFO] 	Process 6 - batch 75199: mean_policy_losses: -153.889, mean_net_lifetime: 3439.2898, mean_mc_travel_dist: 926.1306, mean_rewards: 318.4704, total_rewards: 2533.5477, mean_steps: 9.8500, mean_ecr: 0.0562 mean_entropies: 0.1749, took: 56.3075s
2022-10-10 16:53:58,566 [INFO] 	Process 5 - batch 52899: mean_policy_losses: -377.672, mean_net_lifetime: 4200.5135, mean_mc_travel_dist: 1370.1079, mean_rewards: 265.1405, total_rewards: 2886.3734, mean_steps: 15.7500, mean_ecr: 0.0302 mean_entropies: 0.6269, took: 81.7954s
2022-10-10 16:54:12,678 [INFO] 	Process 3 - batch 55099: mean_policy_losses: 33.596, mean_net_lifetime: 4492.1966, mean_mc_travel_dist: 1216.5904, mean_rewards: 275.0814, total_rewards: 3296.3253, mean_steps: 15.3800, mean_ecr: 0.0486 mean_entropies: 0.4920, took: 81.0738s
2022-10-10 16:54:13,843 [INFO] 	Process 7 - batch 53999: mean_policy_losses: -766.993, mean_net_lifetime: 4015.9213, mean_mc_travel_dist: 1453.8893, mean_rewards: 250.6307, total_rewards: 2611.6111, mean_steps: 15.7400, mean_ecr: 0.0414 mean_entropies: 1.2272, took: 80.4658s
2022-10-10 16:54:45,810 [INFO] 	Process 6 - batch 75299: mean_policy_losses: -160.434, mean_net_lifetime: 3563.1567, mean_mc_travel_dist: 956.3747, mean_rewards: 314.7203, total_rewards: 2634.3222, mean_steps: 10.3900, mean_ecr: 0.0558 mean_entropies: 0.1695, took: 57.1607s
2022-10-10 16:54:59,815 [INFO] 	Process 4 - batch 59799: mean_policy_losses: 65.760, mean_net_lifetime: 4838.8748, mean_mc_travel_dist: 1384.1903, mean_rewards: 288.0977, total_rewards: 3487.9268, mean_steps: 15.8100, mean_ecr: 0.0474 mean_entropies: 0.6064, took: 82.9193s
2022-10-10 16:55:03,596 [INFO] 	Process 2 - batch 53899: mean_policy_losses: -11.938, mean_net_lifetime: 4712.3647, mean_mc_travel_dist: 1283.5794, mean_rewards: 282.0057, total_rewards: 3450.5722, mean_steps: 15.7800, mean_ecr: 0.0408 mean_entropies: 0.4402, took: 82.1238s
2022-10-10 16:55:04,945 [INFO] 	Process 1 - batch 46799: mean_policy_losses: 24.454, mean_net_lifetime: 5422.5447, mean_mc_travel_dist: 1946.5873, mean_rewards: 262.0423, total_rewards: 3512.0736, mean_steps: 19.8200, mean_ecr: 0.0385 mean_entropies: 0.9077, took: 98.1809s
2022-10-10 16:55:21,925 [INFO] 	Process 5 - batch 52999: mean_policy_losses: -378.103, mean_net_lifetime: 4378.9364, mean_mc_travel_dist: 1445.2570, mean_rewards: 257.0596, total_rewards: 2988.4778, mean_steps: 16.7500, mean_ecr: 0.0308 mean_entropies: 0.5906, took: 83.3596s
2022-10-10 16:55:30,504 [INFO] 	Process 3 - batch 55199: mean_policy_losses: 13.048, mean_net_lifetime: 4444.5426, mean_mc_travel_dist: 1211.4979, mean_rewards: 274.5172, total_rewards: 3255.8200, mean_steps: 15.2300, mean_ecr: 0.0487 mean_entropies: 0.5158, took: 77.8253s
2022-10-10 16:55:43,088 [INFO] 	Process 6 - batch 75399: mean_policy_losses: -114.190, mean_net_lifetime: 3644.7175, mean_mc_travel_dist: 978.0393, mean_rewards: 316.4132, total_rewards: 2698.2065, mean_steps: 10.5700, mean_ecr: 0.0558 mean_entropies: 0.1691, took: 57.2783s
2022-10-10 16:56:21,408 [INFO] 	Process 2 - batch 53999: mean_policy_losses: -16.555, mean_net_lifetime: 4721.8492, mean_mc_travel_dist: 1294.0979, mean_rewards: 286.9274, total_rewards: 3449.2589, mean_steps: 15.5200, mean_ecr: 0.0408 mean_entropies: 0.4623, took: 77.8127s
2022-10-10 16:56:22,563 [INFO] 	Process 4 - batch 59899: mean_policy_losses: 67.660, mean_net_lifetime: 4855.2504, mean_mc_travel_dist: 1381.7705, mean_rewards: 282.4596, total_rewards: 3501.9649, mean_steps: 16.2600, mean_ecr: 0.0474 mean_entropies: 0.6289, took: 82.7478s
2022-10-10 16:56:35,447 [INFO] 	Process 6 - batch 75499: mean_policy_losses: -196.403, mean_net_lifetime: 3380.0536, mean_mc_travel_dist: 906.4694, mean_rewards: 322.9814, total_rewards: 2491.8972, mean_steps: 9.5300, mean_ecr: 0.0563 mean_entropies: 0.1749, took: 52.3583s
2022-10-10 16:56:42,183 [INFO] 	Process 1 - batch 46899: mean_policy_losses: 56.495, mean_net_lifetime: 5543.8314, mean_mc_travel_dist: 1918.7395, mean_rewards: 262.7577, total_rewards: 3652.5640, mean_steps: 20.2400, mean_ecr: 0.0386 mean_entropies: 0.9660, took: 97.2386s
2022-10-10 16:56:46,123 [INFO] 	Process 5 - batch 53099: mean_policy_losses: -333.397, mean_net_lifetime: 4450.0422, mean_mc_travel_dist: 1457.2752, mean_rewards: 250.2141, total_rewards: 3047.8761, mean_steps: 17.2600, mean_ecr: 0.0307 mean_entropies: 0.6306, took: 84.1964s
2022-10-10 16:56:47,203 [INFO] 	Process 3 - batch 55299: mean_policy_losses: 13.694, mean_net_lifetime: 4425.4317, mean_mc_travel_dist: 1221.7048, mean_rewards: 275.4036, total_rewards: 3230.8472, mean_steps: 15.1200, mean_ecr: 0.0487 mean_entropies: 0.4924, took: 76.7001s
2022-10-10 16:57:28,796 [INFO] 	Process 6 - batch 75599: mean_policy_losses: -101.936, mean_net_lifetime: 3580.2968, mean_mc_travel_dist: 960.5482, mean_rewards: 326.4190, total_rewards: 2635.1438, mean_steps: 10.0400, mean_ecr: 0.0560 mean_entropies: 0.1697, took: 53.3501s
2022-10-10 16:57:43,595 [INFO] 	Process 4 - batch 59999: mean_policy_losses: 74.538, mean_net_lifetime: 5070.3681, mean_mc_travel_dist: 1466.1304, mean_rewards: 296.8011, total_rewards: 3629.4075, mean_steps: 16.1900, mean_ecr: 0.0466 mean_entropies: 0.5733, took: 81.0320s
2022-10-10 16:58:04,373 [INFO] 	Process 3 - batch 55399: mean_policy_losses: 23.524, mean_net_lifetime: 4550.6575, mean_mc_travel_dist: 1249.7124, mean_rewards: 273.8930, total_rewards: 3340.1168, mean_steps: 15.6600, mean_ecr: 0.0484 mean_entropies: 0.4776, took: 77.1692s
2022-10-10 16:58:06,602 [INFO] 	Process 5 - batch 53199: mean_policy_losses: -372.930, mean_net_lifetime: 4279.9841, mean_mc_travel_dist: 1428.8208, mean_rewards: 251.0700, total_rewards: 2907.7876, mean_steps: 16.8300, mean_ecr: 0.0301 mean_entropies: 0.6073, took: 80.4806s
2022-10-10 16:58:21,641 [INFO] 	Process 1 - batch 46999: mean_policy_losses: 81.818, mean_net_lifetime: 5619.9372, mean_mc_travel_dist: 1925.6565, mean_rewards: 254.9034, total_rewards: 3730.3359, mean_steps: 21.3700, mean_ecr: 0.0385 mean_entropies: 0.9563, took: 99.4584s
2022-10-10 16:58:21,887 [INFO] 	Process 6 - batch 75699: mean_policy_losses: -82.459, mean_net_lifetime: 3626.4223, mean_mc_travel_dist: 965.0334, mean_rewards: 326.0476, total_rewards: 2673.0016, mean_steps: 10.1700, mean_ecr: 0.0558 mean_entropies: 0.1748, took: 53.0909s
2022-10-10 16:59:13,962 [INFO] 	Process 6 - batch 75799: mean_policy_losses: -100.302, mean_net_lifetime: 3661.6006, mean_mc_travel_dist: 973.5330, mean_rewards: 325.0378, total_rewards: 2705.4761, mean_steps: 10.2900, mean_ecr: 0.0557 mean_entropies: 0.1724, took: 52.0744s
2022-10-10 16:59:18,501 [INFO] 	Process 3 - batch 55499: mean_policy_losses: 32.871, mean_net_lifetime: 4519.4216, mean_mc_travel_dist: 1228.5566, mean_rewards: 277.5712, total_rewards: 3306.4859, mean_steps: 15.3300, mean_ecr: 0.0487 mean_entropies: 0.5108, took: 74.1285s
2022-10-10 16:59:30,309 [INFO] 	Process 5 - batch 53299: mean_policy_losses: -269.749, mean_net_lifetime: 4786.9540, mean_mc_travel_dist: 1624.1582, mean_rewards: 255.6036, total_rewards: 3222.3966, mean_steps: 18.4100, mean_ecr: 0.0306 mean_entropies: 0.6265, took: 83.7066s
2022-10-10 16:59:45,020 [INFO] 	Process 1 - batch 47099: mean_policy_losses: -6.021, mean_net_lifetime: 5305.7094, mean_mc_travel_dist: 1956.5699, mean_rewards: 272.2664, total_rewards: 3378.0345, mean_steps: 18.6700, mean_ecr: 0.0386 mean_entropies: 0.8856, took: 83.3792s
2022-10-10 17:00:05,435 [INFO] 	Process 6 - batch 75899: mean_policy_losses: -161.332, mean_net_lifetime: 3652.5406, mean_mc_travel_dist: 972.5186, mean_rewards: 320.0451, total_rewards: 2703.2378, mean_steps: 10.4500, mean_ecr: 0.0558 mean_entropies: 0.1549, took: 51.4728s
2022-10-10 17:00:47,225 [INFO] 	Process 5 - batch 53399: mean_policy_losses: -269.857, mean_net_lifetime: 4676.4074, mean_mc_travel_dist: 1557.8868, mean_rewards: 266.5668, total_rewards: 3171.2327, mean_steps: 17.0500, mean_ecr: 0.0311 mean_entropies: 0.5836, took: 76.9166s
2022-10-10 17:00:58,916 [INFO] 	Process 6 - batch 75999: mean_policy_losses: -107.014, mean_net_lifetime: 3738.0218, mean_mc_travel_dist: 988.3753, mean_rewards: 314.6833, total_rewards: 2770.4266, mean_steps: 10.9000, mean_ecr: 0.0558 mean_entropies: 0.1608, took: 53.4813s
2022-10-10 17:01:03,828 [INFO] 	Process 1 - batch 47199: mean_policy_losses: -23.474, mean_net_lifetime: 5197.8632, mean_mc_travel_dist: 1926.9091, mean_rewards: 278.8147, total_rewards: 3294.5531, mean_steps: 17.7400, mean_ecr: 0.0386 mean_entropies: 0.8138, took: 78.8083s
2022-10-10 17:01:50,852 [INFO] 	Process 6 - batch 76099: mean_policy_losses: -85.438, mean_net_lifetime: 3705.5317, mean_mc_travel_dist: 985.9373, mean_rewards: 324.1460, total_rewards: 2738.9717, mean_steps: 10.4700, mean_ecr: 0.0557 mean_entropies: 0.1542, took: 51.9361s
2022-10-10 17:02:09,313 [INFO] 	Process 5 - batch 53499: mean_policy_losses: -214.731, mean_net_lifetime: 5119.2166, mean_mc_travel_dist: 1733.7585, mean_rewards: 268.8467, total_rewards: 3434.6102, mean_steps: 18.4400, mean_ecr: 0.0314 mean_entropies: 0.5731, took: 82.0875s
2022-10-10 17:02:24,662 [INFO] 	Process 1 - batch 47299: mean_policy_losses: -40.403, mean_net_lifetime: 5263.3167, mean_mc_travel_dist: 2019.4580, mean_rewards: 275.5744, total_rewards: 3268.4283, mean_steps: 18.1700, mean_ecr: 0.0383 mean_entropies: 0.8021, took: 80.8338s
2022-10-10 17:02:41,098 [INFO] 	Process 6 - batch 76199: mean_policy_losses: -137.550, mean_net_lifetime: 3640.7139, mean_mc_travel_dist: 972.3341, mean_rewards: 326.3371, total_rewards: 2687.9085, mean_steps: 10.1700, mean_ecr: 0.0558 mean_entropies: 0.1498, took: 50.2458s
2022-10-10 17:03:34,274 [INFO] 	Process 5 - batch 53599: mean_policy_losses: -147.706, mean_net_lifetime: 5302.7306, mean_mc_travel_dist: 1801.0092, mean_rewards: 264.6882, total_rewards: 3553.7518, mean_steps: 19.1000, mean_ecr: 0.0315 mean_entropies: 0.5407, took: 84.9608s
2022-10-10 17:03:34,939 [INFO] 	Process 6 - batch 76299: mean_policy_losses: -117.041, mean_net_lifetime: 3750.2721, mean_mc_travel_dist: 991.1732, mean_rewards: 319.4698, total_rewards: 2783.1356, mean_steps: 10.7900, mean_ecr: 0.0557 mean_entropies: 0.1285, took: 53.8411s
2022-10-10 17:03:47,733 [INFO] 	Process 1 - batch 47399: mean_policy_losses: -17.141, mean_net_lifetime: 5329.1922, mean_mc_travel_dist: 1964.9868, mean_rewards: 269.9814, total_rewards: 3387.3770, mean_steps: 18.8600, mean_ecr: 0.0384 mean_entropies: 0.8145, took: 83.0709s
2022-10-10 17:03:51,998 [INFO] Process 7 - epoch 36: mean_policy_losses: -298.820, mean_net_lifetime: 3987.0386, mean_mc_travel_dist: 1584.8785, mean_entropies: 1.6860, m_net_lifetime_valid: 4354.4911, took: 1811.5937s, (153.8983 / 100 batches)

2022-10-10 17:04:31,276 [INFO] 	Process 6 - batch 76399: mean_policy_losses: -34.044, mean_net_lifetime: 3863.4165, mean_mc_travel_dist: 1017.0305, mean_rewards: 313.8453, total_rewards: 2876.0995, mean_steps: 11.3100, mean_ecr: 0.0556 mean_entropies: 0.1316, took: 56.3364s
2022-10-10 17:05:00,756 [INFO] 	Process 5 - batch 53699: mean_policy_losses: -128.208, mean_net_lifetime: 5304.5943, mean_mc_travel_dist: 1812.6957, mean_rewards: 268.1851, total_rewards: 3545.4723, mean_steps: 18.9500, mean_ecr: 0.0315 mean_entropies: 0.5268, took: 86.4827s
2022-10-10 17:05:10,797 [INFO] 	Process 7 - batch 54099: mean_policy_losses: -524.699, mean_net_lifetime: 3879.2756, mean_mc_travel_dist: 1305.0577, mean_rewards: 212.6377, total_rewards: 2611.5635, mean_steps: 17.2000, mean_ecr: 0.0417 mean_entropies: 1.0851, took: 656.9542s
2022-10-10 17:05:13,152 [INFO] Process 2 - epoch 36: mean_policy_losses: 6.038, mean_net_lifetime: 4318.1058, mean_mc_travel_dist: 1557.5076, mean_entropies: 1.0637, m_net_lifetime_valid: 4255.6491, took: 1735.3133s, (154.1344 / 100 batches)

2022-10-10 17:05:13,994 [INFO] 	Process 1 - batch 47499: mean_policy_losses: 7.157, mean_net_lifetime: 5261.6886, mean_mc_travel_dist: 1972.7704, mean_rewards: 269.6691, total_rewards: 3317.0827, mean_steps: 18.6600, mean_ecr: 0.0385 mean_entropies: 0.8116, took: 86.2609s
2022-10-10 17:05:25,018 [INFO] 	Process 6 - batch 76499: mean_policy_losses: -141.820, mean_net_lifetime: 3675.0676, mean_mc_travel_dist: 972.1012, mean_rewards: 320.9234, total_rewards: 2721.8488, mean_steps: 10.4400, mean_ecr: 0.0558 mean_entropies: 0.1377, took: 53.7426s
2022-10-10 17:06:07,722 [INFO] Process 4 - epoch 40: mean_policy_losses: 87.387, mean_net_lifetime: 3928.1596, mean_mc_travel_dist: 1310.2698, mean_entropies: 1.2896, m_net_lifetime_valid: 4228.1080, took: 1741.3377s, (138.8830 / 100 batches)

2022-10-10 17:06:31,989 [INFO] 	Process 5 - batch 53799: mean_policy_losses: -105.114, mean_net_lifetime: 5502.6558, mean_mc_travel_dist: 1884.9134, mean_rewards: 269.8999, total_rewards: 3667.3657, mean_steps: 19.6000, mean_ecr: 0.0312 mean_entropies: 0.5493, took: 91.2316s
2022-10-10 17:06:34,851 [INFO] 	Process 2 - batch 54099: mean_policy_losses: -14.996, mean_net_lifetime: 4722.5135, mean_mc_travel_dist: 1343.5213, mean_rewards: 265.8766, total_rewards: 3410.3916, mean_steps: 16.8800, mean_ecr: 0.0405 mean_entropies: 0.4547, took: 613.4426s
2022-10-10 17:06:42,661 [INFO] 	Process 7 - batch 54199: mean_policy_losses: -361.890, mean_net_lifetime: 4462.9281, mean_mc_travel_dist: 1517.2484, mean_rewards: 221.5809, total_rewards: 2992.7425, mean_steps: 19.8100, mean_ecr: 0.0413 mean_entropies: 1.1437, took: 91.8637s
2022-10-10 17:06:51,301 [INFO] 	Process 1 - batch 47599: mean_policy_losses: 54.916, mean_net_lifetime: 5383.7361, mean_mc_travel_dist: 1932.1459, mean_rewards: 248.7121, total_rewards: 3479.1409, mean_steps: 21.0800, mean_ecr: 0.0383 mean_entropies: 0.8608, took: 97.3069s
2022-10-10 17:07:23,717 [INFO] 	Process 4 - batch 60099: mean_policy_losses: 142.715, mean_net_lifetime: 4179.8789, mean_mc_travel_dist: 1242.1011, mean_rewards: 263.0473, total_rewards: 2980.6252, mean_steps: 14.9400, mean_ecr: 0.0484 mean_entropies: 0.5836, took: 580.1219s
2022-10-10 17:07:36,269 [INFO] Process 3 - epoch 37: mean_policy_losses: 80.383, mean_net_lifetime: 4166.8896, mean_mc_travel_dist: 1385.1010, mean_entropies: 1.0381, m_net_lifetime_valid: 4195.5380, took: 1645.0915s, (150.2932 / 100 batches)

2022-10-10 17:07:58,054 [INFO] 	Process 2 - batch 54199: mean_policy_losses: -1.718, mean_net_lifetime: 4705.9149, mean_mc_travel_dist: 1325.2900, mean_rewards: 272.8429, total_rewards: 3406.7778, mean_steps: 16.3500, mean_ecr: 0.0406 mean_entropies: 0.4342, took: 83.2023s
2022-10-10 17:07:58,879 [INFO] 	Process 5 - batch 53899: mean_policy_losses: -182.359, mean_net_lifetime: 4821.4003, mean_mc_travel_dist: 1631.8157, mean_rewards: 256.8439, total_rewards: 3249.7838, mean_steps: 18.0100, mean_ecr: 0.0308 mean_entropies: 0.5583, took: 86.8909s
2022-10-10 17:08:04,419 [INFO] 	Process 7 - batch 54299: mean_policy_losses: -474.568, mean_net_lifetime: 3930.2321, mean_mc_travel_dist: 1385.6807, mean_rewards: 229.3073, total_rewards: 2591.0185, mean_steps: 16.7200, mean_ecr: 0.0415 mean_entropies: 1.1103, took: 81.7589s
2022-10-10 17:08:25,977 [INFO] 	Process 1 - batch 47699: mean_policy_losses: 11.232, mean_net_lifetime: 5293.3725, mean_mc_travel_dist: 1918.8826, mean_rewards: 256.3264, total_rewards: 3405.4274, mean_steps: 19.8300, mean_ecr: 0.0386 mean_entropies: 0.8871, took: 94.6765s
2022-10-10 17:08:41,259 [INFO] 	Process 4 - batch 60199: mean_policy_losses: 96.044, mean_net_lifetime: 4060.6271, mean_mc_travel_dist: 1186.7137, mean_rewards: 259.3998, total_rewards: 2909.1618, mean_steps: 14.7000, mean_ecr: 0.0487 mean_entropies: 0.6717, took: 77.5425s
2022-10-10 17:08:54,741 [INFO] 	Process 3 - batch 55599: mean_policy_losses: 34.094, mean_net_lifetime: 4458.2109, mean_mc_travel_dist: 1238.4542, mean_rewards: 274.2169, total_rewards: 3252.4239, mean_steps: 15.3300, mean_ecr: 0.0485 mean_entropies: 0.5120, took: 576.2400s
2022-10-10 17:09:23,498 [INFO] 	Process 2 - batch 54299: mean_policy_losses: -22.529, mean_net_lifetime: 4898.2167, mean_mc_travel_dist: 1421.6229, mean_rewards: 281.7341, total_rewards: 3506.2450, mean_steps: 16.5100, mean_ecr: 0.0402 mean_entropies: 0.5333, took: 85.4454s
2022-10-10 17:09:27,411 [INFO] 	Process 5 - batch 53999: mean_policy_losses: -222.760, mean_net_lifetime: 5209.6374, mean_mc_travel_dist: 1774.9834, mean_rewards: 282.3288, total_rewards: 3485.0201, mean_steps: 17.9300, mean_ecr: 0.0305 mean_entropies: 0.5940, took: 88.5319s
2022-10-10 17:09:30,438 [INFO] 	Process 7 - batch 54399: mean_policy_losses: -531.765, mean_net_lifetime: 4085.0687, mean_mc_travel_dist: 1399.5900, mean_rewards: 226.6172, total_rewards: 2729.9766, mean_steps: 17.2600, mean_ecr: 0.0415 mean_entropies: 1.1456, took: 86.0188s
2022-10-10 17:10:01,735 [INFO] 	Process 1 - batch 47799: mean_policy_losses: -34.354, mean_net_lifetime: 5276.1619, mean_mc_travel_dist: 1856.7298, mean_rewards: 254.5377, total_rewards: 3437.5528, mean_steps: 20.0100, mean_ecr: 0.0389 mean_entropies: 0.8918, took: 95.7576s
2022-10-10 17:10:03,262 [INFO] 	Process 4 - batch 60299: mean_policy_losses: 121.633, mean_net_lifetime: 4275.9408, mean_mc_travel_dist: 1274.5853, mean_rewards: 257.7750, total_rewards: 3036.7883, mean_steps: 15.6200, mean_ecr: 0.0484 mean_entropies: 0.6656, took: 82.0029s
2022-10-10 17:10:11,903 [INFO] 	Process 3 - batch 55699: mean_policy_losses: 32.170, mean_net_lifetime: 4517.5700, mean_mc_travel_dist: 1247.4705, mean_rewards: 276.7533, total_rewards: 3308.1347, mean_steps: 15.3800, mean_ecr: 0.0482 mean_entropies: 0.5073, took: 77.1617s
2022-10-10 17:10:41,725 [INFO] 	Process 2 - batch 54399: mean_policy_losses: -55.456, mean_net_lifetime: 4770.1907, mean_mc_travel_dist: 1370.0911, mean_rewards: 285.8736, total_rewards: 3428.1965, mean_steps: 15.7700, mean_ecr: 0.0404 mean_entropies: 0.5439, took: 78.2263s
2022-10-10 17:11:08,315 [INFO] 	Process 7 - batch 54499: mean_policy_losses: -441.732, mean_net_lifetime: 4771.1416, mean_mc_travel_dist: 1690.4546, mean_rewards: 225.1122, total_rewards: 3125.2102, mean_steps: 20.7700, mean_ecr: 0.0404 mean_entropies: 1.1717, took: 97.8772s
2022-10-10 17:11:28,501 [INFO] 	Process 3 - batch 55799: mean_policy_losses: 39.071, mean_net_lifetime: 4552.6711, mean_mc_travel_dist: 1255.2275, mean_rewards: 279.6281, total_rewards: 3335.7625, mean_steps: 15.3400, mean_ecr: 0.0482 mean_entropies: 0.5111, took: 76.5987s
2022-10-10 17:11:31,614 [INFO] 	Process 4 - batch 60399: mean_policy_losses: 103.311, mean_net_lifetime: 5011.2898, mean_mc_travel_dist: 1465.0822, mean_rewards: 273.7804, total_rewards: 3575.5487, mean_steps: 17.4700, mean_ecr: 0.0467 mean_entropies: 0.6184, took: 88.3520s
2022-10-10 17:11:38,111 [INFO] 	Process 1 - batch 47899: mean_policy_losses: -29.269, mean_net_lifetime: 5333.1002, mean_mc_travel_dist: 1872.9709, mean_rewards: 249.2249, total_rewards: 3491.1482, mean_steps: 20.6400, mean_ecr: 0.0388 mean_entropies: 0.9054, took: 96.3759s
2022-10-10 17:12:00,555 [INFO] 	Process 2 - batch 54499: mean_policy_losses: -38.319, mean_net_lifetime: 4803.4225, mean_mc_travel_dist: 1375.4719, mean_rewards: 287.8598, total_rewards: 3459.0799, mean_steps: 15.7700, mean_ecr: 0.0404 mean_entropies: 0.5165, took: 78.8297s
2022-10-10 17:12:10,061 [INFO] 	Process 7 - batch 54599: mean_policy_losses: -892.416, mean_net_lifetime: 3251.8631, mean_mc_travel_dist: 1248.2357, mean_rewards: 255.9735, total_rewards: 2052.8841, mean_steps: 12.2800, mean_ecr: 0.0417 mean_entropies: 1.1208, took: 61.7465s
2022-10-10 17:12:45,600 [INFO] 	Process 3 - batch 55899: mean_policy_losses: 37.972, mean_net_lifetime: 4540.2279, mean_mc_travel_dist: 1258.4094, mean_rewards: 274.3442, total_rewards: 3321.4669, mean_steps: 15.6000, mean_ecr: 0.0482 mean_entropies: 0.4897, took: 77.0982s
2022-10-10 17:12:51,404 [INFO] 	Process 4 - batch 60499: mean_policy_losses: 81.785, mean_net_lifetime: 4929.8387, mean_mc_travel_dist: 1611.9318, mean_rewards: 294.9862, total_rewards: 3350.3217, mean_steps: 15.8700, mean_ecr: 0.0460 mean_entropies: 0.4762, took: 79.7897s
2022-10-10 17:13:06,924 [INFO] 	Process 7 - batch 54699: mean_policy_losses: -833.227, mean_net_lifetime: 3202.9478, mean_mc_travel_dist: 1306.1322, mean_rewards: 270.4156, total_rewards: 1942.5880, mean_steps: 11.4400, mean_ecr: 0.0418 mean_entropies: 1.0013, took: 56.8628s
2022-10-10 17:13:10,128 [INFO] 	Process 1 - batch 47999: mean_policy_losses: -25.214, mean_net_lifetime: 5144.1922, mean_mc_travel_dist: 1951.0792, mean_rewards: 255.5170, total_rewards: 3219.0275, mean_steps: 19.5300, mean_ecr: 0.0385 mean_entropies: 0.8086, took: 92.0167s
2022-10-10 17:13:15,553 [INFO] 	Process 2 - batch 54599: mean_policy_losses: -71.296, mean_net_lifetime: 4587.4403, mean_mc_travel_dist: 1397.4482, mean_rewards: 290.9141, total_rewards: 3219.2220, mean_steps: 14.8700, mean_ecr: 0.0402 mean_entropies: 0.4882, took: 74.9984s
2022-10-10 17:13:59,300 [INFO] 	Process 3 - batch 55999: mean_policy_losses: 52.887, mean_net_lifetime: 4421.3732, mean_mc_travel_dist: 1223.1255, mean_rewards: 273.5892, total_rewards: 3227.1216, mean_steps: 15.2300, mean_ecr: 0.0482 mean_entropies: 0.4840, took: 73.7005s
2022-10-10 17:14:19,039 [INFO] 	Process 4 - batch 60599: mean_policy_losses: 133.292, mean_net_lifetime: 5471.0457, mean_mc_travel_dist: 1706.5083, mean_rewards: 290.2774, total_rewards: 3793.3104, mean_steps: 18.4100, mean_ecr: 0.0450 mean_entropies: 0.5104, took: 87.6349s
2022-10-10 17:14:33,353 [INFO] 	Process 2 - batch 54699: mean_policy_losses: -52.911, mean_net_lifetime: 4704.6416, mean_mc_travel_dist: 1318.3146, mean_rewards: 275.2031, total_rewards: 3408.4075, mean_steps: 16.2000, mean_ecr: 0.0408 mean_entropies: 0.4616, took: 77.8003s
2022-10-10 17:14:36,458 [INFO] 	Process 7 - batch 54799: mean_policy_losses: -508.506, mean_net_lifetime: 4751.9006, mean_mc_travel_dist: 1720.2732, mean_rewards: 236.4166, total_rewards: 3073.7449, mean_steps: 19.9600, mean_ecr: 0.0405 mean_entropies: 1.1151, took: 89.5320s
2022-10-10 17:15:14,568 [INFO] 	Process 3 - batch 56099: mean_policy_losses: 13.747, mean_net_lifetime: 4503.3696, mean_mc_travel_dist: 1224.9534, mean_rewards: 271.2687, total_rewards: 3312.3810, mean_steps: 15.6700, mean_ecr: 0.0481 mean_entropies: 0.4780, took: 75.2677s
2022-10-10 17:15:22,244 [INFO] Process 6 - epoch 51: mean_policy_losses: -241.799, mean_net_lifetime: 2817.2917, mean_mc_travel_dist: 949.4426, mean_entropies: 0.7270, m_net_lifetime_valid: 4334.7726, took: 1404.0522s, (109.5688 / 100 batches)

2022-10-10 17:15:45,261 [INFO] 	Process 4 - batch 60699: mean_policy_losses: 128.420, mean_net_lifetime: 5404.7402, mean_mc_travel_dist: 1556.9859, mean_rewards: 287.2722, total_rewards: 3873.7371, mean_steps: 17.9300, mean_ecr: 0.0457 mean_entropies: 0.5382, took: 86.2218s
2022-10-10 17:15:48,527 [INFO] 	Process 2 - batch 54799: mean_policy_losses: -41.717, mean_net_lifetime: 4716.4332, mean_mc_travel_dist: 1309.8871, mean_rewards: 282.4011, total_rewards: 3433.9774, mean_steps: 15.7800, mean_ecr: 0.0408 mean_entropies: 0.4554, took: 75.1736s
2022-10-10 17:16:10,999 [INFO] 	Process 7 - batch 54899: mean_policy_losses: -495.013, mean_net_lifetime: 4804.5738, mean_mc_travel_dist: 1685.7327, mean_rewards: 230.0784, total_rewards: 3158.7554, mean_steps: 20.6800, mean_ecr: 0.0407 mean_entropies: 1.1864, took: 94.5421s
2022-10-10 17:16:13,110 [INFO] 	Process 6 - batch 76599: mean_policy_losses: -167.662, mean_net_lifetime: 3415.2676, mean_mc_travel_dist: 929.3225, mean_rewards: 322.7824, total_rewards: 2511.8249, mean_steps: 9.6500, mean_ecr: 0.0561 mean_entropies: 0.1887, took: 648.0919s
2022-10-10 17:16:30,942 [INFO] 	Process 3 - batch 56199: mean_policy_losses: 14.579, mean_net_lifetime: 4421.8878, mean_mc_travel_dist: 1197.3993, mean_rewards: 270.9166, total_rewards: 3251.5416, mean_steps: 15.3800, mean_ecr: 0.0487 mean_entropies: 0.4993, took: 76.3741s
2022-10-10 17:17:06,700 [INFO] 	Process 4 - batch 60799: mean_policy_losses: 90.441, mean_net_lifetime: 5007.8477, mean_mc_travel_dist: 1445.4142, mean_rewards: 291.6985, total_rewards: 3595.7293, mean_steps: 16.2600, mean_ecr: 0.0469 mean_entropies: 0.5563, took: 81.4395s
2022-10-10 17:17:07,390 [INFO] 	Process 2 - batch 54899: mean_policy_losses: -26.706, mean_net_lifetime: 4729.9859, mean_mc_travel_dist: 1300.7896, mean_rewards: 283.2002, total_rewards: 3453.5255, mean_steps: 15.7700, mean_ecr: 0.0408 mean_entropies: 0.4842, took: 78.8631s
2022-10-10 17:17:09,711 [INFO] 	Process 6 - batch 76699: mean_policy_losses: -100.409, mean_net_lifetime: 3725.9761, mean_mc_travel_dist: 998.2973, mean_rewards: 312.9837, total_rewards: 2752.0039, mean_steps: 10.9200, mean_ecr: 0.0557 mean_entropies: 0.1546, took: 56.6016s
2022-10-10 17:17:26,571 [INFO] 	Process 7 - batch 54999: mean_policy_losses: -707.576, mean_net_lifetime: 3908.7701, mean_mc_travel_dist: 1415.6867, mean_rewards: 236.0933, total_rewards: 2542.4603, mean_steps: 15.8800, mean_ecr: 0.0414 mean_entropies: 1.1648, took: 75.5714s
2022-10-10 17:17:45,351 [INFO] 	Process 3 - batch 56299: mean_policy_losses: 26.690, mean_net_lifetime: 4460.5253, mean_mc_travel_dist: 1225.9972, mean_rewards: 279.4584, total_rewards: 3261.1666, mean_steps: 15.0200, mean_ecr: 0.0485 mean_entropies: 0.4996, took: 74.4075s
2022-10-10 17:18:00,354 [INFO] 	Process 6 - batch 76799: mean_policy_losses: -180.630, mean_net_lifetime: 3436.7876, mean_mc_travel_dist: 932.0465, mean_rewards: 322.8952, total_rewards: 2526.1736, mean_steps: 9.7500, mean_ecr: 0.0559 mean_entropies: 0.1714, took: 50.6427s
2022-10-10 17:18:10,628 [INFO] Process 5 - epoch 36: mean_policy_losses: -217.700, mean_net_lifetime: 4525.3070, mean_mc_travel_dist: 1897.9493, mean_entropies: 1.3458, m_net_lifetime_valid: 4459.3473, took: 1797.5808s, (155.5870 / 100 batches)

2022-10-10 17:18:27,002 [INFO] 	Process 2 - batch 54999: mean_policy_losses: -31.008, mean_net_lifetime: 4724.3429, mean_mc_travel_dist: 1319.1141, mean_rewards: 281.3254, total_rewards: 3426.6189, mean_steps: 15.8900, mean_ecr: 0.0407 mean_entropies: 0.4884, took: 79.6124s
2022-10-10 17:18:30,908 [INFO] 	Process 4 - batch 60899: mean_policy_losses: 91.511, mean_net_lifetime: 5102.3701, mean_mc_travel_dist: 1511.6619, mean_rewards: 294.8542, total_rewards: 3617.8502, mean_steps: 16.3900, mean_ecr: 0.0464 mean_entropies: 0.5120, took: 84.2083s
2022-10-10 17:18:44,681 [INFO] 	Process 7 - batch 55099: mean_policy_losses: -651.405, mean_net_lifetime: 4152.8130, mean_mc_travel_dist: 1522.6167, mean_rewards: 247.6391, total_rewards: 2667.9499, mean_steps: 16.1300, mean_ecr: 0.0412 mean_entropies: 1.1488, took: 78.1109s
2022-10-10 17:18:53,152 [INFO] 	Process 6 - batch 76899: mean_policy_losses: -196.909, mean_net_lifetime: 3502.4352, mean_mc_travel_dist: 947.4587, mean_rewards: 323.3474, total_rewards: 2578.2736, mean_steps: 9.9200, mean_ecr: 0.0558 mean_entropies: 0.1546, took: 52.7983s
2022-10-10 17:19:02,617 [INFO] 	Process 3 - batch 56399: mean_policy_losses: 38.335, mean_net_lifetime: 4520.1351, mean_mc_travel_dist: 1234.9583, mean_rewards: 275.3599, total_rewards: 3306.8197, mean_steps: 15.4500, mean_ecr: 0.0486 mean_entropies: 0.4949, took: 77.2673s
2022-10-10 17:19:37,978 [INFO] 	Process 5 - batch 54099: mean_policy_losses: -244.963, mean_net_lifetime: 4732.8158, mean_mc_travel_dist: 1608.7214, mean_rewards: 262.0041, total_rewards: 3176.9451, mean_steps: 17.6000, mean_ecr: 0.0304 mean_entropies: 0.6109, took: 610.5662s
2022-10-10 17:19:48,175 [INFO] 	Process 2 - batch 55099: mean_policy_losses: -61.328, mean_net_lifetime: 4684.7282, mean_mc_travel_dist: 1427.7775, mean_rewards: 283.6893, total_rewards: 3276.5478, mean_steps: 15.6000, mean_ecr: 0.0399 mean_entropies: 0.4671, took: 81.1726s
2022-10-10 17:19:49,379 [INFO] 	Process 6 - batch 76999: mean_policy_losses: -115.927, mean_net_lifetime: 3676.2046, mean_mc_travel_dist: 991.5572, mean_rewards: 321.7025, total_rewards: 2713.8942, mean_steps: 10.4700, mean_ecr: 0.0559 mean_entropies: 0.1504, took: 56.2262s
2022-10-10 17:19:54,142 [INFO] 	Process 4 - batch 60999: mean_policy_losses: 87.937, mean_net_lifetime: 4823.0800, mean_mc_travel_dist: 1379.8013, mean_rewards: 283.4496, total_rewards: 3473.3934, mean_steps: 16.1200, mean_ecr: 0.0475 mean_entropies: 0.5760, took: 83.2340s
2022-10-10 17:20:13,315 [INFO] 	Process 7 - batch 55199: mean_policy_losses: -549.544, mean_net_lifetime: 4213.6193, mean_mc_travel_dist: 1494.5723, mean_rewards: 225.0073, total_rewards: 2778.6354, mean_steps: 17.8600, mean_ecr: 0.0413 mean_entropies: 1.1324, took: 88.6340s
2022-10-10 17:20:21,676 [INFO] 	Process 3 - batch 56499: mean_policy_losses: 48.328, mean_net_lifetime: 4471.2658, mean_mc_travel_dist: 1238.3104, mean_rewards: 272.7526, total_rewards: 3255.8917, mean_steps: 15.4700, mean_ecr: 0.0484 mean_entropies: 0.4988, took: 79.0597s
2022-10-10 17:20:41,370 [INFO] 	Process 6 - batch 77099: mean_policy_losses: -173.147, mean_net_lifetime: 3416.2462, mean_mc_travel_dist: 924.6186, mean_rewards: 326.7397, total_rewards: 2517.9715, mean_steps: 9.4800, mean_ecr: 0.0561 mean_entropies: 0.1760, took: 51.9912s
2022-10-10 17:20:58,932 [INFO] Process 1 - epoch 32: mean_policy_losses: 41.936, mean_net_lifetime: 4858.7418, mean_mc_travel_dist: 2041.0057, mean_entropies: 1.2855, m_net_lifetime_valid: 3974.1102, took: 1869.9073s, (175.4581 / 100 batches)

2022-10-10 17:20:59,129 [INFO] 	Process 5 - batch 54199: mean_policy_losses: -241.643, mean_net_lifetime: 4572.7982, mean_mc_travel_dist: 1557.3629, mean_rewards: 272.9855, total_rewards: 3077.1231, mean_steps: 16.3600, mean_ecr: 0.0306 mean_entropies: 0.5962, took: 81.1524s
2022-10-10 17:21:11,049 [INFO] 	Process 2 - batch 55199: mean_policy_losses: -25.095, mean_net_lifetime: 4700.8267, mean_mc_travel_dist: 1322.7168, mean_rewards: 281.3853, total_rewards: 3403.5635, mean_steps: 15.7800, mean_ecr: 0.0405 mean_entropies: 0.4515, took: 82.8738s
2022-10-10 17:21:24,855 [INFO] 	Process 4 - batch 61099: mean_policy_losses: 93.926, mean_net_lifetime: 4955.2545, mean_mc_travel_dist: 1406.5165, mean_rewards: 279.1646, total_rewards: 3583.3970, mean_steps: 16.8500, mean_ecr: 0.0470 mean_entropies: 0.5903, took: 90.7126s
2022-10-10 17:21:41,621 [INFO] 	Process 6 - batch 77199: mean_policy_losses: -88.249, mean_net_lifetime: 3776.5769, mean_mc_travel_dist: 1005.0292, mean_rewards: 314.6606, total_rewards: 2798.3411, mean_steps: 11.0900, mean_ecr: 0.0555 mean_entropies: 0.1482, took: 60.2510s
2022-10-10 17:21:43,557 [INFO] 	Process 3 - batch 56599: mean_policy_losses: 31.394, mean_net_lifetime: 4503.3549, mean_mc_travel_dist: 1235.3162, mean_rewards: 269.5787, total_rewards: 3293.9630, mean_steps: 15.7500, mean_ecr: 0.0485 mean_entropies: 0.4876, took: 81.8810s
2022-10-10 17:21:54,525 [INFO] 	Process 7 - batch 55299: mean_policy_losses: -366.817, mean_net_lifetime: 4710.8669, mean_mc_travel_dist: 1634.2629, mean_rewards: 230.5658, total_rewards: 3115.5108, mean_steps: 19.9000, mean_ecr: 0.0409 mean_entropies: 1.0934, took: 101.2103s
2022-10-10 17:22:23,064 [INFO] 	Process 5 - batch 54299: mean_policy_losses: -311.622, mean_net_lifetime: 4470.2458, mean_mc_travel_dist: 1495.7530, mean_rewards: 274.1276, total_rewards: 3019.0395, mean_steps: 16.1900, mean_ecr: 0.0305 mean_entropies: 0.5732, took: 83.9348s
2022-10-10 17:22:28,319 [INFO] 	Process 1 - batch 48099: mean_policy_losses: -89.051, mean_net_lifetime: 4949.4306, mean_mc_travel_dist: 1976.6055, mean_rewards: 268.3850, total_rewards: 2999.9215, mean_steps: 17.6000, mean_ecr: 0.0384 mean_entropies: 0.6986, took: 558.1911s
2022-10-10 17:22:33,189 [INFO] 	Process 2 - batch 55299: mean_policy_losses: -73.209, mean_net_lifetime: 4605.0565, mean_mc_travel_dist: 1384.9812, mean_rewards: 276.3409, total_rewards: 3245.8003, mean_steps: 15.7300, mean_ecr: 0.0401 mean_entropies: 0.4428, took: 82.1405s
2022-10-10 17:22:40,451 [INFO] 	Process 6 - batch 77299: mean_policy_losses: -121.093, mean_net_lifetime: 3586.1754, mean_mc_travel_dist: 956.9561, mean_rewards: 315.0836, total_rewards: 2660.4321, mean_steps: 10.4800, mean_ecr: 0.0559 mean_entropies: 0.1435, took: 58.8295s
2022-10-10 17:22:49,386 [INFO] 	Process 4 - batch 61199: mean_policy_losses: 83.458, mean_net_lifetime: 4789.8425, mean_mc_travel_dist: 1412.1744, mean_rewards: 284.0807, total_rewards: 3407.1826, mean_steps: 15.9000, mean_ecr: 0.0474 mean_entropies: 0.5298, took: 84.5314s
2022-10-10 17:23:08,392 [INFO] 	Process 3 - batch 56699: mean_policy_losses: 48.247, mean_net_lifetime: 4399.8270, mean_mc_travel_dist: 1212.4569, mean_rewards: 262.0434, total_rewards: 3218.8862, mean_steps: 15.8600, mean_ecr: 0.0487 mean_entropies: 0.4798, took: 84.8345s
2022-10-10 17:23:14,488 [INFO] 	Process 7 - batch 55399: mean_policy_losses: -535.927, mean_net_lifetime: 3749.3246, mean_mc_travel_dist: 1404.6242, mean_rewards: 235.9452, total_rewards: 2384.2260, mean_steps: 15.4300, mean_ecr: 0.0416 mean_entropies: 0.9757, took: 79.9631s
2022-10-10 17:23:43,491 [INFO] 	Process 6 - batch 77399: mean_policy_losses: -34.707, mean_net_lifetime: 3869.0538, mean_mc_travel_dist: 1025.2876, mean_rewards: 314.8718, total_rewards: 2869.7490, mean_steps: 11.3300, mean_ecr: 0.0555 mean_entropies: 0.1394, took: 63.0402s
2022-10-10 17:23:45,013 [INFO] 	Process 5 - batch 54399: mean_policy_losses: -328.453, mean_net_lifetime: 4192.1648, mean_mc_travel_dist: 1393.5801, mean_rewards: 265.3905, total_rewards: 2846.7964, mean_steps: 15.8800, mean_ecr: 0.0302 mean_entropies: 0.5855, took: 81.9488s
2022-10-10 17:23:57,152 [INFO] 	Process 2 - batch 55399: mean_policy_losses: -46.977, mean_net_lifetime: 4662.0123, mean_mc_travel_dist: 1337.6274, mean_rewards: 280.5509, total_rewards: 3352.4976, mean_steps: 15.7100, mean_ecr: 0.0405 mean_entropies: 0.4264, took: 83.9619s
2022-10-10 17:23:59,516 [INFO] 	Process 1 - batch 48199: mean_policy_losses: -48.784, mean_net_lifetime: 4981.2377, mean_mc_travel_dist: 1949.2306, mean_rewards: 266.4298, total_rewards: 3056.2422, mean_steps: 17.9200, mean_ecr: 0.0386 mean_entropies: 0.7408, took: 91.1976s
2022-10-10 17:24:19,299 [INFO] 	Process 4 - batch 61299: mean_policy_losses: 120.067, mean_net_lifetime: 5058.4002, mean_mc_travel_dist: 1468.3337, mean_rewards: 284.2465, total_rewards: 3624.4516, mean_steps: 16.8900, mean_ecr: 0.0467 mean_entropies: 0.5492, took: 89.9127s
2022-10-10 17:24:31,379 [INFO] 	Process 3 - batch 56799: mean_policy_losses: 37.776, mean_net_lifetime: 4507.4735, mean_mc_travel_dist: 1234.7186, mean_rewards: 270.6625, total_rewards: 3307.4369, mean_steps: 15.7000, mean_ecr: 0.0485 mean_entropies: 0.4707, took: 82.9862s
2022-10-10 17:24:40,689 [INFO] 	Process 7 - batch 55499: mean_policy_losses: -618.052, mean_net_lifetime: 3899.1598, mean_mc_travel_dist: 1420.2028, mean_rewards: 228.5402, total_rewards: 2526.1176, mean_steps: 16.6200, mean_ecr: 0.0415 mean_entropies: 1.0645, took: 86.2011s
2022-10-10 17:24:44,360 [INFO] 	Process 6 - batch 77499: mean_policy_losses: -104.861, mean_net_lifetime: 3760.1083, mean_mc_travel_dist: 1001.3233, mean_rewards: 316.7786, total_rewards: 2776.7035, mean_steps: 10.9100, mean_ecr: 0.0556 mean_entropies: 0.1554, took: 60.8695s
2022-10-10 17:25:10,536 [INFO] 	Process 5 - batch 54499: mean_policy_losses: -267.182, mean_net_lifetime: 4577.8098, mean_mc_travel_dist: 1524.6709, mean_rewards: 259.3585, total_rewards: 3118.9493, mean_steps: 17.0100, mean_ecr: 0.0308 mean_entropies: 0.6129, took: 85.5233s
2022-10-10 17:25:21,262 [INFO] 	Process 2 - batch 55499: mean_policy_losses: -48.064, mean_net_lifetime: 4696.0431, mean_mc_travel_dist: 1343.8851, mean_rewards: 279.8837, total_rewards: 3374.0777, mean_steps: 15.8600, mean_ecr: 0.0405 mean_entropies: 0.4477, took: 84.1112s
2022-10-10 17:25:30,457 [INFO] 	Process 1 - batch 48299: mean_policy_losses: -77.608, mean_net_lifetime: 5100.2789, mean_mc_travel_dist: 1936.8908, mean_rewards: 265.4295, total_rewards: 3193.4862, mean_steps: 18.3900, mean_ecr: 0.0386 mean_entropies: 0.7857, took: 90.9403s
2022-10-10 17:25:40,966 [INFO] 	Process 4 - batch 61399: mean_policy_losses: 89.305, mean_net_lifetime: 4837.2176, mean_mc_travel_dist: 1407.7085, mean_rewards: 292.2358, total_rewards: 3456.6557, mean_steps: 15.6200, mean_ecr: 0.0473 mean_entropies: 0.5198, took: 81.6665s
2022-10-10 17:25:41,913 [INFO] 	Process 6 - batch 77599: mean_policy_losses: -105.092, mean_net_lifetime: 3731.0416, mean_mc_travel_dist: 992.7058, mean_rewards: 313.2623, total_rewards: 2771.2593, mean_steps: 10.9500, mean_ecr: 0.0557 mean_entropies: 0.1539, took: 57.5524s
2022-10-10 17:25:50,356 [INFO] 	Process 3 - batch 56899: mean_policy_losses: 27.839, mean_net_lifetime: 4493.9758, mean_mc_travel_dist: 1228.6807, mean_rewards: 267.8725, total_rewards: 3287.4713, mean_steps: 15.8100, mean_ecr: 0.0484 mean_entropies: 0.4870, took: 78.9780s
2022-10-10 17:26:36,115 [INFO] 	Process 5 - batch 54599: mean_policy_losses: -319.093, mean_net_lifetime: 4579.4673, mean_mc_travel_dist: 1562.5693, mean_rewards: 261.7408, total_rewards: 3063.0963, mean_steps: 17.8600, mean_ecr: 0.0301 mean_entropies: 0.5823, took: 85.5784s
2022-10-10 17:26:37,686 [INFO] 	Process 6 - batch 77699: mean_policy_losses: -87.138, mean_net_lifetime: 3736.7589, mean_mc_travel_dist: 990.1487, mean_rewards: 316.4376, total_rewards: 2777.5406, mean_steps: 10.8900, mean_ecr: 0.0558 mean_entropies: 0.1531, took: 55.7733s
2022-10-10 17:26:55,843 [INFO] 	Process 1 - batch 48399: mean_policy_losses: -93.621, mean_net_lifetime: 5089.1982, mean_mc_travel_dist: 1915.1919, mean_rewards: 268.4697, total_rewards: 3205.5894, mean_steps: 18.1200, mean_ecr: 0.0387 mean_entropies: 0.7940, took: 85.3860s
2022-10-10 17:27:02,239 [INFO] 	Process 4 - batch 61499: mean_policy_losses: 57.843, mean_net_lifetime: 4917.7565, mean_mc_travel_dist: 1433.4961, mean_rewards: 287.7069, total_rewards: 3515.8751, mean_steps: 16.1600, mean_ecr: 0.0469 mean_entropies: 0.5098, took: 81.2731s
2022-10-10 17:27:05,793 [INFO] 	Process 3 - batch 56999: mean_policy_losses: 15.611, mean_net_lifetime: 4498.0941, mean_mc_travel_dist: 1239.0781, mean_rewards: 276.1573, total_rewards: 3286.4286, mean_steps: 15.3400, mean_ecr: 0.0485 mean_entropies: 0.4736, took: 75.4369s
2022-10-10 17:27:33,234 [INFO] 	Process 6 - batch 77799: mean_policy_losses: -54.025, mean_net_lifetime: 3793.8027, mean_mc_travel_dist: 997.9621, mean_rewards: 317.4786, total_rewards: 2822.1615, mean_steps: 10.9800, mean_ecr: 0.0557 mean_entropies: 0.1310, took: 55.5488s
2022-10-10 17:27:58,250 [INFO] 	Process 5 - batch 54699: mean_policy_losses: -246.482, mean_net_lifetime: 4998.5429, mean_mc_travel_dist: 1708.8175, mean_rewards: 274.6438, total_rewards: 3332.0764, mean_steps: 18.1100, mean_ecr: 0.0304 mean_entropies: 0.6086, took: 82.1356s
2022-10-10 17:28:21,117 [INFO] 	Process 1 - batch 48499: mean_policy_losses: -39.800, mean_net_lifetime: 5264.4848, mean_mc_travel_dist: 1948.6482, mean_rewards: 260.3559, total_rewards: 3346.8447, mean_steps: 19.3800, mean_ecr: 0.0385 mean_entropies: 0.8274, took: 85.2747s
2022-10-10 17:28:26,177 [INFO] 	Process 6 - batch 77899: mean_policy_losses: -111.612, mean_net_lifetime: 3700.2108, mean_mc_travel_dist: 971.2130, mean_rewards: 317.3757, total_rewards: 2754.2313, mean_steps: 10.7000, mean_ecr: 0.0557 mean_entropies: 0.1406, took: 52.9425s
2022-10-10 17:29:17,071 [INFO] 	Process 6 - batch 77999: mean_policy_losses: -141.536, mean_net_lifetime: 3606.6674, mean_mc_travel_dist: 958.0596, mean_rewards: 317.9018, total_rewards: 2677.0618, mean_steps: 10.3600, mean_ecr: 0.0558 mean_entropies: 0.1432, took: 50.8943s
2022-10-10 17:29:26,573 [INFO] 	Process 5 - batch 54799: mean_policy_losses: -132.559, mean_net_lifetime: 5735.2918, mean_mc_travel_dist: 1950.9854, mean_rewards: 277.7549, total_rewards: 3839.0192, mean_steps: 20.1000, mean_ecr: 0.0311 mean_entropies: 0.5475, took: 88.3232s
2022-10-10 17:29:47,327 [INFO] 	Process 1 - batch 48599: mean_policy_losses: -13.854, mean_net_lifetime: 5416.0002, mean_mc_travel_dist: 1976.7952, mean_rewards: 259.3683, total_rewards: 3461.3966, mean_steps: 20.0100, mean_ecr: 0.0387 mean_entropies: 0.8445, took: 86.2096s
2022-10-10 17:30:54,289 [INFO] 	Process 5 - batch 54899: mean_policy_losses: -108.081, mean_net_lifetime: 5795.8752, mean_mc_travel_dist: 2006.1103, mean_rewards: 269.3005, total_rewards: 3839.2718, mean_steps: 20.8000, mean_ecr: 0.0313 mean_entropies: 0.5321, took: 87.7149s
2022-10-10 17:31:13,749 [INFO] 	Process 1 - batch 48699: mean_policy_losses: 32.088, mean_net_lifetime: 5492.8771, mean_mc_travel_dist: 2021.2378, mean_rewards: 254.2122, total_rewards: 3501.9026, mean_steps: 20.7200, mean_ecr: 0.0387 mean_entropies: 0.9026, took: 86.4216s
2022-10-10 17:32:28,375 [INFO] 	Process 5 - batch 54999: mean_policy_losses: -118.085, mean_net_lifetime: 6215.7469, mean_mc_travel_dist: 2190.4050, mean_rewards: 267.1214, total_rewards: 4069.5642, mean_steps: 22.3900, mean_ecr: 0.0312 mean_entropies: 0.5549, took: 94.0866s
2022-10-10 17:32:43,208 [INFO] 	Process 1 - batch 48799: mean_policy_losses: 21.383, mean_net_lifetime: 5580.1828, mean_mc_travel_dist: 1939.2978, mean_rewards: 253.2138, total_rewards: 3660.0058, mean_steps: 21.1400, mean_ecr: 0.0389 mean_entropies: 0.9648, took: 89.4592s
2022-10-10 17:33:34,019 [INFO] Process 7 - epoch 37: mean_policy_losses: -306.047, mean_net_lifetime: 3990.5861, mean_mc_travel_dist: 1581.9545, mean_entropies: 1.6705, m_net_lifetime_valid: 4141.0682, took: 1782.0190s, (153.0321 / 100 batches)

2022-10-10 17:33:55,692 [INFO] Process 2 - epoch 37: mean_policy_losses: 4.774, mean_net_lifetime: 4328.8089, mean_mc_travel_dist: 1551.9868, mean_entropies: 1.0477, m_net_lifetime_valid: 4443.1508, took: 1722.5377s, (153.1053 / 100 batches)

2022-10-10 17:33:56,014 [INFO] 	Process 5 - batch 55099: mean_policy_losses: -141.695, mean_net_lifetime: 6027.4902, mean_mc_travel_dist: 2052.6711, mean_rewards: 278.9206, total_rewards: 4021.9314, mean_steps: 20.8100, mean_ecr: 0.0312 mean_entropies: 0.5740, took: 87.6389s
2022-10-10 17:34:09,031 [INFO] 	Process 1 - batch 48899: mean_policy_losses: 78.541, mean_net_lifetime: 5568.8099, mean_mc_travel_dist: 1992.4203, mean_rewards: 266.8607, total_rewards: 3592.8690, mean_steps: 19.9100, mean_ecr: 0.0387 mean_entropies: 0.9040, took: 85.8228s
2022-10-10 17:34:38,966 [INFO] 	Process 7 - batch 55599: mean_policy_losses: -340.260, mean_net_lifetime: 3121.5038, mean_mc_travel_dist: 1072.2724, mean_rewards: 208.3018, total_rewards: 2089.6794, mean_steps: 14.1300, mean_ecr: 0.0424 mean_entropies: 0.9646, took: 598.2762s
2022-10-10 17:34:47,514 [INFO] Process 4 - epoch 41: mean_policy_losses: 87.730, mean_net_lifetime: 3950.7656, mean_mc_travel_dist: 1313.2860, mean_entropies: 1.2718, m_net_lifetime_valid: 4225.5826, took: 1719.7899s, (138.3560 / 100 batches)

2022-10-10 17:35:13,939 [INFO] 	Process 2 - batch 55599: mean_policy_losses: 0.862, mean_net_lifetime: 4848.3332, mean_mc_travel_dist: 1471.7580, mean_rewards: 277.8794, total_rewards: 3405.8197, mean_steps: 16.5500, mean_ecr: 0.0399 mean_entropies: 0.5608, took: 592.6762s
2022-10-10 17:35:22,036 [INFO] 	Process 5 - batch 55199: mean_policy_losses: -151.930, mean_net_lifetime: 5417.4442, mean_mc_travel_dist: 1826.0019, mean_rewards: 283.9842, total_rewards: 3634.1342, mean_steps: 18.6300, mean_ecr: 0.0308 mean_entropies: 0.6248, took: 86.0221s
2022-10-10 17:35:30,068 [INFO] Process 3 - epoch 38: mean_policy_losses: 79.143, mean_net_lifetime: 4175.2521, mean_mc_travel_dist: 1381.0976, mean_entropies: 1.0237, m_net_lifetime_valid: 4253.9571, took: 1673.7982s, (149.2650 / 100 batches)

2022-10-10 17:35:42,042 [INFO] 	Process 1 - batch 48999: mean_policy_losses: 82.914, mean_net_lifetime: 5312.0891, mean_mc_travel_dist: 1965.9616, mean_rewards: 258.8210, total_rewards: 3372.3585, mean_steps: 19.6600, mean_ecr: 0.0386 mean_entropies: 0.8179, took: 93.0118s
2022-10-10 17:35:50,327 [INFO] 	Process 7 - batch 55699: mean_policy_losses: -381.076, mean_net_lifetime: 3425.9397, mean_mc_travel_dist: 1216.9094, mean_rewards: 219.1574, total_rewards: 2258.2438, mean_steps: 14.8300, mean_ecr: 0.0418 mean_entropies: 1.0365, took: 71.3613s
2022-10-10 17:36:01,840 [INFO] 	Process 4 - batch 61599: mean_policy_losses: 178.358, mean_net_lifetime: 3917.4811, mean_mc_travel_dist: 1223.2266, mean_rewards: 252.2059, total_rewards: 2725.3447, mean_steps: 14.4200, mean_ecr: 0.0489 mean_entropies: 0.5881, took: 539.6016s
2022-10-10 17:36:29,234 [INFO] 	Process 2 - batch 55699: mean_policy_losses: -72.760, mean_net_lifetime: 4706.3487, mean_mc_travel_dist: 1534.4393, mean_rewards: 298.5065, total_rewards: 3196.0387, mean_steps: 14.8300, mean_ecr: 0.0395 mean_entropies: 0.5392, took: 75.2951s
2022-10-10 17:36:48,404 [INFO] 	Process 3 - batch 57099: mean_policy_losses: 95.978, mean_net_lifetime: 4627.6076, mean_mc_travel_dist: 1332.9037, mean_rewards: 283.1429, total_rewards: 3327.2416, mean_steps: 15.3600, mean_ecr: 0.0476 mean_entropies: 0.5432, took: 582.6107s
2022-10-10 17:36:59,421 [INFO] 	Process 5 - batch 55299: mean_policy_losses: -146.257, mean_net_lifetime: 5701.1762, mean_mc_travel_dist: 1991.5057, mean_rewards: 276.5244, total_rewards: 3761.4504, mean_steps: 19.9300, mean_ecr: 0.0299 mean_entropies: 0.6455, took: 97.3837s
2022-10-10 17:37:15,445 [INFO] 	Process 7 - batch 55799: mean_policy_losses: -493.469, mean_net_lifetime: 3956.4986, mean_mc_travel_dist: 1378.6702, mean_rewards: 222.7999, total_rewards: 2612.5904, mean_steps: 17.4300, mean_ecr: 0.0412 mean_entropies: 1.1588, took: 85.1184s
2022-10-10 17:37:20,598 [INFO] 	Process 1 - batch 49099: mean_policy_losses: 4.836, mean_net_lifetime: 5231.9709, mean_mc_travel_dist: 1921.3380, mean_rewards: 246.5822, total_rewards: 3335.9605, mean_steps: 20.4900, mean_ecr: 0.0388 mean_entropies: 0.7976, took: 98.5556s
2022-10-10 17:37:25,652 [INFO] 	Process 4 - batch 61699: mean_policy_losses: 150.142, mean_net_lifetime: 4611.4804, mean_mc_travel_dist: 1355.5505, mean_rewards: 269.5088, total_rewards: 3281.5072, mean_steps: 16.0900, mean_ecr: 0.0478 mean_entropies: 0.6146, took: 83.8120s
2022-10-10 17:37:52,813 [INFO] 	Process 2 - batch 55799: mean_policy_losses: -18.458, mean_net_lifetime: 5025.8146, mean_mc_travel_dist: 1484.0281, mean_rewards: 286.2449, total_rewards: 3568.9598, mean_steps: 16.7100, mean_ecr: 0.0399 mean_entropies: 0.5685, took: 83.5793s
2022-10-10 17:38:05,332 [INFO] 	Process 3 - batch 57199: mean_policy_losses: 52.847, mean_net_lifetime: 4540.3095, mean_mc_travel_dist: 1294.6277, mean_rewards: 283.8534, total_rewards: 3280.9703, mean_steps: 15.0500, mean_ecr: 0.0479 mean_entropies: 0.5099, took: 76.9282s
2022-10-10 17:38:18,508 [INFO] 	Process 7 - batch 55899: mean_policy_losses: -659.539, mean_net_lifetime: 3027.7821, mean_mc_travel_dist: 1118.6675, mean_rewards: 235.5161, total_rewards: 1960.5125, mean_steps: 12.3800, mean_ecr: 0.0423 mean_entropies: 1.0244, took: 63.0631s
2022-10-10 17:38:19,816 [INFO] Process 6 - epoch 52: mean_policy_losses: -239.435, mean_net_lifetime: 2833.2839, mean_mc_travel_dist: 949.9302, mean_entropies: 0.7159, m_net_lifetime_valid: 4757.2691, took: 1377.5700s, (109.2981 / 100 batches)

2022-10-10 17:38:34,146 [INFO] 	Process 5 - batch 55399: mean_policy_losses: -244.456, mean_net_lifetime: 5388.0059, mean_mc_travel_dist: 1866.9946, mean_rewards: 270.1390, total_rewards: 3570.8167, mean_steps: 19.4500, mean_ecr: 0.0297 mean_entropies: 0.6454, took: 94.7263s
2022-10-10 17:38:46,081 [INFO] 	Process 4 - batch 61799: mean_policy_losses: 140.526, mean_net_lifetime: 4667.8330, mean_mc_travel_dist: 1409.7963, mean_rewards: 280.8791, total_rewards: 3290.1205, mean_steps: 15.6000, mean_ecr: 0.0473 mean_entropies: 0.5274, took: 80.4288s
2022-10-10 17:39:02,782 [INFO] 	Process 1 - batch 49199: mean_policy_losses: 38.735, mean_net_lifetime: 5456.0168, mean_mc_travel_dist: 1933.4021, mean_rewards: 252.3078, total_rewards: 3552.9851, mean_steps: 20.8200, mean_ecr: 0.0386 mean_entropies: 0.8965, took: 102.1841s
2022-10-10 17:39:19,540 [INFO] 	Process 2 - batch 55899: mean_policy_losses: -38.603, mean_net_lifetime: 4814.1837, mean_mc_travel_dist: 1350.9518, mean_rewards: 278.5607, total_rewards: 3487.7181, mean_steps: 16.3800, mean_ecr: 0.0404 mean_entropies: 0.5057, took: 86.7265s
2022-10-10 17:39:21,173 [INFO] 	Process 6 - batch 78099: mean_policy_losses: -34.314, mean_net_lifetime: 3741.8565, mean_mc_travel_dist: 985.6486, mean_rewards: 314.4455, total_rewards: 2773.8068, mean_steps: 10.9800, mean_ecr: 0.0557 mean_entropies: 0.1516, took: 604.1013s
2022-10-10 17:39:25,966 [INFO] 	Process 3 - batch 57299: mean_policy_losses: 31.077, mean_net_lifetime: 4478.0651, mean_mc_travel_dist: 1225.6856, mean_rewards: 271.5357, total_rewards: 3283.0594, mean_steps: 15.5400, mean_ecr: 0.0486 mean_entropies: 0.4791, took: 80.6341s
2022-10-10 17:39:38,448 [INFO] 	Process 7 - batch 55999: mean_policy_losses: -658.890, mean_net_lifetime: 3657.1030, mean_mc_travel_dist: 1299.8799, mean_rewards: 228.7798, total_rewards: 2393.5400, mean_steps: 15.7800, mean_ecr: 0.0416 mean_entropies: 1.1677, took: 79.9398s
2022-10-10 17:40:10,394 [INFO] 	Process 4 - batch 61899: mean_policy_losses: 126.626, mean_net_lifetime: 4920.9804, mean_mc_travel_dist: 1389.1524, mean_rewards: 291.9046, total_rewards: 3564.9581, mean_steps: 15.9000, mean_ecr: 0.0469 mean_entropies: 0.5566, took: 84.3132s
2022-10-10 17:40:20,320 [INFO] 	Process 6 - batch 78199: mean_policy_losses: -106.299, mean_net_lifetime: 3666.8004, mean_mc_travel_dist: 974.8318, mean_rewards: 311.5302, total_rewards: 2718.0758, mean_steps: 10.8200, mean_ecr: 0.0558 mean_entropies: 0.1553, took: 59.1472s
2022-10-10 17:40:23,183 [INFO] 	Process 5 - batch 55499: mean_policy_losses: -153.668, mean_net_lifetime: 5835.9206, mean_mc_travel_dist: 2002.8670, mean_rewards: 265.7147, total_rewards: 3870.9687, mean_steps: 21.3400, mean_ecr: 0.0298 mean_entropies: 0.6414, took: 109.0367s
2022-10-10 17:40:43,279 [INFO] 	Process 2 - batch 55999: mean_policy_losses: -28.543, mean_net_lifetime: 4809.3173, mean_mc_travel_dist: 1341.8178, mean_rewards: 279.8094, total_rewards: 3497.5197, mean_steps: 16.2700, mean_ecr: 0.0405 mean_entropies: 0.5101, took: 83.7391s
2022-10-10 17:40:44,471 [INFO] 	Process 1 - batch 49299: mean_policy_losses: -2.694, mean_net_lifetime: 5568.5965, mean_mc_travel_dist: 1921.9417, mean_rewards: 257.2681, total_rewards: 3677.8535, mean_steps: 20.7400, mean_ecr: 0.0387 mean_entropies: 0.8714, took: 101.6886s
2022-10-10 17:40:45,970 [INFO] 	Process 3 - batch 57399: mean_policy_losses: 26.989, mean_net_lifetime: 4475.6179, mean_mc_travel_dist: 1236.5162, mean_rewards: 275.3013, total_rewards: 3273.1979, mean_steps: 15.3000, mean_ecr: 0.0485 mean_entropies: 0.4846, took: 80.0041s
2022-10-10 17:41:02,331 [INFO] 	Process 7 - batch 56099: mean_policy_losses: -588.751, mean_net_lifetime: 3949.5749, mean_mc_travel_dist: 1362.2920, mean_rewards: 226.5293, total_rewards: 2631.9296, mean_steps: 16.7100, mean_ecr: 0.0414 mean_entropies: 1.1314, took: 83.8824s
2022-10-10 17:41:15,837 [INFO] 	Process 6 - batch 78299: mean_policy_losses: -129.802, mean_net_lifetime: 3581.5410, mean_mc_travel_dist: 957.4679, mean_rewards: 321.4213, total_rewards: 2644.0380, mean_steps: 10.2100, mean_ecr: 0.0558 mean_entropies: 0.1682, took: 55.5169s
2022-10-10 17:41:34,495 [INFO] 	Process 4 - batch 61999: mean_policy_losses: 109.344, mean_net_lifetime: 5012.6228, mean_mc_travel_dist: 1456.0249, mean_rewards: 287.2084, total_rewards: 3589.9105, mean_steps: 16.5100, mean_ecr: 0.0467 mean_entropies: 0.5448, took: 84.1004s
2022-10-10 17:42:04,519 [INFO] 	Process 2 - batch 56099: mean_policy_losses: -37.394, mean_net_lifetime: 4782.5473, mean_mc_travel_dist: 1334.5161, mean_rewards: 278.8013, total_rewards: 3478.7642, mean_steps: 16.2200, mean_ecr: 0.0405 mean_entropies: 0.4985, took: 81.2406s
2022-10-10 17:42:05,612 [INFO] 	Process 3 - batch 57499: mean_policy_losses: 34.077, mean_net_lifetime: 4520.8323, mean_mc_travel_dist: 1220.4486, mean_rewards: 275.5724, total_rewards: 3323.3100, mean_steps: 15.4500, mean_ecr: 0.0485 mean_entropies: 0.4609, took: 79.6417s
2022-10-10 17:42:16,197 [INFO] 	Process 6 - batch 78399: mean_policy_losses: -48.908, mean_net_lifetime: 3817.4813, mean_mc_travel_dist: 1015.1461, mean_rewards: 314.8450, total_rewards: 2831.4090, mean_steps: 11.1400, mean_ecr: 0.0557 mean_entropies: 0.1442, took: 60.3602s
2022-10-10 17:42:23,247 [INFO] 	Process 7 - batch 56199: mean_policy_losses: -668.882, mean_net_lifetime: 3978.6859, mean_mc_travel_dist: 1380.3167, mean_rewards: 234.3905, total_rewards: 2642.4104, mean_steps: 16.2200, mean_ecr: 0.0416 mean_entropies: 1.1770, took: 80.9161s
2022-10-10 17:42:25,668 [INFO] 	Process 1 - batch 49399: mean_policy_losses: -39.065, mean_net_lifetime: 5341.3766, mean_mc_travel_dist: 1923.8359, mean_rewards: 248.8616, total_rewards: 3443.2322, mean_steps: 20.7800, mean_ecr: 0.0386 mean_entropies: 0.8355, took: 101.1964s
2022-10-10 17:42:59,383 [INFO] 	Process 4 - batch 62099: mean_policy_losses: 91.894, mean_net_lifetime: 5038.1600, mean_mc_travel_dist: 1428.3339, mean_rewards: 291.5610, total_rewards: 3631.2832, mean_steps: 16.3700, mean_ecr: 0.0469 mean_entropies: 0.5474, took: 84.8881s
2022-10-10 17:43:15,735 [INFO] 	Process 6 - batch 78499: mean_policy_losses: -112.011, mean_net_lifetime: 3698.8331, mean_mc_travel_dist: 986.4714, mean_rewards: 319.0287, total_rewards: 2734.4917, mean_steps: 10.6500, mean_ecr: 0.0557 mean_entropies: 0.1600, took: 59.5377s
2022-10-10 17:43:29,183 [INFO] 	Process 2 - batch 56199: mean_policy_losses: -36.321, mean_net_lifetime: 4738.2907, mean_mc_travel_dist: 1317.6767, mean_rewards: 279.1017, total_rewards: 3446.4312, mean_steps: 16.0500, mean_ecr: 0.0406 mean_entropies: 0.4814, took: 84.6635s
2022-10-10 17:43:30,193 [INFO] 	Process 3 - batch 57599: mean_policy_losses: 25.753, mean_net_lifetime: 4595.3336, mean_mc_travel_dist: 1253.3544, mean_rewards: 272.1624, total_rewards: 3377.2645, mean_steps: 15.9400, mean_ecr: 0.0484 mean_entropies: 0.4540, took: 84.5817s
2022-10-10 17:43:55,147 [INFO] 	Process 7 - batch 56299: mean_policy_losses: -546.448, mean_net_lifetime: 4429.6982, mean_mc_travel_dist: 1546.6359, mean_rewards: 232.5274, total_rewards: 2924.8552, mean_steps: 18.3000, mean_ecr: 0.0410 mean_entropies: 1.2055, took: 91.9000s
2022-10-10 17:44:13,300 [INFO] 	Process 1 - batch 49499: mean_policy_losses: -1.681, mean_net_lifetime: 5462.0494, mean_mc_travel_dist: 1910.1332, mean_rewards: 245.8315, total_rewards: 3572.6768, mean_steps: 21.4600, mean_ecr: 0.0385 mean_entropies: 0.8654, took: 107.6318s
2022-10-10 17:44:17,157 [INFO] 	Process 6 - batch 78599: mean_policy_losses: -97.434, mean_net_lifetime: 3716.1250, mean_mc_travel_dist: 993.0303, mean_rewards: 313.4148, total_rewards: 2749.6550, mean_steps: 10.9000, mean_ecr: 0.0557 mean_entropies: 0.1614, took: 61.4226s
2022-10-10 17:44:24,657 [INFO] 	Process 4 - batch 62199: mean_policy_losses: 93.665, mean_net_lifetime: 5108.2411, mean_mc_travel_dist: 1477.4911, mean_rewards: 296.4388, total_rewards: 3658.4662, mean_steps: 16.4100, mean_ecr: 0.0466 mean_entropies: 0.5328, took: 85.2732s
2022-10-10 17:44:51,585 [INFO] 	Process 3 - batch 57699: mean_policy_losses: 25.937, mean_net_lifetime: 4512.1771, mean_mc_travel_dist: 1218.1986, mean_rewards: 273.3065, total_rewards: 3321.5558, mean_steps: 15.5600, mean_ecr: 0.0484 mean_entropies: 0.4533, took: 81.3918s
2022-10-10 17:44:52,264 [INFO] 	Process 2 - batch 56299: mean_policy_losses: -20.346, mean_net_lifetime: 4792.5329, mean_mc_travel_dist: 1318.2120, mean_rewards: 279.0342, total_rewards: 3498.4284, mean_steps: 16.2800, mean_ecr: 0.0406 mean_entropies: 0.4659, took: 83.0809s
2022-10-10 17:45:08,187 [INFO] 	Process 7 - batch 56399: mean_policy_losses: -757.664, mean_net_lifetime: 3788.6338, mean_mc_travel_dist: 1316.2950, mean_rewards: 244.2076, total_rewards: 2516.7145, mean_steps: 14.9400, mean_ecr: 0.0416 mean_entropies: 1.2138, took: 73.0404s
2022-10-10 17:45:17,406 [INFO] 	Process 6 - batch 78699: mean_policy_losses: -79.774, mean_net_lifetime: 3787.5710, mean_mc_travel_dist: 1008.2925, mean_rewards: 316.2883, total_rewards: 2806.5144, mean_steps: 11.0400, mean_ecr: 0.0556 mean_entropies: 0.1510, took: 60.2477s
2022-10-10 17:45:45,326 [INFO] 	Process 4 - batch 62299: mean_policy_losses: 71.781, mean_net_lifetime: 5033.0672, mean_mc_travel_dist: 1447.7666, mean_rewards: 297.0221, total_rewards: 3608.2523, mean_steps: 16.0200, mean_ecr: 0.0467 mean_entropies: 0.5445, took: 80.6692s
2022-10-10 17:46:11,502 [INFO] 	Process 3 - batch 57799: mean_policy_losses: 34.516, mean_net_lifetime: 4627.6140, mean_mc_travel_dist: 1240.4549, mean_rewards: 279.3904, total_rewards: 3411.0533, mean_steps: 15.6200, mean_ecr: 0.0484 mean_entropies: 0.4523, took: 79.9166s
2022-10-10 17:46:13,481 [INFO] 	Process 2 - batch 56399: mean_policy_losses: -23.467, mean_net_lifetime: 4758.2828, mean_mc_travel_dist: 1290.5420, mean_rewards: 282.9716, total_rewards: 3491.7949, mean_steps: 15.8800, mean_ecr: 0.0407 mean_entropies: 0.4630, took: 81.2175s
2022-10-10 17:46:17,841 [INFO] 	Process 6 - batch 78799: mean_policy_losses: -86.828, mean_net_lifetime: 3790.3701, mean_mc_travel_dist: 1008.2205, mean_rewards: 314.2041, total_rewards: 2811.6419, mean_steps: 11.1000, mean_ecr: 0.0556 mean_entropies: 0.1465, took: 60.4364s
2022-10-10 17:46:23,877 [INFO] 	Process 7 - batch 56499: mean_policy_losses: -769.397, mean_net_lifetime: 3863.6398, mean_mc_travel_dist: 1352.1185, mean_rewards: 240.0990, total_rewards: 2553.5390, mean_steps: 15.7700, mean_ecr: 0.0413 mean_entropies: 1.1843, took: 75.6898s
2022-10-10 17:47:07,365 [INFO] 	Process 4 - batch 62399: mean_policy_losses: 68.794, mean_net_lifetime: 5046.0964, mean_mc_travel_dist: 1461.6017, mean_rewards: 291.6032, total_rewards: 3618.6710, mean_steps: 16.3500, mean_ecr: 0.0467 mean_entropies: 0.5373, took: 82.0390s
2022-10-10 17:47:18,404 [INFO] 	Process 6 - batch 78899: mean_policy_losses: -52.684, mean_net_lifetime: 3823.2460, mean_mc_travel_dist: 1006.6981, mean_rewards: 311.1057, total_rewards: 2845.9040, mean_steps: 11.3000, mean_ecr: 0.0557 mean_entropies: 0.1327, took: 60.5624s
2022-10-10 17:47:30,929 [INFO] 	Process 3 - batch 57899: mean_policy_losses: 26.096, mean_net_lifetime: 4574.2801, mean_mc_travel_dist: 1257.3722, mean_rewards: 278.2259, total_rewards: 3342.4606, mean_steps: 15.4800, mean_ecr: 0.0485 mean_entropies: 0.4956, took: 79.4257s
2022-10-10 17:47:31,735 [INFO] 	Process 7 - batch 56599: mean_policy_losses: -831.893, mean_net_lifetime: 3630.6309, mean_mc_travel_dist: 1311.4031, mean_rewards: 249.2048, total_rewards: 2363.4242, mean_steps: 13.7200, mean_ecr: 0.0416 mean_entropies: 1.1549, took: 67.8578s
2022-10-10 17:47:33,061 [INFO] 	Process 2 - batch 56499: mean_policy_losses: -26.476, mean_net_lifetime: 4746.8838, mean_mc_travel_dist: 1290.6553, mean_rewards: 279.3402, total_rewards: 3476.6239, mean_steps: 16.0600, mean_ecr: 0.0407 mean_entropies: 0.4795, took: 79.5800s
2022-10-10 17:48:17,583 [INFO] 	Process 6 - batch 78999: mean_policy_losses: -117.613, mean_net_lifetime: 3726.3567, mean_mc_travel_dist: 975.5690, mean_rewards: 312.0172, total_rewards: 2772.6138, mean_steps: 10.9900, mean_ecr: 0.0557 mean_entropies: 0.1271, took: 59.1787s
2022-10-10 17:48:26,795 [INFO] 	Process 4 - batch 62499: mean_policy_losses: 58.232, mean_net_lifetime: 4903.9460, mean_mc_travel_dist: 1431.8830, mean_rewards: 299.6673, total_rewards: 3500.9837, mean_steps: 15.4400, mean_ecr: 0.0471 mean_entropies: 0.5226, took: 79.4309s
2022-10-10 17:48:39,027 [INFO] 	Process 7 - batch 56699: mean_policy_losses: -843.069, mean_net_lifetime: 3537.6554, mean_mc_travel_dist: 1280.5371, mean_rewards: 253.1822, total_rewards: 2300.8728, mean_steps: 13.4800, mean_ecr: 0.0417 mean_entropies: 1.1043, took: 67.2928s
2022-10-10 17:48:50,283 [INFO] 	Process 3 - batch 57999: mean_policy_losses: 27.132, mean_net_lifetime: 4487.1811, mean_mc_travel_dist: 1219.5375, mean_rewards: 273.0133, total_rewards: 3290.0838, mean_steps: 15.4900, mean_ecr: 0.0485 mean_entropies: 0.4655, took: 79.3553s
2022-10-10 17:48:52,131 [INFO] 	Process 2 - batch 56599: mean_policy_losses: -16.175, mean_net_lifetime: 4746.8707, mean_mc_travel_dist: 1303.9807, mean_rewards: 276.9261, total_rewards: 3467.2200, mean_steps: 16.2100, mean_ecr: 0.0406 mean_entropies: 0.4606, took: 79.0701s
2022-10-10 17:49:18,800 [INFO] 	Process 6 - batch 79099: mean_policy_losses: -98.453, mean_net_lifetime: 3726.9690, mean_mc_travel_dist: 986.9022, mean_rewards: 307.2807, total_rewards: 2761.7244, mean_steps: 11.2000, mean_ecr: 0.0557 mean_entropies: 0.1485, took: 61.2162s
2022-10-10 17:49:28,535 [INFO] Process 5 - epoch 37: mean_policy_losses: -217.503, mean_net_lifetime: 4543.9758, mean_mc_travel_dist: 1894.8318, mean_entropies: 1.3255, m_net_lifetime_valid: 4389.7288, took: 1877.9054s, (154.7273 / 100 batches)

2022-10-10 17:49:48,013 [INFO] 	Process 4 - batch 62599: mean_policy_losses: 62.795, mean_net_lifetime: 4934.0963, mean_mc_travel_dist: 1422.5408, mean_rewards: 292.3821, total_rewards: 3539.9851, mean_steps: 15.9800, mean_ecr: 0.0471 mean_entropies: 0.5139, took: 81.2177s
2022-10-10 17:49:50,484 [INFO] 	Process 7 - batch 56799: mean_policy_losses: -818.737, mean_net_lifetime: 3679.6228, mean_mc_travel_dist: 1315.3709, mean_rewards: 242.7458, total_rewards: 2410.3383, mean_steps: 14.5200, mean_ecr: 0.0418 mean_entropies: 1.1977, took: 71.4568s
2022-10-10 17:50:15,203 [INFO] 	Process 3 - batch 58099: mean_policy_losses: 20.581, mean_net_lifetime: 4542.9610, mean_mc_travel_dist: 1264.4000, mean_rewards: 264.6773, total_rewards: 3309.7072, mean_steps: 16.2400, mean_ecr: 0.0483 mean_entropies: 0.4663, took: 84.9199s
2022-10-10 17:50:16,666 [INFO] 	Process 2 - batch 56699: mean_policy_losses: -3.461, mean_net_lifetime: 4923.0502, mean_mc_travel_dist: 1362.1051, mean_rewards: 280.7078, total_rewards: 3585.8937, mean_steps: 16.6700, mean_ecr: 0.0405 mean_entropies: 0.4930, took: 84.5346s
2022-10-10 17:50:18,549 [INFO] 	Process 6 - batch 79199: mean_policy_losses: -128.505, mean_net_lifetime: 3641.7977, mean_mc_travel_dist: 961.3647, mean_rewards: 318.9082, total_rewards: 2703.5559, mean_steps: 10.4600, mean_ecr: 0.0559 mean_entropies: 0.1419, took: 59.7500s
2022-10-10 17:51:14,359 [INFO] 	Process 7 - batch 56899: mean_policy_losses: -627.707, mean_net_lifetime: 3962.0186, mean_mc_travel_dist: 1373.5073, mean_rewards: 229.1755, total_rewards: 2628.2071, mean_steps: 16.6800, mean_ecr: 0.0415 mean_entropies: 1.1307, took: 83.8742s
2022-10-10 17:51:14,436 [INFO] 	Process 4 - batch 62699: mean_policy_losses: 43.463, mean_net_lifetime: 4941.7211, mean_mc_travel_dist: 1407.8846, mean_rewards: 285.0585, total_rewards: 3563.1079, mean_steps: 16.3800, mean_ecr: 0.0468 mean_entropies: 0.5741, took: 86.4234s
2022-10-10 17:51:16,366 [INFO] 	Process 5 - batch 55599: mean_policy_losses: -102.439, mean_net_lifetime: 5696.8836, mean_mc_travel_dist: 1985.0677, mean_rewards: 257.6850, total_rewards: 3765.6319, mean_steps: 21.2700, mean_ecr: 0.0301 mean_entropies: 0.5825, took: 653.1823s
2022-10-10 17:51:19,696 [INFO] 	Process 6 - batch 79299: mean_policy_losses: -42.295, mean_net_lifetime: 3820.6356, mean_mc_travel_dist: 1007.0818, mean_rewards: 319.0558, total_rewards: 2835.3345, mean_steps: 11.0200, mean_ecr: 0.0556 mean_entropies: 0.1402, took: 61.1476s
2022-10-10 17:51:38,504 [INFO] 	Process 3 - batch 58199: mean_policy_losses: 33.229, mean_net_lifetime: 4562.1643, mean_mc_travel_dist: 1247.0528, mean_rewards: 273.5388, total_rewards: 3344.5067, mean_steps: 15.7300, mean_ecr: 0.0483 mean_entropies: 0.4588, took: 83.3016s
2022-10-10 17:51:41,479 [INFO] 	Process 2 - batch 56799: mean_policy_losses: -11.826, mean_net_lifetime: 4761.6962, mean_mc_travel_dist: 1317.2265, mean_rewards: 279.2680, total_rewards: 3471.8171, mean_steps: 16.1200, mean_ecr: 0.0406 mean_entropies: 0.4462, took: 84.8122s
2022-10-10 17:52:17,518 [INFO] 	Process 6 - batch 79399: mean_policy_losses: -74.076, mean_net_lifetime: 3613.4397, mean_mc_travel_dist: 957.2857, mean_rewards: 322.9462, total_rewards: 2686.3732, mean_steps: 10.2200, mean_ecr: 0.0557 mean_entropies: 0.1624, took: 57.8213s
2022-10-10 17:52:31,060 [INFO] 	Process 7 - batch 56999: mean_policy_losses: -756.052, mean_net_lifetime: 3803.6961, mean_mc_travel_dist: 1372.4073, mean_rewards: 240.5796, total_rewards: 2481.2117, mean_steps: 15.1700, mean_ecr: 0.0416 mean_entropies: 1.2087, took: 76.7017s
2022-10-10 17:52:38,573 [INFO] 	Process 4 - batch 62799: mean_policy_losses: 86.498, mean_net_lifetime: 5066.1700, mean_mc_travel_dist: 1442.1270, mean_rewards: 294.8139, total_rewards: 3654.3825, mean_steps: 16.2600, mean_ecr: 0.0467 mean_entropies: 0.5432, took: 84.1368s
2022-10-10 17:52:49,071 [INFO] 	Process 5 - batch 55699: mean_policy_losses: -303.139, mean_net_lifetime: 4819.1581, mean_mc_travel_dist: 1657.4009, mean_rewards: 266.5693, total_rewards: 3216.7332, mean_steps: 18.0500, mean_ecr: 0.0300 mean_entropies: 0.5819, took: 92.7068s
2022-10-10 17:52:58,262 [INFO] 	Process 3 - batch 58299: mean_policy_losses: 21.496, mean_net_lifetime: 4492.4158, mean_mc_travel_dist: 1241.5083, mean_rewards: 278.4327, total_rewards: 3284.7925, mean_steps: 15.1700, mean_ecr: 0.0484 mean_entropies: 0.4788, took: 79.7570s
2022-10-10 17:53:01,053 [INFO] 	Process 2 - batch 56899: mean_policy_losses: -2.547, mean_net_lifetime: 4802.1488, mean_mc_travel_dist: 1322.3476, mean_rewards: 287.1010, total_rewards: 3510.4434, mean_steps: 15.8200, mean_ecr: 0.0406 mean_entropies: 0.4956, took: 79.5747s
2022-10-10 17:53:16,649 [INFO] 	Process 6 - batch 79499: mean_policy_losses: -64.180, mean_net_lifetime: 3745.6767, mean_mc_travel_dist: 990.4449, mean_rewards: 316.7635, total_rewards: 2787.4033, mean_steps: 10.8700, mean_ecr: 0.0557 mean_entropies: 0.1647, took: 59.1318s
2022-10-10 17:53:57,070 [INFO] Process 1 - epoch 33: mean_policy_losses: 40.367, mean_net_lifetime: 4872.7488, mean_mc_travel_dist: 2038.2134, mean_entropies: 1.2719, m_net_lifetime_valid: 4697.7394, took: 1978.1363s, (173.9083 / 100 batches)

2022-10-10 17:53:57,187 [INFO] 	Process 4 - batch 62899: mean_policy_losses: 45.277, mean_net_lifetime: 4890.5146, mean_mc_travel_dist: 1393.8776, mean_rewards: 293.5913, total_rewards: 3520.7258, mean_steps: 15.7400, mean_ecr: 0.0474 mean_entropies: 0.5508, took: 78.6126s
2022-10-10 17:54:10,635 [INFO] 	Process 5 - batch 55799: mean_policy_losses: -308.968, mean_net_lifetime: 4637.7380, mean_mc_travel_dist: 1555.7420, mean_rewards: 278.8541, total_rewards: 3132.3636, mean_steps: 16.4900, mean_ecr: 0.0304 mean_entropies: 0.5950, took: 81.5634s
2022-10-10 17:54:16,572 [INFO] 	Process 3 - batch 58399: mean_policy_losses: 14.263, mean_net_lifetime: 4527.4837, mean_mc_travel_dist: 1253.7233, mean_rewards: 277.2836, total_rewards: 3303.8937, mean_steps: 15.4100, mean_ecr: 0.0486 mean_entropies: 0.4837, took: 78.3098s
2022-10-10 17:54:18,943 [INFO] 	Process 2 - batch 56999: mean_policy_losses: -27.351, mean_net_lifetime: 4736.9748, mean_mc_travel_dist: 1288.3098, mean_rewards: 281.4690, total_rewards: 3471.0010, mean_steps: 15.8800, mean_ecr: 0.0407 mean_entropies: 0.4744, took: 77.8897s
2022-10-10 17:55:13,610 [INFO] 	Process 4 - batch 62999: mean_policy_losses: -0.780, mean_net_lifetime: 4637.3762, mean_mc_travel_dist: 1296.0000, mean_rewards: 287.8392, total_rewards: 3373.0456, mean_steps: 15.1600, mean_ecr: 0.0481 mean_entropies: 0.6079, took: 76.4245s
2022-10-10 17:55:32,191 [INFO] 	Process 3 - batch 58499: mean_policy_losses: 12.009, mean_net_lifetime: 4394.8469, mean_mc_travel_dist: 1236.9312, mean_rewards: 270.9759, total_rewards: 3183.1058, mean_steps: 15.2900, mean_ecr: 0.0486 mean_entropies: 0.5312, took: 75.6188s
2022-10-10 17:55:34,101 [INFO] 	Process 5 - batch 55899: mean_policy_losses: -263.344, mean_net_lifetime: 4877.7341, mean_mc_travel_dist: 1656.6833, mean_rewards: 274.7460, total_rewards: 3281.8767, mean_steps: 17.4500, mean_ecr: 0.0303 mean_entropies: 0.6129, took: 83.4664s
2022-10-10 17:55:34,917 [INFO] 	Process 1 - batch 49599: mean_policy_losses: 0.005, mean_net_lifetime: 5501.6793, mean_mc_travel_dist: 1903.1471, mean_rewards: 252.1735, total_rewards: 3626.6463, mean_steps: 20.9500, mean_ecr: 0.0388 mean_entropies: 0.9127, took: 681.6177s
2022-10-10 17:57:00,218 [INFO] 	Process 5 - batch 55999: mean_policy_losses: -157.211, mean_net_lifetime: 5519.8826, mean_mc_travel_dist: 1911.8677, mean_rewards: 287.8930, total_rewards: 3646.0318, mean_steps: 19.0500, mean_ecr: 0.0303 mean_entropies: 0.5918, took: 86.1166s
2022-10-10 17:57:09,243 [INFO] 	Process 1 - batch 49699: mean_policy_losses: 56.550, mean_net_lifetime: 5636.1886, mean_mc_travel_dist: 1951.4001, mean_rewards: 252.2200, total_rewards: 3710.7889, mean_steps: 21.5700, mean_ecr: 0.0386 mean_entropies: 0.9172, took: 94.3253s
2022-10-10 17:58:29,817 [INFO] 	Process 5 - batch 56099: mean_policy_losses: -64.926, mean_net_lifetime: 6020.5252, mean_mc_travel_dist: 2090.2216, mean_rewards: 290.5356, total_rewards: 3975.3528, mean_steps: 20.1700, mean_ecr: 0.0302 mean_entropies: 0.6501, took: 89.5982s
2022-10-10 17:58:48,179 [INFO] 	Process 1 - batch 49799: mean_policy_losses: 89.122, mean_net_lifetime: 5779.5588, mean_mc_travel_dist: 1950.4614, mean_rewards: 243.7569, total_rewards: 3859.6191, mean_steps: 22.9700, mean_ecr: 0.0387 mean_entropies: 0.9391, took: 98.9366s
2022-10-10 17:59:57,918 [INFO] 	Process 5 - batch 56199: mean_policy_losses: -156.929, mean_net_lifetime: 6024.8923, mean_mc_travel_dist: 2087.6162, mean_rewards: 291.4026, total_rewards: 3984.3304, mean_steps: 20.1000, mean_ecr: 0.0304 mean_entropies: 0.6494, took: 88.1013s
2022-10-10 18:00:20,988 [INFO] 	Process 1 - batch 49899: mean_policy_losses: 24.674, mean_net_lifetime: 5673.3276, mean_mc_travel_dist: 1987.9679, mean_rewards: 257.7464, total_rewards: 3721.3321, mean_steps: 21.1200, mean_ecr: 0.0387 mean_entropies: 0.9595, took: 92.8089s
2022-10-10 18:01:23,162 [INFO] 	Process 5 - batch 56299: mean_policy_losses: -203.227, mean_net_lifetime: 5749.5088, mean_mc_travel_dist: 2020.5945, mean_rewards: 290.3694, total_rewards: 3781.5609, mean_steps: 19.0700, mean_ecr: 0.0307 mean_entropies: 0.6449, took: 85.2443s
2022-10-10 18:01:54,381 [INFO] 	Process 1 - batch 49999: mean_policy_losses: 5.469, mean_net_lifetime: 5652.9769, mean_mc_travel_dist: 2051.0331, mean_rewards: 255.7539, total_rewards: 3635.7532, mean_steps: 21.1800, mean_ecr: 0.0386 mean_entropies: 0.9507, took: 93.3933s
2022-10-10 18:02:31,510 [INFO] Process 7 - epoch 38: mean_policy_losses: -315.084, mean_net_lifetime: 3983.4877, mean_mc_travel_dist: 1574.8808, mean_entropies: 1.6564, m_net_lifetime_valid: 4736.9984, took: 1737.4887s, (151.9373 / 100 batches)

2022-10-10 18:02:50,530 [INFO] 	Process 5 - batch 56399: mean_policy_losses: -191.817, mean_net_lifetime: 5652.6910, mean_mc_travel_dist: 1990.2889, mean_rewards: 283.9081, total_rewards: 3709.3798, mean_steps: 19.1300, mean_ecr: 0.0308 mean_entropies: 0.6672, took: 87.3666s
2022-10-10 18:03:11,904 [INFO] Process 4 - epoch 42: mean_policy_losses: 87.747, mean_net_lifetime: 3972.1439, mean_mc_travel_dist: 1315.4193, mean_entropies: 1.2547, m_net_lifetime_valid: 4459.1959, took: 1704.3874s, (137.7475 / 100 batches)

2022-10-10 18:03:20,952 [INFO] Process 6 - epoch 53: mean_policy_losses: -236.518, mean_net_lifetime: 2850.1386, mean_mc_travel_dist: 950.6415, mean_entropies: 0.7053, m_net_lifetime_valid: 4970.2919, took: 1501.1264s, (109.0469 / 100 batches)

2022-10-10 18:03:33,665 [INFO] 	Process 1 - batch 50099: mean_policy_losses: 163.808, mean_net_lifetime: 5847.1189, mean_mc_travel_dist: 2063.8819, mean_rewards: 254.5780, total_rewards: 3810.9583, mean_steps: 22.0600, mean_ecr: 0.0385 mean_entropies: 0.9461, took: 99.2829s
2022-10-10 18:03:35,509 [INFO] Process 2 - epoch 38: mean_policy_losses: 4.011, mean_net_lifetime: 4341.1968, mean_mc_travel_dist: 1546.8091, mean_entropies: 1.0332, m_net_lifetime_valid: 4509.2426, took: 1779.8153s, (152.1265 / 100 batches)

2022-10-10 18:03:44,830 [INFO] 	Process 7 - batch 57099: mean_policy_losses: -331.083, mean_net_lifetime: 3403.9824, mean_mc_travel_dist: 1154.2819, mean_rewards: 206.3435, total_rewards: 2301.7803, mean_steps: 15.3900, mean_ecr: 0.0421 mean_entropies: 1.1728, took: 673.7694s
2022-10-10 18:04:03,238 [INFO] 	Process 6 - batch 79599: mean_policy_losses: -270.885, mean_net_lifetime: 2524.0820, mean_mc_travel_dist: 680.6057, mean_rewards: 312.4774, total_rewards: 1871.4608, mean_steps: 6.9600, mean_ecr: 0.0562 mean_entropies: 0.3275, took: 646.5879s
2022-10-10 18:04:03,693 [INFO] Process 3 - epoch 39: mean_policy_losses: 77.937, mean_net_lifetime: 4184.3634, mean_mc_travel_dist: 1377.7236, mean_entropies: 1.0098, m_net_lifetime_valid: 4191.8958, took: 1713.6228s, (148.3562 / 100 batches)

2022-10-10 18:04:21,129 [INFO] 	Process 4 - batch 63099: mean_policy_losses: 119.681, mean_net_lifetime: 3002.8094, mean_mc_travel_dist: 990.3522, mean_rewards: 215.9714, total_rewards: 2045.4573, mean_steps: 12.8200, mean_ecr: 0.0510 mean_entropies: 0.7445, took: 547.5188s
2022-10-10 18:04:23,845 [INFO] 	Process 5 - batch 56499: mean_policy_losses: -88.659, mean_net_lifetime: 5603.6702, mean_mc_travel_dist: 1940.7091, mean_rewards: 291.1871, total_rewards: 3721.3528, mean_steps: 18.7400, mean_ecr: 0.0304 mean_entropies: 0.6241, took: 93.3160s
2022-10-10 18:05:02,628 [INFO] 	Process 2 - batch 57099: mean_policy_losses: -3.820, mean_net_lifetime: 4913.8585, mean_mc_travel_dist: 1423.6164, mean_rewards: 279.3009, total_rewards: 3519.7886, mean_steps: 16.6800, mean_ecr: 0.0401 mean_entropies: 0.5408, took: 643.6852s
2022-10-10 18:05:04,272 [INFO] 	Process 7 - batch 57199: mean_policy_losses: -569.128, mean_net_lifetime: 3583.2220, mean_mc_travel_dist: 1308.9635, mean_rewards: 223.8194, total_rewards: 2324.8406, mean_steps: 15.4500, mean_ecr: 0.0415 mean_entropies: 1.0654, took: 79.4417s
2022-10-10 18:05:06,793 [INFO] 	Process 6 - batch 79699: mean_policy_losses: -159.181, mean_net_lifetime: 3699.8832, mean_mc_travel_dist: 979.7540, mean_rewards: 314.6601, total_rewards: 2748.1245, mean_steps: 10.8100, mean_ecr: 0.0556 mean_entropies: 0.1451, took: 63.5556s
2022-10-10 18:05:18,126 [INFO] 	Process 1 - batch 50199: mean_policy_losses: 21.900, mean_net_lifetime: 5366.7306, mean_mc_travel_dist: 1943.5748, mean_rewards: 256.6532, total_rewards: 3445.4995, mean_steps: 20.1900, mean_ecr: 0.0385 mean_entropies: 0.7848, took: 104.4613s
2022-10-10 18:05:30,561 [INFO] 	Process 3 - batch 58599: mean_policy_losses: 5.136, mean_net_lifetime: 4438.3142, mean_mc_travel_dist: 1203.2698, mean_rewards: 263.9732, total_rewards: 3260.4539, mean_steps: 15.8600, mean_ecr: 0.0486 mean_entropies: 0.4498, took: 598.3710s
2022-10-10 18:05:51,400 [INFO] 	Process 4 - batch 63199: mean_policy_losses: 128.435, mean_net_lifetime: 4836.9516, mean_mc_travel_dist: 1424.5042, mean_rewards: 274.7525, total_rewards: 3436.1910, mean_steps: 16.7100, mean_ecr: 0.0474 mean_entropies: 0.5940, took: 90.2707s
2022-10-10 18:06:11,707 [INFO] 	Process 6 - batch 79799: mean_policy_losses: -81.082, mean_net_lifetime: 3788.4391, mean_mc_travel_dist: 1004.7997, mean_rewards: 314.1467, total_rewards: 2816.3775, mean_steps: 11.1200, mean_ecr: 0.0556 mean_entropies: 0.1430, took: 64.9136s
2022-10-10 18:06:17,023 [INFO] 	Process 5 - batch 56599: mean_policy_losses: -159.260, mean_net_lifetime: 5837.0850, mean_mc_travel_dist: 2056.3243, mean_rewards: 263.9215, total_rewards: 3823.8396, mean_steps: 21.4500, mean_ecr: 0.0297 mean_entropies: 0.5675, took: 113.1777s
2022-10-10 18:06:29,085 [INFO] 	Process 2 - batch 57199: mean_policy_losses: -19.655, mean_net_lifetime: 4798.5026, mean_mc_travel_dist: 1328.4804, mean_rewards: 278.6263, total_rewards: 3496.6904, mean_steps: 16.3000, mean_ecr: 0.0406 mean_entropies: 0.4828, took: 86.4571s
2022-10-10 18:06:32,287 [INFO] 	Process 7 - batch 57299: mean_policy_losses: -613.868, mean_net_lifetime: 3982.5779, mean_mc_travel_dist: 1417.3142, mean_rewards: 224.2741, total_rewards: 2615.4441, mean_steps: 17.2800, mean_ecr: 0.0412 mean_entropies: 1.0812, took: 88.0160s
2022-10-10 18:06:56,035 [INFO] 	Process 3 - batch 58699: mean_policy_losses: 40.262, mean_net_lifetime: 4512.7422, mean_mc_travel_dist: 1220.5164, mean_rewards: 274.9772, total_rewards: 3308.4595, mean_steps: 15.4500, mean_ecr: 0.0487 mean_entropies: 0.4825, took: 85.4734s
2022-10-10 18:07:03,546 [INFO] 	Process 1 - batch 50299: mean_policy_losses: -64.142, mean_net_lifetime: 5345.5692, mean_mc_travel_dist: 1920.8682, mean_rewards: 254.7247, total_rewards: 3445.2119, mean_steps: 20.1900, mean_ecr: 0.0386 mean_entropies: 0.7935, took: 105.4205s
2022-10-10 18:07:11,401 [INFO] 	Process 6 - batch 79899: mean_policy_losses: -206.456, mean_net_lifetime: 3506.1546, mean_mc_travel_dist: 930.9885, mean_rewards: 317.2786, total_rewards: 2610.4963, mean_steps: 10.1200, mean_ecr: 0.0558 mean_entropies: 0.1498, took: 59.6946s
2022-10-10 18:07:16,348 [INFO] 	Process 4 - batch 63299: mean_policy_losses: 91.441, mean_net_lifetime: 4693.7515, mean_mc_travel_dist: 1342.0181, mean_rewards: 282.0505, total_rewards: 3379.6565, mean_steps: 15.7700, mean_ecr: 0.0476 mean_entropies: 0.6082, took: 84.9480s
2022-10-10 18:07:57,444 [INFO] 	Process 2 - batch 57299: mean_policy_losses: -17.302, mean_net_lifetime: 4823.5047, mean_mc_travel_dist: 1330.3923, mean_rewards: 278.2631, total_rewards: 3524.5749, mean_steps: 16.4500, mean_ecr: 0.0406 mean_entropies: 0.4928, took: 88.3595s
2022-10-10 18:08:02,984 [INFO] 	Process 5 - batch 56699: mean_policy_losses: -227.240, mean_net_lifetime: 5620.9116, mean_mc_travel_dist: 1943.5145, mean_rewards: 272.1556, total_rewards: 3728.1954, mean_steps: 20.0200, mean_ecr: 0.0300 mean_entropies: 0.5888, took: 105.9616s
2022-10-10 18:08:04,310 [INFO] 	Process 7 - batch 57399: mean_policy_losses: -654.120, mean_net_lifetime: 4065.9879, mean_mc_travel_dist: 1372.6583, mean_rewards: 221.3705, total_rewards: 2738.0158, mean_steps: 18.0800, mean_ecr: 0.0414 mean_entropies: 1.1547, took: 92.0222s
2022-10-10 18:08:11,331 [INFO] 	Process 6 - batch 79999: mean_policy_losses: -68.181, mean_net_lifetime: 3575.5055, mean_mc_travel_dist: 944.6512, mean_rewards: 319.7045, total_rewards: 2654.7175, mean_steps: 10.1700, mean_ecr: 0.0559 mean_entropies: 0.1639, took: 59.9292s
2022-10-10 18:08:21,349 [INFO] 	Process 3 - batch 58799: mean_policy_losses: 27.164, mean_net_lifetime: 4522.6785, mean_mc_travel_dist: 1215.2044, mean_rewards: 273.7656, total_rewards: 3338.9344, mean_steps: 15.5700, mean_ecr: 0.0485 mean_entropies: 0.4452, took: 85.3149s
2022-10-10 18:08:50,650 [INFO] 	Process 4 - batch 63399: mean_policy_losses: 93.695, mean_net_lifetime: 5054.6573, mean_mc_travel_dist: 1445.6618, mean_rewards: 274.4243, total_rewards: 3640.5212, mean_steps: 17.6700, mean_ecr: 0.0467 mean_entropies: 0.5986, took: 94.3023s
2022-10-10 18:08:56,318 [INFO] 	Process 1 - batch 50399: mean_policy_losses: -23.763, mean_net_lifetime: 5416.7128, mean_mc_travel_dist: 1874.3537, mean_rewards: 240.5845, total_rewards: 3565.1103, mean_steps: 21.7600, mean_ecr: 0.0386 mean_entropies: 0.8663, took: 112.7724s
2022-10-10 18:09:13,070 [INFO] 	Process 6 - batch 80099: mean_policy_losses: -128.941, mean_net_lifetime: 3642.3224, mean_mc_travel_dist: 962.4776, mean_rewards: 318.2111, total_rewards: 2699.0898, mean_steps: 10.5100, mean_ecr: 0.0558 mean_entropies: 0.1493, took: 61.7386s
2022-10-10 18:09:26,286 [INFO] 	Process 2 - batch 57399: mean_policy_losses: -15.660, mean_net_lifetime: 4889.4476, mean_mc_travel_dist: 1335.4781, mean_rewards: 280.2349, total_rewards: 3578.9403, mean_steps: 16.5300, mean_ecr: 0.0405 mean_entropies: 0.5030, took: 88.8416s
2022-10-10 18:09:37,652 [INFO] 	Process 7 - batch 57499: mean_policy_losses: -595.514, mean_net_lifetime: 4113.6584, mean_mc_travel_dist: 1396.4523, mean_rewards: 217.4461, total_rewards: 2774.2911, mean_steps: 18.5800, mean_ecr: 0.0413 mean_entropies: 1.1170, took: 93.3426s
2022-10-10 18:09:45,197 [INFO] 	Process 5 - batch 56799: mean_policy_losses: -218.101, mean_net_lifetime: 5292.6979, mean_mc_travel_dist: 1811.0459, mean_rewards: 267.3649, total_rewards: 3541.1887, mean_steps: 19.1700, mean_ecr: 0.0304 mean_entropies: 0.5958, took: 102.2119s
2022-10-10 18:09:48,740 [INFO] 	Process 3 - batch 58899: mean_policy_losses: 23.606, mean_net_lifetime: 4480.7493, mean_mc_travel_dist: 1204.6244, mean_rewards: 265.9180, total_rewards: 3296.6351, mean_steps: 15.9000, mean_ecr: 0.0487 mean_entropies: 0.4731, took: 87.3902s
2022-10-10 18:10:13,296 [INFO] 	Process 6 - batch 80199: mean_policy_losses: -145.200, mean_net_lifetime: 3560.3870, mean_mc_travel_dist: 941.9688, mean_rewards: 312.0894, total_rewards: 2640.2137, mean_steps: 10.4200, mean_ecr: 0.0560 mean_entropies: 0.1517, took: 60.2274s
2022-10-10 18:10:20,121 [INFO] 	Process 4 - batch 63499: mean_policy_losses: 71.727, mean_net_lifetime: 4788.3689, mean_mc_travel_dist: 1349.1654, mean_rewards: 284.3146, total_rewards: 3475.9415, mean_steps: 15.9100, mean_ecr: 0.0476 mean_entropies: 0.5838, took: 89.4708s
2022-10-10 18:10:45,782 [INFO] 	Process 1 - batch 50499: mean_policy_losses: 7.423, mean_net_lifetime: 5560.7971, mean_mc_travel_dist: 1931.6457, mean_rewards: 255.9697, total_rewards: 3660.8924, mean_steps: 20.9400, mean_ecr: 0.0385 mean_entropies: 0.9011, took: 109.4637s
2022-10-10 18:10:50,490 [INFO] 	Process 7 - batch 57599: mean_policy_losses: -790.739, mean_net_lifetime: 3282.5504, mean_mc_travel_dist: 1207.4033, mean_rewards: 228.0443, total_rewards: 2129.2430, mean_steps: 13.7900, mean_ecr: 0.0420 mean_entropies: 1.0641, took: 72.8381s
2022-10-10 18:10:55,080 [INFO] 	Process 2 - batch 57499: mean_policy_losses: 3.611, mean_net_lifetime: 4991.6935, mean_mc_travel_dist: 1364.5692, mean_rewards: 285.8762, total_rewards: 3649.1306, mean_steps: 16.6100, mean_ecr: 0.0406 mean_entropies: 0.5361, took: 88.7936s
2022-10-10 18:11:11,986 [INFO] 	Process 3 - batch 58999: mean_policy_losses: 35.709, mean_net_lifetime: 4434.2036, mean_mc_travel_dist: 1215.8492, mean_rewards: 280.1036, total_rewards: 3244.5781, mean_steps: 14.8700, mean_ecr: 0.0486 mean_entropies: 0.5091, took: 83.2472s
2022-10-10 18:11:12,653 [INFO] 	Process 6 - batch 80299: mean_policy_losses: -185.337, mean_net_lifetime: 3540.0449, mean_mc_travel_dist: 942.3497, mean_rewards: 319.0218, total_rewards: 2623.9374, mean_steps: 10.1100, mean_ecr: 0.0559 mean_entropies: 0.1692, took: 59.3569s
2022-10-10 18:11:23,682 [INFO] 	Process 5 - batch 56899: mean_policy_losses: -257.102, mean_net_lifetime: 5197.6611, mean_mc_travel_dist: 1770.1412, mean_rewards: 270.0710, total_rewards: 3493.4456, mean_steps: 18.6000, mean_ecr: 0.0305 mean_entropies: 0.5949, took: 98.4852s
2022-10-10 18:11:49,301 [INFO] 	Process 4 - batch 63599: mean_policy_losses: 95.496, mean_net_lifetime: 4880.9392, mean_mc_travel_dist: 1396.8869, mean_rewards: 282.9095, total_rewards: 3514.3240, mean_steps: 16.3000, mean_ecr: 0.0472 mean_entropies: 0.5800, took: 89.1798s
2022-10-10 18:12:15,362 [INFO] 	Process 7 - batch 57699: mean_policy_losses: -631.297, mean_net_lifetime: 3789.8792, mean_mc_travel_dist: 1296.2432, mean_rewards: 222.6292, total_rewards: 2536.0066, mean_steps: 16.2300, mean_ecr: 0.0415 mean_entropies: 1.1132, took: 84.8711s
2022-10-10 18:12:16,648 [INFO] 	Process 6 - batch 80399: mean_policy_losses: -87.117, mean_net_lifetime: 3756.6929, mean_mc_travel_dist: 992.6130, mean_rewards: 314.9402, total_rewards: 2792.2893, mean_steps: 10.9700, mean_ecr: 0.0556 mean_entropies: 0.1580, took: 63.9942s
2022-10-10 18:12:22,248 [INFO] 	Process 2 - batch 57599: mean_policy_losses: -4.019, mean_net_lifetime: 4912.4165, mean_mc_travel_dist: 1330.6311, mean_rewards: 283.8182, total_rewards: 3607.0685, mean_steps: 16.3700, mean_ecr: 0.0406 mean_entropies: 0.4920, took: 87.1684s
2022-10-10 18:12:32,974 [INFO] 	Process 1 - batch 50599: mean_policy_losses: -23.118, mean_net_lifetime: 5380.2862, mean_mc_travel_dist: 1888.5290, mean_rewards: 253.9770, total_rewards: 3520.1946, mean_steps: 20.3900, mean_ecr: 0.0387 mean_entropies: 0.8782, took: 107.1922s
2022-10-10 18:12:35,680 [INFO] 	Process 3 - batch 59099: mean_policy_losses: 16.915, mean_net_lifetime: 4422.6182, mean_mc_travel_dist: 1211.8755, mean_rewards: 275.8113, total_rewards: 3234.6754, mean_steps: 15.1100, mean_ecr: 0.0487 mean_entropies: 0.5011, took: 83.6930s
2022-10-10 18:13:05,492 [INFO] 	Process 5 - batch 56999: mean_policy_losses: -256.371, mean_net_lifetime: 5311.6855, mean_mc_travel_dist: 1806.6889, mean_rewards: 272.8144, total_rewards: 3552.8338, mean_steps: 18.9900, mean_ecr: 0.0304 mean_entropies: 0.6060, took: 101.8106s
2022-10-10 18:13:15,176 [INFO] 	Process 6 - batch 80499: mean_policy_losses: -275.339, mean_net_lifetime: 3423.2593, mean_mc_travel_dist: 904.2866, mean_rewards: 313.0833, total_rewards: 2546.5146, mean_steps: 9.9800, mean_ecr: 0.0562 mean_entropies: 0.1523, took: 58.5285s
2022-10-10 18:13:18,141 [INFO] 	Process 4 - batch 63699: mean_policy_losses: 103.339, mean_net_lifetime: 4981.3227, mean_mc_travel_dist: 1421.2680, mean_rewards: 282.8492, total_rewards: 3594.2620, mean_steps: 16.6900, mean_ecr: 0.0469 mean_entropies: 0.5852, took: 88.8399s
2022-10-10 18:13:34,726 [INFO] 	Process 7 - batch 57799: mean_policy_losses: -733.767, mean_net_lifetime: 3527.7921, mean_mc_travel_dist: 1208.8840, mean_rewards: 220.6990, total_rewards: 2358.7049, mean_steps: 15.3900, mean_ecr: 0.0419 mean_entropies: 1.1620, took: 79.3652s
2022-10-10 18:13:45,028 [INFO] 	Process 2 - batch 57699: mean_policy_losses: -19.671, mean_net_lifetime: 4832.6940, mean_mc_travel_dist: 1310.1251, mean_rewards: 285.4471, total_rewards: 3544.4324, mean_steps: 16.0100, mean_ecr: 0.0407 mean_entropies: 0.5050, took: 82.7803s
2022-10-10 18:13:58,769 [INFO] 	Process 3 - batch 59199: mean_policy_losses: 26.255, mean_net_lifetime: 4470.0779, mean_mc_travel_dist: 1233.0927, mean_rewards: 276.4716, total_rewards: 3265.3263, mean_steps: 15.2100, mean_ecr: 0.0487 mean_entropies: 0.4951, took: 83.0885s
2022-10-10 18:14:17,064 [INFO] 	Process 6 - batch 80599: mean_policy_losses: -138.980, mean_net_lifetime: 3660.7263, mean_mc_travel_dist: 962.0944, mean_rewards: 310.4236, total_rewards: 2727.8478, mean_steps: 10.7900, mean_ecr: 0.0560 mean_entropies: 0.1412, took: 61.8885s
2022-10-10 18:14:20,041 [INFO] 	Process 1 - batch 50699: mean_policy_losses: 19.800, mean_net_lifetime: 5570.1010, mean_mc_travel_dist: 1901.5302, mean_rewards: 254.1775, total_rewards: 3695.7347, mean_steps: 21.0600, mean_ecr: 0.0387 mean_entropies: 0.9151, took: 107.0668s
2022-10-10 18:14:43,421 [INFO] 	Process 4 - batch 63799: mean_policy_losses: 92.313, mean_net_lifetime: 4957.1448, mean_mc_travel_dist: 1402.4220, mean_rewards: 289.5629, total_rewards: 3585.0362, mean_steps: 16.2200, mean_ecr: 0.0472 mean_entropies: 0.5770, took: 85.2803s
2022-10-10 18:15:05,170 [INFO] 	Process 7 - batch 57899: mean_policy_losses: -529.913, mean_net_lifetime: 4337.1593, mean_mc_travel_dist: 1461.7406, mean_rewards: 234.1360, total_rewards: 2921.3547, mean_steps: 18.2900, mean_ecr: 0.0411 mean_entropies: 1.1699, took: 90.4429s
2022-10-10 18:15:08,738 [INFO] 	Process 2 - batch 57799: mean_policy_losses: -29.824, mean_net_lifetime: 4839.2593, mean_mc_travel_dist: 1304.5936, mean_rewards: 283.1597, total_rewards: 3559.8418, mean_steps: 16.1900, mean_ecr: 0.0407 mean_entropies: 0.4672, took: 83.7096s
2022-10-10 18:15:16,112 [INFO] 	Process 6 - batch 80699: mean_policy_losses: -192.608, mean_net_lifetime: 3592.0702, mean_mc_travel_dist: 947.6680, mean_rewards: 316.2574, total_rewards: 2667.2308, mean_steps: 10.4200, mean_ecr: 0.0557 mean_entropies: 0.1491, took: 59.0482s
2022-10-10 18:15:20,920 [INFO] 	Process 3 - batch 59299: mean_policy_losses: 21.153, mean_net_lifetime: 4564.6991, mean_mc_travel_dist: 1237.5917, mean_rewards: 280.4629, total_rewards: 3349.6956, mean_steps: 15.3300, mean_ecr: 0.0485 mean_entropies: 0.4544, took: 82.1510s
2022-10-10 18:16:12,487 [INFO] 	Process 1 - batch 50799: mean_policy_losses: -17.062, mean_net_lifetime: 5628.9808, mean_mc_travel_dist: 1942.4239, mean_rewards: 245.5810, total_rewards: 3703.0430, mean_steps: 22.2300, mean_ecr: 0.0384 mean_entropies: 0.8507, took: 112.4466s
2022-10-10 18:16:13,856 [INFO] 	Process 4 - batch 63899: mean_policy_losses: 86.315, mean_net_lifetime: 5142.7365, mean_mc_travel_dist: 1489.3958, mean_rewards: 280.9805, total_rewards: 3687.3345, mean_steps: 17.3200, mean_ecr: 0.0466 mean_entropies: 0.5693, took: 90.4348s
2022-10-10 18:16:18,980 [INFO] 	Process 6 - batch 80799: mean_policy_losses: -43.341, mean_net_lifetime: 3800.4037, mean_mc_travel_dist: 1000.5103, mean_rewards: 318.8653, total_rewards: 2827.9472, mean_steps: 10.9600, mean_ecr: 0.0556 mean_entropies: 0.1442, took: 62.8671s
2022-10-10 18:16:31,885 [INFO] 	Process 2 - batch 57899: mean_policy_losses: -20.243, mean_net_lifetime: 4783.0713, mean_mc_travel_dist: 1301.9861, mean_rewards: 281.1281, total_rewards: 3502.2462, mean_steps: 16.0800, mean_ecr: 0.0407 mean_entropies: 0.4651, took: 83.1471s
2022-10-10 18:16:37,268 [INFO] 	Process 7 - batch 57999: mean_policy_losses: -595.776, mean_net_lifetime: 4387.1200, mean_mc_travel_dist: 1495.2499, mean_rewards: 227.7588, total_rewards: 2937.9979, mean_steps: 18.8500, mean_ecr: 0.0410 mean_entropies: 1.2058, took: 92.0989s
2022-10-10 18:16:46,073 [INFO] 	Process 3 - batch 59399: mean_policy_losses: 38.184, mean_net_lifetime: 4553.4584, mean_mc_travel_dist: 1230.1312, mean_rewards: 276.8485, total_rewards: 3351.8071, mean_steps: 15.4900, mean_ecr: 0.0486 mean_entropies: 0.4688, took: 85.1539s
2022-10-10 18:17:22,495 [INFO] 	Process 6 - batch 80899: mean_policy_losses: -86.888, mean_net_lifetime: 3770.8655, mean_mc_travel_dist: 991.9438, mean_rewards: 311.2856, total_rewards: 2816.4417, mean_steps: 11.1400, mean_ecr: 0.0557 mean_entropies: 0.1379, took: 63.5145s
2022-10-10 18:17:37,689 [INFO] 	Process 4 - batch 63999: mean_policy_losses: 79.694, mean_net_lifetime: 4872.9832, mean_mc_travel_dist: 1418.2556, mean_rewards: 285.9933, total_rewards: 3492.4644, mean_steps: 16.2000, mean_ecr: 0.0470 mean_entropies: 0.5688, took: 83.8339s
2022-10-10 18:17:53,917 [INFO] 	Process 1 - batch 50899: mean_policy_losses: -68.138, mean_net_lifetime: 5269.5889, mean_mc_travel_dist: 1945.8242, mean_rewards: 256.0507, total_rewards: 3346.0443, mean_steps: 19.8000, mean_ecr: 0.0385 mean_entropies: 0.8172, took: 101.4255s
2022-10-10 18:17:55,457 [INFO] 	Process 2 - batch 57999: mean_policy_losses: -12.049, mean_net_lifetime: 4840.8459, mean_mc_travel_dist: 1302.7150, mean_rewards: 281.7050, total_rewards: 3563.5400, mean_steps: 16.2800, mean_ecr: 0.0407 mean_entropies: 0.4773, took: 83.5717s
2022-10-10 18:18:01,994 [INFO] 	Process 7 - batch 58099: mean_policy_losses: -576.147, mean_net_lifetime: 4044.4910, mean_mc_travel_dist: 1416.7339, mean_rewards: 226.8392, total_rewards: 2676.2009, mean_steps: 17.1400, mean_ecr: 0.0412 mean_entropies: 1.1217, took: 84.7261s
2022-10-10 18:18:09,736 [INFO] 	Process 3 - batch 59499: mean_policy_losses: 27.392, mean_net_lifetime: 4497.4966, mean_mc_travel_dist: 1226.0235, mean_rewards: 274.6539, total_rewards: 3300.7941, mean_steps: 15.4300, mean_ecr: 0.0486 mean_entropies: 0.4577, took: 83.6628s
2022-10-10 18:18:26,002 [INFO] 	Process 6 - batch 80999: mean_policy_losses: -77.621, mean_net_lifetime: 3811.1226, mean_mc_travel_dist: 1000.7693, mean_rewards: 308.8016, total_rewards: 2831.6148, mean_steps: 11.3700, mean_ecr: 0.0555 mean_entropies: 0.1421, took: 63.5076s
2022-10-10 18:19:00,880 [INFO] 	Process 4 - batch 64099: mean_policy_losses: 80.826, mean_net_lifetime: 5102.7639, mean_mc_travel_dist: 1432.2152, mean_rewards: 296.8610, total_rewards: 3695.7811, mean_steps: 16.2600, mean_ecr: 0.0468 mean_entropies: 0.5616, took: 83.1906s
2022-10-10 18:19:23,141 [INFO] 	Process 2 - batch 58099: mean_policy_losses: -36.711, mean_net_lifetime: 5118.9183, mean_mc_travel_dist: 1414.5965, mean_rewards: 280.5310, total_rewards: 3731.7238, mean_steps: 17.3900, mean_ecr: 0.0403 mean_entropies: 0.5042, took: 87.6843s
2022-10-10 18:19:26,508 [INFO] 	Process 7 - batch 58199: mean_policy_losses: -663.673, mean_net_lifetime: 4335.8608, mean_mc_travel_dist: 1472.8107, mean_rewards: 237.5752, total_rewards: 2901.7019, mean_steps: 17.6000, mean_ecr: 0.0410 mean_entropies: 1.2239, took: 84.5136s
2022-10-10 18:19:32,242 [INFO] 	Process 3 - batch 59599: mean_policy_losses: 12.652, mean_net_lifetime: 4601.4680, mean_mc_travel_dist: 1256.8979, mean_rewards: 278.3449, total_rewards: 3370.5797, mean_steps: 15.5900, mean_ecr: 0.0485 mean_entropies: 0.4780, took: 82.5055s
2022-10-10 18:19:35,904 [INFO] 	Process 1 - batch 50999: mean_policy_losses: -71.593, mean_net_lifetime: 5460.8836, mean_mc_travel_dist: 1929.9211, mean_rewards: 256.8299, total_rewards: 3563.2657, mean_steps: 20.4200, mean_ecr: 0.0385 mean_entropies: 0.8848, took: 101.9915s
2022-10-10 18:20:21,724 [INFO] 	Process 4 - batch 64199: mean_policy_losses: 42.844, mean_net_lifetime: 5072.8162, mean_mc_travel_dist: 1460.6256, mean_rewards: 295.3991, total_rewards: 3640.2757, mean_steps: 16.3100, mean_ecr: 0.0466 mean_entropies: 0.5750, took: 80.8441s
2022-10-10 18:20:40,062 [INFO] 	Process 7 - batch 58299: mean_policy_losses: -826.009, mean_net_lifetime: 3872.9208, mean_mc_travel_dist: 1343.8203, mean_rewards: 235.8082, total_rewards: 2561.0450, mean_steps: 15.9000, mean_ecr: 0.0414 mean_entropies: 1.2393, took: 73.5533s
2022-10-10 18:20:47,763 [INFO] 	Process 2 - batch 58199: mean_policy_losses: -22.094, mean_net_lifetime: 5217.0918, mean_mc_travel_dist: 1457.8952, mean_rewards: 277.4785, total_rewards: 3784.2403, mean_steps: 17.8900, mean_ecr: 0.0400 mean_entropies: 0.5327, took: 84.6223s
2022-10-10 18:20:53,940 [INFO] 	Process 3 - batch 59699: mean_policy_losses: 10.571, mean_net_lifetime: 4648.1467, mean_mc_travel_dist: 1276.3521, mean_rewards: 273.4467, total_rewards: 3406.2877, mean_steps: 16.0700, mean_ecr: 0.0480 mean_entropies: 0.4570, took: 81.6981s
2022-10-10 18:21:55,148 [INFO] 	Process 4 - batch 64299: mean_policy_losses: 78.479, mean_net_lifetime: 5696.4234, mean_mc_travel_dist: 1656.3700, mean_rewards: 286.5429, total_rewards: 4078.1083, mean_steps: 19.3700, mean_ecr: 0.0453 mean_entropies: 0.6278, took: 93.4238s
2022-10-10 18:22:13,437 [INFO] 	Process 7 - batch 58399: mean_policy_losses: -639.745, mean_net_lifetime: 4755.9383, mean_mc_travel_dist: 1613.2155, mean_rewards: 226.9435, total_rewards: 3186.6988, mean_steps: 20.5700, mean_ecr: 0.0409 mean_entropies: 1.2846, took: 93.3756s
2022-10-10 18:22:15,364 [INFO] 	Process 3 - batch 59799: mean_policy_losses: -7.678, mean_net_lifetime: 4741.0886, mean_mc_travel_dist: 1375.1716, mean_rewards: 276.4855, total_rewards: 3398.6692, mean_steps: 16.1700, mean_ecr: 0.0469 mean_entropies: 0.5227, took: 81.4244s
2022-10-10 18:22:27,791 [INFO] 	Process 2 - batch 58299: mean_policy_losses: 27.357, mean_net_lifetime: 6371.3931, mean_mc_travel_dist: 1943.6574, mean_rewards: 279.9034, total_rewards: 4464.8999, mean_steps: 21.8500, mean_ecr: 0.0383 mean_entropies: 0.6572, took: 100.0266s
2022-10-10 18:23:13,287 [INFO] Process 5 - epoch 38: mean_policy_losses: -216.970, mean_net_lifetime: 4568.0163, mean_mc_travel_dist: 1894.5887, mean_entropies: 1.3067, m_net_lifetime_valid: 4825.1667, took: 2024.7499s, (154.0992 / 100 batches)

2022-10-10 18:23:19,999 [INFO] 	Process 4 - batch 64399: mean_policy_losses: 50.591, mean_net_lifetime: 5319.4850, mean_mc_travel_dist: 1513.5352, mean_rewards: 289.9556, total_rewards: 3825.5275, mean_steps: 17.4800, mean_ecr: 0.0462 mean_entropies: 0.6081, took: 84.8510s
2022-10-10 18:23:35,555 [INFO] 	Process 3 - batch 59899: mean_policy_losses: -3.113, mean_net_lifetime: 4669.5845, mean_mc_travel_dist: 1349.8897, mean_rewards: 283.6883, total_rewards: 3368.4406, mean_steps: 15.5100, mean_ecr: 0.0475 mean_entropies: 0.5305, took: 80.1911s
2022-10-10 18:23:36,837 [INFO] 	Process 7 - batch 58499: mean_policy_losses: -682.089, mean_net_lifetime: 4385.2897, mean_mc_travel_dist: 1543.0746, mean_rewards: 236.3416, total_rewards: 2883.0952, mean_steps: 17.9100, mean_ecr: 0.0413 mean_entropies: 1.2415, took: 83.3996s
2022-10-10 18:23:59,929 [INFO] 	Process 2 - batch 58399: mean_policy_losses: -2.453, mean_net_lifetime: 5752.7813, mean_mc_travel_dist: 1757.6947, mean_rewards: 284.7937, total_rewards: 4030.9379, mean_steps: 19.2800, mean_ecr: 0.0389 mean_entropies: 0.5847, took: 92.1393s
2022-10-10 18:24:38,970 [INFO] 	Process 4 - batch 64499: mean_policy_losses: 75.133, mean_net_lifetime: 4824.7739, mean_mc_travel_dist: 1377.8507, mean_rewards: 284.6491, total_rewards: 3488.5647, mean_steps: 16.0300, mean_ecr: 0.0474 mean_entropies: 0.6458, took: 78.9707s
2022-10-10 18:24:44,687 [INFO] 	Process 5 - batch 57099: mean_policy_losses: -270.581, mean_net_lifetime: 5282.4254, mean_mc_travel_dist: 1817.3844, mean_rewards: 274.4026, total_rewards: 3511.6032, mean_steps: 18.8200, mean_ecr: 0.0300 mean_entropies: 0.6548, took: 699.1958s
2022-10-10 18:24:53,624 [INFO] 	Process 3 - batch 59999: mean_policy_losses: 45.375, mean_net_lifetime: 4641.6051, mean_mc_travel_dist: 1296.7146, mean_rewards: 278.5742, total_rewards: 3373.8848, mean_steps: 15.7200, mean_ecr: 0.0479 mean_entropies: 0.5043, took: 78.0683s
2022-10-10 18:25:31,216 [INFO] 	Process 2 - batch 58499: mean_policy_losses: 42.294, mean_net_lifetime: 5987.6265, mean_mc_travel_dist: 1854.8976, mean_rewards: 285.7211, total_rewards: 4166.2243, mean_steps: 20.0100, mean_ecr: 0.0385 mean_entropies: 0.6149, took: 91.2869s
2022-10-10 18:26:13,873 [INFO] 	Process 5 - batch 57199: mean_policy_losses: -39.200, mean_net_lifetime: 6213.0402, mean_mc_travel_dist: 2096.6228, mean_rewards: 288.1007, total_rewards: 4158.9834, mean_steps: 20.7100, mean_ecr: 0.0306 mean_entropies: 0.6782, took: 89.1863s
2022-10-10 18:27:43,895 [INFO] 	Process 5 - batch 57299: mean_policy_losses: -14.720, mean_net_lifetime: 6767.2402, mean_mc_travel_dist: 2292.9888, mean_rewards: 289.6045, total_rewards: 4520.2373, mean_steps: 22.4500, mean_ecr: 0.0307 mean_entropies: 0.7084, took: 90.0217s
2022-10-10 18:27:51,793 [INFO] Process 1 - epoch 34: mean_policy_losses: 39.416, mean_net_lifetime: 4892.3552, mean_mc_travel_dist: 2035.4945, mean_entropies: 1.2606, m_net_lifetime_valid: 4116.2273, took: 2034.7218s, (172.9572 / 100 batches)

2022-10-10 18:27:58,060 [INFO] Process 6 - epoch 54: mean_policy_losses: -234.789, mean_net_lifetime: 2863.5952, mean_mc_travel_dist: 950.5525, mean_entropies: 0.6952, m_net_lifetime_valid: 4465.7323, took: 1477.1064s, (108.8911 / 100 batches)

2022-10-10 18:28:31,360 [INFO] 	Process 6 - batch 81099: mean_policy_losses: -362.736, mean_net_lifetime: 2366.6774, mean_mc_travel_dist: 637.2490, mean_rewards: 324.3835, total_rewards: 1763.2414, mean_steps: 6.1300, mean_ecr: 0.0565 mean_entropies: 0.3393, took: 605.3585s
2022-10-10 18:29:16,127 [INFO] 	Process 6 - batch 81199: mean_policy_losses: -179.989, mean_net_lifetime: 3287.3466, mean_mc_travel_dist: 857.1829, mean_rewards: 334.4404, total_rewards: 2455.7116, mean_steps: 8.7300, mean_ecr: 0.0557 mean_entropies: 0.2832, took: 44.7668s
2022-10-10 18:29:18,415 [INFO] 	Process 5 - batch 57399: mean_policy_losses: 6.961, mean_net_lifetime: 6502.1993, mean_mc_travel_dist: 2182.0540, mean_rewards: 288.8207, total_rewards: 4371.8147, mean_steps: 21.6600, mean_ecr: 0.0308 mean_entropies: 0.7113, took: 94.5192s
2022-10-10 18:29:29,128 [INFO] 	Process 1 - batch 51099: mean_policy_losses: 44.570, mean_net_lifetime: 5596.5852, mean_mc_travel_dist: 2011.9705, mean_rewards: 243.2448, total_rewards: 3615.0733, mean_steps: 22.3900, mean_ecr: 0.0384 mean_entropies: 0.8662, took: 593.2231s
2022-10-10 18:30:03,644 [INFO] 	Process 6 - batch 81299: mean_policy_losses: -140.720, mean_net_lifetime: 3529.0838, mean_mc_travel_dist: 900.4782, mean_rewards: 337.2965, total_rewards: 2649.0268, mean_steps: 9.4000, mean_ecr: 0.0554 mean_entropies: 0.2540, took: 47.5167s
2022-10-10 18:30:49,207 [INFO] 	Process 6 - batch 81399: mean_policy_losses: -120.237, mean_net_lifetime: 3417.0089, mean_mc_travel_dist: 883.5949, mean_rewards: 336.5729, total_rewards: 2558.8569, mean_steps: 9.0600, mean_ecr: 0.0555 mean_entropies: 0.2320, took: 45.5642s
2022-10-10 18:30:49,916 [INFO] 	Process 5 - batch 57499: mean_policy_losses: -77.753, mean_net_lifetime: 6186.7233, mean_mc_travel_dist: 2096.0295, mean_rewards: 289.7907, total_rewards: 4128.0707, mean_steps: 20.4800, mean_ecr: 0.0306 mean_entropies: 0.6467, took: 91.5001s
2022-10-10 18:31:11,040 [INFO] 	Process 1 - batch 51199: mean_policy_losses: 17.219, mean_net_lifetime: 5575.2630, mean_mc_travel_dist: 2065.2599, mean_rewards: 237.6440, total_rewards: 3535.5040, mean_steps: 23.1800, mean_ecr: 0.0380 mean_entropies: 0.7351, took: 101.9125s
2022-10-10 18:31:38,083 [INFO] 	Process 6 - batch 81499: mean_policy_losses: -139.427, mean_net_lifetime: 3585.5648, mean_mc_travel_dist: 912.4784, mean_rewards: 334.8567, total_rewards: 2689.4228, mean_steps: 9.6900, mean_ecr: 0.0549 mean_entropies: 0.2089, took: 48.8749s
2022-10-10 18:32:21,608 [INFO] 	Process 5 - batch 57599: mean_policy_losses: -59.190, mean_net_lifetime: 6140.5516, mean_mc_travel_dist: 2109.2466, mean_rewards: 283.7189, total_rewards: 4086.3390, mean_steps: 20.8300, mean_ecr: 0.0303 mean_entropies: 0.6070, took: 91.6930s
2022-10-10 18:32:25,395 [INFO] 	Process 6 - batch 81599: mean_policy_losses: -132.642, mean_net_lifetime: 3492.4699, mean_mc_travel_dist: 887.2836, mean_rewards: 324.4865, total_rewards: 2630.4186, mean_steps: 9.6000, mean_ecr: 0.0550 mean_entropies: 0.1823, took: 47.3119s
2022-10-10 18:32:31,175 [INFO] Process 7 - epoch 39: mean_policy_losses: -323.129, mean_net_lifetime: 3983.6862, mean_mc_travel_dist: 1569.8990, mean_entropies: 1.6437, m_net_lifetime_valid: 4455.5210, took: 1799.6626s, (151.2320 / 100 batches)

2022-10-10 18:32:44,065 [INFO] 	Process 1 - batch 51299: mean_policy_losses: -6.273, mean_net_lifetime: 5361.1072, mean_mc_travel_dist: 1905.9811, mean_rewards: 242.2741, total_rewards: 3477.0193, mean_steps: 21.4900, mean_ecr: 0.0387 mean_entropies: 0.7772, took: 93.0243s
2022-10-10 18:32:58,100 [INFO] Process 3 - epoch 40: mean_policy_losses: 76.522, mean_net_lifetime: 4193.4192, mean_mc_travel_dist: 1374.5359, mean_entropies: 0.9966, m_net_lifetime_valid: 4529.9534, took: 1734.4056s, (147.5843 / 100 batches)

2022-10-10 18:33:17,307 [INFO] 	Process 6 - batch 81699: mean_policy_losses: -139.431, mean_net_lifetime: 3703.0802, mean_mc_travel_dist: 941.5423, mean_rewards: 334.0098, total_rewards: 2770.5586, mean_steps: 9.9800, mean_ecr: 0.0546 mean_entropies: 0.1866, took: 51.9123s
2022-10-10 18:33:29,230 [INFO] Process 4 - epoch 43: mean_policy_losses: 87.706, mean_net_lifetime: 3993.3001, mean_mc_travel_dist: 1317.5732, mean_entropies: 1.2395, m_net_lifetime_valid: 5097.0248, took: 1817.3240s, (137.2818 / 100 batches)

2022-10-10 18:34:01,031 [INFO] Process 2 - epoch 39: mean_policy_losses: 3.686, mean_net_lifetime: 4361.6330, mean_mc_travel_dist: 1544.3462, mean_entropies: 1.0201, m_net_lifetime_valid: 4913.5139, took: 1825.5192s, (151.4275 / 100 batches)

2022-10-10 18:34:06,480 [INFO] 	Process 5 - batch 57699: mean_policy_losses: -72.411, mean_net_lifetime: 6510.5074, mean_mc_travel_dist: 2210.4946, mean_rewards: 280.7552, total_rewards: 4346.8664, mean_steps: 22.3000, mean_ecr: 0.0301 mean_entropies: 0.6383, took: 104.8725s
2022-10-10 18:34:10,269 [INFO] 	Process 6 - batch 81799: mean_policy_losses: -239.005, mean_net_lifetime: 3638.7649, mean_mc_travel_dist: 934.0057, mean_rewards: 333.6268, total_rewards: 2713.9805, mean_steps: 9.8000, mean_ecr: 0.0548 mean_entropies: 0.2014, took: 52.9621s
2022-10-10 18:34:10,746 [INFO] 	Process 7 - batch 58599: mean_policy_losses: -345.084, mean_net_lifetime: 4424.7900, mean_mc_travel_dist: 1379.2009, mean_rewards: 204.2307, total_rewards: 3077.8945, mean_steps: 20.9800, mean_ecr: 0.0415 mean_entropies: 1.1793, took: 633.9096s
2022-10-10 18:34:19,635 [INFO] 	Process 3 - batch 60099: mean_policy_losses: 25.737, mean_net_lifetime: 4809.6091, mean_mc_travel_dist: 1366.3077, mean_rewards: 278.4075, total_rewards: 3480.1388, mean_steps: 16.3300, mean_ecr: 0.0472 mean_entropies: 0.4863, took: 566.0119s
2022-10-10 18:34:38,945 [INFO] 	Process 1 - batch 51399: mean_policy_losses: -52.775, mean_net_lifetime: 5717.4417, mean_mc_travel_dist: 1971.4486, mean_rewards: 229.9148, total_rewards: 3771.5163, mean_steps: 24.2300, mean_ecr: 0.0384 mean_entropies: 0.8268, took: 114.8807s
2022-10-10 18:34:51,226 [INFO] 	Process 4 - batch 64599: mean_policy_losses: 80.509, mean_net_lifetime: 3986.1929, mean_mc_travel_dist: 1174.7567, mean_rewards: 243.0129, total_rewards: 2833.7515, mean_steps: 15.3900, mean_ecr: 0.0492 mean_entropies: 0.7572, took: 612.2561s
2022-10-10 18:35:06,536 [INFO] 	Process 6 - batch 81899: mean_policy_losses: -145.466, mean_net_lifetime: 3602.6065, mean_mc_travel_dist: 928.2568, mean_rewards: 331.6855, total_rewards: 2690.2785, mean_steps: 9.7600, mean_ecr: 0.0549 mean_entropies: 0.2036, took: 56.2674s
2022-10-10 18:35:46,017 [INFO] 	Process 3 - batch 60199: mean_policy_losses: 27.453, mean_net_lifetime: 4724.8508, mean_mc_travel_dist: 1325.5217, mean_rewards: 272.9517, total_rewards: 3437.5160, mean_steps: 16.3900, mean_ecr: 0.0474 mean_entropies: 0.4792, took: 86.3820s
2022-10-10 18:35:47,335 [INFO] 	Process 7 - batch 58699: mean_policy_losses: -497.825, mean_net_lifetime: 3941.7771, mean_mc_travel_dist: 1271.0267, mean_rewards: 201.9467, total_rewards: 2706.3329, mean_steps: 19.2000, mean_ecr: 0.0416 mean_entropies: 1.2069, took: 96.5891s
2022-10-10 18:35:48,758 [INFO] 	Process 2 - batch 58599: mean_policy_losses: 29.821, mean_net_lifetime: 6047.5037, mean_mc_travel_dist: 1761.7171, mean_rewards: 271.3768, total_rewards: 4315.0563, mean_steps: 21.3900, mean_ecr: 0.0389 mean_entropies: 0.5445, took: 617.5427s
2022-10-10 18:35:53,663 [INFO] 	Process 5 - batch 57799: mean_policy_losses: -124.984, mean_net_lifetime: 6134.0047, mean_mc_travel_dist: 2115.8647, mean_rewards: 278.9458, total_rewards: 4070.5110, mean_steps: 21.1600, mean_ecr: 0.0300 mean_entropies: 0.6447, took: 107.1835s
2022-10-10 18:36:01,439 [INFO] 	Process 6 - batch 81999: mean_policy_losses: -167.046, mean_net_lifetime: 3617.2838, mean_mc_travel_dist: 934.9482, mean_rewards: 334.0785, total_rewards: 2702.2939, mean_steps: 9.7700, mean_ecr: 0.0551 mean_entropies: 0.2076, took: 54.9015s
2022-10-10 18:36:15,276 [INFO] 	Process 4 - batch 64699: mean_policy_losses: 176.974, mean_net_lifetime: 4534.7200, mean_mc_travel_dist: 1290.9113, mean_rewards: 270.1548, total_rewards: 3276.6307, mean_steps: 15.8200, mean_ecr: 0.0480 mean_entropies: 0.6829, took: 84.0499s
2022-10-10 18:36:26,507 [INFO] 	Process 1 - batch 51499: mean_policy_losses: -23.252, mean_net_lifetime: 5578.3395, mean_mc_travel_dist: 1916.1113, mean_rewards: 248.1331, total_rewards: 3688.2613, mean_steps: 21.7300, mean_ecr: 0.0386 mean_entropies: 0.8736, took: 107.5619s
2022-10-10 18:36:58,178 [INFO] 	Process 6 - batch 82099: mean_policy_losses: -122.347, mean_net_lifetime: 3658.3097, mean_mc_travel_dist: 954.4408, mean_rewards: 328.8920, total_rewards: 2729.2551, mean_steps: 10.0000, mean_ecr: 0.0550 mean_entropies: 0.2028, took: 56.7403s
2022-10-10 18:37:14,601 [INFO] 	Process 3 - batch 60299: mean_policy_losses: 25.491, mean_net_lifetime: 4768.1328, mean_mc_travel_dist: 1334.6068, mean_rewards: 268.8145, total_rewards: 3473.0387, mean_steps: 16.7700, mean_ecr: 0.0476 mean_entropies: 0.4902, took: 88.5845s
2022-10-10 18:37:35,759 [INFO] 	Process 7 - batch 58799: mean_policy_losses: -347.332, mean_net_lifetime: 4748.1739, mean_mc_travel_dist: 1496.7846, mean_rewards: 211.2843, total_rewards: 3284.2473, mean_steps: 21.8900, mean_ecr: 0.0410 mean_entropies: 1.2423, took: 108.4232s
2022-10-10 18:37:43,920 [INFO] 	Process 5 - batch 57899: mean_policy_losses: -131.011, mean_net_lifetime: 6111.5688, mean_mc_travel_dist: 2123.6106, mean_rewards: 270.1101, total_rewards: 4043.3947, mean_steps: 21.7600, mean_ecr: 0.0297 mean_entropies: 0.6318, took: 110.2555s
2022-10-10 18:37:45,395 [INFO] 	Process 4 - batch 64799: mean_policy_losses: 110.495, mean_net_lifetime: 4941.4108, mean_mc_travel_dist: 1417.0328, mean_rewards: 274.2766, total_rewards: 3548.8788, mean_steps: 17.2200, mean_ecr: 0.0471 mean_entropies: 0.6783, took: 90.1190s
2022-10-10 18:37:47,594 [INFO] 	Process 6 - batch 82199: mean_policy_losses: -209.452, mean_net_lifetime: 3262.8332, mean_mc_travel_dist: 863.7470, mean_rewards: 323.5888, total_rewards: 2427.8053, mean_steps: 8.8500, mean_ecr: 0.0557 mean_entropies: 0.2460, took: 49.4159s
2022-10-10 18:37:48,961 [INFO] 	Process 2 - batch 58699: mean_policy_losses: 84.206, mean_net_lifetime: 6709.4811, mean_mc_travel_dist: 1969.9312, mean_rewards: 266.6445, total_rewards: 4779.9442, mean_steps: 24.2500, mean_ecr: 0.0382 mean_entropies: 0.5442, took: 120.2020s
2022-10-10 18:38:20,769 [INFO] 	Process 1 - batch 51599: mean_policy_losses: -56.913, mean_net_lifetime: 5552.8275, mean_mc_travel_dist: 1949.9686, mean_rewards: 240.5000, total_rewards: 3638.4573, mean_steps: 22.5000, mean_ecr: 0.0384 mean_entropies: 0.8626, took: 114.2622s
2022-10-10 18:38:38,978 [INFO] 	Process 6 - batch 82299: mean_policy_losses: -196.319, mean_net_lifetime: 3271.0987, mean_mc_travel_dist: 863.1792, mean_rewards: 327.0764, total_rewards: 2432.5316, mean_steps: 8.8700, mean_ecr: 0.0556 mean_entropies: 0.2261, took: 51.3839s
2022-10-10 18:38:41,211 [INFO] 	Process 3 - batch 60399: mean_policy_losses: 49.058, mean_net_lifetime: 4787.9067, mean_mc_travel_dist: 1332.2942, mean_rewards: 273.1861, total_rewards: 3497.4424, mean_steps: 16.5600, mean_ecr: 0.0475 mean_entropies: 0.4960, took: 86.6091s
2022-10-10 18:39:11,086 [INFO] 	Process 4 - batch 64899: mean_policy_losses: 75.174, mean_net_lifetime: 4711.2038, mean_mc_travel_dist: 1354.7597, mean_rewards: 275.4587, total_rewards: 3390.8666, mean_steps: 16.1700, mean_ecr: 0.0475 mean_entropies: 0.6134, took: 85.6914s
2022-10-10 18:39:22,631 [INFO] 	Process 7 - batch 58899: mean_policy_losses: -356.954, mean_net_lifetime: 4666.9704, mean_mc_travel_dist: 1546.5123, mean_rewards: 211.5076, total_rewards: 3159.2003, mean_steps: 21.6500, mean_ecr: 0.0411 mean_entropies: 1.2256, took: 106.8726s
2022-10-10 18:39:24,851 [INFO] 	Process 5 - batch 57999: mean_policy_losses: -218.079, mean_net_lifetime: 5447.9479, mean_mc_travel_dist: 1870.5516, mean_rewards: 269.7279, total_rewards: 3626.0749, mean_steps: 19.8500, mean_ecr: 0.0301 mean_entropies: 0.6694, took: 100.9315s
2022-10-10 18:39:30,789 [INFO] 	Process 2 - batch 58799: mean_policy_losses: 46.864, mean_net_lifetime: 5809.4175, mean_mc_travel_dist: 1623.2086, mean_rewards: 276.9689, total_rewards: 4214.1837, mean_steps: 20.2000, mean_ecr: 0.0396 mean_entropies: 0.5190, took: 101.8287s
2022-10-10 18:39:37,457 [INFO] 	Process 6 - batch 82399: mean_policy_losses: -138.110, mean_net_lifetime: 3663.3596, mean_mc_travel_dist: 965.3238, mean_rewards: 328.3588, total_rewards: 2715.3543, mean_steps: 10.1500, mean_ecr: 0.0556 mean_entropies: 0.1736, took: 58.4785s
2022-10-10 18:40:04,111 [INFO] 	Process 1 - batch 51699: mean_policy_losses: -34.693, mean_net_lifetime: 5485.0488, mean_mc_travel_dist: 1938.8304, mean_rewards: 258.3609, total_rewards: 3576.4176, mean_steps: 20.4800, mean_ecr: 0.0384 mean_entropies: 0.8495, took: 103.3424s
2022-10-10 18:40:05,744 [INFO] 	Process 3 - batch 60499: mean_policy_losses: 29.192, mean_net_lifetime: 4661.1382, mean_mc_travel_dist: 1279.0796, mean_rewards: 273.1522, total_rewards: 3411.5531, mean_steps: 16.1200, mean_ecr: 0.0479 mean_entropies: 0.4793, took: 84.5333s
2022-10-10 18:40:29,963 [INFO] 	Process 6 - batch 82499: mean_policy_losses: -274.281, mean_net_lifetime: 3416.9731, mean_mc_travel_dist: 887.5606, mean_rewards: 330.7594, total_rewards: 2545.2195, mean_steps: 9.2200, mean_ecr: 0.0551 mean_entropies: 0.2439, took: 52.5068s
2022-10-10 18:40:39,333 [INFO] 	Process 4 - batch 64999: mean_policy_losses: 69.530, mean_net_lifetime: 5019.4991, mean_mc_travel_dist: 1411.5126, mean_rewards: 282.8479, total_rewards: 3636.0370, mean_steps: 16.8300, mean_ecr: 0.0472 mean_entropies: 0.6378, took: 88.2464s
2022-10-10 18:41:04,934 [INFO] 	Process 7 - batch 58999: mean_policy_losses: -543.392, mean_net_lifetime: 4635.4120, mean_mc_travel_dist: 1492.4229, mean_rewards: 212.7338, total_rewards: 3178.1934, mean_steps: 20.8400, mean_ecr: 0.0411 mean_entropies: 1.3094, took: 102.3024s
2022-10-10 18:41:14,985 [INFO] 	Process 5 - batch 58099: mean_policy_losses: -168.907, mean_net_lifetime: 6182.0292, mean_mc_travel_dist: 2122.5608, mean_rewards: 277.1971, total_rewards: 4109.6027, mean_steps: 21.5100, mean_ecr: 0.0299 mean_entropies: 0.6730, took: 110.1344s
2022-10-10 18:41:24,473 [INFO] 	Process 2 - batch 58899: mean_policy_losses: 45.090, mean_net_lifetime: 6594.6727, mean_mc_travel_dist: 1898.1464, mean_rewards: 272.7438, total_rewards: 4735.9533, mean_steps: 23.3100, mean_ecr: 0.0386 mean_entropies: 0.5517, took: 113.6840s
2022-10-10 18:41:29,867 [INFO] 	Process 3 - batch 60599: mean_policy_losses: 16.643, mean_net_lifetime: 4786.6722, mean_mc_travel_dist: 1337.7424, mean_rewards: 277.3426, total_rewards: 3489.5577, mean_steps: 16.3200, mean_ecr: 0.0476 mean_entropies: 0.4898, took: 84.1233s
2022-10-10 18:41:51,767 [INFO] 	Process 1 - batch 51799: mean_policy_losses: -49.671, mean_net_lifetime: 5741.7060, mean_mc_travel_dist: 1959.1116, mean_rewards: 250.1058, total_rewards: 3805.5602, mean_steps: 22.2300, mean_ecr: 0.0384 mean_entropies: 0.9159, took: 107.6550s
2022-10-10 18:42:04,961 [INFO] 	Process 4 - batch 65099: mean_policy_losses: 85.852, mean_net_lifetime: 5038.0419, mean_mc_travel_dist: 1410.7688, mean_rewards: 285.8078, total_rewards: 3658.9567, mean_steps: 16.7400, mean_ecr: 0.0469 mean_entropies: 0.5923, took: 85.6283s
2022-10-10 18:42:37,976 [INFO] 	Process 7 - batch 59099: mean_policy_losses: -589.857, mean_net_lifetime: 4307.3319, mean_mc_travel_dist: 1440.5396, mean_rewards: 216.2368, total_rewards: 2904.5913, mean_steps: 19.4200, mean_ecr: 0.0413 mean_entropies: 1.2395, took: 93.0427s
2022-10-10 18:42:53,785 [INFO] 	Process 3 - batch 60699: mean_policy_losses: 17.693, mean_net_lifetime: 4664.8524, mean_mc_travel_dist: 1283.2122, mean_rewards: 270.3091, total_rewards: 3420.6337, mean_steps: 16.3000, mean_ecr: 0.0480 mean_entropies: 0.4912, took: 83.9182s
2022-10-10 18:43:04,397 [INFO] 	Process 5 - batch 58199: mean_policy_losses: -159.498, mean_net_lifetime: 6146.9415, mean_mc_travel_dist: 2119.3700, mean_rewards: 266.7989, total_rewards: 4073.3443, mean_steps: 22.4200, mean_ecr: 0.0299 mean_entropies: 0.6346, took: 109.4122s
2022-10-10 18:43:12,400 [INFO] 	Process 2 - batch 58999: mean_policy_losses: 43.427, mean_net_lifetime: 6388.1702, mean_mc_travel_dist: 1790.8138, mean_rewards: 275.3415, total_rewards: 4626.6811, mean_steps: 22.3200, mean_ecr: 0.0390 mean_entropies: 0.5453, took: 107.9265s
2022-10-10 18:43:31,673 [INFO] 	Process 4 - batch 65199: mean_policy_losses: 80.834, mean_net_lifetime: 5036.5487, mean_mc_travel_dist: 1429.6766, mean_rewards: 280.9568, total_rewards: 3633.8817, mean_steps: 17.0300, mean_ecr: 0.0470 mean_entropies: 0.6168, took: 86.7125s
2022-10-10 18:43:38,551 [INFO] 	Process 1 - batch 51899: mean_policy_losses: -74.666, mean_net_lifetime: 5728.2207, mean_mc_travel_dist: 1955.3550, mean_rewards: 253.9622, total_rewards: 3801.9738, mean_steps: 21.8500, mean_ecr: 0.0384 mean_entropies: 0.9369, took: 106.7836s
2022-10-10 18:44:18,763 [INFO] 	Process 3 - batch 60799: mean_policy_losses: -11.647, mean_net_lifetime: 4814.6132, mean_mc_travel_dist: 1337.9016, mean_rewards: 269.9627, total_rewards: 3511.5888, mean_steps: 16.8800, mean_ecr: 0.0474 mean_entropies: 0.4867, took: 84.9780s
2022-10-10 18:44:25,640 [INFO] 	Process 7 - batch 59199: mean_policy_losses: -565.862, mean_net_lifetime: 4717.4515, mean_mc_travel_dist: 1511.6907, mean_rewards: 204.1122, total_rewards: 3239.2622, mean_steps: 22.5700, mean_ecr: 0.0411 mean_entropies: 1.3095, took: 107.6640s
2022-10-10 18:44:53,003 [INFO] 	Process 5 - batch 58299: mean_policy_losses: -184.039, mean_net_lifetime: 6385.0808, mean_mc_travel_dist: 2199.9001, mean_rewards: 275.9415, total_rewards: 4238.5843, mean_steps: 22.4700, mean_ecr: 0.0296 mean_entropies: 0.6796, took: 108.6054s
2022-10-10 18:45:01,746 [INFO] 	Process 4 - batch 65299: mean_policy_losses: 59.688, mean_net_lifetime: 5073.2487, mean_mc_travel_dist: 1435.2934, mean_rewards: 276.2954, total_rewards: 3669.7297, mean_steps: 17.6300, mean_ecr: 0.0469 mean_entropies: 0.6264, took: 90.0725s
2022-10-10 18:45:13,836 [INFO] 	Process 2 - batch 59099: mean_policy_losses: 80.482, mean_net_lifetime: 7175.8592, mean_mc_travel_dist: 2111.8843, mean_rewards: 273.8983, total_rewards: 5093.7147, mean_steps: 25.2400, mean_ecr: 0.0379 mean_entropies: 0.6356, took: 121.4365s
2022-10-10 18:45:34,107 [INFO] 	Process 1 - batch 51999: mean_policy_losses: -78.038, mean_net_lifetime: 5951.9169, mean_mc_travel_dist: 2040.8224, mean_rewards: 243.0219, total_rewards: 3940.4587, mean_steps: 23.7900, mean_ecr: 0.0381 mean_entropies: 0.9431, took: 115.5570s
2022-10-10 18:45:41,955 [INFO] 	Process 3 - batch 60899: mean_policy_losses: 6.385, mean_net_lifetime: 4672.3123, mean_mc_travel_dist: 1276.5135, mean_rewards: 273.4914, total_rewards: 3434.1315, mean_steps: 16.1300, mean_ecr: 0.0480 mean_entropies: 0.5101, took: 83.1918s
2022-10-10 18:46:12,399 [INFO] 	Process 7 - batch 59299: mean_policy_losses: -398.680, mean_net_lifetime: 4930.9428, mean_mc_travel_dist: 1569.7036, mean_rewards: 214.7141, total_rewards: 3391.5580, mean_steps: 22.3900, mean_ecr: 0.0408 mean_entropies: 1.2568, took: 106.7587s
2022-10-10 18:46:37,827 [INFO] 	Process 4 - batch 65399: mean_policy_losses: 108.978, mean_net_lifetime: 5385.5428, mean_mc_travel_dist: 1565.6874, mean_rewards: 275.3868, total_rewards: 3843.6369, mean_steps: 19.0400, mean_ecr: 0.0462 mean_entropies: 0.6363, took: 96.0815s
2022-10-10 18:46:49,245 [INFO] 	Process 5 - batch 58399: mean_policy_losses: -129.876, mean_net_lifetime: 6624.9006, mean_mc_travel_dist: 2268.4241, mean_rewards: 273.4723, total_rewards: 4391.3543, mean_steps: 23.5700, mean_ecr: 0.0296 mean_entropies: 0.6891, took: 116.2419s
2022-10-10 18:47:07,198 [INFO] 	Process 2 - batch 59199: mean_policy_losses: 28.344, mean_net_lifetime: 6806.4942, mean_mc_travel_dist: 1966.5269, mean_rewards: 278.5555, total_rewards: 4876.6637, mean_steps: 23.5000, mean_ecr: 0.0384 mean_entropies: 0.6033, took: 113.3612s
2022-10-10 18:47:07,224 [INFO] 	Process 3 - batch 60999: mean_policy_losses: -3.489, mean_net_lifetime: 4845.7030, mean_mc_travel_dist: 1348.1632, mean_rewards: 269.9430, total_rewards: 3539.1791, mean_steps: 17.0000, mean_ecr: 0.0475 mean_entropies: 0.5010, took: 85.2684s
2022-10-10 18:47:27,494 [INFO] 	Process 1 - batch 52099: mean_policy_losses: -102.779, mean_net_lifetime: 5908.2405, mean_mc_travel_dist: 2031.1849, mean_rewards: 248.8356, total_rewards: 3906.4501, mean_steps: 23.1600, mean_ecr: 0.0381 mean_entropies: 0.9242, took: 113.3876s
2022-10-10 18:47:55,139 [INFO] 	Process 7 - batch 59399: mean_policy_losses: -491.694, mean_net_lifetime: 4719.1564, mean_mc_travel_dist: 1498.8874, mean_rewards: 212.8176, total_rewards: 3257.0617, mean_steps: 21.4500, mean_ecr: 0.0412 mean_entropies: 1.2739, took: 102.7399s
2022-10-10 18:48:09,653 [INFO] 	Process 4 - batch 65499: mean_policy_losses: 123.085, mean_net_lifetime: 5198.2457, mean_mc_travel_dist: 1491.9355, mean_rewards: 275.5031, total_rewards: 3740.2734, mean_steps: 18.2200, mean_ecr: 0.0464 mean_entropies: 0.6653, took: 91.8259s
2022-10-10 18:48:31,939 [INFO] 	Process 3 - batch 61099: mean_policy_losses: 1.045, mean_net_lifetime: 4763.9187, mean_mc_travel_dist: 1291.4294, mean_rewards: 267.9979, total_rewards: 3496.9352, mean_steps: 16.8400, mean_ecr: 0.0480 mean_entropies: 0.4793, took: 84.7155s
2022-10-10 18:48:35,159 [INFO] 	Process 5 - batch 58499: mean_policy_losses: -199.016, mean_net_lifetime: 6028.3078, mean_mc_travel_dist: 2038.7834, mean_rewards: 278.2166, total_rewards: 4031.0841, mean_steps: 21.4500, mean_ecr: 0.0299 mean_entropies: 0.6550, took: 105.9147s
2022-10-10 18:49:03,571 [INFO] 	Process 2 - batch 59299: mean_policy_losses: 33.035, mean_net_lifetime: 7030.1847, mean_mc_travel_dist: 2011.1313, mean_rewards: 275.8277, total_rewards: 5055.2078, mean_steps: 24.5400, mean_ecr: 0.0382 mean_entropies: 0.6063, took: 116.3738s
2022-10-10 18:49:23,545 [INFO] 	Process 1 - batch 52199: mean_policy_losses: -93.711, mean_net_lifetime: 5922.2330, mean_mc_travel_dist: 2025.9936, mean_rewards: 234.7995, total_rewards: 3926.7852, mean_steps: 24.8200, mean_ecr: 0.0381 mean_entropies: 0.9629, took: 116.0508s
2022-10-10 18:49:38,520 [INFO] 	Process 7 - batch 59499: mean_policy_losses: -523.427, mean_net_lifetime: 4872.7496, mean_mc_travel_dist: 1533.8755, mean_rewards: 215.4282, total_rewards: 3374.3844, mean_steps: 22.1400, mean_ecr: 0.0408 mean_entropies: 1.3117, took: 103.3811s
2022-10-10 18:49:52,876 [INFO] 	Process 4 - batch 65599: mean_policy_losses: 114.602, mean_net_lifetime: 6002.2336, mean_mc_travel_dist: 1718.8562, mean_rewards: 276.3935, total_rewards: 4304.1433, mean_steps: 21.5100, mean_ecr: 0.0446 mean_entropies: 0.6254, took: 103.2233s
2022-10-10 18:49:55,494 [INFO] 	Process 3 - batch 61199: mean_policy_losses: -22.065, mean_net_lifetime: 4668.1564, mean_mc_travel_dist: 1260.6102, mean_rewards: 268.1223, total_rewards: 3443.8981, mean_steps: 16.4500, mean_ecr: 0.0480 mean_entropies: 0.4808, took: 83.5550s
2022-10-10 18:50:41,412 [INFO] Process 6 - epoch 55: mean_policy_losses: -233.802, mean_net_lifetime: 2873.9692, mean_mc_travel_dist: 949.4531, mean_entropies: 0.6867, m_net_lifetime_valid: 4446.3706, took: 1363.3486s, (108.5166 / 100 batches)

2022-10-10 18:50:55,102 [INFO] 	Process 2 - batch 59399: mean_policy_losses: -12.358, mean_net_lifetime: 6760.3190, mean_mc_travel_dist: 1933.9102, mean_rewards: 272.9631, total_rewards: 4854.7597, mean_steps: 23.8700, mean_ecr: 0.0385 mean_entropies: 0.5860, took: 111.5311s
2022-10-10 18:51:17,537 [INFO] 	Process 3 - batch 61299: mean_policy_losses: -16.044, mean_net_lifetime: 4662.9804, mean_mc_travel_dist: 1252.0300, mean_rewards: 269.3719, total_rewards: 3438.4013, mean_steps: 16.3700, mean_ecr: 0.0481 mean_entropies: 0.4877, took: 82.0432s
2022-10-10 18:51:22,696 [INFO] 	Process 1 - batch 52299: mean_policy_losses: 3.063, mean_net_lifetime: 6264.5960, mean_mc_travel_dist: 2055.2974, mean_rewards: 238.6857, total_rewards: 4244.2210, mean_steps: 25.7100, mean_ecr: 0.0381 mean_entropies: 1.0121, took: 119.1513s
2022-10-10 18:51:23,895 [INFO] 	Process 7 - batch 59599: mean_policy_losses: -534.891, mean_net_lifetime: 4896.4876, mean_mc_travel_dist: 1538.0767, mean_rewards: 212.5055, total_rewards: 3390.4404, mean_steps: 22.6300, mean_ecr: 0.0408 mean_entropies: 1.3443, took: 105.3746s
2022-10-10 18:51:29,912 [INFO] 	Process 6 - batch 82599: mean_policy_losses: -230.790, mean_net_lifetime: 3168.1816, mean_mc_travel_dist: 815.9709, mean_rewards: 326.6472, total_rewards: 2372.8870, mean_steps: 8.5700, mean_ecr: 0.0559 mean_entropies: 0.2491, took: 659.9488s
2022-10-10 18:51:35,576 [INFO] 	Process 4 - batch 65699: mean_policy_losses: 84.030, mean_net_lifetime: 5879.6717, mean_mc_travel_dist: 1706.6055, mean_rewards: 273.6079, total_rewards: 4204.7535, mean_steps: 21.0200, mean_ecr: 0.0444 mean_entropies: 0.6308, took: 102.6989s
2022-10-10 18:52:22,367 [INFO] 	Process 6 - batch 82699: mean_policy_losses: -207.506, mean_net_lifetime: 3483.7900, mean_mc_travel_dist: 890.3427, mean_rewards: 332.8314, total_rewards: 2611.4551, mean_steps: 9.4400, mean_ecr: 0.0554 mean_entropies: 0.2115, took: 52.4550s
2022-10-10 18:52:41,671 [INFO] 	Process 3 - batch 61399: mean_policy_losses: 11.555, mean_net_lifetime: 4723.2938, mean_mc_travel_dist: 1272.1485, mean_rewards: 269.6537, total_rewards: 3485.3045, mean_steps: 16.5700, mean_ecr: 0.0480 mean_entropies: 0.4681, took: 84.1334s
2022-10-10 18:52:42,641 [INFO] 	Process 2 - batch 59499: mean_policy_losses: -21.177, mean_net_lifetime: 6428.3022, mean_mc_travel_dist: 1806.6110, mean_rewards: 278.8254, total_rewards: 4653.7506, mean_steps: 22.1600, mean_ecr: 0.0391 mean_entropies: 0.5670, took: 107.5388s
2022-10-10 18:53:00,317 [INFO] 	Process 7 - batch 59699: mean_policy_losses: -629.899, mean_net_lifetime: 4508.8964, mean_mc_travel_dist: 1421.4513, mean_rewards: 216.2949, total_rewards: 3116.8805, mean_steps: 20.0400, mean_ecr: 0.0413 mean_entropies: 1.3265, took: 96.4231s
2022-10-10 18:53:12,210 [INFO] 	Process 6 - batch 82799: mean_policy_losses: -229.723, mean_net_lifetime: 3330.3391, mean_mc_travel_dist: 859.0086, mean_rewards: 326.7025, total_rewards: 2495.5028, mean_steps: 9.0800, mean_ecr: 0.0558 mean_entropies: 0.1956, took: 49.8425s
2022-10-10 18:53:13,297 [INFO] 	Process 4 - batch 65799: mean_policy_losses: 61.859, mean_net_lifetime: 5670.3093, mean_mc_travel_dist: 1641.3259, mean_rewards: 285.7433, total_rewards: 4057.9277, mean_steps: 19.4800, mean_ecr: 0.0455 mean_entropies: 0.6054, took: 97.7220s
2022-10-10 18:53:19,244 [INFO] 	Process 1 - batch 52399: mean_policy_losses: -13.926, mean_net_lifetime: 6041.0468, mean_mc_travel_dist: 1994.1962, mean_rewards: 239.6247, total_rewards: 4074.3719, mean_steps: 24.6400, mean_ecr: 0.0382 mean_entropies: 0.9931, took: 116.5475s
2022-10-10 18:54:06,334 [INFO] 	Process 6 - batch 82899: mean_policy_losses: -149.046, mean_net_lifetime: 3637.4296, mean_mc_travel_dist: 937.8533, mean_rewards: 331.9492, total_rewards: 2717.8624, mean_steps: 9.8600, mean_ecr: 0.0549 mean_entropies: 0.1766, took: 54.1241s
2022-10-10 18:54:08,190 [INFO] 	Process 3 - batch 61499: mean_policy_losses: 5.308, mean_net_lifetime: 4753.3114, mean_mc_travel_dist: 1302.6342, mean_rewards: 260.4413, total_rewards: 3487.3311, mean_steps: 17.3200, mean_ecr: 0.0477 mean_entropies: 0.4647, took: 86.5199s
2022-10-10 18:54:34,035 [INFO] 	Process 2 - batch 59599: mean_policy_losses: -26.277, mean_net_lifetime: 6507.9538, mean_mc_travel_dist: 1862.8853, mean_rewards: 270.0722, total_rewards: 4675.3546, mean_steps: 23.2300, mean_ecr: 0.0387 mean_entropies: 0.5387, took: 111.3937s
2022-10-10 18:54:47,360 [INFO] 	Process 7 - batch 59799: mean_policy_losses: -506.520, mean_net_lifetime: 4928.8562, mean_mc_travel_dist: 1544.3242, mean_rewards: 211.5679, total_rewards: 3430.6265, mean_steps: 22.6800, mean_ecr: 0.0412 mean_entropies: 1.3030, took: 107.0424s
2022-10-10 18:54:52,176 [INFO] 	Process 4 - batch 65899: mean_policy_losses: 52.770, mean_net_lifetime: 5830.7653, mean_mc_travel_dist: 1682.6375, mean_rewards: 282.9594, total_rewards: 4170.6655, mean_steps: 20.2300, mean_ecr: 0.0452 mean_entropies: 0.5702, took: 98.8783s
2022-10-10 18:54:59,894 [INFO] 	Process 6 - batch 82999: mean_policy_losses: -102.488, mean_net_lifetime: 3805.1310, mean_mc_travel_dist: 981.3786, mean_rewards: 332.9208, total_rewards: 2840.8922, mean_steps: 10.3500, mean_ecr: 0.0546 mean_entropies: 0.1666, took: 53.5601s
2022-10-10 18:55:14,502 [INFO] 	Process 1 - batch 52499: mean_policy_losses: -29.834, mean_net_lifetime: 5828.7011, mean_mc_travel_dist: 1893.4940, mean_rewards: 230.7285, total_rewards: 3956.5539, mean_steps: 24.5400, mean_ecr: 0.0387 mean_entropies: 1.0192, took: 115.2577s
2022-10-10 18:55:49,790 [INFO] 	Process 6 - batch 83099: mean_policy_losses: -222.247, mean_net_lifetime: 3509.5272, mean_mc_travel_dist: 897.9660, mean_rewards: 329.6167, total_rewards: 2622.8558, mean_steps: 9.5300, mean_ecr: 0.0549 mean_entropies: 0.1741, took: 49.8959s
2022-10-10 18:56:11,569 [INFO] 	Process 2 - batch 59699: mean_policy_losses: -55.374, mean_net_lifetime: 5955.3767, mean_mc_travel_dist: 1682.9481, mean_rewards: 270.5304, total_rewards: 4312.5294, mean_steps: 21.1300, mean_ecr: 0.0393 mean_entropies: 0.5094, took: 97.5344s
2022-10-10 18:56:32,581 [INFO] 	Process 4 - batch 65999: mean_policy_losses: 73.452, mean_net_lifetime: 6205.7574, mean_mc_travel_dist: 1821.9106, mean_rewards: 281.4208, total_rewards: 4408.7282, mean_steps: 21.8200, mean_ecr: 0.0442 mean_entropies: 0.5360, took: 100.4052s
2022-10-10 18:56:39,916 [INFO] 	Process 7 - batch 59899: mean_policy_losses: -357.163, mean_net_lifetime: 5373.2208, mean_mc_travel_dist: 1708.0961, mean_rewards: 205.7961, total_rewards: 3698.3944, mean_steps: 25.6800, mean_ecr: 0.0404 mean_entropies: 1.2994, took: 112.5559s
2022-10-10 18:56:42,832 [INFO] 	Process 6 - batch 83199: mean_policy_losses: -90.994, mean_net_lifetime: 3877.4014, mean_mc_travel_dist: 982.8284, mean_rewards: 335.1670, total_rewards: 2906.9396, mean_steps: 10.5100, mean_ecr: 0.0546 mean_entropies: 0.1483, took: 53.0421s
2022-10-10 18:57:34,165 [INFO] 	Process 6 - batch 83299: mean_policy_losses: -169.711, mean_net_lifetime: 3856.6087, mean_mc_travel_dist: 988.1264, mean_rewards: 336.3721, total_rewards: 2876.5155, mean_steps: 10.4300, mean_ecr: 0.0545 mean_entropies: 0.1550, took: 51.3327s
2022-10-10 18:57:51,202 [INFO] 	Process 2 - batch 59799: mean_policy_losses: -22.677, mean_net_lifetime: 6402.3374, mean_mc_travel_dist: 1850.2689, mean_rewards: 269.1298, total_rewards: 4581.0564, mean_steps: 22.9800, mean_ecr: 0.0388 mean_entropies: 0.5293, took: 99.6327s
2022-10-10 18:58:15,758 [INFO] 	Process 7 - batch 59999: mean_policy_losses: -502.633, mean_net_lifetime: 4672.9319, mean_mc_travel_dist: 1471.2523, mean_rewards: 205.1625, total_rewards: 3237.1300, mean_steps: 22.4100, mean_ecr: 0.0411 mean_entropies: 1.2815, took: 95.8425s
2022-10-10 18:58:23,534 [INFO] 	Process 6 - batch 83399: mean_policy_losses: -155.148, mean_net_lifetime: 3825.4846, mean_mc_travel_dist: 997.1900, mean_rewards: 338.0808, total_rewards: 2850.5232, mean_steps: 10.3200, mean_ecr: 0.0547 mean_entropies: 0.1661, took: 49.3692s
2022-10-10 18:58:42,370 [INFO] Process 5 - epoch 39: mean_policy_losses: -214.556, mean_net_lifetime: 4609.2867, mean_mc_travel_dist: 1900.1358, mean_entropies: 1.2901, m_net_lifetime_valid: 4715.7926, took: 2129.0809s, (153.7890 / 100 batches)

2022-10-10 18:59:13,462 [INFO] 	Process 6 - batch 83499: mean_policy_losses: -120.891, mean_net_lifetime: 3859.6896, mean_mc_travel_dist: 1010.6018, mean_rewards: 337.0090, total_rewards: 2877.8918, mean_steps: 10.4300, mean_ecr: 0.0549 mean_entropies: 0.1802, took: 49.9285s
2022-10-10 18:59:36,738 [INFO] 	Process 2 - batch 59899: mean_policy_losses: 33.689, mean_net_lifetime: 6981.9224, mean_mc_travel_dist: 1993.8632, mean_rewards: 268.8667, total_rewards: 5024.7966, mean_steps: 25.0200, mean_ecr: 0.0383 mean_entropies: 0.5463, took: 105.5367s
2022-10-10 19:00:05,379 [INFO] 	Process 6 - batch 83599: mean_policy_losses: -50.182, mean_net_lifetime: 3986.7011, mean_mc_travel_dist: 1032.3106, mean_rewards: 336.2918, total_rewards: 2977.0996, mean_steps: 10.8400, mean_ecr: 0.0545 mean_entropies: 0.1477, took: 51.9171s
2022-10-10 19:00:15,630 [INFO] 	Process 5 - batch 58599: mean_policy_losses: -164.693, mean_net_lifetime: 6079.6895, mean_mc_travel_dist: 2130.7354, mean_rewards: 280.4287, total_rewards: 4004.1846, mean_steps: 20.8100, mean_ecr: 0.0297 mean_entropies: 0.6556, took: 700.4708s
2022-10-10 19:00:56,529 [INFO] 	Process 6 - batch 83699: mean_policy_losses: -104.838, mean_net_lifetime: 3969.4310, mean_mc_travel_dist: 1043.7543, mean_rewards: 338.9922, total_rewards: 2952.0684, mean_steps: 10.7200, mean_ecr: 0.0546 mean_entropies: 0.1735, took: 51.1491s
2022-10-10 19:01:27,502 [INFO] 	Process 2 - batch 59999: mean_policy_losses: 28.562, mean_net_lifetime: 7135.4302, mean_mc_travel_dist: 2079.7390, mean_rewards: 264.8254, total_rewards: 5091.1073, mean_steps: 26.0200, mean_ecr: 0.0379 mean_entropies: 0.5579, took: 110.7628s
2022-10-10 19:01:46,957 [INFO] 	Process 5 - batch 58699: mean_policy_losses: -184.697, mean_net_lifetime: 6325.9937, mean_mc_travel_dist: 2111.8111, mean_rewards: 287.4971, total_rewards: 4261.8967, mean_steps: 21.2600, mean_ecr: 0.0302 mean_entropies: 0.6880, took: 91.3271s
2022-10-10 19:01:47,057 [INFO] 	Process 6 - batch 83799: mean_policy_losses: -62.064, mean_net_lifetime: 4007.3497, mean_mc_travel_dist: 1058.5819, mean_rewards: 337.1784, total_rewards: 2984.3340, mean_steps: 10.8900, mean_ecr: 0.0546 mean_entropies: 0.1797, took: 50.5283s
2022-10-10 19:02:38,059 [INFO] 	Process 6 - batch 83899: mean_policy_losses: -147.060, mean_net_lifetime: 4015.8525, mean_mc_travel_dist: 1057.9839, mean_rewards: 335.2919, total_rewards: 2986.8952, mean_steps: 10.9600, mean_ecr: 0.0542 mean_entropies: 0.1625, took: 51.0020s
2022-10-10 19:03:00,163 [INFO] Process 3 - epoch 41: mean_policy_losses: 74.919, mean_net_lifetime: 4206.7625, mean_mc_travel_dist: 1372.8809, mean_entropies: 0.9841, m_net_lifetime_valid: 4256.9365, took: 1802.0607s, (146.8388 / 100 batches)

2022-10-10 19:03:20,096 [INFO] 	Process 5 - batch 58799: mean_policy_losses: -157.138, mean_net_lifetime: 6240.3356, mean_mc_travel_dist: 2104.0024, mean_rewards: 276.7051, total_rewards: 4189.2097, mean_steps: 21.9200, mean_ecr: 0.0299 mean_entropies: 0.6357, took: 93.1394s
2022-10-10 19:03:31,463 [INFO] 	Process 6 - batch 83999: mean_policy_losses: -58.674, mean_net_lifetime: 4030.4705, mean_mc_travel_dist: 1044.1346, mean_rewards: 334.6261, total_rewards: 3002.0241, mean_steps: 11.0200, mean_ecr: 0.0545 mean_entropies: 0.1642, took: 53.4044s
2022-10-10 19:04:03,845 [INFO] Process 1 - epoch 35: mean_policy_losses: 37.239, mean_net_lifetime: 4916.8656, mean_mc_travel_dist: 2033.9376, mean_entropies: 1.2503, m_net_lifetime_valid: 4104.9398, took: 2172.0498s, (172.0907 / 100 batches)

2022-10-10 19:04:16,527 [INFO] 	Process 3 - batch 61599: mean_policy_losses: -0.672, mean_net_lifetime: 4679.3266, mean_mc_travel_dist: 1259.0179, mean_rewards: 257.9601, total_rewards: 3451.2576, mean_steps: 17.2000, mean_ecr: 0.0480 mean_entropies: 0.4621, took: 608.3359s
2022-10-10 19:04:59,690 [INFO] 	Process 5 - batch 58899: mean_policy_losses: -97.948, mean_net_lifetime: 6279.5277, mean_mc_travel_dist: 2080.1243, mean_rewards: 276.5534, total_rewards: 4243.4580, mean_steps: 22.1200, mean_ecr: 0.0303 mean_entropies: 0.6260, took: 99.5931s
2022-10-10 19:05:19,210 [INFO] Process 4 - epoch 44: mean_policy_losses: 87.770, mean_net_lifetime: 4021.5030, mean_mc_travel_dist: 1321.8005, mean_entropies: 1.2257, m_net_lifetime_valid: 4301.2958, took: 1909.9776s, (137.0615 / 100 batches)

2022-10-10 19:05:34,744 [INFO] 	Process 3 - batch 61699: mean_policy_losses: 15.665, mean_net_lifetime: 4660.7785, mean_mc_travel_dist: 1246.2180, mean_rewards: 262.3556, total_rewards: 3442.4953, mean_steps: 16.8100, mean_ecr: 0.0484 mean_entropies: 0.4621, took: 78.2176s
2022-10-10 19:05:41,120 [INFO] 	Process 1 - batch 52599: mean_policy_losses: -40.557, mean_net_lifetime: 5706.8455, mean_mc_travel_dist: 1954.3089, mean_rewards: 248.1760, total_rewards: 3779.5381, mean_steps: 22.1600, mean_ecr: 0.0384 mean_entropies: 0.9384, took: 626.6176s
2022-10-10 19:06:38,143 [INFO] 	Process 4 - batch 66099: mean_policy_losses: 131.672, mean_net_lifetime: 4568.9079, mean_mc_travel_dist: 1280.5536, mean_rewards: 265.0362, total_rewards: 3313.0566, mean_steps: 16.3900, mean_ecr: 0.0481 mean_entropies: 0.7560, took: 605.5622s
2022-10-10 19:06:43,891 [INFO] 	Process 5 - batch 58999: mean_policy_losses: -171.626, mean_net_lifetime: 6680.1220, mean_mc_travel_dist: 2190.7129, mean_rewards: 283.0873, total_rewards: 4530.3814, mean_steps: 23.1000, mean_ecr: 0.0305 mean_entropies: 0.6720, took: 104.2017s
2022-10-10 19:06:57,881 [INFO] 	Process 3 - batch 61799: mean_policy_losses: -27.343, mean_net_lifetime: 4815.3089, mean_mc_travel_dist: 1309.7050, mean_rewards: 266.2546, total_rewards: 3537.6418, mean_steps: 17.1400, mean_ecr: 0.0477 mean_entropies: 0.4932, took: 83.1369s
2022-10-10 19:07:33,384 [INFO] 	Process 1 - batch 52699: mean_policy_losses: -107.350, mean_net_lifetime: 5959.8855, mean_mc_travel_dist: 1948.3396, mean_rewards: 235.0435, total_rewards: 4033.9059, mean_steps: 24.7300, mean_ecr: 0.0384 mean_entropies: 1.0395, took: 112.2653s
2022-10-10 19:08:03,128 [INFO] 	Process 4 - batch 66199: mean_policy_losses: 79.173, mean_net_lifetime: 5164.0320, mean_mc_travel_dist: 1447.3356, mean_rewards: 278.5710, total_rewards: 3740.0857, mean_steps: 17.7200, mean_ecr: 0.0469 mean_entropies: 0.6655, took: 84.9848s
2022-10-10 19:08:06,914 [INFO] Process 7 - epoch 40: mean_policy_losses: -327.036, mean_net_lifetime: 4001.3359, mean_mc_travel_dist: 1568.0246, mean_entropies: 1.6345, m_net_lifetime_valid: 4332.6208, took: 2135.7366s, (150.9166 / 100 batches)

2022-10-10 19:08:17,294 [INFO] 	Process 3 - batch 61899: mean_policy_losses: -5.397, mean_net_lifetime: 4720.7110, mean_mc_travel_dist: 1244.0675, mean_rewards: 266.4863, total_rewards: 3506.0535, mean_steps: 16.7600, mean_ecr: 0.0483 mean_entropies: 0.4578, took: 79.4133s
2022-10-10 19:08:38,401 [INFO] 	Process 5 - batch 59099: mean_policy_losses: -227.856, mean_net_lifetime: 6670.7030, mean_mc_travel_dist: 2208.8335, mean_rewards: 263.1048, total_rewards: 4505.9422, mean_steps: 24.7000, mean_ecr: 0.0300 mean_entropies: 0.6748, took: 114.5102s
2022-10-10 19:09:11,317 [INFO] 	Process 1 - batch 52799: mean_policy_losses: -77.883, mean_net_lifetime: 5601.0579, mean_mc_travel_dist: 1883.2056, mean_rewards: 250.7015, total_rewards: 3736.4635, mean_steps: 21.5200, mean_ecr: 0.0387 mean_entropies: 0.9603, took: 97.9319s
2022-10-10 19:09:35,990 [INFO] 	Process 4 - batch 66299: mean_policy_losses: 125.013, mean_net_lifetime: 5622.9824, mean_mc_travel_dist: 1639.4946, mean_rewards: 288.6196, total_rewards: 4021.2418, mean_steps: 18.8100, mean_ecr: 0.0455 mean_entropies: 0.5719, took: 92.8623s
2022-10-10 19:09:36,841 [INFO] 	Process 7 - batch 60099: mean_policy_losses: -592.127, mean_net_lifetime: 4472.6945, mean_mc_travel_dist: 1408.0913, mean_rewards: 224.1258, total_rewards: 3093.9796, mean_steps: 19.0700, mean_ecr: 0.0411 mean_entropies: 1.3018, took: 681.0824s
2022-10-10 19:09:37,579 [INFO] 	Process 3 - batch 61999: mean_policy_losses: 8.593, mean_net_lifetime: 4797.8628, mean_mc_travel_dist: 1290.3065, mean_rewards: 277.9273, total_rewards: 3534.4399, mean_steps: 16.3000, mean_ecr: 0.0480 mean_entropies: 0.4654, took: 80.2847s
2022-10-10 19:10:40,583 [INFO] 	Process 5 - batch 59199: mean_policy_losses: -144.910, mean_net_lifetime: 7215.9832, mean_mc_travel_dist: 2405.3691, mean_rewards: 270.4418, total_rewards: 4848.3241, mean_steps: 26.4900, mean_ecr: 0.0297 mean_entropies: 0.7147, took: 122.1818s
2022-10-10 19:10:59,198 [INFO] 	Process 1 - batch 52899: mean_policy_losses: -57.069, mean_net_lifetime: 5822.2909, mean_mc_travel_dist: 1912.1723, mean_rewards: 241.4849, total_rewards: 3938.1639, mean_steps: 23.4700, mean_ecr: 0.0386 mean_entropies: 0.9525, took: 107.8813s
2022-10-10 19:10:59,750 [INFO] 	Process 3 - batch 62099: mean_policy_losses: 0.821, mean_net_lifetime: 4770.0945, mean_mc_travel_dist: 1315.5882, mean_rewards: 277.6824, total_rewards: 3494.2407, mean_steps: 16.2100, mean_ecr: 0.0478 mean_entropies: 0.4865, took: 82.1712s
2022-10-10 19:11:10,028 [INFO] 	Process 4 - batch 66399: mean_policy_losses: 85.454, mean_net_lifetime: 5691.0227, mean_mc_travel_dist: 1640.3080, mean_rewards: 285.6045, total_rewards: 4077.3807, mean_steps: 19.2500, mean_ecr: 0.0456 mean_entropies: 0.6114, took: 94.0375s
2022-10-10 19:11:13,190 [INFO] 	Process 7 - batch 60199: mean_policy_losses: -553.278, mean_net_lifetime: 4777.0872, mean_mc_travel_dist: 1501.1253, mean_rewards: 223.9697, total_rewards: 3313.3422, mean_steps: 20.5600, mean_ecr: 0.0410 mean_entropies: 1.3163, took: 96.3489s
2022-10-10 19:11:23,087 [INFO] Process 2 - epoch 40: mean_policy_losses: 4.120, mean_net_lifetime: 4417.1479, mean_mc_travel_dist: 1552.9769, mean_entropies: 1.0086, m_net_lifetime_valid: 4527.5068, took: 2242.0540s, (151.2359 / 100 batches)

2022-10-10 19:12:22,231 [INFO] 	Process 3 - batch 62199: mean_policy_losses: 0.699, mean_net_lifetime: 4773.5064, mean_mc_travel_dist: 1312.4332, mean_rewards: 277.4417, total_rewards: 3491.6935, mean_steps: 16.2400, mean_ecr: 0.0475 mean_entropies: 0.5171, took: 82.4809s
2022-10-10 19:12:43,179 [INFO] 	Process 4 - batch 66499: mean_policy_losses: 45.557, mean_net_lifetime: 5409.8183, mean_mc_travel_dist: 1519.1655, mean_rewards: 280.7953, total_rewards: 3925.9388, mean_steps: 18.5700, mean_ecr: 0.0463 mean_entropies: 0.6570, took: 93.1513s
2022-10-10 19:12:47,842 [INFO] 	Process 7 - batch 60299: mean_policy_losses: -705.015, mean_net_lifetime: 4511.8858, mean_mc_travel_dist: 1435.2455, mean_rewards: 220.6209, total_rewards: 3119.7526, mean_steps: 19.6000, mean_ecr: 0.0410 mean_entropies: 1.3638, took: 94.6524s
2022-10-10 19:12:50,875 [INFO] 	Process 5 - batch 59299: mean_policy_losses: -130.283, mean_net_lifetime: 7620.8570, mean_mc_travel_dist: 2495.2982, mean_rewards: 279.7414, total_rewards: 5176.9012, mean_steps: 26.7000, mean_ecr: 0.0301 mean_entropies: 0.7448, took: 130.2920s
2022-10-10 19:12:55,894 [INFO] 	Process 1 - batch 52999: mean_policy_losses: -67.360, mean_net_lifetime: 6048.8418, mean_mc_travel_dist: 1995.3421, mean_rewards: 233.6610, total_rewards: 4090.3393, mean_steps: 25.0000, mean_ecr: 0.0383 mean_entropies: 1.0118, took: 116.6965s
2022-10-10 19:13:17,689 [INFO] 	Process 2 - batch 60099: mean_policy_losses: -51.442, mean_net_lifetime: 6476.7073, mean_mc_travel_dist: 1875.8650, mean_rewards: 262.2965, total_rewards: 4633.0034, mean_steps: 23.7900, mean_ecr: 0.0386 mean_entropies: 0.6306, took: 710.1876s
2022-10-10 19:13:26,427 [INFO] Process 6 - epoch 56: mean_policy_losses: -232.128, mean_net_lifetime: 2889.7476, mean_mc_travel_dist: 949.8771, mean_entropies: 0.6776, m_net_lifetime_valid: 4186.8117, took: 1365.0130s, (108.2238 / 100 batches)

2022-10-10 19:13:46,645 [INFO] 	Process 3 - batch 62299: mean_policy_losses: 1.437, mean_net_lifetime: 4813.2151, mean_mc_travel_dist: 1284.5660, mean_rewards: 276.5062, total_rewards: 3559.2464, mean_steps: 16.4700, mean_ecr: 0.0478 mean_entropies: 0.4620, took: 84.4136s
2022-10-10 19:14:21,804 [INFO] 	Process 6 - batch 84099: mean_policy_losses: -143.100, mean_net_lifetime: 3699.9493, mean_mc_travel_dist: 947.6723, mean_rewards: 334.1416, total_rewards: 2765.7058, mean_steps: 10.0200, mean_ecr: 0.0546 mean_entropies: 0.1814, took: 650.3409s
2022-10-10 19:14:23,093 [INFO] 	Process 4 - batch 66599: mean_policy_losses: 81.968, mean_net_lifetime: 5684.6526, mean_mc_travel_dist: 1634.3737, mean_rewards: 282.4560, total_rewards: 4077.8846, mean_steps: 19.6100, mean_ecr: 0.0453 mean_entropies: 0.5886, took: 99.9146s
2022-10-10 19:14:35,610 [INFO] 	Process 7 - batch 60399: mean_policy_losses: -515.993, mean_net_lifetime: 4817.1416, mean_mc_travel_dist: 1478.0200, mean_rewards: 211.4213, total_rewards: 3370.0623, mean_steps: 22.2200, mean_ecr: 0.0409 mean_entropies: 1.3737, took: 107.7672s
2022-10-10 19:15:00,815 [INFO] 	Process 1 - batch 53099: mean_policy_losses: -74.568, mean_net_lifetime: 5835.1182, mean_mc_travel_dist: 1869.7613, mean_rewards: 225.9583, total_rewards: 3989.7656, mean_steps: 25.1000, mean_ecr: 0.0388 mean_entropies: 1.0286, took: 124.9209s
2022-10-10 19:15:11,547 [INFO] 	Process 5 - batch 59399: mean_policy_losses: -56.769, mean_net_lifetime: 7975.0345, mean_mc_travel_dist: 2598.5155, mean_rewards: 277.1264, total_rewards: 5404.8542, mean_steps: 28.5300, mean_ecr: 0.0298 mean_entropies: 0.7349, took: 140.6717s
2022-10-10 19:15:14,559 [INFO] 	Process 3 - batch 62399: mean_policy_losses: 5.782, mean_net_lifetime: 4852.0736, mean_mc_travel_dist: 1300.9950, mean_rewards: 275.1135, total_rewards: 3578.1016, mean_steps: 16.7000, mean_ecr: 0.0477 mean_entropies: 0.4596, took: 87.9145s
2022-10-10 19:15:15,881 [INFO] 	Process 2 - batch 60199: mean_policy_losses: -36.053, mean_net_lifetime: 6672.0369, mean_mc_travel_dist: 1920.2229, mean_rewards: 268.7137, total_rewards: 4778.5609, mean_steps: 23.9600, mean_ecr: 0.0385 mean_entropies: 0.6046, took: 118.1911s
2022-10-10 19:15:19,374 [INFO] 	Process 6 - batch 84199: mean_policy_losses: -176.931, mean_net_lifetime: 3802.9983, mean_mc_travel_dist: 979.9651, mean_rewards: 336.0182, total_rewards: 2835.0083, mean_steps: 10.2800, mean_ecr: 0.0547 mean_entropies: 0.1602, took: 57.5694s
2022-10-10 19:16:03,489 [INFO] 	Process 4 - batch 66699: mean_policy_losses: 63.393, mean_net_lifetime: 5671.7274, mean_mc_travel_dist: 1599.2847, mean_rewards: 282.4822, total_rewards: 4099.8027, mean_steps: 19.4200, mean_ecr: 0.0454 mean_entropies: 0.6211, took: 100.3959s
2022-10-10 19:16:19,521 [INFO] 	Process 6 - batch 84299: mean_policy_losses: -84.242, mean_net_lifetime: 4000.8915, mean_mc_travel_dist: 1040.1436, mean_rewards: 337.5413, total_rewards: 2980.6526, mean_steps: 10.8700, mean_ecr: 0.0544 mean_entropies: 0.1628, took: 60.1480s
2022-10-10 19:16:27,198 [INFO] 	Process 7 - batch 60499: mean_policy_losses: -564.812, mean_net_lifetime: 4789.7360, mean_mc_travel_dist: 1503.1493, mean_rewards: 208.5023, total_rewards: 3325.2042, mean_steps: 22.3300, mean_ecr: 0.0410 mean_entropies: 1.3756, took: 111.5888s
2022-10-10 19:16:42,358 [INFO] 	Process 3 - batch 62499: mean_policy_losses: 9.689, mean_net_lifetime: 4737.1973, mean_mc_travel_dist: 1272.7200, mean_rewards: 269.7324, total_rewards: 3494.2654, mean_steps: 16.6100, mean_ecr: 0.0480 mean_entropies: 0.4541, took: 87.7990s
2022-10-10 19:17:08,171 [INFO] 	Process 1 - batch 53199: mean_policy_losses: -71.240, mean_net_lifetime: 5914.0505, mean_mc_travel_dist: 1942.5307, mean_rewards: 228.2788, total_rewards: 3998.1467, mean_steps: 25.4100, mean_ecr: 0.0384 mean_entropies: 1.0030, took: 127.3555s
2022-10-10 19:17:15,428 [INFO] 	Process 6 - batch 84399: mean_policy_losses: -191.520, mean_net_lifetime: 3627.8399, mean_mc_travel_dist: 967.8010, mean_rewards: 328.4648, total_rewards: 2703.2471, mean_steps: 9.9000, mean_ecr: 0.0552 mean_entropies: 0.1909, took: 55.9068s
2022-10-10 19:17:22,843 [INFO] 	Process 2 - batch 60299: mean_policy_losses: -23.781, mean_net_lifetime: 6957.4032, mean_mc_travel_dist: 2019.0591, mean_rewards: 263.5740, total_rewards: 4978.0242, mean_steps: 25.5500, mean_ecr: 0.0382 mean_entropies: 0.5679, took: 126.9622s
2022-10-10 19:17:36,400 [INFO] 	Process 5 - batch 59499: mean_policy_losses: -80.136, mean_net_lifetime: 7901.3292, mean_mc_travel_dist: 2722.3199, mean_rewards: 264.6273, total_rewards: 5227.5956, mean_steps: 29.4200, mean_ecr: 0.0286 mean_entropies: 0.7066, took: 144.8534s
2022-10-10 19:17:49,125 [INFO] 	Process 4 - batch 66799: mean_policy_losses: 113.161, mean_net_lifetime: 6030.8607, mean_mc_travel_dist: 1673.7733, mean_rewards: 288.5416, total_rewards: 4381.6223, mean_steps: 20.3600, mean_ecr: 0.0447 mean_entropies: 0.6003, took: 105.6364s
2022-10-10 19:18:09,445 [INFO] 	Process 3 - batch 62599: mean_policy_losses: 0.571, mean_net_lifetime: 4711.4057, mean_mc_travel_dist: 1280.6042, mean_rewards: 269.9505, total_rewards: 3472.4275, mean_steps: 16.5300, mean_ecr: 0.0478 mean_entropies: 0.4619, took: 87.0868s
2022-10-10 19:18:12,100 [INFO] 	Process 6 - batch 84499: mean_policy_losses: -130.897, mean_net_lifetime: 3754.7986, mean_mc_travel_dist: 1004.8384, mean_rewards: 336.2134, total_rewards: 2794.9984, mean_steps: 10.1600, mean_ecr: 0.0551 mean_entropies: 0.1880, took: 56.6711s
2022-10-10 19:18:16,313 [INFO] 	Process 7 - batch 60599: mean_policy_losses: -506.923, mean_net_lifetime: 4861.0160, mean_mc_travel_dist: 1532.4130, mean_rewards: 212.0614, total_rewards: 3368.7121, mean_steps: 22.1600, mean_ecr: 0.0411 mean_entropies: 1.3528, took: 109.1147s
2022-10-10 19:19:03,604 [INFO] 	Process 1 - batch 53299: mean_policy_losses: -71.537, mean_net_lifetime: 5720.4012, mean_mc_travel_dist: 1907.1925, mean_rewards: 238.1653, total_rewards: 3830.1490, mean_steps: 23.1900, mean_ecr: 0.0385 mean_entropies: 0.9234, took: 115.4331s
2022-10-10 19:19:07,100 [INFO] 	Process 6 - batch 84599: mean_policy_losses: -146.199, mean_net_lifetime: 3709.4418, mean_mc_travel_dist: 991.6750, mean_rewards: 336.6449, total_rewards: 2756.9220, mean_steps: 10.0200, mean_ecr: 0.0552 mean_entropies: 0.1959, took: 55.0001s
2022-10-10 19:19:25,396 [INFO] 	Process 2 - batch 60399: mean_policy_losses: -26.008, mean_net_lifetime: 6631.6717, mean_mc_travel_dist: 1895.9320, mean_rewards: 264.8515, total_rewards: 4776.5524, mean_steps: 24.1900, mean_ecr: 0.0386 mean_entropies: 0.5704, took: 122.5532s
2022-10-10 19:19:30,754 [INFO] 	Process 4 - batch 66899: mean_policy_losses: 39.068, mean_net_lifetime: 5731.9831, mean_mc_travel_dist: 1619.3001, mean_rewards: 284.0594, total_rewards: 4142.8241, mean_steps: 19.6600, mean_ecr: 0.0457 mean_entropies: 0.6116, took: 101.6282s
2022-10-10 19:19:34,949 [INFO] 	Process 3 - batch 62699: mean_policy_losses: 9.351, mean_net_lifetime: 4760.3385, mean_mc_travel_dist: 1288.9798, mean_rewards: 275.4082, total_rewards: 3499.6726, mean_steps: 16.3300, mean_ecr: 0.0478 mean_entropies: 0.4619, took: 85.5043s
2022-10-10 19:19:59,347 [INFO] 	Process 5 - batch 59599: mean_policy_losses: -133.077, mean_net_lifetime: 7885.5699, mean_mc_travel_dist: 2625.0794, mean_rewards: 272.9386, total_rewards: 5310.7014, mean_steps: 28.8100, mean_ecr: 0.0296 mean_entropies: 0.7128, took: 142.9463s
2022-10-10 19:20:06,212 [INFO] 	Process 6 - batch 84699: mean_policy_losses: -119.165, mean_net_lifetime: 3881.6161, mean_mc_travel_dist: 1029.6212, mean_rewards: 336.3590, total_rewards: 2887.5610, mean_steps: 10.4700, mean_ecr: 0.0547 mean_entropies: 0.1931, took: 59.1125s
2022-10-10 19:20:08,476 [INFO] 	Process 7 - batch 60699: mean_policy_losses: -465.016, mean_net_lifetime: 5124.4879, mean_mc_travel_dist: 1595.2641, mean_rewards: 217.9279, total_rewards: 3567.8522, mean_steps: 22.6100, mean_ecr: 0.0406 mean_entropies: 1.3790, took: 112.1634s
2022-10-10 19:21:01,543 [INFO] 	Process 6 - batch 84799: mean_policy_losses: -119.531, mean_net_lifetime: 3731.4921, mean_mc_travel_dist: 990.9377, mean_rewards: 337.6984, total_rewards: 2779.9123, mean_steps: 9.9800, mean_ecr: 0.0555 mean_entropies: 0.2008, took: 55.3305s
2022-10-10 19:21:02,788 [INFO] 	Process 3 - batch 62799: mean_policy_losses: 0.655, mean_net_lifetime: 4771.8951, mean_mc_travel_dist: 1321.0248, mean_rewards: 274.8460, total_rewards: 3489.7926, mean_steps: 16.4100, mean_ecr: 0.0476 mean_entropies: 0.4720, took: 87.8382s
2022-10-10 19:21:04,318 [INFO] 	Process 4 - batch 66999: mean_policy_losses: 32.178, mean_net_lifetime: 5239.6987, mean_mc_travel_dist: 1467.6714, mean_rewards: 282.3977, total_rewards: 3802.2534, mean_steps: 17.8100, mean_ecr: 0.0467 mean_entropies: 0.7036, took: 93.5633s
2022-10-10 19:21:10,211 [INFO] 	Process 1 - batch 53399: mean_policy_losses: -34.979, mean_net_lifetime: 6055.4920, mean_mc_travel_dist: 2022.3120, mean_rewards: 229.6223, total_rewards: 4059.4473, mean_steps: 25.8000, mean_ecr: 0.0381 mean_entropies: 0.9449, took: 126.6072s
2022-10-10 19:21:31,239 [INFO] 	Process 2 - batch 60499: mean_policy_losses: -24.221, mean_net_lifetime: 6979.3040, mean_mc_travel_dist: 2049.8295, mean_rewards: 263.7463, total_rewards: 4972.0990, mean_steps: 25.5900, mean_ecr: 0.0380 mean_entropies: 0.6082, took: 125.8426s
2022-10-10 19:21:59,063 [INFO] 	Process 6 - batch 84899: mean_policy_losses: -160.639, mean_net_lifetime: 3917.6583, mean_mc_travel_dist: 1047.6518, mean_rewards: 339.8992, total_rewards: 2918.8817, mean_steps: 10.4800, mean_ecr: 0.0551 mean_entropies: 0.1845, took: 57.5205s
2022-10-10 19:22:06,299 [INFO] 	Process 7 - batch 60799: mean_policy_losses: -375.086, mean_net_lifetime: 5281.4432, mean_mc_travel_dist: 1636.2179, mean_rewards: 213.7251, total_rewards: 3690.3054, mean_steps: 23.9400, mean_ecr: 0.0406 mean_entropies: 1.3911, took: 117.8228s
2022-10-10 19:22:14,590 [INFO] 	Process 5 - batch 59699: mean_policy_losses: -162.295, mean_net_lifetime: 7290.1045, mean_mc_travel_dist: 2436.5411, mean_rewards: 270.6415, total_rewards: 4893.1825, mean_steps: 26.6200, mean_ecr: 0.0296 mean_entropies: 0.7087, took: 135.2431s
2022-10-10 19:22:32,500 [INFO] 	Process 3 - batch 62899: mean_policy_losses: 0.632, mean_net_lifetime: 4811.2623, mean_mc_travel_dist: 1312.2030, mean_rewards: 268.3302, total_rewards: 3540.0089, mean_steps: 17.0000, mean_ecr: 0.0477 mean_entropies: 0.4696, took: 89.7130s
2022-10-10 19:22:53,202 [INFO] 	Process 4 - batch 67099: mean_policy_losses: 98.503, mean_net_lifetime: 6130.6309, mean_mc_travel_dist: 1770.7748, mean_rewards: 283.1464, total_rewards: 4391.1558, mean_steps: 21.2800, mean_ecr: 0.0445 mean_entropies: 0.6566, took: 108.8853s
2022-10-10 19:22:57,835 [INFO] 	Process 6 - batch 84999: mean_policy_losses: -107.161, mean_net_lifetime: 3933.5541, mean_mc_travel_dist: 1058.7960, mean_rewards: 336.5909, total_rewards: 2930.6272, mean_steps: 10.6200, mean_ecr: 0.0549 mean_entropies: 0.1726, took: 58.7724s
2022-10-10 19:23:11,520 [INFO] 	Process 1 - batch 53499: mean_policy_losses: -94.934, mean_net_lifetime: 5661.6918, mean_mc_travel_dist: 1903.9405, mean_rewards: 230.5599, total_rewards: 3782.8785, mean_steps: 24.0800, mean_ecr: 0.0385 mean_entropies: 0.9224, took: 121.3083s
2022-10-10 19:23:35,438 [INFO] 	Process 2 - batch 60599: mean_policy_losses: -24.308, mean_net_lifetime: 6778.2077, mean_mc_travel_dist: 1934.6060, mean_rewards: 261.3097, total_rewards: 4868.5413, mean_steps: 24.9900, mean_ecr: 0.0384 mean_entropies: 0.5330, took: 124.2000s
2022-10-10 19:23:55,426 [INFO] 	Process 6 - batch 85099: mean_policy_losses: -103.152, mean_net_lifetime: 3797.4377, mean_mc_travel_dist: 1024.0352, mean_rewards: 334.4363, total_rewards: 2834.4342, mean_steps: 10.2600, mean_ecr: 0.0554 mean_entropies: 0.1667, took: 57.5904s
2022-10-10 19:23:58,585 [INFO] 	Process 7 - batch 60899: mean_policy_losses: -496.527, mean_net_lifetime: 4978.4173, mean_mc_travel_dist: 1566.8490, mean_rewards: 213.6704, total_rewards: 3445.5580, mean_steps: 22.7100, mean_ecr: 0.0409 mean_entropies: 1.4124, took: 112.2854s
2022-10-10 19:24:01,736 [INFO] 	Process 3 - batch 62999: mean_policy_losses: 4.401, mean_net_lifetime: 4751.8057, mean_mc_travel_dist: 1301.2347, mean_rewards: 266.0264, total_rewards: 3486.7493, mean_steps: 16.9300, mean_ecr: 0.0475 mean_entropies: 0.4572, took: 89.2351s
2022-10-10 19:24:36,500 [INFO] 	Process 4 - batch 67199: mean_policy_losses: 87.201, mean_net_lifetime: 5936.9029, mean_mc_travel_dist: 1666.0171, mean_rewards: 285.0747, total_rewards: 4298.6938, mean_steps: 20.3100, mean_ecr: 0.0453 mean_entropies: 0.6427, took: 103.2973s
2022-10-10 19:24:38,841 [INFO] 	Process 5 - batch 59799: mean_policy_losses: -94.179, mean_net_lifetime: 7901.9464, mean_mc_travel_dist: 2576.3500, mean_rewards: 269.3407, total_rewards: 5370.0350, mean_steps: 28.9700, mean_ecr: 0.0297 mean_entropies: 0.6890, took: 144.2513s
2022-10-10 19:24:53,076 [INFO] 	Process 6 - batch 85199: mean_policy_losses: -51.260, mean_net_lifetime: 4061.6871, mean_mc_travel_dist: 1088.4752, mean_rewards: 340.5501, total_rewards: 3032.6146, mean_steps: 10.8800, mean_ecr: 0.0550 mean_entropies: 0.1716, took: 57.6506s
2022-10-10 19:25:19,904 [INFO] 	Process 1 - batch 53599: mean_policy_losses: -66.220, mean_net_lifetime: 6020.9362, mean_mc_travel_dist: 2006.5696, mean_rewards: 222.8741, total_rewards: 4040.2113, mean_steps: 26.7700, mean_ecr: 0.0381 mean_entropies: 0.9221, took: 128.3839s
2022-10-10 19:25:39,963 [INFO] 	Process 2 - batch 60699: mean_policy_losses: -31.344, mean_net_lifetime: 6972.6790, mean_mc_travel_dist: 2054.3032, mean_rewards: 260.8917, total_rewards: 4946.8074, mean_steps: 25.8800, mean_ecr: 0.0379 mean_entropies: 0.5514, took: 124.5246s
2022-10-10 19:25:49,076 [INFO] 	Process 6 - batch 85299: mean_policy_losses: -142.409, mean_net_lifetime: 3899.8199, mean_mc_travel_dist: 1037.0447, mean_rewards: 343.3481, total_rewards: 2903.1910, mean_steps: 10.3300, mean_ecr: 0.0552 mean_entropies: 0.1596, took: 55.9991s
2022-10-10 19:25:51,147 [INFO] 	Process 7 - batch 60999: mean_policy_losses: -407.517, mean_net_lifetime: 5252.8523, mean_mc_travel_dist: 1637.7340, mean_rewards: 214.4176, total_rewards: 3655.3413, mean_steps: 23.5400, mean_ecr: 0.0406 mean_entropies: 1.3853, took: 112.5627s
2022-10-10 19:26:13,535 [INFO] 	Process 4 - batch 67299: mean_policy_losses: 75.246, mean_net_lifetime: 5729.4034, mean_mc_travel_dist: 1591.3546, mean_rewards: 289.8906, total_rewards: 4159.3326, mean_steps: 19.0200, mean_ecr: 0.0458 mean_entropies: 0.6589, took: 97.0356s
2022-10-10 19:26:39,709 [INFO] 	Process 5 - batch 59899: mean_policy_losses: -188.059, mean_net_lifetime: 6825.3884, mean_mc_travel_dist: 2205.8712, mean_rewards: 270.4506, total_rewards: 4660.4369, mean_steps: 24.6400, mean_ecr: 0.0300 mean_entropies: 0.6385, took: 120.8680s
2022-10-10 19:26:45,238 [INFO] 	Process 6 - batch 85399: mean_policy_losses: -99.222, mean_net_lifetime: 3939.9495, mean_mc_travel_dist: 1049.3324, mean_rewards: 340.0324, total_rewards: 2935.6998, mean_steps: 10.5400, mean_ecr: 0.0552 mean_entropies: 0.1594, took: 56.1624s
2022-10-10 19:27:21,984 [INFO] 	Process 1 - batch 53699: mean_policy_losses: -69.188, mean_net_lifetime: 5824.0299, mean_mc_travel_dist: 1980.1333, mean_rewards: 219.5584, total_rewards: 3870.3918, mean_steps: 25.9800, mean_ecr: 0.0382 mean_entropies: 0.8837, took: 122.0811s
2022-10-10 19:27:39,617 [INFO] 	Process 2 - batch 60799: mean_policy_losses: -54.126, mean_net_lifetime: 6646.4482, mean_mc_travel_dist: 1938.6843, mean_rewards: 255.9300, total_rewards: 4748.1958, mean_steps: 24.9900, mean_ecr: 0.0383 mean_entropies: 0.5515, took: 119.6538s
2022-10-10 19:27:43,265 [INFO] 	Process 7 - batch 61099: mean_policy_losses: -477.590, mean_net_lifetime: 5059.1234, mean_mc_travel_dist: 1623.1892, mean_rewards: 209.2484, total_rewards: 3467.8874, mean_steps: 23.3800, mean_ecr: 0.0406 mean_entropies: 1.3965, took: 112.1176s
2022-10-10 19:27:44,215 [INFO] 	Process 6 - batch 85499: mean_policy_losses: -65.371, mean_net_lifetime: 4074.0362, mean_mc_travel_dist: 1096.2287, mean_rewards: 340.8522, total_rewards: 3042.6706, mean_steps: 10.9400, mean_ecr: 0.0547 mean_entropies: 0.1488, took: 58.9776s
2022-10-10 19:27:55,246 [INFO] 	Process 4 - batch 67399: mean_policy_losses: 107.489, mean_net_lifetime: 6019.9593, mean_mc_travel_dist: 1753.0782, mean_rewards: 287.2621, total_rewards: 4288.4416, mean_steps: 20.4600, mean_ecr: 0.0447 mean_entropies: 0.6116, took: 101.7114s
2022-10-10 19:29:06,050 [INFO] 	Process 5 - batch 59999: mean_policy_losses: -70.114, mean_net_lifetime: 8441.5057, mean_mc_travel_dist: 2839.9260, mean_rewards: 268.9084, total_rewards: 5641.8273, mean_steps: 31.3200, mean_ecr: 0.0293 mean_entropies: 0.6525, took: 146.3406s
2022-10-10 19:29:15,840 [INFO] 	Process 1 - batch 53799: mean_policy_losses: -43.554, mean_net_lifetime: 5849.8198, mean_mc_travel_dist: 1975.7009, mean_rewards: 228.8637, total_rewards: 3897.2994, mean_steps: 24.8900, mean_ecr: 0.0383 mean_entropies: 0.9074, took: 113.8559s
2022-10-10 19:29:18,602 [INFO] 	Process 7 - batch 61199: mean_policy_losses: -568.047, mean_net_lifetime: 4582.8359, mean_mc_travel_dist: 1433.8183, mean_rewards: 218.5567, total_rewards: 3171.9417, mean_steps: 20.2200, mean_ecr: 0.0411 mean_entropies: 1.4136, took: 95.3376s
2022-10-10 19:29:37,985 [INFO] 	Process 2 - batch 60899: mean_policy_losses: -32.383, mean_net_lifetime: 6762.1878, mean_mc_travel_dist: 2014.0258, mean_rewards: 252.4391, total_rewards: 4788.7292, mean_steps: 25.8100, mean_ecr: 0.0380 mean_entropies: 0.5906, took: 118.3685s
2022-10-10 19:29:42,469 [INFO] 	Process 4 - batch 67499: mean_policy_losses: 124.531, mean_net_lifetime: 6394.4768, mean_mc_travel_dist: 1866.7239, mean_rewards: 280.6128, total_rewards: 4558.7321, mean_steps: 22.5800, mean_ecr: 0.0444 mean_entropies: 0.5815, took: 107.2219s
2022-10-10 19:30:53,615 [INFO] 	Process 7 - batch 61299: mean_policy_losses: -503.086, mean_net_lifetime: 4760.1564, mean_mc_travel_dist: 1517.0009, mean_rewards: 211.7270, total_rewards: 3280.4751, mean_steps: 21.8100, mean_ecr: 0.0408 mean_entropies: 1.3812, took: 95.0129s
2022-10-10 19:31:06,794 [INFO] 	Process 1 - batch 53899: mean_policy_losses: -4.698, mean_net_lifetime: 5860.8164, mean_mc_travel_dist: 2001.7684, mean_rewards: 228.2054, total_rewards: 3887.7376, mean_steps: 25.1500, mean_ecr: 0.0381 mean_entropies: 0.8734, took: 110.9533s
2022-10-10 19:31:31,317 [INFO] 	Process 2 - batch 60999: mean_policy_losses: 14.896, mean_net_lifetime: 7045.0564, mean_mc_travel_dist: 2070.8369, mean_rewards: 258.1751, total_rewards: 5009.3095, mean_steps: 26.3200, mean_ecr: 0.0379 mean_entropies: 0.5860, took: 113.3320s
2022-10-10 19:32:31,949 [INFO] 	Process 7 - batch 61399: mean_policy_losses: -336.871, mean_net_lifetime: 5064.5639, mean_mc_travel_dist: 1654.4145, mean_rewards: 212.0494, total_rewards: 3456.0158, mean_steps: 22.9100, mean_ecr: 0.0407 mean_entropies: 1.3997, took: 98.3335s
2022-10-10 19:32:58,614 [INFO] 	Process 1 - batch 53999: mean_policy_losses: -28.505, mean_net_lifetime: 5892.5960, mean_mc_travel_dist: 1964.1598, mean_rewards: 220.9269, total_rewards: 3954.6455, mean_steps: 26.0400, mean_ecr: 0.0385 mean_entropies: 0.9452, took: 111.8203s
2022-10-10 19:33:26,926 [INFO] 	Process 2 - batch 61099: mean_policy_losses: 5.433, mean_net_lifetime: 7302.6085, mean_mc_travel_dist: 2151.1330, mean_rewards: 259.5248, total_rewards: 5188.2981, mean_steps: 27.2200, mean_ecr: 0.0377 mean_entropies: 0.5871, took: 115.6085s
2022-10-10 19:33:29,248 [INFO] Process 3 - epoch 42: mean_policy_losses: 73.175, mean_net_lifetime: 4219.9774, mean_mc_travel_dist: 1370.8911, mean_entropies: 0.9719, m_net_lifetime_valid: 4385.1412, took: 1829.0833s, (146.1906 / 100 batches)

2022-10-10 19:34:13,494 [INFO] 	Process 7 - batch 61499: mean_policy_losses: -351.136, mean_net_lifetime: 5104.5324, mean_mc_travel_dist: 1682.2342, mean_rewards: 204.5788, total_rewards: 3462.0209, mean_steps: 24.2000, mean_ecr: 0.0409 mean_entropies: 1.3829, took: 101.5451s
2022-10-10 19:34:44,927 [INFO] 	Process 3 - batch 63099: mean_policy_losses: -2.391, mean_net_lifetime: 4801.2344, mean_mc_travel_dist: 1331.4661, mean_rewards: 264.5471, total_rewards: 3507.1480, mean_steps: 17.2000, mean_ecr: 0.0474 mean_entropies: 0.4746, took: 643.1919s
2022-10-10 19:35:11,184 [INFO] 	Process 2 - batch 61199: mean_policy_losses: -42.212, mean_net_lifetime: 6828.6114, mean_mc_travel_dist: 1945.1856, mean_rewards: 265.2410, total_rewards: 4908.3041, mean_steps: 24.9400, mean_ecr: 0.0384 mean_entropies: 0.5231, took: 104.2586s
2022-10-10 19:35:55,512 [INFO] 	Process 3 - batch 63199: mean_policy_losses: -21.364, mean_net_lifetime: 4776.5012, mean_mc_travel_dist: 1329.0179, mean_rewards: 273.2757, total_rewards: 3492.0234, mean_steps: 16.5200, mean_ecr: 0.0474 mean_entropies: 0.4687, took: 70.5849s
2022-10-10 19:36:54,894 [INFO] 	Process 2 - batch 61299: mean_policy_losses: -19.541, mean_net_lifetime: 7128.1964, mean_mc_travel_dist: 2021.5781, mean_rewards: 271.8504, total_rewards: 5137.2394, mean_steps: 25.2900, mean_ecr: 0.0382 mean_entropies: 0.5631, took: 103.7098s
2022-10-10 19:37:07,388 [INFO] 	Process 3 - batch 63299: mean_policy_losses: -12.303, mean_net_lifetime: 4831.6794, mean_mc_travel_dist: 1313.3790, mean_rewards: 275.7867, total_rewards: 3554.6081, mean_steps: 16.5500, mean_ecr: 0.0477 mean_entropies: 0.4775, took: 71.8751s
2022-10-10 19:37:11,055 [INFO] Process 6 - epoch 57: mean_policy_losses: -230.209, mean_net_lifetime: 2906.6914, mean_mc_travel_dist: 951.1708, mean_entropies: 0.6687, m_net_lifetime_valid: 4405.0691, took: 1424.6247s, (108.0245 / 100 batches)

2022-10-10 19:37:58,159 [INFO] Process 4 - epoch 45: mean_policy_losses: 87.730, mean_net_lifetime: 4058.1023, mean_mc_travel_dist: 1328.2334, mean_entropies: 1.2126, m_net_lifetime_valid: 4220.3735, took: 1958.9466s, (136.9638 / 100 batches)

2022-10-10 19:38:01,228 [INFO] 	Process 6 - batch 85599: mean_policy_losses: -112.860, mean_net_lifetime: 3823.4939, mean_mc_travel_dist: 1010.3523, mean_rewards: 340.1931, total_rewards: 2856.6648, mean_steps: 10.2200, mean_ecr: 0.0552 mean_entropies: 0.1845, took: 617.0128s
2022-10-10 19:38:26,575 [INFO] 	Process 3 - batch 63399: mean_policy_losses: -8.038, mean_net_lifetime: 4869.9284, mean_mc_travel_dist: 1331.7020, mean_rewards: 269.0553, total_rewards: 3578.6955, mean_steps: 17.1800, mean_ecr: 0.0475 mean_entropies: 0.4862, took: 79.1878s
2022-10-10 19:38:29,026 [INFO] Process 5 - epoch 40: mean_policy_losses: -212.631, mean_net_lifetime: 4672.9447, mean_mc_travel_dist: 1912.1849, mean_entropies: 1.2750, m_net_lifetime_valid: 4915.6161, took: 2386.6536s, (153.9954 / 100 batches)

2022-10-10 19:38:45,714 [INFO] 	Process 2 - batch 61399: mean_policy_losses: -26.565, mean_net_lifetime: 7102.7961, mean_mc_travel_dist: 2045.1019, mean_rewards: 266.2297, total_rewards: 5087.6686, mean_steps: 25.7500, mean_ecr: 0.0381 mean_entropies: 0.5677, took: 110.8206s
2022-10-10 19:38:54,702 [INFO] 	Process 6 - batch 85699: mean_policy_losses: -93.708, mean_net_lifetime: 3919.5431, mean_mc_travel_dist: 1048.4418, mean_rewards: 340.3304, total_rewards: 2925.3087, mean_steps: 10.4900, mean_ecr: 0.0552 mean_entropies: 0.1750, took: 53.4740s
2022-10-10 19:39:38,752 [INFO] 	Process 4 - batch 67599: mean_policy_losses: 80.576, mean_net_lifetime: 6140.3890, mean_mc_travel_dist: 1798.7665, mean_rewards: 280.9322, total_rewards: 4375.1210, mean_steps: 21.5800, mean_ecr: 0.0443 mean_entropies: 0.6242, took: 596.2841s
2022-10-10 19:39:49,445 [INFO] 	Process 3 - batch 63499: mean_policy_losses: -21.002, mean_net_lifetime: 4826.9505, mean_mc_travel_dist: 1324.0278, mean_rewards: 271.5903, total_rewards: 3541.2796, mean_steps: 16.8300, mean_ecr: 0.0475 mean_entropies: 0.4822, took: 82.8696s
2022-10-10 19:39:49,843 [INFO] 	Process 6 - batch 85799: mean_policy_losses: -68.870, mean_net_lifetime: 3972.6985, mean_mc_travel_dist: 1046.8855, mean_rewards: 340.6541, total_rewards: 2963.5727, mean_steps: 10.6100, mean_ecr: 0.0555 mean_entropies: 0.1725, took: 55.1411s
2022-10-10 19:40:29,890 [INFO] 	Process 5 - batch 60099: mean_policy_losses: -190.315, mean_net_lifetime: 7024.6879, mean_mc_travel_dist: 2264.4365, mean_rewards: 270.4579, total_rewards: 4804.8532, mean_steps: 25.4800, mean_ecr: 0.0302 mean_entropies: 0.6568, took: 683.8394s
2022-10-10 19:40:40,337 [INFO] 	Process 2 - batch 61499: mean_policy_losses: -46.589, mean_net_lifetime: 6856.9204, mean_mc_travel_dist: 1950.3666, mean_rewards: 264.1390, total_rewards: 4946.7655, mean_steps: 24.9900, mean_ecr: 0.0383 mean_entropies: 0.5407, took: 114.6228s
2022-10-10 19:40:42,844 [INFO] 	Process 6 - batch 85899: mean_policy_losses: -93.477, mean_net_lifetime: 3838.8165, mean_mc_travel_dist: 1038.6306, mean_rewards: 338.2408, total_rewards: 2850.0344, mean_steps: 10.3400, mean_ecr: 0.0553 mean_entropies: 0.1823, took: 53.0009s
2022-10-10 19:41:09,870 [INFO] 	Process 3 - batch 63599: mean_policy_losses: 1.744, mean_net_lifetime: 4770.1208, mean_mc_travel_dist: 1287.6343, mean_rewards: 266.0495, total_rewards: 3515.9541, mean_steps: 16.9800, mean_ecr: 0.0479 mean_entropies: 0.4589, took: 80.4246s
2022-10-10 19:41:11,153 [INFO] 	Process 4 - batch 67699: mean_policy_losses: 28.220, mean_net_lifetime: 5679.6264, mean_mc_travel_dist: 1612.1855, mean_rewards: 285.7261, total_rewards: 4099.1450, mean_steps: 19.4700, mean_ecr: 0.0455 mean_entropies: 0.6366, took: 92.4000s
2022-10-10 19:41:37,632 [INFO] 	Process 6 - batch 85999: mean_policy_losses: -64.583, mean_net_lifetime: 4013.4126, mean_mc_travel_dist: 1073.3681, mean_rewards: 339.9784, total_rewards: 2995.1413, mean_steps: 10.7800, mean_ecr: 0.0551 mean_entropies: 0.1547, took: 54.7878s
2022-10-10 19:41:40,664 [INFO] Process 1 - epoch 36: mean_policy_losses: 34.521, mean_net_lifetime: 4942.8302, mean_mc_travel_dist: 2031.6383, mean_entropies: 1.2420, m_net_lifetime_valid: 4347.6520, took: 2256.8173s, (171.5043 / 100 batches)

2022-10-10 19:42:14,537 [INFO] 	Process 5 - batch 60199: mean_policy_losses: -198.107, mean_net_lifetime: 6284.5918, mean_mc_travel_dist: 2038.1243, mean_rewards: 267.9371, total_rewards: 4302.5918, mean_steps: 22.6800, mean_ecr: 0.0305 mean_entropies: 0.6348, took: 104.6483s
2022-10-10 19:42:32,465 [INFO] 	Process 3 - batch 63699: mean_policy_losses: -6.365, mean_net_lifetime: 4846.1962, mean_mc_travel_dist: 1316.2728, mean_rewards: 268.3786, total_rewards: 3566.6570, mean_steps: 17.1100, mean_ecr: 0.0476 mean_entropies: 0.4580, took: 82.5951s
2022-10-10 19:42:33,957 [INFO] 	Process 6 - batch 86099: mean_policy_losses: -68.946, mean_net_lifetime: 4041.3578, mean_mc_travel_dist: 1076.9071, mean_rewards: 339.8955, total_rewards: 3010.9566, mean_steps: 10.8300, mean_ecr: 0.0550 mean_entropies: 0.1420, took: 56.3255s
2022-10-10 19:42:55,246 [INFO] 	Process 4 - batch 67799: mean_policy_losses: 82.816, mean_net_lifetime: 6363.9582, mean_mc_travel_dist: 1839.5053, mean_rewards: 280.2311, total_rewards: 4554.7008, mean_steps: 22.7000, mean_ecr: 0.0443 mean_entropies: 0.6595, took: 104.0938s
2022-10-10 19:43:28,283 [INFO] 	Process 6 - batch 86199: mean_policy_losses: -118.464, mean_net_lifetime: 3961.6823, mean_mc_travel_dist: 1070.4587, mean_rewards: 337.6257, total_rewards: 2960.1379, mean_steps: 10.6400, mean_ecr: 0.0551 mean_entropies: 0.1340, took: 54.3252s
2022-10-10 19:43:45,524 [INFO] 	Process 1 - batch 54099: mean_policy_losses: -117.081, mean_net_lifetime: 5879.4417, mean_mc_travel_dist: 1968.2374, mean_rewards: 212.4379, total_rewards: 3943.1250, mean_steps: 27.2200, mean_ecr: 0.0382 mean_entropies: 0.8988, took: 646.9099s
2022-10-10 19:43:55,106 [INFO] 	Process 3 - batch 63799: mean_policy_losses: -18.392, mean_net_lifetime: 4771.1523, mean_mc_travel_dist: 1286.7154, mean_rewards: 266.2967, total_rewards: 3529.2340, mean_steps: 16.9500, mean_ecr: 0.0477 mean_entropies: 0.4527, took: 82.6417s
2022-10-10 19:44:21,487 [INFO] 	Process 5 - batch 60299: mean_policy_losses: -163.894, mean_net_lifetime: 7034.8003, mean_mc_travel_dist: 2327.3263, mean_rewards: 258.9820, total_rewards: 4754.7875, mean_steps: 26.6600, mean_ecr: 0.0300 mean_entropies: 0.6189, took: 126.9500s
2022-10-10 19:44:27,050 [INFO] 	Process 6 - batch 86299: mean_policy_losses: -133.340, mean_net_lifetime: 4046.5508, mean_mc_travel_dist: 1087.0391, mean_rewards: 340.4849, total_rewards: 3025.8174, mean_steps: 10.8400, mean_ecr: 0.0548 mean_entropies: 0.1244, took: 58.7676s
2022-10-10 19:44:34,245 [INFO] Process 7 - epoch 41: mean_policy_losses: -331.123, mean_net_lifetime: 4023.1537, mean_mc_travel_dist: 1567.5114, mean_entropies: 1.6282, m_net_lifetime_valid: 4268.9663, took: 2187.3294s, (150.7445 / 100 batches)

2022-10-10 19:44:45,675 [INFO] 	Process 4 - batch 67899: mean_policy_losses: 121.123, mean_net_lifetime: 6766.1902, mean_mc_travel_dist: 1986.1068, mean_rewards: 284.6838, total_rewards: 4808.9651, mean_steps: 23.6200, mean_ecr: 0.0433 mean_entropies: 0.6380, took: 110.4291s
2022-10-10 19:45:22,479 [INFO] 	Process 3 - batch 63899: mean_policy_losses: 2.962, mean_net_lifetime: 4809.9617, mean_mc_travel_dist: 1295.4798, mean_rewards: 266.7662, total_rewards: 3553.2891, mean_steps: 17.0800, mean_ecr: 0.0478 mean_entropies: 0.4621, took: 87.3724s
2022-10-10 19:45:27,925 [INFO] 	Process 6 - batch 86399: mean_policy_losses: -39.714, mean_net_lifetime: 4163.1850, mean_mc_travel_dist: 1119.0348, mean_rewards: 340.9478, total_rewards: 3108.5360, mean_steps: 11.1700, mean_ecr: 0.0547 mean_entropies: 0.1200, took: 60.8752s
2022-10-10 19:45:45,988 [INFO] 	Process 1 - batch 54199: mean_policy_losses: -72.446, mean_net_lifetime: 5757.0279, mean_mc_travel_dist: 1922.4845, mean_rewards: 221.1368, total_rewards: 3857.1026, mean_steps: 25.5200, mean_ecr: 0.0384 mean_entropies: 0.8972, took: 120.4636s
2022-10-10 19:46:19,745 [INFO] 	Process 5 - batch 60399: mean_policy_losses: -131.796, mean_net_lifetime: 6749.6934, mean_mc_travel_dist: 2174.2822, mean_rewards: 271.8062, total_rewards: 4617.8249, mean_steps: 24.1800, mean_ecr: 0.0304 mean_entropies: 0.6337, took: 118.2569s
2022-10-10 19:46:21,314 [INFO] 	Process 7 - batch 61599: mean_policy_losses: -504.558, mean_net_lifetime: 4951.8722, mean_mc_travel_dist: 1560.5493, mean_rewards: 215.9127, total_rewards: 3435.2163, mean_steps: 22.3100, mean_ecr: 0.0409 mean_entropies: 1.3477, took: 727.8200s
2022-10-10 19:46:27,060 [INFO] 	Process 6 - batch 86499: mean_policy_losses: -30.975, mean_net_lifetime: 4135.5785, mean_mc_travel_dist: 1112.9335, mean_rewards: 338.6643, total_rewards: 3086.7822, mean_steps: 11.1500, mean_ecr: 0.0548 mean_entropies: 0.1257, took: 59.1341s
2022-10-10 19:46:43,201 [INFO] 	Process 4 - batch 67999: mean_policy_losses: 102.366, mean_net_lifetime: 6536.2697, mean_mc_travel_dist: 1905.4793, mean_rewards: 273.8452, total_rewards: 4653.1754, mean_steps: 24.0500, mean_ecr: 0.0435 mean_entropies: 0.6385, took: 117.5259s
2022-10-10 19:46:47,658 [INFO] 	Process 3 - batch 63999: mean_policy_losses: -19.744, mean_net_lifetime: 4685.9277, mean_mc_travel_dist: 1271.5230, mean_rewards: 264.3812, total_rewards: 3446.8297, mean_steps: 16.7900, mean_ecr: 0.0478 mean_entropies: 0.4812, took: 85.1797s
2022-10-10 19:47:27,376 [INFO] 	Process 6 - batch 86599: mean_policy_losses: -108.839, mean_net_lifetime: 4100.4770, mean_mc_travel_dist: 1100.0034, mean_rewards: 339.8201, total_rewards: 3060.7182, mean_steps: 10.9800, mean_ecr: 0.0550 mean_entropies: 0.1133, took: 60.3160s
2022-10-10 19:47:57,519 [INFO] 	Process 1 - batch 54299: mean_policy_losses: -58.381, mean_net_lifetime: 6042.0729, mean_mc_travel_dist: 1986.5541, mean_rewards: 214.9930, total_rewards: 4080.1107, mean_steps: 27.7400, mean_ecr: 0.0382 mean_entropies: 0.9114, took: 131.5310s
2022-10-10 19:48:02,936 [INFO] 	Process 7 - batch 61699: mean_policy_losses: -572.090, mean_net_lifetime: 4767.1864, mean_mc_travel_dist: 1517.8785, mean_rewards: 220.4469, total_rewards: 3279.2456, mean_steps: 21.0300, mean_ecr: 0.0410 mean_entropies: 1.3713, took: 101.6211s
2022-10-10 19:48:15,910 [INFO] 	Process 3 - batch 64099: mean_policy_losses: -0.025, mean_net_lifetime: 4799.6841, mean_mc_travel_dist: 1289.0818, mean_rewards: 268.8899, total_rewards: 3544.1518, mean_steps: 16.8900, mean_ecr: 0.0479 mean_entropies: 0.4694, took: 88.2515s
2022-10-10 19:48:23,575 [INFO] 	Process 5 - batch 60499: mean_policy_losses: -148.114, mean_net_lifetime: 7040.0523, mean_mc_travel_dist: 2240.4046, mean_rewards: 269.9571, total_rewards: 4840.9054, mean_steps: 25.2900, mean_ecr: 0.0305 mean_entropies: 0.6180, took: 123.8303s
2022-10-10 19:48:26,588 [INFO] 	Process 6 - batch 86699: mean_policy_losses: -152.093, mean_net_lifetime: 3944.3053, mean_mc_travel_dist: 1049.7653, mean_rewards: 337.6031, total_rewards: 2940.4465, mean_steps: 10.5900, mean_ecr: 0.0551 mean_entropies: 0.1151, took: 59.2117s
2022-10-10 19:48:37,053 [INFO] 	Process 4 - batch 68099: mean_policy_losses: 112.969, mean_net_lifetime: 6511.6518, mean_mc_travel_dist: 1858.7873, mean_rewards: 274.9400, total_rewards: 4679.1927, mean_steps: 23.4000, mean_ecr: 0.0435 mean_entropies: 0.6439, took: 113.8520s
2022-10-10 19:49:26,822 [INFO] 	Process 6 - batch 86799: mean_policy_losses: -81.894, mean_net_lifetime: 4111.8164, mean_mc_travel_dist: 1097.2307, mean_rewards: 340.1978, total_rewards: 3070.1172, mean_steps: 11.0300, mean_ecr: 0.0550 mean_entropies: 0.1196, took: 60.2342s
2022-10-10 19:49:43,893 [INFO] 	Process 3 - batch 64199: mean_policy_losses: -16.690, mean_net_lifetime: 4667.2475, mean_mc_travel_dist: 1255.3709, mean_rewards: 258.5858, total_rewards: 3442.4004, mean_steps: 17.1400, mean_ecr: 0.0480 mean_entropies: 0.4500, took: 87.9837s
2022-10-10 19:49:50,470 [INFO] 	Process 7 - batch 61799: mean_policy_losses: -520.978, mean_net_lifetime: 4823.6001, mean_mc_travel_dist: 1547.9221, mean_rewards: 205.5861, total_rewards: 3319.0992, mean_steps: 22.5000, mean_ecr: 0.0408 mean_entropies: 1.3062, took: 107.5346s
2022-10-10 19:50:09,858 [INFO] 	Process 1 - batch 54399: mean_policy_losses: -75.598, mean_net_lifetime: 6030.1021, mean_mc_travel_dist: 2036.0953, mean_rewards: 214.0669, total_rewards: 4021.8763, mean_steps: 27.9700, mean_ecr: 0.0380 mean_entropies: 0.8739, took: 132.3398s
2022-10-10 19:50:16,607 [INFO] 	Process 4 - batch 68199: mean_policy_losses: 104.632, mean_net_lifetime: 5720.7795, mean_mc_travel_dist: 1601.4804, mean_rewards: 281.4577, total_rewards: 4154.9156, mean_steps: 19.7300, mean_ecr: 0.0454 mean_entropies: 0.6472, took: 99.5535s
2022-10-10 19:50:20,402 [INFO] 	Process 5 - batch 60599: mean_policy_losses: -167.895, mean_net_lifetime: 6702.4763, mean_mc_travel_dist: 2133.7094, mean_rewards: 270.9009, total_rewards: 4602.4132, mean_steps: 24.0600, mean_ecr: 0.0306 mean_entropies: 0.5989, took: 116.8281s
2022-10-10 19:50:25,309 [INFO] 	Process 6 - batch 86899: mean_policy_losses: -67.582, mean_net_lifetime: 4073.9549, mean_mc_travel_dist: 1091.2164, mean_rewards: 342.0846, total_rewards: 3051.0247, mean_steps: 10.8900, mean_ecr: 0.0548 mean_entropies: 0.1120, took: 58.4881s
2022-10-10 19:50:52,539 [INFO] Process 2 - epoch 41: mean_policy_losses: 3.339, mean_net_lifetime: 4477.1212, mean_mc_travel_dist: 1563.6957, mean_entropies: 0.9979, m_net_lifetime_valid: 4515.4408, took: 2369.4502s, (151.3728 / 100 batches)

2022-10-10 19:51:10,752 [INFO] 	Process 3 - batch 64299: mean_policy_losses: -18.210, mean_net_lifetime: 4711.0008, mean_mc_travel_dist: 1255.7413, mean_rewards: 266.9982, total_rewards: 3491.8326, mean_steps: 16.7000, mean_ecr: 0.0480 mean_entropies: 0.4620, took: 86.8584s
2022-10-10 19:51:26,835 [INFO] 	Process 6 - batch 86999: mean_policy_losses: -64.620, mean_net_lifetime: 4169.5006, mean_mc_travel_dist: 1111.2332, mean_rewards: 343.7089, total_rewards: 3124.8766, mean_steps: 11.1200, mean_ecr: 0.0545 mean_entropies: 0.0973, took: 61.5247s
2022-10-10 19:51:35,558 [INFO] 	Process 7 - batch 61899: mean_policy_losses: -445.790, mean_net_lifetime: 4912.4982, mean_mc_travel_dist: 1549.8117, mean_rewards: 217.1146, total_rewards: 3404.2607, mean_steps: 21.8600, mean_ecr: 0.0406 mean_entropies: 1.3061, took: 105.0885s
2022-10-10 19:51:56,322 [INFO] 	Process 4 - batch 68299: mean_policy_losses: 106.880, mean_net_lifetime: 5654.1386, mean_mc_travel_dist: 1590.1892, mean_rewards: 278.4653, total_rewards: 4091.4039, mean_steps: 19.5600, mean_ecr: 0.0456 mean_entropies: 0.6333, took: 99.7155s
2022-10-10 19:52:17,706 [INFO] 	Process 1 - batch 54499: mean_policy_losses: -72.106, mean_net_lifetime: 5871.0096, mean_mc_travel_dist: 1947.8118, mean_rewards: 219.3621, total_rewards: 3942.7457, mean_steps: 26.4000, mean_ecr: 0.0383 mean_entropies: 0.9049, took: 127.8485s
2022-10-10 19:52:28,107 [INFO] 	Process 5 - batch 60699: mean_policy_losses: -103.438, mean_net_lifetime: 7348.2633, mean_mc_travel_dist: 2342.9680, mean_rewards: 270.8534, total_rewards: 5044.6540, mean_steps: 26.6500, mean_ecr: 0.0303 mean_entropies: 0.6023, took: 127.7045s
2022-10-10 19:52:37,932 [INFO] 	Process 3 - batch 64399: mean_policy_losses: 6.897, mean_net_lifetime: 4745.1489, mean_mc_travel_dist: 1265.3817, mean_rewards: 266.6058, total_rewards: 3514.1881, mean_steps: 16.8700, mean_ecr: 0.0478 mean_entropies: 0.4475, took: 87.1796s
2022-10-10 19:52:44,904 [INFO] 	Process 2 - batch 61599: mean_policy_losses: -80.381, mean_net_lifetime: 6332.6876, mean_mc_travel_dist: 1778.9262, mean_rewards: 263.7503, total_rewards: 4594.2031, mean_steps: 23.0800, mean_ecr: 0.0390 mean_entropies: 0.4845, took: 724.5668s
2022-10-10 19:53:14,645 [INFO] 	Process 7 - batch 61999: mean_policy_losses: -574.349, mean_net_lifetime: 4688.8367, mean_mc_travel_dist: 1480.0824, mean_rewards: 220.7164, total_rewards: 3253.9545, mean_steps: 20.5700, mean_ecr: 0.0413 mean_entropies: 1.3379, took: 99.0874s
2022-10-10 19:53:27,317 [INFO] 	Process 4 - batch 68399: mean_policy_losses: 50.733, mean_net_lifetime: 5214.0233, mean_mc_travel_dist: 1429.6184, mean_rewards: 278.4854, total_rewards: 3817.1978, mean_steps: 17.9600, mean_ecr: 0.0465 mean_entropies: 0.6207, took: 90.9948s
2022-10-10 19:54:07,152 [INFO] 	Process 3 - batch 64499: mean_policy_losses: -21.446, mean_net_lifetime: 4685.2194, mean_mc_travel_dist: 1265.2924, mean_rewards: 262.5979, total_rewards: 3465.2772, mean_steps: 16.9100, mean_ecr: 0.0482 mean_entropies: 0.4504, took: 89.2198s
2022-10-10 19:54:29,614 [INFO] 	Process 1 - batch 54599: mean_policy_losses: -70.349, mean_net_lifetime: 6063.2342, mean_mc_travel_dist: 1996.4186, mean_rewards: 219.5229, total_rewards: 4097.5154, mean_steps: 27.2000, mean_ecr: 0.0381 mean_entropies: 0.9990, took: 131.9078s
2022-10-10 19:54:38,711 [INFO] 	Process 5 - batch 60799: mean_policy_losses: -94.934, mean_net_lifetime: 7701.9489, mean_mc_travel_dist: 2502.3684, mean_rewards: 276.0676, total_rewards: 5244.8670, mean_steps: 27.4300, mean_ecr: 0.0301 mean_entropies: 0.6178, took: 130.6043s
2022-10-10 19:54:47,396 [INFO] 	Process 2 - batch 61699: mean_policy_losses: -9.995, mean_net_lifetime: 7017.2677, mean_mc_travel_dist: 2025.2677, mean_rewards: 261.8665, total_rewards: 5020.3798, mean_steps: 25.8800, mean_ecr: 0.0381 mean_entropies: 0.5266, took: 122.4928s
2022-10-10 19:55:07,375 [INFO] 	Process 7 - batch 62099: mean_policy_losses: -378.615, mean_net_lifetime: 5280.3741, mean_mc_travel_dist: 1701.3786, mean_rewards: 209.6243, total_rewards: 3621.3451, mean_steps: 24.3800, mean_ecr: 0.0404 mean_entropies: 1.2795, took: 112.7291s
2022-10-10 19:55:12,579 [INFO] 	Process 4 - batch 68499: mean_policy_losses: 131.318, mean_net_lifetime: 6146.8662, mean_mc_travel_dist: 1732.1611, mean_rewards: 282.3389, total_rewards: 4437.0702, mean_steps: 21.7200, mean_ecr: 0.0445 mean_entropies: 0.6120, took: 105.2612s
2022-10-10 19:56:31,471 [INFO] 	Process 1 - batch 54699: mean_policy_losses: -86.794, mean_net_lifetime: 5854.7186, mean_mc_travel_dist: 1964.2985, mean_rewards: 226.9665, total_rewards: 3920.4665, mean_steps: 25.4200, mean_ecr: 0.0382 mean_entropies: 0.9402, took: 121.8558s
2022-10-10 19:56:41,939 [INFO] 	Process 2 - batch 61799: mean_policy_losses: -47.798, mean_net_lifetime: 6711.4058, mean_mc_travel_dist: 1931.1472, mean_rewards: 264.1876, total_rewards: 4810.2675, mean_steps: 24.4100, mean_ecr: 0.0385 mean_entropies: 0.5270, took: 114.5415s
2022-10-10 19:56:42,692 [INFO] 	Process 5 - batch 60899: mean_policy_losses: -160.982, mean_net_lifetime: 7202.2712, mean_mc_travel_dist: 2346.4073, mean_rewards: 273.8884, total_rewards: 4897.9989, mean_steps: 26.1600, mean_ecr: 0.0299 mean_entropies: 0.6177, took: 123.9806s
2022-10-10 19:56:55,419 [INFO] 	Process 4 - batch 68599: mean_policy_losses: 117.127, mean_net_lifetime: 6186.3150, mean_mc_travel_dist: 1757.9601, mean_rewards: 286.2673, total_rewards: 4459.4410, mean_steps: 21.3000, mean_ecr: 0.0442 mean_entropies: 0.5923, took: 102.8402s
2022-10-10 19:56:59,384 [INFO] 	Process 7 - batch 62199: mean_policy_losses: -387.977, mean_net_lifetime: 5275.7674, mean_mc_travel_dist: 1671.0041, mean_rewards: 212.0494, total_rewards: 3650.7000, mean_steps: 24.2800, mean_ecr: 0.0406 mean_entropies: 1.3237, took: 112.0100s
2022-10-10 19:58:25,170 [INFO] 	Process 1 - batch 54799: mean_policy_losses: -71.549, mean_net_lifetime: 5834.9052, mean_mc_travel_dist: 2003.1225, mean_rewards: 235.5095, total_rewards: 3851.9920, mean_steps: 24.1900, mean_ecr: 0.0382 mean_entropies: 0.9242, took: 113.6997s
2022-10-10 19:58:35,487 [INFO] 	Process 2 - batch 61899: mean_policy_losses: -52.036, mean_net_lifetime: 6741.4633, mean_mc_travel_dist: 1953.3709, mean_rewards: 266.3284, total_rewards: 4823.1998, mean_steps: 24.4300, mean_ecr: 0.0384 mean_entropies: 0.5306, took: 113.5486s
2022-10-10 19:58:38,669 [INFO] 	Process 7 - batch 62299: mean_policy_losses: -475.987, mean_net_lifetime: 4725.7238, mean_mc_travel_dist: 1502.2457, mean_rewards: 213.9626, total_rewards: 3272.6910, mean_steps: 21.3900, mean_ecr: 0.0409 mean_entropies: 1.3321, took: 99.2850s
2022-10-10 19:58:40,530 [INFO] 	Process 5 - batch 60999: mean_policy_losses: -117.936, mean_net_lifetime: 6919.8977, mean_mc_travel_dist: 2276.6966, mean_rewards: 273.9794, total_rewards: 4688.5531, mean_steps: 24.5200, mean_ecr: 0.0301 mean_entropies: 0.6078, took: 117.8373s
2022-10-10 19:58:43,639 [INFO] 	Process 4 - batch 68699: mean_policy_losses: 161.641, mean_net_lifetime: 6521.2457, mean_mc_travel_dist: 1888.6902, mean_rewards: 286.3846, total_rewards: 4660.7593, mean_steps: 22.7500, mean_ecr: 0.0439 mean_entropies: 0.5918, took: 108.2207s
2022-10-10 20:00:05,751 [INFO] 	Process 1 - batch 54899: mean_policy_losses: -11.105, mean_net_lifetime: 5313.8373, mean_mc_travel_dist: 2049.3927, mean_rewards: 248.3504, total_rewards: 3291.9312, mean_steps: 20.6500, mean_ecr: 0.0383 mean_entropies: 0.7652, took: 100.5811s
2022-10-10 20:00:05,967 [INFO] 	Process 7 - batch 62399: mean_policy_losses: -373.270, mean_net_lifetime: 4195.0114, mean_mc_travel_dist: 1356.9969, mean_rewards: 217.3552, total_rewards: 2880.9379, mean_steps: 18.5300, mean_ecr: 0.0414 mean_entropies: 1.2229, took: 87.2981s
2022-10-10 20:00:09,650 [INFO] 	Process 5 - batch 61099: mean_policy_losses: -156.793, mean_net_lifetime: 5608.8935, mean_mc_travel_dist: 1884.4690, mean_rewards: 295.8439, total_rewards: 3772.5599, mean_steps: 18.5500, mean_ecr: 0.0305 mean_entropies: 0.5232, took: 89.1201s
2022-10-10 20:00:13,776 [INFO] 	Process 4 - batch 68799: mean_policy_losses: 180.512, mean_net_lifetime: 5243.4395, mean_mc_travel_dist: 1529.0756, mean_rewards: 277.6172, total_rewards: 3739.4182, mean_steps: 18.1400, mean_ecr: 0.0463 mean_entropies: 0.6110, took: 90.1371s
2022-10-10 20:00:29,580 [INFO] 	Process 2 - batch 61999: mean_policy_losses: 14.916, mean_net_lifetime: 6683.6848, mean_mc_travel_dist: 2029.7832, mean_rewards: 260.7949, total_rewards: 4691.2310, mean_steps: 24.6900, mean_ecr: 0.0380 mean_entropies: 0.5739, took: 114.0932s
2022-10-10 20:01:43,688 [INFO] 	Process 7 - batch 62499: mean_policy_losses: -399.762, mean_net_lifetime: 4698.6523, mean_mc_travel_dist: 1479.5888, mean_rewards: 217.5698, total_rewards: 3262.2442, mean_steps: 20.8300, mean_ecr: 0.0411 mean_entropies: 1.3427, took: 97.7207s
2022-10-10 20:01:56,397 [INFO] 	Process 1 - batch 54999: mean_policy_losses: -17.612, mean_net_lifetime: 5646.5676, mean_mc_travel_dist: 2010.1300, mean_rewards: 234.0830, total_rewards: 3662.9906, mean_steps: 23.6100, mean_ecr: 0.0383 mean_entropies: 0.8617, took: 110.6458s
2022-10-10 20:02:03,529 [INFO] 	Process 5 - batch 61199: mean_policy_losses: -138.932, mean_net_lifetime: 6785.9786, mean_mc_travel_dist: 2272.7710, mean_rewards: 277.1058, total_rewards: 4555.8876, mean_steps: 23.7100, mean_ecr: 0.0302 mean_entropies: 0.5642, took: 113.8796s
2022-10-10 20:02:06,997 [INFO] 	Process 4 - batch 68899: mean_policy_losses: 200.951, mean_net_lifetime: 6563.5788, mean_mc_travel_dist: 1979.6288, mean_rewards: 278.7404, total_rewards: 4613.3782, mean_steps: 24.1000, mean_ecr: 0.0433 mean_entropies: 0.5940, took: 113.2203s
2022-10-10 20:02:20,922 [INFO] 	Process 2 - batch 62099: mean_policy_losses: -42.214, mean_net_lifetime: 6514.1962, mean_mc_travel_dist: 1889.7661, mean_rewards: 262.3361, total_rewards: 4657.3860, mean_steps: 23.9600, mean_ecr: 0.0386 mean_entropies: 0.5539, took: 111.3421s
2022-10-10 20:02:28,454 [INFO] Process 6 - epoch 58: mean_policy_losses: -227.734, mean_net_lifetime: 2925.9052, mean_mc_travel_dist: 953.3155, mean_entropies: 0.6596, m_net_lifetime_valid: 4668.8180, took: 1517.3976s, (107.7974 / 100 batches)

2022-10-10 20:03:22,487 [INFO] 	Process 7 - batch 62599: mean_policy_losses: -463.140, mean_net_lifetime: 4662.5901, mean_mc_travel_dist: 1465.3977, mean_rewards: 215.5803, total_rewards: 3241.4535, mean_steps: 20.7500, mean_ecr: 0.0411 mean_entropies: 1.2975, took: 98.7988s
2022-10-10 20:03:27,848 [INFO] 	Process 6 - batch 87099: mean_policy_losses: -28.228, mean_net_lifetime: 4083.9433, mean_mc_travel_dist: 1073.6870, mean_rewards: 340.0797, total_rewards: 3056.4891, mean_steps: 11.0000, mean_ecr: 0.0543 mean_entropies: 0.1469, took: 721.0137s
2022-10-10 20:03:47,318 [INFO] 	Process 1 - batch 55099: mean_policy_losses: -22.547, mean_net_lifetime: 5817.9851, mean_mc_travel_dist: 1985.4961, mean_rewards: 238.5784, total_rewards: 3857.9163, mean_steps: 23.6400, mean_ecr: 0.0382 mean_entropies: 0.9433, took: 110.9209s
2022-10-10 20:03:51,744 [INFO] 	Process 5 - batch 61299: mean_policy_losses: -222.711, mean_net_lifetime: 6309.8868, mean_mc_travel_dist: 2046.6982, mean_rewards: 276.1320, total_rewards: 4316.7094, mean_steps: 21.9300, mean_ecr: 0.0306 mean_entropies: 0.5866, took: 108.2143s
2022-10-10 20:03:59,127 [INFO] 	Process 4 - batch 68999: mean_policy_losses: 143.625, mean_net_lifetime: 6360.5942, mean_mc_travel_dist: 1828.3160, mean_rewards: 279.6723, total_rewards: 4561.8528, mean_steps: 22.6100, mean_ecr: 0.0439 mean_entropies: 0.5879, took: 112.1307s
2022-10-10 20:04:20,095 [INFO] 	Process 2 - batch 62199: mean_policy_losses: -36.316, mean_net_lifetime: 6860.1685, mean_mc_travel_dist: 1931.6461, mean_rewards: 266.7410, total_rewards: 4965.6804, mean_steps: 24.8100, mean_ecr: 0.0385 mean_entropies: 0.5292, took: 119.1721s
2022-10-10 20:04:22,139 [INFO] Process 3 - epoch 43: mean_policy_losses: 71.234, mean_net_lifetime: 4232.8429, mean_mc_travel_dist: 1369.1155, mean_entropies: 0.9601, m_net_lifetime_valid: 4351.8591, took: 1852.8890s, (145.5908 / 100 batches)

2022-10-10 20:04:25,813 [INFO] 	Process 6 - batch 87199: mean_policy_losses: -51.053, mean_net_lifetime: 4112.8827, mean_mc_travel_dist: 1107.6196, mean_rewards: 341.1242, total_rewards: 3080.3766, mean_steps: 11.0200, mean_ecr: 0.0549 mean_entropies: 0.1262, took: 57.9652s
2022-10-10 20:05:11,987 [INFO] 	Process 7 - batch 62699: mean_policy_losses: -406.474, mean_net_lifetime: 5045.9966, mean_mc_travel_dist: 1566.9622, mean_rewards: 211.6914, total_rewards: 3516.8734, mean_steps: 23.3400, mean_ecr: 0.0407 mean_entropies: 1.3116, took: 109.5001s
2022-10-10 20:05:24,010 [INFO] 	Process 6 - batch 87299: mean_policy_losses: -71.634, mean_net_lifetime: 3955.6259, mean_mc_travel_dist: 1046.4135, mean_rewards: 340.1257, total_rewards: 2953.6071, mean_steps: 10.5500, mean_ecr: 0.0552 mean_entropies: 0.1179, took: 58.1972s
2022-10-10 20:05:41,147 [INFO] 	Process 5 - batch 61399: mean_policy_losses: -131.161, mean_net_lifetime: 6293.5166, mean_mc_travel_dist: 1998.3817, mean_rewards: 273.6284, total_rewards: 4340.4155, mean_steps: 22.2400, mean_ecr: 0.0308 mean_entropies: 0.5604, took: 109.4038s
2022-10-10 20:05:48,655 [INFO] 	Process 1 - batch 55199: mean_policy_losses: -71.607, mean_net_lifetime: 5836.2952, mean_mc_travel_dist: 1960.7521, mean_rewards: 220.3884, total_rewards: 3903.2974, mean_steps: 25.8700, mean_ecr: 0.0383 mean_entropies: 0.9494, took: 121.3377s
2022-10-10 20:05:48,702 [INFO] 	Process 3 - batch 64599: mean_policy_losses: 1.277, mean_net_lifetime: 4662.0674, mean_mc_travel_dist: 1228.1662, mean_rewards: 260.9411, total_rewards: 3469.8595, mean_steps: 16.9400, mean_ecr: 0.0480 mean_entropies: 0.4492, took: 701.5498s
2022-10-10 20:06:15,461 [INFO] 	Process 2 - batch 62299: mean_policy_losses: -36.562, mean_net_lifetime: 6669.0080, mean_mc_travel_dist: 1879.2071, mean_rewards: 266.1532, total_rewards: 4815.8783, mean_steps: 24.0700, mean_ecr: 0.0387 mean_entropies: 0.4896, took: 115.3659s
2022-10-10 20:06:22,549 [INFO] 	Process 6 - batch 87399: mean_policy_losses: -100.670, mean_net_lifetime: 4098.2623, mean_mc_travel_dist: 1084.0865, mean_rewards: 343.1950, total_rewards: 3061.8148, mean_steps: 10.9200, mean_ecr: 0.0549 mean_entropies: 0.1177, took: 58.5380s
2022-10-10 20:07:00,961 [INFO] 	Process 7 - batch 62799: mean_policy_losses: -330.760, mean_net_lifetime: 4975.4227, mean_mc_travel_dist: 1548.7092, mean_rewards: 211.4378, total_rewards: 3469.8052, mean_steps: 22.7600, mean_ecr: 0.0408 mean_entropies: 1.2767, took: 108.9742s
2022-10-10 20:07:17,500 [INFO] 	Process 3 - batch 64699: mean_policy_losses: -3.933, mean_net_lifetime: 4860.7636, mean_mc_travel_dist: 1299.7489, mean_rewards: 262.4886, total_rewards: 3609.1220, mean_steps: 17.5800, mean_ecr: 0.0478 mean_entropies: 0.4434, took: 88.7987s
2022-10-10 20:07:22,299 [INFO] 	Process 6 - batch 87499: mean_policy_losses: -78.094, mean_net_lifetime: 4074.9331, mean_mc_travel_dist: 1080.3939, mean_rewards: 343.3955, total_rewards: 3041.9100, mean_steps: 10.8300, mean_ecr: 0.0549 mean_entropies: 0.1177, took: 59.7502s
2022-10-10 20:07:38,880 [INFO] 	Process 5 - batch 61499: mean_policy_losses: -114.044, mean_net_lifetime: 6838.0855, mean_mc_travel_dist: 2209.6664, mean_rewards: 274.9017, total_rewards: 4668.9432, mean_steps: 24.1600, mean_ecr: 0.0306 mean_entropies: 0.5689, took: 117.7332s
2022-10-10 20:07:53,268 [INFO] 	Process 1 - batch 55299: mean_policy_losses: -76.164, mean_net_lifetime: 6030.8264, mean_mc_travel_dist: 2037.9050, mean_rewards: 228.1046, total_rewards: 4015.5618, mean_steps: 25.9900, mean_ecr: 0.0380 mean_entropies: 0.9504, took: 124.6126s
2022-10-10 20:08:16,406 [INFO] 	Process 2 - batch 62399: mean_policy_losses: -29.139, mean_net_lifetime: 7055.1146, mean_mc_travel_dist: 2001.0452, mean_rewards: 267.5964, total_rewards: 5089.9634, mean_steps: 25.5000, mean_ecr: 0.0383 mean_entropies: 0.5309, took: 120.9455s
2022-10-10 20:08:21,725 [INFO] 	Process 6 - batch 87599: mean_policy_losses: -44.246, mean_net_lifetime: 4102.9142, mean_mc_travel_dist: 1091.2574, mean_rewards: 341.5922, total_rewards: 3066.6718, mean_steps: 10.9500, mean_ecr: 0.0548 mean_entropies: 0.1202, took: 59.4252s
2022-10-10 20:08:40,353 [INFO] 	Process 3 - batch 64799: mean_policy_losses: -9.877, mean_net_lifetime: 4725.0213, mean_mc_travel_dist: 1234.1940, mean_rewards: 265.3557, total_rewards: 3530.0679, mean_steps: 16.8500, mean_ecr: 0.0481 mean_entropies: 0.4481, took: 82.8521s
2022-10-10 20:08:41,014 [INFO] 	Process 7 - batch 62899: mean_policy_losses: -461.477, mean_net_lifetime: 4603.0529, mean_mc_travel_dist: 1453.2707, mean_rewards: 208.6785, total_rewards: 3183.3267, mean_steps: 21.1400, mean_ecr: 0.0411 mean_entropies: 1.2630, took: 100.0525s
2022-10-10 20:09:18,274 [INFO] 	Process 6 - batch 87699: mean_policy_losses: -105.530, mean_net_lifetime: 4026.2946, mean_mc_travel_dist: 1076.9138, mean_rewards: 341.0042, total_rewards: 3010.6162, mean_steps: 10.7700, mean_ecr: 0.0552 mean_entropies: 0.1315, took: 56.5507s
2022-10-10 20:09:50,917 [INFO] 	Process 1 - batch 55399: mean_policy_losses: -57.686, mean_net_lifetime: 6108.0176, mean_mc_travel_dist: 2036.0291, mean_rewards: 231.0054, total_rewards: 4098.3863, mean_steps: 25.7900, mean_ecr: 0.0381 mean_entropies: 0.9590, took: 117.6490s
2022-10-10 20:10:05,320 [INFO] 	Process 3 - batch 64899: mean_policy_losses: -9.254, mean_net_lifetime: 4850.6227, mean_mc_travel_dist: 1293.3760, mean_rewards: 270.5717, total_rewards: 3588.8660, mean_steps: 17.0000, mean_ecr: 0.0479 mean_entropies: 0.4527, took: 84.9683s
2022-10-10 20:10:16,327 [INFO] 	Process 2 - batch 62499: mean_policy_losses: -43.212, mean_net_lifetime: 7031.2647, mean_mc_travel_dist: 1981.8179, mean_rewards: 266.1456, total_rewards: 5079.3565, mean_steps: 25.5600, mean_ecr: 0.0383 mean_entropies: 0.5127, took: 119.9210s
2022-10-10 20:10:16,479 [INFO] 	Process 6 - batch 87799: mean_policy_losses: -57.191, mean_net_lifetime: 4201.4497, mean_mc_travel_dist: 1124.2728, mean_rewards: 343.8112, total_rewards: 3130.9115, mean_steps: 11.1900, mean_ecr: 0.0549 mean_entropies: 0.1109, took: 58.2049s
2022-10-10 20:10:26,339 [INFO] 	Process 7 - batch 62999: mean_policy_losses: -385.807, mean_net_lifetime: 4855.0880, mean_mc_travel_dist: 1555.2005, mean_rewards: 206.2338, total_rewards: 3337.7908, mean_steps: 22.8300, mean_ecr: 0.0409 mean_entropies: 1.2717, took: 105.3247s
2022-10-10 20:11:12,020 [INFO] 	Process 6 - batch 87899: mean_policy_losses: -52.822, mean_net_lifetime: 4086.0569, mean_mc_travel_dist: 1100.9337, mean_rewards: 341.3231, total_rewards: 3046.8265, mean_steps: 10.9400, mean_ecr: 0.0551 mean_entropies: 0.1137, took: 55.5409s
2022-10-10 20:11:31,309 [INFO] 	Process 3 - batch 64999: mean_policy_losses: -11.226, mean_net_lifetime: 4741.0983, mean_mc_travel_dist: 1248.0377, mean_rewards: 263.2655, total_rewards: 3523.9585, mean_steps: 17.0500, mean_ecr: 0.0481 mean_entropies: 0.4639, took: 85.9886s
2022-10-10 20:11:44,742 [INFO] 	Process 1 - batch 55499: mean_policy_losses: -64.564, mean_net_lifetime: 6071.0122, mean_mc_travel_dist: 2001.9459, mean_rewards: 230.4080, total_rewards: 4098.0999, mean_steps: 25.6700, mean_ecr: 0.0383 mean_entropies: 0.9382, took: 113.8245s
2022-10-10 20:12:07,351 [INFO] 	Process 6 - batch 87999: mean_policy_losses: -82.390, mean_net_lifetime: 4060.3692, mean_mc_travel_dist: 1083.5386, mean_rewards: 339.9960, total_rewards: 3035.2832, mean_steps: 10.8800, mean_ecr: 0.0551 mean_entropies: 0.1170, took: 55.3307s
2022-10-10 20:12:08,302 [INFO] 	Process 2 - batch 62599: mean_policy_losses: -61.339, mean_net_lifetime: 6865.6188, mean_mc_travel_dist: 1927.5969, mean_rewards: 263.3599, total_rewards: 4977.3191, mean_steps: 25.1800, mean_ecr: 0.0385 mean_entropies: 0.4781, took: 111.9754s
2022-10-10 20:12:49,686 [INFO] 	Process 3 - batch 65099: mean_policy_losses: -15.862, mean_net_lifetime: 4850.0085, mean_mc_travel_dist: 1283.8644, mean_rewards: 267.3023, total_rewards: 3597.6010, mean_steps: 17.1800, mean_ecr: 0.0479 mean_entropies: 0.4468, took: 78.3767s
2022-10-10 20:13:00,387 [INFO] 	Process 6 - batch 88099: mean_policy_losses: -47.836, mean_net_lifetime: 4057.6924, mean_mc_travel_dist: 1079.5909, mean_rewards: 340.8240, total_rewards: 3022.1046, mean_steps: 10.8600, mean_ecr: 0.0552 mean_entropies: 0.1345, took: 53.0357s
2022-10-10 20:13:35,398 [INFO] Process 4 - epoch 46: mean_policy_losses: 88.324, mean_net_lifetime: 4102.6494, mean_mc_travel_dist: 1337.5297, mean_entropies: 1.1998, m_net_lifetime_valid: 4297.8873, took: 2137.2371s, (136.9670 / 100 batches)

2022-10-10 20:13:53,832 [INFO] 	Process 6 - batch 88199: mean_policy_losses: -102.382, mean_net_lifetime: 4061.7027, mean_mc_travel_dist: 1088.7989, mean_rewards: 343.0928, total_rewards: 3024.1912, mean_steps: 10.8100, mean_ecr: 0.0550 mean_entropies: 0.1458, took: 53.4456s
2022-10-10 20:14:00,921 [INFO] 	Process 2 - batch 62699: mean_policy_losses: -22.428, mean_net_lifetime: 7265.2674, mean_mc_travel_dist: 2052.6478, mean_rewards: 266.5549, total_rewards: 5248.0158, mean_steps: 26.4600, mean_ecr: 0.0381 mean_entropies: 0.5308, took: 112.6187s
2022-10-10 20:14:07,045 [INFO] 	Process 3 - batch 65199: mean_policy_losses: -35.047, mean_net_lifetime: 4677.6170, mean_mc_travel_dist: 1225.3611, mean_rewards: 263.4889, total_rewards: 3480.1285, mean_steps: 16.8000, mean_ecr: 0.0483 mean_entropies: 0.4700, took: 77.3595s
2022-10-10 20:14:48,275 [INFO] 	Process 6 - batch 88299: mean_policy_losses: -58.401, mean_net_lifetime: 4047.2130, mean_mc_travel_dist: 1069.2484, mean_rewards: 338.4191, total_rewards: 3017.8999, mean_steps: 10.8900, mean_ecr: 0.0553 mean_entropies: 0.1428, took: 54.4428s
2022-10-10 20:14:54,812 [INFO] 	Process 4 - batch 69099: mean_policy_losses: 45.663, mean_net_lifetime: 4788.1837, mean_mc_travel_dist: 1300.9992, mean_rewards: 274.0779, total_rewards: 3514.4516, mean_steps: 16.8000, mean_ecr: 0.0477 mean_entropies: 0.7044, took: 655.6843s
2022-10-10 20:15:31,229 [INFO] 	Process 3 - batch 65299: mean_policy_losses: -32.491, mean_net_lifetime: 4759.7697, mean_mc_travel_dist: 1258.5888, mean_rewards: 259.6667, total_rewards: 3540.7032, mean_steps: 17.4100, mean_ecr: 0.0480 mean_entropies: 0.4590, took: 84.1839s
2022-10-10 20:15:42,516 [INFO] 	Process 6 - batch 88399: mean_policy_losses: -78.156, mean_net_lifetime: 4091.8394, mean_mc_travel_dist: 1086.2440, mean_rewards: 340.4491, total_rewards: 3042.3040, mean_steps: 10.9400, mean_ecr: 0.0551 mean_entropies: 0.1243, took: 54.2408s
2022-10-10 20:15:50,217 [INFO] 	Process 2 - batch 62799: mean_policy_losses: -93.300, mean_net_lifetime: 6653.6670, mean_mc_travel_dist: 1865.3380, mean_rewards: 260.8480, total_rewards: 4819.9366, mean_steps: 24.5800, mean_ecr: 0.0387 mean_entropies: 0.4693, took: 109.2954s
2022-10-10 20:16:30,834 [INFO] 	Process 4 - batch 69199: mean_policy_losses: 66.893, mean_net_lifetime: 5924.0991, mean_mc_travel_dist: 1674.3192, mean_rewards: 280.0087, total_rewards: 4281.0394, mean_steps: 21.0000, mean_ecr: 0.0453 mean_entropies: 0.6333, took: 96.0219s
2022-10-10 20:16:36,460 [INFO] 	Process 6 - batch 88499: mean_policy_losses: -42.355, mean_net_lifetime: 3943.6464, mean_mc_travel_dist: 1046.7440, mean_rewards: 339.7456, total_rewards: 2949.2241, mean_steps: 10.5800, mean_ecr: 0.0555 mean_entropies: 0.1366, took: 53.9440s
2022-10-10 20:16:48,826 [INFO] 	Process 3 - batch 65399: mean_policy_losses: -31.485, mean_net_lifetime: 4672.4148, mean_mc_travel_dist: 1230.2491, mean_rewards: 259.8703, total_rewards: 3486.5903, mean_steps: 17.0700, mean_ecr: 0.0482 mean_entropies: 0.4360, took: 77.5971s
2022-10-10 20:17:33,629 [INFO] 	Process 2 - batch 62899: mean_policy_losses: -92.989, mean_net_lifetime: 6560.4994, mean_mc_travel_dist: 1802.9062, mean_rewards: 266.2017, total_rewards: 4788.4503, mean_steps: 23.7100, mean_ecr: 0.0390 mean_entropies: 0.4574, took: 103.4119s
2022-10-10 20:17:53,640 [INFO] Process 5 - epoch 41: mean_policy_losses: -211.089, mean_net_lifetime: 4724.5722, mean_mc_travel_dist: 1919.3002, mean_entropies: 1.2585, m_net_lifetime_valid: 4768.3843, took: 2364.6116s, (154.0001 / 100 batches)

2022-10-10 20:18:07,830 [INFO] 	Process 3 - batch 65499: mean_policy_losses: -32.493, mean_net_lifetime: 4661.0878, mean_mc_travel_dist: 1220.0590, mean_rewards: 259.4297, total_rewards: 3472.2288, mean_steps: 17.0300, mean_ecr: 0.0483 mean_entropies: 0.4388, took: 79.0034s
2022-10-10 20:18:11,121 [INFO] 	Process 4 - batch 69299: mean_policy_losses: 62.119, mean_net_lifetime: 6432.4732, mean_mc_travel_dist: 1834.1924, mean_rewards: 283.9301, total_rewards: 4621.1419, mean_steps: 22.8400, mean_ecr: 0.0437 mean_entropies: 0.6320, took: 100.2878s
2022-10-10 20:19:19,955 [INFO] 	Process 2 - batch 62999: mean_policy_losses: -62.633, mean_net_lifetime: 6707.3251, mean_mc_travel_dist: 1867.9385, mean_rewards: 269.9106, total_rewards: 4877.4423, mean_steps: 23.9200, mean_ecr: 0.0389 mean_entropies: 0.4860, took: 106.3259s
2022-10-10 20:19:26,661 [INFO] 	Process 3 - batch 65599: mean_policy_losses: -13.294, mean_net_lifetime: 4792.4029, mean_mc_travel_dist: 1241.4431, mean_rewards: 271.2318, total_rewards: 3590.5829, mean_steps: 16.7000, mean_ecr: 0.0483 mean_entropies: 0.4426, took: 78.8309s
2022-10-10 20:19:43,961 [INFO] 	Process 5 - batch 61599: mean_policy_losses: -181.714, mean_net_lifetime: 6700.6106, mean_mc_travel_dist: 2104.4478, mean_rewards: 262.6950, total_rewards: 4649.7605, mean_steps: 24.9300, mean_ecr: 0.0304 mean_entropies: 0.6081, took: 725.0806s
2022-10-10 20:19:45,674 [INFO] 	Process 4 - batch 69399: mean_policy_losses: 56.006, mean_net_lifetime: 6122.3319, mean_mc_travel_dist: 1736.8545, mean_rewards: 291.2167, total_rewards: 4413.3055, mean_steps: 20.5600, mean_ecr: 0.0443 mean_entropies: 0.5965, took: 94.5527s
2022-10-10 20:20:45,247 [INFO] 	Process 3 - batch 65699: mean_policy_losses: -18.961, mean_net_lifetime: 4795.6574, mean_mc_travel_dist: 1277.2811, mean_rewards: 270.8905, total_rewards: 3550.2681, mean_steps: 16.7600, mean_ecr: 0.0479 mean_entropies: 0.4559, took: 78.5864s
2022-10-10 20:21:03,043 [INFO] Process 1 - epoch 37: mean_policy_losses: 31.884, mean_net_lifetime: 4968.0817, mean_mc_travel_dist: 2030.6150, mean_entropies: 1.2332, m_net_lifetime_valid: 4371.0091, took: 2362.3774s, (171.0610 / 100 batches)

2022-10-10 20:21:29,481 [INFO] 	Process 4 - batch 69499: mean_policy_losses: 63.993, mean_net_lifetime: 6635.0176, mean_mc_travel_dist: 1912.3292, mean_rewards: 283.2912, total_rewards: 4751.5698, mean_steps: 23.5600, mean_ecr: 0.0433 mean_entropies: 0.5967, took: 103.8077s
2022-10-10 20:21:40,482 [INFO] 	Process 5 - batch 61699: mean_policy_losses: -143.030, mean_net_lifetime: 7272.5822, mean_mc_travel_dist: 2313.0735, mean_rewards: 267.9211, total_rewards: 5007.7807, mean_steps: 26.8900, mean_ecr: 0.0302 mean_entropies: 0.6261, took: 116.5204s
2022-10-10 20:21:56,194 [INFO] Process 7 - epoch 42: mean_policy_losses: -333.844, mean_net_lifetime: 4042.3829, mean_mc_travel_dist: 1566.6294, mean_entropies: 1.6205, m_net_lifetime_valid: 4834.0239, took: 2241.9471s, (150.6046 / 100 batches)

2022-10-10 20:22:06,449 [INFO] 	Process 3 - batch 65799: mean_policy_losses: 9.209, mean_net_lifetime: 4846.1411, mean_mc_travel_dist: 1286.9205, mean_rewards: 272.6503, total_rewards: 3593.6141, mean_steps: 16.8200, mean_ecr: 0.0477 mean_entropies: 0.4794, took: 81.2026s
2022-10-10 20:22:53,929 [INFO] 	Process 1 - batch 55599: mean_policy_losses: -47.061, mean_net_lifetime: 5920.1511, mean_mc_travel_dist: 1994.8434, mean_rewards: 238.4157, total_rewards: 3946.9128, mean_steps: 24.2500, mean_ecr: 0.0382 mean_entropies: 0.8864, took: 669.1871s
2022-10-10 20:23:18,414 [INFO] 	Process 4 - batch 69599: mean_policy_losses: 126.167, mean_net_lifetime: 6485.9385, mean_mc_travel_dist: 1849.2868, mean_rewards: 285.6047, total_rewards: 4664.3307, mean_steps: 22.8600, mean_ecr: 0.0438 mean_entropies: 0.5867, took: 108.9323s
2022-10-10 20:23:29,461 [INFO] 	Process 3 - batch 65899: mean_policy_losses: 30.026, mean_net_lifetime: 4758.6070, mean_mc_travel_dist: 1260.9048, mean_rewards: 274.2513, total_rewards: 3521.1687, mean_steps: 16.4000, mean_ecr: 0.0479 mean_entropies: 0.4974, took: 83.0125s
2022-10-10 20:23:33,372 [INFO] 	Process 7 - batch 63099: mean_policy_losses: -570.030, mean_net_lifetime: 4649.5149, mean_mc_travel_dist: 1432.8699, mean_rewards: 216.9476, total_rewards: 3252.9366, mean_steps: 20.8000, mean_ecr: 0.0411 mean_entropies: 1.3366, took: 787.0331s
2022-10-10 20:23:34,712 [INFO] 	Process 5 - batch 61799: mean_policy_losses: -93.318, mean_net_lifetime: 6721.0475, mean_mc_travel_dist: 2186.7969, mean_rewards: 274.8444, total_rewards: 4594.7802, mean_steps: 23.6900, mean_ecr: 0.0305 mean_entropies: 0.6001, took: 114.2303s
2022-10-10 20:24:51,167 [INFO] 	Process 1 - batch 55699: mean_policy_losses: -21.945, mean_net_lifetime: 6059.8974, mean_mc_travel_dist: 2009.8884, mean_rewards: 232.3886, total_rewards: 4075.3526, mean_steps: 25.5800, mean_ecr: 0.0382 mean_entropies: 0.8959, took: 117.2377s
2022-10-10 20:24:52,212 [INFO] 	Process 3 - batch 65999: mean_policy_losses: 23.813, mean_net_lifetime: 4901.6987, mean_mc_travel_dist: 1310.3450, mean_rewards: 279.3836, total_rewards: 3628.7449, mean_steps: 16.5900, mean_ecr: 0.0478 mean_entropies: 0.5076, took: 82.7505s
2022-10-10 20:25:11,618 [INFO] 	Process 4 - batch 69699: mean_policy_losses: 121.809, mean_net_lifetime: 6655.9387, mean_mc_travel_dist: 1905.0712, mean_rewards: 280.3567, total_rewards: 4772.2912, mean_steps: 23.9800, mean_ecr: 0.0436 mean_entropies: 0.6107, took: 113.2041s
2022-10-10 20:25:12,335 [INFO] 	Process 7 - batch 63199: mean_policy_losses: -531.828, mean_net_lifetime: 4722.4784, mean_mc_travel_dist: 1444.9383, mean_rewards: 210.9317, total_rewards: 3316.6206, mean_steps: 21.5800, mean_ecr: 0.0410 mean_entropies: 1.3759, took: 98.9631s
2022-10-10 20:25:32,493 [INFO] 	Process 5 - batch 61899: mean_policy_losses: -104.164, mean_net_lifetime: 7024.5582, mean_mc_travel_dist: 2270.7980, mean_rewards: 283.1313, total_rewards: 4802.1840, mean_steps: 24.1600, mean_ecr: 0.0303 mean_entropies: 0.6640, took: 117.7819s
2022-10-10 20:26:18,968 [INFO] Process 6 - epoch 59: mean_policy_losses: -225.005, mean_net_lifetime: 2945.2456, mean_mc_travel_dist: 955.5076, mean_entropies: 0.6506, m_net_lifetime_valid: 4289.4824, took: 1430.5113s, (107.6763 / 100 batches)

2022-10-10 20:26:49,624 [INFO] 	Process 7 - batch 63299: mean_policy_losses: -621.046, mean_net_lifetime: 4683.6814, mean_mc_travel_dist: 1415.8021, mean_rewards: 213.5396, total_rewards: 3312.6819, mean_steps: 21.2100, mean_ecr: 0.0412 mean_entropies: 1.3896, took: 97.2893s
2022-10-10 20:26:55,422 [INFO] 	Process 1 - batch 55799: mean_policy_losses: 51.788, mean_net_lifetime: 6391.7746, mean_mc_travel_dist: 2070.7847, mean_rewards: 229.5264, total_rewards: 4348.8258, mean_steps: 27.1800, mean_ecr: 0.0379 mean_entropies: 0.9399, took: 124.2563s
2022-10-10 20:27:13,647 [INFO] 	Process 4 - batch 69799: mean_policy_losses: 151.618, mean_net_lifetime: 7259.0215, mean_mc_travel_dist: 2126.2505, mean_rewards: 277.2623, total_rewards: 5159.7068, mean_steps: 26.6700, mean_ecr: 0.0418 mean_entropies: 0.5983, took: 122.0289s
2022-10-10 20:27:16,888 [INFO] 	Process 6 - batch 88599: mean_policy_losses: -119.177, mean_net_lifetime: 3972.9094, mean_mc_travel_dist: 1070.8769, mean_rewards: 338.4557, total_rewards: 2958.5181, mean_steps: 10.6700, mean_ecr: 0.0550 mean_entropies: 0.1440, took: 640.4280s
2022-10-10 20:27:37,667 [INFO] 	Process 5 - batch 61999: mean_policy_losses: -115.062, mean_net_lifetime: 7509.5147, mean_mc_travel_dist: 2444.3521, mean_rewards: 272.5752, total_rewards: 5106.1778, mean_steps: 27.1600, mean_ecr: 0.0301 mean_entropies: 0.6321, took: 125.1738s
2022-10-10 20:28:12,871 [INFO] 	Process 6 - batch 88699: mean_policy_losses: -107.939, mean_net_lifetime: 3891.5954, mean_mc_travel_dist: 1036.6332, mean_rewards: 339.7840, total_rewards: 2905.0905, mean_steps: 10.3800, mean_ecr: 0.0551 mean_entropies: 0.1353, took: 55.9831s
2022-10-10 20:28:37,139 [INFO] 	Process 7 - batch 63399: mean_policy_losses: -512.575, mean_net_lifetime: 5059.6542, mean_mc_travel_dist: 1545.8298, mean_rewards: 215.2193, total_rewards: 3548.7686, mean_steps: 23.2000, mean_ecr: 0.0407 mean_entropies: 1.3747, took: 107.5145s
2022-10-10 20:28:58,821 [INFO] 	Process 1 - batch 55899: mean_policy_losses: -34.527, mean_net_lifetime: 6175.8438, mean_mc_travel_dist: 2030.0615, mean_rewards: 227.2687, total_rewards: 4177.0009, mean_steps: 26.5800, mean_ecr: 0.0381 mean_entropies: 0.9696, took: 123.3978s
2022-10-10 20:28:59,406 [INFO] 	Process 4 - batch 69899: mean_policy_losses: 80.215, mean_net_lifetime: 6414.3461, mean_mc_travel_dist: 1837.5787, mean_rewards: 283.1182, total_rewards: 4605.2555, mean_steps: 22.3300, mean_ecr: 0.0442 mean_entropies: 0.6237, took: 105.7594s
2022-10-10 20:29:08,245 [INFO] 	Process 6 - batch 88799: mean_policy_losses: -115.601, mean_net_lifetime: 3902.0578, mean_mc_travel_dist: 1042.1903, mean_rewards: 338.4049, total_rewards: 2914.1841, mean_steps: 10.4200, mean_ecr: 0.0552 mean_entropies: 0.1230, took: 55.3741s
2022-10-10 20:29:39,910 [INFO] Process 2 - epoch 42: mean_policy_losses: 2.156, mean_net_lifetime: 4531.9019, mean_mc_travel_dist: 1572.3671, mean_entropies: 0.9864, m_net_lifetime_valid: 4751.5525, took: 2327.3700s, (151.4505 / 100 batches)

2022-10-10 20:30:02,628 [INFO] 	Process 5 - batch 62099: mean_policy_losses: -106.736, mean_net_lifetime: 8346.6715, mean_mc_travel_dist: 2676.2183, mean_rewards: 266.1751, total_rewards: 5709.7619, mean_steps: 31.2300, mean_ecr: 0.0300 mean_entropies: 0.6557, took: 144.9609s
2022-10-10 20:30:07,133 [INFO] 	Process 6 - batch 88899: mean_policy_losses: -41.411, mean_net_lifetime: 4119.7822, mean_mc_travel_dist: 1112.1391, mean_rewards: 340.7131, total_rewards: 3075.4672, mean_steps: 11.0300, mean_ecr: 0.0549 mean_entropies: 0.1257, took: 58.8884s
2022-10-10 20:30:21,672 [INFO] 	Process 7 - batch 63499: mean_policy_losses: -501.089, mean_net_lifetime: 4890.5933, mean_mc_travel_dist: 1506.2522, mean_rewards: 212.6233, total_rewards: 3419.9778, mean_steps: 22.2200, mean_ecr: 0.0408 mean_entropies: 1.3271, took: 104.5324s
2022-10-10 20:30:49,938 [INFO] 	Process 4 - batch 69999: mean_policy_losses: 104.740, mean_net_lifetime: 6436.1962, mean_mc_travel_dist: 1823.1392, mean_rewards: 282.1000, total_rewards: 4647.0061, mean_steps: 22.7000, mean_ecr: 0.0439 mean_entropies: 0.6199, took: 110.5315s
2022-10-10 20:30:54,481 [INFO] 	Process 1 - batch 55999: mean_policy_losses: -70.485, mean_net_lifetime: 5809.3950, mean_mc_travel_dist: 1952.8150, mean_rewards: 232.6166, total_rewards: 3889.6738, mean_steps: 24.3400, mean_ecr: 0.0383 mean_entropies: 0.9178, took: 115.6608s
2022-10-10 20:31:08,731 [INFO] 	Process 6 - batch 88999: mean_policy_losses: -33.762, mean_net_lifetime: 4145.1940, mean_mc_travel_dist: 1119.1333, mean_rewards: 341.3565, total_rewards: 3099.8362, mean_steps: 11.1200, mean_ecr: 0.0548 mean_entropies: 0.1214, took: 61.5970s
2022-10-10 20:31:34,308 [INFO] 	Process 2 - batch 63099: mean_policy_losses: -55.464, mean_net_lifetime: 6558.0728, mean_mc_travel_dist: 1841.6191, mean_rewards: 266.4015, total_rewards: 4756.7375, mean_steps: 23.6900, mean_ecr: 0.0388 mean_entropies: 0.4690, took: 734.3537s
2022-10-10 20:32:07,953 [INFO] 	Process 6 - batch 89099: mean_policy_losses: -67.351, mean_net_lifetime: 4083.4576, mean_mc_travel_dist: 1099.3161, mean_rewards: 341.1239, total_rewards: 3059.1460, mean_steps: 10.9200, mean_ecr: 0.0548 mean_entropies: 0.1163, took: 59.2221s
2022-10-10 20:32:08,707 [INFO] 	Process 7 - batch 63599: mean_policy_losses: -483.939, mean_net_lifetime: 4969.7163, mean_mc_travel_dist: 1536.2110, mean_rewards: 214.7281, total_rewards: 3462.7283, mean_steps: 22.2100, mean_ecr: 0.0407 mean_entropies: 1.3268, took: 107.0356s
2022-10-10 20:32:16,272 [INFO] 	Process 5 - batch 62199: mean_policy_losses: -163.364, mean_net_lifetime: 7441.1662, mean_mc_travel_dist: 2421.6943, mean_rewards: 265.3448, total_rewards: 5069.1842, mean_steps: 27.9100, mean_ecr: 0.0301 mean_entropies: 0.5935, took: 133.6437s
2022-10-10 20:32:30,769 [INFO] 	Process 4 - batch 70099: mean_policy_losses: 70.816, mean_net_lifetime: 5928.6965, mean_mc_travel_dist: 1656.1938, mean_rewards: 284.2307, total_rewards: 4297.3111, mean_steps: 20.2200, mean_ecr: 0.0448 mean_entropies: 0.6274, took: 100.8312s
2022-10-10 20:32:57,910 [INFO] 	Process 1 - batch 56099: mean_policy_losses: -42.471, mean_net_lifetime: 6135.4730, mean_mc_travel_dist: 2001.2226, mean_rewards: 231.4662, total_rewards: 4159.2518, mean_steps: 25.8000, mean_ecr: 0.0382 mean_entropies: 0.9560, took: 123.4288s
2022-10-10 20:33:08,329 [INFO] 	Process 6 - batch 89199: mean_policy_losses: -104.698, mean_net_lifetime: 4152.2569, mean_mc_travel_dist: 1121.6189, mean_rewards: 341.4751, total_rewards: 3107.6117, mean_steps: 11.1100, mean_ecr: 0.0547 mean_entropies: 0.1032, took: 60.3763s
2022-10-10 20:33:33,090 [INFO] 	Process 2 - batch 63199: mean_policy_losses: -60.994, mean_net_lifetime: 6778.4374, mean_mc_travel_dist: 1911.6320, mean_rewards: 264.6653, total_rewards: 4900.4413, mean_steps: 24.7400, mean_ecr: 0.0385 mean_entropies: 0.4754, took: 118.7821s
2022-10-10 20:33:57,062 [INFO] 	Process 7 - batch 63699: mean_policy_losses: -555.157, mean_net_lifetime: 4932.9297, mean_mc_travel_dist: 1545.3185, mean_rewards: 210.2443, total_rewards: 3424.9228, mean_steps: 22.8100, mean_ecr: 0.0410 mean_entropies: 1.3738, took: 108.3548s
2022-10-10 20:34:07,159 [INFO] 	Process 6 - batch 89299: mean_policy_losses: -97.590, mean_net_lifetime: 4030.8086, mean_mc_travel_dist: 1085.2666, mean_rewards: 340.2594, total_rewards: 3012.5960, mean_steps: 10.7800, mean_ecr: 0.0550 mean_entropies: 0.1027, took: 58.8306s
2022-10-10 20:34:18,234 [INFO] 	Process 4 - batch 70199: mean_policy_losses: 73.835, mean_net_lifetime: 6221.1637, mean_mc_travel_dist: 1731.0788, mean_rewards: 282.6567, total_rewards: 4521.6297, mean_steps: 21.8000, mean_ecr: 0.0448 mean_entropies: 0.6578, took: 107.4641s
2022-10-10 20:34:20,152 [INFO] Process 3 - epoch 44: mean_policy_losses: 69.388, mean_net_lifetime: 4245.0586, mean_mc_travel_dist: 1366.6334, mean_entropies: 0.9487, m_net_lifetime_valid: 4430.1563, took: 1798.0114s, (145.0783 / 100 batches)

2022-10-10 20:34:35,218 [INFO] 	Process 5 - batch 62299: mean_policy_losses: -117.001, mean_net_lifetime: 7733.3375, mean_mc_travel_dist: 2546.8450, mean_rewards: 266.7929, total_rewards: 5230.9523, mean_steps: 28.5500, mean_ecr: 0.0299 mean_entropies: 0.6192, took: 138.9457s
2022-10-10 20:35:06,390 [INFO] 	Process 1 - batch 56199: mean_policy_losses: 8.186, mean_net_lifetime: 6496.3051, mean_mc_travel_dist: 2146.7395, mean_rewards: 237.2976, total_rewards: 4372.1172, mean_steps: 26.6800, mean_ecr: 0.0377 mean_entropies: 0.9472, took: 128.4795s
2022-10-10 20:35:09,806 [INFO] 	Process 6 - batch 89399: mean_policy_losses: -28.645, mean_net_lifetime: 4325.8044, mean_mc_travel_dist: 1167.1633, mean_rewards: 343.1625, total_rewards: 3242.1797, mean_steps: 11.5800, mean_ecr: 0.0544 mean_entropies: 0.0864, took: 62.6464s
2022-10-10 20:35:35,936 [INFO] 	Process 2 - batch 63299: mean_policy_losses: -38.779, mean_net_lifetime: 6995.1628, mean_mc_travel_dist: 1979.6299, mean_rewards: 267.0516, total_rewards: 5049.4124, mean_steps: 25.2700, mean_ecr: 0.0383 mean_entropies: 0.4872, took: 122.8458s
2022-10-10 20:35:36,807 [INFO] 	Process 7 - batch 63799: mean_policy_losses: -675.083, mean_net_lifetime: 4540.6260, mean_mc_travel_dist: 1443.8736, mean_rewards: 220.2230, total_rewards: 3131.2442, mean_steps: 19.9700, mean_ecr: 0.0413 mean_entropies: 1.3364, took: 99.7462s
2022-10-10 20:35:46,348 [INFO] 	Process 3 - batch 66099: mean_policy_losses: -24.555, mean_net_lifetime: 4710.3133, mean_mc_travel_dist: 1285.0238, mean_rewards: 271.9250, total_rewards: 3460.7983, mean_steps: 16.3600, mean_ecr: 0.0476 mean_entropies: 0.4852, took: 654.1359s
2022-10-10 20:36:09,950 [INFO] 	Process 6 - batch 89499: mean_policy_losses: -73.873, mean_net_lifetime: 4011.5132, mean_mc_travel_dist: 1071.6926, mean_rewards: 341.1330, total_rewards: 2996.2069, mean_steps: 10.6900, mean_ecr: 0.0552 mean_entropies: 0.1063, took: 60.1444s
2022-10-10 20:36:18,134 [INFO] 	Process 4 - batch 70299: mean_policy_losses: 133.466, mean_net_lifetime: 6737.5803, mean_mc_travel_dist: 1940.7061, mean_rewards: 281.8512, total_rewards: 4821.6515, mean_steps: 23.8600, mean_ecr: 0.0433 mean_entropies: 0.6214, took: 119.9011s
2022-10-10 20:36:56,268 [INFO] 	Process 5 - batch 62399: mean_policy_losses: -107.132, mean_net_lifetime: 7815.8886, mean_mc_travel_dist: 2503.5084, mean_rewards: 266.7195, total_rewards: 5358.3456, mean_steps: 28.7300, mean_ecr: 0.0301 mean_entropies: 0.6439, took: 141.0507s
2022-10-10 20:37:12,333 [INFO] 	Process 3 - batch 66199: mean_policy_losses: -20.276, mean_net_lifetime: 4730.4486, mean_mc_travel_dist: 1286.2981, mean_rewards: 273.0250, total_rewards: 3479.0553, mean_steps: 16.4100, mean_ecr: 0.0479 mean_entropies: 0.4856, took: 85.9856s
2022-10-10 20:37:12,733 [INFO] 	Process 6 - batch 89599: mean_policy_losses: -61.433, mean_net_lifetime: 4154.0863, mean_mc_travel_dist: 1121.7530, mean_rewards: 341.3703, total_rewards: 3113.7960, mean_steps: 11.1200, mean_ecr: 0.0548 mean_entropies: 0.0973, took: 62.7829s
2022-10-10 20:37:14,334 [INFO] 	Process 1 - batch 56299: mean_policy_losses: -9.780, mean_net_lifetime: 6286.7333, mean_mc_travel_dist: 2056.7366, mean_rewards: 234.5631, total_rewards: 4260.8244, mean_steps: 26.0800, mean_ecr: 0.0380 mean_entropies: 0.9687, took: 127.9437s
2022-10-10 20:37:19,636 [INFO] 	Process 7 - batch 63899: mean_policy_losses: -618.576, mean_net_lifetime: 4682.0158, mean_mc_travel_dist: 1504.2194, mean_rewards: 218.9000, total_rewards: 3222.3434, mean_steps: 20.4800, mean_ecr: 0.0411 mean_entropies: 1.3745, took: 102.8280s
2022-10-10 20:37:21,881 [INFO] 	Process 2 - batch 63399: mean_policy_losses: -142.261, mean_net_lifetime: 5774.6811, mean_mc_travel_dist: 1632.6416, mean_rewards: 263.4983, total_rewards: 4172.9006, mean_steps: 21.0700, mean_ecr: 0.0396 mean_entropies: 0.4530, took: 105.9454s
2022-10-10 20:38:13,066 [INFO] 	Process 6 - batch 89699: mean_policy_losses: -71.569, mean_net_lifetime: 4102.3147, mean_mc_travel_dist: 1106.3764, mean_rewards: 343.7405, total_rewards: 3073.2673, mean_steps: 10.9300, mean_ecr: 0.0548 mean_entropies: 0.1013, took: 60.3335s
2022-10-10 20:38:16,743 [INFO] 	Process 4 - batch 70399: mean_policy_losses: 159.430, mean_net_lifetime: 6733.5549, mean_mc_travel_dist: 1990.9829, mean_rewards: 286.6048, total_rewards: 4776.7772, mean_steps: 23.5900, mean_ecr: 0.0430 mean_entropies: 0.5792, took: 118.6088s
2022-10-10 20:38:37,038 [INFO] 	Process 3 - batch 66299: mean_policy_losses: -0.490, mean_net_lifetime: 4655.3988, mean_mc_travel_dist: 1237.4395, mean_rewards: 271.9855, total_rewards: 3449.5900, mean_steps: 16.1700, mean_ecr: 0.0483 mean_entropies: 0.4597, took: 84.7043s
2022-10-10 20:38:52,516 [INFO] 	Process 7 - batch 63999: mean_policy_losses: -589.206, mean_net_lifetime: 4369.3089, mean_mc_travel_dist: 1415.6476, mean_rewards: 224.1740, total_rewards: 2997.4781, mean_steps: 18.5000, mean_ecr: 0.0412 mean_entropies: 1.2984, took: 92.8798s
2022-10-10 20:39:04,310 [INFO] 	Process 2 - batch 63499: mean_policy_losses: -100.917, mean_net_lifetime: 5674.2258, mean_mc_travel_dist: 1556.3284, mean_rewards: 266.8322, total_rewards: 4154.3719, mean_steps: 20.3500, mean_ecr: 0.0398 mean_entropies: 0.4593, took: 102.4292s
2022-10-10 20:39:06,874 [INFO] 	Process 1 - batch 56399: mean_policy_losses: -96.124, mean_net_lifetime: 5569.6024, mean_mc_travel_dist: 1989.1284, mean_rewards: 238.3010, total_rewards: 3600.2222, mean_steps: 22.6400, mean_ecr: 0.0383 mean_entropies: 0.8642, took: 112.5402s
2022-10-10 20:39:10,164 [INFO] 	Process 5 - batch 62499: mean_policy_losses: -148.459, mean_net_lifetime: 7098.8914, mean_mc_travel_dist: 2286.4165, mean_rewards: 268.2657, total_rewards: 4854.4715, mean_steps: 26.5300, mean_ecr: 0.0301 mean_entropies: 0.5555, took: 133.8959s
2022-10-10 20:39:16,109 [INFO] 	Process 6 - batch 89799: mean_policy_losses: -10.416, mean_net_lifetime: 4263.0518, mean_mc_travel_dist: 1147.0223, mean_rewards: 344.4722, total_rewards: 3197.2050, mean_steps: 11.3800, mean_ecr: 0.0546 mean_entropies: 0.0775, took: 63.0425s
2022-10-10 20:40:02,611 [INFO] 	Process 3 - batch 66399: mean_policy_losses: 1.529, mean_net_lifetime: 4659.1695, mean_mc_travel_dist: 1228.6031, mean_rewards: 267.4499, total_rewards: 3468.8949, mean_steps: 16.4800, mean_ecr: 0.0481 mean_entropies: 0.4510, took: 85.5728s
2022-10-10 20:40:16,820 [INFO] 	Process 6 - batch 89899: mean_policy_losses: -21.148, mean_net_lifetime: 4222.7234, mean_mc_travel_dist: 1133.6524, mean_rewards: 342.9492, total_rewards: 3166.4819, mean_steps: 11.2900, mean_ecr: 0.0546 mean_entropies: 0.0868, took: 60.7107s
2022-10-10 20:40:18,241 [INFO] 	Process 4 - batch 70499: mean_policy_losses: 155.701, mean_net_lifetime: 6744.6403, mean_mc_travel_dist: 1968.9060, mean_rewards: 280.6349, total_rewards: 4800.0319, mean_steps: 24.1800, mean_ecr: 0.0429 mean_entropies: 0.5996, took: 121.4984s
2022-10-10 20:40:37,122 [INFO] 	Process 7 - batch 64099: mean_policy_losses: -607.347, mean_net_lifetime: 4640.2997, mean_mc_travel_dist: 1461.4003, mean_rewards: 213.0769, total_rewards: 3221.5334, mean_steps: 21.0800, mean_ecr: 0.0410 mean_entropies: 1.3590, took: 104.6071s
2022-10-10 20:40:51,340 [INFO] 	Process 2 - batch 63599: mean_policy_losses: -98.961, mean_net_lifetime: 6043.3930, mean_mc_travel_dist: 1668.7236, mean_rewards: 267.4804, total_rewards: 4401.2734, mean_steps: 21.6600, mean_ecr: 0.0395 mean_entropies: 0.4488, took: 107.0300s
2022-10-10 20:41:14,676 [INFO] 	Process 1 - batch 56499: mean_policy_losses: -98.103, mean_net_lifetime: 5844.5068, mean_mc_travel_dist: 1960.8869, mean_rewards: 220.5135, total_rewards: 3912.2549, mean_steps: 25.8300, mean_ecr: 0.0383 mean_entropies: 0.9012, took: 127.8030s
2022-10-10 20:41:17,596 [INFO] 	Process 6 - batch 89999: mean_policy_losses: -62.585, mean_net_lifetime: 4227.8689, mean_mc_travel_dist: 1138.2779, mean_rewards: 343.6194, total_rewards: 3161.9464, mean_steps: 11.2800, mean_ecr: 0.0547 mean_entropies: 0.0798, took: 60.7766s
2022-10-10 20:41:17,628 [INFO] 	Process 5 - batch 62599: mean_policy_losses: -169.250, mean_net_lifetime: 6921.0125, mean_mc_travel_dist: 2246.4761, mean_rewards: 266.8781, total_rewards: 4722.9834, mean_steps: 25.5400, mean_ecr: 0.0303 mean_entropies: 0.5810, took: 127.4637s
2022-10-10 20:41:28,892 [INFO] 	Process 3 - batch 66499: mean_policy_losses: -4.569, mean_net_lifetime: 4716.4237, mean_mc_travel_dist: 1257.7173, mean_rewards: 264.9780, total_rewards: 3490.6640, mean_steps: 16.8700, mean_ecr: 0.0481 mean_entropies: 0.4577, took: 86.2812s
2022-10-10 20:42:20,155 [INFO] 	Process 7 - batch 64199: mean_policy_losses: -336.541, mean_net_lifetime: 4959.1589, mean_mc_travel_dist: 1534.9242, mean_rewards: 217.8277, total_rewards: 3470.9514, mean_steps: 22.0500, mean_ecr: 0.0409 mean_entropies: 1.2736, took: 103.0324s
2022-10-10 20:42:54,095 [INFO] 	Process 3 - batch 66599: mean_policy_losses: -10.968, mean_net_lifetime: 4737.9517, mean_mc_travel_dist: 1272.4415, mean_rewards: 260.7570, total_rewards: 3492.8612, mean_steps: 17.2000, mean_ecr: 0.0481 mean_entropies: 0.4795, took: 85.2034s
2022-10-10 20:42:56,403 [INFO] 	Process 2 - batch 63699: mean_policy_losses: 1.710, mean_net_lifetime: 7311.7436, mean_mc_travel_dist: 2075.4226, mean_rewards: 262.1451, total_rewards: 5270.1526, mean_steps: 27.0300, mean_ecr: 0.0381 mean_entropies: 0.4680, took: 125.0626s
2022-10-10 20:43:07,246 [INFO] 	Process 1 - batch 56599: mean_policy_losses: -11.597, mean_net_lifetime: 6078.9127, mean_mc_travel_dist: 2039.0934, mean_rewards: 240.4792, total_rewards: 4066.2167, mean_steps: 24.6200, mean_ecr: 0.0380 mean_entropies: 0.8965, took: 112.5705s
2022-10-10 20:43:20,469 [INFO] 	Process 5 - batch 62699: mean_policy_losses: -79.917, mean_net_lifetime: 7337.1833, mean_mc_travel_dist: 2385.8412, mean_rewards: 276.6799, total_rewards: 4997.6285, mean_steps: 25.7800, mean_ecr: 0.0303 mean_entropies: 0.5904, took: 122.8407s
2022-10-10 20:44:01,294 [INFO] 	Process 7 - batch 64299: mean_policy_losses: -335.113, mean_net_lifetime: 4727.6665, mean_mc_travel_dist: 1446.1221, mean_rewards: 210.6559, total_rewards: 3311.1065, mean_steps: 21.8200, mean_ecr: 0.0412 mean_entropies: 1.2767, took: 101.1395s
2022-10-10 20:44:14,887 [INFO] 	Process 3 - batch 66699: mean_policy_losses: 3.630, mean_net_lifetime: 4795.5258, mean_mc_travel_dist: 1287.5552, mean_rewards: 275.3862, total_rewards: 3543.7119, mean_steps: 16.4400, mean_ecr: 0.0477 mean_entropies: 0.5221, took: 80.7914s
2022-10-10 20:44:59,073 [INFO] 	Process 2 - batch 63799: mean_policy_losses: -35.982, mean_net_lifetime: 6981.6950, mean_mc_travel_dist: 2046.3056, mean_rewards: 252.9888, total_rewards: 4964.9179, mean_steps: 26.7500, mean_ecr: 0.0380 mean_entropies: 0.5105, took: 122.6699s
2022-10-10 20:45:10,641 [INFO] 	Process 1 - batch 56699: mean_policy_losses: -37.418, mean_net_lifetime: 6158.9576, mean_mc_travel_dist: 2063.2296, mean_rewards: 227.5526, total_rewards: 4119.3766, mean_steps: 26.5100, mean_ecr: 0.0381 mean_entropies: 0.8538, took: 123.3943s
2022-10-10 20:45:22,400 [INFO] 	Process 5 - batch 62799: mean_policy_losses: -35.832, mean_net_lifetime: 7463.6592, mean_mc_travel_dist: 2489.2349, mean_rewards: 281.1219, total_rewards: 5019.7258, mean_steps: 25.8000, mean_ecr: 0.0300 mean_entropies: 0.6014, took: 121.9312s
2022-10-10 20:45:35,329 [INFO] 	Process 3 - batch 66799: mean_policy_losses: 6.238, mean_net_lifetime: 4631.8666, mean_mc_travel_dist: 1210.2576, mean_rewards: 271.9748, total_rewards: 3454.4261, mean_steps: 16.0600, mean_ecr: 0.0483 mean_entropies: 0.4924, took: 80.4423s
2022-10-10 20:45:37,330 [INFO] 	Process 7 - batch 64399: mean_policy_losses: -372.005, mean_net_lifetime: 4556.5202, mean_mc_travel_dist: 1445.3818, mean_rewards: 209.8476, total_rewards: 3159.9338, mean_steps: 20.8800, mean_ecr: 0.0412 mean_entropies: 1.2450, took: 96.0359s
2022-10-10 20:46:57,186 [INFO] 	Process 3 - batch 66899: mean_policy_losses: 3.557, mean_net_lifetime: 4782.0983, mean_mc_travel_dist: 1269.4335, mean_rewards: 273.6285, total_rewards: 3542.0396, mean_steps: 16.5600, mean_ecr: 0.0482 mean_entropies: 0.4627, took: 81.8567s
2022-10-10 20:47:00,237 [INFO] 	Process 2 - batch 63899: mean_policy_losses: -18.677, mean_net_lifetime: 7112.2577, mean_mc_travel_dist: 2015.8963, mean_rewards: 263.8852, total_rewards: 5132.3915, mean_steps: 26.0900, mean_ecr: 0.0381 mean_entropies: 0.4994, took: 121.1644s
2022-10-10 20:47:11,557 [INFO] 	Process 1 - batch 56799: mean_policy_losses: -36.979, mean_net_lifetime: 6220.3706, mean_mc_travel_dist: 2056.0273, mean_rewards: 229.5256, total_rewards: 4198.5488, mean_steps: 26.4000, mean_ecr: 0.0380 mean_entropies: 0.9189, took: 120.9162s
2022-10-10 20:47:16,293 [INFO] 	Process 7 - batch 64499: mean_policy_losses: -429.428, mean_net_lifetime: 4533.6817, mean_mc_travel_dist: 1423.2196, mean_rewards: 209.1340, total_rewards: 3153.0450, mean_steps: 21.1600, mean_ecr: 0.0413 mean_entropies: 1.2538, took: 98.9625s
2022-10-10 20:47:23,499 [INFO] 	Process 5 - batch 62899: mean_policy_losses: -40.468, mean_net_lifetime: 7337.3986, mean_mc_travel_dist: 2430.9389, mean_rewards: 282.1951, total_rewards: 4958.7876, mean_steps: 25.4700, mean_ecr: 0.0302 mean_entropies: 0.5824, took: 121.0986s
2022-10-10 20:48:16,785 [INFO] 	Process 3 - batch 66999: mean_policy_losses: -18.628, mean_net_lifetime: 4806.6841, mean_mc_travel_dist: 1262.8118, mean_rewards: 271.8830, total_rewards: 3574.8316, mean_steps: 16.7300, mean_ecr: 0.0481 mean_entropies: 0.4792, took: 79.5993s
2022-10-10 20:49:04,664 [INFO] 	Process 2 - batch 63999: mean_policy_losses: -5.719, mean_net_lifetime: 7516.8711, mean_mc_travel_dist: 2133.1570, mean_rewards: 262.4547, total_rewards: 5416.9915, mean_steps: 27.6900, mean_ecr: 0.0377 mean_entropies: 0.5193, took: 124.4263s
2022-10-10 20:49:07,621 [INFO] 	Process 1 - batch 56899: mean_policy_losses: -7.999, mean_net_lifetime: 6458.3528, mean_mc_travel_dist: 2104.3207, mean_rewards: 241.8319, total_rewards: 4382.6463, mean_steps: 25.8800, mean_ecr: 0.0379 mean_entropies: 0.9657, took: 116.0639s
2022-10-10 20:49:35,464 [INFO] 	Process 3 - batch 67099: mean_policy_losses: -23.547, mean_net_lifetime: 4691.8224, mean_mc_travel_dist: 1227.9209, mean_rewards: 268.0922, total_rewards: 3500.6103, mean_steps: 16.5500, mean_ecr: 0.0482 mean_entropies: 0.4803, took: 78.6793s
2022-10-10 20:49:43,450 [INFO] 	Process 5 - batch 62999: mean_policy_losses: -21.572, mean_net_lifetime: 8474.3649, mean_mc_travel_dist: 2775.1374, mean_rewards: 277.3335, total_rewards: 5739.1739, mean_steps: 30.4500, mean_ecr: 0.0301 mean_entropies: 0.6344, took: 139.9510s
2022-10-10 20:50:24,667 [INFO] Process 4 - epoch 47: mean_policy_losses: 88.533, mean_net_lifetime: 4150.8472, mean_mc_travel_dist: 1347.7779, mean_entropies: 1.1874, m_net_lifetime_valid: 4323.9358, took: 2209.2667s, (137.1435 / 100 batches)

2022-10-10 20:50:51,781 [INFO] 	Process 3 - batch 67199: mean_policy_losses: -37.963, mean_net_lifetime: 4710.9694, mean_mc_travel_dist: 1238.6568, mean_rewards: 267.5660, total_rewards: 3510.2588, mean_steps: 16.6600, mean_ecr: 0.0483 mean_entropies: 0.5025, took: 76.3171s
2022-10-10 20:50:59,690 [INFO] 	Process 1 - batch 56999: mean_policy_losses: -33.269, mean_net_lifetime: 6370.0252, mean_mc_travel_dist: 2062.1523, mean_rewards: 235.4324, total_rewards: 4337.1752, mean_steps: 26.3700, mean_ecr: 0.0380 mean_entropies: 0.9569, took: 112.0687s
2022-10-10 20:51:02,112 [INFO] 	Process 2 - batch 64099: mean_policy_losses: -52.139, mean_net_lifetime: 7285.6269, mean_mc_travel_dist: 2067.8776, mean_rewards: 264.7559, total_rewards: 5245.9817, mean_steps: 26.6200, mean_ecr: 0.0380 mean_entropies: 0.5083, took: 117.4482s
2022-10-10 20:51:40,622 [INFO] Process 6 - epoch 60: mean_policy_losses: -222.385, mean_net_lifetime: 2964.6086, mean_mc_travel_dist: 957.9971, mean_entropies: 0.6415, m_net_lifetime_valid: 4316.6741, took: 1521.6509s, (107.5275 / 100 batches)

2022-10-10 20:51:57,738 [INFO] 	Process 4 - batch 70599: mean_policy_losses: 116.550, mean_net_lifetime: 5543.4071, mean_mc_travel_dist: 1566.4065, mean_rewards: 265.0937, total_rewards: 4000.7874, mean_steps: 20.6300, mean_ecr: 0.0459 mean_entropies: 0.6859, took: 699.4959s
2022-10-10 20:52:08,383 [INFO] 	Process 3 - batch 67299: mean_policy_losses: -25.845, mean_net_lifetime: 4766.2986, mean_mc_travel_dist: 1236.4298, mean_rewards: 272.4344, total_rewards: 3555.0056, mean_steps: 16.5600, mean_ecr: 0.0481 mean_entropies: 0.4777, took: 76.6015s
2022-10-10 20:52:31,796 [INFO] 	Process 6 - batch 90099: mean_policy_losses: -165.406, mean_net_lifetime: 3874.0457, mean_mc_travel_dist: 1044.2656, mean_rewards: 337.1529, total_rewards: 2884.6612, mean_steps: 10.4500, mean_ecr: 0.0551 mean_entropies: 0.1660, took: 674.2001s
2022-10-10 20:52:53,569 [INFO] 	Process 2 - batch 64199: mean_policy_losses: -55.933, mean_net_lifetime: 6992.2914, mean_mc_travel_dist: 1965.6847, mean_rewards: 265.3745, total_rewards: 5056.6221, mean_steps: 25.4300, mean_ecr: 0.0384 mean_entropies: 0.4683, took: 111.4567s
2022-10-10 20:53:24,759 [INFO] 	Process 6 - batch 90199: mean_policy_losses: -113.388, mean_net_lifetime: 3920.4573, mean_mc_travel_dist: 1032.7677, mean_rewards: 340.0195, total_rewards: 2934.8365, mean_steps: 10.4800, mean_ecr: 0.0554 mean_entropies: 0.1421, took: 52.9624s
2022-10-10 20:53:28,123 [INFO] 	Process 3 - batch 67399: mean_policy_losses: -15.807, mean_net_lifetime: 4743.4472, mean_mc_travel_dist: 1244.6919, mean_rewards: 268.7442, total_rewards: 3544.5880, mean_steps: 16.7000, mean_ecr: 0.0481 mean_entropies: 0.4618, took: 79.7400s
2022-10-10 20:53:49,330 [INFO] 	Process 4 - batch 70699: mean_policy_losses: 103.048, mean_net_lifetime: 6640.0265, mean_mc_travel_dist: 1935.9497, mean_rewards: 273.1246, total_rewards: 4730.7773, mean_steps: 24.4200, mean_ecr: 0.0432 mean_entropies: 0.6032, took: 111.5926s
2022-10-10 20:54:16,712 [INFO] 	Process 6 - batch 90299: mean_policy_losses: -96.350, mean_net_lifetime: 3839.4647, mean_mc_travel_dist: 1024.5613, mean_rewards: 338.4409, total_rewards: 2873.4609, mean_steps: 10.2900, mean_ecr: 0.0556 mean_entropies: 0.1415, took: 51.9535s
2022-10-10 20:54:39,839 [INFO] 	Process 2 - batch 64299: mean_policy_losses: -87.129, mean_net_lifetime: 6596.7950, mean_mc_travel_dist: 1800.1482, mean_rewards: 269.1920, total_rewards: 4827.0691, mean_steps: 23.5700, mean_ecr: 0.0391 mean_entropies: 0.4728, took: 106.2699s
2022-10-10 20:54:47,430 [INFO] 	Process 3 - batch 67499: mean_policy_losses: -25.085, mean_net_lifetime: 4724.6757, mean_mc_travel_dist: 1244.8583, mean_rewards: 267.4949, total_rewards: 3513.7206, mean_steps: 16.7100, mean_ecr: 0.0482 mean_entropies: 0.4815, took: 79.3069s
2022-10-10 20:55:07,700 [INFO] 	Process 6 - batch 90399: mean_policy_losses: -151.313, mean_net_lifetime: 3848.3361, mean_mc_travel_dist: 1031.0489, mean_rewards: 340.9567, total_rewards: 2882.7653, mean_steps: 10.2600, mean_ecr: 0.0555 mean_entropies: 0.1343, took: 50.9876s
2022-10-10 20:55:26,780 [INFO] 	Process 4 - batch 70799: mean_policy_losses: 13.948, mean_net_lifetime: 6167.5184, mean_mc_travel_dist: 1726.7545, mean_rewards: 283.1345, total_rewards: 4466.7443, mean_steps: 21.5100, mean_ecr: 0.0446 mean_entropies: 0.6343, took: 97.4495s
2022-10-10 20:55:59,236 [INFO] 	Process 6 - batch 90499: mean_policy_losses: -35.570, mean_net_lifetime: 3917.6144, mean_mc_travel_dist: 1052.8033, mean_rewards: 340.2982, total_rewards: 2929.3672, mean_steps: 10.4900, mean_ecr: 0.0553 mean_entropies: 0.1456, took: 51.5363s
2022-10-10 20:56:27,948 [INFO] 	Process 2 - batch 64399: mean_policy_losses: -49.356, mean_net_lifetime: 6943.2814, mean_mc_travel_dist: 1935.7991, mean_rewards: 269.5688, total_rewards: 5038.8059, mean_steps: 24.8500, mean_ecr: 0.0386 mean_entropies: 0.4587, took: 108.1099s
2022-10-10 20:56:52,560 [INFO] 	Process 6 - batch 90599: mean_policy_losses: -47.337, mean_net_lifetime: 4095.9438, mean_mc_travel_dist: 1100.3849, mean_rewards: 341.3493, total_rewards: 3064.3600, mean_steps: 10.9900, mean_ecr: 0.0548 mean_entropies: 0.1327, took: 53.3232s
2022-10-10 20:57:05,087 [INFO] 	Process 4 - batch 70899: mean_policy_losses: 50.316, mean_net_lifetime: 6396.7507, mean_mc_travel_dist: 1798.1157, mean_rewards: 280.9318, total_rewards: 4622.9981, mean_steps: 22.4700, mean_ecr: 0.0441 mean_entropies: 0.6357, took: 98.3079s
2022-10-10 20:57:43,628 [INFO] 	Process 6 - batch 90699: mean_policy_losses: -117.185, mean_net_lifetime: 3938.8888, mean_mc_travel_dist: 1054.2168, mean_rewards: 339.3918, total_rewards: 2946.1891, mean_steps: 10.5700, mean_ecr: 0.0552 mean_entropies: 0.1485, took: 51.0682s
2022-10-10 20:57:57,447 [INFO] Process 7 - epoch 43: mean_policy_losses: -338.079, mean_net_lifetime: 4058.3241, mean_mc_travel_dist: 1564.4628, mean_entropies: 1.6137, m_net_lifetime_valid: 4840.2848, took: 2161.2516s, (150.5285 / 100 batches)

2022-10-10 20:58:22,660 [INFO] 	Process 2 - batch 64499: mean_policy_losses: -29.242, mean_net_lifetime: 7434.4409, mean_mc_travel_dist: 2129.9242, mean_rewards: 268.1697, total_rewards: 5326.2796, mean_steps: 26.7800, mean_ecr: 0.0380 mean_entropies: 0.5044, took: 114.7115s
2022-10-10 20:58:40,105 [INFO] 	Process 6 - batch 90799: mean_policy_losses: -65.501, mean_net_lifetime: 4066.2658, mean_mc_travel_dist: 1091.0582, mean_rewards: 341.0630, total_rewards: 3044.8085, mean_steps: 10.9000, mean_ecr: 0.0550 mean_entropies: 0.1229, took: 56.4771s
2022-10-10 20:58:52,408 [INFO] 	Process 4 - batch 70999: mean_policy_losses: 49.140, mean_net_lifetime: 6722.9838, mean_mc_travel_dist: 1944.3916, mean_rewards: 279.0699, total_rewards: 4804.2115, mean_steps: 24.2100, mean_ecr: 0.0430 mean_entropies: 0.5844, took: 107.3205s
2022-10-10 20:59:24,620 [INFO] 	Process 7 - batch 64599: mean_policy_losses: -726.047, mean_net_lifetime: 4670.6949, mean_mc_travel_dist: 1444.7422, mean_rewards: 223.3266, total_rewards: 3257.7006, mean_steps: 20.1000, mean_ecr: 0.0411 mean_entropies: 1.3486, took: 728.3264s
2022-10-10 20:59:35,663 [INFO] 	Process 6 - batch 90899: mean_policy_losses: -80.888, mean_net_lifetime: 4151.5087, mean_mc_travel_dist: 1125.4504, mean_rewards: 342.8013, total_rewards: 3111.9108, mean_steps: 11.1000, mean_ecr: 0.0548 mean_entropies: 0.0956, took: 55.5586s
2022-10-10 21:00:28,935 [INFO] 	Process 6 - batch 90999: mean_policy_losses: -47.202, mean_net_lifetime: 4107.3826, mean_mc_travel_dist: 1112.2535, mean_rewards: 342.1775, total_rewards: 3078.3264, mean_steps: 10.9900, mean_ecr: 0.0549 mean_entropies: 0.1153, took: 53.2718s
2022-10-10 21:00:29,457 [INFO] Process 5 - epoch 42: mean_policy_losses: -208.646, mean_net_lifetime: 4788.5869, mean_mc_travel_dist: 1930.8753, mean_entropies: 1.2432, m_net_lifetime_valid: 4970.6939, took: 2555.8152s, (154.3401 / 100 batches)

2022-10-10 21:00:32,659 [INFO] 	Process 4 - batch 71099: mean_policy_losses: 70.820, mean_net_lifetime: 6527.2005, mean_mc_travel_dist: 1893.7193, mean_rewards: 284.8707, total_rewards: 4667.4892, mean_steps: 22.8300, mean_ecr: 0.0437 mean_entropies: 0.5672, took: 100.2510s
2022-10-10 21:00:54,609 [INFO] 	Process 7 - batch 64699: mean_policy_losses: -732.196, mean_net_lifetime: 4620.0749, mean_mc_travel_dist: 1432.5543, mean_rewards: 217.7693, total_rewards: 3219.5456, mean_steps: 20.5500, mean_ecr: 0.0411 mean_entropies: 1.3450, took: 89.9897s
2022-10-10 21:01:01,470 [INFO] Process 1 - epoch 38: mean_policy_losses: 30.189, mean_net_lifetime: 4998.7047, mean_mc_travel_dist: 2030.7531, mean_entropies: 1.2250, m_net_lifetime_valid: 4720.1758, took: 2398.4256s, (170.6916 / 100 batches)

2022-10-10 21:01:24,368 [INFO] 	Process 6 - batch 91099: mean_policy_losses: -39.555, mean_net_lifetime: 4172.8844, mean_mc_travel_dist: 1130.9697, mean_rewards: 341.2587, total_rewards: 3120.8721, mean_steps: 11.1800, mean_ecr: 0.0549 mean_entropies: 0.0947, took: 55.4327s
2022-10-10 21:02:17,689 [INFO] 	Process 5 - batch 63099: mean_policy_losses: -174.475, mean_net_lifetime: 6545.3267, mean_mc_travel_dist: 2087.1190, mean_rewards: 271.4424, total_rewards: 4495.2056, mean_steps: 23.3800, mean_ecr: 0.0306 mean_entropies: 0.5691, took: 754.2394s
2022-10-10 21:02:22,795 [INFO] 	Process 6 - batch 91199: mean_policy_losses: -76.116, mean_net_lifetime: 4184.5963, mean_mc_travel_dist: 1139.6685, mean_rewards: 341.1936, total_rewards: 3137.3241, mean_steps: 11.2100, mean_ecr: 0.0547 mean_entropies: 0.0733, took: 58.4272s
2022-10-10 21:02:37,849 [INFO] 	Process 4 - batch 71199: mean_policy_losses: 159.893, mean_net_lifetime: 7379.3169, mean_mc_travel_dist: 2163.6762, mean_rewards: 276.1162, total_rewards: 5238.0894, mean_steps: 27.2000, mean_ecr: 0.0418 mean_entropies: 0.6105, took: 125.1905s
2022-10-10 21:02:37,911 [INFO] 	Process 7 - batch 64799: mean_policy_losses: -477.088, mean_net_lifetime: 5070.0960, mean_mc_travel_dist: 1603.5255, mean_rewards: 217.7226, total_rewards: 3507.7473, mean_steps: 22.4400, mean_ecr: 0.0409 mean_entropies: 1.3215, took: 103.3022s
2022-10-10 21:03:01,650 [INFO] 	Process 1 - batch 57099: mean_policy_losses: -46.657, mean_net_lifetime: 6005.0132, mean_mc_travel_dist: 1956.2824, mean_rewards: 226.3388, total_rewards: 4075.9510, mean_steps: 25.6500, mean_ecr: 0.0383 mean_entropies: 0.9526, took: 721.9598s
2022-10-10 21:03:23,027 [INFO] 	Process 6 - batch 91299: mean_policy_losses: -47.222, mean_net_lifetime: 4246.2786, mean_mc_travel_dist: 1154.0722, mean_rewards: 342.3536, total_rewards: 3181.4975, mean_steps: 11.3800, mean_ecr: 0.0546 mean_entropies: 0.0716, took: 60.2317s
2022-10-10 21:04:15,925 [INFO] 	Process 5 - batch 63199: mean_policy_losses: -156.736, mean_net_lifetime: 6925.6213, mean_mc_travel_dist: 2227.8068, mean_rewards: 271.5292, total_rewards: 4742.6857, mean_steps: 24.7900, mean_ecr: 0.0304 mean_entropies: 0.5669, took: 118.2367s
2022-10-10 21:04:18,059 [INFO] Process 3 - epoch 45: mean_policy_losses: 67.561, mean_net_lifetime: 4255.7063, mean_mc_travel_dist: 1364.1010, mean_entropies: 0.9383, m_net_lifetime_valid: 4535.5864, took: 1797.9044s, (144.5147 / 100 batches)

2022-10-10 21:04:20,547 [INFO] 	Process 7 - batch 64899: mean_policy_losses: -572.066, mean_net_lifetime: 4900.1833, mean_mc_travel_dist: 1557.1876, mean_rewards: 214.8646, total_rewards: 3380.7506, mean_steps: 22.0000, mean_ecr: 0.0409 mean_entropies: 1.3432, took: 102.6358s
2022-10-10 21:04:21,708 [INFO] 	Process 6 - batch 91399: mean_policy_losses: -68.460, mean_net_lifetime: 4224.6510, mean_mc_travel_dist: 1149.9932, mean_rewards: 340.5568, total_rewards: 3170.5196, mean_steps: 11.3400, mean_ecr: 0.0547 mean_entropies: 0.0680, took: 58.6816s
2022-10-10 21:04:44,592 [INFO] 	Process 4 - batch 71299: mean_policy_losses: 123.344, mean_net_lifetime: 7265.2657, mean_mc_travel_dist: 2126.6815, mean_rewards: 275.5485, total_rewards: 5160.8140, mean_steps: 26.8400, mean_ecr: 0.0422 mean_entropies: 0.5651, took: 126.7426s
2022-10-10 21:05:04,388 [INFO] 	Process 1 - batch 57199: mean_policy_losses: -85.295, mean_net_lifetime: 6010.0020, mean_mc_travel_dist: 1998.3805, mean_rewards: 220.5465, total_rewards: 4043.4788, mean_steps: 26.6900, mean_ecr: 0.0382 mean_entropies: 0.8739, took: 122.7380s
2022-10-10 21:05:23,708 [INFO] 	Process 6 - batch 91499: mean_policy_losses: -16.810, mean_net_lifetime: 4297.7914, mean_mc_travel_dist: 1172.7182, mean_rewards: 342.2651, total_rewards: 3225.9969, mean_steps: 11.5400, mean_ecr: 0.0546 mean_entropies: 0.0654, took: 61.9987s
2022-10-10 21:05:42,193 [INFO] 	Process 3 - batch 67599: mean_policy_losses: -1.880, mean_net_lifetime: 4773.0628, mean_mc_travel_dist: 1257.7443, mean_rewards: 269.8403, total_rewards: 3547.2130, mean_steps: 16.7200, mean_ecr: 0.0482 mean_entropies: 0.4907, took: 654.7629s
2022-10-10 21:06:08,821 [INFO] 	Process 7 - batch 64999: mean_policy_losses: -470.445, mean_net_lifetime: 5088.3349, mean_mc_travel_dist: 1633.8006, mean_rewards: 216.4886, total_rewards: 3493.9826, mean_steps: 22.9200, mean_ecr: 0.0407 mean_entropies: 1.3204, took: 108.2739s
2022-10-10 21:06:33,829 [INFO] 	Process 5 - batch 63299: mean_policy_losses: -122.054, mean_net_lifetime: 7803.3571, mean_mc_travel_dist: 2606.3532, mean_rewards: 267.9676, total_rewards: 5242.3208, mean_steps: 29.1700, mean_ecr: 0.0299 mean_entropies: 0.5688, took: 137.9031s
2022-10-10 21:07:00,000 [INFO] 	Process 1 - batch 57299: mean_policy_losses: -94.313, mean_net_lifetime: 5715.8815, mean_mc_travel_dist: 1936.6292, mean_rewards: 224.7749, total_rewards: 3806.0880, mean_steps: 25.0300, mean_ecr: 0.0384 mean_entropies: 0.8590, took: 115.6126s
2022-10-10 21:07:05,665 [INFO] 	Process 4 - batch 71399: mean_policy_losses: 175.437, mean_net_lifetime: 7927.4043, mean_mc_travel_dist: 2372.2375, mean_rewards: 269.7444, total_rewards: 5576.1295, mean_steps: 30.2700, mean_ecr: 0.0402 mean_entropies: 0.5691, took: 141.0728s
2022-10-10 21:07:06,313 [INFO] 	Process 3 - batch 67699: mean_policy_losses: 5.291, mean_net_lifetime: 4784.5477, mean_mc_travel_dist: 1279.8373, mean_rewards: 270.3553, total_rewards: 3536.3559, mean_steps: 16.7400, mean_ecr: 0.0480 mean_entropies: 0.4749, took: 84.1204s
2022-10-10 21:07:59,623 [INFO] 	Process 7 - batch 65099: mean_policy_losses: -447.672, mean_net_lifetime: 5162.2929, mean_mc_travel_dist: 1591.5215, mean_rewards: 212.8019, total_rewards: 3607.5332, mean_steps: 23.6200, mean_ecr: 0.0408 mean_entropies: 1.3777, took: 110.8020s
2022-10-10 21:08:27,362 [INFO] 	Process 3 - batch 67799: mean_policy_losses: 15.698, mean_net_lifetime: 4748.4863, mean_mc_travel_dist: 1298.9158, mean_rewards: 270.5977, total_rewards: 3482.5200, mean_steps: 16.6000, mean_ecr: 0.0474 mean_entropies: 0.4813, took: 81.0492s
2022-10-10 21:08:40,966 [INFO] Process 2 - epoch 43: mean_policy_losses: 0.819, mean_net_lifetime: 4584.6468, mean_mc_travel_dist: 1580.3908, mean_entropies: 0.9746, m_net_lifetime_valid: 4736.7939, took: 2341.0538s, (151.5603 / 100 batches)

2022-10-10 21:08:54,556 [INFO] 	Process 5 - batch 63399: mean_policy_losses: -101.831, mean_net_lifetime: 8286.0302, mean_mc_travel_dist: 2777.4780, mean_rewards: 273.7426, total_rewards: 5547.7734, mean_steps: 29.9600, mean_ecr: 0.0296 mean_entropies: 0.6231, took: 140.7281s
2022-10-10 21:09:08,626 [INFO] 	Process 1 - batch 57399: mean_policy_losses: -41.143, mean_net_lifetime: 5978.6776, mean_mc_travel_dist: 2016.3363, mean_rewards: 216.7516, total_rewards: 3988.4135, mean_steps: 27.1700, mean_ecr: 0.0382 mean_entropies: 0.8933, took: 128.6251s
2022-10-10 21:09:25,388 [INFO] 	Process 4 - batch 71499: mean_policy_losses: 187.425, mean_net_lifetime: 7717.4313, mean_mc_travel_dist: 2257.1206, mean_rewards: 267.6178, total_rewards: 5483.5603, mean_steps: 29.8000, mean_ecr: 0.0407 mean_entropies: 0.6069, took: 139.7232s
2022-10-10 21:09:51,269 [INFO] 	Process 3 - batch 67899: mean_policy_losses: -0.680, mean_net_lifetime: 4697.2362, mean_mc_travel_dist: 1265.9275, mean_rewards: 270.3016, total_rewards: 3463.4838, mean_steps: 16.4300, mean_ecr: 0.0477 mean_entropies: 0.4751, took: 83.9066s
2022-10-10 21:09:53,836 [INFO] 	Process 7 - batch 65199: mean_policy_losses: -406.264, mean_net_lifetime: 5206.7381, mean_mc_travel_dist: 1583.5734, mean_rewards: 206.7528, total_rewards: 3655.0547, mean_steps: 24.4100, mean_ecr: 0.0407 mean_entropies: 1.3390, took: 114.2131s
2022-10-10 21:10:34,886 [INFO] 	Process 2 - batch 64599: mean_policy_losses: -89.653, mean_net_lifetime: 6361.6600, mean_mc_travel_dist: 1832.1001, mean_rewards: 259.5344, total_rewards: 4565.1713, mean_steps: 23.6000, mean_ecr: 0.0387 mean_entropies: 0.4800, took: 732.2266s
2022-10-10 21:11:01,843 [INFO] 	Process 1 - batch 57499: mean_policy_losses: -42.203, mean_net_lifetime: 5812.1743, mean_mc_travel_dist: 2008.1258, mean_rewards: 240.9039, total_rewards: 3826.8499, mean_steps: 23.4500, mean_ecr: 0.0381 mean_entropies: 0.8484, took: 113.2171s
2022-10-10 21:11:15,232 [INFO] 	Process 3 - batch 67999: mean_policy_losses: 10.939, mean_net_lifetime: 4676.7500, mean_mc_travel_dist: 1231.8459, mean_rewards: 269.1015, total_rewards: 3468.2828, mean_steps: 16.4500, mean_ecr: 0.0482 mean_entropies: 0.4637, took: 83.9635s
2022-10-10 21:11:33,735 [INFO] 	Process 5 - batch 63499: mean_policy_losses: -92.598, mean_net_lifetime: 8913.3111, mean_mc_travel_dist: 2966.0467, mean_rewards: 271.1520, total_rewards: 5994.9951, mean_steps: 33.0100, mean_ecr: 0.0296 mean_entropies: 0.6071, took: 159.1780s
2022-10-10 21:11:41,823 [INFO] 	Process 4 - batch 71599: mean_policy_losses: 164.556, mean_net_lifetime: 7516.7141, mean_mc_travel_dist: 2188.7909, mean_rewards: 271.7873, total_rewards: 5355.1991, mean_steps: 28.1300, mean_ecr: 0.0413 mean_entropies: 0.5647, took: 136.4353s
2022-10-10 21:11:44,860 [INFO] 	Process 7 - batch 65299: mean_policy_losses: -441.514, mean_net_lifetime: 5088.8916, mean_mc_travel_dist: 1594.4213, mean_rewards: 215.8515, total_rewards: 3531.0422, mean_steps: 22.8600, mean_ecr: 0.0406 mean_entropies: 1.2996, took: 111.0240s
2022-10-10 21:12:31,662 [INFO] 	Process 2 - batch 64699: mean_policy_losses: -63.082, mean_net_lifetime: 6709.7633, mean_mc_travel_dist: 1882.0810, mean_rewards: 269.4204, total_rewards: 4861.1503, mean_steps: 24.0000, mean_ecr: 0.0386 mean_entropies: 0.4473, took: 116.7757s
2022-10-10 21:12:42,075 [INFO] 	Process 3 - batch 68099: mean_policy_losses: 0.862, mean_net_lifetime: 4741.9986, mean_mc_travel_dist: 1267.3942, mean_rewards: 264.8708, total_rewards: 3512.8949, mean_steps: 16.9700, mean_ecr: 0.0480 mean_entropies: 0.4882, took: 86.8427s
2022-10-10 21:13:02,505 [INFO] 	Process 1 - batch 57599: mean_policy_losses: -20.275, mean_net_lifetime: 6050.0592, mean_mc_travel_dist: 2003.8238, mean_rewards: 233.8190, total_rewards: 4077.9235, mean_steps: 25.1800, mean_ecr: 0.0382 mean_entropies: 0.9410, took: 120.6623s
2022-10-10 21:13:31,672 [INFO] 	Process 7 - batch 65399: mean_policy_losses: -528.143, mean_net_lifetime: 4994.5642, mean_mc_travel_dist: 1580.4586, mean_rewards: 216.4548, total_rewards: 3454.4494, mean_steps: 22.3500, mean_ecr: 0.0410 mean_entropies: 1.3555, took: 106.8128s
2022-10-10 21:13:45,143 [INFO] 	Process 4 - batch 71699: mean_policy_losses: 143.607, mean_net_lifetime: 6998.2302, mean_mc_travel_dist: 1997.6875, mean_rewards: 280.5127, total_rewards: 5026.5933, mean_steps: 25.0200, mean_ecr: 0.0433 mean_entropies: 0.5672, took: 123.3196s
2022-10-10 21:13:48,224 [INFO] 	Process 5 - batch 63599: mean_policy_losses: -140.922, mean_net_lifetime: 7610.6237, mean_mc_travel_dist: 2471.8615, mean_rewards: 274.7248, total_rewards: 5168.8641, mean_steps: 27.4100, mean_ecr: 0.0302 mean_entropies: 0.5978, took: 134.4888s
2022-10-10 21:14:03,379 [INFO] 	Process 3 - batch 68199: mean_policy_losses: 12.578, mean_net_lifetime: 4683.3632, mean_mc_travel_dist: 1246.7490, mean_rewards: 275.5101, total_rewards: 3464.9705, mean_steps: 16.0800, mean_ecr: 0.0480 mean_entropies: 0.4848, took: 81.3036s
2022-10-10 21:14:30,039 [INFO] 	Process 2 - batch 64799: mean_policy_losses: -35.485, mean_net_lifetime: 6824.3439, mean_mc_travel_dist: 1938.5849, mean_rewards: 268.7260, total_rewards: 4914.5433, mean_steps: 24.5100, mean_ecr: 0.0385 mean_entropies: 0.4719, took: 118.3768s
2022-10-10 21:14:53,582 [INFO] 	Process 1 - batch 57699: mean_policy_losses: -48.661, mean_net_lifetime: 5819.0503, mean_mc_travel_dist: 2098.6184, mean_rewards: 248.4626, total_rewards: 3755.8042, mean_steps: 22.7000, mean_ecr: 0.0380 mean_entropies: 0.8619, took: 111.0770s
2022-10-10 21:15:11,996 [INFO] 	Process 7 - batch 65499: mean_policy_losses: -512.711, mean_net_lifetime: 4665.9523, mean_mc_travel_dist: 1460.4628, mean_rewards: 216.9642, total_rewards: 3251.6273, mean_steps: 20.7100, mean_ecr: 0.0410 mean_entropies: 1.3061, took: 100.3239s
2022-10-10 21:15:27,994 [INFO] 	Process 3 - batch 68299: mean_policy_losses: 7.274, mean_net_lifetime: 4633.6350, mean_mc_travel_dist: 1213.6586, mean_rewards: 270.1371, total_rewards: 3460.5567, mean_steps: 16.2100, mean_ecr: 0.0483 mean_entropies: 0.4897, took: 84.6148s
2022-10-10 21:15:44,663 [INFO] 	Process 5 - batch 63699: mean_policy_losses: -228.638, mean_net_lifetime: 6643.8300, mean_mc_travel_dist: 2187.6873, mean_rewards: 280.3412, total_rewards: 4497.9595, mean_steps: 23.4300, mean_ecr: 0.0302 mean_entropies: 0.5562, took: 116.4400s
2022-10-10 21:15:50,590 [INFO] Process 6 - epoch 61: mean_policy_losses: -220.016, mean_net_lifetime: 2982.5507, mean_mc_travel_dist: 960.2335, mean_entropies: 0.6329, m_net_lifetime_valid: 4337.6100, took: 1449.9653s, (107.3454 / 100 batches)

2022-10-10 21:16:06,960 [INFO] 	Process 4 - batch 71799: mean_policy_losses: 203.661, mean_net_lifetime: 7712.3427, mean_mc_travel_dist: 2287.6528, mean_rewards: 268.2084, total_rewards: 5442.8191, mean_steps: 29.6400, mean_ecr: 0.0413 mean_entropies: 0.5743, took: 141.8173s
2022-10-10 21:16:38,741 [INFO] 	Process 2 - batch 64899: mean_policy_losses: -26.485, mean_net_lifetime: 7252.5875, mean_mc_travel_dist: 2102.4096, mean_rewards: 264.6344, total_rewards: 5185.6757, mean_steps: 26.4800, mean_ecr: 0.0380 mean_entropies: 0.4905, took: 128.7017s
2022-10-10 21:16:51,751 [INFO] 	Process 6 - batch 91599: mean_policy_losses: -73.034, mean_net_lifetime: 4062.1765, mean_mc_travel_dist: 1088.5225, mean_rewards: 342.4532, total_rewards: 3038.7584, mean_steps: 10.8200, mean_ecr: 0.0548 mean_entropies: 0.1114, took: 688.0442s
2022-10-10 21:16:55,906 [INFO] 	Process 3 - batch 68399: mean_policy_losses: -14.676, mean_net_lifetime: 4675.1955, mean_mc_travel_dist: 1230.1448, mean_rewards: 262.6195, total_rewards: 3476.3035, mean_steps: 16.8600, mean_ecr: 0.0482 mean_entropies: 0.4627, took: 87.9130s
2022-10-10 21:16:57,182 [INFO] 	Process 1 - batch 57799: mean_policy_losses: 14.514, mean_net_lifetime: 6409.2774, mean_mc_travel_dist: 2121.4481, mean_rewards: 243.7946, total_rewards: 4317.4466, mean_steps: 25.5700, mean_ecr: 0.0379 mean_entropies: 1.0276, took: 123.5998s
2022-10-10 21:17:02,473 [INFO] 	Process 7 - batch 65599: mean_policy_losses: -518.663, mean_net_lifetime: 4945.9065, mean_mc_travel_dist: 1523.0103, mean_rewards: 213.0320, total_rewards: 3460.7332, mean_steps: 22.5500, mean_ecr: 0.0410 mean_entropies: 1.3220, took: 110.4766s
2022-10-10 21:17:53,715 [INFO] 	Process 6 - batch 91699: mean_policy_losses: -49.422, mean_net_lifetime: 4197.5690, mean_mc_travel_dist: 1120.7091, mean_rewards: 342.2735, total_rewards: 3129.9264, mean_steps: 11.2100, mean_ecr: 0.0548 mean_entropies: 0.1194, took: 61.9638s
2022-10-10 21:18:03,603 [INFO] 	Process 5 - batch 63799: mean_policy_losses: -118.176, mean_net_lifetime: 7569.5861, mean_mc_travel_dist: 2418.2036, mean_rewards: 274.4608, total_rewards: 5184.8949, mean_steps: 27.2000, mean_ecr: 0.0300 mean_entropies: 0.5950, took: 138.9377s
2022-10-10 21:18:21,014 [INFO] 	Process 4 - batch 71899: mean_policy_losses: 140.483, mean_net_lifetime: 7166.7105, mean_mc_travel_dist: 2078.4698, mean_rewards: 267.3850, total_rewards: 5111.2417, mean_steps: 27.0600, mean_ecr: 0.0421 mean_entropies: 0.5937, took: 134.0537s
2022-10-10 21:18:26,666 [INFO] 	Process 3 - batch 68499: mean_policy_losses: -26.546, mean_net_lifetime: 4768.8431, mean_mc_travel_dist: 1258.6803, mean_rewards: 259.3800, total_rewards: 3541.1984, mean_steps: 17.4600, mean_ecr: 0.0481 mean_entropies: 0.4557, took: 90.7593s
2022-10-10 21:18:43,929 [INFO] 	Process 2 - batch 64999: mean_policy_losses: -61.838, mean_net_lifetime: 6881.7916, mean_mc_travel_dist: 1955.5882, mean_rewards: 263.5920, total_rewards: 4967.2006, mean_steps: 25.1200, mean_ecr: 0.0385 mean_entropies: 0.4629, took: 125.1887s
2022-10-10 21:18:56,700 [INFO] 	Process 7 - batch 65699: mean_policy_losses: -600.980, mean_net_lifetime: 4974.0701, mean_mc_travel_dist: 1554.0709, mean_rewards: 208.7794, total_rewards: 3451.3481, mean_steps: 23.0900, mean_ecr: 0.0408 mean_entropies: 1.3598, took: 114.2268s
2022-10-10 21:18:57,204 [INFO] 	Process 6 - batch 91799: mean_policy_losses: -30.500, mean_net_lifetime: 4261.8882, mean_mc_travel_dist: 1154.6194, mean_rewards: 342.0461, total_rewards: 3185.1605, mean_steps: 11.4400, mean_ecr: 0.0548 mean_entropies: 0.0977, took: 63.4892s
2022-10-10 21:19:10,282 [INFO] 	Process 1 - batch 57899: mean_policy_losses: -20.905, mean_net_lifetime: 6477.2705, mean_mc_travel_dist: 2123.6969, mean_rewards: 235.3286, total_rewards: 4375.3647, mean_steps: 26.8400, mean_ecr: 0.0379 mean_entropies: 1.0450, took: 133.1003s
2022-10-10 21:19:54,534 [INFO] 	Process 3 - batch 68599: mean_policy_losses: 4.040, mean_net_lifetime: 4822.0653, mean_mc_travel_dist: 1249.7392, mean_rewards: 269.7872, total_rewards: 3615.2533, mean_steps: 16.9100, mean_ecr: 0.0480 mean_entropies: 0.4394, took: 87.8675s
2022-10-10 21:19:57,270 [INFO] 	Process 6 - batch 91899: mean_policy_losses: -44.505, mean_net_lifetime: 4036.9387, mean_mc_travel_dist: 1092.3484, mean_rewards: 340.9806, total_rewards: 3027.7916, mean_steps: 10.7800, mean_ecr: 0.0550 mean_entropies: 0.1118, took: 60.0660s
2022-10-10 21:20:13,379 [INFO] 	Process 5 - batch 63899: mean_policy_losses: -171.947, mean_net_lifetime: 7210.1315, mean_mc_travel_dist: 2316.5073, mean_rewards: 270.7077, total_rewards: 4932.0757, mean_steps: 26.2300, mean_ecr: 0.0300 mean_entropies: 0.6008, took: 129.7784s
2022-10-10 21:20:26,027 [INFO] 	Process 4 - batch 71999: mean_policy_losses: 153.328, mean_net_lifetime: 6882.8124, mean_mc_travel_dist: 2017.5349, mean_rewards: 279.4770, total_rewards: 4892.3369, mean_steps: 24.9200, mean_ecr: 0.0428 mean_entropies: 0.6222, took: 125.0131s
2022-10-10 21:20:43,956 [INFO] 	Process 7 - batch 65799: mean_policy_losses: -634.916, mean_net_lifetime: 4862.6117, mean_mc_travel_dist: 1539.9343, mean_rewards: 216.5741, total_rewards: 3365.5732, mean_steps: 21.8800, mean_ecr: 0.0409 mean_entropies: 1.3676, took: 107.2549s
2022-10-10 21:20:47,009 [INFO] 	Process 2 - batch 65099: mean_policy_losses: -37.212, mean_net_lifetime: 6933.5180, mean_mc_travel_dist: 1923.9398, mean_rewards: 267.9961, total_rewards: 5041.7457, mean_steps: 24.9500, mean_ecr: 0.0385 mean_entropies: 0.4864, took: 123.0790s
2022-10-10 21:20:58,876 [INFO] 	Process 6 - batch 91999: mean_policy_losses: -39.784, mean_net_lifetime: 4105.4459, mean_mc_travel_dist: 1108.9245, mean_rewards: 339.5956, total_rewards: 3070.4171, mean_steps: 11.0000, mean_ecr: 0.0549 mean_entropies: 0.1004, took: 61.6059s
2022-10-10 21:21:16,607 [INFO] 	Process 1 - batch 57999: mean_policy_losses: -5.450, mean_net_lifetime: 6303.1764, mean_mc_travel_dist: 2056.7809, mean_rewards: 235.9222, total_rewards: 4273.1410, mean_steps: 25.9500, mean_ecr: 0.0381 mean_entropies: 1.0054, took: 126.3255s
2022-10-10 21:21:22,599 [INFO] 	Process 3 - batch 68699: mean_policy_losses: -15.792, mean_net_lifetime: 4773.3054, mean_mc_travel_dist: 1251.1128, mean_rewards: 265.6997, total_rewards: 3557.0151, mean_steps: 17.0200, mean_ecr: 0.0480 mean_entropies: 0.4613, took: 88.0650s
2022-10-10 21:21:59,797 [INFO] 	Process 6 - batch 92099: mean_policy_losses: -18.742, mean_net_lifetime: 4311.3038, mean_mc_travel_dist: 1150.0020, mean_rewards: 344.0388, total_rewards: 3216.1323, mean_steps: 11.5100, mean_ecr: 0.0546 mean_entropies: 0.0930, took: 60.9209s
2022-10-10 21:22:19,361 [INFO] 	Process 5 - batch 63999: mean_policy_losses: -109.744, mean_net_lifetime: 7219.1335, mean_mc_travel_dist: 2316.8431, mean_rewards: 269.7862, total_rewards: 4940.7504, mean_steps: 26.1000, mean_ecr: 0.0303 mean_entropies: 0.6103, took: 125.9812s
2022-10-10 21:22:33,469 [INFO] 	Process 7 - batch 65899: mean_policy_losses: -401.695, mean_net_lifetime: 5037.4153, mean_mc_travel_dist: 1596.2495, mean_rewards: 211.6368, total_rewards: 3470.1482, mean_steps: 23.0200, mean_ecr: 0.0408 mean_entropies: 1.3238, took: 109.5147s
2022-10-10 21:22:48,370 [INFO] 	Process 3 - batch 68799: mean_policy_losses: -16.687, mean_net_lifetime: 4679.4818, mean_mc_travel_dist: 1231.8282, mean_rewards: 268.1505, total_rewards: 3478.2324, mean_steps: 16.5600, mean_ecr: 0.0482 mean_entropies: 0.4766, took: 85.7719s
2022-10-10 21:22:48,459 [INFO] 	Process 2 - batch 65199: mean_policy_losses: -38.567, mean_net_lifetime: 6924.0197, mean_mc_travel_dist: 1969.9808, mean_rewards: 265.7922, total_rewards: 4987.3240, mean_steps: 25.1100, mean_ecr: 0.0383 mean_entropies: 0.4613, took: 121.4509s
2022-10-10 21:22:58,264 [INFO] 	Process 6 - batch 92199: mean_policy_losses: -113.560, mean_net_lifetime: 4055.1216, mean_mc_travel_dist: 1094.0930, mean_rewards: 341.1773, total_rewards: 3040.2368, mean_steps: 10.8400, mean_ecr: 0.0550 mean_entropies: 0.0956, took: 58.4664s
2022-10-10 21:23:23,427 [INFO] 	Process 1 - batch 58099: mean_policy_losses: -46.800, mean_net_lifetime: 6212.7606, mean_mc_travel_dist: 2042.3768, mean_rewards: 231.4220, total_rewards: 4197.4429, mean_steps: 26.2000, mean_ecr: 0.0382 mean_entropies: 0.9583, took: 126.8190s
2022-10-10 21:23:58,136 [INFO] 	Process 6 - batch 92299: mean_policy_losses: -54.361, mean_net_lifetime: 4204.9559, mean_mc_travel_dist: 1138.4714, mean_rewards: 342.8440, total_rewards: 3139.0311, mean_steps: 11.2400, mean_ecr: 0.0548 mean_entropies: 0.0932, took: 59.8721s
2022-10-10 21:24:14,541 [INFO] 	Process 3 - batch 68899: mean_policy_losses: -20.345, mean_net_lifetime: 4662.3327, mean_mc_travel_dist: 1221.9322, mean_rewards: 265.7224, total_rewards: 3475.0050, mean_steps: 16.6000, mean_ecr: 0.0483 mean_entropies: 0.4751, took: 86.1711s
2022-10-10 21:24:15,173 [INFO] 	Process 5 - batch 64099: mean_policy_losses: -86.470, mean_net_lifetime: 6891.9332, mean_mc_travel_dist: 2218.1102, mean_rewards: 278.6904, total_rewards: 4715.3660, mean_steps: 23.9700, mean_ecr: 0.0306 mean_entropies: 0.5605, took: 115.8117s
2022-10-10 21:24:20,435 [INFO] 	Process 7 - batch 65999: mean_policy_losses: -403.402, mean_net_lifetime: 4812.3026, mean_mc_travel_dist: 1543.3719, mean_rewards: 206.5041, total_rewards: 3308.2779, mean_steps: 22.5600, mean_ecr: 0.0408 mean_entropies: 1.3028, took: 106.9651s
2022-10-10 21:24:49,900 [INFO] 	Process 2 - batch 65299: mean_policy_losses: -32.664, mean_net_lifetime: 7072.4122, mean_mc_travel_dist: 2000.8860, mean_rewards: 265.5561, total_rewards: 5099.2747, mean_steps: 25.7700, mean_ecr: 0.0383 mean_entropies: 0.4562, took: 121.4393s
2022-10-10 21:24:55,698 [INFO] 	Process 6 - batch 92399: mean_policy_losses: -75.244, mean_net_lifetime: 4082.1106, mean_mc_travel_dist: 1092.7780, mean_rewards: 342.9108, total_rewards: 3052.2122, mean_steps: 10.8700, mean_ecr: 0.0549 mean_entropies: 0.1119, took: 57.5621s
2022-10-10 21:25:23,213 [INFO] 	Process 1 - batch 58199: mean_policy_losses: 6.310, mean_net_lifetime: 6383.7305, mean_mc_travel_dist: 2110.6961, mean_rewards: 243.3203, total_rewards: 4304.5396, mean_steps: 25.5100, mean_ecr: 0.0379 mean_entropies: 0.9685, took: 119.7862s
2022-10-10 21:25:36,176 [INFO] 	Process 3 - batch 68999: mean_policy_losses: -16.014, mean_net_lifetime: 4684.8158, mean_mc_travel_dist: 1209.5605, mean_rewards: 268.1033, total_rewards: 3505.0617, mean_steps: 16.5300, mean_ecr: 0.0483 mean_entropies: 0.4827, took: 81.6345s
2022-10-10 21:25:51,424 [INFO] 	Process 6 - batch 92499: mean_policy_losses: -59.406, mean_net_lifetime: 4072.0681, mean_mc_travel_dist: 1086.1301, mean_rewards: 342.8919, total_rewards: 3028.6829, mean_steps: 10.8500, mean_ecr: 0.0552 mean_entropies: 0.1172, took: 55.7261s
2022-10-10 21:26:07,479 [INFO] 	Process 5 - batch 64199: mean_policy_losses: -64.376, mean_net_lifetime: 6847.9089, mean_mc_travel_dist: 2237.6132, mean_rewards: 280.2093, total_rewards: 4652.8275, mean_steps: 23.6000, mean_ecr: 0.0306 mean_entropies: 0.5716, took: 112.3063s
2022-10-10 21:26:45,782 [INFO] 	Process 6 - batch 92599: mean_policy_losses: -188.926, mean_net_lifetime: 3934.0882, mean_mc_travel_dist: 1065.8348, mean_rewards: 342.2846, total_rewards: 2913.2282, mean_steps: 10.4500, mean_ecr: 0.0553 mean_entropies: 0.1365, took: 54.3585s
2022-10-10 21:26:51,712 [INFO] 	Process 2 - batch 65399: mean_policy_losses: 6.439, mean_net_lifetime: 7420.9352, mean_mc_travel_dist: 2125.4359, mean_rewards: 263.7818, total_rewards: 5325.9271, mean_steps: 27.2100, mean_ecr: 0.0379 mean_entropies: 0.4896, took: 121.8134s
2022-10-10 21:27:17,448 [INFO] 	Process 1 - batch 58299: mean_policy_losses: -14.116, mean_net_lifetime: 6298.5319, mean_mc_travel_dist: 2074.9656, mean_rewards: 247.7053, total_rewards: 4248.3458, mean_steps: 24.6200, mean_ecr: 0.0381 mean_entropies: 0.9866, took: 114.2349s
2022-10-10 21:27:41,660 [INFO] 	Process 6 - batch 92699: mean_policy_losses: -67.822, mean_net_lifetime: 4192.7658, mean_mc_travel_dist: 1124.3432, mean_rewards: 344.0168, total_rewards: 3116.4586, mean_steps: 11.1700, mean_ecr: 0.0548 mean_entropies: 0.1160, took: 55.8778s
2022-10-10 21:27:58,665 [INFO] 	Process 5 - batch 64299: mean_policy_losses: -34.881, mean_net_lifetime: 7006.2492, mean_mc_travel_dist: 2243.1984, mean_rewards: 280.1430, total_rewards: 4810.1454, mean_steps: 24.3000, mean_ecr: 0.0306 mean_entropies: 0.6064, took: 111.1864s
2022-10-10 21:28:35,085 [INFO] 	Process 6 - batch 92799: mean_policy_losses: -102.860, mean_net_lifetime: 3959.5463, mean_mc_travel_dist: 1052.0901, mean_rewards: 342.1535, total_rewards: 2957.8671, mean_steps: 10.5400, mean_ecr: 0.0551 mean_entropies: 0.1591, took: 53.4250s
2022-10-10 21:28:51,788 [INFO] 	Process 2 - batch 65499: mean_policy_losses: -7.674, mean_net_lifetime: 7317.0855, mean_mc_travel_dist: 2094.4678, mean_rewards: 263.6120, total_rewards: 5262.6289, mean_steps: 26.8500, mean_ecr: 0.0379 mean_entropies: 0.5050, took: 120.0770s
2022-10-10 21:29:15,093 [INFO] 	Process 1 - batch 58399: mean_policy_losses: 34.170, mean_net_lifetime: 6521.5278, mean_mc_travel_dist: 2105.4370, mean_rewards: 244.1668, total_rewards: 4434.8956, mean_steps: 25.9200, mean_ecr: 0.0379 mean_entropies: 1.0086, took: 117.6447s
2022-10-10 21:29:29,109 [INFO] 	Process 6 - batch 92899: mean_policy_losses: -113.141, mean_net_lifetime: 3940.2660, mean_mc_travel_dist: 1053.0663, mean_rewards: 338.3650, total_rewards: 2943.5363, mean_steps: 10.5600, mean_ecr: 0.0553 mean_entropies: 0.1784, took: 54.0242s
2022-10-10 21:29:55,126 [INFO] 	Process 5 - batch 64399: mean_policy_losses: -76.051, mean_net_lifetime: 7181.4925, mean_mc_travel_dist: 2295.3081, mean_rewards: 269.6152, total_rewards: 4925.7185, mean_steps: 26.0800, mean_ecr: 0.0306 mean_entropies: 0.5909, took: 116.4606s
2022-10-10 21:30:21,892 [INFO] 	Process 6 - batch 92999: mean_policy_losses: -103.962, mean_net_lifetime: 3958.7383, mean_mc_travel_dist: 1065.0121, mean_rewards: 341.5421, total_rewards: 2946.1891, mean_steps: 10.5600, mean_ecr: 0.0554 mean_entropies: 0.1552, took: 52.7830s
2022-10-10 21:30:40,373 [INFO] Process 4 - epoch 48: mean_policy_losses: 89.266, mean_net_lifetime: 4209.5992, mean_mc_travel_dist: 1361.8592, mean_entropies: 1.1751, m_net_lifetime_valid: 4535.8181, took: 2415.7043s, (137.6298 / 100 batches)

2022-10-10 21:30:49,367 [INFO] 	Process 2 - batch 65599: mean_policy_losses: -1.727, mean_net_lifetime: 7310.6140, mean_mc_travel_dist: 2060.8904, mean_rewards: 266.8647, total_rewards: 5284.3721, mean_steps: 26.4700, mean_ecr: 0.0380 mean_entropies: 0.5009, took: 117.5778s
2022-10-10 21:31:10,566 [INFO] 	Process 1 - batch 58499: mean_policy_losses: 2.381, mean_net_lifetime: 6540.5213, mean_mc_travel_dist: 2105.6054, mean_rewards: 240.7203, total_rewards: 4465.3043, mean_steps: 26.3700, mean_ecr: 0.0379 mean_entropies: 1.0313, took: 115.4732s
2022-10-10 21:31:53,054 [INFO] 	Process 4 - batch 72099: mean_policy_losses: 67.130, mean_net_lifetime: 4242.5073, mean_mc_travel_dist: 1151.5516, mean_rewards: 260.6184, total_rewards: 3121.7888, mean_steps: 15.2900, mean_ecr: 0.0490 mean_entropies: 0.7580, took: 687.0271s
2022-10-10 21:32:02,520 [INFO] 	Process 5 - batch 64499: mean_policy_losses: -89.837, mean_net_lifetime: 8013.4822, mean_mc_travel_dist: 2496.7339, mean_rewards: 269.9106, total_rewards: 5555.4934, mean_steps: 29.4300, mean_ecr: 0.0303 mean_entropies: 0.6892, took: 127.3943s
2022-10-10 21:32:38,678 [INFO] 	Process 2 - batch 65699: mean_policy_losses: -95.160, mean_net_lifetime: 7003.0838, mean_mc_travel_dist: 1956.3526, mean_rewards: 264.0724, total_rewards: 5091.9511, mean_steps: 25.6700, mean_ecr: 0.0386 mean_entropies: 0.4619, took: 109.3120s
2022-10-10 21:33:07,739 [INFO] 	Process 4 - batch 72199: mean_policy_losses: 20.355, mean_net_lifetime: 5088.3382, mean_mc_travel_dist: 1385.9229, mean_rewards: 285.1538, total_rewards: 3728.8363, mean_steps: 17.0300, mean_ecr: 0.0470 mean_entropies: 0.6029, took: 74.6847s
2022-10-10 21:34:20,846 [INFO] 	Process 2 - batch 65799: mean_policy_losses: -126.031, mean_net_lifetime: 6707.4830, mean_mc_travel_dist: 1829.8475, mean_rewards: 260.4612, total_rewards: 4900.4208, mean_steps: 24.9100, mean_ecr: 0.0390 mean_entropies: 0.4174, took: 102.1683s
2022-10-10 21:34:40,422 [INFO] 	Process 4 - batch 72299: mean_policy_losses: 19.705, mean_net_lifetime: 6238.4500, mean_mc_travel_dist: 1786.1918, mean_rewards: 281.9902, total_rewards: 4481.2794, mean_steps: 21.8900, mean_ecr: 0.0437 mean_entropies: 0.5156, took: 92.6836s
2022-10-10 21:34:58,960 [INFO] Process 3 - epoch 46: mean_policy_losses: 66.011, mean_net_lifetime: 4265.8071, mean_mc_travel_dist: 1361.5699, mean_entropies: 0.9282, m_net_lifetime_valid: 4249.8354, took: 1840.8991s, (144.0531 / 100 batches)

2022-10-10 21:35:10,148 [INFO] Process 7 - epoch 44: mean_policy_losses: -342.325, mean_net_lifetime: 4078.3624, mean_mc_travel_dist: 1564.1173, mean_entropies: 1.6074, m_net_lifetime_valid: 4748.0690, took: 2232.6993s, (150.4774 / 100 batches)

2022-10-10 21:36:03,185 [INFO] 	Process 2 - batch 65899: mean_policy_losses: -97.860, mean_net_lifetime: 6440.0307, mean_mc_travel_dist: 1777.2635, mean_rewards: 265.9256, total_rewards: 4689.8340, mean_steps: 23.2600, mean_ecr: 0.0391 mean_entropies: 0.4393, took: 102.3380s
2022-10-10 21:36:17,397 [INFO] 	Process 3 - batch 69099: mean_policy_losses: -21.050, mean_net_lifetime: 4665.3638, mean_mc_travel_dist: 1238.0697, mean_rewards: 269.1755, total_rewards: 3452.1009, mean_steps: 16.3900, mean_ecr: 0.0481 mean_entropies: 0.4710, took: 641.2212s
2022-10-10 21:36:31,984 [INFO] 	Process 4 - batch 72399: mean_policy_losses: 128.659, mean_net_lifetime: 6965.6047, mean_mc_travel_dist: 2040.4673, mean_rewards: 283.9668, total_rewards: 4953.8096, mean_steps: 24.7800, mean_ecr: 0.0424 mean_entropies: 0.5319, took: 111.5612s
2022-10-10 21:36:39,599 [INFO] 	Process 7 - batch 66099: mean_policy_losses: -745.957, mean_net_lifetime: 4545.2598, mean_mc_travel_dist: 1438.6845, mean_rewards: 217.2483, total_rewards: 3136.3655, mean_steps: 19.8500, mean_ecr: 0.0412 mean_entropies: 1.3920, took: 739.1642s
2022-10-10 21:37:36,116 [INFO] 	Process 3 - batch 69199: mean_policy_losses: -0.537, mean_net_lifetime: 4787.9038, mean_mc_travel_dist: 1267.6171, mean_rewards: 277.9981, total_rewards: 3550.9527, mean_steps: 16.2500, mean_ecr: 0.0480 mean_entropies: 0.4901, took: 78.7186s
2022-10-10 21:37:51,840 [INFO] 	Process 2 - batch 65999: mean_policy_losses: -30.519, mean_net_lifetime: 6888.5017, mean_mc_travel_dist: 1919.5953, mean_rewards: 273.7739, total_rewards: 5006.8260, mean_steps: 24.2700, mean_ecr: 0.0387 mean_entropies: 0.4807, took: 108.6547s
2022-10-10 21:37:56,385 [INFO] 	Process 7 - batch 66199: mean_policy_losses: -913.557, mean_net_lifetime: 4050.0349, mean_mc_travel_dist: 1325.6047, mean_rewards: 232.1410, total_rewards: 2767.3733, mean_steps: 16.8500, mean_ecr: 0.0417 mean_entropies: 1.4112, took: 76.7857s
2022-10-10 21:38:14,822 [INFO] 	Process 4 - batch 72499: mean_policy_losses: 94.831, mean_net_lifetime: 6538.3395, mean_mc_travel_dist: 1880.2907, mean_rewards: 284.4948, total_rewards: 4684.0157, mean_steps: 22.8200, mean_ecr: 0.0437 mean_entropies: 0.6087, took: 102.8380s
2022-10-10 21:38:49,139 [INFO] 	Process 3 - batch 69299: mean_policy_losses: -8.454, mean_net_lifetime: 4645.4887, mean_mc_travel_dist: 1232.0919, mean_rewards: 277.9144, total_rewards: 3452.4839, mean_steps: 15.7900, mean_ecr: 0.0482 mean_entropies: 0.5007, took: 73.0240s
2022-10-10 21:38:58,213 [INFO] 	Process 7 - batch 66299: mean_policy_losses: -1185.271, mean_net_lifetime: 3503.9410, mean_mc_travel_dist: 1179.1340, mean_rewards: 240.4087, total_rewards: 2362.8829, mean_steps: 13.7200, mean_ecr: 0.0421 mean_entropies: 1.4334, took: 61.8285s
2022-10-10 21:40:02,461 [INFO] 	Process 3 - batch 69399: mean_policy_losses: -11.469, mean_net_lifetime: 4638.8170, mean_mc_travel_dist: 1228.2554, mean_rewards: 273.4494, total_rewards: 3447.3577, mean_steps: 16.0200, mean_ecr: 0.0483 mean_entropies: 0.4921, took: 73.3211s
2022-10-10 21:40:02,868 [INFO] 	Process 4 - batch 72599: mean_policy_losses: 114.270, mean_net_lifetime: 7061.1767, mean_mc_travel_dist: 2117.4608, mean_rewards: 284.9271, total_rewards: 4972.0133, mean_steps: 25.0900, mean_ecr: 0.0419 mean_entropies: 0.5204, took: 108.0460s
2022-10-10 21:40:10,517 [INFO] Process 6 - epoch 62: mean_policy_losses: -217.689, mean_net_lifetime: 3000.4396, mean_mc_travel_dist: 962.4737, mean_entropies: 0.6246, m_net_lifetime_valid: 4359.6659, took: 1459.9242s, (107.2251 / 100 batches)

2022-10-10 21:40:21,878 [INFO] 	Process 7 - batch 66399: mean_policy_losses: -754.076, mean_net_lifetime: 4554.7910, mean_mc_travel_dist: 1488.9927, mean_rewards: 230.0226, total_rewards: 3093.3128, mean_steps: 19.0000, mean_ecr: 0.0412 mean_entropies: 1.3734, took: 83.6650s
2022-10-10 21:41:01,340 [INFO] Process 1 - epoch 39: mean_policy_losses: 28.717, mean_net_lifetime: 5028.7168, mean_mc_travel_dist: 2031.2624, mean_entropies: 1.2179, m_net_lifetime_valid: 4275.6978, took: 2399.8690s, (170.4365 / 100 batches)

2022-10-10 21:41:05,873 [INFO] 	Process 6 - batch 93099: mean_policy_losses: -69.457, mean_net_lifetime: 4168.7686, mean_mc_travel_dist: 1122.6723, mean_rewards: 341.6570, total_rewards: 3115.2007, mean_steps: 11.1500, mean_ecr: 0.0549 mean_entropies: 0.1122, took: 643.9805s
2022-10-10 21:41:18,262 [INFO] 	Process 3 - batch 69499: mean_policy_losses: -21.124, mean_net_lifetime: 4730.3307, mean_mc_travel_dist: 1273.7869, mean_rewards: 280.7897, total_rewards: 3486.3566, mean_steps: 15.8800, mean_ecr: 0.0479 mean_entropies: 0.5198, took: 75.8014s
2022-10-10 21:41:52,048 [INFO] 	Process 7 - batch 66499: mean_policy_losses: -717.180, mean_net_lifetime: 4650.8636, mean_mc_travel_dist: 1511.7572, mean_rewards: 227.0777, total_rewards: 3172.2302, mean_steps: 19.8000, mean_ecr: 0.0412 mean_entropies: 1.3589, took: 90.1693s
2022-10-10 21:41:59,329 [INFO] 	Process 4 - batch 72699: mean_policy_losses: 100.197, mean_net_lifetime: 7180.2941, mean_mc_travel_dist: 2093.2230, mean_rewards: 283.0154, total_rewards: 5111.2753, mean_steps: 25.6500, mean_ecr: 0.0422 mean_entropies: 0.5491, took: 116.4616s
2022-10-10 21:42:02,015 [INFO] 	Process 6 - batch 93199: mean_policy_losses: -162.607, mean_net_lifetime: 4041.6399, mean_mc_travel_dist: 1091.7323, mean_rewards: 340.6754, total_rewards: 3024.9962, mean_steps: 10.8000, mean_ecr: 0.0549 mean_entropies: 0.1038, took: 56.1419s
2022-10-10 21:42:23,591 [INFO] Process 5 - epoch 43: mean_policy_losses: -206.536, mean_net_lifetime: 4848.8028, mean_mc_travel_dist: 1941.5787, mean_entropies: 1.2281, m_net_lifetime_valid: 4614.1007, took: 2514.1318s, (154.6868 / 100 batches)

2022-10-10 21:42:39,725 [INFO] 	Process 3 - batch 69599: mean_policy_losses: -24.410, mean_net_lifetime: 4717.8472, mean_mc_travel_dist: 1256.6789, mean_rewards: 276.1299, total_rewards: 3497.9779, mean_steps: 16.1000, mean_ecr: 0.0482 mean_entropies: 0.5059, took: 81.4624s
2022-10-10 21:42:59,799 [INFO] 	Process 1 - batch 58599: mean_policy_losses: -36.563, mean_net_lifetime: 6179.5200, mean_mc_travel_dist: 1998.2537, mean_rewards: 234.1385, total_rewards: 4209.4205, mean_steps: 25.7900, mean_ecr: 0.0382 mean_entropies: 0.9656, took: 709.2332s
2022-10-10 21:42:59,982 [INFO] 	Process 6 - batch 93299: mean_policy_losses: -117.862, mean_net_lifetime: 4046.4372, mean_mc_travel_dist: 1085.6215, mean_rewards: 341.9181, total_rewards: 3025.4159, mean_steps: 10.7900, mean_ecr: 0.0550 mean_entropies: 0.1035, took: 57.9673s
2022-10-10 21:43:30,774 [INFO] 	Process 7 - batch 66599: mean_policy_losses: -579.603, mean_net_lifetime: 4835.7231, mean_mc_travel_dist: 1515.6429, mean_rewards: 223.2343, total_rewards: 3348.2093, mean_steps: 20.9600, mean_ecr: 0.0410 mean_entropies: 1.2837, took: 98.7264s
2022-10-10 21:43:51,748 [INFO] 	Process 4 - batch 72799: mean_policy_losses: 102.963, mean_net_lifetime: 6573.7319, mean_mc_travel_dist: 1872.7951, mean_rewards: 283.1322, total_rewards: 4723.9702, mean_steps: 22.9600, mean_ecr: 0.0434 mean_entropies: 0.5613, took: 112.4184s
2022-10-10 21:43:58,251 [INFO] 	Process 6 - batch 93399: mean_policy_losses: -35.960, mean_net_lifetime: 4108.7758, mean_mc_travel_dist: 1102.8401, mean_rewards: 342.4469, total_rewards: 3071.5177, mean_steps: 10.9600, mean_ecr: 0.0549 mean_entropies: 0.0980, took: 58.2691s
2022-10-10 21:44:04,643 [INFO] 	Process 3 - batch 69699: mean_policy_losses: 0.953, mean_net_lifetime: 4710.8273, mean_mc_travel_dist: 1239.0544, mean_rewards: 267.3693, total_rewards: 3507.6636, mean_steps: 16.6800, mean_ecr: 0.0481 mean_entropies: 0.4644, took: 84.9181s
2022-10-10 21:44:24,363 [INFO] 	Process 5 - batch 64599: mean_policy_losses: -189.742, mean_net_lifetime: 6768.0319, mean_mc_travel_dist: 2199.3023, mean_rewards: 266.4339, total_rewards: 4616.2747, mean_steps: 24.9200, mean_ecr: 0.0303 mean_entropies: 0.5541, took: 741.8432s
2022-10-10 21:45:00,348 [INFO] 	Process 1 - batch 58699: mean_policy_losses: -82.190, mean_net_lifetime: 5872.2666, mean_mc_travel_dist: 1930.8693, mean_rewards: 231.2810, total_rewards: 3956.6459, mean_steps: 24.7200, mean_ecr: 0.0384 mean_entropies: 0.9238, took: 120.5490s
2022-10-10 21:45:02,008 [INFO] 	Process 6 - batch 93499: mean_policy_losses: -10.784, mean_net_lifetime: 4340.7641, mean_mc_travel_dist: 1178.0033, mean_rewards: 343.0682, total_rewards: 3251.4075, mean_steps: 11.6400, mean_ecr: 0.0546 mean_entropies: 0.0780, took: 63.7568s
2022-10-10 21:45:21,937 [INFO] 	Process 7 - batch 66699: mean_policy_losses: -460.580, mean_net_lifetime: 5065.4492, mean_mc_travel_dist: 1564.5491, mean_rewards: 213.3061, total_rewards: 3532.4269, mean_steps: 23.4600, mean_ecr: 0.0406 mean_entropies: 1.2571, took: 111.1631s
2022-10-10 21:45:28,584 [INFO] 	Process 3 - batch 69799: mean_policy_losses: -1.279, mean_net_lifetime: 4745.9633, mean_mc_travel_dist: 1241.4954, mean_rewards: 270.8250, total_rewards: 3539.0026, mean_steps: 16.6000, mean_ecr: 0.0482 mean_entropies: 0.4609, took: 83.9407s
2022-10-10 21:45:57,658 [INFO] 	Process 4 - batch 72899: mean_policy_losses: 152.094, mean_net_lifetime: 7071.6694, mean_mc_travel_dist: 2072.9820, mean_rewards: 273.5766, total_rewards: 5024.5436, mean_steps: 26.1200, mean_ecr: 0.0420 mean_entropies: 0.5802, took: 125.9109s
2022-10-10 21:45:59,527 [INFO] 	Process 6 - batch 93599: mean_policy_losses: -112.412, mean_net_lifetime: 4048.2649, mean_mc_travel_dist: 1103.3142, mean_rewards: 340.7431, total_rewards: 3028.2696, mean_steps: 10.8100, mean_ecr: 0.0550 mean_entropies: 0.0915, took: 57.5192s
2022-10-10 21:46:20,540 [INFO] 	Process 5 - batch 64699: mean_policy_losses: -171.888, mean_net_lifetime: 6646.4795, mean_mc_travel_dist: 2124.2690, mean_rewards: 271.8641, total_rewards: 4555.9155, mean_steps: 23.8000, mean_ecr: 0.0308 mean_entropies: 0.5165, took: 116.1763s
2022-10-10 21:46:53,032 [INFO] 	Process 3 - batch 69899: mean_policy_losses: -8.376, mean_net_lifetime: 4712.4675, mean_mc_travel_dist: 1246.3173, mean_rewards: 272.7189, total_rewards: 3509.9378, mean_steps: 16.3100, mean_ecr: 0.0480 mean_entropies: 0.4625, took: 84.4482s
2022-10-10 21:46:56,041 [INFO] 	Process 1 - batch 58799: mean_policy_losses: -41.319, mean_net_lifetime: 6126.5810, mean_mc_travel_dist: 2001.8810, mean_rewards: 241.7823, total_rewards: 4150.4643, mean_steps: 24.5300, mean_ecr: 0.0384 mean_entropies: 0.9621, took: 115.6923s
2022-10-10 21:46:59,386 [INFO] 	Process 6 - batch 93699: mean_policy_losses: -45.361, mean_net_lifetime: 4115.4593, mean_mc_travel_dist: 1114.7838, mean_rewards: 340.9808, total_rewards: 3080.3941, mean_steps: 11.0100, mean_ecr: 0.0548 mean_entropies: 0.0884, took: 59.8589s
2022-10-10 21:47:04,024 [INFO] 	Process 7 - batch 66799: mean_policy_losses: -636.935, mean_net_lifetime: 4677.5315, mean_mc_travel_dist: 1469.3317, mean_rewards: 215.3890, total_rewards: 3244.1588, mean_steps: 21.4500, mean_ecr: 0.0411 mean_entropies: 1.2779, took: 102.0881s
2022-10-10 21:48:00,395 [INFO] 	Process 4 - batch 72999: mean_policy_losses: 136.842, mean_net_lifetime: 6807.2200, mean_mc_travel_dist: 1989.5863, mean_rewards: 274.3623, total_rewards: 4849.9162, mean_steps: 25.4400, mean_ecr: 0.0435 mean_entropies: 0.5995, took: 122.7355s
2022-10-10 21:48:01,889 [INFO] 	Process 6 - batch 93799: mean_policy_losses: -19.389, mean_net_lifetime: 4296.1423, mean_mc_travel_dist: 1171.1090, mean_rewards: 343.2523, total_rewards: 3220.3543, mean_steps: 11.5100, mean_ecr: 0.0548 mean_entropies: 0.0783, took: 62.5025s
2022-10-10 21:48:07,238 [INFO] Process 2 - epoch 44: mean_policy_losses: -0.317, mean_net_lifetime: 4638.0985, mean_mc_travel_dist: 1588.9719, mean_entropies: 0.9631, m_net_lifetime_valid: 4798.8962, took: 2366.2703s, (151.7052 / 100 batches)

2022-10-10 21:48:20,157 [INFO] 	Process 3 - batch 69999: mean_policy_losses: -44.918, mean_net_lifetime: 4530.5810, mean_mc_travel_dist: 1179.9162, mean_rewards: 253.9967, total_rewards: 3375.7065, mean_steps: 16.9200, mean_ecr: 0.0484 mean_entropies: 0.4689, took: 87.1254s
2022-10-10 21:48:25,305 [INFO] 	Process 5 - batch 64799: mean_policy_losses: -129.402, mean_net_lifetime: 7051.8200, mean_mc_travel_dist: 2262.4672, mean_rewards: 273.9901, total_rewards: 4839.6656, mean_steps: 25.0000, mean_ecr: 0.0306 mean_entropies: 0.5163, took: 124.7655s
2022-10-10 21:49:00,959 [INFO] 	Process 7 - batch 66899: mean_policy_losses: -412.055, mean_net_lifetime: 5208.0057, mean_mc_travel_dist: 1637.8234, mean_rewards: 207.1875, total_rewards: 3619.9851, mean_steps: 24.3600, mean_ecr: 0.0407 mean_entropies: 1.2626, took: 116.9341s
2022-10-10 21:49:02,745 [INFO] 	Process 1 - batch 58899: mean_policy_losses: -46.883, mean_net_lifetime: 6162.4716, mean_mc_travel_dist: 2031.2182, mean_rewards: 227.4880, total_rewards: 4158.8190, mean_steps: 26.5000, mean_ecr: 0.0381 mean_entropies: 0.9119, took: 126.7050s
2022-10-10 21:49:04,169 [INFO] 	Process 6 - batch 93899: mean_policy_losses: -28.434, mean_net_lifetime: 4191.0049, mean_mc_travel_dist: 1143.7328, mean_rewards: 340.5906, total_rewards: 3136.7796, mean_steps: 11.2300, mean_ecr: 0.0548 mean_entropies: 0.0769, took: 62.2804s
2022-10-10 21:49:49,469 [INFO] 	Process 3 - batch 70099: mean_policy_losses: -1.913, mean_net_lifetime: 4774.6195, mean_mc_travel_dist: 1227.5436, mean_rewards: 262.4480, total_rewards: 3578.4429, mean_steps: 17.2600, mean_ecr: 0.0482 mean_entropies: 0.4561, took: 89.3119s
2022-10-10 21:49:59,882 [INFO] 	Process 2 - batch 66099: mean_policy_losses: -98.485, mean_net_lifetime: 6260.8636, mean_mc_travel_dist: 1754.7860, mean_rewards: 266.8825, total_rewards: 4541.9470, mean_steps: 22.5500, mean_ecr: 0.0391 mean_entropies: 0.4208, took: 728.0432s
2022-10-10 21:50:05,991 [INFO] 	Process 6 - batch 93999: mean_policy_losses: -71.933, mean_net_lifetime: 4171.8563, mean_mc_travel_dist: 1143.5586, mean_rewards: 342.4092, total_rewards: 3124.7689, mean_steps: 11.1500, mean_ecr: 0.0548 mean_entropies: 0.0701, took: 61.8218s
2022-10-10 21:50:06,610 [INFO] 	Process 4 - batch 73099: mean_policy_losses: 139.969, mean_net_lifetime: 6863.5847, mean_mc_travel_dist: 1976.2255, mean_rewards: 273.2003, total_rewards: 4915.6338, mean_steps: 25.2000, mean_ecr: 0.0428 mean_entropies: 0.5865, took: 126.2157s
2022-10-10 21:50:25,290 [INFO] 	Process 5 - batch 64899: mean_policy_losses: -178.675, mean_net_lifetime: 6600.1939, mean_mc_travel_dist: 2141.9317, mean_rewards: 270.6607, total_rewards: 4505.6324, mean_steps: 23.6700, mean_ecr: 0.0306 mean_entropies: 0.5131, took: 119.9842s
2022-10-10 21:50:54,968 [INFO] 	Process 7 - batch 66999: mean_policy_losses: -513.173, mean_net_lifetime: 4956.6039, mean_mc_travel_dist: 1572.5062, mean_rewards: 207.6043, total_rewards: 3427.3690, mean_steps: 23.2500, mean_ecr: 0.0408 mean_entropies: 1.2867, took: 114.0099s
2022-10-10 21:51:02,937 [INFO] 	Process 1 - batch 58999: mean_policy_losses: -91.207, mean_net_lifetime: 5838.4627, mean_mc_travel_dist: 1993.6533, mean_rewards: 229.8153, total_rewards: 3877.2821, mean_steps: 24.7700, mean_ecr: 0.0383 mean_entropies: 0.8853, took: 120.1915s
2022-10-10 21:51:09,215 [INFO] 	Process 6 - batch 94099: mean_policy_losses: -47.876, mean_net_lifetime: 4232.2064, mean_mc_travel_dist: 1160.1819, mean_rewards: 342.3026, total_rewards: 3171.7669, mean_steps: 11.3300, mean_ecr: 0.0547 mean_entropies: 0.0601, took: 63.2246s
2022-10-10 21:51:16,455 [INFO] 	Process 3 - batch 70199: mean_policy_losses: 8.213, mean_net_lifetime: 4744.4447, mean_mc_travel_dist: 1231.2096, mean_rewards: 267.7880, total_rewards: 3547.9508, mean_steps: 16.7900, mean_ecr: 0.0482 mean_entropies: 0.4889, took: 86.9858s
2022-10-10 21:52:02,010 [INFO] 	Process 2 - batch 66199: mean_policy_losses: -38.553, mean_net_lifetime: 6817.4412, mean_mc_travel_dist: 1922.3329, mean_rewards: 266.3960, total_rewards: 4929.4256, mean_steps: 24.6200, mean_ecr: 0.0386 mean_entropies: 0.3985, took: 122.1269s
2022-10-10 21:52:09,206 [INFO] 	Process 5 - batch 64999: mean_policy_losses: -202.366, mean_net_lifetime: 5917.0183, mean_mc_travel_dist: 1940.5420, mean_rewards: 278.3839, total_rewards: 4029.5974, mean_steps: 20.4000, mean_ecr: 0.0307 mean_entropies: 0.4857, took: 103.9169s
2022-10-10 21:52:12,761 [INFO] 	Process 6 - batch 94199: mean_policy_losses: -41.043, mean_net_lifetime: 4316.8033, mean_mc_travel_dist: 1181.5509, mean_rewards: 343.1658, total_rewards: 3239.0231, mean_steps: 11.5700, mean_ecr: 0.0546 mean_entropies: 0.0526, took: 63.5461s
2022-10-10 21:52:36,480 [INFO] 	Process 4 - batch 73199: mean_policy_losses: 207.046, mean_net_lifetime: 7702.9493, mean_mc_travel_dist: 2333.5929, mean_rewards: 261.7775, total_rewards: 5393.9905, mean_steps: 30.5500, mean_ecr: 0.0420 mean_entropies: 0.6082, took: 149.8701s
2022-10-10 21:52:43,718 [INFO] 	Process 7 - batch 67099: mean_policy_losses: -463.173, mean_net_lifetime: 4750.8686, mean_mc_travel_dist: 1475.6485, mean_rewards: 206.7498, total_rewards: 3300.7112, mean_steps: 22.1900, mean_ecr: 0.0410 mean_entropies: 1.2263, took: 108.7486s
2022-10-10 21:52:47,797 [INFO] 	Process 3 - batch 70299: mean_policy_losses: 2.049, mean_net_lifetime: 4805.2339, mean_mc_travel_dist: 1260.5767, mean_rewards: 270.2547, total_rewards: 3578.3412, mean_steps: 16.8500, mean_ecr: 0.0481 mean_entropies: 0.4879, took: 91.3418s
2022-10-10 21:52:58,911 [INFO] 	Process 1 - batch 59099: mean_policy_losses: -121.208, mean_net_lifetime: 5740.2885, mean_mc_travel_dist: 1999.7738, mean_rewards: 237.2079, total_rewards: 3767.0471, mean_steps: 23.4300, mean_ecr: 0.0383 mean_entropies: 0.8625, took: 115.9745s
2022-10-10 21:53:16,416 [INFO] 	Process 6 - batch 94299: mean_policy_losses: -38.078, mean_net_lifetime: 4237.7237, mean_mc_travel_dist: 1163.6245, mean_rewards: 342.1512, total_rewards: 3174.6055, mean_steps: 11.3800, mean_ecr: 0.0548 mean_entropies: 0.0653, took: 63.6545s
2022-10-10 21:54:00,169 [INFO] 	Process 2 - batch 66299: mean_policy_losses: -57.011, mean_net_lifetime: 6652.7490, mean_mc_travel_dist: 1907.8952, mean_rewards: 268.0191, total_rewards: 4779.4930, mean_steps: 23.8800, mean_ecr: 0.0386 mean_entropies: 0.3914, took: 118.1589s
2022-10-10 21:54:04,121 [INFO] 	Process 5 - batch 65099: mean_policy_losses: -129.604, mean_net_lifetime: 6376.9884, mean_mc_travel_dist: 2150.1809, mean_rewards: 276.7715, total_rewards: 4265.2008, mean_steps: 22.2600, mean_ecr: 0.0303 mean_entropies: 0.4984, took: 114.9144s
2022-10-10 21:54:15,858 [INFO] 	Process 3 - batch 70399: mean_policy_losses: 1.385, mean_net_lifetime: 4743.3295, mean_mc_travel_dist: 1221.6722, mean_rewards: 269.3090, total_rewards: 3560.6085, mean_steps: 16.6600, mean_ecr: 0.0483 mean_entropies: 0.4903, took: 88.0601s
2022-10-10 21:54:17,363 [INFO] 	Process 6 - batch 94399: mean_policy_losses: -30.412, mean_net_lifetime: 4148.2902, mean_mc_travel_dist: 1132.6413, mean_rewards: 341.2341, total_rewards: 3111.3596, mean_steps: 11.1200, mean_ecr: 0.0549 mean_entropies: 0.0695, took: 60.9475s
2022-10-10 21:54:23,057 [INFO] 	Process 4 - batch 73299: mean_policy_losses: 126.160, mean_net_lifetime: 5608.4120, mean_mc_travel_dist: 1583.3961, mean_rewards: 270.1545, total_rewards: 4061.6227, mean_steps: 20.7900, mean_ecr: 0.0468 mean_entropies: 0.6465, took: 106.5768s
2022-10-10 21:54:42,320 [INFO] 	Process 7 - batch 67199: mean_policy_losses: -370.659, mean_net_lifetime: 5035.0823, mean_mc_travel_dist: 1585.3379, mean_rewards: 205.0103, total_rewards: 3487.7338, mean_steps: 23.8100, mean_ecr: 0.0407 mean_entropies: 1.2075, took: 118.6024s
2022-10-10 21:55:01,515 [INFO] 	Process 1 - batch 59199: mean_policy_losses: -59.925, mean_net_lifetime: 6028.3892, mean_mc_travel_dist: 2047.2117, mean_rewards: 235.1841, total_rewards: 4007.1109, mean_steps: 24.8900, mean_ecr: 0.0381 mean_entropies: 0.8544, took: 122.6038s
2022-10-10 21:55:20,436 [INFO] 	Process 6 - batch 94499: mean_policy_losses: -41.878, mean_net_lifetime: 4281.2985, mean_mc_travel_dist: 1172.8269, mean_rewards: 342.4168, total_rewards: 3211.1803, mean_steps: 11.4900, mean_ecr: 0.0546 mean_entropies: 0.0569, took: 63.0730s
2022-10-10 21:55:41,840 [INFO] 	Process 3 - batch 70499: mean_policy_losses: -20.743, mean_net_lifetime: 4629.4082, mean_mc_travel_dist: 1198.5152, mean_rewards: 266.4295, total_rewards: 3455.1457, mean_steps: 16.4200, mean_ecr: 0.0483 mean_entropies: 0.4707, took: 85.9841s
2022-10-10 21:56:04,061 [INFO] 	Process 5 - batch 65199: mean_policy_losses: -137.372, mean_net_lifetime: 6650.6153, mean_mc_travel_dist: 2163.0266, mean_rewards: 274.6199, total_rewards: 4538.8233, mean_steps: 23.5200, mean_ecr: 0.0306 mean_entropies: 0.5053, took: 119.9406s
2022-10-10 21:56:05,370 [INFO] 	Process 2 - batch 66399: mean_policy_losses: -30.876, mean_net_lifetime: 7106.7064, mean_mc_travel_dist: 2011.7028, mean_rewards: 268.2392, total_rewards: 5126.2185, mean_steps: 25.6000, mean_ecr: 0.0383 mean_entropies: 0.4030, took: 125.2018s
2022-10-10 21:56:18,181 [INFO] 	Process 4 - batch 73399: mean_policy_losses: 165.885, mean_net_lifetime: 6379.3628, mean_mc_travel_dist: 1806.0184, mean_rewards: 273.5294, total_rewards: 4592.8531, mean_steps: 23.3700, mean_ecr: 0.0445 mean_entropies: 0.6037, took: 115.1249s
2022-10-10 21:56:23,428 [INFO] 	Process 7 - batch 67299: mean_policy_losses: -569.360, mean_net_lifetime: 4668.3373, mean_mc_travel_dist: 1440.6979, mean_rewards: 213.0449, total_rewards: 3258.0851, mean_steps: 21.1400, mean_ecr: 0.0411 mean_entropies: 1.2924, took: 101.1079s
2022-10-10 21:57:05,649 [INFO] 	Process 1 - batch 59299: mean_policy_losses: -37.693, mean_net_lifetime: 6134.6313, mean_mc_travel_dist: 2002.9366, mean_rewards: 225.1841, total_rewards: 4151.1478, mean_steps: 26.5600, mean_ecr: 0.0383 mean_entropies: 0.9080, took: 124.1344s
2022-10-10 21:58:07,673 [INFO] 	Process 2 - batch 66499: mean_policy_losses: -21.183, mean_net_lifetime: 7189.4990, mean_mc_travel_dist: 2087.6813, mean_rewards: 264.7070, total_rewards: 5139.8290, mean_steps: 26.2600, mean_ecr: 0.0380 mean_entropies: 0.4451, took: 122.3021s
2022-10-10 21:58:09,448 [INFO] 	Process 7 - batch 67399: mean_policy_losses: -426.469, mean_net_lifetime: 5013.1385, mean_mc_travel_dist: 1538.2300, mean_rewards: 211.9071, total_rewards: 3510.9053, mean_steps: 22.8200, mean_ecr: 0.0408 mean_entropies: 1.3402, took: 106.0194s
2022-10-10 21:58:10,727 [INFO] 	Process 5 - batch 65299: mean_policy_losses: -105.294, mean_net_lifetime: 7555.4682, mean_mc_travel_dist: 2481.9060, mean_rewards: 278.7393, total_rewards: 5129.7245, mean_steps: 26.4800, mean_ecr: 0.0302 mean_entropies: 0.5498, took: 126.6656s
2022-10-10 21:58:30,772 [INFO] 	Process 4 - batch 73499: mean_policy_losses: 212.073, mean_net_lifetime: 7400.3538, mean_mc_travel_dist: 2131.2740, mean_rewards: 265.4404, total_rewards: 5295.6241, mean_steps: 28.4000, mean_ecr: 0.0417 mean_entropies: 0.5873, took: 132.5912s
2022-10-10 21:59:10,785 [INFO] 	Process 1 - batch 59399: mean_policy_losses: 6.338, mean_net_lifetime: 6148.9592, mean_mc_travel_dist: 2027.6053, mean_rewards: 225.5769, total_rewards: 4149.5837, mean_steps: 26.6500, mean_ecr: 0.0382 mean_entropies: 0.9525, took: 125.1360s
2022-10-10 21:59:36,361 [INFO] 	Process 7 - batch 67499: mean_policy_losses: -533.290, mean_net_lifetime: 4208.7031, mean_mc_travel_dist: 1315.5580, mean_rewards: 214.7567, total_rewards: 2918.1977, mean_steps: 19.0000, mean_ecr: 0.0415 mean_entropies: 1.2873, took: 86.9136s
2022-10-10 22:00:06,831 [INFO] 	Process 2 - batch 66599: mean_policy_losses: 17.836, mean_net_lifetime: 7340.4287, mean_mc_travel_dist: 2088.3338, mean_rewards: 265.0243, total_rewards: 5292.9939, mean_steps: 26.8100, mean_ecr: 0.0380 mean_entropies: 0.4466, took: 119.1590s
2022-10-10 22:00:19,279 [INFO] 	Process 5 - batch 65399: mean_policy_losses: -51.970, mean_net_lifetime: 7748.8875, mean_mc_travel_dist: 2534.7926, mean_rewards: 275.0417, total_rewards: 5252.3170, mean_steps: 27.7700, mean_ecr: 0.0302 mean_entropies: 0.5742, took: 128.5518s
2022-10-10 22:01:01,777 [INFO] 	Process 1 - batch 59499: mean_policy_losses: 19.100, mean_net_lifetime: 6177.3156, mean_mc_travel_dist: 2014.4129, mean_rewards: 236.7505, total_rewards: 4190.6982, mean_steps: 25.3600, mean_ecr: 0.0382 mean_entropies: 0.9717, took: 110.9913s
2022-10-10 22:02:03,377 [INFO] 	Process 2 - batch 66699: mean_policy_losses: -5.354, mean_net_lifetime: 7393.2891, mean_mc_travel_dist: 2091.7096, mean_rewards: 266.7545, total_rewards: 5336.6296, mean_steps: 26.7900, mean_ecr: 0.0380 mean_entropies: 0.4480, took: 116.5450s
2022-10-10 22:02:36,856 [INFO] 	Process 5 - batch 65499: mean_policy_losses: -60.672, mean_net_lifetime: 8504.5964, mean_mc_travel_dist: 2724.7392, mean_rewards: 274.8396, total_rewards: 5821.0726, mean_steps: 30.7400, mean_ecr: 0.0300 mean_entropies: 0.6006, took: 137.5763s
2022-10-10 22:02:51,368 [INFO] 	Process 1 - batch 59599: mean_policy_losses: -45.647, mean_net_lifetime: 6279.5297, mean_mc_travel_dist: 2052.2164, mean_rewards: 234.3111, total_rewards: 4261.4559, mean_steps: 26.0500, mean_ecr: 0.0381 mean_entropies: 0.9561, took: 109.5915s
2022-10-10 22:04:01,849 [INFO] 	Process 2 - batch 66799: mean_policy_losses: -20.637, mean_net_lifetime: 7536.5545, mean_mc_travel_dist: 2141.9696, mean_rewards: 265.4281, total_rewards: 5419.4994, mean_steps: 27.5000, mean_ecr: 0.0378 mean_entropies: 0.4411, took: 118.4725s
2022-10-10 22:04:43,021 [INFO] 	Process 1 - batch 59699: mean_policy_losses: -58.710, mean_net_lifetime: 6292.0945, mean_mc_travel_dist: 2040.5003, mean_rewards: 232.5646, total_rewards: 4280.3920, mean_steps: 26.2300, mean_ecr: 0.0381 mean_entropies: 0.9411, took: 111.6517s
2022-10-10 22:04:50,320 [INFO] 	Process 5 - batch 65599: mean_policy_losses: -7.438, mean_net_lifetime: 8491.0670, mean_mc_travel_dist: 2680.1837, mean_rewards: 276.2218, total_rewards: 5839.3881, mean_steps: 30.4400, mean_ecr: 0.0301 mean_entropies: 0.6165, took: 133.4647s
2022-10-10 22:05:32,392 [INFO] Process 6 - epoch 63: mean_policy_losses: -215.157, mean_net_lifetime: 3019.2109, mean_mc_travel_dist: 965.2579, mean_entropies: 0.6160, m_net_lifetime_valid: 4157.3189, took: 1521.8734s, (107.1090 / 100 batches)

2022-10-10 22:05:54,829 [INFO] Process 3 - epoch 47: mean_policy_losses: 64.391, mean_net_lifetime: 4275.1624, mean_mc_travel_dist: 1358.9022, mean_entropies: 0.9187, m_net_lifetime_valid: 4453.8096, took: 1855.8666s, (143.5501 / 100 batches)

2022-10-10 22:05:59,921 [INFO] 	Process 2 - batch 66899: mean_policy_losses: -46.362, mean_net_lifetime: 7346.9691, mean_mc_travel_dist: 2089.8271, mean_rewards: 264.5676, total_rewards: 5291.5810, mean_steps: 26.8600, mean_ecr: 0.0379 mean_entropies: 0.4880, took: 118.0715s
2022-10-10 22:06:27,650 [INFO] 	Process 6 - batch 94599: mean_policy_losses: -81.752, mean_net_lifetime: 4040.2659, mean_mc_travel_dist: 1090.3892, mean_rewards: 340.2316, total_rewards: 3025.8358, mean_steps: 10.8500, mean_ecr: 0.0549 mean_entropies: 0.1242, took: 667.2135s
2022-10-10 22:06:38,727 [INFO] 	Process 1 - batch 59799: mean_policy_losses: 4.359, mean_net_lifetime: 6389.1811, mean_mc_travel_dist: 2057.3495, mean_rewards: 235.3737, total_rewards: 4350.8558, mean_steps: 26.3200, mean_ecr: 0.0380 mean_entropies: 0.9893, took: 115.7071s
2022-10-10 22:07:03,875 [INFO] 	Process 5 - batch 65699: mean_policy_losses: -23.812, mean_net_lifetime: 8101.0261, mean_mc_travel_dist: 2568.4417, mean_rewards: 274.5555, total_rewards: 5584.3096, mean_steps: 29.2000, mean_ecr: 0.0301 mean_entropies: 0.6320, took: 133.5561s
2022-10-10 22:07:19,338 [INFO] 	Process 3 - batch 70599: mean_policy_losses: -29.970, mean_net_lifetime: 4737.7987, mean_mc_travel_dist: 1234.5634, mean_rewards: 266.4332, total_rewards: 3544.4990, mean_steps: 16.8200, mean_ecr: 0.0481 mean_entropies: 0.4722, took: 697.4969s
2022-10-10 22:07:25,700 [INFO] 	Process 6 - batch 94699: mean_policy_losses: -82.263, mean_net_lifetime: 4118.1432, mean_mc_travel_dist: 1109.1861, mean_rewards: 341.9101, total_rewards: 3084.2734, mean_steps: 11.0200, mean_ecr: 0.0548 mean_entropies: 0.1080, took: 58.0500s
2022-10-10 22:08:06,493 [INFO] 	Process 2 - batch 66999: mean_policy_losses: 3.420, mean_net_lifetime: 7535.8714, mean_mc_travel_dist: 2137.4609, mean_rewards: 268.5929, total_rewards: 5428.4181, mean_steps: 27.1800, mean_ecr: 0.0378 mean_entropies: 0.4579, took: 126.5729s
2022-10-10 22:08:23,401 [INFO] 	Process 6 - batch 94799: mean_policy_losses: -36.083, mean_net_lifetime: 4194.5593, mean_mc_travel_dist: 1126.0051, mean_rewards: 342.1917, total_rewards: 3134.2589, mean_steps: 11.2200, mean_ecr: 0.0548 mean_entropies: 0.1102, took: 57.7014s
2022-10-10 22:08:41,937 [INFO] 	Process 3 - batch 70699: mean_policy_losses: -32.098, mean_net_lifetime: 4736.0804, mean_mc_travel_dist: 1237.5076, mean_rewards: 266.8439, total_rewards: 3534.8895, mean_steps: 16.8200, mean_ecr: 0.0482 mean_entropies: 0.4748, took: 82.5998s
2022-10-10 22:08:41,947 [INFO] 	Process 1 - batch 59899: mean_policy_losses: 59.621, mean_net_lifetime: 6617.2052, mean_mc_travel_dist: 2129.3816, mean_rewards: 241.0821, total_rewards: 4512.3370, mean_steps: 26.6900, mean_ecr: 0.0379 mean_entropies: 0.9664, took: 123.2194s
2022-10-10 22:08:58,185 [INFO] 	Process 5 - batch 65799: mean_policy_losses: -62.193, mean_net_lifetime: 6891.7376, mean_mc_travel_dist: 2201.4984, mean_rewards: 275.3660, total_rewards: 4742.5685, mean_steps: 24.2800, mean_ecr: 0.0306 mean_entropies: 0.5771, took: 114.3098s
2022-10-10 22:09:03,067 [INFO] Process 4 - epoch 49: mean_policy_losses: 89.877, mean_net_lifetime: 4256.6441, mean_mc_travel_dist: 1372.4620, mean_entropies: 1.1632, m_net_lifetime_valid: 4693.7824, took: 2302.6914s, (137.9291 / 100 batches)

2022-10-10 22:09:20,301 [INFO] 	Process 6 - batch 94899: mean_policy_losses: -119.213, mean_net_lifetime: 4104.2853, mean_mc_travel_dist: 1108.0845, mean_rewards: 341.8969, total_rewards: 3072.5813, mean_steps: 10.9600, mean_ecr: 0.0547 mean_entropies: 0.1111, took: 56.8998s
2022-10-10 22:10:04,685 [INFO] 	Process 3 - batch 70799: mean_policy_losses: -29.827, mean_net_lifetime: 4783.0190, mean_mc_travel_dist: 1228.0340, mean_rewards: 273.3499, total_rewards: 3584.6260, mean_steps: 16.5300, mean_ecr: 0.0482 mean_entropies: 0.4744, took: 82.7475s
2022-10-10 22:10:13,222 [INFO] 	Process 2 - batch 67099: mean_policy_losses: -7.318, mean_net_lifetime: 7504.3372, mean_mc_travel_dist: 2087.7877, mean_rewards: 268.8308, total_rewards: 5457.9094, mean_steps: 27.0000, mean_ecr: 0.0380 mean_entropies: 0.4296, took: 126.7289s
2022-10-10 22:10:18,171 [INFO] 	Process 6 - batch 94999: mean_policy_losses: -138.583, mean_net_lifetime: 3907.4208, mean_mc_travel_dist: 1036.4409, mean_rewards: 341.9175, total_rewards: 2926.4918, mean_steps: 10.3800, mean_ecr: 0.0552 mean_entropies: 0.1145, took: 57.8706s
2022-10-10 22:10:34,176 [INFO] 	Process 4 - batch 73599: mean_policy_losses: 208.896, mean_net_lifetime: 4927.2220, mean_mc_travel_dist: 1359.7414, mean_rewards: 270.1243, total_rewards: 3597.8859, mean_steps: 17.6100, mean_ecr: 0.0473 mean_entropies: 0.7201, took: 723.4027s
2022-10-10 22:10:41,377 [INFO] 	Process 1 - batch 59999: mean_policy_losses: -16.600, mean_net_lifetime: 6387.9242, mean_mc_travel_dist: 2061.3899, mean_rewards: 245.3189, total_rewards: 4353.1013, mean_steps: 25.1800, mean_ecr: 0.0381 mean_entropies: 0.9551, took: 119.4312s
2022-10-10 22:11:05,804 [INFO] 	Process 5 - batch 65899: mean_policy_losses: -114.860, mean_net_lifetime: 7476.9991, mean_mc_travel_dist: 2369.8306, mean_rewards: 271.0458, total_rewards: 5148.3882, mean_steps: 26.8200, mean_ecr: 0.0304 mean_entropies: 0.6279, took: 127.6185s
2022-10-10 22:11:05,818 [INFO] Process 7 - epoch 45: mean_policy_losses: -348.468, mean_net_lifetime: 4091.0274, mean_mc_travel_dist: 1562.0399, mean_entropies: 1.6008, m_net_lifetime_valid: 4669.6640, took: 2155.6683s, (150.2685 / 100 batches)

2022-10-10 22:11:17,263 [INFO] 	Process 6 - batch 95099: mean_policy_losses: -70.841, mean_net_lifetime: 4090.1405, mean_mc_travel_dist: 1107.2654, mean_rewards: 339.5879, total_rewards: 3065.9983, mean_steps: 10.9900, mean_ecr: 0.0550 mean_entropies: 0.1099, took: 59.0917s
2022-10-10 22:11:31,990 [INFO] 	Process 3 - batch 70899: mean_policy_losses: -11.751, mean_net_lifetime: 4758.0688, mean_mc_travel_dist: 1236.9195, mean_rewards: 269.0256, total_rewards: 3555.7567, mean_steps: 16.7500, mean_ecr: 0.0480 mean_entropies: 0.4650, took: 87.3046s
2022-10-10 22:12:04,224 [INFO] 	Process 4 - batch 73699: mean_policy_losses: 105.012, mean_net_lifetime: 5237.6845, mean_mc_travel_dist: 1433.9353, mean_rewards: 282.1083, total_rewards: 3829.4194, mean_steps: 17.8300, mean_ecr: 0.0468 mean_entropies: 0.6266, took: 90.0484s
2022-10-10 22:12:16,394 [INFO] 	Process 6 - batch 95199: mean_policy_losses: -34.985, mean_net_lifetime: 4210.1812, mean_mc_travel_dist: 1139.1461, mean_rewards: 343.1641, total_rewards: 3152.0283, mean_steps: 11.2500, mean_ecr: 0.0547 mean_entropies: 0.1075, took: 59.1309s
2022-10-10 22:12:20,045 [INFO] 	Process 2 - batch 67199: mean_policy_losses: -8.247, mean_net_lifetime: 7418.8435, mean_mc_travel_dist: 2053.4252, mean_rewards: 268.9012, total_rewards: 5393.7697, mean_steps: 26.6500, mean_ecr: 0.0381 mean_entropies: 0.4252, took: 126.8224s
2022-10-10 22:12:33,851 [INFO] 	Process 7 - batch 67599: mean_policy_losses: -682.777, mean_net_lifetime: 4067.6475, mean_mc_travel_dist: 1275.9319, mean_rewards: 212.9734, total_rewards: 2830.7589, mean_steps: 18.2700, mean_ecr: 0.0416 mean_entropies: 1.2836, took: 777.4900s
2022-10-10 22:12:57,131 [INFO] 	Process 3 - batch 70999: mean_policy_losses: -16.309, mean_net_lifetime: 4827.9671, mean_mc_travel_dist: 1258.9101, mean_rewards: 273.7373, total_rewards: 3601.4071, mean_steps: 16.6900, mean_ecr: 0.0477 mean_entropies: 0.4919, took: 85.1413s
2022-10-10 22:13:02,070 [INFO] 	Process 5 - batch 65999: mean_policy_losses: -179.433, mean_net_lifetime: 6470.7729, mean_mc_travel_dist: 2090.5148, mean_rewards: 268.2367, total_rewards: 4425.5550, mean_steps: 23.2800, mean_ecr: 0.0305 mean_entropies: 0.6158, took: 116.2663s
2022-10-10 22:13:16,941 [INFO] 	Process 6 - batch 95299: mean_policy_losses: -83.728, mean_net_lifetime: 4097.0602, mean_mc_travel_dist: 1101.1419, mean_rewards: 340.7223, total_rewards: 3059.7262, mean_steps: 10.9800, mean_ecr: 0.0550 mean_entropies: 0.1129, took: 60.5461s
2022-10-10 22:13:47,637 [INFO] 	Process 4 - batch 73799: mean_policy_losses: 145.679, mean_net_lifetime: 5985.6394, mean_mc_travel_dist: 1697.2367, mean_rewards: 279.0336, total_rewards: 4315.8524, mean_steps: 21.1400, mean_ecr: 0.0451 mean_entropies: 0.6145, took: 103.4133s
2022-10-10 22:14:13,564 [INFO] 	Process 6 - batch 95399: mean_policy_losses: -44.554, mean_net_lifetime: 4187.0660, mean_mc_travel_dist: 1129.1873, mean_rewards: 344.4238, total_rewards: 3124.0472, mean_steps: 11.1500, mean_ecr: 0.0549 mean_entropies: 0.1022, took: 56.6242s
2022-10-10 22:14:16,480 [INFO] 	Process 7 - batch 67699: mean_policy_losses: -554.080, mean_net_lifetime: 4799.8201, mean_mc_travel_dist: 1494.9221, mean_rewards: 211.5458, total_rewards: 3340.8824, mean_steps: 21.9200, mean_ecr: 0.0410 mean_entropies: 1.3049, took: 102.6290s
2022-10-10 22:14:18,536 [INFO] 	Process 3 - batch 71099: mean_policy_losses: -34.060, mean_net_lifetime: 4643.2890, mean_mc_travel_dist: 1221.9956, mean_rewards: 265.3927, total_rewards: 3456.6027, mean_steps: 16.5900, mean_ecr: 0.0482 mean_entropies: 0.4809, took: 81.4057s
2022-10-10 22:14:19,980 [INFO] 	Process 2 - batch 67299: mean_policy_losses: -40.376, mean_net_lifetime: 7051.5202, mean_mc_travel_dist: 1990.7350, mean_rewards: 266.2982, total_rewards: 5094.5079, mean_steps: 25.5400, mean_ecr: 0.0384 mean_entropies: 0.4574, took: 119.9353s
2022-10-10 22:15:11,304 [INFO] 	Process 6 - batch 95499: mean_policy_losses: -33.421, mean_net_lifetime: 4068.7363, mean_mc_travel_dist: 1096.0623, mean_rewards: 341.1554, total_rewards: 3034.3844, mean_steps: 10.8800, mean_ecr: 0.0552 mean_entropies: 0.1185, took: 57.7393s
2022-10-10 22:15:29,939 [INFO] 	Process 4 - batch 73899: mean_policy_losses: 76.702, mean_net_lifetime: 6000.2103, mean_mc_travel_dist: 1669.5661, mean_rewards: 278.2277, total_rewards: 4354.9067, mean_steps: 21.1700, mean_ecr: 0.0447 mean_entropies: 0.6032, took: 102.3024s
2022-10-10 22:15:41,633 [INFO] 	Process 3 - batch 71199: mean_policy_losses: -9.831, mean_net_lifetime: 4765.6262, mean_mc_travel_dist: 1246.1858, mean_rewards: 268.2272, total_rewards: 3558.4748, mean_steps: 16.8400, mean_ecr: 0.0481 mean_entropies: 0.4790, took: 83.0963s
2022-10-10 22:15:56,250 [INFO] 	Process 7 - batch 67799: mean_policy_losses: -629.020, mean_net_lifetime: 4756.9737, mean_mc_travel_dist: 1530.9530, mean_rewards: 213.4959, total_rewards: 3268.1942, mean_steps: 21.5200, mean_ecr: 0.0410 mean_entropies: 1.2945, took: 99.7702s
2022-10-10 22:16:09,360 [INFO] 	Process 6 - batch 95599: mean_policy_losses: -51.080, mean_net_lifetime: 4177.3979, mean_mc_travel_dist: 1115.3273, mean_rewards: 342.8853, total_rewards: 3108.6994, mean_steps: 11.1500, mean_ecr: 0.0550 mean_entropies: 0.1057, took: 58.0561s
2022-10-10 22:16:22,625 [INFO] 	Process 2 - batch 67399: mean_policy_losses: -18.192, mean_net_lifetime: 7401.1678, mean_mc_travel_dist: 2099.8673, mean_rewards: 270.4968, total_rewards: 5336.1600, mean_steps: 26.4100, mean_ecr: 0.0380 mean_entropies: 0.4720, took: 122.6448s
2022-10-10 22:17:05,256 [INFO] 	Process 3 - batch 71299: mean_policy_losses: -20.739, mean_net_lifetime: 4686.1137, mean_mc_travel_dist: 1242.0849, mean_rewards: 264.3193, total_rewards: 3489.0207, mean_steps: 16.7800, mean_ecr: 0.0482 mean_entropies: 0.4760, took: 83.6237s
2022-10-10 22:17:05,950 [INFO] 	Process 6 - batch 95699: mean_policy_losses: -43.521, mean_net_lifetime: 4052.1936, mean_mc_travel_dist: 1093.3042, mean_rewards: 341.7238, total_rewards: 3033.3493, mean_steps: 10.8200, mean_ecr: 0.0550 mean_entropies: 0.1126, took: 56.5905s
2022-10-10 22:17:18,179 [INFO] 	Process 4 - batch 73999: mean_policy_losses: 91.028, mean_net_lifetime: 6274.8429, mean_mc_travel_dist: 1813.7326, mean_rewards: 275.6513, total_rewards: 4492.8530, mean_steps: 22.6300, mean_ecr: 0.0445 mean_entropies: 0.6204, took: 108.2394s
2022-10-10 22:17:25,225 [INFO] 	Process 7 - batch 67899: mean_policy_losses: -717.134, mean_net_lifetime: 4440.7128, mean_mc_travel_dist: 1446.8823, mean_rewards: 226.2521, total_rewards: 3031.1245, mean_steps: 18.9100, mean_ecr: 0.0413 mean_entropies: 1.3160, took: 88.9751s
2022-10-10 22:18:04,117 [INFO] 	Process 6 - batch 95799: mean_policy_losses: -52.079, mean_net_lifetime: 4131.8667, mean_mc_travel_dist: 1118.4800, mean_rewards: 341.5149, total_rewards: 3085.0821, mean_steps: 11.0600, mean_ecr: 0.0550 mean_entropies: 0.1114, took: 58.1653s
2022-10-10 22:18:23,430 [INFO] 	Process 2 - batch 67499: mean_policy_losses: -8.516, mean_net_lifetime: 7373.5965, mean_mc_travel_dist: 2062.3084, mean_rewards: 271.9525, total_rewards: 5341.2056, mean_steps: 26.2400, mean_ecr: 0.0382 mean_entropies: 0.4511, took: 120.8051s
2022-10-10 22:18:29,196 [INFO] 	Process 3 - batch 71399: mean_policy_losses: -23.132, mean_net_lifetime: 4696.4363, mean_mc_travel_dist: 1216.4267, mean_rewards: 263.4060, total_rewards: 3514.2730, mean_steps: 16.9100, mean_ecr: 0.0483 mean_entropies: 0.4430, took: 83.9397s
2022-10-10 22:18:57,081 [INFO] 	Process 7 - batch 67999: mean_policy_losses: -700.652, mean_net_lifetime: 4547.9523, mean_mc_travel_dist: 1463.5987, mean_rewards: 226.0620, total_rewards: 3123.7193, mean_steps: 19.8100, mean_ecr: 0.0412 mean_entropies: 1.2967, took: 91.8562s
2022-10-10 22:19:01,482 [INFO] 	Process 6 - batch 95899: mean_policy_losses: -38.271, mean_net_lifetime: 4302.7797, mean_mc_travel_dist: 1156.4928, mean_rewards: 343.8212, total_rewards: 3208.8811, mean_steps: 11.5000, mean_ecr: 0.0547 mean_entropies: 0.0976, took: 57.3658s
2022-10-10 22:19:03,517 [INFO] 	Process 4 - batch 74099: mean_policy_losses: 124.676, mean_net_lifetime: 6443.6209, mean_mc_travel_dist: 1827.6540, mean_rewards: 283.0032, total_rewards: 4646.7766, mean_steps: 22.4400, mean_ecr: 0.0436 mean_entropies: 0.5921, took: 105.3383s
2022-10-10 22:19:49,335 [INFO] 	Process 3 - batch 71499: mean_policy_losses: -27.611, mean_net_lifetime: 4773.6384, mean_mc_travel_dist: 1244.5527, mean_rewards: 268.5256, total_rewards: 3564.7413, mean_steps: 16.8500, mean_ecr: 0.0481 mean_entropies: 0.4668, took: 80.1394s
2022-10-10 22:19:58,944 [INFO] 	Process 6 - batch 95999: mean_policy_losses: -24.194, mean_net_lifetime: 4352.3178, mean_mc_travel_dist: 1176.4722, mean_rewards: 344.7789, total_rewards: 3250.1660, mean_steps: 11.6200, mean_ecr: 0.0546 mean_entropies: 0.0925, took: 57.4628s
2022-10-10 22:20:16,448 [INFO] 	Process 7 - batch 68099: mean_policy_losses: -817.309, mean_net_lifetime: 4115.8829, mean_mc_travel_dist: 1301.8247, mean_rewards: 224.9804, total_rewards: 2849.1228, mean_steps: 17.7700, mean_ecr: 0.0417 mean_entropies: 1.3059, took: 79.3675s
2022-10-10 22:20:54,018 [INFO] 	Process 4 - batch 74199: mean_policy_losses: 111.469, mean_net_lifetime: 6826.6245, mean_mc_travel_dist: 1998.6654, mean_rewards: 273.2596, total_rewards: 4847.9917, mean_steps: 25.0400, mean_ecr: 0.0429 mean_entropies: 0.5790, took: 110.5009s
2022-10-10 22:21:07,197 [INFO] 	Process 3 - batch 71599: mean_policy_losses: -8.713, mean_net_lifetime: 4802.1157, mean_mc_travel_dist: 1237.8036, mean_rewards: 265.8205, total_rewards: 3602.1442, mean_steps: 17.1200, mean_ecr: 0.0480 mean_entropies: 0.4556, took: 77.8614s
2022-10-10 22:21:23,925 [INFO] Process 1 - epoch 40: mean_policy_losses: 27.085, mean_net_lifetime: 5056.9569, mean_mc_travel_dist: 2031.1286, mean_entropies: 1.2108, m_net_lifetime_valid: 4640.1372, took: 2422.5820s, (170.1274 / 100 batches)

2022-10-10 22:21:57,690 [INFO] 	Process 7 - batch 68199: mean_policy_losses: -510.767, mean_net_lifetime: 5043.4029, mean_mc_travel_dist: 1555.7672, mean_rewards: 212.4590, total_rewards: 3522.9331, mean_steps: 23.4300, mean_ecr: 0.0407 mean_entropies: 1.3054, took: 101.2415s
2022-10-10 22:22:28,488 [INFO] 	Process 3 - batch 71699: mean_policy_losses: -0.898, mean_net_lifetime: 4801.9470, mean_mc_travel_dist: 1242.5971, mean_rewards: 270.7005, total_rewards: 3603.7657, mean_steps: 16.7800, mean_ecr: 0.0480 mean_entropies: 0.4533, took: 81.2915s
2022-10-10 22:22:41,737 [INFO] 	Process 4 - batch 74299: mean_policy_losses: 89.407, mean_net_lifetime: 6789.1326, mean_mc_travel_dist: 1940.5047, mean_rewards: 282.2436, total_rewards: 4876.8185, mean_steps: 23.9900, mean_ecr: 0.0430 mean_entropies: 0.5633, took: 107.7188s
2022-10-10 22:23:18,616 [INFO] 	Process 1 - batch 60099: mean_policy_losses: -37.350, mean_net_lifetime: 6040.1657, mean_mc_travel_dist: 1985.8011, mean_rewards: 230.2044, total_rewards: 4075.8502, mean_steps: 25.6500, mean_ecr: 0.0382 mean_entropies: 0.8973, took: 757.2389s
2022-10-10 22:23:27,253 [INFO] 	Process 7 - batch 68299: mean_policy_losses: -676.256, mean_net_lifetime: 4527.5029, mean_mc_travel_dist: 1401.5535, mean_rewards: 218.3376, total_rewards: 3167.6805, mean_steps: 19.7800, mean_ecr: 0.0411 mean_entropies: 1.3151, took: 89.5625s
2022-10-10 22:23:44,817 [INFO] Process 5 - epoch 44: mean_policy_losses: -204.485, mean_net_lifetime: 4901.1053, mean_mc_travel_dist: 1949.9271, mean_entropies: 1.2129, m_net_lifetime_valid: 4660.5171, took: 2481.2236s, (154.8975 / 100 batches)

2022-10-10 22:23:49,374 [INFO] 	Process 3 - batch 71799: mean_policy_losses: -1.520, mean_net_lifetime: 4746.1193, mean_mc_travel_dist: 1220.4306, mean_rewards: 273.4422, total_rewards: 3551.3514, mean_steps: 16.4100, mean_ecr: 0.0483 mean_entropies: 0.4495, took: 80.8860s
2022-10-10 22:24:45,973 [INFO] 	Process 4 - batch 74399: mean_policy_losses: 157.953, mean_net_lifetime: 7464.2950, mean_mc_travel_dist: 2196.1471, mean_rewards: 279.4291, total_rewards: 5298.7135, mean_steps: 26.9600, mean_ecr: 0.0416 mean_entropies: 0.5320, took: 124.2355s
2022-10-10 22:25:09,505 [INFO] 	Process 7 - batch 68399: mean_policy_losses: -488.258, mean_net_lifetime: 4917.7892, mean_mc_travel_dist: 1467.2514, mean_rewards: 216.1805, total_rewards: 3484.7173, mean_steps: 22.1200, mean_ecr: 0.0409 mean_entropies: 1.3687, took: 102.2519s
2022-10-10 22:25:12,464 [INFO] 	Process 3 - batch 71899: mean_policy_losses: 13.790, mean_net_lifetime: 4896.6326, mean_mc_travel_dist: 1273.5466, mean_rewards: 280.8544, total_rewards: 3658.5147, mean_steps: 16.4800, mean_ecr: 0.0478 mean_entropies: 0.4689, took: 83.0894s
2022-10-10 22:25:19,181 [INFO] 	Process 1 - batch 60199: mean_policy_losses: -9.572, mean_net_lifetime: 6066.2797, mean_mc_travel_dist: 1967.3005, mean_rewards: 230.2819, total_rewards: 4120.4317, mean_steps: 25.8300, mean_ecr: 0.0382 mean_entropies: 0.8734, took: 120.5644s
2022-10-10 22:25:53,415 [INFO] 	Process 5 - batch 66099: mean_policy_losses: -112.909, mean_net_lifetime: 7316.1984, mean_mc_travel_dist: 2380.8390, mean_rewards: 267.3467, total_rewards: 4980.8411, mean_steps: 27.0600, mean_ecr: 0.0300 mean_entropies: 0.5781, took: 771.3450s
2022-10-10 22:26:31,862 [INFO] 	Process 3 - batch 71999: mean_policy_losses: 23.080, mean_net_lifetime: 4709.6551, mean_mc_travel_dist: 1248.8881, mean_rewards: 280.5778, total_rewards: 3492.5165, mean_steps: 15.8300, mean_ecr: 0.0480 mean_entropies: 0.5097, took: 79.3982s
2022-10-10 22:26:44,592 [INFO] 	Process 7 - batch 68499: mean_policy_losses: -467.615, mean_net_lifetime: 4690.5306, mean_mc_travel_dist: 1420.2929, mean_rewards: 220.8373, total_rewards: 3310.3752, mean_steps: 20.5100, mean_ecr: 0.0411 mean_entropies: 1.3479, took: 95.0875s
2022-10-10 22:26:58,515 [INFO] 	Process 4 - batch 74499: mean_policy_losses: 230.377, mean_net_lifetime: 7870.5413, mean_mc_travel_dist: 2309.7039, mean_rewards: 278.2126, total_rewards: 5590.6079, mean_steps: 28.9100, mean_ecr: 0.0417 mean_entropies: 0.5726, took: 132.5431s
2022-10-10 22:27:11,428 [INFO] 	Process 1 - batch 60299: mean_policy_losses: 17.874, mean_net_lifetime: 6168.5274, mean_mc_travel_dist: 2054.8964, mean_rewards: 245.9291, total_rewards: 4148.1194, mean_steps: 24.2300, mean_ecr: 0.0381 mean_entropies: 0.9214, took: 112.2467s
2022-10-10 22:27:58,404 [INFO] 	Process 5 - batch 66199: mean_policy_losses: -118.840, mean_net_lifetime: 7302.5649, mean_mc_travel_dist: 2412.0038, mean_rewards: 273.6719, total_rewards: 4937.6355, mean_steps: 26.1800, mean_ecr: 0.0300 mean_entropies: 0.5884, took: 124.9882s
2022-10-10 22:28:25,895 [INFO] 	Process 7 - batch 68599: mean_policy_losses: -472.676, mean_net_lifetime: 4890.4462, mean_mc_travel_dist: 1475.8024, mean_rewards: 209.9306, total_rewards: 3446.8409, mean_steps: 22.5600, mean_ecr: 0.0411 mean_entropies: 1.3652, took: 101.3030s
2022-10-10 22:28:38,435 [INFO] Process 2 - epoch 45: mean_policy_losses: -0.873, mean_net_lifetime: 4694.9257, mean_mc_travel_dist: 1598.8879, mean_entropies: 0.9515, m_net_lifetime_valid: 4448.0895, took: 2431.1948s, (151.9360 / 100 batches)

2022-10-10 22:29:04,967 [INFO] 	Process 1 - batch 60399: mean_policy_losses: 4.408, mean_net_lifetime: 6147.6984, mean_mc_travel_dist: 2060.8536, mean_rewards: 237.7581, total_rewards: 4108.1033, mean_steps: 25.2900, mean_ecr: 0.0382 mean_entropies: 0.9322, took: 113.5398s
2022-10-10 22:29:31,038 [INFO] 	Process 4 - batch 74599: mean_policy_losses: 228.723, mean_net_lifetime: 8630.4438, mean_mc_travel_dist: 2574.0449, mean_rewards: 264.5634, total_rewards: 6092.4182, mean_steps: 34.1200, mean_ecr: 0.0412 mean_entropies: 0.6260, took: 152.5226s
2022-10-10 22:30:00,478 [INFO] Process 6 - epoch 64: mean_policy_losses: -212.769, mean_net_lifetime: 3036.6549, mean_mc_travel_dist: 967.5747, mean_entropies: 0.6080, m_net_lifetime_valid: 4169.2479, took: 1468.0832s, (106.9757 / 100 batches)

2022-10-10 22:30:18,451 [INFO] 	Process 7 - batch 68699: mean_policy_losses: -382.437, mean_net_lifetime: 5134.5869, mean_mc_travel_dist: 1562.6153, mean_rewards: 204.0906, total_rewards: 3608.1424, mean_steps: 24.3800, mean_ecr: 0.0408 mean_entropies: 1.3414, took: 112.5556s
2022-10-10 22:30:27,885 [INFO] 	Process 5 - batch 66299: mean_policy_losses: -80.731, mean_net_lifetime: 8897.6978, mean_mc_travel_dist: 3043.6675, mean_rewards: 283.6932, total_rewards: 5892.1705, mean_steps: 31.8500, mean_ecr: 0.0294 mean_entropies: 0.5730, took: 149.4819s
2022-10-10 22:30:43,673 [INFO] 	Process 2 - batch 67599: mean_policy_losses: -18.729, mean_net_lifetime: 7332.6036, mean_mc_travel_dist: 2133.6490, mean_rewards: 266.4893, total_rewards: 5231.6001, mean_steps: 26.6100, mean_ecr: 0.0379 mean_entropies: 0.4823, took: 740.2431s
2022-10-10 22:30:58,873 [INFO] 	Process 6 - batch 96099: mean_policy_losses: -88.089, mean_net_lifetime: 3999.1000, mean_mc_travel_dist: 1081.2475, mean_rewards: 338.4232, total_rewards: 2989.1700, mean_steps: 10.7400, mean_ecr: 0.0552 mean_entropies: 0.1109, took: 659.9277s
2022-10-10 22:31:09,712 [INFO] 	Process 1 - batch 60499: mean_policy_losses: -26.901, mean_net_lifetime: 6263.1225, mean_mc_travel_dist: 2078.6279, mean_rewards: 230.2119, total_rewards: 4219.2263, mean_steps: 26.6200, mean_ecr: 0.0379 mean_entropies: 0.8977, took: 124.7444s
2022-10-10 22:31:56,674 [INFO] 	Process 4 - batch 74699: mean_policy_losses: 251.376, mean_net_lifetime: 8324.4253, mean_mc_travel_dist: 2435.2243, mean_rewards: 275.6158, total_rewards: 5916.3804, mean_steps: 30.9600, mean_ecr: 0.0404 mean_entropies: 0.5525, took: 145.6354s
2022-10-10 22:32:01,378 [INFO] 	Process 6 - batch 96199: mean_policy_losses: -18.502, mean_net_lifetime: 4355.2821, mean_mc_travel_dist: 1181.1825, mean_rewards: 343.3938, total_rewards: 3253.4437, mean_steps: 11.6800, mean_ecr: 0.0546 mean_entropies: 0.0870, took: 62.5056s
2022-10-10 22:32:05,139 [INFO] 	Process 7 - batch 68799: mean_policy_losses: -516.937, mean_net_lifetime: 4846.4479, mean_mc_travel_dist: 1482.6153, mean_rewards: 212.2885, total_rewards: 3397.0099, mean_steps: 22.3600, mean_ecr: 0.0409 mean_entropies: 1.3291, took: 106.6883s
2022-10-10 22:32:43,864 [INFO] 	Process 2 - batch 67699: mean_policy_losses: -55.823, mean_net_lifetime: 6896.4481, mean_mc_travel_dist: 1921.8499, mean_rewards: 267.8519, total_rewards: 5001.0763, mean_steps: 24.8300, mean_ecr: 0.0387 mean_entropies: 0.3963, took: 120.1915s
2022-10-10 22:32:43,934 [INFO] 	Process 5 - batch 66399: mean_policy_losses: -144.700, mean_net_lifetime: 7579.8500, mean_mc_travel_dist: 2464.8383, mean_rewards: 265.8375, total_rewards: 5164.0912, mean_steps: 28.3400, mean_ecr: 0.0301 mean_entropies: 0.5486, took: 136.0488s
2022-10-10 22:33:02,484 [INFO] 	Process 6 - batch 96299: mean_policy_losses: -58.908, mean_net_lifetime: 4177.8837, mean_mc_travel_dist: 1126.7641, mean_rewards: 341.3050, total_rewards: 3127.2904, mean_steps: 11.2100, mean_ecr: 0.0547 mean_entropies: 0.0976, took: 61.1056s
2022-10-10 22:33:17,621 [INFO] 	Process 1 - batch 60599: mean_policy_losses: -34.797, mean_net_lifetime: 6256.0013, mean_mc_travel_dist: 2067.8370, mean_rewards: 234.4896, total_rewards: 4217.9485, mean_steps: 25.8900, mean_ecr: 0.0380 mean_entropies: 0.9172, took: 127.9094s
2022-10-10 22:33:52,165 [INFO] 	Process 7 - batch 68899: mean_policy_losses: -423.915, mean_net_lifetime: 5073.5662, mean_mc_travel_dist: 1556.1081, mean_rewards: 218.0230, total_rewards: 3560.6436, mean_steps: 22.3500, mean_ecr: 0.0409 mean_entropies: 1.3330, took: 107.0251s
2022-10-10 22:34:04,212 [INFO] 	Process 6 - batch 96399: mean_policy_losses: -55.252, mean_net_lifetime: 4128.5234, mean_mc_travel_dist: 1123.6996, mean_rewards: 343.0982, total_rewards: 3081.5503, mean_steps: 11.0300, mean_ecr: 0.0549 mean_entropies: 0.1037, took: 61.7288s
2022-10-10 22:34:05,426 [INFO] 	Process 4 - batch 74799: mean_policy_losses: 254.452, mean_net_lifetime: 7451.3440, mean_mc_travel_dist: 2123.2948, mean_rewards: 280.9546, total_rewards: 5356.4624, mean_steps: 26.6700, mean_ecr: 0.0424 mean_entropies: 0.6005, took: 128.7522s
2022-10-10 22:34:43,807 [INFO] 	Process 2 - batch 67799: mean_policy_losses: -54.941, mean_net_lifetime: 6963.3024, mean_mc_travel_dist: 1928.9925, mean_rewards: 269.8281, total_rewards: 5074.0101, mean_steps: 24.8600, mean_ecr: 0.0386 mean_entropies: 0.3827, took: 119.9423s
2022-10-10 22:34:47,626 [INFO] 	Process 5 - batch 66499: mean_policy_losses: -127.683, mean_net_lifetime: 7058.2643, mean_mc_travel_dist: 2280.3009, mean_rewards: 266.9135, total_rewards: 4819.8596, mean_steps: 25.8100, mean_ecr: 0.0304 mean_entropies: 0.5311, took: 123.6911s
2022-10-10 22:35:04,357 [INFO] 	Process 6 - batch 96499: mean_policy_losses: -80.749, mean_net_lifetime: 4139.7066, mean_mc_travel_dist: 1128.0666, mean_rewards: 341.2051, total_rewards: 3091.0320, mean_steps: 11.1000, mean_ecr: 0.0549 mean_entropies: 0.0981, took: 60.1446s
2022-10-10 22:35:28,788 [INFO] 	Process 1 - batch 60699: mean_policy_losses: 25.044, mean_net_lifetime: 6512.7985, mean_mc_travel_dist: 2085.6939, mean_rewards: 239.3822, total_rewards: 4458.8405, mean_steps: 26.3400, mean_ecr: 0.0381 mean_entropies: 0.9673, took: 131.1668s
2022-10-10 22:35:43,239 [INFO] 	Process 7 - batch 68999: mean_policy_losses: -517.857, mean_net_lifetime: 4927.6868, mean_mc_travel_dist: 1533.7010, mean_rewards: 207.1436, total_rewards: 3433.1280, mean_steps: 23.3100, mean_ecr: 0.0410 mean_entropies: 1.2957, took: 111.0745s
2022-10-10 22:36:01,238 [INFO] 	Process 6 - batch 96599: mean_policy_losses: -115.665, mean_net_lifetime: 4081.4734, mean_mc_travel_dist: 1104.8636, mean_rewards: 342.1124, total_rewards: 3051.1380, mean_steps: 10.9000, mean_ecr: 0.0550 mean_entropies: 0.0999, took: 56.8815s
2022-10-10 22:36:17,206 [INFO] 	Process 4 - batch 74899: mean_policy_losses: 166.508, mean_net_lifetime: 7250.8351, mean_mc_travel_dist: 2125.2284, mean_rewards: 267.3854, total_rewards: 5147.9450, mean_steps: 27.5700, mean_ecr: 0.0421 mean_entropies: 0.6153, took: 131.7808s
2022-10-10 22:36:40,826 [INFO] Process 3 - epoch 48: mean_policy_losses: 62.759, mean_net_lifetime: 4285.2139, mean_mc_travel_dist: 1356.4118, mean_entropies: 0.9093, m_net_lifetime_valid: 4604.7604, took: 1845.9951s, (143.1295 / 100 batches)

2022-10-10 22:36:46,359 [INFO] 	Process 2 - batch 67899: mean_policy_losses: -58.753, mean_net_lifetime: 7171.0893, mean_mc_travel_dist: 2042.3833, mean_rewards: 270.7191, total_rewards: 5153.2786, mean_steps: 25.6600, mean_ecr: 0.0382 mean_entropies: 0.3947, took: 122.5520s
2022-10-10 22:36:59,354 [INFO] 	Process 6 - batch 96699: mean_policy_losses: -71.762, mean_net_lifetime: 4051.5153, mean_mc_travel_dist: 1102.5067, mean_rewards: 338.7788, total_rewards: 3019.5482, mean_steps: 10.8600, mean_ecr: 0.0551 mean_entropies: 0.1279, took: 58.1164s
2022-10-10 22:37:03,870 [INFO] 	Process 5 - batch 66599: mean_policy_losses: -79.492, mean_net_lifetime: 8061.4996, mean_mc_travel_dist: 2552.6585, mean_rewards: 280.4023, total_rewards: 5556.9416, mean_steps: 28.2500, mean_ecr: 0.0303 mean_entropies: 0.5724, took: 136.2455s
2022-10-10 22:37:33,117 [INFO] 	Process 1 - batch 60799: mean_policy_losses: -42.445, mean_net_lifetime: 6329.8996, mean_mc_travel_dist: 2047.7678, mean_rewards: 233.0956, total_rewards: 4313.7759, mean_steps: 26.4800, mean_ecr: 0.0381 mean_entropies: 0.9496, took: 124.3291s
2022-10-10 22:37:54,800 [INFO] 	Process 6 - batch 96799: mean_policy_losses: -147.996, mean_net_lifetime: 3801.6762, mean_mc_travel_dist: 1023.4383, mean_rewards: 337.4177, total_rewards: 2833.9299, mean_steps: 10.1600, mean_ecr: 0.0557 mean_entropies: 0.1468, took: 55.4459s
2022-10-10 22:38:07,533 [INFO] 	Process 3 - batch 72099: mean_policy_losses: -38.208, mean_net_lifetime: 4650.3368, mean_mc_travel_dist: 1230.8473, mean_rewards: 265.6985, total_rewards: 3456.4772, mean_steps: 16.5900, mean_ecr: 0.0481 mean_entropies: 0.5046, took: 695.6714s
2022-10-10 22:38:42,273 [INFO] 	Process 4 - batch 74999: mean_policy_losses: 204.171, mean_net_lifetime: 8209.5959, mean_mc_travel_dist: 2432.5442, mean_rewards: 270.3058, total_rewards: 5804.2213, mean_steps: 30.8300, mean_ecr: 0.0400 mean_entropies: 0.5902, took: 145.0652s
2022-10-10 22:38:46,658 [INFO] 	Process 2 - batch 67999: mean_policy_losses: -17.371, mean_net_lifetime: 7039.0675, mean_mc_travel_dist: 1965.8505, mean_rewards: 269.8240, total_rewards: 5103.4874, mean_steps: 25.1500, mean_ecr: 0.0385 mean_entropies: 0.4219, took: 120.2992s
2022-10-10 22:38:53,902 [INFO] 	Process 6 - batch 96899: mean_policy_losses: -92.877, mean_net_lifetime: 4124.1167, mean_mc_travel_dist: 1116.8434, mean_rewards: 342.1419, total_rewards: 3081.1300, mean_steps: 11.0500, mean_ecr: 0.0549 mean_entropies: 0.1140, took: 59.1017s
2022-10-10 22:39:06,137 [INFO] 	Process 5 - batch 66699: mean_policy_losses: -135.627, mean_net_lifetime: 6941.4633, mean_mc_travel_dist: 2172.2303, mean_rewards: 270.7160, total_rewards: 4816.9177, mean_steps: 24.8800, mean_ecr: 0.0306 mean_entropies: 0.5847, took: 122.2661s
2022-10-10 22:39:29,740 [INFO] 	Process 3 - batch 72199: mean_policy_losses: -16.507, mean_net_lifetime: 4788.7785, mean_mc_travel_dist: 1258.2339, mean_rewards: 271.5987, total_rewards: 3561.6365, mean_steps: 16.6700, mean_ecr: 0.0479 mean_entropies: 0.4821, took: 82.2066s
2022-10-10 22:39:32,267 [INFO] 	Process 1 - batch 60899: mean_policy_losses: 39.654, mean_net_lifetime: 6447.5136, mean_mc_travel_dist: 2088.3368, mean_rewards: 251.0438, total_rewards: 4386.0326, mean_steps: 24.7900, mean_ecr: 0.0380 mean_entropies: 0.9722, took: 119.1499s
2022-10-10 22:39:50,574 [INFO] 	Process 6 - batch 96999: mean_policy_losses: -111.863, mean_net_lifetime: 4079.9597, mean_mc_travel_dist: 1091.2631, mean_rewards: 343.3290, total_rewards: 3039.8616, mean_steps: 10.8600, mean_ecr: 0.0550 mean_entropies: 0.1229, took: 56.6721s
2022-10-10 22:40:48,611 [INFO] 	Process 6 - batch 97099: mean_policy_losses: -33.397, mean_net_lifetime: 4224.7493, mean_mc_travel_dist: 1135.1149, mean_rewards: 341.5390, total_rewards: 3157.2362, mean_steps: 11.3300, mean_ecr: 0.0548 mean_entropies: 0.1148, took: 58.0374s
2022-10-10 22:40:50,469 [INFO] 	Process 2 - batch 68099: mean_policy_losses: -42.692, mean_net_lifetime: 7336.0532, mean_mc_travel_dist: 2067.0515, mean_rewards: 269.5051, total_rewards: 5294.9615, mean_steps: 26.3300, mean_ecr: 0.0381 mean_entropies: 0.4270, took: 123.8112s
2022-10-10 22:40:52,086 [INFO] 	Process 3 - batch 72299: mean_policy_losses: -21.391, mean_net_lifetime: 4845.6071, mean_mc_travel_dist: 1276.7313, mean_rewards: 274.5929, total_rewards: 3598.6712, mean_steps: 16.7000, mean_ecr: 0.0479 mean_entropies: 0.4663, took: 82.3466s
2022-10-10 22:41:14,693 [INFO] 	Process 5 - batch 66799: mean_policy_losses: -73.740, mean_net_lifetime: 7908.7004, mean_mc_travel_dist: 2524.7079, mean_rewards: 282.1713, total_rewards: 5442.1743, mean_steps: 27.4800, mean_ecr: 0.0299 mean_entropies: 0.5851, took: 128.5555s
2022-10-10 22:41:31,930 [INFO] 	Process 1 - batch 60999: mean_policy_losses: 8.872, mean_net_lifetime: 6406.5259, mean_mc_travel_dist: 2097.5735, mean_rewards: 250.0035, total_rewards: 4340.9717, mean_steps: 24.8200, mean_ecr: 0.0379 mean_entropies: 0.9551, took: 119.6632s
2022-10-10 22:41:43,427 [INFO] 	Process 6 - batch 97199: mean_policy_losses: -117.787, mean_net_lifetime: 3948.2447, mean_mc_travel_dist: 1066.4022, mean_rewards: 340.6002, total_rewards: 2959.2860, mean_steps: 10.5400, mean_ecr: 0.0549 mean_entropies: 0.1321, took: 54.8155s
2022-10-10 22:42:11,718 [INFO] 	Process 3 - batch 72399: mean_policy_losses: -14.510, mean_net_lifetime: 4739.4340, mean_mc_travel_dist: 1257.7883, mean_rewards: 274.4552, total_rewards: 3523.2203, mean_steps: 16.3300, mean_ecr: 0.0481 mean_entropies: 0.4957, took: 79.6320s
2022-10-10 22:42:40,729 [INFO] 	Process 6 - batch 97299: mean_policy_losses: -69.465, mean_net_lifetime: 4133.2769, mean_mc_travel_dist: 1110.8891, mean_rewards: 341.7294, total_rewards: 3098.4227, mean_steps: 11.0400, mean_ecr: 0.0548 mean_entropies: 0.1137, took: 57.3017s
2022-10-10 22:42:52,200 [INFO] 	Process 2 - batch 68199: mean_policy_losses: 3.654, mean_net_lifetime: 7405.9785, mean_mc_travel_dist: 2103.3927, mean_rewards: 273.9733, total_rewards: 5341.6492, mean_steps: 26.1400, mean_ecr: 0.0380 mean_entropies: 0.4749, took: 121.7308s
2022-10-10 22:43:12,513 [INFO] 	Process 5 - batch 66899: mean_policy_losses: -74.336, mean_net_lifetime: 7070.0866, mean_mc_travel_dist: 2245.5601, mean_rewards: 278.3515, total_rewards: 4865.7826, mean_steps: 24.7500, mean_ecr: 0.0304 mean_entropies: 0.5571, took: 117.8214s
2022-10-10 22:43:27,522 [INFO] 	Process 1 - batch 61099: mean_policy_losses: 4.141, mean_net_lifetime: 6333.8557, mean_mc_travel_dist: 2054.4303, mean_rewards: 248.5278, total_rewards: 4311.0410, mean_steps: 24.6800, mean_ecr: 0.0381 mean_entropies: 0.9674, took: 115.5912s
2022-10-10 22:43:33,310 [INFO] 	Process 3 - batch 72499: mean_policy_losses: -17.352, mean_net_lifetime: 4846.9683, mean_mc_travel_dist: 1282.5648, mean_rewards: 276.4566, total_rewards: 3605.3522, mean_steps: 16.5900, mean_ecr: 0.0476 mean_entropies: 0.5032, took: 81.5917s
2022-10-10 22:43:39,057 [INFO] 	Process 6 - batch 97399: mean_policy_losses: -60.901, mean_net_lifetime: 4112.5450, mean_mc_travel_dist: 1121.6062, mean_rewards: 339.9402, total_rewards: 3067.8485, mean_steps: 11.0600, mean_ecr: 0.0551 mean_entropies: 0.1352, took: 58.3282s
2022-10-10 22:44:36,103 [INFO] 	Process 6 - batch 97499: mean_policy_losses: -92.505, mean_net_lifetime: 4100.0873, mean_mc_travel_dist: 1125.4926, mean_rewards: 341.1672, total_rewards: 3056.4698, mean_steps: 10.9900, mean_ecr: 0.0549 mean_entropies: 0.1078, took: 57.0463s
2022-10-10 22:44:43,573 [INFO] 	Process 2 - batch 68299: mean_policy_losses: -34.961, mean_net_lifetime: 6822.3374, mean_mc_travel_dist: 1887.7048, mean_rewards: 274.1509, total_rewards: 4960.8424, mean_steps: 23.9400, mean_ecr: 0.0386 mean_entropies: 0.4244, took: 111.3735s
2022-10-10 22:44:51,789 [INFO] 	Process 3 - batch 72599: mean_policy_losses: -15.822, mean_net_lifetime: 4660.4434, mean_mc_travel_dist: 1234.5136, mean_rewards: 275.2728, total_rewards: 3464.4476, mean_steps: 15.9800, mean_ecr: 0.0482 mean_entropies: 0.5175, took: 78.4793s
2022-10-10 22:45:22,830 [INFO] 	Process 1 - batch 61199: mean_policy_losses: 8.473, mean_net_lifetime: 6377.6599, mean_mc_travel_dist: 2048.5179, mean_rewards: 242.8881, total_rewards: 4360.5731, mean_steps: 25.4000, mean_ecr: 0.0381 mean_entropies: 0.9471, took: 115.3082s
2022-10-10 22:45:34,977 [INFO] 	Process 5 - batch 66999: mean_policy_losses: -23.085, mean_net_lifetime: 8680.0920, mean_mc_travel_dist: 2774.0706, mean_rewards: 277.2810, total_rewards: 5939.6433, mean_steps: 31.1600, mean_ecr: 0.0301 mean_entropies: 0.5950, took: 142.4637s
2022-10-10 22:46:09,716 [INFO] 	Process 3 - batch 72699: mean_policy_losses: -16.560, mean_net_lifetime: 4761.9810, mean_mc_travel_dist: 1272.6745, mean_rewards: 278.1575, total_rewards: 3528.0389, mean_steps: 16.1700, mean_ecr: 0.0478 mean_entropies: 0.5035, took: 77.9262s
2022-10-10 22:46:37,608 [INFO] 	Process 2 - batch 68399: mean_policy_losses: -32.270, mean_net_lifetime: 7229.3684, mean_mc_travel_dist: 2017.8749, mean_rewards: 275.1584, total_rewards: 5240.6816, mean_steps: 25.3700, mean_ecr: 0.0383 mean_entropies: 0.4502, took: 114.0358s
2022-10-10 22:47:08,404 [INFO] 	Process 1 - batch 61299: mean_policy_losses: -32.363, mean_net_lifetime: 6116.7909, mean_mc_travel_dist: 2024.4595, mean_rewards: 256.9129, total_rewards: 4115.2653, mean_steps: 22.9100, mean_ecr: 0.0382 mean_entropies: 0.9328, took: 105.5744s
2022-10-10 22:47:28,703 [INFO] 	Process 3 - batch 72799: mean_policy_losses: -24.097, mean_net_lifetime: 4773.3383, mean_mc_travel_dist: 1264.9095, mean_rewards: 281.0253, total_rewards: 3555.0455, mean_steps: 16.0400, mean_ecr: 0.0480 mean_entropies: 0.5040, took: 78.9874s
2022-10-10 22:47:37,677 [INFO] 	Process 5 - batch 67099: mean_policy_losses: -18.361, mean_net_lifetime: 7875.8007, mean_mc_travel_dist: 2496.1000, mean_rewards: 279.9993, total_rewards: 5420.9646, mean_steps: 27.5200, mean_ecr: 0.0303 mean_entropies: 0.5845, took: 122.6992s
2022-10-10 22:47:39,628 [INFO] Process 7 - epoch 46: mean_policy_losses: -353.295, mean_net_lifetime: 4104.6731, mean_mc_travel_dist: 1559.9228, mean_entropies: 1.5947, m_net_lifetime_valid: 4815.8540, took: 2193.8075s, (150.1424 / 100 batches)

2022-10-10 22:48:30,785 [INFO] 	Process 2 - batch 68499: mean_policy_losses: -37.270, mean_net_lifetime: 7098.2013, mean_mc_travel_dist: 1983.5093, mean_rewards: 273.6485, total_rewards: 5148.7889, mean_steps: 24.9600, mean_ecr: 0.0384 mean_entropies: 0.4432, took: 113.1758s
2022-10-10 22:48:49,767 [INFO] 	Process 3 - batch 72899: mean_policy_losses: -8.099, mean_net_lifetime: 4865.6133, mean_mc_travel_dist: 1279.4421, mean_rewards: 279.1665, total_rewards: 3624.6545, mean_steps: 16.4700, mean_ecr: 0.0479 mean_entropies: 0.5056, took: 81.0639s
2022-10-10 22:48:55,235 [INFO] Process 4 - epoch 50: mean_policy_losses: 91.342, mean_net_lifetime: 4309.7598, mean_mc_travel_dist: 1384.9291, mean_entropies: 1.1520, m_net_lifetime_valid: 4774.5488, took: 2392.1660s, (138.3853 / 100 batches)

2022-10-10 22:49:04,181 [INFO] 	Process 1 - batch 61399: mean_policy_losses: 13.003, mean_net_lifetime: 6368.5492, mean_mc_travel_dist: 2060.6200, mean_rewards: 248.3567, total_rewards: 4330.1736, mean_steps: 24.7500, mean_ecr: 0.0380 mean_entropies: 0.9587, took: 115.7767s
2022-10-10 22:49:08,676 [INFO] 	Process 7 - batch 69099: mean_policy_losses: -455.283, mean_net_lifetime: 4342.5570, mean_mc_travel_dist: 1310.5333, mean_rewards: 219.1697, total_rewards: 3072.2068, mean_steps: 19.0300, mean_ecr: 0.0417 mean_entropies: 1.3459, took: 805.4375s
2022-10-10 22:50:00,362 [INFO] 	Process 5 - batch 67199: mean_policy_losses: -1.741, mean_net_lifetime: 8528.7050, mean_mc_travel_dist: 2772.2578, mean_rewards: 282.8689, total_rewards: 5806.1415, mean_steps: 29.7700, mean_ecr: 0.0300 mean_entropies: 0.6298, took: 142.6856s
2022-10-10 22:50:13,269 [INFO] 	Process 3 - batch 72999: mean_policy_losses: -35.739, mean_net_lifetime: 4850.0689, mean_mc_travel_dist: 1290.5010, mean_rewards: 281.7913, total_rewards: 3595.5113, mean_steps: 16.2300, mean_ecr: 0.0473 mean_entropies: 0.5058, took: 83.5017s
2022-10-10 22:50:29,126 [INFO] 	Process 4 - batch 75099: mean_policy_losses: 285.019, mean_net_lifetime: 5185.4851, mean_mc_travel_dist: 1462.5560, mean_rewards: 268.0074, total_rewards: 3754.4163, mean_steps: 18.7700, mean_ecr: 0.0468 mean_entropies: 0.6705, took: 706.8538s
2022-10-10 22:50:29,604 [INFO] 	Process 2 - batch 68599: mean_policy_losses: -41.124, mean_net_lifetime: 7111.2417, mean_mc_travel_dist: 1977.1927, mean_rewards: 274.9261, total_rewards: 5172.2219, mean_steps: 24.8900, mean_ecr: 0.0384 mean_entropies: 0.4906, took: 118.8191s
2022-10-10 22:50:51,205 [INFO] 	Process 7 - batch 69199: mean_policy_losses: -515.765, mean_net_lifetime: 4514.3476, mean_mc_travel_dist: 1358.6360, mean_rewards: 202.6964, total_rewards: 3188.4917, mean_steps: 21.3300, mean_ecr: 0.0414 mean_entropies: 1.3231, took: 102.5291s
2022-10-10 22:51:11,469 [INFO] 	Process 1 - batch 61499: mean_policy_losses: -34.268, mean_net_lifetime: 6334.4047, mean_mc_travel_dist: 2044.0978, mean_rewards: 231.8243, total_rewards: 4312.1426, mean_steps: 26.6400, mean_ecr: 0.0381 mean_entropies: 0.9703, took: 127.2882s
2022-10-10 22:51:35,966 [INFO] 	Process 3 - batch 73099: mean_policy_losses: 1.844, mean_net_lifetime: 4849.1420, mean_mc_travel_dist: 1252.0357, mean_rewards: 278.1327, total_rewards: 3635.0303, mean_steps: 16.4800, mean_ecr: 0.0478 mean_entropies: 0.4548, took: 82.6977s
2022-10-10 22:51:57,634 [INFO] 	Process 4 - batch 75199: mean_policy_losses: 115.522, mean_net_lifetime: 5087.9744, mean_mc_travel_dist: 1409.1415, mean_rewards: 277.0442, total_rewards: 3710.1571, mean_steps: 17.8200, mean_ecr: 0.0470 mean_entropies: 0.6407, took: 88.5079s
2022-10-10 22:52:12,084 [INFO] 	Process 5 - batch 67299: mean_policy_losses: -78.992, mean_net_lifetime: 7884.0759, mean_mc_travel_dist: 2548.7460, mean_rewards: 281.1671, total_rewards: 5395.6534, mean_steps: 27.4500, mean_ecr: 0.0301 mean_entropies: 0.6111, took: 131.7212s
2022-10-10 22:52:22,188 [INFO] 	Process 7 - batch 69299: mean_policy_losses: -592.564, mean_net_lifetime: 4360.8039, mean_mc_travel_dist: 1319.7647, mean_rewards: 213.6715, total_rewards: 3077.2104, mean_steps: 19.3500, mean_ecr: 0.0417 mean_entropies: 1.3101, took: 90.9828s
2022-10-10 22:52:27,253 [INFO] 	Process 2 - batch 68699: mean_policy_losses: -42.463, mean_net_lifetime: 6985.7808, mean_mc_travel_dist: 1921.0623, mean_rewards: 270.9387, total_rewards: 5111.0601, mean_steps: 24.8800, mean_ecr: 0.0387 mean_entropies: 0.4391, took: 117.6490s
2022-10-10 22:52:54,747 [INFO] 	Process 3 - batch 73199: mean_policy_losses: -14.436, mean_net_lifetime: 4770.8419, mean_mc_travel_dist: 1234.6290, mean_rewards: 275.5301, total_rewards: 3572.9032, mean_steps: 16.3600, mean_ecr: 0.0481 mean_entropies: 0.4553, took: 78.7809s
2022-10-10 22:53:32,786 [INFO] 	Process 4 - batch 75299: mean_policy_losses: 130.384, mean_net_lifetime: 5696.6897, mean_mc_travel_dist: 1585.4788, mean_rewards: 284.6151, total_rewards: 4134.3625, mean_steps: 19.6800, mean_ecr: 0.0453 mean_entropies: 0.6127, took: 95.1510s
2022-10-10 22:53:58,815 [INFO] 	Process 7 - batch 69399: mean_policy_losses: -547.764, mean_net_lifetime: 4732.1440, mean_mc_travel_dist: 1457.5915, mean_rewards: 217.9502, total_rewards: 3308.4424, mean_steps: 20.8300, mean_ecr: 0.0412 mean_entropies: 1.2980, took: 96.6264s
2022-10-10 22:54:16,374 [INFO] 	Process 3 - batch 73299: mean_policy_losses: -17.053, mean_net_lifetime: 4780.9599, mean_mc_travel_dist: 1230.1255, mean_rewards: 278.1081, total_rewards: 3576.0079, mean_steps: 16.2300, mean_ecr: 0.0482 mean_entropies: 0.4403, took: 81.6263s
2022-10-10 22:54:20,866 [INFO] 	Process 2 - batch 68799: mean_policy_losses: -70.338, mean_net_lifetime: 6877.6112, mean_mc_travel_dist: 1876.0021, mean_rewards: 270.2377, total_rewards: 5027.8407, mean_steps: 24.5500, mean_ecr: 0.0388 mean_entropies: 0.4340, took: 113.6129s
2022-10-10 22:54:34,186 [INFO] Process 6 - epoch 65: mean_policy_losses: -210.743, mean_net_lifetime: 3052.9711, mean_mc_travel_dist: 969.7550, mean_entropies: 0.6004, m_net_lifetime_valid: 4289.1232, took: 1473.7061s, (106.8451 / 100 batches)

2022-10-10 22:54:47,300 [INFO] 	Process 5 - batch 67399: mean_policy_losses: -59.100, mean_net_lifetime: 9063.8846, mean_mc_travel_dist: 3005.7645, mean_rewards: 274.9686, total_rewards: 6099.3354, mean_steps: 33.0100, mean_ecr: 0.0296 mean_entropies: 0.6134, took: 155.2162s
2022-10-10 22:55:34,034 [INFO] 	Process 4 - batch 75399: mean_policy_losses: 164.056, mean_net_lifetime: 7095.5553, mean_mc_travel_dist: 2066.2166, mean_rewards: 281.8224, total_rewards: 5055.8058, mean_steps: 25.5500, mean_ecr: 0.0425 mean_entropies: 0.5369, took: 121.2494s
2022-10-10 22:55:34,416 [INFO] 	Process 6 - batch 97599: mean_policy_losses: -44.702, mean_net_lifetime: 4152.2432, mean_mc_travel_dist: 1128.0471, mean_rewards: 339.7979, total_rewards: 3113.1429, mean_steps: 11.1700, mean_ecr: 0.0547 mean_entropies: 0.1117, took: 658.3125s
2022-10-10 22:55:37,686 [INFO] 	Process 3 - batch 73399: mean_policy_losses: -22.986, mean_net_lifetime: 4748.7107, mean_mc_travel_dist: 1218.8806, mean_rewards: 278.7500, total_rewards: 3562.6435, mean_steps: 16.0800, mean_ecr: 0.0483 mean_entropies: 0.4470, took: 81.3127s
2022-10-10 22:55:41,170 [INFO] 	Process 7 - batch 69499: mean_policy_losses: -654.360, mean_net_lifetime: 4707.1138, mean_mc_travel_dist: 1432.0736, mean_rewards: 212.0239, total_rewards: 3298.5815, mean_steps: 21.6600, mean_ecr: 0.0411 mean_entropies: 1.2556, took: 102.3558s
2022-10-10 22:56:19,858 [INFO] 	Process 2 - batch 68899: mean_policy_losses: -54.279, mean_net_lifetime: 6954.2851, mean_mc_travel_dist: 1918.9091, mean_rewards: 270.7434, total_rewards: 5060.9078, mean_steps: 24.7400, mean_ecr: 0.0387 mean_entropies: 0.4297, took: 118.9927s
2022-10-10 22:56:33,253 [INFO] 	Process 6 - batch 97699: mean_policy_losses: -122.193, mean_net_lifetime: 3990.0582, mean_mc_travel_dist: 1077.9763, mean_rewards: 340.2147, total_rewards: 2982.7523, mean_steps: 10.6700, mean_ecr: 0.0553 mean_entropies: 0.1301, took: 58.8373s
2022-10-10 22:57:03,562 [INFO] 	Process 3 - batch 73499: mean_policy_losses: -14.394, mean_net_lifetime: 4768.3347, mean_mc_travel_dist: 1213.7933, mean_rewards: 275.4928, total_rewards: 3595.1160, mean_steps: 16.3600, mean_ecr: 0.0483 mean_entropies: 0.4517, took: 85.8762s
2022-10-10 22:57:28,091 [INFO] 	Process 5 - batch 67499: mean_policy_losses: -76.679, mean_net_lifetime: 9030.3955, mean_mc_travel_dist: 2953.3767, mean_rewards: 271.1145, total_rewards: 6112.3220, mean_steps: 33.6500, mean_ecr: 0.0298 mean_entropies: 0.5827, took: 160.7910s
2022-10-10 22:57:30,932 [INFO] 	Process 6 - batch 97799: mean_policy_losses: -31.789, mean_net_lifetime: 4211.8223, mean_mc_travel_dist: 1138.6152, mean_rewards: 341.2200, total_rewards: 3149.3581, mean_steps: 11.3000, mean_ecr: 0.0548 mean_entropies: 0.1218, took: 57.6786s
2022-10-10 22:57:32,169 [INFO] 	Process 4 - batch 75499: mean_policy_losses: 147.403, mean_net_lifetime: 6828.7133, mean_mc_travel_dist: 1928.9196, mean_rewards: 279.2208, total_rewards: 4929.8243, mean_steps: 24.4700, mean_ecr: 0.0429 mean_entropies: 0.5778, took: 118.1345s
2022-10-10 22:57:38,693 [INFO] 	Process 7 - batch 69599: mean_policy_losses: -383.086, mean_net_lifetime: 5294.8917, mean_mc_travel_dist: 1623.9813, mean_rewards: 203.8472, total_rewards: 3701.4999, mean_steps: 25.1700, mean_ecr: 0.0406 mean_entropies: 1.2457, took: 117.5225s
2022-10-10 22:58:18,528 [INFO] 	Process 2 - batch 68999: mean_policy_losses: -40.952, mean_net_lifetime: 7205.8598, mean_mc_travel_dist: 1978.7144, mean_rewards: 271.2661, total_rewards: 5257.3161, mean_steps: 25.5900, mean_ecr: 0.0385 mean_entropies: 0.4279, took: 118.6691s
2022-10-10 22:58:25,314 [INFO] 	Process 6 - batch 97899: mean_policy_losses: -96.496, mean_net_lifetime: 4185.8703, mean_mc_travel_dist: 1128.3712, mean_rewards: 341.5917, total_rewards: 3120.1835, mean_steps: 11.2100, mean_ecr: 0.0549 mean_entropies: 0.1215, took: 54.3822s
2022-10-10 22:59:13,649 [INFO] 	Process 7 - batch 69699: mean_policy_losses: -575.439, mean_net_lifetime: 4734.6825, mean_mc_travel_dist: 1435.2019, mean_rewards: 214.7392, total_rewards: 3333.6047, mean_steps: 21.5700, mean_ecr: 0.0412 mean_entropies: 1.2955, took: 94.9561s
2022-10-10 22:59:22,158 [INFO] 	Process 6 - batch 97999: mean_policy_losses: -73.355, mean_net_lifetime: 4178.8998, mean_mc_travel_dist: 1121.2210, mean_rewards: 340.5195, total_rewards: 3116.0184, mean_steps: 11.2000, mean_ecr: 0.0549 mean_entropies: 0.1158, took: 56.8440s
2022-10-10 22:59:24,549 [INFO] 	Process 4 - batch 75599: mean_policy_losses: 137.713, mean_net_lifetime: 6956.9631, mean_mc_travel_dist: 1994.1231, mean_rewards: 277.3021, total_rewards: 4981.9337, mean_steps: 25.5900, mean_ecr: 0.0426 mean_entropies: 0.5705, took: 112.3812s
2022-10-10 23:00:19,659 [INFO] 	Process 6 - batch 98099: mean_policy_losses: -74.110, mean_net_lifetime: 4234.8464, mean_mc_travel_dist: 1146.9797, mean_rewards: 344.0784, total_rewards: 3150.6122, mean_steps: 11.3100, mean_ecr: 0.0549 mean_entropies: 0.1174, took: 57.5011s
2022-10-10 23:00:45,827 [INFO] Process 1 - epoch 41: mean_policy_losses: 26.268, mean_net_lifetime: 5086.7381, mean_mc_travel_dist: 2031.6162, mean_entropies: 1.2042, m_net_lifetime_valid: 4365.4207, took: 2361.9004s, (169.9297 / 100 batches)

2022-10-10 23:00:57,384 [INFO] 	Process 7 - batch 69799: mean_policy_losses: -464.576, mean_net_lifetime: 5176.8276, mean_mc_travel_dist: 1566.7646, mean_rewards: 207.1640, total_rewards: 3642.8942, mean_steps: 24.0300, mean_ecr: 0.0407 mean_entropies: 1.2578, took: 103.7343s
2022-10-10 23:01:16,157 [INFO] 	Process 6 - batch 98199: mean_policy_losses: -102.154, mean_net_lifetime: 4159.3259, mean_mc_travel_dist: 1116.0863, mean_rewards: 344.6537, total_rewards: 3093.9553, mean_steps: 11.0600, mean_ecr: 0.0551 mean_entropies: 0.1280, took: 56.4979s
2022-10-10 23:01:27,484 [INFO] 	Process 4 - batch 75699: mean_policy_losses: 163.909, mean_net_lifetime: 7633.3021, mean_mc_travel_dist: 2182.7601, mean_rewards: 272.8480, total_rewards: 5477.6821, mean_steps: 28.2900, mean_ecr: 0.0409 mean_entropies: 0.5379, took: 122.9346s
2022-10-10 23:02:13,272 [INFO] 	Process 6 - batch 98299: mean_policy_losses: -32.642, mean_net_lifetime: 4296.9895, mean_mc_travel_dist: 1155.7239, mean_rewards: 342.7530, total_rewards: 3200.7637, mean_steps: 11.5000, mean_ecr: 0.0549 mean_entropies: 0.1233, took: 57.1152s
2022-10-10 23:02:41,332 [INFO] 	Process 7 - batch 69899: mean_policy_losses: -546.008, mean_net_lifetime: 4907.4958, mean_mc_travel_dist: 1508.4082, mean_rewards: 204.6510, total_rewards: 3428.7180, mean_steps: 23.2400, mean_ecr: 0.0408 mean_entropies: 1.2648, took: 103.9481s
2022-10-10 23:02:44,549 [INFO] 	Process 1 - batch 61599: mean_policy_losses: -2.990, mean_net_lifetime: 6298.6162, mean_mc_travel_dist: 2027.4474, mean_rewards: 235.2803, total_rewards: 4293.8794, mean_steps: 26.2000, mean_ecr: 0.0381 mean_entropies: 0.8706, took: 693.0805s
2022-10-10 23:03:11,111 [INFO] 	Process 6 - batch 98399: mean_policy_losses: -41.690, mean_net_lifetime: 4212.2622, mean_mc_travel_dist: 1150.9402, mean_rewards: 341.2504, total_rewards: 3142.7508, mean_steps: 11.3100, mean_ecr: 0.0549 mean_entropies: 0.1263, took: 57.8391s
2022-10-10 23:03:13,985 [INFO] 	Process 4 - batch 75799: mean_policy_losses: 94.523, mean_net_lifetime: 6565.4670, mean_mc_travel_dist: 1830.6671, mean_rewards: 285.3271, total_rewards: 4764.0651, mean_steps: 22.8400, mean_ecr: 0.0435 mean_entropies: 0.5546, took: 106.5007s
2022-10-10 23:04:07,818 [INFO] 	Process 6 - batch 98499: mean_policy_losses: -75.136, mean_net_lifetime: 4126.7539, mean_mc_travel_dist: 1123.2278, mean_rewards: 342.3728, total_rewards: 3082.2235, mean_steps: 11.0300, mean_ecr: 0.0550 mean_entropies: 0.1114, took: 56.7072s
2022-10-10 23:04:19,371 [INFO] 	Process 7 - batch 69999: mean_policy_losses: -588.327, mean_net_lifetime: 4759.6895, mean_mc_travel_dist: 1508.8422, mean_rewards: 212.8432, total_rewards: 3294.9452, mean_steps: 21.4200, mean_ecr: 0.0410 mean_entropies: 1.2693, took: 98.0399s
2022-10-10 23:04:38,768 [INFO] 	Process 1 - batch 61699: mean_policy_losses: -9.051, mean_net_lifetime: 6250.2457, mean_mc_travel_dist: 2038.6118, mean_rewards: 247.2459, total_rewards: 4235.5765, mean_steps: 24.4300, mean_ecr: 0.0381 mean_entropies: 0.9262, took: 114.2177s
2022-10-10 23:05:02,580 [INFO] 	Process 6 - batch 98599: mean_policy_losses: -58.380, mean_net_lifetime: 4059.4305, mean_mc_travel_dist: 1110.3825, mean_rewards: 339.3824, total_rewards: 3015.6783, mean_steps: 10.9200, mean_ecr: 0.0551 mean_entropies: 0.1375, took: 54.7618s
2022-10-10 23:05:07,900 [INFO] 	Process 4 - batch 75899: mean_policy_losses: 136.270, mean_net_lifetime: 7007.1677, mean_mc_travel_dist: 1989.1097, mean_rewards: 281.1524, total_rewards: 5043.9227, mean_steps: 24.8500, mean_ecr: 0.0425 mean_entropies: 0.5471, took: 113.9155s
2022-10-10 23:05:51,802 [INFO] 	Process 7 - batch 70099: mean_policy_losses: -567.066, mean_net_lifetime: 4612.1658, mean_mc_travel_dist: 1433.4048, mean_rewards: 215.8601, total_rewards: 3209.1915, mean_steps: 20.5000, mean_ecr: 0.0410 mean_entropies: 1.2596, took: 92.4302s
2022-10-10 23:05:55,501 [INFO] 	Process 6 - batch 98699: mean_policy_losses: -76.197, mean_net_lifetime: 3831.0031, mean_mc_travel_dist: 1062.1488, mean_rewards: 335.5849, total_rewards: 2813.4699, mean_steps: 10.4100, mean_ecr: 0.0555 mean_entropies: 0.1463, took: 52.9206s
2022-10-10 23:06:29,677 [INFO] 	Process 1 - batch 61799: mean_policy_losses: 34.551, mean_net_lifetime: 6190.0453, mean_mc_travel_dist: 2051.0666, mean_rewards: 247.2878, total_rewards: 4165.7718, mean_steps: 24.2500, mean_ecr: 0.0380 mean_entropies: 0.9106, took: 110.9094s
2022-10-10 23:06:47,398 [INFO] Process 3 - epoch 49: mean_policy_losses: 61.103, mean_net_lifetime: 4295.3123, mean_mc_travel_dist: 1354.3050, mean_entropies: 0.9006, m_net_lifetime_valid: 4359.2145, took: 1806.5696s, (142.7012 / 100 batches)

2022-10-10 23:06:53,316 [INFO] 	Process 6 - batch 98799: mean_policy_losses: -87.777, mean_net_lifetime: 4039.5418, mean_mc_travel_dist: 1086.6524, mean_rewards: 335.9745, total_rewards: 3011.5891, mean_steps: 10.9200, mean_ecr: 0.0550 mean_entropies: 0.1386, took: 57.8159s
2022-10-10 23:07:16,419 [INFO] Process 5 - epoch 45: mean_policy_losses: -201.728, mean_net_lifetime: 4968.7834, mean_mc_travel_dist: 1963.8208, mean_entropies: 1.1988, m_net_lifetime_valid: 4512.2484, took: 2611.5989s, (155.4042 / 100 batches)

2022-10-10 23:07:37,552 [INFO] 	Process 7 - batch 70199: mean_policy_losses: -468.177, mean_net_lifetime: 4936.7089, mean_mc_travel_dist: 1540.3553, mean_rewards: 206.4186, total_rewards: 3436.0210, mean_steps: 23.2500, mean_ecr: 0.0409 mean_entropies: 1.2677, took: 105.7502s
2022-10-10 23:07:45,020 [INFO] 	Process 4 - batch 75999: mean_policy_losses: 168.662, mean_net_lifetime: 8877.5298, mean_mc_travel_dist: 2700.7825, mean_rewards: 270.5437, total_rewards: 6202.9378, mean_steps: 35.4700, mean_ecr: 0.0406 mean_entropies: 0.5326, took: 157.1194s
2022-10-10 23:07:51,721 [INFO] 	Process 6 - batch 98899: mean_policy_losses: -59.853, mean_net_lifetime: 4149.2290, mean_mc_travel_dist: 1110.7234, mean_rewards: 342.3032, total_rewards: 3092.1625, mean_steps: 11.0900, mean_ecr: 0.0550 mean_entropies: 0.1223, took: 58.4047s
2022-10-10 23:08:14,296 [INFO] 	Process 3 - batch 73599: mean_policy_losses: -7.706, mean_net_lifetime: 4739.0969, mean_mc_travel_dist: 1215.6559, mean_rewards: 262.9306, total_rewards: 3550.0339, mean_steps: 17.0900, mean_ecr: 0.0481 mean_entropies: 0.5007, took: 670.7330s
2022-10-10 23:08:28,445 [INFO] 	Process 1 - batch 61899: mean_policy_losses: -25.723, mean_net_lifetime: 6211.4464, mean_mc_travel_dist: 2043.8457, mean_rewards: 246.4260, total_rewards: 4189.7880, mean_steps: 24.4200, mean_ecr: 0.0382 mean_entropies: 0.9182, took: 118.7681s
2022-10-10 23:08:50,690 [INFO] 	Process 6 - batch 98999: mean_policy_losses: -36.829, mean_net_lifetime: 4252.1781, mean_mc_travel_dist: 1134.3697, mean_rewards: 343.6708, total_rewards: 3163.7387, mean_steps: 11.3300, mean_ecr: 0.0549 mean_entropies: 0.1009, took: 58.9676s
2022-10-10 23:09:08,046 [INFO] Process 2 - epoch 46: mean_policy_losses: -1.721, mean_net_lifetime: 4747.1073, mean_mc_travel_dist: 1607.2079, mean_entropies: 0.9402, m_net_lifetime_valid: 4702.6405, took: 2429.6086s, (152.1039 / 100 batches)

2022-10-10 23:09:22,018 [INFO] 	Process 7 - batch 70299: mean_policy_losses: -475.337, mean_net_lifetime: 4880.1340, mean_mc_travel_dist: 1509.9688, mean_rewards: 216.0291, total_rewards: 3400.4842, mean_steps: 21.9100, mean_ecr: 0.0410 mean_entropies: 1.2103, took: 104.4662s
2022-10-10 23:09:25,843 [INFO] 	Process 5 - batch 67599: mean_policy_losses: -181.842, mean_net_lifetime: 7216.5714, mean_mc_travel_dist: 2317.6858, mean_rewards: 273.7208, total_rewards: 4944.3505, mean_steps: 26.3100, mean_ecr: 0.0304 mean_entropies: 0.5354, took: 717.7515s
2022-10-10 23:09:40,037 [INFO] 	Process 3 - batch 73699: mean_policy_losses: -35.643, mean_net_lifetime: 4565.8875, mean_mc_travel_dist: 1173.7823, mean_rewards: 255.8165, total_rewards: 3420.9452, mean_steps: 16.9300, mean_ecr: 0.0485 mean_entropies: 0.4800, took: 85.7412s
2022-10-10 23:09:53,705 [INFO] 	Process 4 - batch 76099: mean_policy_losses: 143.915, mean_net_lifetime: 7251.6431, mean_mc_travel_dist: 2101.6545, mean_rewards: 279.0920, total_rewards: 5179.1470, mean_steps: 26.7500, mean_ecr: 0.0435 mean_entropies: 0.5518, took: 128.6854s
2022-10-10 23:10:25,870 [INFO] 	Process 1 - batch 61999: mean_policy_losses: 11.365, mean_net_lifetime: 6282.3090, mean_mc_travel_dist: 2098.4794, mean_rewards: 250.6823, total_rewards: 4210.7463, mean_steps: 24.3200, mean_ecr: 0.0379 mean_entropies: 0.9294, took: 117.4246s
2022-10-10 23:10:47,539 [INFO] 	Process 7 - batch 70399: mean_policy_losses: -679.139, mean_net_lifetime: 4030.7171, mean_mc_travel_dist: 1279.4470, mean_rewards: 218.8685, total_rewards: 2781.6847, mean_steps: 17.5600, mean_ecr: 0.0416 mean_entropies: 1.2110, took: 85.5215s
2022-10-10 23:11:04,194 [INFO] 	Process 2 - batch 69099: mean_policy_losses: -40.618, mean_net_lifetime: 6684.0967, mean_mc_travel_dist: 1818.8848, mean_rewards: 269.7197, total_rewards: 4892.6673, mean_steps: 23.8800, mean_ecr: 0.0390 mean_entropies: 0.4253, took: 765.6663s
2022-10-10 23:11:05,784 [INFO] 	Process 3 - batch 73799: mean_policy_losses: -0.670, mean_net_lifetime: 4730.9920, mean_mc_travel_dist: 1198.5790, mean_rewards: 274.5741, total_rewards: 3560.9384, mean_steps: 16.2700, mean_ecr: 0.0484 mean_entropies: 0.4813, took: 85.7468s
2022-10-10 23:11:36,982 [INFO] 	Process 4 - batch 76199: mean_policy_losses: 114.092, mean_net_lifetime: 5923.8464, mean_mc_travel_dist: 1616.0514, mean_rewards: 283.6373, total_rewards: 4337.1646, mean_steps: 20.3700, mean_ecr: 0.0452 mean_entropies: 0.5736, took: 103.2771s
2022-10-10 23:11:40,279 [INFO] 	Process 5 - batch 67699: mean_policy_losses: -106.044, mean_net_lifetime: 7803.0834, mean_mc_travel_dist: 2516.7597, mean_rewards: 274.1429, total_rewards: 5336.3113, mean_steps: 28.0600, mean_ecr: 0.0301 mean_entropies: 0.6408, took: 134.4375s
2022-10-10 23:12:24,384 [INFO] 	Process 1 - batch 62099: mean_policy_losses: -30.712, mean_net_lifetime: 6329.0453, mean_mc_travel_dist: 2065.5584, mean_rewards: 247.0259, total_rewards: 4290.6298, mean_steps: 24.8300, mean_ecr: 0.0380 mean_entropies: 0.9907, took: 118.5148s
2022-10-10 23:12:31,893 [INFO] 	Process 3 - batch 73899: mean_policy_losses: -21.216, mean_net_lifetime: 4777.9383, mean_mc_travel_dist: 1201.7613, mean_rewards: 270.0209, total_rewards: 3613.6662, mean_steps: 16.7700, mean_ecr: 0.0483 mean_entropies: 0.4584, took: 86.1090s
2022-10-10 23:12:41,417 [INFO] 	Process 7 - batch 70499: mean_policy_losses: -425.464, mean_net_lifetime: 5165.3358, mean_mc_travel_dist: 1588.3094, mean_rewards: 210.0005, total_rewards: 3614.1436, mean_steps: 23.8700, mean_ecr: 0.0406 mean_entropies: 1.2624, took: 113.8763s
2022-10-10 23:13:08,295 [INFO] 	Process 2 - batch 69199: mean_policy_losses: -26.973, mean_net_lifetime: 7267.4645, mean_mc_travel_dist: 2038.3827, mean_rewards: 269.9868, total_rewards: 5263.8103, mean_steps: 26.0700, mean_ecr: 0.0383 mean_entropies: 0.4735, took: 124.1015s
2022-10-10 23:13:32,785 [INFO] 	Process 4 - batch 76299: mean_policy_losses: 100.667, mean_net_lifetime: 6685.2824, mean_mc_travel_dist: 1879.4940, mean_rewards: 278.0416, total_rewards: 4825.1351, mean_steps: 23.9600, mean_ecr: 0.0435 mean_entropies: 0.5706, took: 115.8033s
2022-10-10 23:13:53,701 [INFO] 	Process 3 - batch 73999: mean_policy_losses: -30.484, mean_net_lifetime: 4795.6658, mean_mc_travel_dist: 1218.0306, mean_rewards: 273.7558, total_rewards: 3608.7974, mean_steps: 16.5700, mean_ecr: 0.0482 mean_entropies: 0.4448, took: 81.8080s
2022-10-10 23:14:24,902 [INFO] 	Process 1 - batch 62199: mean_policy_losses: -21.344, mean_net_lifetime: 6512.5117, mean_mc_travel_dist: 2110.2884, mean_rewards: 246.8178, total_rewards: 4424.1836, mean_steps: 25.6500, mean_ecr: 0.0378 mean_entropies: 0.9825, took: 120.5175s
2022-10-10 23:14:34,310 [INFO] 	Process 5 - batch 67799: mean_policy_losses: -62.611, mean_net_lifetime: 9957.7034, mean_mc_travel_dist: 3226.7018, mean_rewards: 268.7481, total_rewards: 6775.0442, mean_steps: 37.0400, mean_ecr: 0.0295 mean_entropies: 0.6709, took: 174.0302s
2022-10-10 23:15:06,773 [INFO] 	Process 2 - batch 69299: mean_policy_losses: -82.550, mean_net_lifetime: 7032.1092, mean_mc_travel_dist: 1936.7298, mean_rewards: 268.1862, total_rewards: 5128.2085, mean_steps: 25.3400, mean_ecr: 0.0385 mean_entropies: 0.4676, took: 118.4776s
2022-10-10 23:15:14,803 [INFO] 	Process 3 - batch 74099: mean_policy_losses: -38.965, mean_net_lifetime: 4739.4504, mean_mc_travel_dist: 1204.4482, mean_rewards: 273.1289, total_rewards: 3574.9852, mean_steps: 16.3900, mean_ecr: 0.0484 mean_entropies: 0.4406, took: 81.1021s
2022-10-10 23:15:16,759 [INFO] 	Process 4 - batch 76399: mean_policy_losses: 76.909, mean_net_lifetime: 6287.5440, mean_mc_travel_dist: 1717.4663, mean_rewards: 285.2609, total_rewards: 4597.5409, mean_steps: 21.6700, mean_ecr: 0.0445 mean_entropies: 0.5924, took: 103.9741s
2022-10-10 23:16:20,177 [INFO] 	Process 1 - batch 62299: mean_policy_losses: -47.809, mean_net_lifetime: 6305.1574, mean_mc_travel_dist: 2060.0981, mean_rewards: 251.8593, total_rewards: 4277.3588, mean_steps: 24.2400, mean_ecr: 0.0381 mean_entropies: 0.9658, took: 115.2743s
2022-10-10 23:16:38,003 [INFO] 	Process 3 - batch 74199: mean_policy_losses: -14.398, mean_net_lifetime: 4765.3416, mean_mc_travel_dist: 1196.4592, mean_rewards: 276.3613, total_rewards: 3601.6011, mean_steps: 16.2900, mean_ecr: 0.0483 mean_entropies: 0.4609, took: 83.2006s
2022-10-10 23:16:58,091 [INFO] 	Process 4 - batch 76499: mean_policy_losses: 83.416, mean_net_lifetime: 6173.0343, mean_mc_travel_dist: 1683.3099, mean_rewards: 286.5901, total_rewards: 4516.9613, mean_steps: 21.2000, mean_ecr: 0.0450 mean_entropies: 0.5629, took: 101.3318s
2022-10-10 23:17:03,985 [INFO] 	Process 5 - batch 67899: mean_policy_losses: -195.373, mean_net_lifetime: 8848.1856, mean_mc_travel_dist: 2873.1012, mean_rewards: 272.6779, total_rewards: 6036.5250, mean_steps: 32.5100, mean_ecr: 0.0298 mean_entropies: 0.6749, took: 149.6740s
2022-10-10 23:17:05,689 [INFO] 	Process 2 - batch 69399: mean_policy_losses: -46.580, mean_net_lifetime: 7166.5595, mean_mc_travel_dist: 1960.7643, mean_rewards: 270.1260, total_rewards: 5235.7496, mean_steps: 25.6500, mean_ecr: 0.0384 mean_entropies: 0.4933, took: 118.9161s
2022-10-10 23:17:57,725 [INFO] 	Process 3 - batch 74299: mean_policy_losses: -11.672, mean_net_lifetime: 4722.7210, mean_mc_travel_dist: 1214.1248, mean_rewards: 276.4626, total_rewards: 3552.6159, mean_steps: 16.1400, mean_ecr: 0.0479 mean_entropies: 0.4777, took: 79.7209s
2022-10-10 23:18:14,749 [INFO] 	Process 1 - batch 62399: mean_policy_losses: -25.325, mean_net_lifetime: 6388.7890, mean_mc_travel_dist: 2074.3468, mean_rewards: 248.0091, total_rewards: 4345.6603, mean_steps: 24.8800, mean_ecr: 0.0382 mean_entropies: 0.9786, took: 114.5721s
2022-10-10 23:19:05,395 [INFO] 	Process 2 - batch 69499: mean_policy_losses: -14.613, mean_net_lifetime: 7489.1534, mean_mc_travel_dist: 2067.8022, mean_rewards: 268.6070, total_rewards: 5456.0229, mean_steps: 26.9600, mean_ecr: 0.0381 mean_entropies: 0.5252, took: 119.7056s
2022-10-10 23:19:12,055 [INFO] Process 6 - epoch 66: mean_policy_losses: -208.573, mean_net_lifetime: 3069.4215, mean_mc_travel_dist: 972.0228, mean_entropies: 0.5932, m_net_lifetime_valid: 4197.5448, took: 1477.8662s, (106.6957 / 100 batches)

2022-10-10 23:19:17,879 [INFO] 	Process 3 - batch 74399: mean_policy_losses: -1.888, mean_net_lifetime: 4795.5398, mean_mc_travel_dist: 1202.0773, mean_rewards: 278.2971, total_rewards: 3640.7238, mean_steps: 16.2700, mean_ecr: 0.0483 mean_entropies: 0.4549, took: 80.1548s
2022-10-10 23:19:35,320 [INFO] 	Process 5 - batch 67999: mean_policy_losses: -95.632, mean_net_lifetime: 9433.3329, mean_mc_travel_dist: 3087.8443, mean_rewards: 277.4331, total_rewards: 6389.0056, mean_steps: 33.8800, mean_ecr: 0.0296 mean_entropies: 0.6729, took: 151.3363s
2022-10-10 23:20:05,782 [INFO] 	Process 6 - batch 99099: mean_policy_losses: -139.078, mean_net_lifetime: 3795.3244, mean_mc_travel_dist: 1023.8697, mean_rewards: 336.0091, total_rewards: 2838.4528, mean_steps: 10.2000, mean_ecr: 0.0554 mean_entropies: 0.1489, took: 675.0925s
2022-10-10 23:20:07,822 [INFO] 	Process 1 - batch 62499: mean_policy_losses: -13.504, mean_net_lifetime: 6408.8899, mean_mc_travel_dist: 2110.1387, mean_rewards: 253.0125, total_rewards: 4330.3361, mean_steps: 24.5600, mean_ecr: 0.0380 mean_entropies: 0.9521, took: 113.0738s
2022-10-10 23:20:37,761 [INFO] 	Process 3 - batch 74499: mean_policy_losses: -10.765, mean_net_lifetime: 4733.0833, mean_mc_travel_dist: 1176.9269, mean_rewards: 272.9471, total_rewards: 3580.8267, mean_steps: 16.4100, mean_ecr: 0.0483 mean_entropies: 0.4670, took: 79.8816s
2022-10-10 23:21:02,738 [INFO] 	Process 6 - batch 99199: mean_policy_losses: -100.612, mean_net_lifetime: 3980.8894, mean_mc_travel_dist: 1064.7145, mean_rewards: 340.2134, total_rewards: 2982.2778, mean_steps: 10.6400, mean_ecr: 0.0550 mean_entropies: 0.1293, took: 56.9572s
2022-10-10 23:21:02,789 [INFO] 	Process 2 - batch 69599: mean_policy_losses: -30.692, mean_net_lifetime: 7159.7509, mean_mc_travel_dist: 1942.8880, mean_rewards: 271.3731, total_rewards: 5244.4803, mean_steps: 25.4500, mean_ecr: 0.0386 mean_entropies: 0.4627, took: 117.3949s
2022-10-10 23:21:58,820 [INFO] 	Process 3 - batch 74599: mean_policy_losses: -21.411, mean_net_lifetime: 4713.8887, mean_mc_travel_dist: 1156.1091, mean_rewards: 265.1989, total_rewards: 3598.3057, mean_steps: 16.8300, mean_ecr: 0.0484 mean_entropies: 0.4620, took: 81.0589s
2022-10-10 23:21:59,129 [INFO] 	Process 6 - batch 99299: mean_policy_losses: -85.640, mean_net_lifetime: 4031.5412, mean_mc_travel_dist: 1091.4819, mean_rewards: 336.6496, total_rewards: 3021.4200, mean_steps: 10.8600, mean_ecr: 0.0552 mean_entropies: 0.1252, took: 56.3902s
2022-10-10 23:22:04,737 [INFO] 	Process 1 - batch 62599: mean_policy_losses: -33.660, mean_net_lifetime: 6273.7734, mean_mc_travel_dist: 2056.5172, mean_rewards: 245.7017, total_rewards: 4244.1408, mean_steps: 24.7500, mean_ecr: 0.0382 mean_entropies: 0.9575, took: 116.9147s
2022-10-10 23:22:17,344 [INFO] 	Process 5 - batch 68099: mean_policy_losses: -39.727, mean_net_lifetime: 9381.9938, mean_mc_travel_dist: 3039.5343, mean_rewards: 273.3822, total_rewards: 6385.5788, mean_steps: 34.7200, mean_ecr: 0.0299 mean_entropies: 0.6258, took: 162.0242s
2022-10-10 23:22:55,351 [INFO] 	Process 6 - batch 99399: mean_policy_losses: -96.919, mean_net_lifetime: 4076.4073, mean_mc_travel_dist: 1105.6928, mean_rewards: 339.4351, total_rewards: 3042.1748, mean_steps: 10.9500, mean_ecr: 0.0550 mean_entropies: 0.1239, took: 56.2225s
2022-10-10 23:22:58,634 [INFO] 	Process 2 - batch 69699: mean_policy_losses: -56.512, mean_net_lifetime: 7048.9476, mean_mc_travel_dist: 1938.1844, mean_rewards: 271.3797, total_rewards: 5149.0020, mean_steps: 25.0900, mean_ecr: 0.0385 mean_entropies: 0.4385, took: 115.8442s
2022-10-10 23:23:21,823 [INFO] 	Process 3 - batch 74699: mean_policy_losses: -36.712, mean_net_lifetime: 4639.3776, mean_mc_travel_dist: 1165.0455, mean_rewards: 265.5194, total_rewards: 3505.3514, mean_steps: 16.5400, mean_ecr: 0.0485 mean_entropies: 0.4854, took: 83.0037s
2022-10-10 23:23:53,430 [INFO] 	Process 6 - batch 99499: mean_policy_losses: -78.927, mean_net_lifetime: 4185.9939, mean_mc_travel_dist: 1135.4332, mean_rewards: 343.5930, total_rewards: 3115.6721, mean_steps: 11.1600, mean_ecr: 0.0549 mean_entropies: 0.1185, took: 58.0788s
2022-10-10 23:24:02,895 [INFO] 	Process 1 - batch 62699: mean_policy_losses: -4.275, mean_net_lifetime: 6409.8648, mean_mc_travel_dist: 2108.9462, mean_rewards: 251.3597, total_rewards: 4335.5805, mean_steps: 24.6700, mean_ecr: 0.0380 mean_entropies: 0.9525, took: 118.1584s
2022-10-10 23:24:06,848 [INFO] Process 7 - epoch 47: mean_policy_losses: -357.038, mean_net_lifetime: 4118.2696, mean_mc_travel_dist: 1557.7589, mean_entropies: 1.5879, m_net_lifetime_valid: 4440.1774, took: 2187.2167s, (150.0943 / 100 batches)

2022-10-10 23:24:38,751 [INFO] 	Process 5 - batch 68199: mean_policy_losses: -29.767, mean_net_lifetime: 8481.8000, mean_mc_travel_dist: 2764.0043, mean_rewards: 278.1311, total_rewards: 5777.3791, mean_steps: 30.2900, mean_ecr: 0.0301 mean_entropies: 0.6026, took: 141.4061s
2022-10-10 23:24:46,882 [INFO] 	Process 3 - batch 74799: mean_policy_losses: -28.563, mean_net_lifetime: 4732.1776, mean_mc_travel_dist: 1198.8037, mean_rewards: 266.5667, total_rewards: 3572.2343, mean_steps: 16.8200, mean_ecr: 0.0481 mean_entropies: 0.5106, took: 85.0583s
2022-10-10 23:24:53,235 [INFO] 	Process 6 - batch 99599: mean_policy_losses: -54.232, mean_net_lifetime: 4143.4998, mean_mc_travel_dist: 1117.4247, mean_rewards: 340.5720, total_rewards: 3082.1308, mean_steps: 11.1100, mean_ecr: 0.0551 mean_entropies: 0.1322, took: 59.8058s
2022-10-10 23:25:02,817 [INFO] 	Process 2 - batch 69799: mean_policy_losses: -0.234, mean_net_lifetime: 7354.4369, mean_mc_travel_dist: 2046.9752, mean_rewards: 271.0493, total_rewards: 5339.7812, mean_steps: 26.2500, mean_ecr: 0.0381 mean_entropies: 0.4567, took: 124.1829s
2022-10-10 23:25:53,025 [INFO] 	Process 6 - batch 99699: mean_policy_losses: -96.642, mean_net_lifetime: 4089.7023, mean_mc_travel_dist: 1101.9367, mean_rewards: 340.0429, total_rewards: 3047.4134, mean_steps: 10.9500, mean_ecr: 0.0551 mean_entropies: 0.1407, took: 59.7891s
2022-10-10 23:26:01,203 [INFO] 	Process 7 - batch 70599: mean_policy_losses: -316.780, mean_net_lifetime: 5086.0385, mean_mc_travel_dist: 1603.7935, mean_rewards: 205.5358, total_rewards: 3515.1166, mean_steps: 24.1400, mean_ecr: 0.0410 mean_entropies: 1.2336, took: 799.7870s
2022-10-10 23:26:03,730 [INFO] 	Process 1 - batch 62799: mean_policy_losses: -6.319, mean_net_lifetime: 6463.8766, mean_mc_travel_dist: 2069.7646, mean_rewards: 248.5753, total_rewards: 4422.6814, mean_steps: 25.1300, mean_ecr: 0.0382 mean_entropies: 0.9635, took: 120.8355s
2022-10-10 23:26:14,102 [INFO] 	Process 3 - batch 74899: mean_policy_losses: -20.597, mean_net_lifetime: 4866.3048, mean_mc_travel_dist: 1238.8280, mean_rewards: 274.1904, total_rewards: 3650.8274, mean_steps: 16.8200, mean_ecr: 0.0479 mean_entropies: 0.5252, took: 87.2195s
2022-10-10 23:26:47,554 [INFO] 	Process 6 - batch 99799: mean_policy_losses: -150.059, mean_net_lifetime: 3781.8208, mean_mc_travel_dist: 1023.2957, mean_rewards: 339.4084, total_rewards: 2804.8466, mean_steps: 10.0800, mean_ecr: 0.0557 mean_entropies: 0.1567, took: 54.5296s
2022-10-10 23:27:15,381 [INFO] 	Process 2 - batch 69899: mean_policy_losses: 22.189, mean_net_lifetime: 7693.4965, mean_mc_travel_dist: 2178.7275, mean_rewards: 269.9597, total_rewards: 5550.2079, mean_steps: 27.6000, mean_ecr: 0.0377 mean_entropies: 0.4651, took: 132.5644s
2022-10-10 23:27:23,291 [INFO] 	Process 5 - batch 68299: mean_policy_losses: 24.946, mean_net_lifetime: 9652.1379, mean_mc_travel_dist: 3158.5371, mean_rewards: 279.8311, total_rewards: 6545.6570, mean_steps: 34.2900, mean_ecr: 0.0297 mean_entropies: 0.6132, took: 164.5400s
2022-10-10 23:27:41,013 [INFO] 	Process 3 - batch 74999: mean_policy_losses: -23.709, mean_net_lifetime: 4804.9396, mean_mc_travel_dist: 1240.4946, mean_rewards: 267.8697, total_rewards: 3606.9190, mean_steps: 17.0100, mean_ecr: 0.0478 mean_entropies: 0.5025, took: 86.9116s
2022-10-10 23:27:46,187 [INFO] 	Process 6 - batch 99899: mean_policy_losses: -96.749, mean_net_lifetime: 4084.7228, mean_mc_travel_dist: 1099.7489, mean_rewards: 339.4405, total_rewards: 3036.4316, mean_steps: 10.9300, mean_ecr: 0.0550 mean_entropies: 0.1371, took: 58.6318s
2022-10-10 23:27:48,866 [INFO] Process 4 - epoch 51: mean_policy_losses: 92.247, mean_net_lifetime: 4355.0014, mean_mc_travel_dist: 1394.5680, mean_entropies: 1.1407, m_net_lifetime_valid: 4785.3553, took: 2333.6295s, (138.6725 / 100 batches)

2022-10-10 23:27:50,370 [INFO] 	Process 7 - batch 70699: mean_policy_losses: -350.712, mean_net_lifetime: 4871.9716, mean_mc_travel_dist: 1525.6251, mean_rewards: 207.7016, total_rewards: 3380.9719, mean_steps: 23.0100, mean_ecr: 0.0410 mean_entropies: 1.2388, took: 109.1672s
2022-10-10 23:28:04,096 [INFO] 	Process 1 - batch 62899: mean_policy_losses: -1.594, mean_net_lifetime: 6505.7113, mean_mc_travel_dist: 2103.4433, mean_rewards: 251.5657, total_rewards: 4434.3801, mean_steps: 24.9800, mean_ecr: 0.0381 mean_entropies: 0.9635, took: 120.3660s
2022-10-10 23:28:42,576 [INFO] 	Process 6 - batch 99999: mean_policy_losses: -95.573, mean_net_lifetime: 3867.5974, mean_mc_travel_dist: 1060.0069, mean_rewards: 338.2902, total_rewards: 2865.7926, mean_steps: 10.3900, mean_ecr: 0.0556 mean_entropies: 0.1592, took: 56.3893s
2022-10-10 23:29:23,209 [INFO] 	Process 4 - batch 76599: mean_policy_losses: 164.224, mean_net_lifetime: 5319.4757, mean_mc_travel_dist: 1469.7786, mean_rewards: 273.8027, total_rewards: 3879.7359, mean_steps: 18.8100, mean_ecr: 0.0461 mean_entropies: 0.5670, took: 745.1161s
2022-10-10 23:29:24,950 [INFO] 	Process 2 - batch 69999: mean_policy_losses: 5.261, mean_net_lifetime: 7516.4052, mean_mc_travel_dist: 2119.0330, mean_rewards: 268.0958, total_rewards: 5429.8024, mean_steps: 27.1000, mean_ecr: 0.0378 mean_entropies: 0.4682, took: 129.5680s
2022-10-10 23:29:33,659 [INFO] 	Process 7 - batch 70799: mean_policy_losses: -554.399, mean_net_lifetime: 4451.2712, mean_mc_travel_dist: 1374.3615, mean_rewards: 208.7588, total_rewards: 3115.2560, mean_steps: 20.7600, mean_ecr: 0.0413 mean_entropies: 1.2028, took: 103.2891s
2022-10-10 23:29:38,951 [INFO] 	Process 6 - batch 100099: mean_policy_losses: -140.670, mean_net_lifetime: 3816.0582, mean_mc_travel_dist: 1044.6958, mean_rewards: 338.0113, total_rewards: 2833.3709, mean_steps: 10.2100, mean_ecr: 0.0556 mean_entropies: 0.1514, took: 56.3756s
2022-10-10 23:29:43,530 [INFO] 	Process 5 - batch 68399: mean_policy_losses: -40.138, mean_net_lifetime: 8071.6765, mean_mc_travel_dist: 2557.8464, mean_rewards: 275.1146, total_rewards: 5558.2908, mean_steps: 28.7500, mean_ecr: 0.0302 mean_entropies: 0.6127, took: 140.2384s
2022-10-10 23:30:01,150 [INFO] 	Process 1 - batch 62999: mean_policy_losses: -10.052, mean_net_lifetime: 6318.4448, mean_mc_travel_dist: 2076.6310, mean_rewards: 258.4819, total_rewards: 4270.4362, mean_steps: 23.5400, mean_ecr: 0.0381 mean_entropies: 0.9245, took: 117.0539s
2022-10-10 23:30:35,605 [INFO] 	Process 6 - batch 100199: mean_policy_losses: -138.769, mean_net_lifetime: 4016.6788, mean_mc_travel_dist: 1089.6953, mean_rewards: 339.8119, total_rewards: 2991.0599, mean_steps: 10.7500, mean_ecr: 0.0553 mean_entropies: 0.1287, took: 56.6539s
2022-10-10 23:31:16,017 [INFO] 	Process 4 - batch 76699: mean_policy_losses: 157.096, mean_net_lifetime: 6383.3173, mean_mc_travel_dist: 1781.4920, mean_rewards: 271.5014, total_rewards: 4625.4959, mean_steps: 23.4600, mean_ecr: 0.0437 mean_entropies: 0.5685, took: 112.8093s
2022-10-10 23:31:25,309 [INFO] 	Process 7 - batch 70899: mean_policy_losses: -419.924, mean_net_lifetime: 5025.7766, mean_mc_travel_dist: 1510.9844, mean_rewards: 206.2163, total_rewards: 3547.1139, mean_steps: 23.9300, mean_ecr: 0.0407 mean_entropies: 1.2443, took: 111.6505s
2022-10-10 23:31:26,533 [INFO] 	Process 2 - batch 70099: mean_policy_losses: -29.082, mean_net_lifetime: 7335.3987, mean_mc_travel_dist: 2042.8559, mean_rewards: 271.9783, total_rewards: 5318.9967, mean_steps: 26.0300, mean_ecr: 0.0381 mean_entropies: 0.4571, took: 121.5836s
2022-10-10 23:31:33,436 [INFO] 	Process 6 - batch 100299: mean_policy_losses: -70.157, mean_net_lifetime: 4118.8152, mean_mc_travel_dist: 1109.9257, mean_rewards: 340.2945, total_rewards: 3070.2548, mean_steps: 11.0300, mean_ecr: 0.0551 mean_entropies: 0.1380, took: 57.8312s
2022-10-10 23:31:57,886 [INFO] 	Process 5 - batch 68499: mean_policy_losses: -83.499, mean_net_lifetime: 8219.4925, mean_mc_travel_dist: 2564.3830, mean_rewards: 276.3724, total_rewards: 5692.3187, mean_steps: 29.1700, mean_ecr: 0.0301 mean_entropies: 0.6141, took: 134.3572s
2022-10-10 23:32:31,424 [INFO] 	Process 6 - batch 100399: mean_policy_losses: -58.053, mean_net_lifetime: 4087.1132, mean_mc_travel_dist: 1109.7615, mean_rewards: 341.2910, total_rewards: 3040.7986, mean_steps: 10.9100, mean_ecr: 0.0552 mean_entropies: 0.1502, took: 57.9873s
2022-10-10 23:33:11,826 [INFO] 	Process 4 - batch 76799: mean_policy_losses: 157.349, mean_net_lifetime: 6755.5206, mean_mc_travel_dist: 1891.9572, mean_rewards: 268.2335, total_rewards: 4893.9657, mean_steps: 24.7300, mean_ecr: 0.0425 mean_entropies: 0.5802, took: 115.8094s
2022-10-10 23:33:24,500 [INFO] 	Process 7 - batch 70999: mean_policy_losses: -432.923, mean_net_lifetime: 5282.5836, mean_mc_travel_dist: 1626.0463, mean_rewards: 198.7256, total_rewards: 3697.5426, mean_steps: 26.2900, mean_ecr: 0.0405 mean_entropies: 1.2493, took: 119.1905s
2022-10-10 23:33:28,267 [INFO] 	Process 2 - batch 70199: mean_policy_losses: -16.015, mean_net_lifetime: 7430.8548, mean_mc_travel_dist: 2075.0036, mean_rewards: 271.6366, total_rewards: 5395.1535, mean_steps: 26.4500, mean_ecr: 0.0380 mean_entropies: 0.4511, took: 121.7339s
2022-10-10 23:33:29,411 [INFO] 	Process 6 - batch 100499: mean_policy_losses: -73.993, mean_net_lifetime: 4191.5406, mean_mc_travel_dist: 1131.1122, mean_rewards: 342.3553, total_rewards: 3108.4753, mean_steps: 11.1900, mean_ecr: 0.0550 mean_entropies: 0.1414, took: 57.9865s
2022-10-10 23:34:26,438 [INFO] 	Process 5 - batch 68599: mean_policy_losses: -34.705, mean_net_lifetime: 8831.5182, mean_mc_travel_dist: 2761.0331, mean_rewards: 272.2896, total_rewards: 6103.5487, mean_steps: 31.9400, mean_ecr: 0.0298 mean_entropies: 0.6460, took: 148.5516s
2022-10-10 23:35:05,491 [INFO] 	Process 4 - batch 76899: mean_policy_losses: 129.932, mean_net_lifetime: 6833.8926, mean_mc_travel_dist: 1903.5201, mean_rewards: 274.3554, total_rewards: 4959.0255, mean_steps: 24.7400, mean_ecr: 0.0429 mean_entropies: 0.5587, took: 113.6647s
2022-10-10 23:35:12,463 [INFO] 	Process 7 - batch 71099: mean_policy_losses: -534.925, mean_net_lifetime: 5057.1614, mean_mc_travel_dist: 1542.1091, mean_rewards: 202.9004, total_rewards: 3552.2208, mean_steps: 24.3800, mean_ecr: 0.0407 mean_entropies: 1.2526, took: 107.9631s
2022-10-10 23:35:24,058 [INFO] 	Process 2 - batch 70299: mean_policy_losses: -30.211, mean_net_lifetime: 7319.0350, mean_mc_travel_dist: 2018.5129, mean_rewards: 274.9180, total_rewards: 5330.2875, mean_steps: 25.6700, mean_ecr: 0.0382 mean_entropies: 0.4503, took: 115.7911s
2022-10-10 23:36:54,210 [INFO] 	Process 5 - batch 68699: mean_policy_losses: -70.814, mean_net_lifetime: 9123.2418, mean_mc_travel_dist: 2882.6343, mean_rewards: 268.3911, total_rewards: 6282.2912, mean_steps: 33.7400, mean_ecr: 0.0296 mean_entropies: 0.6519, took: 147.7724s
2022-10-10 23:37:00,699 [INFO] 	Process 4 - batch 76999: mean_policy_losses: 143.027, mean_net_lifetime: 6953.0115, mean_mc_travel_dist: 1940.2045, mean_rewards: 277.2338, total_rewards: 5038.4799, mean_steps: 25.1600, mean_ecr: 0.0429 mean_entropies: 0.5657, took: 115.2087s
2022-10-10 23:37:06,324 [INFO] 	Process 7 - batch 71199: mean_policy_losses: -417.618, mean_net_lifetime: 5403.1485, mean_mc_travel_dist: 1633.7324, mean_rewards: 205.4743, total_rewards: 3806.7480, mean_steps: 25.7300, mean_ecr: 0.0404 mean_entropies: 1.2477, took: 113.8610s
2022-10-10 23:37:18,676 [INFO] Process 3 - epoch 50: mean_policy_losses: 59.475, mean_net_lifetime: 4304.2360, mean_mc_travel_dist: 1351.2204, mean_entropies: 0.8922, m_net_lifetime_valid: 4205.7858, took: 1831.2753s, (142.2976 / 100 batches)

2022-10-10 23:37:21,616 [INFO] 	Process 2 - batch 70399: mean_policy_losses: -32.623, mean_net_lifetime: 7343.0737, mean_mc_travel_dist: 2049.2158, mean_rewards: 273.1160, total_rewards: 5324.9373, mean_steps: 25.9700, mean_ecr: 0.0381 mean_entropies: 0.4712, took: 117.5580s
2022-10-10 23:38:39,650 [INFO] 	Process 3 - batch 75099: mean_policy_losses: -19.561, mean_net_lifetime: 4690.3770, mean_mc_travel_dist: 1206.6430, mean_rewards: 266.7626, total_rewards: 3517.6228, mean_steps: 16.6300, mean_ecr: 0.0482 mean_entropies: 0.4716, took: 658.6368s
2022-10-10 23:38:42,040 [INFO] 	Process 7 - batch 71299: mean_policy_losses: -627.926, mean_net_lifetime: 4502.1506, mean_mc_travel_dist: 1352.6448, mean_rewards: 216.3417, total_rewards: 3180.5354, mean_steps: 20.5600, mean_ecr: 0.0412 mean_entropies: 1.2787, took: 95.7161s
2022-10-10 23:38:52,113 [INFO] 	Process 4 - batch 77099: mean_policy_losses: 154.859, mean_net_lifetime: 6720.1459, mean_mc_travel_dist: 1868.0222, mean_rewards: 281.7010, total_rewards: 4878.0240, mean_steps: 23.7200, mean_ecr: 0.0429 mean_entropies: 0.5264, took: 111.4129s
2022-10-10 23:39:13,811 [INFO] 	Process 5 - batch 68799: mean_policy_losses: -123.941, mean_net_lifetime: 8221.0893, mean_mc_travel_dist: 2601.1055, mean_rewards: 267.9149, total_rewards: 5669.0128, mean_steps: 30.4100, mean_ecr: 0.0301 mean_entropies: 0.6436, took: 139.6011s
2022-10-10 23:39:21,543 [INFO] 	Process 2 - batch 70499: mean_policy_losses: 4.365, mean_net_lifetime: 7342.2338, mean_mc_travel_dist: 2030.2758, mean_rewards: 276.0690, total_rewards: 5338.6286, mean_steps: 25.7500, mean_ecr: 0.0382 mean_entropies: 0.4725, took: 119.9269s
2022-10-10 23:40:03,067 [INFO] 	Process 3 - batch 75199: mean_policy_losses: -2.997, mean_net_lifetime: 4850.6883, mean_mc_travel_dist: 1257.7554, mean_rewards: 274.4669, total_rewards: 3636.5023, mean_steps: 16.7400, mean_ecr: 0.0476 mean_entropies: 0.4689, took: 83.4179s
2022-10-10 23:40:06,034 [INFO] Process 1 - epoch 42: mean_policy_losses: 25.346, mean_net_lifetime: 5116.6550, mean_mc_travel_dist: 2032.6018, mean_entropies: 1.1980, m_net_lifetime_valid: 4538.5314, took: 2360.2052s, (169.5822 / 100 batches)

2022-10-10 23:40:27,426 [INFO] 	Process 7 - batch 71399: mean_policy_losses: -551.628, mean_net_lifetime: 4883.2578, mean_mc_travel_dist: 1485.8587, mean_rewards: 207.1241, total_rewards: 3437.6956, mean_steps: 23.5100, mean_ecr: 0.0408 mean_entropies: 1.2864, took: 105.3854s
2022-10-10 23:41:02,758 [INFO] 	Process 4 - batch 77199: mean_policy_losses: 202.295, mean_net_lifetime: 7633.3638, mean_mc_travel_dist: 2157.3224, mean_rewards: 274.6910, total_rewards: 5498.6210, mean_steps: 28.1500, mean_ecr: 0.0411 mean_entropies: 0.5409, took: 130.6457s
2022-10-10 23:41:26,848 [INFO] 	Process 3 - batch 75299: mean_policy_losses: 2.796, mean_net_lifetime: 4834.7403, mean_mc_travel_dist: 1252.6094, mean_rewards: 272.1116, total_rewards: 3618.6514, mean_steps: 16.8100, mean_ecr: 0.0478 mean_entropies: 0.4779, took: 83.7805s
2022-10-10 23:41:41,801 [INFO] 	Process 5 - batch 68899: mean_policy_losses: -85.225, mean_net_lifetime: 8524.2530, mean_mc_travel_dist: 2699.0415, mean_rewards: 267.3908, total_rewards: 5856.2213, mean_steps: 31.6100, mean_ecr: 0.0299 mean_entropies: 0.6215, took: 147.9895s
2022-10-10 23:42:06,247 [INFO] 	Process 1 - batch 63099: mean_policy_losses: -28.305, mean_net_lifetime: 6198.6349, mean_mc_travel_dist: 2038.9498, mean_rewards: 234.1482, total_rewards: 4185.0828, mean_steps: 25.8300, mean_ecr: 0.0381 mean_entropies: 0.8912, took: 725.0956s
2022-10-10 23:42:20,623 [INFO] 	Process 7 - batch 71499: mean_policy_losses: -422.832, mean_net_lifetime: 5068.4531, mean_mc_travel_dist: 1545.2650, mean_rewards: 201.9320, total_rewards: 3547.9902, mean_steps: 24.5600, mean_ecr: 0.0405 mean_entropies: 1.2798, took: 113.1977s
2022-10-10 23:42:49,051 [INFO] 	Process 4 - batch 77299: mean_policy_losses: 110.184, mean_net_lifetime: 6185.2186, mean_mc_travel_dist: 1691.2302, mean_rewards: 274.2452, total_rewards: 4528.0741, mean_steps: 22.1900, mean_ecr: 0.0443 mean_entropies: 0.5448, took: 106.2931s
2022-10-10 23:42:49,515 [INFO] 	Process 3 - batch 75399: mean_policy_losses: 0.234, mean_net_lifetime: 4810.3982, mean_mc_travel_dist: 1234.8646, mean_rewards: 269.5674, total_rewards: 3597.0669, mean_steps: 16.9200, mean_ecr: 0.0478 mean_entropies: 0.4707, took: 82.6673s
2022-10-10 23:43:44,884 [INFO] Process 6 - epoch 67: mean_policy_losses: -206.929, mean_net_lifetime: 3083.5771, mean_mc_travel_dist: 973.7427, mean_entropies: 0.5864, m_net_lifetime_valid: 4439.1856, took: 1472.8268s, (106.5747 / 100 batches)

2022-10-10 23:44:04,261 [INFO] 	Process 1 - batch 63199: mean_policy_losses: -30.506, mean_net_lifetime: 6284.3565, mean_mc_travel_dist: 2089.7214, mean_rewards: 244.6015, total_rewards: 4223.5447, mean_steps: 24.9700, mean_ecr: 0.0380 mean_entropies: 0.9266, took: 118.0154s
2022-10-10 23:44:07,366 [INFO] 	Process 5 - batch 68999: mean_policy_losses: -112.317, mean_net_lifetime: 8601.7677, mean_mc_travel_dist: 2741.3182, mean_rewards: 276.2221, total_rewards: 5915.2504, mean_steps: 30.9200, mean_ecr: 0.0298 mean_entropies: 0.5985, took: 145.5649s
2022-10-10 23:44:07,643 [INFO] 	Process 7 - batch 71599: mean_policy_losses: -476.464, mean_net_lifetime: 4778.4983, mean_mc_travel_dist: 1472.6463, mean_rewards: 202.0824, total_rewards: 3338.9402, mean_steps: 23.2700, mean_ecr: 0.0410 mean_entropies: 1.2580, took: 107.0201s
2022-10-10 23:44:12,773 [INFO] 	Process 3 - batch 75499: mean_policy_losses: 4.258, mean_net_lifetime: 4792.8221, mean_mc_travel_dist: 1231.1674, mean_rewards: 269.7837, total_rewards: 3603.9406, mean_steps: 16.8400, mean_ecr: 0.0479 mean_entropies: 0.4838, took: 83.2581s
2022-10-10 23:44:40,537 [INFO] 	Process 6 - batch 100599: mean_policy_losses: -154.160, mean_net_lifetime: 3891.1033, mean_mc_travel_dist: 1051.2178, mean_rewards: 341.1065, total_rewards: 2893.9892, mean_steps: 10.3500, mean_ecr: 0.0553 mean_entropies: 0.1501, took: 671.1258s
2022-10-10 23:44:58,948 [INFO] 	Process 4 - batch 77399: mean_policy_losses: 176.027, mean_net_lifetime: 7509.5704, mean_mc_travel_dist: 2133.2211, mean_rewards: 276.0446, total_rewards: 5412.7304, mean_steps: 28.0500, mean_ecr: 0.0427 mean_entropies: 0.5496, took: 129.8968s
2022-10-10 23:45:31,764 [INFO] 	Process 3 - batch 75599: mean_policy_losses: -22.310, mean_net_lifetime: 4686.6903, mean_mc_travel_dist: 1188.3545, mean_rewards: 279.5737, total_rewards: 3531.6811, mean_steps: 15.7900, mean_ecr: 0.0483 mean_entropies: 0.5078, took: 78.9908s
2022-10-10 23:45:34,637 [INFO] 	Process 7 - batch 71699: mean_policy_losses: -694.980, mean_net_lifetime: 4218.6366, mean_mc_travel_dist: 1305.6235, mean_rewards: 220.8583, total_rewards: 2957.1708, mean_steps: 18.5500, mean_ecr: 0.0415 mean_entropies: 1.2898, took: 86.9938s
2022-10-10 23:45:36,800 [INFO] 	Process 6 - batch 100699: mean_policy_losses: -46.407, mean_net_lifetime: 4057.9920, mean_mc_travel_dist: 1099.4491, mean_rewards: 341.8607, total_rewards: 3022.8349, mean_steps: 10.8600, mean_ecr: 0.0551 mean_entropies: 0.1311, took: 56.2641s
2022-10-10 23:46:02,823 [INFO] 	Process 1 - batch 63299: mean_policy_losses: -14.780, mean_net_lifetime: 6334.0692, mean_mc_travel_dist: 2102.0881, mean_rewards: 245.1112, total_rewards: 4258.5754, mean_steps: 25.1700, mean_ecr: 0.0379 mean_entropies: 0.9134, took: 118.5620s
2022-10-10 23:46:33,289 [INFO] 	Process 6 - batch 100799: mean_policy_losses: -54.477, mean_net_lifetime: 4072.8700, mean_mc_travel_dist: 1100.6435, mean_rewards: 340.5873, total_rewards: 3043.2064, mean_steps: 10.9000, mean_ecr: 0.0551 mean_entropies: 0.1259, took: 56.4884s
2022-10-10 23:46:52,715 [INFO] 	Process 3 - batch 75699: mean_policy_losses: -16.444, mean_net_lifetime: 4745.6710, mean_mc_travel_dist: 1187.2338, mean_rewards: 272.4003, total_rewards: 3589.1633, mean_steps: 16.4700, mean_ecr: 0.0483 mean_entropies: 0.4740, took: 80.9504s
2022-10-10 23:47:16,578 [INFO] 	Process 7 - batch 71799: mean_policy_losses: -564.536, mean_net_lifetime: 4813.4176, mean_mc_travel_dist: 1456.2790, mean_rewards: 213.4058, total_rewards: 3394.4606, mean_steps: 22.1500, mean_ecr: 0.0408 mean_entropies: 1.2727, took: 101.9402s
2022-10-10 23:47:32,803 [INFO] 	Process 6 - batch 100899: mean_policy_losses: -39.609, mean_net_lifetime: 4237.5342, mean_mc_travel_dist: 1147.8123, mean_rewards: 341.1193, total_rewards: 3162.6235, mean_steps: 11.3700, mean_ecr: 0.0548 mean_entropies: 0.1056, took: 59.5151s
2022-10-10 23:47:39,560 [INFO] 	Process 4 - batch 77499: mean_policy_losses: 217.325, mean_net_lifetime: 9045.8736, mean_mc_travel_dist: 2739.8257, mean_rewards: 267.8844, total_rewards: 6339.1866, mean_steps: 35.4800, mean_ecr: 0.0402 mean_entropies: 0.5518, took: 160.6123s
2022-10-10 23:47:50,249 [INFO] 	Process 1 - batch 63399: mean_policy_losses: -52.577, mean_net_lifetime: 6102.1660, mean_mc_travel_dist: 2030.9320, mean_rewards: 251.6743, total_rewards: 4100.3703, mean_steps: 23.4200, mean_ecr: 0.0381 mean_entropies: 0.8760, took: 107.4253s
2022-10-10 23:48:14,188 [INFO] 	Process 3 - batch 75799: mean_policy_losses: -13.113, mean_net_lifetime: 4782.3372, mean_mc_travel_dist: 1206.4393, mean_rewards: 279.3109, total_rewards: 3603.5691, mean_steps: 16.1800, mean_ecr: 0.0481 mean_entropies: 0.5021, took: 81.4734s
2022-10-10 23:48:30,057 [INFO] 	Process 6 - batch 100999: mean_policy_losses: -47.053, mean_net_lifetime: 4202.0568, mean_mc_travel_dist: 1145.0899, mean_rewards: 343.4723, total_rewards: 3140.6138, mean_steps: 11.2100, mean_ecr: 0.0549 mean_entropies: 0.1054, took: 57.2533s
2022-10-10 23:49:01,120 [INFO] 	Process 7 - batch 71899: mean_policy_losses: -482.657, mean_net_lifetime: 5028.3427, mean_mc_travel_dist: 1527.7985, mean_rewards: 211.5514, total_rewards: 3529.0732, mean_steps: 22.9400, mean_ecr: 0.0406 mean_entropies: 1.2890, took: 104.5429s
2022-10-10 23:49:28,063 [INFO] 	Process 6 - batch 101099: mean_policy_losses: -52.575, mean_net_lifetime: 4101.1638, mean_mc_travel_dist: 1109.8276, mean_rewards: 343.1977, total_rewards: 3058.5631, mean_steps: 10.9300, mean_ecr: 0.0552 mean_entropies: 0.1299, took: 58.0065s
2022-10-10 23:49:36,310 [INFO] 	Process 3 - batch 75899: mean_policy_losses: -21.014, mean_net_lifetime: 4714.9685, mean_mc_travel_dist: 1197.4321, mean_rewards: 272.1016, total_rewards: 3544.5185, mean_steps: 16.3600, mean_ecr: 0.0483 mean_entropies: 0.4915, took: 82.1210s
2022-10-10 23:49:38,226 [INFO] 	Process 1 - batch 63499: mean_policy_losses: -31.509, mean_net_lifetime: 6205.3696, mean_mc_travel_dist: 2081.2063, mean_rewards: 260.0902, total_rewards: 4162.8053, mean_steps: 22.9900, mean_ecr: 0.0383 mean_entropies: 0.9296, took: 107.9777s
2022-10-10 23:49:56,011 [INFO] 	Process 4 - batch 77599: mean_policy_losses: 202.414, mean_net_lifetime: 8037.5615, mean_mc_travel_dist: 2275.0973, mean_rewards: 274.0280, total_rewards: 5800.6201, mean_steps: 29.8100, mean_ecr: 0.0409 mean_entropies: 0.5832, took: 136.4512s
2022-10-10 23:50:02,126 [INFO] Process 2 - epoch 47: mean_policy_losses: -2.216, mean_net_lifetime: 4800.9746, mean_mc_travel_dist: 1615.9400, mean_entropies: 0.9301, m_net_lifetime_valid: 4586.1877, took: 2454.0777s, (152.3609 / 100 batches)

2022-10-10 23:50:26,537 [INFO] 	Process 6 - batch 101199: mean_policy_losses: -50.999, mean_net_lifetime: 4163.8833, mean_mc_travel_dist: 1125.6656, mean_rewards: 339.6217, total_rewards: 3103.9015, mean_steps: 11.1700, mean_ecr: 0.0551 mean_entropies: 0.1233, took: 58.4734s
2022-10-10 23:50:48,305 [INFO] 	Process 7 - batch 71999: mean_policy_losses: -519.608, mean_net_lifetime: 4932.1102, mean_mc_travel_dist: 1495.8227, mean_rewards: 208.7825, total_rewards: 3478.3552, mean_steps: 22.9700, mean_ecr: 0.0408 mean_entropies: 1.3031, took: 107.1850s
2022-10-10 23:51:00,257 [INFO] 	Process 3 - batch 75999: mean_policy_losses: -13.556, mean_net_lifetime: 4865.4039, mean_mc_travel_dist: 1264.7135, mean_rewards: 275.0325, total_rewards: 3636.6637, mean_steps: 16.7400, mean_ecr: 0.0476 mean_entropies: 0.5233, took: 83.9478s
2022-10-10 23:51:23,727 [INFO] 	Process 6 - batch 101299: mean_policy_losses: -110.456, mean_net_lifetime: 4086.8697, mean_mc_travel_dist: 1112.7802, mean_rewards: 340.2840, total_rewards: 3051.7193, mean_steps: 10.9400, mean_ecr: 0.0551 mean_entropies: 0.1103, took: 57.1908s
2022-10-10 23:51:39,908 [INFO] 	Process 1 - batch 63599: mean_policy_losses: -30.128, mean_net_lifetime: 6460.0642, mean_mc_travel_dist: 2097.2561, mean_rewards: 242.3790, total_rewards: 4385.6032, mean_steps: 25.8300, mean_ecr: 0.0380 mean_entropies: 0.9499, took: 121.6818s
2022-10-10 23:52:02,476 [INFO] 	Process 2 - batch 70599: mean_policy_losses: -26.653, mean_net_lifetime: 7310.3274, mean_mc_travel_dist: 2036.9062, mean_rewards: 276.5249, total_rewards: 5299.4383, mean_steps: 25.5300, mean_ecr: 0.0382 mean_entropies: 0.4385, took: 760.9329s
2022-10-10 23:52:22,606 [INFO] 	Process 6 - batch 101399: mean_policy_losses: -58.712, mean_net_lifetime: 4247.6525, mean_mc_travel_dist: 1150.8753, mean_rewards: 343.1625, total_rewards: 3156.5917, mean_steps: 11.3700, mean_ecr: 0.0549 mean_entropies: 0.1183, took: 58.8778s
2022-10-10 23:52:23,883 [INFO] 	Process 4 - batch 77699: mean_policy_losses: 170.593, mean_net_lifetime: 8328.7751, mean_mc_travel_dist: 2423.6719, mean_rewards: 267.0854, total_rewards: 5931.6854, mean_steps: 32.1000, mean_ecr: 0.0410 mean_entropies: 0.5912, took: 147.8717s
2022-10-10 23:52:24,536 [INFO] 	Process 3 - batch 76099: mean_policy_losses: -19.650, mean_net_lifetime: 4831.1285, mean_mc_travel_dist: 1223.9801, mean_rewards: 273.8119, total_rewards: 3646.0926, mean_steps: 16.6900, mean_ecr: 0.0479 mean_entropies: 0.4726, took: 84.2798s
2022-10-10 23:53:18,297 [INFO] 	Process 6 - batch 101499: mean_policy_losses: -67.798, mean_net_lifetime: 3952.6802, mean_mc_travel_dist: 1070.0018, mean_rewards: 336.4597, total_rewards: 2950.8809, mean_steps: 10.6800, mean_ecr: 0.0552 mean_entropies: 0.1591, took: 55.6907s
2022-10-10 23:53:28,721 [INFO] 	Process 1 - batch 63699: mean_policy_losses: -27.568, mean_net_lifetime: 6307.6025, mean_mc_travel_dist: 2085.5580, mean_rewards: 257.9986, total_rewards: 4253.4956, mean_steps: 23.5600, mean_ecr: 0.0381 mean_entropies: 0.9164, took: 108.8124s
2022-10-10 23:53:47,907 [INFO] 	Process 3 - batch 76199: mean_policy_losses: -27.567, mean_net_lifetime: 4750.6246, mean_mc_travel_dist: 1202.2327, mean_rewards: 268.5525, total_rewards: 3584.6116, mean_steps: 16.7600, mean_ecr: 0.0482 mean_entropies: 0.4486, took: 83.3706s
2022-10-10 23:53:58,537 [INFO] 	Process 2 - batch 70699: mean_policy_losses: -40.796, mean_net_lifetime: 7164.0658, mean_mc_travel_dist: 1968.6637, mean_rewards: 274.2494, total_rewards: 5235.5208, mean_steps: 25.1600, mean_ecr: 0.0384 mean_entropies: 0.4361, took: 116.0607s
2022-10-10 23:53:59,370 [INFO] Process 5 - epoch 46: mean_policy_losses: -199.135, mean_net_lifetime: 5049.7052, mean_mc_travel_dist: 1981.6965, mean_entropies: 1.1864, m_net_lifetime_valid: 4461.5693, took: 2802.9488s, (156.0818 / 100 batches)

2022-10-10 23:54:14,147 [INFO] 	Process 6 - batch 101599: mean_policy_losses: -108.074, mean_net_lifetime: 3814.3663, mean_mc_travel_dist: 1024.2676, mean_rewards: 335.1871, total_rewards: 2841.4986, mean_steps: 10.3400, mean_ecr: 0.0553 mean_entropies: 0.1619, took: 55.8507s
2022-10-10 23:54:26,305 [INFO] 	Process 4 - batch 77799: mean_policy_losses: 132.971, mean_net_lifetime: 7326.6710, mean_mc_travel_dist: 2102.9329, mean_rewards: 284.2682, total_rewards: 5261.4033, mean_steps: 26.0900, mean_ecr: 0.0424 mean_entropies: 0.5472, took: 122.4219s
2022-10-10 23:55:10,274 [INFO] 	Process 3 - batch 76299: mean_policy_losses: -3.601, mean_net_lifetime: 4796.2088, mean_mc_travel_dist: 1215.1056, mean_rewards: 275.7090, total_rewards: 3613.5232, mean_steps: 16.4400, mean_ecr: 0.0479 mean_entropies: 0.4789, took: 82.3667s
2022-10-10 23:55:11,281 [INFO] 	Process 6 - batch 101699: mean_policy_losses: -68.304, mean_net_lifetime: 4057.9393, mean_mc_travel_dist: 1092.5682, mean_rewards: 341.0345, total_rewards: 3017.1975, mean_steps: 10.8400, mean_ecr: 0.0551 mean_entropies: 0.1482, took: 57.1347s
2022-10-10 23:55:22,290 [INFO] 	Process 1 - batch 63799: mean_policy_losses: 7.578, mean_net_lifetime: 6299.9884, mean_mc_travel_dist: 2071.5149, mean_rewards: 255.9377, total_rewards: 4250.0592, mean_steps: 23.7500, mean_ecr: 0.0382 mean_entropies: 0.9494, took: 113.5696s
2022-10-10 23:56:02,998 [INFO] 	Process 2 - batch 70799: mean_policy_losses: -9.750, mean_net_lifetime: 7412.9963, mean_mc_travel_dist: 2027.2612, mean_rewards: 275.4805, total_rewards: 5422.9244, mean_steps: 25.9700, mean_ecr: 0.0383 mean_entropies: 0.4630, took: 124.4623s
2022-10-10 23:56:09,157 [INFO] 	Process 5 - batch 69099: mean_policy_losses: -267.171, mean_net_lifetime: 7293.4528, mean_mc_travel_dist: 2351.8523, mean_rewards: 268.7803, total_rewards: 4994.2777, mean_steps: 26.8100, mean_ecr: 0.0301 mean_entropies: 0.5952, took: 721.7915s
2022-10-10 23:56:09,564 [INFO] 	Process 6 - batch 101799: mean_policy_losses: -66.709, mean_net_lifetime: 3985.5832, mean_mc_travel_dist: 1079.8202, mean_rewards: 335.4436, total_rewards: 2969.4973, mean_steps: 10.8100, mean_ecr: 0.0553 mean_entropies: 0.1509, took: 58.2812s
2022-10-10 23:56:28,797 [INFO] 	Process 4 - batch 77899: mean_policy_losses: 149.636, mean_net_lifetime: 7055.5547, mean_mc_travel_dist: 1973.0499, mean_rewards: 283.1455, total_rewards: 5106.1468, mean_steps: 25.2100, mean_ecr: 0.0435 mean_entropies: 0.5807, took: 122.4918s
2022-10-10 23:56:36,418 [INFO] 	Process 3 - batch 76399: mean_policy_losses: -16.843, mean_net_lifetime: 4865.2882, mean_mc_travel_dist: 1227.0052, mean_rewards: 272.8126, total_rewards: 3687.8519, mean_steps: 16.8900, mean_ecr: 0.0479 mean_entropies: 0.4387, took: 86.1447s
2022-10-10 23:57:06,282 [INFO] 	Process 6 - batch 101899: mean_policy_losses: -82.191, mean_net_lifetime: 3978.9690, mean_mc_travel_dist: 1077.8567, mean_rewards: 333.9387, total_rewards: 2966.8477, mean_steps: 10.8100, mean_ecr: 0.0554 mean_entropies: 0.1417, took: 56.7197s
2022-10-10 23:57:23,155 [INFO] 	Process 1 - batch 63899: mean_policy_losses: 11.841, mean_net_lifetime: 6549.5703, mean_mc_travel_dist: 2139.4923, mean_rewards: 256.4587, total_rewards: 4433.5505, mean_steps: 24.7300, mean_ecr: 0.0379 mean_entropies: 0.9337, took: 120.8647s
2022-10-10 23:58:01,137 [INFO] 	Process 3 - batch 76499: mean_policy_losses: -11.921, mean_net_lifetime: 4787.1795, mean_mc_travel_dist: 1197.2964, mean_rewards: 270.9617, total_rewards: 3627.8096, mean_steps: 16.7100, mean_ecr: 0.0481 mean_entropies: 0.4542, took: 84.7187s
2022-10-10 23:58:03,672 [INFO] 	Process 6 - batch 101999: mean_policy_losses: -113.129, mean_net_lifetime: 3983.1708, mean_mc_travel_dist: 1077.2311, mean_rewards: 338.7611, total_rewards: 2978.6681, mean_steps: 10.7000, mean_ecr: 0.0550 mean_entropies: 0.1523, took: 57.3896s
2022-10-10 23:58:04,530 [INFO] 	Process 5 - batch 69199: mean_policy_losses: -241.410, mean_net_lifetime: 6470.3676, mean_mc_travel_dist: 2079.3577, mean_rewards: 265.2259, total_rewards: 4447.0110, mean_steps: 23.7800, mean_ecr: 0.0302 mean_entropies: 0.6215, took: 115.3721s
2022-10-10 23:58:07,741 [INFO] 	Process 2 - batch 70899: mean_policy_losses: 0.770, mean_net_lifetime: 7421.6929, mean_mc_travel_dist: 2026.7327, mean_rewards: 273.1794, total_rewards: 5418.6289, mean_steps: 26.2700, mean_ecr: 0.0382 mean_entropies: 0.4355, took: 124.7428s
2022-10-10 23:58:20,753 [INFO] 	Process 4 - batch 77999: mean_policy_losses: 101.957, mean_net_lifetime: 6656.8279, mean_mc_travel_dist: 1866.6004, mean_rewards: 285.2228, total_rewards: 4823.1519, mean_steps: 23.2400, mean_ecr: 0.0439 mean_entropies: 0.5777, took: 111.9547s
2022-10-10 23:59:17,697 [INFO] 	Process 1 - batch 63999: mean_policy_losses: 5.742, mean_net_lifetime: 6561.6781, mean_mc_travel_dist: 2116.0539, mean_rewards: 250.0405, total_rewards: 4474.1136, mean_steps: 25.5600, mean_ecr: 0.0379 mean_entropies: 0.9543, took: 114.5417s
2022-10-11 00:00:02,961 [INFO] 	Process 2 - batch 70999: mean_policy_losses: -18.067, mean_net_lifetime: 7509.3766, mean_mc_travel_dist: 2067.3130, mean_rewards: 274.9421, total_rewards: 5470.4448, mean_steps: 26.4000, mean_ecr: 0.0382 mean_entropies: 0.4411, took: 115.2199s
2022-10-11 00:00:09,610 [INFO] 	Process 5 - batch 69299: mean_policy_losses: -147.204, mean_net_lifetime: 7814.9358, mean_mc_travel_dist: 2464.6218, mean_rewards: 268.6035, total_rewards: 5390.1016, mean_steps: 28.5600, mean_ecr: 0.0300 mean_entropies: 0.6428, took: 125.0814s
2022-10-11 00:01:02,372 [INFO] 	Process 1 - batch 64099: mean_policy_losses: -48.465, mean_net_lifetime: 6267.7729, mean_mc_travel_dist: 2047.6275, mean_rewards: 251.6593, total_rewards: 4257.5108, mean_steps: 24.1000, mean_ecr: 0.0382 mean_entropies: 0.9770, took: 104.6754s
2022-10-11 00:01:53,899 [INFO] 	Process 2 - batch 71099: mean_policy_losses: -34.507, mean_net_lifetime: 7271.0831, mean_mc_travel_dist: 2027.9453, mean_rewards: 272.6094, total_rewards: 5282.6356, mean_steps: 25.7700, mean_ecr: 0.0383 mean_entropies: 0.4666, took: 110.9380s
2022-10-11 00:02:17,015 [INFO] Process 7 - epoch 48: mean_policy_losses: -359.833, mean_net_lifetime: 4134.4207, mean_mc_travel_dist: 1556.4981, mean_entropies: 1.5811, m_net_lifetime_valid: 4581.7678, took: 2290.1658s, (150.1435 / 100 batches)

2022-10-11 00:02:28,447 [INFO] 	Process 5 - batch 69399: mean_policy_losses: -84.837, mean_net_lifetime: 8757.2857, mean_mc_travel_dist: 2766.8473, mean_rewards: 269.9926, total_rewards: 6042.5107, mean_steps: 31.9200, mean_ecr: 0.0299 mean_entropies: 0.6572, took: 138.8364s
2022-10-11 00:02:59,613 [INFO] 	Process 1 - batch 64199: mean_policy_losses: -15.975, mean_net_lifetime: 6719.1092, mean_mc_travel_dist: 2123.1113, mean_rewards: 241.9972, total_rewards: 4626.1319, mean_steps: 26.9200, mean_ecr: 0.0381 mean_entropies: 1.0199, took: 117.2410s
2022-10-11 00:03:50,353 [INFO] 	Process 2 - batch 71199: mean_policy_losses: -1.230, mean_net_lifetime: 7467.6469, mean_mc_travel_dist: 2050.3905, mean_rewards: 278.2875, total_rewards: 5448.5134, mean_steps: 25.9300, mean_ecr: 0.0382 mean_entropies: 0.4838, took: 116.4542s
2022-10-11 00:04:07,562 [INFO] 	Process 7 - batch 72099: mean_policy_losses: -428.999, mean_net_lifetime: 5141.0050, mean_mc_travel_dist: 1559.0431, mean_rewards: 205.8955, total_rewards: 3627.2162, mean_steps: 24.4100, mean_ecr: 0.0409 mean_entropies: 1.3866, took: 799.2566s
2022-10-11 00:05:02,751 [INFO] 	Process 1 - batch 64299: mean_policy_losses: -21.228, mean_net_lifetime: 6812.4330, mean_mc_travel_dist: 2133.2481, mean_rewards: 240.1677, total_rewards: 4698.1292, mean_steps: 27.5000, mean_ecr: 0.0381 mean_entropies: 1.0091, took: 123.1381s
2022-10-11 00:05:06,538 [INFO] 	Process 5 - batch 69499: mean_policy_losses: -9.739, mean_net_lifetime: 9545.5585, mean_mc_travel_dist: 3045.0084, mean_rewards: 275.1196, total_rewards: 6544.9842, mean_steps: 34.5600, mean_ecr: 0.0295 mean_entropies: 0.6691, took: 158.0912s
2022-10-11 00:05:48,976 [INFO] 	Process 2 - batch 71299: mean_policy_losses: -16.955, mean_net_lifetime: 7312.4111, mean_mc_travel_dist: 2016.0679, mean_rewards: 273.4180, total_rewards: 5324.0825, mean_steps: 25.8500, mean_ecr: 0.0383 mean_entropies: 0.4655, took: 118.6225s
2022-10-11 00:05:52,716 [INFO] 	Process 7 - batch 72199: mean_policy_losses: -357.370, mean_net_lifetime: 4977.6487, mean_mc_travel_dist: 1501.3213, mean_rewards: 208.3046, total_rewards: 3504.5613, mean_steps: 23.2900, mean_ecr: 0.0409 mean_entropies: 1.3537, took: 105.1537s
2022-10-11 00:07:05,223 [INFO] 	Process 1 - batch 64399: mean_policy_losses: -4.089, mean_net_lifetime: 6764.6706, mean_mc_travel_dist: 2184.1888, mean_rewards: 242.8438, total_rewards: 4611.2723, mean_steps: 27.1100, mean_ecr: 0.0378 mean_entropies: 0.9815, took: 122.4725s
2022-10-11 00:07:26,105 [INFO] 	Process 5 - batch 69599: mean_policy_losses: -41.669, mean_net_lifetime: 8527.0588, mean_mc_travel_dist: 2721.5164, mean_rewards: 272.4879, total_rewards: 5848.9940, mean_steps: 30.9800, mean_ecr: 0.0297 mean_entropies: 0.6467, took: 139.5661s
2022-10-11 00:07:40,490 [INFO] 	Process 2 - batch 71399: mean_policy_losses: -48.812, mean_net_lifetime: 7113.7017, mean_mc_travel_dist: 1955.8591, mean_rewards: 281.7929, total_rewards: 5187.7326, mean_steps: 24.4100, mean_ecr: 0.0386 mean_entropies: 0.4571, took: 111.5141s
2022-10-11 00:07:40,895 [INFO] 	Process 7 - batch 72299: mean_policy_losses: -344.340, mean_net_lifetime: 5158.8241, mean_mc_travel_dist: 1557.2731, mean_rewards: 206.6451, total_rewards: 3630.3517, mean_steps: 24.2600, mean_ecr: 0.0408 mean_entropies: 1.3785, took: 108.1800s
2022-10-11 00:08:00,385 [INFO] Process 3 - epoch 51: mean_policy_losses: 58.072, mean_net_lifetime: 4313.7013, mean_mc_travel_dist: 1348.6380, mean_entropies: 0.8840, m_net_lifetime_valid: 4561.8269, took: 1841.7062s, (141.8873 / 100 batches)

2022-10-11 00:08:53,040 [INFO] Process 6 - epoch 68: mean_policy_losses: -204.984, mean_net_lifetime: 3097.8714, mean_mc_travel_dist: 975.5652, mean_entropies: 0.5798, m_net_lifetime_valid: 4626.3791, took: 1508.1527s, (106.4529 / 100 batches)

2022-10-11 00:09:01,578 [INFO] Process 4 - epoch 52: mean_policy_losses: 93.511, mean_net_lifetime: 4408.1036, mean_mc_travel_dist: 1406.4903, mean_entropies: 1.1295, m_net_lifetime_valid: 4736.0155, took: 2472.7091s, (139.1880 / 100 batches)

2022-10-11 00:09:11,981 [INFO] 	Process 1 - batch 64499: mean_policy_losses: -24.329, mean_net_lifetime: 6781.6285, mean_mc_travel_dist: 2160.8807, mean_rewards: 239.6226, total_rewards: 4653.3293, mean_steps: 27.4700, mean_ecr: 0.0381 mean_entropies: 0.9697, took: 126.7578s
2022-10-11 00:09:21,211 [INFO] 	Process 3 - batch 76599: mean_policy_losses: -38.316, mean_net_lifetime: 4838.5895, mean_mc_travel_dist: 1231.5579, mean_rewards: 279.5406, total_rewards: 3636.5911, mean_steps: 16.3500, mean_ecr: 0.0477 mean_entropies: 0.5064, took: 680.0733s
2022-10-11 00:09:33,186 [INFO] 	Process 7 - batch 72399: mean_policy_losses: -260.540, mean_net_lifetime: 5194.7404, mean_mc_travel_dist: 1580.7177, mean_rewards: 209.0141, total_rewards: 3656.4854, mean_steps: 24.0700, mean_ecr: 0.0408 mean_entropies: 1.3432, took: 112.2904s
2022-10-11 00:09:38,570 [INFO] 	Process 2 - batch 71499: mean_policy_losses: -33.492, mean_net_lifetime: 7162.5186, mean_mc_travel_dist: 1986.5035, mean_rewards: 273.7118, total_rewards: 5203.1270, mean_steps: 25.2300, mean_ecr: 0.0384 mean_entropies: 0.4665, took: 118.0797s
2022-10-11 00:09:39,957 [INFO] 	Process 5 - batch 69699: mean_policy_losses: -35.961, mean_net_lifetime: 8110.8278, mean_mc_travel_dist: 2617.1995, mean_rewards: 277.9435, total_rewards: 5535.6515, mean_steps: 28.5700, mean_ecr: 0.0300 mean_entropies: 0.6501, took: 133.8522s
2022-10-11 00:09:51,379 [INFO] 	Process 6 - batch 102099: mean_policy_losses: -114.128, mean_net_lifetime: 3992.9487, mean_mc_travel_dist: 1071.0668, mean_rewards: 342.0424, total_rewards: 2976.4794, mean_steps: 10.6400, mean_ecr: 0.0550 mean_entropies: 0.1485, took: 707.7072s
2022-10-11 00:10:43,225 [INFO] 	Process 4 - batch 78099: mean_policy_losses: 302.212, mean_net_lifetime: 5909.4729, mean_mc_travel_dist: 1616.1469, mean_rewards: 283.0523, total_rewards: 4322.7117, mean_steps: 20.3600, mean_ecr: 0.0452 mean_entropies: 0.6308, took: 742.4728s
2022-10-11 00:10:46,709 [INFO] 	Process 3 - batch 76699: mean_policy_losses: -30.745, mean_net_lifetime: 4734.4416, mean_mc_travel_dist: 1174.8469, mean_rewards: 271.7779, total_rewards: 3592.0826, mean_steps: 16.4600, mean_ecr: 0.0483 mean_entropies: 0.4542, took: 85.4983s
2022-10-11 00:10:49,430 [INFO] 	Process 6 - batch 102199: mean_policy_losses: -65.076, mean_net_lifetime: 4117.5018, mean_mc_travel_dist: 1118.2526, mean_rewards: 342.3891, total_rewards: 3065.8242, mean_steps: 11.0000, mean_ecr: 0.0550 mean_entropies: 0.1368, took: 58.0514s
2022-10-11 00:11:31,260 [INFO] 	Process 7 - batch 72499: mean_policy_losses: -386.823, mean_net_lifetime: 5279.6712, mean_mc_travel_dist: 1634.2999, mean_rewards: 204.6727, total_rewards: 3677.8000, mean_steps: 25.2200, mean_ecr: 0.0403 mean_entropies: 1.2757, took: 118.0738s
2022-10-11 00:11:35,778 [INFO] 	Process 2 - batch 71599: mean_policy_losses: -34.565, mean_net_lifetime: 6964.4697, mean_mc_travel_dist: 1889.3222, mean_rewards: 277.3060, total_rewards: 5111.8838, mean_steps: 24.2100, mean_ecr: 0.0388 mean_entropies: 0.4255, took: 117.2076s
2022-10-11 00:11:45,501 [INFO] 	Process 6 - batch 102299: mean_policy_losses: -100.695, mean_net_lifetime: 3916.5566, mean_mc_travel_dist: 1050.6367, mean_rewards: 340.6599, total_rewards: 2926.0039, mean_steps: 10.4400, mean_ecr: 0.0552 mean_entropies: 0.1483, took: 56.0705s
2022-10-11 00:12:06,446 [INFO] 	Process 5 - batch 69799: mean_policy_losses: -64.865, mean_net_lifetime: 8286.0853, mean_mc_travel_dist: 2657.0655, mean_rewards: 266.3756, total_rewards: 5672.1907, mean_steps: 30.6400, mean_ecr: 0.0298 mean_entropies: 0.6457, took: 146.4890s
2022-10-11 00:12:11,256 [INFO] 	Process 3 - batch 76799: mean_policy_losses: -12.118, mean_net_lifetime: 4784.3431, mean_mc_travel_dist: 1178.7873, mean_rewards: 273.8137, total_rewards: 3635.3407, mean_steps: 16.5300, mean_ecr: 0.0482 mean_entropies: 0.4620, took: 84.5469s
2022-10-11 00:12:19,908 [INFO] 	Process 4 - batch 78199: mean_policy_losses: 109.797, mean_net_lifetime: 5599.3573, mean_mc_travel_dist: 1504.1775, mean_rewards: 283.0954, total_rewards: 4119.3417, mean_steps: 19.2000, mean_ecr: 0.0459 mean_entropies: 0.6406, took: 96.6837s
2022-10-11 00:12:44,928 [INFO] 	Process 6 - batch 102399: mean_policy_losses: -36.382, mean_net_lifetime: 4249.4601, mean_mc_travel_dist: 1149.7058, mean_rewards: 342.5246, total_rewards: 3174.6171, mean_steps: 11.3700, mean_ecr: 0.0549 mean_entropies: 0.1183, took: 59.4269s
2022-10-11 00:13:29,158 [INFO] 	Process 7 - batch 72599: mean_policy_losses: -402.899, mean_net_lifetime: 5375.1174, mean_mc_travel_dist: 1647.9022, mean_rewards: 209.9303, total_rewards: 3755.9924, mean_steps: 25.0100, mean_ecr: 0.0405 mean_entropies: 1.3005, took: 117.8986s
2022-10-11 00:13:35,745 [INFO] 	Process 3 - batch 76899: mean_policy_losses: -19.793, mean_net_lifetime: 4816.6556, mean_mc_travel_dist: 1210.8800, mean_rewards: 274.6700, total_rewards: 3644.6527, mean_steps: 16.6100, mean_ecr: 0.0479 mean_entropies: 0.4719, took: 84.4890s
2022-10-11 00:13:37,556 [INFO] 	Process 2 - batch 71699: mean_policy_losses: -4.162, mean_net_lifetime: 7312.6993, mean_mc_travel_dist: 2012.6370, mean_rewards: 276.6867, total_rewards: 5328.6930, mean_steps: 25.5100, mean_ecr: 0.0383 mean_entropies: 0.4388, took: 121.7785s
2022-10-11 00:13:45,649 [INFO] 	Process 6 - batch 102499: mean_policy_losses: -64.585, mean_net_lifetime: 4134.3808, mean_mc_travel_dist: 1113.3117, mean_rewards: 342.5794, total_rewards: 3072.9642, mean_steps: 11.0300, mean_ecr: 0.0552 mean_entropies: 0.1413, took: 60.7207s
2022-10-11 00:14:34,863 [INFO] 	Process 4 - batch 78299: mean_policy_losses: 189.304, mean_net_lifetime: 7493.2817, mean_mc_travel_dist: 2117.5664, mean_rewards: 274.7040, total_rewards: 5410.4299, mean_steps: 27.4700, mean_ecr: 0.0418 mean_entropies: 0.5878, took: 134.9554s
2022-10-11 00:14:44,332 [INFO] 	Process 6 - batch 102599: mean_policy_losses: -49.031, mean_net_lifetime: 4119.7868, mean_mc_travel_dist: 1113.7543, mean_rewards: 341.7054, total_rewards: 3064.4530, mean_steps: 11.0100, mean_ecr: 0.0551 mean_entropies: 0.1416, took: 58.6835s
2022-10-11 00:14:45,131 [INFO] 	Process 5 - batch 69899: mean_policy_losses: -77.493, mean_net_lifetime: 8921.8077, mean_mc_travel_dist: 2879.3710, mean_rewards: 268.3240, total_rewards: 6085.7577, mean_steps: 33.1200, mean_ecr: 0.0297 mean_entropies: 0.6078, took: 158.6853s
2022-10-11 00:15:01,642 [INFO] 	Process 3 - batch 76999: mean_policy_losses: -12.821, mean_net_lifetime: 4877.9854, mean_mc_travel_dist: 1252.6599, mean_rewards: 269.9096, total_rewards: 3669.4377, mean_steps: 17.1400, mean_ecr: 0.0477 mean_entropies: 0.4597, took: 85.8975s
2022-10-11 00:15:13,247 [INFO] 	Process 7 - batch 72699: mean_policy_losses: -602.519, mean_net_lifetime: 4752.7306, mean_mc_travel_dist: 1443.9160, mean_rewards: 215.3277, total_rewards: 3340.5762, mean_steps: 21.5600, mean_ecr: 0.0411 mean_entropies: 1.3359, took: 104.0884s
2022-10-11 00:15:39,186 [INFO] 	Process 2 - batch 71799: mean_policy_losses: -13.818, mean_net_lifetime: 7239.5322, mean_mc_travel_dist: 1996.4378, mean_rewards: 275.4691, total_rewards: 5273.5317, mean_steps: 25.3100, mean_ecr: 0.0383 mean_entropies: 0.4559, took: 121.6300s
2022-10-11 00:15:43,254 [INFO] 	Process 6 - batch 102699: mean_policy_losses: -89.896, mean_net_lifetime: 4115.5936, mean_mc_travel_dist: 1110.8529, mean_rewards: 343.3114, total_rewards: 3066.8742, mean_steps: 10.9500, mean_ecr: 0.0549 mean_entropies: 0.1330, took: 58.9221s
2022-10-11 00:16:24,694 [INFO] 	Process 3 - batch 77099: mean_policy_losses: 12.674, mean_net_lifetime: 4915.2391, mean_mc_travel_dist: 1255.1388, mean_rewards: 281.8399, total_rewards: 3689.8004, mean_steps: 16.4900, mean_ecr: 0.0476 mean_entropies: 0.4732, took: 83.0520s
2022-10-11 00:16:29,285 [INFO] 	Process 4 - batch 78399: mean_policy_losses: 170.897, mean_net_lifetime: 6608.5596, mean_mc_travel_dist: 1834.3691, mean_rewards: 281.0958, total_rewards: 4809.5407, mean_steps: 23.2700, mean_ecr: 0.0437 mean_entropies: 0.5917, took: 114.4217s
2022-10-11 00:16:36,408 [INFO] 	Process 7 - batch 72799: mean_policy_losses: -826.391, mean_net_lifetime: 4003.0112, mean_mc_travel_dist: 1242.3525, mean_rewards: 227.8474, total_rewards: 2790.9857, mean_steps: 16.8900, mean_ecr: 0.0419 mean_entropies: 1.3652, took: 83.1619s
2022-10-11 00:16:43,070 [INFO] 	Process 6 - batch 102799: mean_policy_losses: -112.619, mean_net_lifetime: 4191.4707, mean_mc_travel_dist: 1130.3422, mean_rewards: 344.5397, total_rewards: 3120.1119, mean_steps: 11.1400, mean_ecr: 0.0550 mean_entropies: 0.1203, took: 59.8161s
2022-10-11 00:17:12,010 [INFO] 	Process 5 - batch 69999: mean_policy_losses: -159.798, mean_net_lifetime: 8614.3885, mean_mc_travel_dist: 2742.4532, mean_rewards: 275.2413, total_rewards: 5924.9143, mean_steps: 30.9700, mean_ecr: 0.0300 mean_entropies: 0.5872, took: 146.8786s
2022-10-11 00:17:42,224 [INFO] 	Process 6 - batch 102899: mean_policy_losses: -60.783, mean_net_lifetime: 4154.0107, mean_mc_travel_dist: 1118.6971, mean_rewards: 343.8748, total_rewards: 3088.7422, mean_steps: 11.0600, mean_ecr: 0.0551 mean_entropies: 0.1335, took: 59.1537s
2022-10-11 00:17:44,127 [INFO] 	Process 2 - batch 71899: mean_policy_losses: 18.296, mean_net_lifetime: 7542.9397, mean_mc_travel_dist: 2080.8885, mean_rewards: 278.5501, total_rewards: 5488.6922, mean_steps: 26.1300, mean_ecr: 0.0380 mean_entropies: 0.4673, took: 124.9408s
2022-10-11 00:17:51,858 [INFO] 	Process 3 - batch 77199: mean_policy_losses: -12.416, mean_net_lifetime: 4890.9813, mean_mc_travel_dist: 1265.2403, mean_rewards: 273.3570, total_rewards: 3659.9033, mean_steps: 16.9400, mean_ecr: 0.0475 mean_entropies: 0.4857, took: 87.1640s
2022-10-11 00:18:18,865 [INFO] 	Process 7 - batch 72899: mean_policy_losses: -588.333, mean_net_lifetime: 4700.9686, mean_mc_travel_dist: 1463.0224, mean_rewards: 212.5618, total_rewards: 3281.5823, mean_steps: 21.4100, mean_ecr: 0.0411 mean_entropies: 1.3349, took: 102.4571s
2022-10-11 00:18:40,427 [INFO] 	Process 4 - batch 78499: mean_policy_losses: 178.724, mean_net_lifetime: 7576.1843, mean_mc_travel_dist: 2142.8512, mean_rewards: 281.2953, total_rewards: 5457.5447, mean_steps: 27.1700, mean_ecr: 0.0425 mean_entropies: 0.5611, took: 131.1422s
2022-10-11 00:18:40,837 [INFO] 	Process 6 - batch 102999: mean_policy_losses: -122.873, mean_net_lifetime: 4042.2353, mean_mc_travel_dist: 1082.5072, mean_rewards: 341.1464, total_rewards: 3003.9291, mean_steps: 10.7600, mean_ecr: 0.0552 mean_entropies: 0.1323, took: 58.6128s
2022-10-11 00:19:16,712 [INFO] 	Process 3 - batch 77299: mean_policy_losses: 8.767, mean_net_lifetime: 4901.4889, mean_mc_travel_dist: 1253.3211, mean_rewards: 279.0806, total_rewards: 3680.0898, mean_steps: 16.6100, mean_ecr: 0.0475 mean_entropies: 0.4849, took: 84.8530s
2022-10-11 00:19:21,101 [INFO] 	Process 5 - batch 70099: mean_policy_losses: -162.796, mean_net_lifetime: 7438.3512, mean_mc_travel_dist: 2380.8006, mean_rewards: 272.2126, total_rewards: 5105.9792, mean_steps: 27.1000, mean_ecr: 0.0303 mean_entropies: 0.5768, took: 129.0921s
2022-10-11 00:19:43,745 [INFO] 	Process 6 - batch 103099: mean_policy_losses: -19.606, mean_net_lifetime: 4303.8085, mean_mc_travel_dist: 1150.9317, mean_rewards: 345.9247, total_rewards: 3199.2871, mean_steps: 11.4300, mean_ecr: 0.0549 mean_entropies: 0.1095, took: 62.9078s
2022-10-11 00:19:45,868 [INFO] 	Process 2 - batch 71999: mean_policy_losses: 0.393, mean_net_lifetime: 7350.4860, mean_mc_travel_dist: 2050.6058, mean_rewards: 280.1013, total_rewards: 5326.7090, mean_steps: 25.3800, mean_ecr: 0.0381 mean_entropies: 0.4524, took: 121.7407s
2022-10-11 00:19:51,077 [INFO] Process 1 - epoch 43: mean_policy_losses: 24.285, mean_net_lifetime: 5147.5066, mean_mc_travel_dist: 2034.1720, mean_entropies: 1.1922, m_net_lifetime_valid: 4514.3403, took: 2385.0415s, (169.2836 / 100 batches)

2022-10-11 00:19:57,492 [INFO] 	Process 7 - batch 72999: mean_policy_losses: -539.098, mean_net_lifetime: 4605.3181, mean_mc_travel_dist: 1413.0758, mean_rewards: 216.3905, total_rewards: 3223.4111, mean_steps: 20.5400, mean_ecr: 0.0412 mean_entropies: 1.3184, took: 98.6260s
2022-10-11 00:20:40,945 [INFO] 	Process 3 - batch 77399: mean_policy_losses: -9.675, mean_net_lifetime: 4940.6598, mean_mc_travel_dist: 1295.8406, mean_rewards: 281.0532, total_rewards: 3675.1439, mean_steps: 16.6400, mean_ecr: 0.0473 mean_entropies: 0.4947, took: 84.2338s
2022-10-11 00:20:43,823 [INFO] 	Process 6 - batch 103199: mean_policy_losses: -87.908, mean_net_lifetime: 4211.0198, mean_mc_travel_dist: 1131.3559, mean_rewards: 343.2640, total_rewards: 3127.8502, mean_steps: 11.2100, mean_ecr: 0.0548 mean_entropies: 0.1318, took: 60.0784s
2022-10-11 00:21:15,157 [INFO] 	Process 4 - batch 78599: mean_policy_losses: 244.074, mean_net_lifetime: 8690.8235, mean_mc_travel_dist: 2522.5154, mean_rewards: 277.5064, total_rewards: 6193.6254, mean_steps: 32.6600, mean_ecr: 0.0416 mean_entropies: 0.5674, took: 154.7297s
2022-10-11 00:21:32,153 [INFO] 	Process 5 - batch 70199: mean_policy_losses: -114.101, mean_net_lifetime: 7815.3703, mean_mc_travel_dist: 2549.4197, mean_rewards: 279.0003, total_rewards: 5314.0050, mean_steps: 27.6000, mean_ecr: 0.0300 mean_entropies: 0.5601, took: 131.0511s
2022-10-11 00:21:39,701 [INFO] 	Process 6 - batch 103299: mean_policy_losses: -91.822, mean_net_lifetime: 3856.9563, mean_mc_travel_dist: 1028.3380, mean_rewards: 340.8963, total_rewards: 2870.9554, mean_steps: 10.2400, mean_ecr: 0.0555 mean_entropies: 0.1554, took: 55.8772s
2022-10-11 00:21:47,057 [INFO] 	Process 1 - batch 64599: mean_policy_losses: -21.288, mean_net_lifetime: 6233.5882, mean_mc_travel_dist: 2036.6121, mean_rewards: 246.7989, total_rewards: 4217.7536, mean_steps: 24.4200, mean_ecr: 0.0382 mean_entropies: 0.9367, took: 755.0758s
2022-10-11 00:21:58,251 [INFO] 	Process 7 - batch 73099: mean_policy_losses: -301.076, mean_net_lifetime: 5317.4605, mean_mc_travel_dist: 1626.3059, mean_rewards: 203.4329, total_rewards: 3732.3714, mean_steps: 25.5400, mean_ecr: 0.0404 mean_entropies: 1.2362, took: 120.7596s
2022-10-11 00:22:09,101 [INFO] 	Process 3 - batch 77499: mean_policy_losses: 21.645, mean_net_lifetime: 4995.9304, mean_mc_travel_dist: 1298.1294, mean_rewards: 274.9506, total_rewards: 3733.5748, mean_steps: 17.2500, mean_ecr: 0.0471 mean_entropies: 0.4862, took: 88.1557s
2022-10-11 00:22:37,744 [INFO] 	Process 6 - batch 103399: mean_policy_losses: -90.516, mean_net_lifetime: 4119.5195, mean_mc_travel_dist: 1099.2728, mean_rewards: 343.5973, total_rewards: 3059.5149, mean_steps: 10.9500, mean_ecr: 0.0550 mean_entropies: 0.1417, took: 58.0437s
2022-10-11 00:23:33,718 [INFO] 	Process 6 - batch 103499: mean_policy_losses: -69.753, mean_net_lifetime: 3976.5122, mean_mc_travel_dist: 1062.5883, mean_rewards: 341.7962, total_rewards: 2967.5402, mean_steps: 10.5900, mean_ecr: 0.0552 mean_entropies: 0.1556, took: 55.9735s
2022-10-11 00:23:36,106 [INFO] 	Process 3 - batch 77599: mean_policy_losses: 10.694, mean_net_lifetime: 5045.8034, mean_mc_travel_dist: 1306.1956, mean_rewards: 279.6989, total_rewards: 3776.0039, mean_steps: 17.0800, mean_ecr: 0.0471 mean_entropies: 0.4649, took: 87.0056s
2022-10-11 00:23:36,913 [INFO] 	Process 4 - batch 78699: mean_policy_losses: 227.058, mean_net_lifetime: 8077.0246, mean_mc_travel_dist: 2289.5126, mean_rewards: 278.9859, total_rewards: 5817.7101, mean_steps: 29.6600, mean_ecr: 0.0422 mean_entropies: 0.5700, took: 141.7561s
2022-10-11 00:23:41,565 [INFO] 	Process 5 - batch 70299: mean_policy_losses: -130.494, mean_net_lifetime: 7493.5014, mean_mc_travel_dist: 2420.3160, mean_rewards: 273.0049, total_rewards: 5118.4724, mean_steps: 26.9000, mean_ecr: 0.0299 mean_entropies: 0.5825, took: 129.4121s
2022-10-11 00:23:44,937 [INFO] 	Process 1 - batch 64699: mean_policy_losses: -4.762, mean_net_lifetime: 6457.1099, mean_mc_travel_dist: 2109.6359, mean_rewards: 250.2364, total_rewards: 4377.0525, mean_steps: 25.0600, mean_ecr: 0.0380 mean_entropies: 0.9533, took: 117.8786s
2022-10-11 00:24:02,413 [INFO] 	Process 7 - batch 73199: mean_policy_losses: -295.343, mean_net_lifetime: 5494.8938, mean_mc_travel_dist: 1640.1022, mean_rewards: 203.0367, total_rewards: 3883.7083, mean_steps: 26.6600, mean_ecr: 0.0402 mean_entropies: 1.2374, took: 124.1614s
2022-10-11 00:25:00,607 [INFO] 	Process 3 - batch 77699: mean_policy_losses: -5.218, mean_net_lifetime: 4939.6287, mean_mc_travel_dist: 1270.4720, mean_rewards: 270.7914, total_rewards: 3697.9552, mean_steps: 17.3200, mean_ecr: 0.0472 mean_entropies: 0.4770, took: 84.5009s
2022-10-11 00:25:38,312 [INFO] 	Process 4 - batch 78799: mean_policy_losses: 156.220, mean_net_lifetime: 6911.8179, mean_mc_travel_dist: 1934.5150, mean_rewards: 273.5745, total_rewards: 5004.6245, mean_steps: 25.4800, mean_ecr: 0.0435 mean_entropies: 0.5528, took: 121.3992s
2022-10-11 00:25:42,267 [INFO] 	Process 1 - batch 64799: mean_policy_losses: -12.271, mean_net_lifetime: 6253.4475, mean_mc_travel_dist: 2033.2016, mean_rewards: 239.4363, total_rewards: 4257.1397, mean_steps: 25.4300, mean_ecr: 0.0381 mean_entropies: 0.9140, took: 117.3311s
2022-10-11 00:25:56,301 [INFO] 	Process 7 - batch 73299: mean_policy_losses: -430.883, mean_net_lifetime: 4943.7769, mean_mc_travel_dist: 1430.2190, mean_rewards: 194.6345, total_rewards: 3542.1110, mean_steps: 24.7200, mean_ecr: 0.0407 mean_entropies: 1.3056, took: 113.8878s
2022-10-11 00:26:27,687 [INFO] 	Process 3 - batch 77799: mean_policy_losses: 12.068, mean_net_lifetime: 4993.1690, mean_mc_travel_dist: 1248.2799, mean_rewards: 274.5584, total_rewards: 3778.6931, mean_steps: 17.2900, mean_ecr: 0.0478 mean_entropies: 0.4458, took: 87.0802s
2022-10-11 00:26:32,902 [INFO] 	Process 5 - batch 70399: mean_policy_losses: -83.797, mean_net_lifetime: 9937.1476, mean_mc_travel_dist: 3320.9210, mean_rewards: 267.8438, total_rewards: 6659.7127, mean_steps: 37.9000, mean_ecr: 0.0294 mean_entropies: 0.5983, took: 171.3378s
2022-10-11 00:27:37,876 [INFO] 	Process 7 - batch 73399: mean_policy_losses: -526.005, mean_net_lifetime: 4589.7669, mean_mc_travel_dist: 1359.7104, mean_rewards: 206.2788, total_rewards: 3258.6652, mean_steps: 21.2900, mean_ecr: 0.0410 mean_entropies: 1.3541, took: 101.5755s
2022-10-11 00:27:38,102 [INFO] 	Process 1 - batch 64899: mean_policy_losses: -4.199, mean_net_lifetime: 6300.8552, mean_mc_travel_dist: 2056.2171, mean_rewards: 243.1984, total_rewards: 4271.6536, mean_steps: 25.1900, mean_ecr: 0.0381 mean_entropies: 0.9193, took: 115.8348s
2022-10-11 00:27:46,852 [INFO] 	Process 4 - batch 78899: mean_policy_losses: 181.404, mean_net_lifetime: 7054.7503, mean_mc_travel_dist: 1993.8565, mean_rewards: 276.7100, total_rewards: 5094.9965, mean_steps: 25.6200, mean_ecr: 0.0429 mean_entropies: 0.5531, took: 128.5398s
2022-10-11 00:27:50,341 [INFO] 	Process 3 - batch 77899: mean_policy_losses: -2.723, mean_net_lifetime: 4903.0319, mean_mc_travel_dist: 1247.6073, mean_rewards: 275.6079, total_rewards: 3690.4770, mean_steps: 16.8100, mean_ecr: 0.0475 mean_entropies: 0.4509, took: 82.6527s
2022-10-11 00:29:10,849 [INFO] 	Process 5 - batch 70499: mean_policy_losses: -90.115, mean_net_lifetime: 9270.1045, mean_mc_travel_dist: 2985.6289, mean_rewards: 266.3786, total_rewards: 6331.9821, mean_steps: 34.7700, mean_ecr: 0.0295 mean_entropies: 0.6133, took: 157.9460s
2022-10-11 00:29:13,662 [INFO] 	Process 3 - batch 77999: mean_policy_losses: -9.514, mean_net_lifetime: 4946.4672, mean_mc_travel_dist: 1274.6472, mean_rewards: 273.6326, total_rewards: 3714.4274, mean_steps: 17.1800, mean_ecr: 0.0476 mean_entropies: 0.4772, took: 83.3218s
2022-10-11 00:29:17,055 [INFO] 	Process 7 - batch 73499: mean_policy_losses: -570.662, mean_net_lifetime: 4564.0405, mean_mc_travel_dist: 1339.3546, mean_rewards: 208.3538, total_rewards: 3255.4775, mean_steps: 21.3800, mean_ecr: 0.0412 mean_entropies: 1.3211, took: 99.1791s
2022-10-11 00:29:38,943 [INFO] 	Process 1 - batch 64999: mean_policy_losses: 10.557, mean_net_lifetime: 6492.2570, mean_mc_travel_dist: 2081.9457, mean_rewards: 247.6095, total_rewards: 4437.8525, mean_steps: 25.3800, mean_ecr: 0.0380 mean_entropies: 0.9454, took: 120.8410s
2022-10-11 00:29:40,314 [INFO] 	Process 4 - batch 78999: mean_policy_losses: 137.979, mean_net_lifetime: 6819.6188, mean_mc_travel_dist: 1918.4243, mean_rewards: 275.2652, total_rewards: 4925.8265, mean_steps: 24.9500, mean_ecr: 0.0437 mean_entropies: 0.5575, took: 113.4621s
2022-10-11 00:30:10,579 [INFO] Process 2 - epoch 48: mean_policy_losses: -2.535, mean_net_lifetime: 4853.1153, mean_mc_travel_dist: 1624.2100, mean_entropies: 0.9202, m_net_lifetime_valid: 4527.1439, took: 2408.4501s, (152.5536 / 100 batches)

2022-10-11 00:31:27,588 [INFO] 	Process 1 - batch 65099: mean_policy_losses: -92.298, mean_net_lifetime: 6430.5219, mean_mc_travel_dist: 2078.6377, mean_rewards: 253.9479, total_rewards: 4379.6886, mean_steps: 24.4800, mean_ecr: 0.0381 mean_entropies: 0.9099, took: 108.6448s
2022-10-11 00:31:37,138 [INFO] 	Process 4 - batch 79099: mean_policy_losses: 89.867, mean_net_lifetime: 7565.4845, mean_mc_travel_dist: 2092.7126, mean_rewards: 279.7639, total_rewards: 5494.9613, mean_steps: 27.4600, mean_ecr: 0.0425 mean_entropies: 0.5318, took: 116.8241s
2022-10-11 00:32:02,003 [INFO] 	Process 2 - batch 72099: mean_policy_losses: -90.689, mean_net_lifetime: 7190.1262, mean_mc_travel_dist: 1984.5343, mean_rewards: 270.3622, total_rewards: 5234.4278, mean_steps: 25.7000, mean_ecr: 0.0384 mean_entropies: 0.4120, took: 736.1362s
2022-10-11 00:33:21,280 [INFO] 	Process 1 - batch 65199: mean_policy_losses: -91.535, mean_net_lifetime: 6446.1521, mean_mc_travel_dist: 2071.5342, mean_rewards: 247.4978, total_rewards: 4400.5558, mean_steps: 25.2800, mean_ecr: 0.0382 mean_entropies: 0.9624, took: 113.6928s
2022-10-11 00:33:34,292 [INFO] 	Process 4 - batch 79199: mean_policy_losses: 116.713, mean_net_lifetime: 7617.4045, mean_mc_travel_dist: 2128.7812, mean_rewards: 282.3013, total_rewards: 5510.9084, mean_steps: 27.2000, mean_ecr: 0.0428 mean_entropies: 0.5191, took: 117.1542s
2022-10-11 00:33:54,425 [INFO] 	Process 2 - batch 72199: mean_policy_losses: -59.584, mean_net_lifetime: 7429.5799, mean_mc_travel_dist: 2051.6456, mean_rewards: 275.0298, total_rewards: 5407.9442, mean_steps: 26.1100, mean_ecr: 0.0381 mean_entropies: 0.4317, took: 112.4210s
2022-10-11 00:33:58,499 [INFO] Process 6 - epoch 69: mean_policy_losses: -203.150, mean_net_lifetime: 3112.3967, mean_mc_travel_dist: 977.3991, mean_entropies: 0.5734, m_net_lifetime_valid: 4773.9978, took: 1505.4561s, (106.3884 / 100 batches)

2022-10-11 00:34:54,235 [INFO] 	Process 6 - batch 103599: mean_policy_losses: -106.581, mean_net_lifetime: 4010.7447, mean_mc_travel_dist: 1077.2303, mean_rewards: 341.7902, total_rewards: 2993.1928, mean_steps: 10.7000, mean_ecr: 0.0550 mean_entropies: 0.1610, took: 680.5173s
2022-10-11 00:35:13,236 [INFO] 	Process 1 - batch 65299: mean_policy_losses: -28.696, mean_net_lifetime: 6572.6578, mean_mc_travel_dist: 2122.9027, mean_rewards: 249.5271, total_rewards: 4477.1718, mean_steps: 25.5200, mean_ecr: 0.0381 mean_entropies: 0.9813, took: 111.9554s
2022-10-11 00:35:43,159 [INFO] 	Process 4 - batch 79299: mean_policy_losses: 99.089, mean_net_lifetime: 7969.0343, mean_mc_travel_dist: 2257.0583, mean_rewards: 280.2514, total_rewards: 5742.2412, mean_steps: 29.1800, mean_ecr: 0.0433 mean_entropies: 0.5596, took: 128.8673s
2022-10-11 00:35:48,028 [INFO] 	Process 6 - batch 103699: mean_policy_losses: -97.294, mean_net_lifetime: 3926.0888, mean_mc_travel_dist: 1060.8679, mean_rewards: 336.9496, total_rewards: 2905.0262, mean_steps: 10.6500, mean_ecr: 0.0551 mean_entropies: 0.1879, took: 53.7928s
2022-10-11 00:35:51,809 [INFO] 	Process 2 - batch 72299: mean_policy_losses: 12.277, mean_net_lifetime: 7608.3310, mean_mc_travel_dist: 2097.3096, mean_rewards: 278.6953, total_rewards: 5543.3216, mean_steps: 26.3800, mean_ecr: 0.0379 mean_entropies: 0.4404, took: 117.3841s
2022-10-11 00:36:42,649 [INFO] 	Process 6 - batch 103799: mean_policy_losses: -80.207, mean_net_lifetime: 4062.8233, mean_mc_travel_dist: 1096.8064, mean_rewards: 343.1412, total_rewards: 3029.8995, mean_steps: 10.8300, mean_ecr: 0.0550 mean_entropies: 0.1472, took: 54.6208s
2022-10-11 00:37:07,070 [INFO] 	Process 1 - batch 65399: mean_policy_losses: 3.298, mean_net_lifetime: 6586.8073, mean_mc_travel_dist: 2119.5037, mean_rewards: 251.4833, total_rewards: 4497.9313, mean_steps: 25.4100, mean_ecr: 0.0380 mean_entropies: 0.9287, took: 113.8348s
2022-10-11 00:37:35,438 [INFO] 	Process 6 - batch 103899: mean_policy_losses: -146.170, mean_net_lifetime: 3752.4607, mean_mc_travel_dist: 1033.4591, mean_rewards: 339.0567, total_rewards: 2756.5103, mean_steps: 10.0500, mean_ecr: 0.0556 mean_entropies: 0.1559, took: 52.7901s
2022-10-11 00:37:43,576 [INFO] 	Process 2 - batch 72399: mean_policy_losses: -47.565, mean_net_lifetime: 7133.0451, mean_mc_travel_dist: 1958.9699, mean_rewards: 274.4603, total_rewards: 5205.3555, mean_steps: 25.0600, mean_ecr: 0.0384 mean_entropies: 0.4189, took: 111.7671s
2022-10-11 00:37:54,075 [INFO] 	Process 4 - batch 79399: mean_policy_losses: 166.289, mean_net_lifetime: 8148.5481, mean_mc_travel_dist: 2335.1056, mean_rewards: 285.0403, total_rewards: 5842.0336, mean_steps: 29.3400, mean_ecr: 0.0421 mean_entropies: 0.5241, took: 130.9151s
2022-10-11 00:38:27,263 [INFO] 	Process 6 - batch 103999: mean_policy_losses: -90.460, mean_net_lifetime: 3780.2389, mean_mc_travel_dist: 1027.7028, mean_rewards: 339.0306, total_rewards: 2794.5947, mean_steps: 10.1400, mean_ecr: 0.0556 mean_entropies: 0.1832, took: 51.8243s
2022-10-11 00:38:36,029 [INFO] Process 3 - epoch 52: mean_policy_losses: 56.843, mean_net_lifetime: 4325.0076, mean_mc_travel_dist: 1346.7586, mean_entropies: 0.8761, m_net_lifetime_valid: 4244.4629, took: 1835.6423s, (141.5598 / 100 batches)

2022-10-11 00:38:55,229 [INFO] 	Process 1 - batch 65499: mean_policy_losses: 47.507, mean_net_lifetime: 6345.7089, mean_mc_travel_dist: 2076.7581, mean_rewards: 255.6565, total_rewards: 4292.8610, mean_steps: 23.9500, mean_ecr: 0.0380 mean_entropies: 0.8941, took: 108.1582s
2022-10-11 00:39:21,171 [INFO] Process 5 - epoch 47: mean_policy_losses: -197.326, mean_net_lifetime: 5118.5714, mean_mc_travel_dist: 1996.2453, mean_entropies: 1.1743, m_net_lifetime_valid: 4511.8613, took: 2721.8001s, (156.5949 / 100 batches)

2022-10-11 00:39:21,466 [INFO] 	Process 6 - batch 104099: mean_policy_losses: -122.010, mean_net_lifetime: 3696.9330, mean_mc_travel_dist: 1007.0226, mean_rewards: 334.0359, total_rewards: 2749.7060, mean_steps: 10.0100, mean_ecr: 0.0557 mean_entropies: 0.1907, took: 54.2034s
2022-10-11 00:39:42,905 [INFO] 	Process 2 - batch 72499: mean_policy_losses: -0.359, mean_net_lifetime: 7472.2202, mean_mc_travel_dist: 2022.5499, mean_rewards: 277.4662, total_rewards: 5474.4685, mean_steps: 25.9900, mean_ecr: 0.0382 mean_entropies: 0.4217, took: 119.3287s
2022-10-11 00:39:58,608 [INFO] 	Process 4 - batch 79499: mean_policy_losses: 112.633, mean_net_lifetime: 7611.2061, mean_mc_travel_dist: 2171.2684, mean_rewards: 286.3493, total_rewards: 5474.3041, mean_steps: 26.9300, mean_ecr: 0.0422 mean_entropies: 0.5238, took: 124.5330s
2022-10-11 00:40:02,578 [INFO] 	Process 3 - batch 78099: mean_policy_losses: -4.181, mean_net_lifetime: 4951.5965, mean_mc_travel_dist: 1267.8470, mean_rewards: 275.3934, total_rewards: 3720.7473, mean_steps: 17.0000, mean_ecr: 0.0471 mean_entropies: 0.4705, took: 648.9159s
2022-10-11 00:40:17,816 [INFO] 	Process 6 - batch 104199: mean_policy_losses: -87.444, mean_net_lifetime: 3902.1145, mean_mc_travel_dist: 1042.6860, mean_rewards: 337.8589, total_rewards: 2901.6338, mean_steps: 10.4900, mean_ecr: 0.0555 mean_entropies: 0.1862, took: 56.3501s
2022-10-11 00:40:23,024 [INFO] Process 7 - epoch 49: mean_policy_losses: -361.825, mean_net_lifetime: 4150.8597, mean_mc_travel_dist: 1555.2615, mean_entropies: 1.5758, m_net_lifetime_valid: 4458.2381, took: 2286.0063s, (150.2204 / 100 batches)

2022-10-11 00:40:59,287 [INFO] 	Process 1 - batch 65599: mean_policy_losses: 18.637, mean_net_lifetime: 6491.3429, mean_mc_travel_dist: 2121.4863, mean_rewards: 246.7179, total_rewards: 4396.3699, mean_steps: 25.6700, mean_ecr: 0.0378 mean_entropies: 0.9105, took: 124.0587s
2022-10-11 00:41:16,924 [INFO] 	Process 6 - batch 104299: mean_policy_losses: -53.086, mean_net_lifetime: 3956.8309, mean_mc_travel_dist: 1081.9253, mean_rewards: 341.1745, total_rewards: 2930.2407, mean_steps: 10.5700, mean_ecr: 0.0553 mean_entropies: 0.1600, took: 59.1080s
2022-10-11 00:41:26,196 [INFO] 	Process 3 - batch 78199: mean_policy_losses: 13.836, mean_net_lifetime: 4964.8745, mean_mc_travel_dist: 1284.7100, mean_rewards: 281.7789, total_rewards: 3717.5860, mean_steps: 16.6500, mean_ecr: 0.0474 mean_entropies: 0.4863, took: 83.6177s
2022-10-11 00:41:44,706 [INFO] 	Process 2 - batch 72599: mean_policy_losses: 2.418, mean_net_lifetime: 7342.4831, mean_mc_travel_dist: 1994.9493, mean_rewards: 277.7937, total_rewards: 5374.7377, mean_steps: 25.5700, mean_ecr: 0.0383 mean_entropies: 0.4269, took: 121.8016s
2022-10-11 00:42:13,653 [INFO] 	Process 6 - batch 104399: mean_policy_losses: -134.010, mean_net_lifetime: 3920.5260, mean_mc_travel_dist: 1057.7900, mean_rewards: 341.9449, total_rewards: 2929.0952, mean_steps: 10.4500, mean_ecr: 0.0549 mean_entropies: 0.1635, took: 56.7283s
2022-10-11 00:42:13,680 [INFO] 	Process 7 - batch 73599: mean_policy_losses: -398.420, mean_net_lifetime: 5097.8164, mean_mc_travel_dist: 1533.4272, mean_rewards: 209.7671, total_rewards: 3596.6380, mean_steps: 23.3800, mean_ecr: 0.0408 mean_entropies: 1.3367, took: 776.6252s
2022-10-11 00:42:40,584 [INFO] 	Process 5 - batch 70599: mean_policy_losses: -113.187, mean_net_lifetime: 10987.8048, mean_mc_travel_dist: 3650.4045, mean_rewards: 260.5369, total_rewards: 7372.2623, mean_steps: 43.0600, mean_ecr: 0.0290 mean_entropies: 0.6477, took: 809.7359s
2022-10-11 00:42:51,908 [INFO] 	Process 3 - batch 78299: mean_policy_losses: -16.708, mean_net_lifetime: 4804.1436, mean_mc_travel_dist: 1231.4966, mean_rewards: 274.1535, total_rewards: 3599.1398, mean_steps: 16.6400, mean_ecr: 0.0476 mean_entropies: 0.4656, took: 85.7121s
2022-10-11 00:43:05,257 [INFO] 	Process 1 - batch 65699: mean_policy_losses: 122.135, mean_net_lifetime: 6570.7554, mean_mc_travel_dist: 2093.2134, mean_rewards: 246.1401, total_rewards: 4503.6163, mean_steps: 25.9900, mean_ecr: 0.0379 mean_entropies: 0.9135, took: 125.9694s
2022-10-11 00:43:09,606 [INFO] 	Process 6 - batch 104499: mean_policy_losses: -62.657, mean_net_lifetime: 3890.9991, mean_mc_travel_dist: 1064.6731, mean_rewards: 339.1682, total_rewards: 2891.2837, mean_steps: 10.4300, mean_ecr: 0.0553 mean_entropies: 0.1618, took: 55.9526s
2022-10-11 00:43:41,462 [INFO] 	Process 2 - batch 72699: mean_policy_losses: -26.946, mean_net_lifetime: 6980.3222, mean_mc_travel_dist: 1883.5390, mean_rewards: 277.3282, total_rewards: 5121.5929, mean_steps: 24.2500, mean_ecr: 0.0387 mean_entropies: 0.4151, took: 116.7560s
2022-10-11 00:44:03,648 [INFO] 	Process 7 - batch 73699: mean_policy_losses: -373.637, mean_net_lifetime: 5046.8859, mean_mc_travel_dist: 1544.9146, mean_rewards: 211.5006, total_rewards: 3536.0476, mean_steps: 23.0100, mean_ecr: 0.0407 mean_entropies: 1.3045, took: 109.9679s
2022-10-11 00:44:08,599 [INFO] 	Process 6 - batch 104599: mean_policy_losses: -77.201, mean_net_lifetime: 4088.7983, mean_mc_travel_dist: 1109.1018, mean_rewards: 342.2776, total_rewards: 3047.9864, mean_steps: 10.9000, mean_ecr: 0.0549 mean_entropies: 0.1344, took: 58.9939s
2022-10-11 00:44:16,958 [INFO] 	Process 3 - batch 78399: mean_policy_losses: 5.378, mean_net_lifetime: 4801.1135, mean_mc_travel_dist: 1218.5162, mean_rewards: 276.8841, total_rewards: 3626.8055, mean_steps: 16.3900, mean_ecr: 0.0477 mean_entropies: 0.4526, took: 85.0506s
2022-10-11 00:45:03,679 [INFO] 	Process 6 - batch 104699: mean_policy_losses: -164.652, mean_net_lifetime: 3855.9638, mean_mc_travel_dist: 1045.3308, mean_rewards: 342.5277, total_rewards: 2876.5415, mean_steps: 10.2300, mean_ecr: 0.0551 mean_entropies: 0.1511, took: 55.0797s
2022-10-11 00:45:04,440 [INFO] 	Process 1 - batch 65799: mean_policy_losses: 19.521, mean_net_lifetime: 6341.1940, mean_mc_travel_dist: 2026.4157, mean_rewards: 247.1025, total_rewards: 4341.3137, mean_steps: 24.7900, mean_ecr: 0.0382 mean_entropies: 0.9631, took: 119.1835s
2022-10-11 00:45:21,793 [INFO] 	Process 5 - batch 70699: mean_policy_losses: -72.831, mean_net_lifetime: 8935.6398, mean_mc_travel_dist: 2937.0807, mean_rewards: 263.6677, total_rewards: 6037.1096, mean_steps: 33.8700, mean_ecr: 0.0291 mean_entropies: 0.6314, took: 161.2077s
2022-10-11 00:45:42,397 [INFO] 	Process 3 - batch 78499: mean_policy_losses: 8.890, mean_net_lifetime: 4984.6429, mean_mc_travel_dist: 1266.0849, mean_rewards: 285.5732, total_rewards: 3753.3723, mean_steps: 16.4900, mean_ecr: 0.0474 mean_entropies: 0.4822, took: 85.4389s
2022-10-11 00:45:45,095 [INFO] 	Process 2 - batch 72799: mean_policy_losses: -11.832, mean_net_lifetime: 7281.1913, mean_mc_travel_dist: 2000.0282, mean_rewards: 273.2742, total_rewards: 5319.2975, mean_steps: 25.7500, mean_ecr: 0.0383 mean_entropies: 0.4122, took: 123.6334s
2022-10-11 00:45:53,081 [INFO] 	Process 7 - batch 73799: mean_policy_losses: -326.174, mean_net_lifetime: 5072.5985, mean_mc_travel_dist: 1523.3581, mean_rewards: 211.6219, total_rewards: 3584.5673, mean_steps: 23.0000, mean_ecr: 0.0408 mean_entropies: 1.3072, took: 109.4326s
2022-10-11 00:46:02,102 [INFO] 	Process 6 - batch 104799: mean_policy_losses: -47.943, mean_net_lifetime: 3979.1382, mean_mc_travel_dist: 1081.6846, mean_rewards: 342.6206, total_rewards: 2969.3444, mean_steps: 10.6000, mean_ecr: 0.0551 mean_entropies: 0.1518, took: 58.4228s
2022-10-11 00:47:01,566 [INFO] 	Process 6 - batch 104899: mean_policy_losses: -60.272, mean_net_lifetime: 4214.9122, mean_mc_travel_dist: 1135.1577, mean_rewards: 344.9992, total_rewards: 3138.2079, mean_steps: 11.2100, mean_ecr: 0.0548 mean_entropies: 0.1315, took: 59.4641s
2022-10-11 00:47:06,410 [INFO] 	Process 1 - batch 65899: mean_policy_losses: -3.750, mean_net_lifetime: 6219.9864, mean_mc_travel_dist: 1978.1926, mean_rewards: 242.2018, total_rewards: 4275.5888, mean_steps: 24.9900, mean_ecr: 0.0385 mean_entropies: 0.9392, took: 121.9694s
2022-10-11 00:47:07,884 [INFO] 	Process 3 - batch 78599: mean_policy_losses: 8.949, mean_net_lifetime: 4935.3742, mean_mc_travel_dist: 1291.9405, mean_rewards: 282.4370, total_rewards: 3681.2883, mean_steps: 16.5400, mean_ecr: 0.0471 mean_entropies: 0.4892, took: 85.4871s
2022-10-11 00:47:44,663 [INFO] 	Process 7 - batch 73899: mean_policy_losses: -321.990, mean_net_lifetime: 5082.6931, mean_mc_travel_dist: 1525.7637, mean_rewards: 213.0713, total_rewards: 3588.5381, mean_steps: 23.2200, mean_ecr: 0.0408 mean_entropies: 1.3398, took: 111.5826s
2022-10-11 00:47:49,132 [INFO] 	Process 2 - batch 72899: mean_policy_losses: 16.626, mean_net_lifetime: 7490.9032, mean_mc_travel_dist: 2037.2560, mean_rewards: 281.4269, total_rewards: 5485.6852, mean_steps: 25.7000, mean_ecr: 0.0382 mean_entropies: 0.4239, took: 124.0372s
2022-10-11 00:47:59,510 [INFO] 	Process 6 - batch 104999: mean_policy_losses: -68.914, mean_net_lifetime: 4058.1861, mean_mc_travel_dist: 1090.6002, mean_rewards: 343.4203, total_rewards: 3032.6688, mean_steps: 10.7900, mean_ecr: 0.0550 mean_entropies: 0.1395, took: 57.9446s
2022-10-11 00:48:04,803 [INFO] 	Process 5 - batch 70799: mean_policy_losses: -45.202, mean_net_lifetime: 9439.6491, mean_mc_travel_dist: 2985.2417, mean_rewards: 275.3717, total_rewards: 6497.5952, mean_steps: 34.0800, mean_ecr: 0.0297 mean_entropies: 0.6485, took: 163.0099s
2022-10-11 00:48:32,012 [INFO] 	Process 3 - batch 78699: mean_policy_losses: -7.754, mean_net_lifetime: 4971.8933, mean_mc_travel_dist: 1287.9711, mean_rewards: 282.2073, total_rewards: 3716.2437, mean_steps: 16.6300, mean_ecr: 0.0471 mean_entropies: 0.4813, took: 84.1267s
2022-10-11 00:49:19,594 [INFO] 	Process 1 - batch 65999: mean_policy_losses: -0.116, mean_net_lifetime: 6478.5577, mean_mc_travel_dist: 2065.0620, mean_rewards: 226.2375, total_rewards: 4437.6100, mean_steps: 28.0100, mean_ecr: 0.0383 mean_entropies: 0.9274, took: 133.1838s
2022-10-11 00:49:39,147 [INFO] 	Process 7 - batch 73999: mean_policy_losses: -264.683, mean_net_lifetime: 5305.9348, mean_mc_travel_dist: 1589.1682, mean_rewards: 206.0733, total_rewards: 3747.2287, mean_steps: 24.9900, mean_ecr: 0.0406 mean_entropies: 1.3442, took: 114.4832s
2022-10-11 00:49:48,880 [INFO] 	Process 2 - batch 72999: mean_policy_losses: 10.523, mean_net_lifetime: 7462.4007, mean_mc_travel_dist: 2078.4771, mean_rewards: 279.3276, total_rewards: 5416.9220, mean_steps: 25.8100, mean_ecr: 0.0380 mean_entropies: 0.5273, took: 119.7475s
2022-10-11 00:49:53,432 [INFO] 	Process 3 - batch 78799: mean_policy_losses: -3.611, mean_net_lifetime: 4927.1535, mean_mc_travel_dist: 1264.9401, mean_rewards: 280.9396, total_rewards: 3697.3002, mean_steps: 16.6000, mean_ecr: 0.0473 mean_entropies: 0.4758, took: 81.4200s
2022-10-11 00:50:28,920 [INFO] 	Process 5 - batch 70899: mean_policy_losses: -78.861, mean_net_lifetime: 8691.4049, mean_mc_travel_dist: 2664.6841, mean_rewards: 274.1248, total_rewards: 6067.8245, mean_steps: 31.2700, mean_ecr: 0.0299 mean_entropies: 0.6560, took: 144.1180s
2022-10-11 00:50:47,762 [INFO] Process 4 - epoch 53: mean_policy_losses: 94.869, mean_net_lifetime: 4462.8596, mean_mc_travel_dist: 1418.7690, mean_entropies: 1.1189, m_net_lifetime_valid: 4834.9792, took: 2506.1824s, (139.7031 / 100 batches)

2022-10-11 00:51:17,044 [INFO] 	Process 3 - batch 78899: mean_policy_losses: -20.321, mean_net_lifetime: 4915.6602, mean_mc_travel_dist: 1228.8516, mean_rewards: 282.0012, total_rewards: 3717.5523, mean_steps: 16.4800, mean_ecr: 0.0474 mean_entropies: 0.4606, took: 83.6123s
2022-10-11 00:51:29,425 [INFO] 	Process 7 - batch 74099: mean_policy_losses: -352.123, mean_net_lifetime: 5011.1135, mean_mc_travel_dist: 1472.6875, mean_rewards: 197.4881, total_rewards: 3567.1654, mean_steps: 24.7900, mean_ecr: 0.0408 mean_entropies: 1.2836, took: 110.2785s
2022-10-11 00:51:44,944 [INFO] 	Process 2 - batch 73099: mean_policy_losses: -19.261, mean_net_lifetime: 7336.8205, mean_mc_travel_dist: 1993.1034, mean_rewards: 276.9907, total_rewards: 5376.6639, mean_steps: 25.5700, mean_ecr: 0.0384 mean_entropies: 0.4517, took: 116.0638s
2022-10-11 00:52:18,384 [INFO] 	Process 4 - batch 79599: mean_policy_losses: 193.291, mean_net_lifetime: 5518.2817, mean_mc_travel_dist: 1477.1993, mean_rewards: 285.2763, total_rewards: 4073.3279, mean_steps: 18.4900, mean_ecr: 0.0461 mean_entropies: 0.5901, took: 739.7757s
2022-10-11 00:52:40,217 [INFO] 	Process 3 - batch 78999: mean_policy_losses: -21.138, mean_net_lifetime: 4935.0577, mean_mc_travel_dist: 1236.0574, mean_rewards: 277.8274, total_rewards: 3731.8112, mean_steps: 16.8100, mean_ecr: 0.0475 mean_entropies: 0.4576, took: 83.1734s
2022-10-11 00:53:15,832 [INFO] 	Process 5 - batch 70999: mean_policy_losses: -99.550, mean_net_lifetime: 9544.6161, mean_mc_travel_dist: 3019.6408, mean_rewards: 265.6265, total_rewards: 6570.1947, mean_steps: 36.1500, mean_ecr: 0.0294 mean_entropies: 0.6489, took: 166.9119s
2022-10-11 00:53:17,097 [INFO] 	Process 7 - batch 74199: mean_policy_losses: -530.307, mean_net_lifetime: 4824.6884, mean_mc_travel_dist: 1445.3323, mean_rewards: 200.4645, total_rewards: 3412.0590, mean_steps: 23.3000, mean_ecr: 0.0408 mean_entropies: 1.3158, took: 107.6719s
2022-10-11 00:53:47,936 [INFO] 	Process 2 - batch 73199: mean_policy_losses: -17.434, mean_net_lifetime: 7467.7673, mean_mc_travel_dist: 2025.9050, mean_rewards: 273.7426, total_rewards: 5466.5412, mean_steps: 26.3500, mean_ecr: 0.0382 mean_entropies: 0.4206, took: 122.9914s
2022-10-11 00:53:58,169 [INFO] 	Process 4 - batch 79699: mean_policy_losses: 145.905, mean_net_lifetime: 6104.9947, mean_mc_travel_dist: 1664.7552, mean_rewards: 290.0746, total_rewards: 4466.1632, mean_steps: 20.4500, mean_ecr: 0.0446 mean_entropies: 0.5287, took: 99.7847s
2022-10-11 00:54:02,897 [INFO] 	Process 3 - batch 79099: mean_policy_losses: -10.902, mean_net_lifetime: 4978.2345, mean_mc_travel_dist: 1256.3116, mean_rewards: 279.7768, total_rewards: 3757.7223, mean_steps: 16.8400, mean_ecr: 0.0474 mean_entropies: 0.4638, took: 82.6807s
2022-10-11 00:55:00,072 [INFO] 	Process 7 - batch 74299: mean_policy_losses: -546.683, mean_net_lifetime: 4866.9775, mean_mc_travel_dist: 1454.5211, mean_rewards: 210.4738, total_rewards: 3445.0022, mean_steps: 22.3000, mean_ecr: 0.0408 mean_entropies: 1.3290, took: 102.9746s
2022-10-11 00:55:25,545 [INFO] 	Process 3 - batch 79199: mean_policy_losses: -10.889, mean_net_lifetime: 4946.3901, mean_mc_travel_dist: 1251.0639, mean_rewards: 280.7489, total_rewards: 3726.4898, mean_steps: 16.7100, mean_ecr: 0.0473 mean_entropies: 0.4703, took: 82.6477s
2022-10-11 00:55:44,834 [INFO] 	Process 2 - batch 73299: mean_policy_losses: -2.402, mean_net_lifetime: 7250.5399, mean_mc_travel_dist: 1952.7004, mean_rewards: 279.6801, total_rewards: 5319.9403, mean_steps: 25.0300, mean_ecr: 0.0385 mean_entropies: 0.4134, took: 116.8989s
2022-10-11 00:55:48,559 [INFO] 	Process 4 - batch 79799: mean_policy_losses: 138.013, mean_net_lifetime: 6708.1955, mean_mc_travel_dist: 1883.4448, mean_rewards: 284.1109, total_rewards: 4858.5728, mean_steps: 23.2700, mean_ecr: 0.0434 mean_entropies: 0.5414, took: 110.3910s
2022-10-11 00:56:01,458 [INFO] 	Process 5 - batch 71099: mean_policy_losses: -85.619, mean_net_lifetime: 9361.6190, mean_mc_travel_dist: 2976.7033, mean_rewards: 264.2432, total_rewards: 6423.4474, mean_steps: 35.2100, mean_ecr: 0.0295 mean_entropies: 0.6665, took: 165.6259s
2022-10-11 00:56:51,185 [INFO] 	Process 3 - batch 79299: mean_policy_losses: -21.891, mean_net_lifetime: 4978.5460, mean_mc_travel_dist: 1266.8605, mean_rewards: 279.2393, total_rewards: 3738.7563, mean_steps: 16.8900, mean_ecr: 0.0472 mean_entropies: 0.4970, took: 85.6398s
2022-10-11 00:56:59,519 [INFO] 	Process 7 - batch 74399: mean_policy_losses: -455.447, mean_net_lifetime: 5381.3596, mean_mc_travel_dist: 1616.0984, mean_rewards: 199.1643, total_rewards: 3794.7560, mean_steps: 26.2800, mean_ecr: 0.0403 mean_entropies: 1.3147, took: 119.4472s
2022-10-11 00:57:36,384 [INFO] 	Process 4 - batch 79899: mean_policy_losses: 115.378, mean_net_lifetime: 6472.0891, mean_mc_travel_dist: 1763.2062, mean_rewards: 280.8144, total_rewards: 4736.9630, mean_steps: 22.6600, mean_ecr: 0.0439 mean_entropies: 0.5641, took: 107.8249s
2022-10-11 00:57:43,869 [INFO] 	Process 2 - batch 73399: mean_policy_losses: 3.218, mean_net_lifetime: 7435.0087, mean_mc_travel_dist: 2048.4016, mean_rewards: 281.6901, total_rewards: 5417.4263, mean_steps: 25.5400, mean_ecr: 0.0382 mean_entropies: 0.4597, took: 119.0349s
2022-10-11 00:58:15,107 [INFO] 	Process 3 - batch 79399: mean_policy_losses: -12.824, mean_net_lifetime: 5034.0344, mean_mc_travel_dist: 1279.3130, mean_rewards: 283.1717, total_rewards: 3782.6274, mean_steps: 16.8200, mean_ecr: 0.0470 mean_entropies: 0.4846, took: 83.9216s
2022-10-11 00:58:22,043 [INFO] Process 6 - epoch 70: mean_policy_losses: -201.580, mean_net_lifetime: 3124.2165, mean_mc_travel_dist: 978.6858, mean_entropies: 0.5675, m_net_lifetime_valid: 4373.5433, took: 1463.5421s, (106.2647 / 100 batches)

2022-10-11 00:58:48,098 [INFO] 	Process 5 - batch 71199: mean_policy_losses: -98.917, mean_net_lifetime: 9962.1191, mean_mc_travel_dist: 3120.1783, mean_rewards: 269.2759, total_rewards: 6882.7765, mean_steps: 36.9000, mean_ecr: 0.0295 mean_entropies: 0.6527, took: 166.6401s
2022-10-11 00:58:57,187 [INFO] 	Process 7 - batch 74499: mean_policy_losses: -413.204, mean_net_lifetime: 5346.5862, mean_mc_travel_dist: 1568.8637, mean_rewards: 203.5337, total_rewards: 3807.2482, mean_steps: 25.4400, mean_ecr: 0.0404 mean_entropies: 1.3257, took: 117.6682s
2022-10-11 00:59:18,518 [INFO] 	Process 6 - batch 105099: mean_policy_losses: -74.148, mean_net_lifetime: 3993.2759, mean_mc_travel_dist: 1074.0334, mean_rewards: 341.5833, total_rewards: 2972.2804, mean_steps: 10.6800, mean_ecr: 0.0551 mean_entropies: 0.1721, took: 679.0079s
2022-10-11 00:59:41,426 [INFO] 	Process 4 - batch 79999: mean_policy_losses: 167.653, mean_net_lifetime: 7304.3209, mean_mc_travel_dist: 2055.0828, mean_rewards: 281.1788, total_rewards: 5276.3796, mean_steps: 26.0500, mean_ecr: 0.0421 mean_entropies: 0.5433, took: 125.0416s
2022-10-11 00:59:45,279 [INFO] 	Process 3 - batch 79499: mean_policy_losses: 7.715, mean_net_lifetime: 5086.0581, mean_mc_travel_dist: 1328.7997, mean_rewards: 278.2411, total_rewards: 3786.2387, mean_steps: 17.5400, mean_ecr: 0.0469 mean_entropies: 0.4900, took: 90.1722s
2022-10-11 00:59:45,544 [INFO] 	Process 2 - batch 73499: mean_policy_losses: 12.947, mean_net_lifetime: 7394.7282, mean_mc_travel_dist: 2046.3777, mean_rewards: 280.6322, total_rewards: 5375.0024, mean_steps: 25.5500, mean_ecr: 0.0382 mean_entropies: 0.4551, took: 121.6748s
2022-10-11 01:00:10,555 [INFO] 	Process 6 - batch 105199: mean_policy_losses: -130.705, mean_net_lifetime: 3757.1519, mean_mc_travel_dist: 1012.7430, mean_rewards: 341.0828, total_rewards: 2800.2216, mean_steps: 9.9900, mean_ecr: 0.0556 mean_entropies: 0.1835, took: 52.0371s
2022-10-11 01:00:13,868 [INFO] Process 1 - epoch 44: mean_policy_losses: 23.677, mean_net_lifetime: 5176.3071, mean_mc_travel_dist: 2035.0186, mean_entropies: 1.1863, m_net_lifetime_valid: 5073.6085, took: 2422.7890s, (169.0844 / 100 batches)

2022-10-11 01:00:51,285 [INFO] 	Process 7 - batch 74599: mean_policy_losses: -428.477, mean_net_lifetime: 5174.9982, mean_mc_travel_dist: 1549.8344, mean_rewards: 205.4690, total_rewards: 3654.2924, mean_steps: 24.5700, mean_ecr: 0.0404 mean_entropies: 1.3161, took: 114.0983s
2022-10-11 01:01:09,797 [INFO] 	Process 6 - batch 105299: mean_policy_losses: -52.948, mean_net_lifetime: 4120.4528, mean_mc_travel_dist: 1104.8608, mean_rewards: 340.5767, total_rewards: 3068.9454, mean_steps: 11.0400, mean_ecr: 0.0550 mean_entropies: 0.1528, took: 59.2420s
2022-10-11 01:01:27,421 [INFO] 	Process 5 - batch 71299: mean_policy_losses: -39.406, mean_net_lifetime: 9222.8636, mean_mc_travel_dist: 2898.8407, mean_rewards: 265.4164, total_rewards: 6368.5813, mean_steps: 34.3000, mean_ecr: 0.0295 mean_entropies: 0.6452, took: 159.3230s
2022-10-11 01:01:48,651 [INFO] 	Process 4 - batch 80099: mean_policy_losses: 172.201, mean_net_lifetime: 7692.9773, mean_mc_travel_dist: 2161.3220, mean_rewards: 284.7533, total_rewards: 5550.8713, mean_steps: 27.3600, mean_ecr: 0.0423 mean_entropies: 0.5232, took: 127.2248s
2022-10-11 01:02:07,513 [INFO] 	Process 6 - batch 105399: mean_policy_losses: -29.817, mean_net_lifetime: 4208.1638, mean_mc_travel_dist: 1134.5686, mean_rewards: 343.8970, total_rewards: 3134.8185, mean_steps: 11.2200, mean_ecr: 0.0550 mean_entropies: 0.1391, took: 57.7158s
2022-10-11 01:02:12,363 [INFO] 	Process 1 - batch 66099: mean_policy_losses: -7.962, mean_net_lifetime: 6389.5722, mean_mc_travel_dist: 2006.2916, mean_rewards: 238.5427, total_rewards: 4405.8904, mean_steps: 26.0300, mean_ecr: 0.0382 mean_entropies: 0.9314, took: 772.7701s
2022-10-11 01:02:40,425 [INFO] 	Process 7 - batch 74699: mean_policy_losses: -411.662, mean_net_lifetime: 5152.4572, mean_mc_travel_dist: 1536.9117, mean_rewards: 209.7962, total_rewards: 3643.8572, mean_steps: 23.7300, mean_ecr: 0.0406 mean_entropies: 1.3347, took: 109.1396s
2022-10-11 01:03:04,379 [INFO] 	Process 6 - batch 105499: mean_policy_losses: -86.489, mean_net_lifetime: 3984.5059, mean_mc_travel_dist: 1063.0761, mean_rewards: 342.8299, total_rewards: 2966.3739, mean_steps: 10.5800, mean_ecr: 0.0554 mean_entropies: 0.1674, took: 56.8663s
2022-10-11 01:04:03,446 [INFO] 	Process 6 - batch 105599: mean_policy_losses: -52.959, mean_net_lifetime: 4226.6546, mean_mc_travel_dist: 1134.7640, mean_rewards: 344.5942, total_rewards: 3144.5333, mean_steps: 11.2500, mean_ecr: 0.0548 mean_entropies: 0.1316, took: 59.0659s
2022-10-11 01:04:05,815 [INFO] 	Process 4 - batch 80199: mean_policy_losses: 187.379, mean_net_lifetime: 7983.4260, mean_mc_travel_dist: 2309.5123, mean_rewards: 277.2682, total_rewards: 5709.3215, mean_steps: 29.3200, mean_ecr: 0.0415 mean_entropies: 0.5661, took: 137.1642s
2022-10-11 01:04:15,769 [INFO] 	Process 5 - batch 71399: mean_policy_losses: -109.853, mean_net_lifetime: 9757.5436, mean_mc_travel_dist: 3078.2624, mean_rewards: 269.9318, total_rewards: 6720.4220, mean_steps: 36.2400, mean_ecr: 0.0296 mean_entropies: 0.6464, took: 168.3480s
2022-10-11 01:04:16,592 [INFO] 	Process 1 - batch 66199: mean_policy_losses: -13.377, mean_net_lifetime: 6564.3867, mean_mc_travel_dist: 2084.3542, mean_rewards: 239.2975, total_rewards: 4504.6000, mean_steps: 26.6300, mean_ecr: 0.0381 mean_entropies: 0.9541, took: 124.2282s
2022-10-11 01:04:32,815 [INFO] 	Process 7 - batch 74799: mean_policy_losses: -451.709, mean_net_lifetime: 5140.7985, mean_mc_travel_dist: 1551.3303, mean_rewards: 206.9152, total_rewards: 3621.5569, mean_steps: 24.4500, mean_ecr: 0.0406 mean_entropies: 1.3013, took: 112.3907s
2022-10-11 01:05:00,853 [INFO] 	Process 6 - batch 105699: mean_policy_losses: -64.704, mean_net_lifetime: 4046.5847, mean_mc_travel_dist: 1093.6817, mean_rewards: 342.2684, total_rewards: 3018.9297, mean_steps: 10.8000, mean_ecr: 0.0552 mean_entropies: 0.1495, took: 57.4075s
2022-10-11 01:06:00,630 [INFO] 	Process 6 - batch 105799: mean_policy_losses: -22.837, mean_net_lifetime: 4325.8805, mean_mc_travel_dist: 1169.1727, mean_rewards: 343.7484, total_rewards: 3225.5413, mean_steps: 11.5700, mean_ecr: 0.0548 mean_entropies: 0.1198, took: 59.7773s
2022-10-11 01:06:10,900 [INFO] 	Process 7 - batch 74899: mean_policy_losses: -580.957, mean_net_lifetime: 4742.2213, mean_mc_travel_dist: 1422.6080, mean_rewards: 218.3931, total_rewards: 3362.5417, mean_steps: 20.8900, mean_ecr: 0.0412 mean_entropies: 1.4152, took: 98.0847s
2022-10-11 01:06:17,606 [INFO] 	Process 1 - batch 66299: mean_policy_losses: -4.748, mean_net_lifetime: 6390.4502, mean_mc_travel_dist: 2030.7511, mean_rewards: 236.9213, total_rewards: 4385.0641, mean_steps: 26.3200, mean_ecr: 0.0383 mean_entropies: 0.9133, took: 121.0142s
2022-10-11 01:06:30,538 [INFO] 	Process 4 - batch 80299: mean_policy_losses: 196.060, mean_net_lifetime: 8599.4132, mean_mc_travel_dist: 2546.5314, mean_rewards: 284.9023, total_rewards: 6086.0377, mean_steps: 31.5100, mean_ecr: 0.0416 mean_entropies: 0.5253, took: 144.7229s
2022-10-11 01:06:58,840 [INFO] 	Process 6 - batch 105899: mean_policy_losses: -91.917, mean_net_lifetime: 4084.5109, mean_mc_travel_dist: 1103.4213, mean_rewards: 344.5004, total_rewards: 3046.0163, mean_steps: 10.8400, mean_ecr: 0.0549 mean_entropies: 0.1294, took: 58.2101s
2022-10-11 01:07:17,912 [INFO] 	Process 5 - batch 71499: mean_policy_losses: -101.231, mean_net_lifetime: 10527.7093, mean_mc_travel_dist: 3356.6707, mean_rewards: 268.8368, total_rewards: 7215.1739, mean_steps: 39.5100, mean_ecr: 0.0292 mean_entropies: 0.6724, took: 182.1426s
2022-10-11 01:07:44,353 [INFO] 	Process 7 - batch 74999: mean_policy_losses: -602.347, mean_net_lifetime: 4571.2331, mean_mc_travel_dist: 1410.8214, mean_rewards: 219.9295, total_rewards: 3196.8368, mean_steps: 19.9800, mean_ecr: 0.0414 mean_entropies: 1.4308, took: 93.4529s
2022-10-11 01:07:52,379 [INFO] 	Process 6 - batch 105999: mean_policy_losses: -115.995, mean_net_lifetime: 3878.6203, mean_mc_travel_dist: 1044.2989, mean_rewards: 343.4123, total_rewards: 2890.9700, mean_steps: 10.2900, mean_ecr: 0.0553 mean_entropies: 0.1514, took: 53.5384s
2022-10-11 01:08:19,457 [INFO] 	Process 1 - batch 66399: mean_policy_losses: 12.026, mean_net_lifetime: 6533.0742, mean_mc_travel_dist: 2064.1078, mean_rewards: 242.1498, total_rewards: 4496.4714, mean_steps: 26.1800, mean_ecr: 0.0383 mean_entropies: 0.9702, took: 121.8516s
2022-10-11 01:08:46,567 [INFO] 	Process 6 - batch 106099: mean_policy_losses: -91.817, mean_net_lifetime: 3937.5643, mean_mc_travel_dist: 1057.8468, mean_rewards: 341.2009, total_rewards: 2937.7706, mean_steps: 10.4700, mean_ecr: 0.0551 mean_entropies: 0.1461, took: 54.1879s
2022-10-11 01:08:47,291 [INFO] 	Process 4 - batch 80399: mean_policy_losses: 227.725, mean_net_lifetime: 8486.7519, mean_mc_travel_dist: 2490.6558, mean_rewards: 285.7714, total_rewards: 6026.5568, mean_steps: 30.3200, mean_ecr: 0.0413 mean_entropies: 0.5477, took: 136.7529s
2022-10-11 01:09:40,709 [INFO] 	Process 6 - batch 106199: mean_policy_losses: -74.934, mean_net_lifetime: 4021.2390, mean_mc_travel_dist: 1078.4803, mean_rewards: 344.3953, total_rewards: 3008.1604, mean_steps: 10.6600, mean_ecr: 0.0549 mean_entropies: 0.1436, took: 54.1432s
2022-10-11 01:10:01,869 [INFO] 	Process 5 - batch 71599: mean_policy_losses: -107.285, mean_net_lifetime: 9886.8673, mean_mc_travel_dist: 3175.9469, mean_rewards: 269.3392, total_rewards: 6749.4614, mean_steps: 36.8900, mean_ecr: 0.0294 mean_entropies: 0.6968, took: 163.9571s
2022-10-11 01:10:08,867 [INFO] Process 2 - epoch 49: mean_policy_losses: -2.780, mean_net_lifetime: 4904.1068, mean_mc_travel_dist: 1632.1183, mean_entropies: 0.9103, m_net_lifetime_valid: 4455.3121, took: 2398.2864s, (152.7049 / 100 batches)

2022-10-11 01:10:11,353 [INFO] 	Process 1 - batch 66499: mean_policy_losses: -42.076, mean_net_lifetime: 6170.0616, mean_mc_travel_dist: 1992.2602, mean_rewards: 236.9525, total_rewards: 4203.5310, mean_steps: 25.3100, mean_ecr: 0.0383 mean_entropies: 0.9479, took: 111.8951s
2022-10-11 01:10:12,573 [INFO] Process 3 - epoch 53: mean_policy_losses: 55.663, mean_net_lifetime: 4336.7556, mean_mc_travel_dist: 1345.1981, mean_entropies: 0.8686, m_net_lifetime_valid: 4665.7474, took: 1896.5410s, (141.1932 / 100 batches)

2022-10-11 01:10:34,680 [INFO] 	Process 6 - batch 106299: mean_policy_losses: -110.716, mean_net_lifetime: 4019.4411, mean_mc_travel_dist: 1069.6399, mean_rewards: 345.3187, total_rewards: 2994.1930, mean_steps: 10.6200, mean_ecr: 0.0549 mean_entropies: 0.1277, took: 53.9699s
2022-10-11 01:11:18,168 [INFO] 	Process 4 - batch 80499: mean_policy_losses: 175.804, mean_net_lifetime: 8905.0635, mean_mc_travel_dist: 2663.3738, mean_rewards: 281.4777, total_rewards: 6284.0076, mean_steps: 33.2200, mean_ecr: 0.0413 mean_entropies: 0.5311, took: 150.8774s
2022-10-11 01:11:30,827 [INFO] 	Process 6 - batch 106399: mean_policy_losses: -93.641, mean_net_lifetime: 3824.5718, mean_mc_travel_dist: 1042.5410, mean_rewards: 341.1061, total_rewards: 2817.4181, mean_steps: 10.1800, mean_ecr: 0.0555 mean_entropies: 0.1379, took: 56.1477s
2022-10-11 01:11:35,669 [INFO] 	Process 3 - batch 79599: mean_policy_losses: 4.560, mean_net_lifetime: 4980.3860, mean_mc_travel_dist: 1278.0353, mean_rewards: 283.9995, total_rewards: 3731.4781, mean_steps: 16.5700, mean_ecr: 0.0472 mean_entropies: 0.4839, took: 710.3897s
2022-10-11 01:12:10,454 [INFO] 	Process 1 - batch 66599: mean_policy_losses: 27.100, mean_net_lifetime: 6526.1134, mean_mc_travel_dist: 2112.4574, mean_rewards: 254.2481, total_rewards: 4436.1692, mean_steps: 24.8200, mean_ecr: 0.0379 mean_entropies: 0.9350, took: 119.1011s
2022-10-11 01:12:12,047 [INFO] 	Process 2 - batch 73599: mean_policy_losses: 9.768, mean_net_lifetime: 7366.5363, mean_mc_travel_dist: 1998.4863, mean_rewards: 277.2692, total_rewards: 5398.9533, mean_steps: 25.6300, mean_ecr: 0.0384 mean_entropies: 0.4163, took: 746.5028s
2022-10-11 01:12:28,724 [INFO] 	Process 6 - batch 106499: mean_policy_losses: -139.766, mean_net_lifetime: 3880.6632, mean_mc_travel_dist: 1059.1209, mean_rewards: 341.0228, total_rewards: 2876.2621, mean_steps: 10.3600, mean_ecr: 0.0554 mean_entropies: 0.1518, took: 57.8957s
2022-10-11 01:12:48,771 [INFO] 	Process 5 - batch 71699: mean_policy_losses: -147.999, mean_net_lifetime: 9392.2729, mean_mc_travel_dist: 2995.1174, mean_rewards: 268.0648, total_rewards: 6440.9257, mean_steps: 34.9900, mean_ecr: 0.0296 mean_entropies: 0.6326, took: 166.9023s
2022-10-11 01:12:59,537 [INFO] 	Process 3 - batch 79699: mean_policy_losses: -14.678, mean_net_lifetime: 4875.3362, mean_mc_travel_dist: 1239.3154, mean_rewards: 280.1491, total_rewards: 3669.2832, mean_steps: 16.4600, mean_ecr: 0.0474 mean_entropies: 0.4788, took: 83.8689s
2022-10-11 01:13:58,684 [INFO] 	Process 4 - batch 80599: mean_policy_losses: 154.105, mean_net_lifetime: 9287.3859, mean_mc_travel_dist: 2797.9237, mean_rewards: 279.8511, total_rewards: 6522.0378, mean_steps: 35.2300, mean_ecr: 0.0413 mean_entropies: 0.5192, took: 160.5162s
2022-10-11 01:14:10,306 [INFO] 	Process 2 - batch 73699: mean_policy_losses: -36.470, mean_net_lifetime: 7168.3277, mean_mc_travel_dist: 1942.0664, mean_rewards: 271.5327, total_rewards: 5252.7685, mean_steps: 25.4800, mean_ecr: 0.0385 mean_entropies: 0.4398, took: 118.2594s
2022-10-11 01:14:12,599 [INFO] 	Process 1 - batch 66699: mean_policy_losses: -34.702, mean_net_lifetime: 6476.7867, mean_mc_travel_dist: 2094.7849, mean_rewards: 246.7192, total_rewards: 4409.8733, mean_steps: 25.5500, mean_ecr: 0.0379 mean_entropies: 0.9213, took: 122.1450s
2022-10-11 01:14:24,426 [INFO] 	Process 3 - batch 79799: mean_policy_losses: -31.905, mean_net_lifetime: 4861.0521, mean_mc_travel_dist: 1249.0467, mean_rewards: 276.1214, total_rewards: 3645.1141, mean_steps: 16.6500, mean_ecr: 0.0472 mean_entropies: 0.4839, took: 84.8888s
2022-10-11 01:15:20,966 [INFO] 	Process 5 - batch 71799: mean_policy_losses: -152.122, mean_net_lifetime: 8737.9440, mean_mc_travel_dist: 2754.6592, mean_rewards: 268.2854, total_rewards: 6029.3032, mean_steps: 32.1500, mean_ecr: 0.0298 mean_entropies: 0.6283, took: 152.1955s
2022-10-11 01:15:48,307 [INFO] 	Process 3 - batch 79899: mean_policy_losses: -33.307, mean_net_lifetime: 4961.9830, mean_mc_travel_dist: 1253.8348, mean_rewards: 275.8070, total_rewards: 3745.0470, mean_steps: 17.0400, mean_ecr: 0.0475 mean_entropies: 0.4660, took: 83.8810s
2022-10-11 01:16:12,175 [INFO] 	Process 1 - batch 66799: mean_policy_losses: -58.731, mean_net_lifetime: 6557.5206, mean_mc_travel_dist: 2128.7307, mean_rewards: 244.0493, total_rewards: 4456.1381, mean_steps: 26.0700, mean_ecr: 0.0378 mean_entropies: 0.9254, took: 119.5758s
2022-10-11 01:16:13,036 [INFO] 	Process 2 - batch 73799: mean_policy_losses: 8.138, mean_net_lifetime: 7665.3613, mean_mc_travel_dist: 2058.5011, mean_rewards: 279.5995, total_rewards: 5630.9358, mean_steps: 26.4700, mean_ecr: 0.0381 mean_entropies: 0.4319, took: 122.7298s
2022-10-11 01:16:17,123 [INFO] 	Process 4 - batch 80699: mean_policy_losses: 131.959, mean_net_lifetime: 8218.5144, mean_mc_travel_dist: 2397.9773, mean_rewards: 283.9026, total_rewards: 5852.2354, mean_steps: 30.1400, mean_ecr: 0.0423 mean_entropies: 0.5209, took: 138.4387s
2022-10-11 01:17:12,006 [INFO] 	Process 3 - batch 79999: mean_policy_losses: -26.986, mean_net_lifetime: 5032.3296, mean_mc_travel_dist: 1271.2514, mean_rewards: 280.2855, total_rewards: 3798.2124, mean_steps: 17.0000, mean_ecr: 0.0472 mean_entropies: 0.4648, took: 83.6979s
2022-10-11 01:18:12,663 [INFO] 	Process 5 - batch 71899: mean_policy_losses: -185.092, mean_net_lifetime: 9985.5699, mean_mc_travel_dist: 3191.9319, mean_rewards: 271.2577, total_rewards: 6834.8455, mean_steps: 37.3500, mean_ecr: 0.0296 mean_entropies: 0.6744, took: 171.6970s
2022-10-11 01:18:13,416 [INFO] 	Process 1 - batch 66899: mean_policy_losses: -18.368, mean_net_lifetime: 6724.6391, mean_mc_travel_dist: 2163.1564, mean_rewards: 245.9666, total_rewards: 4593.2419, mean_steps: 26.6500, mean_ecr: 0.0378 mean_entropies: 0.9777, took: 121.2413s
2022-10-11 01:18:14,646 [INFO] 	Process 2 - batch 73899: mean_policy_losses: -28.292, mean_net_lifetime: 7399.6446, mean_mc_travel_dist: 2035.8252, mean_rewards: 276.0867, total_rewards: 5391.3995, mean_steps: 25.8600, mean_ecr: 0.0382 mean_entropies: 0.4541, took: 121.6109s
2022-10-11 01:18:34,472 [INFO] 	Process 3 - batch 80099: mean_policy_losses: -38.523, mean_net_lifetime: 4858.4852, mean_mc_travel_dist: 1238.7988, mean_rewards: 276.4678, total_rewards: 3659.4498, mean_steps: 16.6400, mean_ecr: 0.0474 mean_entropies: 0.4914, took: 82.4673s
2022-10-11 01:18:47,524 [INFO] Process 7 - epoch 50: mean_policy_losses: -363.199, mean_net_lifetime: 4168.9337, mean_mc_travel_dist: 1554.4838, mean_entropies: 1.5710, m_net_lifetime_valid: 4642.7595, took: 2304.4974s, (150.2923 / 100 batches)

2022-10-11 01:18:57,488 [INFO] 	Process 4 - batch 80799: mean_policy_losses: 135.395, mean_net_lifetime: 9251.3855, mean_mc_travel_dist: 2764.1432, mean_rewards: 285.6931, total_rewards: 6525.1534, mean_steps: 34.9900, mean_ecr: 0.0423 mean_entropies: 0.5489, took: 160.3641s
2022-10-11 01:20:04,924 [INFO] 	Process 3 - batch 80199: mean_policy_losses: -9.771, mean_net_lifetime: 4977.6996, mean_mc_travel_dist: 1273.5745, mean_rewards: 267.8411, total_rewards: 3746.9849, mean_steps: 17.6500, mean_ecr: 0.0470 mean_entropies: 0.4646, took: 90.4514s
2022-10-11 01:20:15,509 [INFO] 	Process 2 - batch 73999: mean_policy_losses: -28.526, mean_net_lifetime: 7215.3855, mean_mc_travel_dist: 1978.9423, mean_rewards: 278.8772, total_rewards: 5260.0913, mean_steps: 24.9700, mean_ecr: 0.0384 mean_entropies: 0.4406, took: 120.8626s
2022-10-11 01:20:15,879 [INFO] 	Process 1 - batch 66999: mean_policy_losses: -26.165, mean_net_lifetime: 6421.0461, mean_mc_travel_dist: 2090.3284, mean_rewards: 244.4718, total_rewards: 4349.9319, mean_steps: 25.6700, mean_ecr: 0.0379 mean_entropies: 0.9388, took: 122.4628s
2022-10-11 01:20:27,793 [INFO] 	Process 5 - batch 71999: mean_policy_losses: -214.622, mean_net_lifetime: 7730.2753, mean_mc_travel_dist: 2492.2337, mean_rewards: 267.8539, total_rewards: 5286.6998, mean_steps: 28.6000, mean_ecr: 0.0299 mean_entropies: 0.6211, took: 135.1292s
2022-10-11 01:20:42,002 [INFO] 	Process 7 - batch 75099: mean_policy_losses: -429.849, mean_net_lifetime: 5237.2417, mean_mc_travel_dist: 1546.6982, mean_rewards: 213.8729, total_rewards: 3729.1462, mean_steps: 23.8600, mean_ecr: 0.0405 mean_entropies: 1.3128, took: 777.6495s
2022-10-11 01:21:33,392 [INFO] 	Process 3 - batch 80299: mean_policy_losses: -34.326, mean_net_lifetime: 5023.9546, mean_mc_travel_dist: 1263.3619, mean_rewards: 271.1995, total_rewards: 3797.2028, mean_steps: 17.5600, mean_ecr: 0.0471 mean_entropies: 0.4835, took: 88.4684s
2022-10-11 01:21:45,756 [INFO] 	Process 4 - batch 80899: mean_policy_losses: 233.025, mean_net_lifetime: 9435.5637, mean_mc_travel_dist: 2821.1349, mean_rewards: 275.3404, total_rewards: 6647.8960, mean_steps: 36.5800, mean_ecr: 0.0420 mean_entropies: 0.5532, took: 168.2673s
2022-10-11 01:22:13,561 [INFO] 	Process 1 - batch 67099: mean_policy_losses: -50.391, mean_net_lifetime: 6488.4596, mean_mc_travel_dist: 2115.0934, mean_rewards: 252.0265, total_rewards: 4398.2753, mean_steps: 24.9600, mean_ecr: 0.0380 mean_entropies: 0.9534, took: 117.6825s
2022-10-11 01:22:19,557 [INFO] 	Process 2 - batch 74099: mean_policy_losses: -11.547, mean_net_lifetime: 7612.9156, mean_mc_travel_dist: 2105.5118, mean_rewards: 277.4488, total_rewards: 5531.1764, mean_steps: 26.5100, mean_ecr: 0.0379 mean_entropies: 0.4667, took: 124.0471s
2022-10-11 01:22:36,309 [INFO] 	Process 7 - batch 75199: mean_policy_losses: -491.548, mean_net_lifetime: 4996.4268, mean_mc_travel_dist: 1520.8304, mean_rewards: 198.0261, total_rewards: 3513.1745, mean_steps: 24.9100, mean_ecr: 0.0406 mean_entropies: 1.2234, took: 114.3068s
2022-10-11 01:23:02,222 [INFO] 	Process 3 - batch 80399: mean_policy_losses: -48.314, mean_net_lifetime: 4897.0969, mean_mc_travel_dist: 1250.2762, mean_rewards: 260.9542, total_rewards: 3679.9597, mean_steps: 17.8500, mean_ecr: 0.0472 mean_entropies: 0.4549, took: 88.8301s
2022-10-11 01:23:12,596 [INFO] Process 6 - epoch 71: mean_policy_losses: -199.899, mean_net_lifetime: 3136.8419, mean_mc_travel_dist: 980.1525, mean_entropies: 0.5615, m_net_lifetime_valid: 4500.2697, took: 1490.5504s, (106.1477 / 100 batches)

2022-10-11 01:23:37,273 [INFO] 	Process 4 - batch 80999: mean_policy_losses: 143.087, mean_net_lifetime: 6597.1793, mean_mc_travel_dist: 1812.1437, mean_rewards: 283.9776, total_rewards: 4810.6872, mean_steps: 23.3500, mean_ecr: 0.0449 mean_entropies: 0.5271, took: 111.5194s
2022-10-11 01:24:04,353 [INFO] 	Process 1 - batch 67199: mean_policy_losses: -20.192, mean_net_lifetime: 6341.0897, mean_mc_travel_dist: 2084.0817, mean_rewards: 256.8552, total_rewards: 4280.8704, mean_steps: 23.8100, mean_ecr: 0.0380 mean_entropies: 0.9372, took: 110.7916s
2022-10-11 01:24:05,258 [INFO] 	Process 6 - batch 106599: mean_policy_losses: -211.754, mean_net_lifetime: 3684.4069, mean_mc_travel_dist: 991.5603, mean_rewards: 338.5085, total_rewards: 2743.2596, mean_steps: 9.8100, mean_ecr: 0.0555 mean_entropies: 0.2002, took: 696.5349s
2022-10-11 01:24:25,281 [INFO] 	Process 2 - batch 74199: mean_policy_losses: 15.478, mean_net_lifetime: 7621.2693, mean_mc_travel_dist: 2078.4141, mean_rewards: 274.3796, total_rewards: 5565.6050, mean_steps: 26.8900, mean_ecr: 0.0380 mean_entropies: 0.4351, took: 125.7247s
2022-10-11 01:24:28,981 [INFO] 	Process 7 - batch 75299: mean_policy_losses: -370.019, mean_net_lifetime: 5067.0670, mean_mc_travel_dist: 1539.7976, mean_rewards: 201.2679, total_rewards: 3557.0721, mean_steps: 24.4300, mean_ecr: 0.0406 mean_entropies: 1.2317, took: 112.6720s
2022-10-11 01:24:32,979 [INFO] 	Process 3 - batch 80499: mean_policy_losses: -9.811, mean_net_lifetime: 4919.9935, mean_mc_travel_dist: 1244.7646, mean_rewards: 262.4646, total_rewards: 3705.9417, mean_steps: 17.9300, mean_ecr: 0.0473 mean_entropies: 0.4507, took: 90.7558s
2022-10-11 01:24:58,451 [INFO] 	Process 6 - batch 106699: mean_policy_losses: -172.759, mean_net_lifetime: 3660.5863, mean_mc_travel_dist: 981.7316, mean_rewards: 332.5146, total_rewards: 2717.3813, mean_steps: 9.9400, mean_ecr: 0.0555 mean_entropies: 0.2175, took: 53.1928s
2022-10-11 01:25:50,696 [INFO] 	Process 6 - batch 106799: mean_policy_losses: -189.494, mean_net_lifetime: 3744.0886, mean_mc_travel_dist: 990.7217, mean_rewards: 334.3365, total_rewards: 2787.2661, mean_steps: 10.0700, mean_ecr: 0.0555 mean_entropies: 0.2171, took: 52.2454s
2022-10-11 01:26:02,738 [INFO] 	Process 3 - batch 80599: mean_policy_losses: -5.472, mean_net_lifetime: 5025.9560, mean_mc_travel_dist: 1258.3132, mean_rewards: 266.4954, total_rewards: 3807.1880, mean_steps: 18.0400, mean_ecr: 0.0472 mean_entropies: 0.4553, took: 89.7601s
2022-10-11 01:26:04,802 [INFO] 	Process 1 - batch 67299: mean_policy_losses: 78.513, mean_net_lifetime: 6596.8124, mean_mc_travel_dist: 2120.7593, mean_rewards: 245.2707, total_rewards: 4514.7647, mean_steps: 26.2300, mean_ecr: 0.0378 mean_entropies: 0.9160, took: 120.4493s
2022-10-11 01:26:28,293 [INFO] 	Process 2 - batch 74299: mean_policy_losses: 30.459, mean_net_lifetime: 7658.3220, mean_mc_travel_dist: 2091.1494, mean_rewards: 276.4984, total_rewards: 5598.1228, mean_steps: 26.7900, mean_ecr: 0.0379 mean_entropies: 0.4381, took: 123.0116s
2022-10-11 01:26:30,428 [INFO] 	Process 7 - batch 75399: mean_policy_losses: -278.306, mean_net_lifetime: 5368.6131, mean_mc_travel_dist: 1613.5346, mean_rewards: 195.4477, total_rewards: 3789.9648, mean_steps: 26.6800, mean_ecr: 0.0404 mean_entropies: 1.2600, took: 121.4475s
2022-10-11 01:26:44,501 [INFO] 	Process 6 - batch 106899: mean_policy_losses: -122.280, mean_net_lifetime: 3807.9655, mean_mc_travel_dist: 999.1709, mean_rewards: 340.0234, total_rewards: 2842.6602, mean_steps: 10.1400, mean_ecr: 0.0554 mean_entropies: 0.1961, took: 53.8054s
2022-10-11 01:27:28,050 [INFO] 	Process 3 - batch 80699: mean_policy_losses: 4.060, mean_net_lifetime: 4962.4069, mean_mc_travel_dist: 1252.4602, mean_rewards: 277.2946, total_rewards: 3742.7480, mean_steps: 16.9800, mean_ecr: 0.0471 mean_entropies: 0.4711, took: 85.3111s
2022-10-11 01:27:38,985 [INFO] 	Process 6 - batch 106999: mean_policy_losses: -81.458, mean_net_lifetime: 3756.7739, mean_mc_travel_dist: 1013.5324, mean_rewards: 339.7852, total_rewards: 2788.4316, mean_steps: 10.0300, mean_ecr: 0.0554 mean_entropies: 0.1874, took: 54.4831s
2022-10-11 01:28:08,237 [INFO] 	Process 1 - batch 67399: mean_policy_losses: 55.443, mean_net_lifetime: 6545.6537, mean_mc_travel_dist: 2108.0891, mean_rewards: 247.5754, total_rewards: 4467.1272, mean_steps: 25.8300, mean_ecr: 0.0380 mean_entropies: 0.9260, took: 123.4348s
2022-10-11 01:28:17,670 [INFO] 	Process 7 - batch 75499: mean_policy_losses: -312.660, mean_net_lifetime: 4871.3263, mean_mc_travel_dist: 1457.9305, mean_rewards: 201.1809, total_rewards: 3441.1814, mean_steps: 23.5500, mean_ecr: 0.0408 mean_entropies: 1.2325, took: 107.2412s
2022-10-11 01:28:30,551 [INFO] 	Process 2 - batch 74399: mean_policy_losses: 34.212, mean_net_lifetime: 7601.1454, mean_mc_travel_dist: 2048.9070, mean_rewards: 278.5355, total_rewards: 5576.8130, mean_steps: 26.3500, mean_ecr: 0.0381 mean_entropies: 0.4338, took: 122.2578s
2022-10-11 01:28:34,698 [INFO] 	Process 6 - batch 107099: mean_policy_losses: -101.525, mean_net_lifetime: 3969.0830, mean_mc_travel_dist: 1053.6404, mean_rewards: 342.2887, total_rewards: 2949.5963, mean_steps: 10.5700, mean_ecr: 0.0552 mean_entropies: 0.1820, took: 55.7136s
2022-10-11 01:28:54,902 [INFO] 	Process 3 - batch 80799: mean_policy_losses: 15.174, mean_net_lifetime: 4995.5692, mean_mc_travel_dist: 1259.1521, mean_rewards: 273.6465, total_rewards: 3761.1704, mean_steps: 17.3400, mean_ecr: 0.0473 mean_entropies: 0.4858, took: 86.8519s
2022-10-11 01:29:30,117 [INFO] 	Process 6 - batch 107199: mean_policy_losses: -75.720, mean_net_lifetime: 3906.5929, mean_mc_travel_dist: 1062.8342, mean_rewards: 339.6178, total_rewards: 2896.7808, mean_steps: 10.4700, mean_ecr: 0.0554 mean_entropies: 0.1701, took: 55.4186s
2022-10-11 01:30:06,915 [INFO] 	Process 1 - batch 67499: mean_policy_losses: 11.780, mean_net_lifetime: 6367.5280, mean_mc_travel_dist: 2062.0792, mean_rewards: 244.1928, total_rewards: 4327.5259, mean_steps: 25.4600, mean_ecr: 0.0379 mean_entropies: 0.9376, took: 118.6773s
2022-10-11 01:30:09,245 [INFO] 	Process 7 - batch 75599: mean_policy_losses: -221.346, mean_net_lifetime: 5177.5778, mean_mc_travel_dist: 1511.6639, mean_rewards: 205.7603, total_rewards: 3686.8690, mean_steps: 24.6500, mean_ecr: 0.0407 mean_entropies: 1.2594, took: 111.5749s
2022-10-11 01:30:20,632 [INFO] 	Process 3 - batch 80899: mean_policy_losses: 3.954, mean_net_lifetime: 4909.2846, mean_mc_travel_dist: 1218.2929, mean_rewards: 273.8012, total_rewards: 3727.4983, mean_steps: 17.0100, mean_ecr: 0.0473 mean_entropies: 0.4558, took: 85.7311s
2022-10-11 01:30:23,448 [INFO] 	Process 6 - batch 107299: mean_policy_losses: -114.149, mean_net_lifetime: 3973.3417, mean_mc_travel_dist: 1061.4951, mean_rewards: 342.4003, total_rewards: 2961.7286, mean_steps: 10.5300, mean_ecr: 0.0552 mean_entropies: 0.1481, took: 53.3309s
2022-10-11 01:30:27,100 [INFO] 	Process 2 - batch 74499: mean_policy_losses: -0.052, mean_net_lifetime: 7284.9950, mean_mc_travel_dist: 1956.8251, mean_rewards: 277.6351, total_rewards: 5355.5129, mean_steps: 25.3400, mean_ecr: 0.0384 mean_entropies: 0.4081, took: 116.5487s
2022-10-11 01:30:27,136 [INFO] Process 5 - epoch 48: mean_policy_losses: -195.509, mean_net_lifetime: 5209.3844, mean_mc_travel_dist: 2017.5702, mean_entropies: 1.1634, m_net_lifetime_valid: 4497.8668, took: 3065.9625s, (157.6047 / 100 batches)

2022-10-11 01:31:16,216 [INFO] 	Process 6 - batch 107399: mean_policy_losses: -156.316, mean_net_lifetime: 3805.2176, mean_mc_travel_dist: 1018.6375, mean_rewards: 343.1676, total_rewards: 2840.4638, mean_steps: 10.0600, mean_ecr: 0.0550 mean_entropies: 0.1582, took: 52.7680s
2022-10-11 01:31:41,116 [INFO] 	Process 3 - batch 80999: mean_policy_losses: 11.979, mean_net_lifetime: 4891.3287, mean_mc_travel_dist: 1202.5056, mean_rewards: 279.9493, total_rewards: 3724.1992, mean_steps: 16.5100, mean_ecr: 0.0475 mean_entropies: 0.4560, took: 80.4842s
2022-10-11 01:32:01,338 [INFO] 	Process 7 - batch 75699: mean_policy_losses: -234.489, mean_net_lifetime: 5277.5970, mean_mc_travel_dist: 1576.1987, mean_rewards: 207.1834, total_rewards: 3733.8754, mean_steps: 24.9800, mean_ecr: 0.0404 mean_entropies: 1.2792, took: 112.0931s
2022-10-11 01:32:11,254 [INFO] 	Process 6 - batch 107499: mean_policy_losses: -59.874, mean_net_lifetime: 4069.6653, mean_mc_travel_dist: 1089.3271, mean_rewards: 344.3793, total_rewards: 3027.6986, mean_steps: 10.8100, mean_ecr: 0.0548 mean_entropies: 0.1454, took: 55.0381s
2022-10-11 01:32:21,046 [INFO] 	Process 2 - batch 74599: mean_policy_losses: 15.392, mean_net_lifetime: 7158.9949, mean_mc_travel_dist: 1915.2084, mean_rewards: 279.1964, total_rewards: 5270.3113, mean_steps: 24.7100, mean_ecr: 0.0387 mean_entropies: 0.3960, took: 113.9471s
2022-10-11 01:33:03,148 [INFO] 	Process 6 - batch 107599: mean_policy_losses: -63.181, mean_net_lifetime: 3817.4687, mean_mc_travel_dist: 1025.5312, mean_rewards: 343.5465, total_rewards: 2835.6777, mean_steps: 10.1000, mean_ecr: 0.0551 mean_entropies: 0.1667, took: 51.8939s
2022-10-11 01:33:05,229 [INFO] 	Process 5 - batch 72099: mean_policy_losses: -55.885, mean_net_lifetime: 9176.7138, mean_mc_travel_dist: 2958.3853, mean_rewards: 262.0192, total_rewards: 6258.5566, mean_steps: 34.9400, mean_ecr: 0.0295 mean_entropies: 0.6582, took: 757.4358s
2022-10-11 01:33:52,988 [INFO] 	Process 7 - batch 75799: mean_policy_losses: -151.361, mean_net_lifetime: 5301.5182, mean_mc_travel_dist: 1587.7217, mean_rewards: 203.3896, total_rewards: 3747.9882, mean_steps: 25.2800, mean_ecr: 0.0405 mean_entropies: 1.2638, took: 111.6500s
2022-10-11 01:33:54,260 [INFO] 	Process 6 - batch 107699: mean_policy_losses: -70.594, mean_net_lifetime: 3813.2370, mean_mc_travel_dist: 1021.9667, mean_rewards: 343.1483, total_rewards: 2841.4286, mean_steps: 10.0900, mean_ecr: 0.0550 mean_entropies: 0.1518, took: 51.1120s
2022-10-11 01:34:14,894 [INFO] 	Process 2 - batch 74699: mean_policy_losses: 32.828, mean_net_lifetime: 7345.9650, mean_mc_travel_dist: 1976.0860, mean_rewards: 279.1575, total_rewards: 5394.9856, mean_steps: 25.3700, mean_ecr: 0.0384 mean_entropies: 0.4040, took: 113.8470s
2022-10-11 01:34:46,009 [INFO] Process 4 - epoch 54: mean_policy_losses: 96.219, mean_net_lifetime: 4524.1221, mean_mc_travel_dist: 1433.9873, mean_entropies: 1.1082, m_net_lifetime_valid: 5103.6145, took: 2638.2442s, (140.3482 / 100 batches)

2022-10-11 01:34:48,055 [INFO] 	Process 6 - batch 107799: mean_policy_losses: -67.845, mean_net_lifetime: 3960.3130, mean_mc_travel_dist: 1059.5791, mean_rewards: 344.5367, total_rewards: 2957.8658, mean_steps: 10.4700, mean_ecr: 0.0549 mean_entropies: 0.1528, took: 53.7953s
2022-10-11 01:35:35,840 [INFO] 	Process 5 - batch 72199: mean_policy_losses: -70.205, mean_net_lifetime: 9032.7917, mean_mc_travel_dist: 2833.2161, mean_rewards: 268.5861, total_rewards: 6243.4954, mean_steps: 33.3900, mean_ecr: 0.0299 mean_entropies: 0.6565, took: 150.6114s
2022-10-11 01:35:41,615 [INFO] 	Process 7 - batch 75899: mean_policy_losses: -377.444, mean_net_lifetime: 4894.7944, mean_mc_travel_dist: 1469.6481, mean_rewards: 197.3391, total_rewards: 3453.0377, mean_steps: 24.1100, mean_ecr: 0.0408 mean_entropies: 1.3006, took: 108.6275s
2022-10-11 01:35:44,032 [INFO] 	Process 6 - batch 107899: mean_policy_losses: -157.346, mean_net_lifetime: 3827.2167, mean_mc_travel_dist: 1040.7558, mean_rewards: 340.1418, total_rewards: 2849.6740, mean_steps: 10.2100, mean_ecr: 0.0553 mean_entropies: 0.1668, took: 55.9768s
2022-10-11 01:36:16,504 [INFO] 	Process 2 - batch 74799: mean_policy_losses: 46.553, mean_net_lifetime: 7606.9204, mean_mc_travel_dist: 2053.5389, mean_rewards: 275.9151, total_rewards: 5576.9752, mean_steps: 26.6500, mean_ecr: 0.0381 mean_entropies: 0.4259, took: 121.6104s
2022-10-11 01:36:31,955 [INFO] 	Process 4 - batch 81099: mean_policy_losses: 219.186, mean_net_lifetime: 6422.1694, mean_mc_travel_dist: 1782.8296, mean_rewards: 282.7818, total_rewards: 4668.5347, mean_steps: 22.2300, mean_ecr: 0.0441 mean_entropies: 0.5281, took: 774.6813s
2022-10-11 01:36:37,754 [INFO] 	Process 6 - batch 107999: mean_policy_losses: -58.474, mean_net_lifetime: 3787.4580, mean_mc_travel_dist: 1035.8177, mean_rewards: 339.2549, total_rewards: 2799.8122, mean_steps: 10.1600, mean_ecr: 0.0552 mean_entropies: 0.1778, took: 53.7225s
2022-10-11 01:37:31,483 [INFO] 	Process 7 - batch 75999: mean_policy_losses: -395.021, mean_net_lifetime: 5149.7933, mean_mc_travel_dist: 1506.8151, mean_rewards: 205.2971, total_rewards: 3670.8121, mean_steps: 24.3600, mean_ecr: 0.0408 mean_entropies: 1.2916, took: 109.8673s
2022-10-11 01:38:04,897 [INFO] 	Process 5 - batch 72299: mean_policy_losses: -116.837, mean_net_lifetime: 8785.9283, mean_mc_travel_dist: 2700.8632, mean_rewards: 267.8786, total_rewards: 6129.3537, mean_steps: 32.3000, mean_ecr: 0.0300 mean_entropies: 0.6502, took: 149.0572s
2022-10-11 01:38:18,137 [INFO] 	Process 2 - batch 74899: mean_policy_losses: 27.166, mean_net_lifetime: 7705.1450, mean_mc_travel_dist: 2113.8299, mean_rewards: 277.3304, total_rewards: 5621.5255, mean_steps: 26.8500, mean_ecr: 0.0379 mean_entropies: 0.4442, took: 121.6328s
2022-10-11 01:38:28,859 [INFO] 	Process 4 - batch 81199: mean_policy_losses: 134.151, mean_net_lifetime: 7136.8891, mean_mc_travel_dist: 1976.2357, mean_rewards: 279.5565, total_rewards: 5188.1814, mean_steps: 25.5200, mean_ecr: 0.0433 mean_entropies: 0.5479, took: 116.9042s
2022-10-11 01:39:18,766 [INFO] 	Process 7 - batch 76099: mean_policy_losses: -503.544, mean_net_lifetime: 5146.2239, mean_mc_travel_dist: 1531.1845, mean_rewards: 207.1866, total_rewards: 3644.1586, mean_steps: 24.1000, mean_ecr: 0.0406 mean_entropies: 1.2837, took: 107.2830s
2022-10-11 01:40:16,042 [INFO] 	Process 2 - batch 74999: mean_policy_losses: 4.690, mean_net_lifetime: 7684.3964, mean_mc_travel_dist: 2070.3183, mean_rewards: 282.9743, total_rewards: 5636.4398, mean_steps: 26.2400, mean_ecr: 0.0381 mean_entropies: 0.4395, took: 117.9055s
2022-10-11 01:40:30,531 [INFO] 	Process 4 - batch 81299: mean_policy_losses: 135.960, mean_net_lifetime: 7463.3886, mean_mc_travel_dist: 2138.8060, mean_rewards: 280.0981, total_rewards: 5358.6391, mean_steps: 27.2100, mean_ecr: 0.0428 mean_entropies: 0.5255, took: 121.6719s
2022-10-11 01:40:49,751 [INFO] 	Process 5 - batch 72399: mean_policy_losses: -119.101, mean_net_lifetime: 9961.2148, mean_mc_travel_dist: 3117.8582, mean_rewards: 268.6853, total_rewards: 6881.9647, mean_steps: 36.7300, mean_ecr: 0.0294 mean_entropies: 0.6769, took: 164.8538s
2022-10-11 01:40:52,430 [INFO] Process 1 - epoch 45: mean_policy_losses: 23.014, mean_net_lifetime: 5205.1198, mean_mc_travel_dist: 2036.1031, mean_entropies: 1.1808, m_net_lifetime_valid: 4878.0697, took: 2438.5597s, (168.9528 / 100 batches)

2022-10-11 01:40:58,304 [INFO] 	Process 7 - batch 76199: mean_policy_losses: -468.956, mean_net_lifetime: 4879.0332, mean_mc_travel_dist: 1464.4546, mean_rewards: 208.7149, total_rewards: 3456.6216, mean_steps: 22.4400, mean_ecr: 0.0410 mean_entropies: 1.2715, took: 99.5378s
2022-10-11 01:41:38,603 [INFO] Process 3 - epoch 54: mean_policy_losses: 54.369, mean_net_lifetime: 4348.0167, mean_mc_travel_dist: 1343.4388, mean_entropies: 0.8612, m_net_lifetime_valid: 4427.7679, took: 1886.0271s, (140.9441 / 100 batches)

2022-10-11 01:42:36,169 [INFO] 	Process 4 - batch 81399: mean_policy_losses: 218.424, mean_net_lifetime: 7810.3989, mean_mc_travel_dist: 2249.1079, mean_rewards: 284.6014, total_rewards: 5590.7538, mean_steps: 27.5900, mean_ecr: 0.0417 mean_entropies: 0.5128, took: 125.6376s
2022-10-11 01:42:39,489 [INFO] 	Process 7 - batch 76299: mean_policy_losses: -483.390, mean_net_lifetime: 4957.1666, mean_mc_travel_dist: 1473.9103, mean_rewards: 215.6298, total_rewards: 3512.6692, mean_steps: 22.1300, mean_ecr: 0.0409 mean_entropies: 1.2741, took: 101.1854s
2022-10-11 01:42:49,759 [INFO] 	Process 1 - batch 67599: mean_policy_losses: -13.987, mean_net_lifetime: 6273.5923, mean_mc_travel_dist: 2020.2755, mean_rewards: 241.3440, total_rewards: 4278.3157, mean_steps: 25.3300, mean_ecr: 0.0380 mean_entropies: 0.9175, took: 762.8444s
2022-10-11 01:43:02,156 [INFO] 	Process 3 - batch 81099: mean_policy_losses: -1.850, mean_net_lifetime: 5015.1897, mean_mc_travel_dist: 1335.4215, mean_rewards: 279.5963, total_rewards: 3718.4521, mean_steps: 16.9700, mean_ecr: 0.0467 mean_entropies: 0.5164, took: 681.0393s
2022-10-11 01:43:27,790 [INFO] 	Process 5 - batch 72499: mean_policy_losses: -138.051, mean_net_lifetime: 9051.9085, mean_mc_travel_dist: 2827.1958, mean_rewards: 258.0894, total_rewards: 6273.6206, mean_steps: 34.7300, mean_ecr: 0.0298 mean_entropies: 0.6354, took: 158.0397s
2022-10-11 01:44:24,887 [INFO] 	Process 3 - batch 81199: mean_policy_losses: 4.548, mean_net_lifetime: 5023.2963, mean_mc_travel_dist: 1351.3476, mean_rewards: 280.5574, total_rewards: 3709.8338, mean_steps: 16.9300, mean_ecr: 0.0462 mean_entropies: 0.5390, took: 82.7316s
2022-10-11 01:44:31,313 [INFO] 	Process 7 - batch 76399: mean_policy_losses: -452.224, mean_net_lifetime: 5156.5337, mean_mc_travel_dist: 1566.3507, mean_rewards: 206.8994, total_rewards: 3629.5034, mean_steps: 24.4200, mean_ecr: 0.0407 mean_entropies: 1.3163, took: 111.8240s
2022-10-11 01:44:54,546 [INFO] 	Process 4 - batch 81499: mean_policy_losses: 176.880, mean_net_lifetime: 8205.5955, mean_mc_travel_dist: 2353.2015, mean_rewards: 278.4703, total_rewards: 5875.4891, mean_steps: 30.0300, mean_ecr: 0.0415 mean_entropies: 0.5777, took: 138.3779s
2022-10-11 01:44:59,643 [INFO] 	Process 1 - batch 67699: mean_policy_losses: 48.345, mean_net_lifetime: 6732.9849, mean_mc_travel_dist: 2098.5421, mean_rewards: 238.5774, total_rewards: 4671.1098, mean_steps: 27.6100, mean_ecr: 0.0380 mean_entropies: 0.9903, took: 129.8850s
2022-10-11 01:45:50,838 [INFO] 	Process 3 - batch 81299: mean_policy_losses: 7.429, mean_net_lifetime: 5093.6050, mean_mc_travel_dist: 1347.3679, mean_rewards: 280.9441, total_rewards: 3780.7669, mean_steps: 17.1700, mean_ecr: 0.0464 mean_entropies: 0.4962, took: 85.9506s
2022-10-11 01:46:22,276 [INFO] 	Process 7 - batch 76499: mean_policy_losses: -448.741, mean_net_lifetime: 5224.6307, mean_mc_travel_dist: 1571.8819, mean_rewards: 209.3680, total_rewards: 3687.3323, mean_steps: 24.1400, mean_ecr: 0.0406 mean_entropies: 1.2943, took: 110.9632s
2022-10-11 01:46:36,083 [INFO] Process 6 - epoch 72: mean_policy_losses: -198.699, mean_net_lifetime: 3146.5927, mean_mc_travel_dist: 980.8414, mean_entropies: 0.5562, m_net_lifetime_valid: 4408.0720, took: 1403.4837s, (106.0152 / 100 batches)

2022-10-11 01:46:39,507 [INFO] 	Process 5 - batch 72599: mean_policy_losses: -84.138, mean_net_lifetime: 11217.5179, mean_mc_travel_dist: 3545.3824, mean_rewards: 268.8769, total_rewards: 7706.9773, mean_steps: 42.0100, mean_ecr: 0.0291 mean_entropies: 0.6962, took: 191.7160s
2022-10-11 01:46:58,357 [INFO] 	Process 1 - batch 67799: mean_policy_losses: -37.306, mean_net_lifetime: 6358.4415, mean_mc_travel_dist: 2018.5901, mean_rewards: 241.6321, total_rewards: 4361.2003, mean_steps: 25.4900, mean_ecr: 0.0381 mean_entropies: 0.9477, took: 118.7124s
2022-10-11 01:47:06,485 [INFO] 	Process 4 - batch 81599: mean_policy_losses: 160.572, mean_net_lifetime: 7815.5161, mean_mc_travel_dist: 2240.7051, mean_rewards: 279.0996, total_rewards: 5600.3107, mean_steps: 28.4500, mean_ecr: 0.0413 mean_entropies: 0.5368, took: 131.9388s
2022-10-11 01:47:15,810 [INFO] 	Process 3 - batch 81399: mean_policy_losses: -13.124, mean_net_lifetime: 5069.5272, mean_mc_travel_dist: 1348.1190, mean_rewards: 282.4435, total_rewards: 3749.7175, mean_steps: 17.1000, mean_ecr: 0.0466 mean_entropies: 0.4807, took: 84.9720s
2022-10-11 01:47:27,896 [INFO] 	Process 6 - batch 108099: mean_policy_losses: -145.654, mean_net_lifetime: 3699.8710, mean_mc_travel_dist: 992.8556, mean_rewards: 339.4239, total_rewards: 2753.6137, mean_steps: 9.8700, mean_ecr: 0.0556 mean_entropies: 0.1858, took: 650.1414s
2022-10-11 01:48:21,018 [INFO] 	Process 6 - batch 108199: mean_policy_losses: -120.477, mean_net_lifetime: 3789.6388, mean_mc_travel_dist: 1004.0652, mean_rewards: 343.0600, total_rewards: 2821.8165, mean_steps: 10.0100, mean_ecr: 0.0554 mean_entropies: 0.1923, took: 53.1224s
2022-10-11 01:48:39,251 [INFO] 	Process 3 - batch 81499: mean_policy_losses: 4.247, mean_net_lifetime: 5007.0034, mean_mc_travel_dist: 1328.7760, mean_rewards: 278.5879, total_rewards: 3709.3842, mean_steps: 17.0400, mean_ecr: 0.0468 mean_entropies: 0.5095, took: 83.4406s
2022-10-11 01:49:01,504 [INFO] 	Process 1 - batch 67899: mean_policy_losses: 107.309, mean_net_lifetime: 6699.8127, mean_mc_travel_dist: 2121.0743, mean_rewards: 248.2107, total_rewards: 4604.0814, mean_steps: 26.1500, mean_ecr: 0.0380 mean_entropies: 0.9892, took: 123.1481s
2022-10-11 01:49:13,877 [INFO] 	Process 4 - batch 81699: mean_policy_losses: 128.705, mean_net_lifetime: 7630.2507, mean_mc_travel_dist: 2153.0639, mean_rewards: 284.9997, total_rewards: 5503.4094, mean_steps: 27.2900, mean_ecr: 0.0419 mean_entropies: 0.5264, took: 127.3924s
2022-10-11 01:49:14,265 [INFO] 	Process 6 - batch 108299: mean_policy_losses: -112.054, mean_net_lifetime: 3711.9038, mean_mc_travel_dist: 999.0719, mean_rewards: 343.0534, total_rewards: 2756.8914, mean_steps: 9.8000, mean_ecr: 0.0556 mean_entropies: 0.1741, took: 53.2468s
2022-10-11 01:49:39,741 [INFO] 	Process 5 - batch 72699: mean_policy_losses: -88.006, mean_net_lifetime: 10513.9730, mean_mc_travel_dist: 3336.9038, mean_rewards: 268.6053, total_rewards: 7210.5552, mean_steps: 39.5300, mean_ecr: 0.0293 mean_entropies: 0.6802, took: 180.2335s
2022-10-11 01:50:01,770 [INFO] 	Process 3 - batch 81599: mean_policy_losses: 6.025, mean_net_lifetime: 4841.1404, mean_mc_travel_dist: 1266.6553, mean_rewards: 280.8977, total_rewards: 3606.1988, mean_steps: 16.2900, mean_ecr: 0.0470 mean_entropies: 0.5154, took: 82.5187s
2022-10-11 01:50:02,858 [INFO] 	Process 6 - batch 108399: mean_policy_losses: -124.810, mean_net_lifetime: 3500.1364, mean_mc_travel_dist: 951.1262, mean_rewards: 340.0754, total_rewards: 2599.2709, mean_steps: 9.2800, mean_ecr: 0.0558 mean_entropies: 0.1807, took: 48.5938s
2022-10-11 01:50:37,838 [INFO] Process 2 - epoch 50: mean_policy_losses: -2.565, mean_net_lifetime: 4955.4851, mean_mc_travel_dist: 1640.0408, mean_entropies: 0.9007, m_net_lifetime_valid: 4664.0530, took: 2428.9681s, (152.8913 / 100 batches)

2022-10-11 01:50:55,497 [INFO] 	Process 6 - batch 108499: mean_policy_losses: -180.749, mean_net_lifetime: 3527.5538, mean_mc_travel_dist: 953.9187, mean_rewards: 340.5535, total_rewards: 2626.0835, mean_steps: 9.3300, mean_ecr: 0.0555 mean_entropies: 0.1871, took: 52.6375s
2022-10-11 01:50:56,624 [INFO] 	Process 1 - batch 67999: mean_policy_losses: 42.817, mean_net_lifetime: 6480.1332, mean_mc_travel_dist: 2096.4368, mean_rewards: 260.1817, total_rewards: 4411.3095, mean_steps: 23.9900, mean_ecr: 0.0381 mean_entropies: 0.9993, took: 115.1200s
2022-10-11 01:51:07,107 [INFO] 	Process 4 - batch 81799: mean_policy_losses: 68.695, mean_net_lifetime: 6865.7875, mean_mc_travel_dist: 1912.5939, mean_rewards: 292.3135, total_rewards: 4984.5355, mean_steps: 23.6500, mean_ecr: 0.0439 mean_entropies: 0.5532, took: 113.2300s
2022-10-11 01:51:25,264 [INFO] 	Process 3 - batch 81699: mean_policy_losses: -1.103, mean_net_lifetime: 4859.2049, mean_mc_travel_dist: 1236.5030, mean_rewards: 280.0804, total_rewards: 3649.2997, mean_steps: 16.3900, mean_ecr: 0.0474 mean_entropies: 0.5018, took: 83.4939s
2022-10-11 01:51:51,661 [INFO] 	Process 6 - batch 108599: mean_policy_losses: -100.529, mean_net_lifetime: 3757.4464, mean_mc_travel_dist: 1020.5661, mean_rewards: 339.3473, total_rewards: 2790.4496, mean_steps: 10.0500, mean_ecr: 0.0554 mean_entropies: 0.1920, took: 56.1649s
2022-10-11 01:52:39,290 [INFO] 	Process 2 - batch 75099: mean_policy_losses: 40.099, mean_net_lifetime: 7468.2725, mean_mc_travel_dist: 2052.7726, mean_rewards: 285.5331, total_rewards: 5442.3809, mean_steps: 25.2400, mean_ecr: 0.0382 mean_entropies: 0.4827, took: 743.2469s
2022-10-11 01:52:46,461 [INFO] 	Process 6 - batch 108699: mean_policy_losses: -119.300, mean_net_lifetime: 3715.6462, mean_mc_travel_dist: 979.5345, mean_rewards: 341.6579, total_rewards: 2770.1636, mean_steps: 9.8500, mean_ecr: 0.0550 mean_entropies: 0.2137, took: 54.8002s
2022-10-11 01:52:50,351 [INFO] 	Process 3 - batch 81799: mean_policy_losses: 21.382, mean_net_lifetime: 5047.3823, mean_mc_travel_dist: 1286.1003, mean_rewards: 284.8590, total_rewards: 3789.7829, mean_steps: 16.7600, mean_ecr: 0.0469 mean_entropies: 0.5160, took: 85.0882s
2022-10-11 01:52:52,532 [INFO] 	Process 5 - batch 72799: mean_policy_losses: -121.405, mean_net_lifetime: 11044.6801, mean_mc_travel_dist: 3546.5827, mean_rewards: 271.5675, total_rewards: 7539.8474, mean_steps: 41.1500, mean_ecr: 0.0293 mean_entropies: 0.6839, took: 192.7919s
2022-10-11 01:52:54,805 [INFO] 	Process 1 - batch 68099: mean_policy_losses: -37.833, mean_net_lifetime: 6476.6497, mean_mc_travel_dist: 2118.5793, mean_rewards: 257.2352, total_rewards: 4382.8015, mean_steps: 24.3800, mean_ecr: 0.0379 mean_entropies: 0.9665, took: 118.1803s
2022-10-11 01:53:00,933 [INFO] 	Process 4 - batch 81899: mean_policy_losses: 85.672, mean_net_lifetime: 6897.0115, mean_mc_travel_dist: 1895.9539, mean_rewards: 294.1436, total_rewards: 5030.9656, mean_steps: 23.0900, mean_ecr: 0.0434 mean_entropies: 0.5211, took: 113.8250s
2022-10-11 01:53:39,422 [INFO] 	Process 6 - batch 108799: mean_policy_losses: -121.873, mean_net_lifetime: 3654.8794, mean_mc_travel_dist: 987.7091, mean_rewards: 337.2751, total_rewards: 2695.9714, mean_steps: 9.8300, mean_ecr: 0.0556 mean_entropies: 0.2154, took: 52.9609s
2022-10-11 01:54:19,205 [INFO] 	Process 3 - batch 81899: mean_policy_losses: 6.977, mean_net_lifetime: 4947.8551, mean_mc_travel_dist: 1269.1190, mean_rewards: 273.3549, total_rewards: 3712.0749, mean_steps: 17.2000, mean_ecr: 0.0471 mean_entropies: 0.5022, took: 88.8534s
2022-10-11 01:54:35,297 [INFO] 	Process 6 - batch 108899: mean_policy_losses: -147.101, mean_net_lifetime: 3648.1889, mean_mc_travel_dist: 999.2204, mean_rewards: 333.1177, total_rewards: 2688.8103, mean_steps: 9.8900, mean_ecr: 0.0557 mean_entropies: 0.1999, took: 55.8748s
2022-10-11 01:54:36,429 [INFO] 	Process 2 - batch 75199: mean_policy_losses: -10.892, mean_net_lifetime: 6935.3557, mean_mc_travel_dist: 1908.4431, mean_rewards: 277.9285, total_rewards: 5062.5417, mean_steps: 24.0300, mean_ecr: 0.0387 mean_entropies: 0.4525, took: 117.1394s
2022-10-11 01:54:52,056 [INFO] 	Process 1 - batch 68199: mean_policy_losses: 6.202, mean_net_lifetime: 6259.6133, mean_mc_travel_dist: 2039.8636, mean_rewards: 251.1891, total_rewards: 4248.1735, mean_steps: 24.1600, mean_ecr: 0.0382 mean_entropies: 0.9428, took: 117.2518s
2022-10-11 01:55:07,898 [INFO] 	Process 4 - batch 81999: mean_policy_losses: 83.817, mean_net_lifetime: 7398.7973, mean_mc_travel_dist: 2130.9002, mean_rewards: 286.5848, total_rewards: 5299.3969, mean_steps: 25.8200, mean_ecr: 0.0428 mean_entropies: 0.5449, took: 126.9648s
2022-10-11 01:55:33,315 [INFO] 	Process 6 - batch 108999: mean_policy_losses: -116.625, mean_net_lifetime: 3964.9709, mean_mc_travel_dist: 1052.6365, mean_rewards: 341.4180, total_rewards: 2947.6714, mean_steps: 10.5800, mean_ecr: 0.0552 mean_entropies: 0.1868, took: 58.0184s
2022-10-11 01:55:45,292 [INFO] 	Process 3 - batch 81999: mean_policy_losses: 22.905, mean_net_lifetime: 4939.9457, mean_mc_travel_dist: 1250.2469, mean_rewards: 276.8412, total_rewards: 3716.5842, mean_steps: 16.9200, mean_ecr: 0.0472 mean_entropies: 0.4699, took: 86.0864s
2022-10-11 01:55:57,582 [INFO] 	Process 5 - batch 72899: mean_policy_losses: -129.119, mean_net_lifetime: 10113.8910, mean_mc_travel_dist: 3215.1574, mean_rewards: 260.3940, total_rewards: 6943.7077, mean_steps: 38.8600, mean_ecr: 0.0293 mean_entropies: 0.6947, took: 185.0501s
2022-10-11 01:56:30,846 [INFO] 	Process 6 - batch 109099: mean_policy_losses: -136.661, mean_net_lifetime: 3884.5984, mean_mc_travel_dist: 1038.7794, mean_rewards: 338.6185, total_rewards: 2885.8113, mean_steps: 10.4100, mean_ecr: 0.0553 mean_entropies: 0.1934, took: 57.5303s
2022-10-11 01:56:35,582 [INFO] 	Process 2 - batch 75299: mean_policy_losses: -25.805, mean_net_lifetime: 7123.2476, mean_mc_travel_dist: 1976.1174, mean_rewards: 280.1659, total_rewards: 5177.1959, mean_steps: 24.5600, mean_ecr: 0.0385 mean_entropies: 0.4916, took: 119.1520s
2022-10-11 01:56:47,461 [INFO] Process 7 - epoch 51: mean_policy_losses: -363.422, mean_net_lifetime: 4187.4585, mean_mc_travel_dist: 1553.9889, mean_entropies: 1.5651, m_net_lifetime_valid: 4266.7726, took: 2279.9356s, (150.3752 / 100 batches)

2022-10-11 01:56:55,425 [INFO] 	Process 1 - batch 68299: mean_policy_losses: 8.999, mean_net_lifetime: 6632.0052, mean_mc_travel_dist: 2128.3879, mean_rewards: 251.1474, total_rewards: 4538.3487, mean_steps: 25.5600, mean_ecr: 0.0378 mean_entropies: 0.9610, took: 123.3682s
2022-10-11 01:57:13,413 [INFO] 	Process 4 - batch 82099: mean_policy_losses: 133.752, mean_net_lifetime: 7338.9818, mean_mc_travel_dist: 2071.4366, mean_rewards: 286.8134, total_rewards: 5305.9431, mean_steps: 25.3300, mean_ecr: 0.0422 mean_entropies: 0.5500, took: 125.5155s
2022-10-11 01:57:15,567 [INFO] 	Process 3 - batch 82099: mean_policy_losses: 8.361, mean_net_lifetime: 4989.6058, mean_mc_travel_dist: 1290.0015, mean_rewards: 276.6297, total_rewards: 3726.0099, mean_steps: 17.1000, mean_ecr: 0.0470 mean_entropies: 0.5146, took: 90.2757s
2022-10-11 01:57:27,507 [INFO] 	Process 6 - batch 109199: mean_policy_losses: -81.410, mean_net_lifetime: 3748.3146, mean_mc_travel_dist: 1012.1216, mean_rewards: 336.4580, total_rewards: 2776.0095, mean_steps: 10.1200, mean_ecr: 0.0558 mean_entropies: 0.2065, took: 56.6615s
2022-10-11 01:58:28,104 [INFO] 	Process 6 - batch 109299: mean_policy_losses: -77.349, mean_net_lifetime: 3908.9435, mean_mc_travel_dist: 1041.2138, mean_rewards: 338.5270, total_rewards: 2903.5921, mean_steps: 10.4900, mean_ecr: 0.0554 mean_entropies: 0.1799, took: 60.5966s
2022-10-11 01:58:38,402 [INFO] 	Process 7 - batch 76599: mean_policy_losses: -618.596, mean_net_lifetime: 4661.9422, mean_mc_travel_dist: 1457.0906, mean_rewards: 206.4216, total_rewards: 3243.5159, mean_steps: 21.9400, mean_ecr: 0.0410 mean_entropies: 1.2631, took: 736.1261s
2022-10-11 01:58:43,271 [INFO] 	Process 2 - batch 75399: mean_policy_losses: 15.243, mean_net_lifetime: 7226.8270, mean_mc_travel_dist: 1971.1281, mean_rewards: 278.5729, total_rewards: 5290.5931, mean_steps: 25.0000, mean_ecr: 0.0384 mean_entropies: 0.4252, took: 127.6910s
2022-10-11 01:58:45,485 [INFO] 	Process 3 - batch 82199: mean_policy_losses: 28.538, mean_net_lifetime: 5068.1427, mean_mc_travel_dist: 1290.2462, mean_rewards: 281.6378, total_rewards: 3809.6398, mean_steps: 17.0600, mean_ecr: 0.0470 mean_entropies: 0.4735, took: 89.9179s
2022-10-11 01:58:59,142 [INFO] 	Process 5 - batch 72999: mean_policy_losses: -144.086, mean_net_lifetime: 9919.2811, mean_mc_travel_dist: 3142.2455, mean_rewards: 266.3531, total_rewards: 6815.8659, mean_steps: 37.4100, mean_ecr: 0.0298 mean_entropies: 0.6688, took: 181.5601s
2022-10-11 01:59:01,320 [INFO] 	Process 1 - batch 68399: mean_policy_losses: -22.789, mean_net_lifetime: 6325.9556, mean_mc_travel_dist: 2050.4593, mean_rewards: 244.9025, total_rewards: 4296.0644, mean_steps: 25.0600, mean_ecr: 0.0380 mean_entropies: 0.8820, took: 125.8955s
2022-10-11 01:59:11,608 [INFO] 	Process 4 - batch 82199: mean_policy_losses: 134.568, mean_net_lifetime: 6695.0414, mean_mc_travel_dist: 1836.7867, mean_rewards: 285.5395, total_rewards: 4886.8714, mean_steps: 22.9500, mean_ecr: 0.0438 mean_entropies: 0.5936, took: 118.1958s
2022-10-11 01:59:27,481 [INFO] 	Process 6 - batch 109399: mean_policy_losses: -98.048, mean_net_lifetime: 3814.9206, mean_mc_travel_dist: 1019.3419, mean_rewards: 339.3405, total_rewards: 2831.7163, mean_steps: 10.2300, mean_ecr: 0.0555 mean_entropies: 0.1780, took: 59.3774s
2022-10-11 02:00:15,939 [INFO] 	Process 3 - batch 82299: mean_policy_losses: 24.929, mean_net_lifetime: 5051.4781, mean_mc_travel_dist: 1305.3187, mean_rewards: 278.7264, total_rewards: 3775.4107, mean_steps: 17.1500, mean_ecr: 0.0467 mean_entropies: 0.5071, took: 90.4542s
2022-10-11 02:00:19,679 [INFO] 	Process 7 - batch 76699: mean_policy_losses: -612.158, mean_net_lifetime: 4418.3573, mean_mc_travel_dist: 1367.4914, mean_rewards: 210.8568, total_rewards: 3085.8622, mean_steps: 20.2300, mean_ecr: 0.0414 mean_entropies: 1.2830, took: 101.2768s
2022-10-11 02:00:24,939 [INFO] 	Process 6 - batch 109499: mean_policy_losses: -175.426, mean_net_lifetime: 3798.1793, mean_mc_travel_dist: 1016.5995, mean_rewards: 338.5190, total_rewards: 2814.4187, mean_steps: 10.1700, mean_ecr: 0.0556 mean_entropies: 0.1711, took: 57.4576s
2022-10-11 02:00:51,112 [INFO] 	Process 2 - batch 75499: mean_policy_losses: 10.008, mean_net_lifetime: 7267.9949, mean_mc_travel_dist: 1978.5139, mean_rewards: 276.6434, total_rewards: 5318.3890, mean_steps: 25.3800, mean_ecr: 0.0383 mean_entropies: 0.4304, took: 127.8403s
2022-10-11 02:01:08,894 [INFO] 	Process 1 - batch 68499: mean_policy_losses: -5.750, mean_net_lifetime: 6515.6731, mean_mc_travel_dist: 2085.9330, mean_rewards: 244.2289, total_rewards: 4458.6548, mean_steps: 25.8600, mean_ecr: 0.0380 mean_entropies: 0.9234, took: 127.5739s
2022-10-11 02:01:10,662 [INFO] 	Process 4 - batch 82299: mean_policy_losses: 165.719, mean_net_lifetime: 6846.5756, mean_mc_travel_dist: 1863.1480, mean_rewards: 288.1578, total_rewards: 5014.6130, mean_steps: 23.5700, mean_ecr: 0.0434 mean_entropies: 0.5577, took: 119.0529s
2022-10-11 02:01:43,926 [INFO] 	Process 5 - batch 73099: mean_policy_losses: -146.016, mean_net_lifetime: 9153.5741, mean_mc_travel_dist: 2809.0146, mean_rewards: 271.4523, total_rewards: 6386.8446, mean_steps: 33.3600, mean_ecr: 0.0299 mean_entropies: 0.6832, took: 164.7835s
2022-10-11 02:01:45,508 [INFO] 	Process 3 - batch 82399: mean_policy_losses: -11.346, mean_net_lifetime: 5190.0606, mean_mc_travel_dist: 1348.8021, mean_rewards: 281.8602, total_rewards: 3873.1331, mean_steps: 17.4800, mean_ecr: 0.0466 mean_entropies: 0.4939, took: 89.5689s
2022-10-11 02:02:12,630 [INFO] 	Process 7 - batch 76799: mean_policy_losses: -531.408, mean_net_lifetime: 5012.5657, mean_mc_travel_dist: 1564.9991, mean_rewards: 211.3054, total_rewards: 3486.1062, mean_steps: 23.3800, mean_ecr: 0.0407 mean_entropies: 1.3112, took: 112.9506s
2022-10-11 02:02:55,929 [INFO] 	Process 2 - batch 75599: mean_policy_losses: -12.066, mean_net_lifetime: 7340.0652, mean_mc_travel_dist: 2014.5893, mean_rewards: 280.0996, total_rewards: 5358.3618, mean_steps: 25.3000, mean_ecr: 0.0383 mean_entropies: 0.4466, took: 124.8171s
2022-10-11 02:03:01,303 [INFO] 	Process 4 - batch 82399: mean_policy_losses: 152.547, mean_net_lifetime: 6377.5940, mean_mc_travel_dist: 1768.4486, mean_rewards: 290.8537, total_rewards: 4642.5579, mean_steps: 21.6500, mean_ecr: 0.0446 mean_entropies: 0.5868, took: 110.6409s
2022-10-11 02:03:12,602 [INFO] 	Process 1 - batch 68599: mean_policy_losses: 23.771, mean_net_lifetime: 6734.6627, mean_mc_travel_dist: 2147.9330, mean_rewards: 254.3682, total_rewards: 4606.5483, mean_steps: 25.6900, mean_ecr: 0.0380 mean_entropies: 0.9220, took: 123.7079s
2022-10-11 02:03:13,254 [INFO] 	Process 3 - batch 82499: mean_policy_losses: -25.476, mean_net_lifetime: 4948.9494, mean_mc_travel_dist: 1306.6866, mean_rewards: 279.1242, total_rewards: 3676.0334, mean_steps: 16.7700, mean_ecr: 0.0469 mean_entropies: 0.5160, took: 87.7461s
2022-10-11 02:03:52,154 [INFO] 	Process 7 - batch 76899: mean_policy_losses: -650.146, mean_net_lifetime: 4452.6639, mean_mc_travel_dist: 1379.3638, mean_rewards: 215.6875, total_rewards: 3108.0620, mean_steps: 20.4800, mean_ecr: 0.0414 mean_entropies: 1.2712, took: 99.5247s
2022-10-11 02:04:18,668 [INFO] 	Process 5 - batch 73199: mean_policy_losses: -167.929, mean_net_lifetime: 8937.3905, mean_mc_travel_dist: 2842.5899, mean_rewards: 272.8542, total_rewards: 6142.7297, mean_steps: 32.2900, mean_ecr: 0.0297 mean_entropies: 0.6615, took: 154.7427s
2022-10-11 02:05:02,386 [INFO] 	Process 2 - batch 75699: mean_policy_losses: -12.477, mean_net_lifetime: 7470.3679, mean_mc_travel_dist: 2076.1415, mean_rewards: 276.3965, total_rewards: 5425.5292, mean_steps: 26.1500, mean_ecr: 0.0380 mean_entropies: 0.4350, took: 126.4568s
2022-10-11 02:05:18,191 [INFO] 	Process 1 - batch 68699: mean_policy_losses: -61.253, mean_net_lifetime: 6552.6250, mean_mc_travel_dist: 2082.7884, mean_rewards: 241.9067, total_rewards: 4491.0149, mean_steps: 26.4100, mean_ecr: 0.0381 mean_entropies: 0.9457, took: 125.5890s
2022-10-11 02:05:25,403 [INFO] 	Process 4 - batch 82499: mean_policy_losses: 229.326, mean_net_lifetime: 8166.2135, mean_mc_travel_dist: 2321.7166, mean_rewards: 275.8841, total_rewards: 5873.6124, mean_steps: 30.2600, mean_ecr: 0.0416 mean_entropies: 0.5488, took: 144.1008s
2022-10-11 02:05:54,168 [INFO] 	Process 7 - batch 76999: mean_policy_losses: -352.359, mean_net_lifetime: 5256.2314, mean_mc_travel_dist: 1593.8096, mean_rewards: 200.2838, total_rewards: 3701.5606, mean_steps: 25.6500, mean_ecr: 0.0405 mean_entropies: 1.2531, took: 122.0142s
2022-10-11 02:07:04,372 [INFO] 	Process 2 - batch 75799: mean_policy_losses: 13.755, mean_net_lifetime: 7508.8920, mean_mc_travel_dist: 2060.4824, mean_rewards: 274.5449, total_rewards: 5481.7462, mean_steps: 26.4600, mean_ecr: 0.0381 mean_entropies: 0.4326, took: 121.9867s
2022-10-11 02:07:09,769 [INFO] 	Process 5 - batch 73299: mean_policy_losses: -103.265, mean_net_lifetime: 10358.7239, mean_mc_travel_dist: 3360.3653, mean_rewards: 273.0314, total_rewards: 7041.1203, mean_steps: 37.9300, mean_ecr: 0.0293 mean_entropies: 0.6420, took: 171.1001s
2022-10-11 02:07:16,599 [INFO] 	Process 1 - batch 68799: mean_policy_losses: -20.414, mean_net_lifetime: 6660.6469, mean_mc_travel_dist: 2123.4456, mean_rewards: 251.0260, total_rewards: 4563.1100, mean_steps: 25.6800, mean_ecr: 0.0380 mean_entropies: 1.0030, took: 118.4085s
2022-10-11 02:07:46,111 [INFO] 	Process 7 - batch 77099: mean_policy_losses: -286.605, mean_net_lifetime: 5312.1976, mean_mc_travel_dist: 1605.8267, mean_rewards: 205.8413, total_rewards: 3736.6524, mean_steps: 25.0800, mean_ecr: 0.0405 mean_entropies: 1.2657, took: 111.9427s
2022-10-11 02:09:04,018 [INFO] 	Process 2 - batch 75899: mean_policy_losses: 2.257, mean_net_lifetime: 7546.8212, mean_mc_travel_dist: 2035.3971, mean_rewards: 277.4188, total_rewards: 5537.5982, mean_steps: 26.3200, mean_ecr: 0.0382 mean_entropies: 0.4285, took: 119.6462s
2022-10-11 02:09:10,101 [INFO] 	Process 1 - batch 68899: mean_policy_losses: -48.201, mean_net_lifetime: 6532.6697, mean_mc_travel_dist: 2105.3770, mean_rewards: 256.9909, total_rewards: 4453.3009, mean_steps: 24.6200, mean_ecr: 0.0380 mean_entropies: 0.9658, took: 113.5022s
2022-10-11 02:09:32,209 [INFO] 	Process 7 - batch 77199: mean_policy_losses: -386.247, mean_net_lifetime: 4923.8462, mean_mc_travel_dist: 1489.5072, mean_rewards: 204.4477, total_rewards: 3462.3564, mean_steps: 23.5700, mean_ecr: 0.0408 mean_entropies: 1.2621, took: 106.0972s
2022-10-11 02:10:01,165 [INFO] 	Process 5 - batch 73399: mean_policy_losses: -96.581, mean_net_lifetime: 10215.3041, mean_mc_travel_dist: 3221.8089, mean_rewards: 267.0289, total_rewards: 7035.0204, mean_steps: 38.3200, mean_ecr: 0.0295 mean_entropies: 0.6523, took: 171.3971s
2022-10-11 02:10:55,568 [INFO] 	Process 1 - batch 68999: mean_policy_losses: 19.403, mean_net_lifetime: 6349.3781, mean_mc_travel_dist: 2088.3653, mean_rewards: 264.5172, total_rewards: 4291.9917, mean_steps: 23.1100, mean_ecr: 0.0380 mean_entropies: 0.9274, took: 105.4662s
2022-10-11 02:10:56,461 [INFO] 	Process 7 - batch 77299: mean_policy_losses: -468.065, mean_net_lifetime: 4128.0197, mean_mc_travel_dist: 1255.8379, mean_rewards: 217.6678, total_rewards: 2901.4962, mean_steps: 18.4000, mean_ecr: 0.0413 mean_entropies: 1.2853, took: 84.2527s
2022-10-11 02:11:01,300 [INFO] 	Process 2 - batch 75999: mean_policy_losses: 10.957, mean_net_lifetime: 7252.4059, mean_mc_travel_dist: 1933.8275, mean_rewards: 271.5293, total_rewards: 5343.9328, mean_steps: 25.7900, mean_ecr: 0.0385 mean_entropies: 0.3919, took: 117.2817s
2022-10-11 02:11:15,669 [INFO] Process 6 - epoch 73: mean_policy_losses: -197.674, mean_net_lifetime: 3154.7445, mean_mc_travel_dist: 981.1666, mean_entropies: 0.5512, m_net_lifetime_valid: 4594.3886, took: 1479.5835s, (105.8665 / 100 batches)

2022-10-11 02:12:07,829 [INFO] 	Process 6 - batch 109599: mean_policy_losses: -160.102, mean_net_lifetime: 3850.7683, mean_mc_travel_dist: 1039.1876, mean_rewards: 337.4160, total_rewards: 2861.7246, mean_steps: 10.3700, mean_ecr: 0.0552 mean_entropies: 0.1840, took: 702.8903s
2022-10-11 02:12:10,130 [INFO] 	Process 5 - batch 73499: mean_policy_losses: -173.696, mean_net_lifetime: 7684.1869, mean_mc_travel_dist: 2360.3879, mean_rewards: 263.9379, total_rewards: 5372.7016, mean_steps: 29.0400, mean_ecr: 0.0300 mean_entropies: 0.6551, took: 128.9638s
2022-10-11 02:12:34,484 [INFO] 	Process 7 - batch 77399: mean_policy_losses: -215.171, mean_net_lifetime: 4595.9656, mean_mc_travel_dist: 1378.5592, mean_rewards: 207.2439, total_rewards: 3245.3285, mean_steps: 21.8700, mean_ecr: 0.0409 mean_entropies: 1.2953, took: 98.0230s
2022-10-11 02:12:50,094 [INFO] Process 3 - epoch 55: mean_policy_losses: 53.480, mean_net_lifetime: 4359.9830, mean_mc_travel_dist: 1342.7226, mean_entropies: 0.8547, m_net_lifetime_valid: 4456.8656, took: 1871.4885s, (140.6753 / 100 batches)

2022-10-11 02:12:59,109 [INFO] 	Process 2 - batch 76099: mean_policy_losses: 56.184, mean_net_lifetime: 7538.5014, mean_mc_travel_dist: 2024.4232, mean_rewards: 277.9934, total_rewards: 5540.0773, mean_steps: 26.2500, mean_ecr: 0.0382 mean_entropies: 0.4316, took: 117.8091s
2022-10-11 02:13:00,741 [INFO] 	Process 6 - batch 109699: mean_policy_losses: -74.651, mean_net_lifetime: 3870.5530, mean_mc_travel_dist: 1050.4848, mean_rewards: 338.3694, total_rewards: 2854.0803, mean_steps: 10.4200, mean_ecr: 0.0553 mean_entropies: 0.1733, took: 52.9121s
2022-10-11 02:13:54,312 [INFO] 	Process 6 - batch 109799: mean_policy_losses: -128.934, mean_net_lifetime: 3919.9335, mean_mc_travel_dist: 1033.3959, mean_rewards: 335.4168, total_rewards: 2921.4892, mean_steps: 10.6400, mean_ecr: 0.0550 mean_entropies: 0.1967, took: 53.5704s
2022-10-11 02:14:10,368 [INFO] 	Process 3 - batch 82599: mean_policy_losses: 33.544, mean_net_lifetime: 5003.3328, mean_mc_travel_dist: 1265.9525, mean_rewards: 278.4655, total_rewards: 3771.6343, mean_steps: 17.0200, mean_ecr: 0.0469 mean_entropies: 0.4912, took: 657.1139s
2022-10-11 02:14:23,371 [INFO] 	Process 7 - batch 77499: mean_policy_losses: -149.448, mean_net_lifetime: 5026.8329, mean_mc_travel_dist: 1459.0356, mean_rewards: 196.9839, total_rewards: 3601.8110, mean_steps: 25.1200, mean_ecr: 0.0407 mean_entropies: 1.2508, took: 108.8868s
2022-10-11 02:14:49,898 [INFO] 	Process 6 - batch 109899: mean_policy_losses: -124.139, mean_net_lifetime: 3958.9724, mean_mc_travel_dist: 1044.6619, mean_rewards: 335.2159, total_rewards: 2955.4003, mean_steps: 10.7500, mean_ecr: 0.0550 mean_entropies: 0.1899, took: 55.5854s
2022-10-11 02:14:54,668 [INFO] 	Process 2 - batch 76199: mean_policy_losses: 33.410, mean_net_lifetime: 7426.6163, mean_mc_travel_dist: 2010.8157, mean_rewards: 276.7796, total_rewards: 5440.1831, mean_steps: 25.9100, mean_ecr: 0.0383 mean_entropies: 0.4043, took: 115.5588s
2022-10-11 02:15:12,209 [INFO] Process 4 - epoch 55: mean_policy_losses: 97.171, mean_net_lifetime: 4574.0717, mean_mc_travel_dist: 1445.1208, mean_entropies: 1.0980, m_net_lifetime_valid: 4432.1374, took: 2426.1974s, (140.8359 / 100 batches)

2022-10-11 02:15:34,023 [INFO] 	Process 3 - batch 82699: mean_policy_losses: 13.625, mean_net_lifetime: 5001.8342, mean_mc_travel_dist: 1269.7850, mean_rewards: 275.2285, total_rewards: 3772.3821, mean_steps: 17.2100, mean_ecr: 0.0473 mean_entropies: 0.4984, took: 83.6556s
2022-10-11 02:15:43,283 [INFO] 	Process 6 - batch 109999: mean_policy_losses: -154.626, mean_net_lifetime: 3739.2529, mean_mc_travel_dist: 994.9594, mean_rewards: 338.5453, total_rewards: 2793.1477, mean_steps: 9.9900, mean_ecr: 0.0551 mean_entropies: 0.1774, took: 53.3856s
2022-10-11 02:16:10,259 [INFO] 	Process 7 - batch 77599: mean_policy_losses: -290.440, mean_net_lifetime: 5004.5952, mean_mc_travel_dist: 1531.0129, mean_rewards: 206.5371, total_rewards: 3514.1604, mean_steps: 23.6100, mean_ecr: 0.0407 mean_entropies: 1.2858, took: 106.8882s
2022-10-11 02:16:36,619 [INFO] 	Process 6 - batch 110099: mean_policy_losses: -104.356, mean_net_lifetime: 3682.5164, mean_mc_travel_dist: 1009.3033, mean_rewards: 334.4560, total_rewards: 2695.5756, mean_steps: 9.9700, mean_ecr: 0.0559 mean_entropies: 0.1610, took: 53.3362s
2022-10-11 02:16:52,889 [INFO] 	Process 4 - batch 82599: mean_policy_losses: 211.770, mean_net_lifetime: 6031.4557, mean_mc_travel_dist: 1653.3702, mean_rewards: 282.5415, total_rewards: 4415.6143, mean_steps: 20.8200, mean_ecr: 0.0448 mean_entropies: 0.5847, took: 687.4842s
2022-10-11 02:16:53,906 [INFO] 	Process 2 - batch 76299: mean_policy_losses: 5.353, mean_net_lifetime: 7261.5227, mean_mc_travel_dist: 1957.9909, mean_rewards: 274.2779, total_rewards: 5328.1377, mean_steps: 25.5500, mean_ecr: 0.0385 mean_entropies: 0.4210, took: 119.2381s
2022-10-11 02:17:00,916 [INFO] 	Process 3 - batch 82799: mean_policy_losses: -1.329, mean_net_lifetime: 4882.4250, mean_mc_travel_dist: 1246.7436, mean_rewards: 264.9774, total_rewards: 3667.3218, mean_steps: 17.6200, mean_ecr: 0.0471 mean_entropies: 0.4707, took: 86.8932s
2022-10-11 02:17:31,375 [INFO] 	Process 6 - batch 110199: mean_policy_losses: -118.859, mean_net_lifetime: 3944.0470, mean_mc_travel_dist: 1064.7987, mean_rewards: 338.0454, total_rewards: 2920.7361, mean_steps: 10.6400, mean_ecr: 0.0551 mean_entropies: 0.1791, took: 54.7559s
2022-10-11 02:18:08,855 [INFO] 	Process 7 - batch 77699: mean_policy_losses: -385.025, mean_net_lifetime: 5352.7982, mean_mc_travel_dist: 1619.8350, mean_rewards: 201.1227, total_rewards: 3762.0626, mean_steps: 26.1900, mean_ecr: 0.0401 mean_entropies: 1.2458, took: 118.5961s
2022-10-11 02:18:24,422 [INFO] 	Process 3 - batch 82899: mean_policy_losses: 13.098, mean_net_lifetime: 5079.6054, mean_mc_travel_dist: 1300.2838, mean_rewards: 281.4908, total_rewards: 3798.0228, mean_steps: 17.0700, mean_ecr: 0.0467 mean_entropies: 0.4846, took: 83.5060s
2022-10-11 02:18:25,499 [INFO] 	Process 6 - batch 110299: mean_policy_losses: -65.558, mean_net_lifetime: 3930.5190, mean_mc_travel_dist: 1050.4035, mean_rewards: 339.8069, total_rewards: 2917.5658, mean_steps: 10.5400, mean_ecr: 0.0555 mean_entropies: 0.1596, took: 54.1239s
2022-10-11 02:18:33,115 [INFO] 	Process 4 - batch 82699: mean_policy_losses: 99.603, mean_net_lifetime: 6037.1579, mean_mc_travel_dist: 1598.8227, mean_rewards: 287.1635, total_rewards: 4462.2887, mean_steps: 20.2500, mean_ecr: 0.0450 mean_entropies: 0.6066, took: 100.2280s
2022-10-11 02:18:55,272 [INFO] 	Process 2 - batch 76399: mean_policy_losses: 25.590, mean_net_lifetime: 7538.2912, mean_mc_travel_dist: 2029.6667, mean_rewards: 279.2662, total_rewards: 5534.3049, mean_steps: 26.0800, mean_ecr: 0.0382 mean_entropies: 0.4068, took: 121.3654s
2022-10-11 02:19:20,381 [INFO] 	Process 6 - batch 110399: mean_policy_losses: -116.406, mean_net_lifetime: 3938.5357, mean_mc_travel_dist: 1057.0587, mean_rewards: 337.7014, total_rewards: 2924.6250, mean_steps: 10.5700, mean_ecr: 0.0554 mean_entropies: 0.1625, took: 54.8825s
2022-10-11 02:19:46,494 [INFO] 	Process 3 - batch 82999: mean_policy_losses: -2.797, mean_net_lifetime: 4902.5128, mean_mc_travel_dist: 1239.0636, mean_rewards: 279.0532, total_rewards: 3688.7873, mean_steps: 16.6200, mean_ecr: 0.0472 mean_entropies: 0.4592, took: 82.0709s
2022-10-11 02:20:09,220 [INFO] 	Process 7 - batch 77799: mean_policy_losses: -316.292, mean_net_lifetime: 5474.7324, mean_mc_travel_dist: 1660.2365, mean_rewards: 204.1506, total_rewards: 3849.8669, mean_steps: 26.2700, mean_ecr: 0.0401 mean_entropies: 1.2614, took: 120.3649s
2022-10-11 02:20:17,137 [INFO] 	Process 6 - batch 110499: mean_policy_losses: -75.341, mean_net_lifetime: 4124.2361, mean_mc_travel_dist: 1088.3837, mean_rewards: 344.1296, total_rewards: 3063.4337, mean_steps: 10.9500, mean_ecr: 0.0552 mean_entropies: 0.1377, took: 56.7555s
2022-10-11 02:20:54,076 [INFO] 	Process 2 - batch 76499: mean_policy_losses: 24.535, mean_net_lifetime: 7369.4504, mean_mc_travel_dist: 1998.0448, mean_rewards: 282.7498, total_rewards: 5398.6450, mean_steps: 25.1700, mean_ecr: 0.0383 mean_entropies: 0.4212, took: 118.8046s
2022-10-11 02:21:11,288 [INFO] 	Process 6 - batch 110599: mean_policy_losses: -139.737, mean_net_lifetime: 3897.9383, mean_mc_travel_dist: 1040.2572, mean_rewards: 339.0837, total_rewards: 2895.3484, mean_steps: 10.4100, mean_ecr: 0.0554 mean_entropies: 0.1532, took: 54.1518s
2022-10-11 02:21:11,596 [INFO] 	Process 3 - batch 83099: mean_policy_losses: -3.701, mean_net_lifetime: 4940.3758, mean_mc_travel_dist: 1280.2063, mean_rewards: 275.0020, total_rewards: 3693.5502, mean_steps: 17.0300, mean_ecr: 0.0467 mean_entropies: 0.4596, took: 85.1024s
2022-10-11 02:21:22,281 [INFO] 	Process 4 - batch 82799: mean_policy_losses: 155.659, mean_net_lifetime: 9894.4931, mean_mc_travel_dist: 2986.6107, mean_rewards: 279.7783, total_rewards: 6941.2336, mean_steps: 37.6600, mean_ecr: 0.0411 mean_entropies: 0.5184, took: 169.1660s
2022-10-11 02:21:59,907 [INFO] Process 1 - epoch 46: mean_policy_losses: 22.528, mean_net_lifetime: 5233.3924, mean_mc_travel_dist: 2037.2401, mean_entropies: 1.1758, m_net_lifetime_valid: 5178.8960, took: 2467.4737s, (168.8289 / 100 batches)

2022-10-11 02:22:04,391 [INFO] 	Process 6 - batch 110699: mean_policy_losses: -123.913, mean_net_lifetime: 3913.7879, mean_mc_travel_dist: 1039.8611, mean_rewards: 338.7360, total_rewards: 2913.1942, mean_steps: 10.4800, mean_ecr: 0.0555 mean_entropies: 0.1602, took: 53.1030s
2022-10-11 02:22:11,980 [INFO] 	Process 7 - batch 77899: mean_policy_losses: -256.179, mean_net_lifetime: 5718.0039, mean_mc_travel_dist: 1748.2307, mean_rewards: 201.5895, total_rewards: 4003.6993, mean_steps: 27.6600, mean_ecr: 0.0399 mean_entropies: 1.3063, took: 122.7591s
2022-10-11 02:22:13,124 [INFO] Process 5 - epoch 49: mean_policy_losses: -193.906, mean_net_lifetime: 5300.5766, mean_mc_travel_dist: 2038.7326, mean_entropies: 1.1533, m_net_lifetime_valid: 4477.9386, took: 3105.9853s, (158.6078 / 100 batches)

2022-10-11 02:22:35,019 [INFO] 	Process 3 - batch 83199: mean_policy_losses: 15.456, mean_net_lifetime: 5028.2670, mean_mc_travel_dist: 1294.9439, mean_rewards: 274.5669, total_rewards: 3766.4769, mean_steps: 17.4000, mean_ecr: 0.0467 mean_entropies: 0.4480, took: 83.4237s
2022-10-11 02:23:02,304 [INFO] 	Process 6 - batch 110799: mean_policy_losses: -125.111, mean_net_lifetime: 3977.8335, mean_mc_travel_dist: 1051.2969, mean_rewards: 340.9321, total_rewards: 2957.8326, mean_steps: 10.6000, mean_ecr: 0.0554 mean_entropies: 0.1492, took: 57.9125s
2022-10-11 02:24:00,164 [INFO] 	Process 6 - batch 110899: mean_policy_losses: -90.386, mean_net_lifetime: 4038.6915, mean_mc_travel_dist: 1073.8789, mean_rewards: 341.5635, total_rewards: 2996.3439, mean_steps: 10.7600, mean_ecr: 0.0554 mean_entropies: 0.1488, took: 57.8596s
2022-10-11 02:24:00,655 [INFO] 	Process 1 - batch 69099: mean_policy_losses: 19.694, mean_net_lifetime: 6220.3284, mean_mc_travel_dist: 1984.6775, mean_rewards: 240.8110, total_rewards: 4262.4106, mean_steps: 25.0200, mean_ecr: 0.0384 mean_entropies: 0.9233, took: 785.0875s
2022-10-11 02:24:02,098 [INFO] 	Process 3 - batch 83299: mean_policy_losses: 16.055, mean_net_lifetime: 5073.8128, mean_mc_travel_dist: 1326.8383, mean_rewards: 280.9609, total_rewards: 3777.3634, mean_steps: 17.1200, mean_ecr: 0.0467 mean_entropies: 0.4699, took: 87.0781s
2022-10-11 02:24:06,135 [INFO] 	Process 4 - batch 82899: mean_policy_losses: 206.544, mean_net_lifetime: 9680.4973, mean_mc_travel_dist: 2850.0433, mean_rewards: 280.0451, total_rewards: 6866.2461, mean_steps: 35.7900, mean_ecr: 0.0399 mean_entropies: 0.5528, took: 163.8534s
2022-10-11 02:24:11,221 [INFO] 	Process 7 - batch 77999: mean_policy_losses: -361.030, mean_net_lifetime: 5376.7905, mean_mc_travel_dist: 1658.0905, mean_rewards: 206.2855, total_rewards: 3751.2680, mean_steps: 25.2700, mean_ecr: 0.0402 mean_entropies: 1.3251, took: 119.2415s
2022-10-11 02:24:45,222 [INFO] 	Process 5 - batch 73599: mean_policy_losses: -236.649, mean_net_lifetime: 8558.0516, mean_mc_travel_dist: 2639.9378, mean_rewards: 268.1937, total_rewards: 5952.6130, mean_steps: 31.7400, mean_ecr: 0.0297 mean_entropies: 0.6490, took: 755.0928s
2022-10-11 02:25:00,450 [INFO] 	Process 6 - batch 110999: mean_policy_losses: -50.040, mean_net_lifetime: 4167.5485, mean_mc_travel_dist: 1101.6192, mean_rewards: 341.8044, total_rewards: 3090.6523, mean_steps: 11.1100, mean_ecr: 0.0551 mean_entropies: 0.1371, took: 60.2866s
2022-10-11 02:25:28,968 [INFO] 	Process 3 - batch 83399: mean_policy_losses: -7.685, mean_net_lifetime: 5152.1311, mean_mc_travel_dist: 1343.9691, mean_rewards: 281.7497, total_rewards: 3833.6857, mean_steps: 17.3300, mean_ecr: 0.0463 mean_entropies: 0.4820, took: 86.8703s
2022-10-11 02:26:04,166 [INFO] 	Process 1 - batch 69199: mean_policy_losses: 21.841, mean_net_lifetime: 6498.1924, mean_mc_travel_dist: 2064.7988, mean_rewards: 237.4087, total_rewards: 4455.7434, mean_steps: 26.6600, mean_ecr: 0.0380 mean_entropies: 0.9117, took: 123.5110s
2022-10-11 02:26:31,890 [INFO] 	Process 4 - batch 82999: mean_policy_losses: 156.236, mean_net_lifetime: 8761.8428, mean_mc_travel_dist: 2539.2921, mean_rewards: 279.0462, total_rewards: 6258.1088, mean_steps: 32.5900, mean_ecr: 0.0408 mean_entropies: 0.5248, took: 145.7541s
2022-10-11 02:26:52,298 [INFO] 	Process 3 - batch 83499: mean_policy_losses: 6.501, mean_net_lifetime: 5153.7467, mean_mc_travel_dist: 1337.0689, mean_rewards: 281.5649, total_rewards: 3847.8630, mean_steps: 17.3500, mean_ecr: 0.0463 mean_entropies: 0.4663, took: 83.3299s
2022-10-11 02:27:12,622 [INFO] 	Process 5 - batch 73699: mean_policy_losses: -306.160, mean_net_lifetime: 9111.9875, mean_mc_travel_dist: 2788.3276, mean_rewards: 269.8007, total_rewards: 6369.0344, mean_steps: 33.6300, mean_ecr: 0.0299 mean_entropies: 0.6462, took: 147.4004s
2022-10-11 02:28:00,539 [INFO] 	Process 1 - batch 69299: mean_policy_losses: -38.164, mean_net_lifetime: 6513.5634, mean_mc_travel_dist: 2093.0312, mean_rewards: 246.1068, total_rewards: 4440.2885, mean_steps: 25.6400, mean_ecr: 0.0379 mean_entropies: 0.9072, took: 116.3727s
2022-10-11 02:28:14,293 [INFO] 	Process 3 - batch 83599: mean_policy_losses: -17.208, mean_net_lifetime: 4937.8141, mean_mc_travel_dist: 1260.6599, mean_rewards: 276.1384, total_rewards: 3702.6408, mean_steps: 16.9400, mean_ecr: 0.0470 mean_entropies: 0.4657, took: 81.9951s
2022-10-11 02:29:00,504 [INFO] 	Process 4 - batch 83099: mean_policy_losses: 185.854, mean_net_lifetime: 9268.3409, mean_mc_travel_dist: 2694.7744, mean_rewards: 279.9708, total_rewards: 6604.0447, mean_steps: 34.0500, mean_ecr: 0.0402 mean_entropies: 0.5503, took: 148.6154s
2022-10-11 02:29:34,287 [INFO] 	Process 3 - batch 83699: mean_policy_losses: 2.240, mean_net_lifetime: 5080.6918, mean_mc_travel_dist: 1297.9575, mean_rewards: 289.6417, total_rewards: 3808.3428, mean_steps: 16.5800, mean_ecr: 0.0466 mean_entropies: 0.4805, took: 79.9942s
2022-10-11 02:29:54,406 [INFO] 	Process 1 - batch 69399: mean_policy_losses: 2.220, mean_net_lifetime: 6633.5694, mean_mc_travel_dist: 2120.6865, mean_rewards: 251.2475, total_rewards: 4544.2545, mean_steps: 25.6100, mean_ecr: 0.0379 mean_entropies: 0.9357, took: 113.8667s
2022-10-11 02:30:00,985 [INFO] 	Process 5 - batch 73799: mean_policy_losses: -264.453, mean_net_lifetime: 10034.4978, mean_mc_travel_dist: 3095.2062, mean_rewards: 264.0706, total_rewards: 6969.8061, mean_steps: 38.0300, mean_ecr: 0.0297 mean_entropies: 0.6742, took: 168.3632s
2022-10-11 02:30:57,163 [INFO] 	Process 3 - batch 83799: mean_policy_losses: -12.878, mean_net_lifetime: 5101.7472, mean_mc_travel_dist: 1324.6452, mean_rewards: 285.5235, total_rewards: 3806.3116, mean_steps: 16.9000, mean_ecr: 0.0462 mean_entropies: 0.4743, took: 82.8755s
2022-10-11 02:31:46,359 [INFO] Process 2 - epoch 51: mean_policy_losses: -2.285, mean_net_lifetime: 5002.4686, mean_mc_travel_dist: 1647.1358, mean_entropies: 0.8916, m_net_lifetime_valid: 4565.8754, took: 2468.5193s, (153.0801 / 100 batches)

2022-10-11 02:31:51,260 [INFO] 	Process 1 - batch 69499: mean_policy_losses: -28.107, mean_net_lifetime: 6558.6191, mean_mc_travel_dist: 2097.7963, mean_rewards: 245.3820, total_rewards: 4480.0074, mean_steps: 25.9200, mean_ecr: 0.0379 mean_entropies: 0.9075, took: 116.8543s
2022-10-11 02:31:51,979 [INFO] 	Process 4 - batch 83199: mean_policy_losses: 141.180, mean_net_lifetime: 10022.5129, mean_mc_travel_dist: 3066.0518, mean_rewards: 269.6450, total_rewards: 6985.4059, mean_steps: 39.2700, mean_ecr: 0.0397 mean_entropies: 0.5457, took: 171.4748s
2022-10-11 02:32:20,959 [INFO] 	Process 3 - batch 83899: mean_policy_losses: -1.555, mean_net_lifetime: 5018.9886, mean_mc_travel_dist: 1286.5399, mean_rewards: 276.4045, total_rewards: 3765.0567, mean_steps: 17.2300, mean_ecr: 0.0468 mean_entropies: 0.4606, took: 83.7957s
2022-10-11 02:32:37,294 [INFO] 	Process 5 - batch 73899: mean_policy_losses: -233.257, mean_net_lifetime: 9215.2741, mean_mc_travel_dist: 2902.3901, mean_rewards: 261.5733, total_rewards: 6356.0768, mean_steps: 35.0600, mean_ecr: 0.0295 mean_entropies: 0.6553, took: 156.3082s
2022-10-11 02:33:42,275 [INFO] 	Process 2 - batch 76599: mean_policy_losses: -56.877, mean_net_lifetime: 6846.9760, mean_mc_travel_dist: 1848.6896, mean_rewards: 272.8226, total_rewards: 5028.5505, mean_steps: 24.2600, mean_ecr: 0.0390 mean_entropies: 0.4157, took: 768.1988s
2022-10-11 02:33:44,484 [INFO] 	Process 3 - batch 83999: mean_policy_losses: -10.109, mean_net_lifetime: 4967.1014, mean_mc_travel_dist: 1276.0046, mean_rewards: 281.1757, total_rewards: 3732.4981, mean_steps: 16.6900, mean_ecr: 0.0468 mean_entropies: 0.4722, took: 83.5253s
2022-10-11 02:33:45,020 [INFO] 	Process 1 - batch 69599: mean_policy_losses: -39.320, mean_net_lifetime: 6358.3057, mean_mc_travel_dist: 2074.9525, mean_rewards: 252.3514, total_rewards: 4308.9221, mean_steps: 24.3900, mean_ecr: 0.0380 mean_entropies: 0.9039, took: 113.7596s
2022-10-11 02:34:29,420 [INFO] 	Process 4 - batch 83299: mean_policy_losses: 162.782, mean_net_lifetime: 9176.8572, mean_mc_travel_dist: 2673.6891, mean_rewards: 280.9496, total_rewards: 6534.2435, mean_steps: 34.0500, mean_ecr: 0.0413 mean_entropies: 0.5370, took: 157.4410s
2022-10-11 02:35:01,710 [INFO] Process 7 - epoch 52: mean_policy_losses: -363.971, mean_net_lifetime: 4202.7196, mean_mc_travel_dist: 1553.2954, mean_entropies: 1.5596, m_net_lifetime_valid: 4388.2410, took: 2294.2463s, (150.3923 / 100 batches)

2022-10-11 02:35:20,484 [INFO] 	Process 5 - batch 73999: mean_policy_losses: -186.259, mean_net_lifetime: 9801.7319, mean_mc_travel_dist: 3101.6603, mean_rewards: 271.0485, total_rewards: 6743.2798, mean_steps: 36.3600, mean_ecr: 0.0291 mean_entropies: 0.6873, took: 163.1909s
2022-10-11 02:35:36,159 [INFO] Process 6 - epoch 74: mean_policy_losses: -196.491, mean_net_lifetime: 3165.2256, mean_mc_travel_dist: 982.0874, mean_entropies: 0.5460, m_net_lifetime_valid: 4506.6468, took: 1460.4874s, (105.7652 / 100 batches)

2022-10-11 02:35:37,524 [INFO] 	Process 2 - batch 76699: mean_policy_losses: -53.235, mean_net_lifetime: 7009.3085, mean_mc_travel_dist: 1925.9988, mean_rewards: 280.7421, total_rewards: 5113.5482, mean_steps: 24.0400, mean_ecr: 0.0387 mean_entropies: 0.4287, took: 115.2481s
2022-10-11 02:35:42,600 [INFO] 	Process 1 - batch 69699: mean_policy_losses: -52.261, mean_net_lifetime: 6632.1326, mean_mc_travel_dist: 2106.1089, mean_rewards: 246.3834, total_rewards: 4550.0011, mean_steps: 26.1000, mean_ecr: 0.0380 mean_entropies: 0.9360, took: 117.5802s
2022-10-11 02:36:34,073 [INFO] 	Process 6 - batch 111099: mean_policy_losses: -84.603, mean_net_lifetime: 4024.7143, mean_mc_travel_dist: 1071.7625, mean_rewards: 341.9393, total_rewards: 2996.3057, mean_steps: 10.7200, mean_ecr: 0.0551 mean_entropies: 0.1691, took: 693.6231s
2022-10-11 02:36:53,100 [INFO] 	Process 4 - batch 83399: mean_policy_losses: 176.167, mean_net_lifetime: 8126.3913, mean_mc_travel_dist: 2325.4804, mean_rewards: 279.5831, total_rewards: 5828.8706, mean_steps: 29.9900, mean_ecr: 0.0424 mean_entropies: 0.5340, took: 143.6801s
2022-10-11 02:36:58,906 [INFO] 	Process 7 - batch 78099: mean_policy_losses: -405.020, mean_net_lifetime: 5090.1634, mean_mc_travel_dist: 1522.8136, mean_rewards: 206.9872, total_rewards: 3607.6655, mean_steps: 23.7300, mean_ecr: 0.0408 mean_entropies: 1.3397, took: 767.6854s
2022-10-11 02:37:31,824 [INFO] 	Process 6 - batch 111199: mean_policy_losses: -136.735, mean_net_lifetime: 4006.9135, mean_mc_travel_dist: 1067.6598, mean_rewards: 344.3554, total_rewards: 2977.3985, mean_steps: 10.6100, mean_ecr: 0.0552 mean_entropies: 0.1623, took: 57.7505s
2022-10-11 02:37:45,329 [INFO] 	Process 1 - batch 69799: mean_policy_losses: 7.588, mean_net_lifetime: 6471.7488, mean_mc_travel_dist: 2094.4680, mean_rewards: 244.6295, total_rewards: 4414.3795, mean_steps: 25.7400, mean_ecr: 0.0380 mean_entropies: 0.8856, took: 122.7301s
2022-10-11 02:37:46,447 [INFO] 	Process 2 - batch 76799: mean_policy_losses: 37.302, mean_net_lifetime: 7595.5671, mean_mc_travel_dist: 2057.8226, mean_rewards: 282.6002, total_rewards: 5558.5706, mean_steps: 26.1100, mean_ecr: 0.0382 mean_entropies: 0.4012, took: 128.9241s
2022-10-11 02:37:56,952 [INFO] 	Process 5 - batch 74099: mean_policy_losses: -158.077, mean_net_lifetime: 8968.1925, mean_mc_travel_dist: 2868.9392, mean_rewards: 271.2364, total_rewards: 6153.2193, mean_steps: 32.9800, mean_ecr: 0.0297 mean_entropies: 0.6486, took: 156.4669s
2022-10-11 02:38:29,802 [INFO] 	Process 6 - batch 111299: mean_policy_losses: -98.005, mean_net_lifetime: 4047.9527, mean_mc_travel_dist: 1081.0825, mean_rewards: 342.6950, total_rewards: 3009.4041, mean_steps: 10.7500, mean_ecr: 0.0551 mean_entropies: 0.1352, took: 57.9786s
2022-10-11 02:39:06,230 [INFO] 	Process 7 - batch 78199: mean_policy_losses: -296.760, mean_net_lifetime: 5356.1517, mean_mc_travel_dist: 1655.7850, mean_rewards: 196.4757, total_rewards: 3740.3764, mean_steps: 26.4500, mean_ecr: 0.0403 mean_entropies: 1.3035, took: 127.3235s
2022-10-11 02:39:26,475 [INFO] 	Process 6 - batch 111399: mean_policy_losses: -77.596, mean_net_lifetime: 3894.6160, mean_mc_travel_dist: 1058.3562, mean_rewards: 342.0747, total_rewards: 2874.1229, mean_steps: 10.3800, mean_ecr: 0.0554 mean_entropies: 0.1579, took: 56.6726s
2022-10-11 02:39:34,089 [INFO] 	Process 4 - batch 83499: mean_policy_losses: 243.579, mean_net_lifetime: 8892.9164, mean_mc_travel_dist: 2582.6687, mean_rewards: 279.7923, total_rewards: 6334.2570, mean_steps: 33.3300, mean_ecr: 0.0415 mean_entropies: 0.5653, took: 160.9887s
2022-10-11 02:39:48,154 [INFO] 	Process 1 - batch 69899: mean_policy_losses: 2.319, mean_net_lifetime: 6422.7013, mean_mc_travel_dist: 2072.8634, mean_rewards: 246.7735, total_rewards: 4382.1130, mean_steps: 25.2400, mean_ecr: 0.0381 mean_entropies: 0.8903, took: 122.8248s
2022-10-11 02:39:55,962 [INFO] 	Process 2 - batch 76899: mean_policy_losses: 24.082, mean_net_lifetime: 7612.4671, mean_mc_travel_dist: 2060.0715, mean_rewards: 279.1891, total_rewards: 5573.2577, mean_steps: 26.3300, mean_ecr: 0.0381 mean_entropies: 0.4051, took: 129.5149s
2022-10-11 02:40:21,607 [INFO] 	Process 6 - batch 111499: mean_policy_losses: -122.533, mean_net_lifetime: 3814.9471, mean_mc_travel_dist: 1041.5277, mean_rewards: 340.5964, total_rewards: 2829.8811, mean_steps: 10.1600, mean_ecr: 0.0551 mean_entropies: 0.1670, took: 55.1312s
2022-10-11 02:41:01,812 [INFO] 	Process 7 - batch 78299: mean_policy_losses: -366.055, mean_net_lifetime: 5230.8063, mean_mc_travel_dist: 1599.4330, mean_rewards: 214.0495, total_rewards: 3664.8557, mean_steps: 23.8100, mean_ecr: 0.0406 mean_entropies: 1.2881, took: 115.5823s
2022-10-11 02:41:15,431 [INFO] 	Process 6 - batch 111599: mean_policy_losses: -105.550, mean_net_lifetime: 3713.5458, mean_mc_travel_dist: 987.7632, mean_rewards: 344.9317, total_rewards: 2766.2178, mean_steps: 9.7600, mean_ecr: 0.0553 mean_entropies: 0.1975, took: 53.8241s
2022-10-11 02:41:21,731 [INFO] 	Process 4 - batch 83599: mean_policy_losses: 122.011, mean_net_lifetime: 6194.0915, mean_mc_travel_dist: 1671.6292, mean_rewards: 288.8189, total_rewards: 4547.6632, mean_steps: 21.1700, mean_ecr: 0.0449 mean_entropies: 0.5562, took: 107.6425s
2022-10-11 02:41:23,556 [INFO] 	Process 5 - batch 74199: mean_policy_losses: -112.603, mean_net_lifetime: 11511.7122, mean_mc_travel_dist: 3697.8794, mean_rewards: 266.5468, total_rewards: 7859.2465, mean_steps: 44.1500, mean_ecr: 0.0293 mean_entropies: 0.6665, took: 206.6037s
2022-10-11 02:41:48,002 [INFO] 	Process 1 - batch 69999: mean_policy_losses: 28.424, mean_net_lifetime: 6510.8032, mean_mc_travel_dist: 2088.3074, mean_rewards: 254.8898, total_rewards: 4456.3835, mean_steps: 24.7000, mean_ecr: 0.0382 mean_entropies: 0.9327, took: 119.8471s
2022-10-11 02:42:05,986 [INFO] 	Process 2 - batch 76999: mean_policy_losses: 49.691, mean_net_lifetime: 7665.7300, mean_mc_travel_dist: 2121.7908, mean_rewards: 278.9990, total_rewards: 5570.8362, mean_steps: 26.6300, mean_ecr: 0.0378 mean_entropies: 0.4555, took: 130.0227s
2022-10-11 02:42:10,613 [INFO] 	Process 6 - batch 111699: mean_policy_losses: -138.883, mean_net_lifetime: 3772.6995, mean_mc_travel_dist: 1003.4386, mean_rewards: 340.6962, total_rewards: 2817.5134, mean_steps: 10.0000, mean_ecr: 0.0553 mean_entropies: 0.1733, took: 55.1827s
2022-10-11 02:42:57,008 [INFO] 	Process 7 - batch 78399: mean_policy_losses: -539.392, mean_net_lifetime: 4958.7673, mean_mc_travel_dist: 1562.5407, mean_rewards: 201.1897, total_rewards: 3432.5098, mean_steps: 24.1000, mean_ecr: 0.0408 mean_entropies: 1.3352, took: 115.1953s
2022-10-11 02:43:07,159 [INFO] 	Process 6 - batch 111799: mean_policy_losses: -80.313, mean_net_lifetime: 3952.8437, mean_mc_travel_dist: 1046.6204, mean_rewards: 340.7888, total_rewards: 2937.1431, mean_steps: 10.5300, mean_ecr: 0.0553 mean_entropies: 0.1631, took: 56.5462s
2022-10-11 02:43:42,794 [INFO] 	Process 4 - batch 83699: mean_policy_losses: 223.700, mean_net_lifetime: 7990.0763, mean_mc_travel_dist: 2247.6906, mean_rewards: 281.7043, total_rewards: 5764.3839, mean_steps: 28.9100, mean_ecr: 0.0414 mean_entropies: 0.5427, took: 141.0628s
2022-10-11 02:43:48,777 [INFO] 	Process 1 - batch 70099: mean_policy_losses: 48.352, mean_net_lifetime: 6476.7707, mean_mc_travel_dist: 2072.3838, mean_rewards: 250.8756, total_rewards: 4429.0799, mean_steps: 25.0200, mean_ecr: 0.0381 mean_entropies: 0.9025, took: 120.7751s
2022-10-11 02:43:49,106 [INFO] Process 3 - epoch 56: mean_policy_losses: 52.577, mean_net_lifetime: 4371.7980, mean_mc_travel_dist: 1341.7819, mean_entropies: 0.8478, m_net_lifetime_valid: 4442.4383, took: 1859.0097s, (140.3436 / 100 batches)

2022-10-11 02:44:02,301 [INFO] 	Process 6 - batch 111899: mean_policy_losses: -86.486, mean_net_lifetime: 3791.8573, mean_mc_travel_dist: 1029.9123, mean_rewards: 336.8520, total_rewards: 2808.6037, mean_steps: 10.2200, mean_ecr: 0.0555 mean_entropies: 0.1745, took: 55.1414s
2022-10-11 02:44:14,008 [INFO] 	Process 2 - batch 77099: mean_policy_losses: 34.147, mean_net_lifetime: 7564.4598, mean_mc_travel_dist: 2046.9131, mean_rewards: 279.2535, total_rewards: 5549.7394, mean_steps: 26.1800, mean_ecr: 0.0381 mean_entropies: 0.4271, took: 128.0236s
2022-10-11 02:44:22,768 [INFO] 	Process 5 - batch 74299: mean_policy_losses: -122.997, mean_net_lifetime: 9793.3398, mean_mc_travel_dist: 3036.7958, mean_rewards: 261.0211, total_rewards: 6806.9837, mean_steps: 37.2200, mean_ecr: 0.0295 mean_entropies: 0.6885, took: 179.2126s
2022-10-11 02:44:49,952 [INFO] 	Process 7 - batch 78499: mean_policy_losses: -383.172, mean_net_lifetime: 5038.8025, mean_mc_travel_dist: 1519.6272, mean_rewards: 211.8142, total_rewards: 3542.8819, mean_steps: 23.1200, mean_ecr: 0.0409 mean_entropies: 1.2382, took: 112.9443s
2022-10-11 02:44:57,391 [INFO] 	Process 6 - batch 111999: mean_policy_losses: -153.540, mean_net_lifetime: 3699.8443, mean_mc_travel_dist: 990.5796, mean_rewards: 337.8636, total_rewards: 2749.8137, mean_steps: 9.8700, mean_ecr: 0.0553 mean_entropies: 0.1831, took: 55.0910s
2022-10-11 02:45:18,476 [INFO] 	Process 3 - batch 84099: mean_policy_losses: 10.174, mean_net_lifetime: 4998.3201, mean_mc_travel_dist: 1228.2963, mean_rewards: 279.1867, total_rewards: 3797.2026, mean_steps: 16.9400, mean_ecr: 0.0471 mean_entropies: 0.4675, took: 693.9915s
2022-10-11 02:45:30,825 [INFO] 	Process 4 - batch 83799: mean_policy_losses: 114.431, mean_net_lifetime: 6146.3998, mean_mc_travel_dist: 1660.6102, mean_rewards: 289.1029, total_rewards: 4513.9184, mean_steps: 20.8600, mean_ecr: 0.0453 mean_entropies: 0.5423, took: 108.0311s
2022-10-11 02:45:48,338 [INFO] 	Process 1 - batch 70199: mean_policy_losses: 3.373, mean_net_lifetime: 6416.1995, mean_mc_travel_dist: 2079.5081, mean_rewards: 258.6300, total_rewards: 4362.2386, mean_steps: 23.8800, mean_ecr: 0.0382 mean_entropies: 0.9099, took: 119.5613s
2022-10-11 02:45:53,622 [INFO] 	Process 6 - batch 112099: mean_policy_losses: -173.660, mean_net_lifetime: 3703.7790, mean_mc_travel_dist: 995.1383, mean_rewards: 341.8652, total_rewards: 2750.8747, mean_steps: 9.7900, mean_ecr: 0.0553 mean_entropies: 0.1940, took: 56.2301s
2022-10-11 02:46:27,875 [INFO] 	Process 2 - batch 77199: mean_policy_losses: 55.795, mean_net_lifetime: 7745.2301, mean_mc_travel_dist: 2086.2837, mean_rewards: 280.4741, total_rewards: 5682.3432, mean_steps: 26.7100, mean_ecr: 0.0379 mean_entropies: 0.4424, took: 133.8666s
2022-10-11 02:46:48,896 [INFO] 	Process 7 - batch 78599: mean_policy_losses: -395.616, mean_net_lifetime: 5149.1233, mean_mc_travel_dist: 1569.9300, mean_rewards: 207.1679, total_rewards: 3613.5805, mean_steps: 24.0800, mean_ecr: 0.0406 mean_entropies: 1.2591, took: 118.9432s
2022-10-11 02:46:50,022 [INFO] 	Process 3 - batch 84199: mean_policy_losses: 16.378, mean_net_lifetime: 5022.5102, mean_mc_travel_dist: 1252.5953, mean_rewards: 275.6065, total_rewards: 3806.1158, mean_steps: 17.2800, mean_ecr: 0.0470 mean_entropies: 0.4820, took: 91.5467s
2022-10-11 02:46:51,993 [INFO] 	Process 6 - batch 112199: mean_policy_losses: -135.650, mean_net_lifetime: 3818.5308, mean_mc_travel_dist: 1018.0763, mean_rewards: 335.3443, total_rewards: 2843.3583, mean_steps: 10.2500, mean_ecr: 0.0555 mean_entropies: 0.1775, took: 58.3710s
2022-10-11 02:47:16,293 [INFO] 	Process 5 - batch 74399: mean_policy_losses: -123.048, mean_net_lifetime: 9776.7564, mean_mc_travel_dist: 3064.6129, mean_rewards: 269.7070, total_rewards: 6748.8726, mean_steps: 35.8700, mean_ecr: 0.0295 mean_entropies: 0.6395, took: 173.5254s
2022-10-11 02:47:46,986 [INFO] 	Process 6 - batch 112299: mean_policy_losses: -198.769, mean_net_lifetime: 3604.6219, mean_mc_travel_dist: 972.1618, mean_rewards: 333.6533, total_rewards: 2698.1417, mean_steps: 9.6900, mean_ecr: 0.0555 mean_entropies: 0.2088, took: 54.9931s
2022-10-11 02:47:49,265 [INFO] 	Process 4 - batch 83899: mean_policy_losses: 171.384, mean_net_lifetime: 7496.4486, mean_mc_travel_dist: 2124.6502, mean_rewards: 280.9556, total_rewards: 5399.6124, mean_steps: 27.6400, mean_ecr: 0.0433 mean_entropies: 0.5381, took: 138.4397s
2022-10-11 02:47:57,682 [INFO] 	Process 1 - batch 70299: mean_policy_losses: 19.641, mean_net_lifetime: 6654.6677, mean_mc_travel_dist: 2133.6917, mean_rewards: 250.7226, total_rewards: 4554.5716, mean_steps: 25.7600, mean_ecr: 0.0379 mean_entropies: 0.9023, took: 129.3444s
2022-10-11 02:48:19,803 [INFO] 	Process 3 - batch 84299: mean_policy_losses: 9.774, mean_net_lifetime: 5016.3594, mean_mc_travel_dist: 1236.1019, mean_rewards: 276.2247, total_rewards: 3818.6163, mean_steps: 17.2200, mean_ecr: 0.0473 mean_entropies: 0.4577, took: 89.7816s
2022-10-11 02:48:41,691 [INFO] 	Process 2 - batch 77299: mean_policy_losses: 41.475, mean_net_lifetime: 7646.0400, mean_mc_travel_dist: 2054.6664, mean_rewards: 279.1047, total_rewards: 5625.2293, mean_steps: 26.4700, mean_ecr: 0.0380 mean_entropies: 0.4462, took: 133.8147s
2022-10-11 02:48:44,807 [INFO] 	Process 6 - batch 112399: mean_policy_losses: -149.419, mean_net_lifetime: 3855.7758, mean_mc_travel_dist: 1025.7314, mean_rewards: 340.1068, total_rewards: 2870.7073, mean_steps: 10.2500, mean_ecr: 0.0552 mean_entropies: 0.1880, took: 57.8209s
2022-10-11 02:48:51,102 [INFO] 	Process 7 - batch 78699: mean_policy_losses: -396.750, mean_net_lifetime: 5108.6409, mean_mc_travel_dist: 1571.1868, mean_rewards: 202.6036, total_rewards: 3571.9372, mean_steps: 24.5400, mean_ecr: 0.0404 mean_entropies: 1.2434, took: 122.2070s
2022-10-11 02:49:42,377 [INFO] 	Process 6 - batch 112499: mean_policy_losses: -145.894, mean_net_lifetime: 3844.6791, mean_mc_travel_dist: 1013.5663, mean_rewards: 337.9357, total_rewards: 2858.4272, mean_steps: 10.2900, mean_ecr: 0.0553 mean_entropies: 0.1973, took: 57.5697s
2022-10-11 02:49:45,572 [INFO] 	Process 4 - batch 83999: mean_policy_losses: 209.467, mean_net_lifetime: 6430.7372, mean_mc_travel_dist: 1731.2358, mean_rewards: 282.2165, total_rewards: 4730.9186, mean_steps: 22.4100, mean_ecr: 0.0441 mean_entropies: 0.5170, took: 116.3077s
2022-10-11 02:49:51,582 [INFO] 	Process 3 - batch 84399: mean_policy_losses: 5.548, mean_net_lifetime: 5053.9183, mean_mc_travel_dist: 1284.1337, mean_rewards: 275.9828, total_rewards: 3796.8789, mean_steps: 17.3600, mean_ecr: 0.0466 mean_entropies: 0.4938, took: 91.7785s
2022-10-11 02:50:05,765 [INFO] 	Process 1 - batch 70399: mean_policy_losses: -45.319, mean_net_lifetime: 6389.5401, mean_mc_travel_dist: 2086.5349, mean_rewards: 242.3675, total_rewards: 4327.1734, mean_steps: 25.6100, mean_ecr: 0.0382 mean_entropies: 0.9194, took: 128.0818s
2022-10-11 02:50:13,352 [INFO] 	Process 5 - batch 74499: mean_policy_losses: -176.512, mean_net_lifetime: 9984.6704, mean_mc_travel_dist: 3235.7335, mean_rewards: 275.0189, total_rewards: 6796.0846, mean_steps: 36.6100, mean_ecr: 0.0296 mean_entropies: 0.5985, took: 177.0588s
2022-10-11 02:50:47,837 [INFO] 	Process 2 - batch 77399: mean_policy_losses: 36.860, mean_net_lifetime: 7632.7830, mean_mc_travel_dist: 2036.4647, mean_rewards: 285.8669, total_rewards: 5615.7864, mean_steps: 25.7900, mean_ecr: 0.0382 mean_entropies: 0.4347, took: 126.1473s
2022-10-11 02:50:56,988 [INFO] 	Process 7 - batch 78799: mean_policy_losses: -300.848, mean_net_lifetime: 5335.8257, mean_mc_travel_dist: 1650.7481, mean_rewards: 196.6717, total_rewards: 3713.8941, mean_steps: 26.7100, mean_ecr: 0.0403 mean_entropies: 1.2251, took: 125.8855s
2022-10-11 02:51:18,242 [INFO] 	Process 3 - batch 84499: mean_policy_losses: -4.058, mean_net_lifetime: 4911.9120, mean_mc_travel_dist: 1238.0426, mean_rewards: 273.8277, total_rewards: 3706.9854, mean_steps: 16.9800, mean_ecr: 0.0469 mean_entropies: 0.4682, took: 86.6594s
2022-10-11 02:52:01,782 [INFO] 	Process 1 - batch 70499: mean_policy_losses: 3.286, mean_net_lifetime: 6383.4610, mean_mc_travel_dist: 2087.1399, mean_rewards: 251.0470, total_rewards: 4326.8154, mean_steps: 24.6100, mean_ecr: 0.0381 mean_entropies: 0.8405, took: 116.0178s
2022-10-11 02:52:41,393 [INFO] 	Process 5 - batch 74599: mean_policy_losses: -145.464, mean_net_lifetime: 8814.0645, mean_mc_travel_dist: 2813.2488, mean_rewards: 271.6120, total_rewards: 6049.7130, mean_steps: 32.1800, mean_ecr: 0.0298 mean_entropies: 0.6232, took: 148.0407s
2022-10-11 02:52:42,758 [INFO] 	Process 3 - batch 84599: mean_policy_losses: 3.741, mean_net_lifetime: 5103.9225, mean_mc_travel_dist: 1313.1459, mean_rewards: 280.2848, total_rewards: 3822.0117, mean_steps: 17.2600, mean_ecr: 0.0464 mean_entropies: 0.4774, took: 84.5164s
2022-10-11 02:52:42,973 [INFO] 	Process 7 - batch 78899: mean_policy_losses: -228.511, mean_net_lifetime: 5089.4710, mean_mc_travel_dist: 1528.1741, mean_rewards: 209.6855, total_rewards: 3592.4252, mean_steps: 23.3800, mean_ecr: 0.0407 mean_entropies: 1.2086, took: 105.9863s
2022-10-11 02:52:47,435 [INFO] 	Process 2 - batch 77499: mean_policy_losses: 3.591, mean_net_lifetime: 7435.2755, mean_mc_travel_dist: 1992.6261, mean_rewards: 276.7859, total_rewards: 5465.1961, mean_steps: 25.9400, mean_ecr: 0.0383 mean_entropies: 0.4221, took: 119.5978s
2022-10-11 02:54:03,157 [INFO] 	Process 3 - batch 84699: mean_policy_losses: -13.131, mean_net_lifetime: 5025.5387, mean_mc_travel_dist: 1287.5558, mean_rewards: 283.6421, total_rewards: 3772.1918, mean_steps: 16.7800, mean_ecr: 0.0467 mean_entropies: 0.5024, took: 80.3992s
2022-10-11 02:54:28,967 [INFO] 	Process 7 - batch 78999: mean_policy_losses: -276.230, mean_net_lifetime: 5124.4897, mean_mc_travel_dist: 1554.2499, mean_rewards: 207.5246, total_rewards: 3604.3492, mean_steps: 23.9300, mean_ecr: 0.0405 mean_entropies: 1.2862, took: 105.9930s
2022-10-11 02:54:47,502 [INFO] 	Process 2 - batch 77599: mean_policy_losses: 20.451, mean_net_lifetime: 7593.7995, mean_mc_travel_dist: 2037.3389, mean_rewards: 278.1147, total_rewards: 5580.5322, mean_steps: 26.4100, mean_ecr: 0.0382 mean_entropies: 0.4384, took: 120.0657s
2022-10-11 02:55:25,934 [INFO] 	Process 3 - batch 84799: mean_policy_losses: 1.659, mean_net_lifetime: 5051.4684, mean_mc_travel_dist: 1279.1298, mean_rewards: 281.4890, total_rewards: 3808.2589, mean_steps: 16.9700, mean_ecr: 0.0468 mean_entropies: 0.4813, took: 82.7765s
2022-10-11 02:55:40,176 [INFO] 	Process 5 - batch 74699: mean_policy_losses: -123.394, mean_net_lifetime: 10979.4415, mean_mc_travel_dist: 3488.6187, mean_rewards: 271.0253, total_rewards: 7536.6084, mean_steps: 41.0500, mean_ecr: 0.0293 mean_entropies: 0.6672, took: 178.7826s
2022-10-11 02:56:07,568 [INFO] 	Process 7 - batch 79099: mean_policy_losses: -362.921, mean_net_lifetime: 4902.0379, mean_mc_travel_dist: 1466.1987, mean_rewards: 213.0662, total_rewards: 3464.6869, mean_steps: 22.1900, mean_ecr: 0.0408 mean_entropies: 1.3015, took: 98.6022s
2022-10-11 02:56:46,162 [INFO] 	Process 2 - batch 77699: mean_policy_losses: 10.588, mean_net_lifetime: 7650.9949, mean_mc_travel_dist: 2052.5062, mean_rewards: 281.0159, total_rewards: 5627.1302, mean_steps: 26.3000, mean_ecr: 0.0381 mean_entropies: 0.4391, took: 118.6614s
2022-10-11 02:56:49,635 [INFO] 	Process 3 - batch 84899: mean_policy_losses: -12.086, mean_net_lifetime: 5029.3824, mean_mc_travel_dist: 1279.5640, mean_rewards: 281.0683, total_rewards: 3778.7586, mean_steps: 16.9900, mean_ecr: 0.0468 mean_entropies: 0.4992, took: 83.7006s
2022-10-11 02:57:55,087 [INFO] 	Process 7 - batch 79199: mean_policy_losses: -321.591, mean_net_lifetime: 5017.5270, mean_mc_travel_dist: 1505.5924, mean_rewards: 209.0217, total_rewards: 3542.1740, mean_steps: 23.3800, mean_ecr: 0.0407 mean_entropies: 1.2907, took: 107.5181s
2022-10-11 02:58:11,457 [INFO] 	Process 3 - batch 84999: mean_policy_losses: -19.884, mean_net_lifetime: 5095.8734, mean_mc_travel_dist: 1293.3654, mean_rewards: 282.5458, total_rewards: 3834.5566, mean_steps: 17.0700, mean_ecr: 0.0468 mean_entropies: 0.4677, took: 81.8223s
2022-10-11 02:58:29,985 [INFO] 	Process 5 - batch 74799: mean_policy_losses: -188.303, mean_net_lifetime: 10243.0062, mean_mc_travel_dist: 3193.5725, mean_rewards: 267.3528, total_rewards: 7093.3490, mean_steps: 38.4500, mean_ecr: 0.0295 mean_entropies: 0.6534, took: 169.8093s
2022-10-11 02:58:48,574 [INFO] 	Process 2 - batch 77799: mean_policy_losses: 8.663, mean_net_lifetime: 7617.8173, mean_mc_travel_dist: 2015.8560, mean_rewards: 283.5284, total_rewards: 5616.7750, mean_steps: 25.9600, mean_ecr: 0.0382 mean_entropies: 0.4248, took: 122.4116s
2022-10-11 02:59:35,835 [INFO] 	Process 3 - batch 85099: mean_policy_losses: 2.335, mean_net_lifetime: 5142.1609, mean_mc_travel_dist: 1304.0403, mean_rewards: 280.2727, total_rewards: 3859.0303, mean_steps: 17.4600, mean_ecr: 0.0465 mean_entropies: 0.4609, took: 84.3783s
2022-10-11 02:59:40,281 [INFO] 	Process 7 - batch 79299: mean_policy_losses: -305.825, mean_net_lifetime: 4741.2911, mean_mc_travel_dist: 1418.2476, mean_rewards: 203.0774, total_rewards: 3359.4634, mean_steps: 22.7200, mean_ecr: 0.0410 mean_entropies: 1.3112, took: 105.1947s
2022-10-11 03:00:12,969 [INFO] Process 6 - epoch 75: mean_policy_losses: -195.549, mean_net_lifetime: 3174.1757, mean_mc_travel_dist: 982.6848, mean_entropies: 0.5410, m_net_lifetime_valid: 4422.8400, took: 1476.8071s, (105.6724 / 100 batches)

2022-10-11 03:00:50,478 [INFO] 	Process 2 - batch 77899: mean_policy_losses: 38.776, mean_net_lifetime: 7664.2252, mean_mc_travel_dist: 2054.7669, mean_rewards: 282.9755, total_rewards: 5640.2552, mean_steps: 26.1700, mean_ecr: 0.0381 mean_entropies: 0.4469, took: 121.9038s
2022-10-11 03:00:51,573 [INFO] Process 4 - epoch 56: mean_policy_losses: 98.507, mean_net_lifetime: 4635.4278, mean_mc_travel_dist: 1460.2753, mean_entropies: 1.0882, m_net_lifetime_valid: 4767.7370, took: 2739.3625s, (141.4871 / 100 batches)

2022-10-11 03:01:03,403 [INFO] 	Process 5 - batch 74899: mean_policy_losses: -136.330, mean_net_lifetime: 9176.4992, mean_mc_travel_dist: 2790.1127, mean_rewards: 271.4209, total_rewards: 6432.9494, mean_steps: 33.5600, mean_ecr: 0.0299 mean_entropies: 0.6689, took: 153.4175s
2022-10-11 03:01:06,689 [INFO] 	Process 3 - batch 85199: mean_policy_losses: 15.035, mean_net_lifetime: 5197.9543, mean_mc_travel_dist: 1333.3559, mean_rewards: 277.1985, total_rewards: 3897.2473, mean_steps: 17.8700, mean_ecr: 0.0463 mean_entropies: 0.4707, took: 90.8543s
2022-10-11 03:01:07,554 [INFO] 	Process 6 - batch 112599: mean_policy_losses: -158.614, mean_net_lifetime: 3739.7081, mean_mc_travel_dist: 983.0173, mean_rewards: 339.3665, total_rewards: 2786.0689, mean_steps: 9.9600, mean_ecr: 0.0555 mean_entropies: 0.2022, took: 685.1778s
2022-10-11 03:01:34,282 [INFO] 	Process 7 - batch 79399: mean_policy_losses: -243.383, mean_net_lifetime: 5034.0928, mean_mc_travel_dist: 1525.7460, mean_rewards: 204.4440, total_rewards: 3544.5135, mean_steps: 24.0800, mean_ecr: 0.0408 mean_entropies: 1.3049, took: 114.0005s
2022-10-11 03:02:02,224 [INFO] 	Process 6 - batch 112699: mean_policy_losses: -137.789, mean_net_lifetime: 3674.8395, mean_mc_travel_dist: 973.8603, mean_rewards: 338.2834, total_rewards: 2734.2489, mean_steps: 9.8100, mean_ecr: 0.0556 mean_entropies: 0.2030, took: 54.6687s
2022-10-11 03:02:33,043 [INFO] 	Process 4 - batch 84099: mean_policy_losses: 264.212, mean_net_lifetime: 5635.1250, mean_mc_travel_dist: 1460.3780, mean_rewards: 282.1100, total_rewards: 4202.1951, mean_steps: 19.3000, mean_ecr: 0.0459 mean_entropies: 0.5476, took: 767.4700s
2022-10-11 03:02:40,873 [INFO] 	Process 3 - batch 85299: mean_policy_losses: 36.713, mean_net_lifetime: 5267.8466, mean_mc_travel_dist: 1345.3311, mean_rewards: 279.3559, total_rewards: 3952.6907, mean_steps: 17.9800, mean_ecr: 0.0459 mean_entropies: 0.4538, took: 94.1840s
2022-10-11 03:02:45,134 [INFO] Process 1 - epoch 47: mean_policy_losses: 21.982, mean_net_lifetime: 5259.8317, mean_mc_travel_dist: 2038.2306, mean_entropies: 1.1701, m_net_lifetime_valid: 4901.5260, took: 2445.2254s, (168.7351 / 100 batches)

2022-10-11 03:02:57,123 [INFO] 	Process 2 - batch 77999: mean_policy_losses: 24.371, mean_net_lifetime: 7339.7639, mean_mc_travel_dist: 1965.9341, mean_rewards: 278.8501, total_rewards: 5404.5955, mean_steps: 25.4200, mean_ecr: 0.0384 mean_entropies: 0.4252, took: 126.6457s
2022-10-11 03:02:58,419 [INFO] 	Process 6 - batch 112799: mean_policy_losses: -185.177, mean_net_lifetime: 3704.1670, mean_mc_travel_dist: 991.7467, mean_rewards: 335.8058, total_rewards: 2748.2095, mean_steps: 10.0000, mean_ecr: 0.0555 mean_entropies: 0.1918, took: 56.1958s
2022-10-11 03:03:29,183 [INFO] 	Process 7 - batch 79499: mean_policy_losses: -395.474, mean_net_lifetime: 4931.5621, mean_mc_travel_dist: 1496.4802, mean_rewards: 203.9865, total_rewards: 3465.6540, mean_steps: 23.6300, mean_ecr: 0.0407 mean_entropies: 1.2423, took: 114.9012s
2022-10-11 03:03:49,067 [INFO] 	Process 5 - batch 74999: mean_policy_losses: -129.836, mean_net_lifetime: 9455.3168, mean_mc_travel_dist: 2867.2885, mean_rewards: 270.3100, total_rewards: 6631.0561, mean_steps: 34.7700, mean_ecr: 0.0300 mean_entropies: 0.6607, took: 165.6643s
2022-10-11 03:03:52,450 [INFO] 	Process 6 - batch 112899: mean_policy_losses: -161.432, mean_net_lifetime: 3708.6661, mean_mc_travel_dist: 996.5954, mean_rewards: 338.5053, total_rewards: 2733.7990, mean_steps: 10.0100, mean_ecr: 0.0553 mean_entropies: 0.1957, took: 54.0316s
2022-10-11 03:04:01,760 [INFO] 	Process 4 - batch 84199: mean_policy_losses: 124.924, mean_net_lifetime: 5188.8435, mean_mc_travel_dist: 1344.6471, mean_rewards: 286.8714, total_rewards: 3869.1957, mean_steps: 17.2500, mean_ecr: 0.0470 mean_entropies: 0.5618, took: 88.7173s
2022-10-11 03:04:06,857 [INFO] 	Process 3 - batch 85399: mean_policy_losses: 47.507, mean_net_lifetime: 5125.3452, mean_mc_travel_dist: 1307.8965, mean_rewards: 287.0712, total_rewards: 3847.4823, mean_steps: 16.8900, mean_ecr: 0.0465 mean_entropies: 0.5061, took: 85.9840s
2022-10-11 03:04:43,471 [INFO] 	Process 1 - batch 70599: mean_policy_losses: 27.333, mean_net_lifetime: 6513.4468, mean_mc_travel_dist: 2094.3193, mean_rewards: 248.7741, total_rewards: 4446.7734, mean_steps: 25.3500, mean_ecr: 0.0381 mean_entropies: 0.8963, took: 761.6892s
2022-10-11 03:04:44,291 [INFO] 	Process 6 - batch 112999: mean_policy_losses: -126.457, mean_net_lifetime: 3800.2173, mean_mc_travel_dist: 1021.1460, mean_rewards: 341.7442, total_rewards: 2815.2618, mean_steps: 10.0700, mean_ecr: 0.0554 mean_entropies: 0.1713, took: 51.8394s
2022-10-11 03:05:28,811 [INFO] 	Process 3 - batch 85499: mean_policy_losses: 19.118, mean_net_lifetime: 5032.3955, mean_mc_travel_dist: 1287.8012, mean_rewards: 281.1614, total_rewards: 3769.7897, mean_steps: 16.9400, mean_ecr: 0.0464 mean_entropies: 0.4626, took: 81.9540s
2022-10-11 03:05:32,147 [INFO] 	Process 4 - batch 84299: mean_policy_losses: 112.163, mean_net_lifetime: 5739.0005, mean_mc_travel_dist: 1489.9895, mean_rewards: 292.1896, total_rewards: 4278.5289, mean_steps: 18.9300, mean_ecr: 0.0456 mean_entropies: 0.5051, took: 90.3874s
2022-10-11 03:05:33,441 [INFO] 	Process 6 - batch 113099: mean_policy_losses: -178.217, mean_net_lifetime: 3548.5469, mean_mc_travel_dist: 968.0810, mean_rewards: 337.2121, total_rewards: 2621.8317, mean_steps: 9.4700, mean_ecr: 0.0557 mean_entropies: 0.1906, took: 49.1510s
2022-10-11 03:06:23,152 [INFO] 	Process 6 - batch 113199: mean_policy_losses: -73.454, mean_net_lifetime: 3864.8466, mean_mc_travel_dist: 1041.8396, mean_rewards: 342.0752, total_rewards: 2857.8480, mean_steps: 10.2700, mean_ecr: 0.0553 mean_entropies: 0.1595, took: 49.7113s
2022-10-11 03:06:27,192 [INFO] 	Process 1 - batch 70699: mean_policy_losses: 19.083, mean_net_lifetime: 6234.5323, mean_mc_travel_dist: 1999.5549, mean_rewards: 248.4641, total_rewards: 4252.4540, mean_steps: 24.2800, mean_ecr: 0.0383 mean_entropies: 0.8831, took: 103.7205s
2022-10-11 03:07:11,434 [INFO] 	Process 4 - batch 84399: mean_policy_losses: 96.005, mean_net_lifetime: 6523.1014, mean_mc_travel_dist: 1759.4155, mean_rewards: 286.6009, total_rewards: 4792.8674, mean_steps: 22.2400, mean_ecr: 0.0442 mean_entropies: 0.5335, took: 99.2871s
2022-10-11 03:07:13,615 [INFO] 	Process 6 - batch 113299: mean_policy_losses: -95.166, mean_net_lifetime: 3862.4584, mean_mc_travel_dist: 1036.6800, mean_rewards: 342.6059, total_rewards: 2861.6255, mean_steps: 10.2300, mean_ecr: 0.0552 mean_entropies: 0.1768, took: 50.4636s
2022-10-11 03:08:05,403 [INFO] 	Process 6 - batch 113399: mean_policy_losses: -121.913, mean_net_lifetime: 3805.4963, mean_mc_travel_dist: 997.0185, mean_rewards: 343.3838, total_rewards: 2835.1971, mean_steps: 10.0200, mean_ecr: 0.0554 mean_entropies: 0.1585, took: 51.7881s
2022-10-11 03:08:19,045 [INFO] 	Process 1 - batch 70799: mean_policy_losses: 0.299, mean_net_lifetime: 6501.9630, mean_mc_travel_dist: 2067.8798, mean_rewards: 242.8513, total_rewards: 4466.7530, mean_steps: 25.9900, mean_ecr: 0.0381 mean_entropies: 0.9159, took: 111.8540s
2022-10-11 03:08:53,377 [INFO] 	Process 6 - batch 113499: mean_policy_losses: -184.950, mean_net_lifetime: 3548.5261, mean_mc_travel_dist: 950.3078, mean_rewards: 340.4005, total_rewards: 2649.8550, mean_steps: 9.3700, mean_ecr: 0.0556 mean_entropies: 0.1907, took: 47.9728s
2022-10-11 03:08:57,890 [INFO] 	Process 4 - batch 84499: mean_policy_losses: 100.953, mean_net_lifetime: 6877.5327, mean_mc_travel_dist: 1866.1903, mean_rewards: 290.3538, total_rewards: 5044.8093, mean_steps: 23.2400, mean_ecr: 0.0430 mean_entropies: 0.5405, took: 106.4548s
2022-10-11 03:09:41,728 [INFO] 	Process 6 - batch 113599: mean_policy_losses: -133.311, mean_net_lifetime: 3636.4246, mean_mc_travel_dist: 976.6396, mean_rewards: 340.3131, total_rewards: 2694.9588, mean_steps: 9.6500, mean_ecr: 0.0555 mean_entropies: 0.1902, took: 48.3522s
2022-10-11 03:10:06,866 [INFO] 	Process 1 - batch 70899: mean_policy_losses: 26.305, mean_net_lifetime: 6407.6717, mean_mc_travel_dist: 2056.9001, mean_rewards: 255.2898, total_rewards: 4381.6293, mean_steps: 24.3100, mean_ecr: 0.0381 mean_entropies: 0.9099, took: 107.8201s
2022-10-11 03:10:31,268 [INFO] 	Process 6 - batch 113699: mean_policy_losses: -127.966, mean_net_lifetime: 3885.7162, mean_mc_travel_dist: 1029.3476, mean_rewards: 344.1406, total_rewards: 2893.7502, mean_steps: 10.2400, mean_ecr: 0.0552 mean_entropies: 0.1598, took: 49.5393s
2022-10-11 03:10:45,471 [INFO] 	Process 4 - batch 84599: mean_policy_losses: 92.592, mean_net_lifetime: 7113.1449, mean_mc_travel_dist: 1964.1386, mean_rewards: 291.8145, total_rewards: 5180.8055, mean_steps: 24.2400, mean_ecr: 0.0434 mean_entropies: 0.5363, took: 107.5818s
2022-10-11 03:11:20,269 [INFO] 	Process 6 - batch 113799: mean_policy_losses: -107.242, mean_net_lifetime: 3714.3444, mean_mc_travel_dist: 995.2914, mean_rewards: 343.0928, total_rewards: 2758.8799, mean_steps: 9.8000, mean_ecr: 0.0551 mean_entropies: 0.1759, took: 49.0014s
2022-10-11 03:11:53,929 [INFO] 	Process 1 - batch 70999: mean_policy_losses: 19.717, mean_net_lifetime: 6409.8643, mean_mc_travel_dist: 2056.2413, mean_rewards: 251.9581, total_rewards: 4383.0059, mean_steps: 24.4800, mean_ecr: 0.0382 mean_entropies: 0.9437, took: 107.0622s
2022-10-11 03:12:10,320 [INFO] 	Process 6 - batch 113899: mean_policy_losses: -94.155, mean_net_lifetime: 3660.1900, mean_mc_travel_dist: 985.3946, mean_rewards: 341.8106, total_rewards: 2728.5841, mean_steps: 9.6700, mean_ecr: 0.0552 mean_entropies: 0.1667, took: 50.0504s
2022-10-11 03:12:44,024 [INFO] 	Process 4 - batch 84699: mean_policy_losses: 92.783, mean_net_lifetime: 7673.9093, mean_mc_travel_dist: 2192.7303, mean_rewards: 285.0458, total_rewards: 5518.9179, mean_steps: 27.1000, mean_ecr: 0.0423 mean_entropies: 0.5134, took: 118.5533s
2022-10-11 03:13:02,647 [INFO] 	Process 6 - batch 113999: mean_policy_losses: -148.711, mean_net_lifetime: 3953.3769, mean_mc_travel_dist: 1054.5432, mean_rewards: 343.5074, total_rewards: 2930.8129, mean_steps: 10.4500, mean_ecr: 0.0553 mean_entropies: 0.1426, took: 52.3274s
2022-10-11 03:13:13,804 [INFO] Process 2 - epoch 52: mean_policy_losses: -1.887, mean_net_lifetime: 5050.6524, mean_mc_travel_dist: 1654.3803, mean_entropies: 0.8827, m_net_lifetime_valid: 4757.3835, took: 2487.4424s, (153.3706 / 100 batches)

2022-10-11 03:13:42,835 [INFO] 	Process 1 - batch 71099: mean_policy_losses: -27.255, mean_net_lifetime: 6388.9288, mean_mc_travel_dist: 2041.5648, mean_rewards: 250.7331, total_rewards: 4372.1517, mean_steps: 24.6900, mean_ecr: 0.0382 mean_entropies: 0.9031, took: 108.9070s
2022-10-11 03:13:42,888 [INFO] Process 5 - epoch 50: mean_policy_losses: -193.552, mean_net_lifetime: 5388.4645, mean_mc_travel_dist: 2058.7371, mean_entropies: 1.1433, m_net_lifetime_valid: 4840.6422, took: 3089.7632s, (159.5662 / 100 batches)

2022-10-11 03:14:24,905 [INFO] Process 7 - epoch 53: mean_policy_losses: -363.666, mean_net_lifetime: 4219.1573, mean_mc_travel_dist: 1553.1033, mean_entropies: 1.5543, m_net_lifetime_valid: 4836.2759, took: 2363.1929s, (150.5205 / 100 batches)

2022-10-11 03:14:53,696 [INFO] Process 3 - epoch 57: mean_policy_losses: 51.793, mean_net_lifetime: 4384.0763, mean_mc_travel_dist: 1340.7803, mean_entropies: 0.8413, m_net_lifetime_valid: 4361.5147, took: 1864.5875s, (140.1090 / 100 batches)

2022-10-11 03:15:10,501 [INFO] 	Process 4 - batch 84799: mean_policy_losses: 150.244, mean_net_lifetime: 8865.3154, mean_mc_travel_dist: 2582.0742, mean_rewards: 284.0557, total_rewards: 6325.0721, mean_steps: 32.3000, mean_ecr: 0.0413 mean_entropies: 0.5643, took: 146.4772s
2022-10-11 03:15:12,418 [INFO] 	Process 2 - batch 78099: mean_policy_losses: -20.811, mean_net_lifetime: 7423.7440, mean_mc_travel_dist: 2010.3532, mean_rewards: 283.2973, total_rewards: 5432.7766, mean_steps: 25.2900, mean_ecr: 0.0384 mean_entropies: 0.4330, took: 735.2942s
2022-10-11 03:15:47,780 [INFO] 	Process 1 - batch 71199: mean_policy_losses: -11.233, mean_net_lifetime: 6594.7336, mean_mc_travel_dist: 2099.2433, mean_rewards: 242.7591, total_rewards: 4521.6327, mean_steps: 26.3200, mean_ecr: 0.0381 mean_entropies: 0.9190, took: 124.9450s
2022-10-11 03:16:17,429 [INFO] 	Process 5 - batch 75099: mean_policy_losses: -289.726, mean_net_lifetime: 8843.3347, mean_mc_travel_dist: 2776.4844, mean_rewards: 269.2457, total_rewards: 6106.6516, mean_steps: 32.8500, mean_ecr: 0.0296 mean_entropies: 0.6233, took: 748.3632s
2022-10-11 03:16:27,655 [INFO] 	Process 3 - batch 85599: mean_policy_losses: -0.516, mean_net_lifetime: 5189.0726, mean_mc_travel_dist: 1320.0993, mean_rewards: 271.3944, total_rewards: 3897.1292, mean_steps: 18.2200, mean_ecr: 0.0464 mean_entropies: 0.4858, took: 658.8443s
2022-10-11 03:16:30,922 [INFO] 	Process 7 - batch 79599: mean_policy_losses: -399.925, mean_net_lifetime: 5527.6161, mean_mc_travel_dist: 1654.8800, mean_rewards: 200.7795, total_rewards: 3905.2147, mean_steps: 26.6800, mean_ecr: 0.0403 mean_entropies: 1.3125, took: 781.7390s
2022-10-11 03:17:12,497 [INFO] 	Process 2 - batch 78199: mean_policy_losses: -48.781, mean_net_lifetime: 7063.3321, mean_mc_travel_dist: 1884.9436, mean_rewards: 276.4581, total_rewards: 5197.0201, mean_steps: 24.6200, mean_ecr: 0.0386 mean_entropies: 0.4258, took: 120.0800s
2022-10-11 03:17:47,642 [INFO] 	Process 4 - batch 84899: mean_policy_losses: 277.914, mean_net_lifetime: 9018.1580, mean_mc_travel_dist: 2563.7770, mean_rewards: 281.4025, total_rewards: 6488.7022, mean_steps: 33.0200, mean_ecr: 0.0403 mean_entropies: 0.5192, took: 157.1406s
2022-10-11 03:17:49,081 [INFO] 	Process 1 - batch 71299: mean_policy_losses: -48.586, mean_net_lifetime: 6226.5911, mean_mc_travel_dist: 2024.0541, mean_rewards: 241.1947, total_rewards: 4234.0185, mean_steps: 25.0700, mean_ecr: 0.0382 mean_entropies: 0.8817, took: 121.3011s
2022-10-11 03:17:57,239 [INFO] 	Process 3 - batch 85699: mean_policy_losses: 17.382, mean_net_lifetime: 5151.5016, mean_mc_travel_dist: 1289.4167, mean_rewards: 277.7978, total_rewards: 3898.6360, mean_steps: 17.6300, mean_ecr: 0.0467 mean_entropies: 0.4632, took: 89.5832s
2022-10-11 03:18:26,038 [INFO] 	Process 7 - batch 79699: mean_policy_losses: -443.313, mean_net_lifetime: 5158.1977, mean_mc_travel_dist: 1559.8244, mean_rewards: 207.9249, total_rewards: 3631.1699, mean_steps: 23.9700, mean_ecr: 0.0404 mean_entropies: 1.3183, took: 115.1158s
2022-10-11 03:18:55,153 [INFO] 	Process 5 - batch 75199: mean_policy_losses: -295.257, mean_net_lifetime: 8832.3468, mean_mc_travel_dist: 2725.1391, mean_rewards: 263.5717, total_rewards: 6144.2329, mean_steps: 33.2700, mean_ecr: 0.0298 mean_entropies: 0.6193, took: 157.7229s
2022-10-11 03:19:21,457 [INFO] 	Process 2 - batch 78299: mean_policy_losses: -2.216, mean_net_lifetime: 7637.7146, mean_mc_travel_dist: 2056.2873, mean_rewards: 276.0404, total_rewards: 5602.8055, mean_steps: 26.7400, mean_ecr: 0.0381 mean_entropies: 0.4264, took: 128.9596s
2022-10-11 03:19:28,256 [INFO] 	Process 3 - batch 85799: mean_policy_losses: -3.082, mean_net_lifetime: 5132.2541, mean_mc_travel_dist: 1301.1893, mean_rewards: 281.0228, total_rewards: 3852.7916, mean_steps: 17.3100, mean_ecr: 0.0465 mean_entropies: 0.4749, took: 91.0168s
2022-10-11 03:19:51,381 [INFO] 	Process 1 - batch 71399: mean_policy_losses: -14.465, mean_net_lifetime: 6415.7249, mean_mc_travel_dist: 2031.2968, mean_rewards: 245.3243, total_rewards: 4410.5761, mean_steps: 25.4400, mean_ecr: 0.0383 mean_entropies: 0.9013, took: 122.2994s
2022-10-11 03:20:27,593 [INFO] 	Process 7 - batch 79799: mean_policy_losses: -387.565, mean_net_lifetime: 5303.7202, mean_mc_travel_dist: 1618.1181, mean_rewards: 203.3512, total_rewards: 3712.0609, mean_steps: 25.2900, mean_ecr: 0.0404 mean_entropies: 1.3235, took: 121.5552s
2022-10-11 03:20:42,517 [INFO] 	Process 4 - batch 84999: mean_policy_losses: 255.907, mean_net_lifetime: 9820.2920, mean_mc_travel_dist: 2894.9351, mean_rewards: 283.2856, total_rewards: 6953.4053, mean_steps: 37.4000, mean_ecr: 0.0414 mean_entropies: 0.5204, took: 174.8751s
2022-10-11 03:20:57,769 [INFO] 	Process 3 - batch 85899: mean_policy_losses: -7.417, mean_net_lifetime: 5129.2250, mean_mc_travel_dist: 1305.7987, mean_rewards: 279.9357, total_rewards: 3856.2271, mean_steps: 17.3800, mean_ecr: 0.0463 mean_entropies: 0.4732, took: 89.5135s
2022-10-11 03:21:25,621 [INFO] 	Process 2 - batch 78399: mean_policy_losses: -31.564, mean_net_lifetime: 7346.6090, mean_mc_travel_dist: 1987.0208, mean_rewards: 279.6037, total_rewards: 5383.7983, mean_steps: 25.3700, mean_ecr: 0.0384 mean_entropies: 0.4263, took: 124.1648s
2022-10-11 03:21:52,392 [INFO] 	Process 1 - batch 71499: mean_policy_losses: -8.494, mean_net_lifetime: 6629.1174, mean_mc_travel_dist: 2116.5641, mean_rewards: 254.6921, total_rewards: 4542.2855, mean_steps: 25.0800, mean_ecr: 0.0381 mean_entropies: 0.9888, took: 121.0116s
2022-10-11 03:22:18,032 [INFO] 	Process 7 - batch 79899: mean_policy_losses: -540.140, mean_net_lifetime: 5172.1376, mean_mc_travel_dist: 1592.1406, mean_rewards: 214.6256, total_rewards: 3617.1085, mean_steps: 23.0700, mean_ecr: 0.0407 mean_entropies: 1.3855, took: 110.4388s
2022-10-11 03:22:28,221 [INFO] 	Process 3 - batch 85999: mean_policy_losses: -22.015, mean_net_lifetime: 5145.8753, mean_mc_travel_dist: 1314.3258, mean_rewards: 284.5801, total_rewards: 3863.0735, mean_steps: 17.1100, mean_ecr: 0.0464 mean_entropies: 0.4995, took: 90.4515s
2022-10-11 03:22:31,946 [INFO] 	Process 5 - batch 75299: mean_policy_losses: -193.658, mean_net_lifetime: 11882.9702, mean_mc_travel_dist: 3765.7365, mean_rewards: 266.2736, total_rewards: 8161.4867, mean_steps: 45.4200, mean_ecr: 0.0292 mean_entropies: 0.6697, took: 216.7926s
2022-10-11 03:22:47,225 [INFO] 	Process 4 - batch 85099: mean_policy_losses: 192.908, mean_net_lifetime: 7350.6310, mean_mc_travel_dist: 2050.3315, mean_rewards: 291.5307, total_rewards: 5327.9543, mean_steps: 25.4100, mean_ecr: 0.0437 mean_entropies: 0.5664, took: 124.7078s
2022-10-11 03:23:32,052 [INFO] 	Process 2 - batch 78499: mean_policy_losses: -20.670, mean_net_lifetime: 7621.4956, mean_mc_travel_dist: 2035.6769, mean_rewards: 284.5674, total_rewards: 5611.1919, mean_steps: 25.8900, mean_ecr: 0.0382 mean_entropies: 0.4288, took: 126.4306s
2022-10-11 03:23:42,888 [INFO] Process 6 - epoch 76: mean_policy_losses: -194.761, mean_net_lifetime: 3181.6274, mean_mc_travel_dist: 982.9139, mean_entropies: 0.5363, m_net_lifetime_valid: 4331.5881, took: 1409.9158s, (105.5104 / 100 batches)

2022-10-11 03:23:48,217 [INFO] 	Process 1 - batch 71599: mean_policy_losses: -1.613, mean_net_lifetime: 6463.2575, mean_mc_travel_dist: 2102.8135, mean_rewards: 261.1416, total_rewards: 4386.0444, mean_steps: 23.8400, mean_ecr: 0.0380 mean_entropies: 0.9313, took: 115.8247s
2022-10-11 03:23:57,136 [INFO] 	Process 3 - batch 86099: mean_policy_losses: -12.475, mean_net_lifetime: 5088.0325, mean_mc_travel_dist: 1303.2284, mean_rewards: 278.5435, total_rewards: 3810.7722, mean_steps: 17.3300, mean_ecr: 0.0464 mean_entropies: 0.4745, took: 88.9161s
2022-10-11 03:24:06,977 [INFO] 	Process 7 - batch 79999: mean_policy_losses: -517.307, mean_net_lifetime: 4989.5757, mean_mc_travel_dist: 1559.0140, mean_rewards: 214.6042, total_rewards: 3454.8039, mean_steps: 22.5400, mean_ecr: 0.0408 mean_entropies: 1.3288, took: 108.9449s
2022-10-11 03:24:35,879 [INFO] 	Process 6 - batch 114099: mean_policy_losses: -102.281, mean_net_lifetime: 3525.2869, mean_mc_travel_dist: 936.9475, mean_rewards: 338.0753, total_rewards: 2612.6448, mean_steps: 9.3800, mean_ecr: 0.0556 mean_entropies: 0.2031, took: 693.2317s
2022-10-11 03:24:49,960 [INFO] 	Process 4 - batch 85199: mean_policy_losses: 265.448, mean_net_lifetime: 7197.7343, mean_mc_travel_dist: 2013.0221, mean_rewards: 291.0562, total_rewards: 5212.1414, mean_steps: 24.5100, mean_ecr: 0.0431 mean_entropies: 0.5640, took: 122.7352s
2022-10-11 03:25:30,036 [INFO] 	Process 3 - batch 86199: mean_policy_losses: 34.098, mean_net_lifetime: 5095.5291, mean_mc_travel_dist: 1295.5373, mean_rewards: 279.3076, total_rewards: 3828.1744, mean_steps: 17.3000, mean_ecr: 0.0463 mean_entropies: 0.4913, took: 92.9000s
2022-10-11 03:25:33,988 [INFO] 	Process 6 - batch 114199: mean_policy_losses: -119.806, mean_net_lifetime: 3814.1586, mean_mc_travel_dist: 993.2533, mean_rewards: 336.0912, total_rewards: 2840.5810, mean_steps: 10.2700, mean_ecr: 0.0553 mean_entropies: 0.1845, took: 58.1086s
2022-10-11 03:25:36,803 [INFO] 	Process 5 - batch 75399: mean_policy_losses: -214.824, mean_net_lifetime: 10181.2668, mean_mc_travel_dist: 3176.7022, mean_rewards: 265.9785, total_rewards: 7045.0888, mean_steps: 38.4800, mean_ecr: 0.0296 mean_entropies: 0.6789, took: 184.8585s
2022-10-11 03:25:39,053 [INFO] 	Process 2 - batch 78599: mean_policy_losses: 22.987, mean_net_lifetime: 7256.4045, mean_mc_travel_dist: 1950.6834, mean_rewards: 279.7913, total_rewards: 5333.2412, mean_steps: 25.0100, mean_ecr: 0.0385 mean_entropies: 0.4413, took: 126.9998s
2022-10-11 03:25:54,770 [INFO] 	Process 1 - batch 71699: mean_policy_losses: 72.278, mean_net_lifetime: 6480.1928, mean_mc_travel_dist: 2121.9179, mean_rewards: 252.5372, total_rewards: 4396.4216, mean_steps: 24.9300, mean_ecr: 0.0380 mean_entropies: 0.9037, took: 126.5531s
2022-10-11 03:26:07,933 [INFO] 	Process 7 - batch 80099: mean_policy_losses: -372.387, mean_net_lifetime: 5153.8093, mean_mc_travel_dist: 1577.2796, mean_rewards: 205.6828, total_rewards: 3612.6822, mean_steps: 24.1200, mean_ecr: 0.0407 mean_entropies: 1.3281, took: 120.9548s
2022-10-11 03:26:33,406 [INFO] 	Process 6 - batch 114299: mean_policy_losses: -98.112, mean_net_lifetime: 3843.5640, mean_mc_travel_dist: 1022.5383, mean_rewards: 339.0193, total_rewards: 2863.3663, mean_steps: 10.3500, mean_ecr: 0.0550 mean_entropies: 0.1929, took: 59.4177s
2022-10-11 03:27:05,359 [INFO] 	Process 3 - batch 86299: mean_policy_losses: 28.670, mean_net_lifetime: 5193.8114, mean_mc_travel_dist: 1336.2494, mean_rewards: 277.0579, total_rewards: 3890.3633, mean_steps: 17.8000, mean_ecr: 0.0460 mean_entropies: 0.4967, took: 95.3226s
2022-10-11 03:27:18,367 [INFO] 	Process 4 - batch 85299: mean_policy_losses: 277.959, mean_net_lifetime: 8213.4982, mean_mc_travel_dist: 2306.5765, mean_rewards: 289.6528, total_rewards: 5941.7939, mean_steps: 29.0500, mean_ecr: 0.0421 mean_entropies: 0.5174, took: 148.4068s
2022-10-11 03:27:31,402 [INFO] 	Process 6 - batch 114399: mean_policy_losses: -165.092, mean_net_lifetime: 3700.1474, mean_mc_travel_dist: 962.3802, mean_rewards: 336.6216, total_rewards: 2761.1852, mean_steps: 9.9100, mean_ecr: 0.0557 mean_entropies: 0.1962, took: 57.9959s
2022-10-11 03:27:40,066 [INFO] 	Process 2 - batch 78699: mean_policy_losses: -27.303, mean_net_lifetime: 6767.8741, mean_mc_travel_dist: 1795.4236, mean_rewards: 278.2098, total_rewards: 4998.8962, mean_steps: 23.4000, mean_ecr: 0.0391 mean_entropies: 0.4070, took: 121.0134s
2022-10-11 03:28:05,115 [INFO] 	Process 1 - batch 71799: mean_policy_losses: 24.445, mean_net_lifetime: 6528.3108, mean_mc_travel_dist: 2082.6129, mean_rewards: 244.0453, total_rewards: 4467.3677, mean_steps: 25.9100, mean_ecr: 0.0382 mean_entropies: 0.8920, took: 130.3447s
2022-10-11 03:28:20,151 [INFO] 	Process 7 - batch 80199: mean_policy_losses: -329.662, mean_net_lifetime: 5439.4211, mean_mc_travel_dist: 1668.4706, mean_rewards: 202.3114, total_rewards: 3795.3702, mean_steps: 26.2600, mean_ecr: 0.0403 mean_entropies: 1.3028, took: 132.2183s
2022-10-11 03:28:32,226 [INFO] 	Process 6 - batch 114499: mean_policy_losses: -121.087, mean_net_lifetime: 3956.7762, mean_mc_travel_dist: 1052.9409, mean_rewards: 341.6021, total_rewards: 2925.4564, mean_steps: 10.5100, mean_ecr: 0.0554 mean_entropies: 0.1629, took: 60.8241s
2022-10-11 03:28:38,894 [INFO] 	Process 3 - batch 86399: mean_policy_losses: 24.126, mean_net_lifetime: 5141.9639, mean_mc_travel_dist: 1323.9696, mean_rewards: 276.7249, total_rewards: 3858.7877, mean_steps: 17.6400, mean_ecr: 0.0462 mean_entropies: 0.4650, took: 93.5348s
2022-10-11 03:29:04,259 [INFO] 	Process 5 - batch 75499: mean_policy_losses: -160.185, mean_net_lifetime: 10824.9653, mean_mc_travel_dist: 3475.8768, mean_rewards: 260.5170, total_rewards: 7395.1236, mean_steps: 42.4000, mean_ecr: 0.0293 mean_entropies: 0.6570, took: 207.4547s
2022-10-11 03:29:29,697 [INFO] 	Process 6 - batch 114599: mean_policy_losses: -148.887, mean_net_lifetime: 3747.3997, mean_mc_travel_dist: 1012.5923, mean_rewards: 338.3972, total_rewards: 2762.9047, mean_steps: 10.0600, mean_ecr: 0.0555 mean_entropies: 0.1994, took: 57.4723s
2022-10-11 03:29:45,131 [INFO] 	Process 2 - batch 78799: mean_policy_losses: -16.399, mean_net_lifetime: 6807.5500, mean_mc_travel_dist: 1826.5504, mean_rewards: 273.0205, total_rewards: 5009.4228, mean_steps: 24.0600, mean_ecr: 0.0389 mean_entropies: 0.3972, took: 125.0660s
2022-10-11 03:30:05,344 [INFO] 	Process 4 - batch 85399: mean_policy_losses: 257.448, mean_net_lifetime: 9040.6040, mean_mc_travel_dist: 2603.3943, mean_rewards: 284.1182, total_rewards: 6465.3283, mean_steps: 33.4500, mean_ecr: 0.0412 mean_entropies: 0.5304, took: 166.9773s
2022-10-11 03:30:09,798 [INFO] 	Process 3 - batch 86499: mean_policy_losses: 33.395, mean_net_lifetime: 5059.9413, mean_mc_travel_dist: 1324.4021, mean_rewards: 280.5284, total_rewards: 3772.3178, mean_steps: 17.0600, mean_ecr: 0.0463 mean_entropies: 0.4935, took: 90.9040s
2022-10-11 03:30:11,584 [INFO] 	Process 1 - batch 71899: mean_policy_losses: 33.577, mean_net_lifetime: 6409.5447, mean_mc_travel_dist: 2113.3860, mean_rewards: 246.6461, total_rewards: 4322.6043, mean_steps: 25.2000, mean_ecr: 0.0380 mean_entropies: 0.8609, took: 126.4688s
2022-10-11 03:30:22,858 [INFO] 	Process 7 - batch 80299: mean_policy_losses: -375.279, mean_net_lifetime: 5096.8570, mean_mc_travel_dist: 1549.8576, mean_rewards: 205.9418, total_rewards: 3572.6650, mean_steps: 24.2800, mean_ecr: 0.0406 mean_entropies: 1.2817, took: 122.7085s
2022-10-11 03:30:28,912 [INFO] 	Process 6 - batch 114699: mean_policy_losses: -98.447, mean_net_lifetime: 3878.6146, mean_mc_travel_dist: 1033.3199, mean_rewards: 338.1911, total_rewards: 2882.6531, mean_steps: 10.4000, mean_ecr: 0.0552 mean_entropies: 0.1868, took: 59.2144s
2022-10-11 03:31:26,212 [INFO] 	Process 6 - batch 114799: mean_policy_losses: -82.483, mean_net_lifetime: 3776.2015, mean_mc_travel_dist: 1008.1782, mean_rewards: 342.3141, total_rewards: 2807.3223, mean_steps: 10.0100, mean_ecr: 0.0555 mean_entropies: 0.1785, took: 57.3001s
2022-10-11 03:31:46,098 [INFO] 	Process 3 - batch 86599: mean_policy_losses: 26.543, mean_net_lifetime: 5188.3143, mean_mc_travel_dist: 1347.8002, mean_rewards: 274.2282, total_rewards: 3883.8654, mean_steps: 17.9500, mean_ecr: 0.0461 mean_entropies: 0.4657, took: 96.2998s
2022-10-11 03:31:52,145 [INFO] 	Process 2 - batch 78899: mean_policy_losses: -20.166, mean_net_lifetime: 7107.4137, mean_mc_travel_dist: 1897.4195, mean_rewards: 274.9010, total_rewards: 5230.3644, mean_steps: 24.9000, mean_ecr: 0.0386 mean_entropies: 0.3967, took: 127.0129s
2022-10-11 03:32:16,908 [INFO] 	Process 1 - batch 71999: mean_policy_losses: 20.531, mean_net_lifetime: 6381.1459, mean_mc_travel_dist: 2055.1738, mean_rewards: 248.8341, total_rewards: 4351.2064, mean_steps: 24.8500, mean_ecr: 0.0381 mean_entropies: 0.8739, took: 125.3202s
2022-10-11 03:32:20,871 [INFO] 	Process 7 - batch 80399: mean_policy_losses: -498.488, mean_net_lifetime: 4927.2957, mean_mc_travel_dist: 1505.9493, mean_rewards: 205.3021, total_rewards: 3455.5421, mean_steps: 23.4200, mean_ecr: 0.0407 mean_entropies: 1.3257, took: 118.0132s
2022-10-11 03:32:24,543 [INFO] 	Process 6 - batch 114899: mean_policy_losses: -106.218, mean_net_lifetime: 3782.3829, mean_mc_travel_dist: 1000.7969, mean_rewards: 337.5466, total_rewards: 2819.1061, mean_steps: 10.1300, mean_ecr: 0.0555 mean_entropies: 0.2036, took: 58.3309s
2022-10-11 03:32:27,811 [INFO] 	Process 5 - batch 75599: mean_policy_losses: -200.656, mean_net_lifetime: 10612.0094, mean_mc_travel_dist: 3303.4051, mean_rewards: 261.7256, total_rewards: 7352.8821, mean_steps: 40.9900, mean_ecr: 0.0295 mean_entropies: 0.6709, took: 203.5530s
2022-10-11 03:32:28,124 [INFO] 	Process 4 - batch 85499: mean_policy_losses: 233.195, mean_net_lifetime: 7937.4734, mean_mc_travel_dist: 2222.5521, mean_rewards: 286.3576, total_rewards: 5749.5579, mean_steps: 28.1700, mean_ecr: 0.0418 mean_entropies: 0.5199, took: 142.7800s
2022-10-11 03:33:18,155 [INFO] 	Process 3 - batch 86699: mean_policy_losses: 26.549, mean_net_lifetime: 5121.3578, mean_mc_travel_dist: 1326.5448, mean_rewards: 275.4674, total_rewards: 3829.0183, mean_steps: 17.6700, mean_ecr: 0.0463 mean_entropies: 0.4757, took: 92.0577s
2022-10-11 03:33:21,014 [INFO] 	Process 6 - batch 114999: mean_policy_losses: -101.357, mean_net_lifetime: 3842.9862, mean_mc_travel_dist: 1031.7910, mean_rewards: 339.1369, total_rewards: 2868.4878, mean_steps: 10.2900, mean_ecr: 0.0554 mean_entropies: 0.1690, took: 56.4717s
2022-10-11 03:33:53,689 [INFO] 	Process 2 - batch 78999: mean_policy_losses: 35.194, mean_net_lifetime: 7392.4319, mean_mc_travel_dist: 1978.6204, mean_rewards: 279.7460, total_rewards: 5444.5681, mean_steps: 25.5300, mean_ecr: 0.0383 mean_entropies: 0.4145, took: 121.5454s
2022-10-11 03:34:13,865 [INFO] 	Process 7 - batch 80499: mean_policy_losses: -361.799, mean_net_lifetime: 5160.7344, mean_mc_travel_dist: 1551.6368, mean_rewards: 204.7158, total_rewards: 3642.9578, mean_steps: 24.4900, mean_ecr: 0.0407 mean_entropies: 1.3164, took: 112.9932s
2022-10-11 03:34:14,660 [INFO] 	Process 6 - batch 115099: mean_policy_losses: -138.832, mean_net_lifetime: 3853.5794, mean_mc_travel_dist: 1027.3247, mean_rewards: 339.2701, total_rewards: 2877.8517, mean_steps: 10.2700, mean_ecr: 0.0549 mean_entropies: 0.1898, took: 53.6453s
2022-10-11 03:34:44,451 [INFO] 	Process 3 - batch 86799: mean_policy_losses: 43.641, mean_net_lifetime: 5213.6726, mean_mc_travel_dist: 1327.3630, mean_rewards: 283.7888, total_rewards: 3911.3869, mean_steps: 17.4300, mean_ecr: 0.0462 mean_entropies: 0.4767, took: 86.2958s
2022-10-11 03:35:08,110 [INFO] 	Process 6 - batch 115199: mean_policy_losses: -120.285, mean_net_lifetime: 3807.5613, mean_mc_travel_dist: 1012.7745, mean_rewards: 340.4323, total_rewards: 2840.2898, mean_steps: 10.1200, mean_ecr: 0.0553 mean_entropies: 0.1781, took: 53.4496s
2022-10-11 03:35:50,031 [INFO] 	Process 5 - batch 75699: mean_policy_losses: -135.532, mean_net_lifetime: 11355.4426, mean_mc_travel_dist: 3533.4496, mean_rewards: 262.9856, total_rewards: 7852.9901, mean_steps: 43.8000, mean_ecr: 0.0293 mean_entropies: 0.6523, took: 202.2195s
2022-10-11 03:35:57,562 [INFO] 	Process 2 - batch 79099: mean_policy_losses: 48.083, mean_net_lifetime: 7561.8303, mean_mc_travel_dist: 2022.6394, mean_rewards: 280.2902, total_rewards: 5564.6501, mean_steps: 26.0600, mean_ecr: 0.0381 mean_entropies: 0.4229, took: 123.8722s
2022-10-11 03:36:02,742 [INFO] 	Process 6 - batch 115299: mean_policy_losses: -174.249, mean_net_lifetime: 3776.6281, mean_mc_travel_dist: 998.5218, mean_rewards: 340.2850, total_rewards: 2807.6468, mean_steps: 10.0400, mean_ecr: 0.0553 mean_entropies: 0.1837, took: 54.6324s
2022-10-11 03:36:10,927 [INFO] 	Process 7 - batch 80599: mean_policy_losses: -268.344, mean_net_lifetime: 5171.4048, mean_mc_travel_dist: 1552.4670, mean_rewards: 199.5155, total_rewards: 3654.1688, mean_steps: 25.0800, mean_ecr: 0.0406 mean_entropies: 1.2595, took: 117.0623s
2022-10-11 03:36:15,757 [INFO] 	Process 3 - batch 86899: mean_policy_losses: 30.100, mean_net_lifetime: 5174.1301, mean_mc_travel_dist: 1290.9300, mean_rewards: 277.3632, total_rewards: 3918.2605, mean_steps: 17.7100, mean_ecr: 0.0465 mean_entropies: 0.4550, took: 91.3062s
2022-10-11 03:37:00,357 [INFO] 	Process 6 - batch 115399: mean_policy_losses: -112.401, mean_net_lifetime: 3894.7701, mean_mc_travel_dist: 1036.3248, mean_rewards: 339.6414, total_rewards: 2890.7321, mean_steps: 10.3700, mean_ecr: 0.0553 mean_entropies: 0.1562, took: 57.6150s
2022-10-11 03:37:44,777 [INFO] 	Process 3 - batch 86999: mean_policy_losses: 31.881, mean_net_lifetime: 5164.5658, mean_mc_travel_dist: 1296.5549, mean_rewards: 279.8812, total_rewards: 3889.0436, mean_steps: 17.5100, mean_ecr: 0.0464 mean_entropies: 0.4456, took: 89.0194s
2022-10-11 03:37:56,029 [INFO] 	Process 6 - batch 115499: mean_policy_losses: -119.677, mean_net_lifetime: 3920.9018, mean_mc_travel_dist: 1038.1958, mean_rewards: 343.1233, total_rewards: 2918.6336, mean_steps: 10.3800, mean_ecr: 0.0552 mean_entropies: 0.1545, took: 55.6718s
2022-10-11 03:38:00,111 [INFO] 	Process 2 - batch 79199: mean_policy_losses: 42.585, mean_net_lifetime: 7339.6742, mean_mc_travel_dist: 1988.0232, mean_rewards: 276.5521, total_rewards: 5378.8842, mean_steps: 25.6700, mean_ecr: 0.0382 mean_entropies: 0.4174, took: 122.5478s
2022-10-11 03:38:10,968 [INFO] 	Process 7 - batch 80699: mean_policy_losses: -201.557, mean_net_lifetime: 5413.4403, mean_mc_travel_dist: 1626.1587, mean_rewards: 204.1577, total_rewards: 3812.8173, mean_steps: 26.0200, mean_ecr: 0.0402 mean_entropies: 1.2307, took: 120.0410s
2022-10-11 03:38:45,143 [INFO] 	Process 5 - batch 75799: mean_policy_losses: -147.798, mean_net_lifetime: 10312.3639, mean_mc_travel_dist: 3149.9838, mean_rewards: 265.4334, total_rewards: 7197.7995, mean_steps: 38.9600, mean_ecr: 0.0297 mean_entropies: 0.6509, took: 175.1124s
2022-10-11 03:39:59,256 [INFO] 	Process 2 - batch 79299: mean_policy_losses: 0.085, mean_net_lifetime: 7539.5198, mean_mc_travel_dist: 2067.4726, mean_rewards: 276.3114, total_rewards: 5502.3275, mean_steps: 26.3900, mean_ecr: 0.0381 mean_entropies: 0.4451, took: 119.1462s
2022-10-11 03:40:04,651 [INFO] 	Process 7 - batch 80799: mean_policy_losses: -314.872, mean_net_lifetime: 5454.8838, mean_mc_travel_dist: 1634.8766, mean_rewards: 201.4908, total_rewards: 3852.3469, mean_steps: 26.3300, mean_ecr: 0.0404 mean_entropies: 1.2541, took: 113.6825s
2022-10-11 03:41:52,234 [INFO] 	Process 5 - batch 75899: mean_policy_losses: -101.004, mean_net_lifetime: 11854.5766, mean_mc_travel_dist: 3626.7001, mean_rewards: 268.7183, total_rewards: 8263.7481, mean_steps: 44.2500, mean_ecr: 0.0292 mean_entropies: 0.6773, took: 187.0889s
2022-10-11 03:41:53,303 [INFO] 	Process 2 - batch 79399: mean_policy_losses: 7.764, mean_net_lifetime: 7428.7660, mean_mc_travel_dist: 2013.1252, mean_rewards: 282.8253, total_rewards: 5449.4999, mean_steps: 25.4000, mean_ecr: 0.0384 mean_entropies: 0.4541, took: 114.0467s
2022-10-11 03:42:01,218 [INFO] 	Process 7 - batch 80899: mean_policy_losses: -224.962, mean_net_lifetime: 5566.4470, mean_mc_travel_dist: 1664.1068, mean_rewards: 199.9432, total_rewards: 3934.0799, mean_steps: 27.0300, mean_ecr: 0.0403 mean_entropies: 1.2759, took: 116.5672s
2022-10-11 03:42:47,795 [INFO] Process 4 - epoch 57: mean_policy_losses: 100.048, mean_net_lifetime: 4685.3260, mean_mc_travel_dist: 1471.2812, mean_entropies: 1.0785, m_net_lifetime_valid: 4628.8250, took: 2516.2194s, (142.0014 / 100 batches)

2022-10-11 03:43:13,486 [INFO] Process 1 - epoch 48: mean_policy_losses: 21.708, mean_net_lifetime: 5284.3977, mean_mc_travel_dist: 2038.9113, mean_entropies: 1.1646, m_net_lifetime_valid: 5094.1875, took: 2428.3496s, (168.5743 / 100 batches)

2022-10-11 03:43:49,125 [INFO] 	Process 7 - batch 80999: mean_policy_losses: -402.067, mean_net_lifetime: 5035.0666, mean_mc_travel_dist: 1532.2481, mean_rewards: 200.1706, total_rewards: 3534.9178, mean_steps: 24.3000, mean_ecr: 0.0407 mean_entropies: 1.2754, took: 107.9075s
2022-10-11 03:43:49,776 [INFO] 	Process 2 - batch 79499: mean_policy_losses: -18.999, mean_net_lifetime: 7439.8001, mean_mc_travel_dist: 1975.7573, mean_rewards: 282.8862, total_rewards: 5482.9045, mean_steps: 25.3500, mean_ecr: 0.0383 mean_entropies: 0.4183, took: 116.4731s
2022-10-11 03:44:13,121 [INFO] 	Process 4 - batch 85599: mean_policy_losses: 222.728, mean_net_lifetime: 5141.7554, mean_mc_travel_dist: 1344.3583, mean_rewards: 280.0160, total_rewards: 3824.7900, mean_steps: 17.5200, mean_ecr: 0.0464 mean_entropies: 0.5697, took: 704.9966s
2022-10-11 03:44:57,348 [INFO] 	Process 5 - batch 75999: mean_policy_losses: -185.786, mean_net_lifetime: 11307.5639, mean_mc_travel_dist: 3507.8825, mean_rewards: 264.8178, total_rewards: 7847.7065, mean_steps: 42.8000, mean_ecr: 0.0294 mean_entropies: 0.6752, took: 185.1158s
2022-10-11 03:45:13,126 [INFO] 	Process 1 - batch 72099: mean_policy_losses: -160.433, mean_net_lifetime: 6325.8928, mean_mc_travel_dist: 2027.8513, mean_rewards: 231.9102, total_rewards: 4326.9468, mean_steps: 26.6300, mean_ecr: 0.0382 mean_entropies: 0.8713, took: 776.2218s
2022-10-11 03:45:43,637 [INFO] 	Process 4 - batch 85699: mean_policy_losses: 150.253, mean_net_lifetime: 5984.8822, mean_mc_travel_dist: 1595.2661, mean_rewards: 287.3094, total_rewards: 4419.2673, mean_steps: 20.1500, mean_ecr: 0.0447 mean_entropies: 0.5088, took: 90.5157s
2022-10-11 03:47:08,329 [INFO] 	Process 1 - batch 72199: mean_policy_losses: -92.963, mean_net_lifetime: 6484.7215, mean_mc_travel_dist: 2086.0541, mean_rewards: 240.7144, total_rewards: 4422.4339, mean_steps: 26.2000, mean_ecr: 0.0381 mean_entropies: 0.9120, took: 115.2036s
2022-10-11 03:47:35,333 [INFO] 	Process 4 - batch 85799: mean_policy_losses: 163.676, mean_net_lifetime: 7210.3261, mean_mc_travel_dist: 2009.3250, mean_rewards: 284.4449, total_rewards: 5228.7714, mean_steps: 25.5700, mean_ecr: 0.0432 mean_entropies: 0.5230, took: 111.6959s
2022-10-11 03:47:51,787 [INFO] 	Process 5 - batch 76099: mean_policy_losses: -290.288, mean_net_lifetime: 10662.8345, mean_mc_travel_dist: 3384.5878, mean_rewards: 262.2184, total_rewards: 7331.7610, mean_steps: 41.1800, mean_ecr: 0.0291 mean_entropies: 0.6521, took: 174.4387s
2022-10-11 03:47:58,135 [INFO] Process 3 - epoch 58: mean_policy_losses: 51.189, mean_net_lifetime: 4397.2120, mean_mc_travel_dist: 1340.3110, mean_entropies: 0.8350, m_net_lifetime_valid: 4403.5649, took: 1984.4359s, (139.9188 / 100 batches)

2022-10-11 03:48:13,161 [INFO] Process 6 - epoch 77: mean_policy_losses: -193.798, mean_net_lifetime: 3189.7629, mean_mc_travel_dist: 983.2812, mean_entropies: 0.5317, m_net_lifetime_valid: 4262.3208, took: 1470.2698s, (105.4332 / 100 batches)

2022-10-11 03:49:06,252 [INFO] 	Process 1 - batch 72299: mean_policy_losses: -20.533, mean_net_lifetime: 6558.7491, mean_mc_travel_dist: 2101.6487, mean_rewards: 245.0704, total_rewards: 4490.2016, mean_steps: 26.0300, mean_ecr: 0.0381 mean_entropies: 0.8805, took: 117.9233s
2022-10-11 03:49:09,742 [INFO] 	Process 6 - batch 115599: mean_policy_losses: -115.561, mean_net_lifetime: 4009.2182, mean_mc_travel_dist: 1057.4529, mean_rewards: 339.2234, total_rewards: 2992.5526, mean_steps: 10.7900, mean_ecr: 0.0549 mean_entropies: 0.1950, took: 673.7140s
2022-10-11 03:49:27,902 [INFO] 	Process 3 - batch 87099: mean_policy_losses: 10.992, mean_net_lifetime: 5093.9967, mean_mc_travel_dist: 1285.0820, mean_rewards: 274.9824, total_rewards: 3842.0077, mean_steps: 17.6200, mean_ecr: 0.0466 mean_entropies: 0.4661, took: 703.1251s
2022-10-11 03:50:06,326 [INFO] 	Process 6 - batch 115699: mean_policy_losses: -80.760, mean_net_lifetime: 3933.8328, mean_mc_travel_dist: 1050.4672, mean_rewards: 338.9907, total_rewards: 2923.9686, mean_steps: 10.5800, mean_ecr: 0.0552 mean_entropies: 0.1894, took: 56.5838s
2022-10-11 03:50:20,864 [INFO] 	Process 4 - batch 85899: mean_policy_losses: 209.018, mean_net_lifetime: 9686.2641, mean_mc_travel_dist: 2847.5583, mean_rewards: 279.2320, total_rewards: 6878.0639, mean_steps: 37.0700, mean_ecr: 0.0412 mean_entropies: 0.4935, took: 165.5312s
2022-10-11 03:50:57,258 [INFO] 	Process 3 - batch 87199: mean_policy_losses: 31.443, mean_net_lifetime: 5250.2851, mean_mc_travel_dist: 1338.9883, mean_rewards: 275.3971, total_rewards: 3946.1194, mean_steps: 18.1400, mean_ecr: 0.0461 mean_entropies: 0.4451, took: 89.3558s
2022-10-11 03:51:00,935 [INFO] 	Process 6 - batch 115799: mean_policy_losses: -98.722, mean_net_lifetime: 3997.9444, mean_mc_travel_dist: 1060.0562, mean_rewards: 340.6323, total_rewards: 2977.8138, mean_steps: 10.6700, mean_ecr: 0.0551 mean_entropies: 0.1603, took: 54.6076s
2022-10-11 03:51:03,997 [INFO] 	Process 1 - batch 72399: mean_policy_losses: 11.519, mean_net_lifetime: 6400.5842, mean_mc_travel_dist: 2048.1852, mean_rewards: 248.0601, total_rewards: 4371.6667, mean_steps: 25.0800, mean_ecr: 0.0380 mean_entropies: 0.8854, took: 117.7444s
2022-10-11 03:51:42,365 [INFO] 	Process 5 - batch 76199: mean_policy_losses: -178.508, mean_net_lifetime: 12595.0753, mean_mc_travel_dist: 4040.8365, mean_rewards: 258.3118, total_rewards: 8596.7812, mean_steps: 50.3300, mean_ecr: 0.0290 mean_entropies: 0.6456, took: 230.5787s
2022-10-11 03:51:53,216 [INFO] 	Process 6 - batch 115899: mean_policy_losses: -192.066, mean_net_lifetime: 3591.3703, mean_mc_travel_dist: 955.0905, mean_rewards: 339.8077, total_rewards: 2674.7658, mean_steps: 9.4900, mean_ecr: 0.0553 mean_entropies: 0.1705, took: 52.2817s
2022-10-11 03:52:23,448 [INFO] 	Process 3 - batch 87299: mean_policy_losses: 16.919, mean_net_lifetime: 5063.6402, mean_mc_travel_dist: 1271.0060, mean_rewards: 281.6202, total_rewards: 3829.4182, mean_steps: 17.0300, mean_ecr: 0.0468 mean_entropies: 0.4683, took: 86.1892s
2022-10-11 03:52:45,051 [INFO] 	Process 4 - batch 85999: mean_policy_losses: 173.220, mean_net_lifetime: 8432.5734, mean_mc_travel_dist: 2438.6976, mean_rewards: 286.8264, total_rewards: 6028.6530, mean_steps: 30.4200, mean_ecr: 0.0425 mean_entropies: 0.5171, took: 144.1865s
2022-10-11 03:52:49,604 [INFO] 	Process 6 - batch 115999: mean_policy_losses: -127.335, mean_net_lifetime: 3924.0985, mean_mc_travel_dist: 1045.0692, mean_rewards: 339.2436, total_rewards: 2925.1856, mean_steps: 10.5200, mean_ecr: 0.0549 mean_entropies: 0.1660, took: 56.3879s
2022-10-11 03:53:05,240 [INFO] 	Process 1 - batch 72499: mean_policy_losses: 34.603, mean_net_lifetime: 6536.1370, mean_mc_travel_dist: 2112.8591, mean_rewards: 245.7452, total_rewards: 4453.3845, mean_steps: 25.8900, mean_ecr: 0.0379 mean_entropies: 0.8907, took: 121.2423s
2022-10-11 03:53:44,150 [INFO] 	Process 6 - batch 116099: mean_policy_losses: -116.331, mean_net_lifetime: 3937.5623, mean_mc_travel_dist: 1041.0609, mean_rewards: 337.1939, total_rewards: 2929.0499, mean_steps: 10.5500, mean_ecr: 0.0554 mean_entropies: 0.1623, took: 54.5466s
2022-10-11 03:53:50,926 [INFO] 	Process 3 - batch 87399: mean_policy_losses: 19.802, mean_net_lifetime: 5078.9529, mean_mc_travel_dist: 1279.6179, mean_rewards: 278.4429, total_rewards: 3831.7593, mean_steps: 17.3300, mean_ecr: 0.0468 mean_entropies: 0.4427, took: 87.4791s
2022-10-11 03:54:32,338 [INFO] Process 2 - epoch 53: mean_policy_losses: -1.915, mean_net_lifetime: 5093.3875, mean_mc_travel_dist: 1660.2599, mean_entropies: 0.8740, m_net_lifetime_valid: 4460.5594, took: 2478.5316s, (153.5616 / 100 batches)

2022-10-11 03:54:36,399 [INFO] 	Process 6 - batch 116199: mean_policy_losses: -138.776, mean_net_lifetime: 3649.2900, mean_mc_travel_dist: 966.9058, mean_rewards: 338.5580, total_rewards: 2724.5165, mean_steps: 9.6800, mean_ecr: 0.0555 mean_entropies: 0.1735, took: 52.2491s
2022-10-11 03:54:44,935 [INFO] 	Process 5 - batch 76299: mean_policy_losses: -172.397, mean_net_lifetime: 10291.2814, mean_mc_travel_dist: 3256.3570, mean_rewards: 263.2486, total_rewards: 7079.4843, mean_steps: 39.5600, mean_ecr: 0.0295 mean_entropies: 0.6549, took: 182.5693s
2022-10-11 03:54:58,843 [INFO] Process 7 - epoch 54: mean_policy_losses: -363.892, mean_net_lifetime: 4238.0255, mean_mc_travel_dist: 1553.7829, mean_entropies: 1.5496, m_net_lifetime_valid: 4459.4664, took: 2433.9357s, (150.7204 / 100 batches)

2022-10-11 03:55:00,301 [INFO] 	Process 4 - batch 86099: mean_policy_losses: 194.693, mean_net_lifetime: 7910.7427, mean_mc_travel_dist: 2252.1633, mean_rewards: 279.8961, total_rewards: 5690.2474, mean_steps: 28.5300, mean_ecr: 0.0424 mean_entropies: 0.5334, took: 135.2511s
2022-10-11 03:55:08,277 [INFO] 	Process 1 - batch 72599: mean_policy_losses: 31.218, mean_net_lifetime: 6589.6151, mean_mc_travel_dist: 2117.0578, mean_rewards: 247.0526, total_rewards: 4495.5707, mean_steps: 25.9200, mean_ecr: 0.0380 mean_entropies: 0.9163, took: 123.0371s
2022-10-11 03:55:17,554 [INFO] 	Process 3 - batch 87499: mean_policy_losses: 19.361, mean_net_lifetime: 5100.0006, mean_mc_travel_dist: 1298.1232, mean_rewards: 283.7359, total_rewards: 3837.8080, mean_steps: 17.0000, mean_ecr: 0.0468 mean_entropies: 0.5027, took: 86.6278s
2022-10-11 03:55:33,140 [INFO] 	Process 6 - batch 116299: mean_policy_losses: -105.322, mean_net_lifetime: 3907.9467, mean_mc_travel_dist: 1041.5306, mean_rewards: 344.8291, total_rewards: 2912.7695, mean_steps: 10.3100, mean_ecr: 0.0548 mean_entropies: 0.1589, took: 56.7410s
2022-10-11 03:56:28,900 [INFO] 	Process 6 - batch 116399: mean_policy_losses: -146.698, mean_net_lifetime: 3816.4610, mean_mc_travel_dist: 1014.9161, mean_rewards: 343.9446, total_rewards: 2833.4710, mean_steps: 10.0600, mean_ecr: 0.0551 mean_entropies: 0.1573, took: 55.7595s
2022-10-11 03:56:45,238 [INFO] 	Process 2 - batch 79599: mean_policy_losses: 48.096, mean_net_lifetime: 7630.0525, mean_mc_travel_dist: 2096.3048, mean_rewards: 276.4131, total_rewards: 5560.4546, mean_steps: 26.6700, mean_ecr: 0.0378 mean_entropies: 0.4576, took: 775.4619s
2022-10-11 03:56:47,724 [INFO] 	Process 4 - batch 86199: mean_policy_losses: 141.383, mean_net_lifetime: 6098.0253, mean_mc_travel_dist: 1645.0551, mean_rewards: 287.3140, total_rewards: 4475.1576, mean_steps: 20.5500, mean_ecr: 0.0449 mean_entropies: 0.5550, took: 107.4223s
2022-10-11 03:56:48,294 [INFO] 	Process 3 - batch 87599: mean_policy_losses: 24.866, mean_net_lifetime: 5117.7173, mean_mc_travel_dist: 1297.4062, mean_rewards: 286.9934, total_rewards: 3850.7830, mean_steps: 16.8600, mean_ecr: 0.0463 mean_entropies: 0.4601, took: 90.7404s
2022-10-11 03:56:54,304 [INFO] 	Process 7 - batch 81099: mean_policy_losses: -544.940, mean_net_lifetime: 5032.3703, mean_mc_travel_dist: 1519.0213, mean_rewards: 208.5835, total_rewards: 3544.6805, mean_steps: 23.2300, mean_ecr: 0.0408 mean_entropies: 1.2692, took: 785.1788s
2022-10-11 03:57:19,627 [INFO] 	Process 1 - batch 72699: mean_policy_losses: 27.578, mean_net_lifetime: 6644.8707, mean_mc_travel_dist: 2125.8838, mean_rewards: 244.0274, total_rewards: 4545.4371, mean_steps: 26.4900, mean_ecr: 0.0380 mean_entropies: 0.8735, took: 131.3510s
2022-10-11 03:57:25,083 [INFO] 	Process 6 - batch 116499: mean_policy_losses: -227.041, mean_net_lifetime: 3717.2721, mean_mc_travel_dist: 997.5419, mean_rewards: 338.2201, total_rewards: 2753.9526, mean_steps: 9.9000, mean_ecr: 0.0556 mean_entropies: 0.1726, took: 56.1826s
2022-10-11 03:58:19,514 [INFO] 	Process 3 - batch 87699: mean_policy_losses: 20.611, mean_net_lifetime: 5111.4076, mean_mc_travel_dist: 1279.6483, mean_rewards: 282.0309, total_rewards: 3869.1828, mean_steps: 17.1600, mean_ecr: 0.0467 mean_entropies: 0.4615, took: 91.2199s
2022-10-11 03:58:26,337 [INFO] 	Process 6 - batch 116599: mean_policy_losses: -119.034, mean_net_lifetime: 4032.8803, mean_mc_travel_dist: 1061.6909, mean_rewards: 340.6446, total_rewards: 2998.3293, mean_steps: 10.7700, mean_ecr: 0.0550 mean_entropies: 0.1709, took: 61.2543s
2022-10-11 03:58:44,818 [INFO] 	Process 5 - batch 76399: mean_policy_losses: -163.835, mean_net_lifetime: 12490.2369, mean_mc_travel_dist: 3901.0218, mean_rewards: 258.7615, total_rewards: 8630.4278, mean_steps: 48.8100, mean_ecr: 0.0291 mean_entropies: 0.6630, took: 239.8838s
2022-10-11 03:58:53,448 [INFO] 	Process 2 - batch 79699: mean_policy_losses: 8.185, mean_net_lifetime: 7278.2064, mean_mc_travel_dist: 1945.5456, mean_rewards: 279.3119, total_rewards: 5360.0341, mean_steps: 25.1000, mean_ecr: 0.0384 mean_entropies: 0.4194, took: 128.2107s
2022-10-11 03:58:55,090 [INFO] 	Process 4 - batch 86299: mean_policy_losses: 190.028, mean_net_lifetime: 7153.1937, mean_mc_travel_dist: 1962.7557, mean_rewards: 285.2786, total_rewards: 5214.8965, mean_steps: 25.0900, mean_ecr: 0.0430 mean_entropies: 0.5077, took: 127.3666s
2022-10-11 03:59:00,856 [INFO] 	Process 7 - batch 81199: mean_policy_losses: -439.699, mean_net_lifetime: 5285.2373, mean_mc_travel_dist: 1603.2226, mean_rewards: 202.0716, total_rewards: 3720.2515, mean_steps: 25.4900, mean_ecr: 0.0404 mean_entropies: 1.2773, took: 126.5513s
2022-10-11 03:59:26,919 [INFO] 	Process 6 - batch 116699: mean_policy_losses: -84.498, mean_net_lifetime: 4004.3184, mean_mc_travel_dist: 1064.4683, mean_rewards: 337.2078, total_rewards: 2978.7329, mean_steps: 10.8300, mean_ecr: 0.0549 mean_entropies: 0.1905, took: 60.5827s
2022-10-11 03:59:31,820 [INFO] 	Process 1 - batch 72799: mean_policy_losses: 20.213, mean_net_lifetime: 6546.7427, mean_mc_travel_dist: 2097.2609, mean_rewards: 238.4759, total_rewards: 4479.4713, mean_steps: 26.8800, mean_ecr: 0.0380 mean_entropies: 0.8905, took: 132.1932s
2022-10-11 03:59:51,953 [INFO] 	Process 3 - batch 87799: mean_policy_losses: 18.226, mean_net_lifetime: 5138.9520, mean_mc_travel_dist: 1291.5790, mean_rewards: 281.1396, total_rewards: 3878.8882, mean_steps: 17.3300, mean_ecr: 0.0464 mean_entropies: 0.4556, took: 92.4384s
2022-10-11 04:00:27,145 [INFO] 	Process 6 - batch 116799: mean_policy_losses: -77.907, mean_net_lifetime: 3944.7130, mean_mc_travel_dist: 1042.8653, mean_rewards: 337.6828, total_rewards: 2949.3967, mean_steps: 10.6800, mean_ecr: 0.0550 mean_entropies: 0.1954, took: 60.2246s
2022-10-11 04:00:55,448 [INFO] 	Process 4 - batch 86399: mean_policy_losses: 148.878, mean_net_lifetime: 6542.2666, mean_mc_travel_dist: 1768.5091, mean_rewards: 283.7117, total_rewards: 4793.6564, mean_steps: 22.9800, mean_ecr: 0.0439 mean_entropies: 0.5147, took: 120.3579s
2022-10-11 04:01:00,880 [INFO] 	Process 7 - batch 81299: mean_policy_losses: -471.763, mean_net_lifetime: 5071.3442, mean_mc_travel_dist: 1519.2545, mean_rewards: 201.0101, total_rewards: 3588.3589, mean_steps: 24.4800, mean_ecr: 0.0406 mean_entropies: 1.2672, took: 120.0242s
2022-10-11 04:01:05,607 [INFO] 	Process 2 - batch 79799: mean_policy_losses: 11.151, mean_net_lifetime: 7482.7713, mean_mc_travel_dist: 2017.2497, mean_rewards: 273.2979, total_rewards: 5487.9205, mean_steps: 26.4400, mean_ecr: 0.0382 mean_entropies: 0.4501, took: 132.1582s
2022-10-11 04:01:27,931 [INFO] 	Process 6 - batch 116899: mean_policy_losses: -84.278, mean_net_lifetime: 3919.3872, mean_mc_travel_dist: 1048.8609, mean_rewards: 336.9852, total_rewards: 2920.8424, mean_steps: 10.5900, mean_ecr: 0.0552 mean_entropies: 0.1947, took: 60.7862s
2022-10-11 04:01:28,558 [INFO] 	Process 3 - batch 87899: mean_policy_losses: 29.555, mean_net_lifetime: 5231.3928, mean_mc_travel_dist: 1314.2579, mean_rewards: 278.4164, total_rewards: 3941.7858, mean_steps: 17.9000, mean_ecr: 0.0463 mean_entropies: 0.4599, took: 96.6061s
2022-10-11 04:01:38,008 [INFO] 	Process 1 - batch 72899: mean_policy_losses: 5.956, mean_net_lifetime: 6402.2518, mean_mc_travel_dist: 2031.0633, mean_rewards: 243.7898, total_rewards: 4397.5206, mean_steps: 25.4600, mean_ecr: 0.0382 mean_entropies: 0.9045, took: 126.1864s
2022-10-11 04:02:25,847 [INFO] 	Process 6 - batch 116999: mean_policy_losses: -160.362, mean_net_lifetime: 3710.5949, mean_mc_travel_dist: 1012.6998, mean_rewards: 335.2999, total_rewards: 2746.4987, mean_steps: 10.0300, mean_ecr: 0.0557 mean_entropies: 0.2001, took: 57.9164s
2022-10-11 04:02:40,370 [INFO] 	Process 5 - batch 76499: mean_policy_losses: -139.457, mean_net_lifetime: 12448.0855, mean_mc_travel_dist: 3825.5542, mean_rewards: 260.2733, total_rewards: 8660.9807, mean_steps: 48.3200, mean_ecr: 0.0294 mean_entropies: 0.6528, took: 235.5523s
2022-10-11 04:02:51,916 [INFO] 	Process 4 - batch 86499: mean_policy_losses: 134.634, mean_net_lifetime: 6651.8099, mean_mc_travel_dist: 1792.3562, mean_rewards: 288.8061, total_rewards: 4884.5938, mean_steps: 22.7700, mean_ecr: 0.0436 mean_entropies: 0.5062, took: 116.4682s
2022-10-11 04:02:58,823 [INFO] 	Process 7 - batch 81399: mean_policy_losses: -578.956, mean_net_lifetime: 4929.9629, mean_mc_travel_dist: 1455.6315, mean_rewards: 205.4230, total_rewards: 3504.6575, mean_steps: 23.1800, mean_ecr: 0.0409 mean_entropies: 1.2934, took: 117.9435s
2022-10-11 04:02:59,508 [INFO] 	Process 3 - batch 87999: mean_policy_losses: 3.629, mean_net_lifetime: 5212.9117, mean_mc_travel_dist: 1338.0368, mean_rewards: 283.5068, total_rewards: 3903.4489, mean_steps: 17.4600, mean_ecr: 0.0461 mean_entropies: 0.4447, took: 90.9492s
2022-10-11 04:03:15,249 [INFO] 	Process 2 - batch 79899: mean_policy_losses: 16.736, mean_net_lifetime: 7516.5121, mean_mc_travel_dist: 2029.5318, mean_rewards: 274.4845, total_rewards: 5511.4242, mean_steps: 26.4700, mean_ecr: 0.0380 mean_entropies: 0.4309, took: 129.6432s
2022-10-11 04:03:43,240 [INFO] 	Process 1 - batch 72999: mean_policy_losses: 11.719, mean_net_lifetime: 6529.4233, mean_mc_travel_dist: 2060.6879, mean_rewards: 248.1161, total_rewards: 4495.4214, mean_steps: 25.5700, mean_ecr: 0.0381 mean_entropies: 0.9167, took: 125.2332s
2022-10-11 04:04:29,859 [INFO] 	Process 3 - batch 88099: mean_policy_losses: -20.556, mean_net_lifetime: 5226.5568, mean_mc_travel_dist: 1368.5248, mean_rewards: 274.7357, total_rewards: 3886.5993, mean_steps: 18.2000, mean_ecr: 0.0459 mean_entropies: 0.4566, took: 90.3513s
2022-10-11 04:04:41,997 [INFO] 	Process 7 - batch 81499: mean_policy_losses: -706.358, mean_net_lifetime: 4720.3605, mean_mc_travel_dist: 1440.9008, mean_rewards: 211.8177, total_rewards: 3318.4461, mean_steps: 21.7700, mean_ecr: 0.0409 mean_entropies: 1.2851, took: 103.1740s
2022-10-11 04:04:49,548 [INFO] 	Process 4 - batch 86599: mean_policy_losses: 141.710, mean_net_lifetime: 7122.6673, mean_mc_travel_dist: 1984.4829, mean_rewards: 285.2052, total_rewards: 5160.5856, mean_steps: 24.7300, mean_ecr: 0.0423 mean_entropies: 0.4770, took: 117.6312s
2022-10-11 04:05:21,375 [INFO] 	Process 2 - batch 79999: mean_policy_losses: -12.121, mean_net_lifetime: 7443.8958, mean_mc_travel_dist: 2031.5560, mean_rewards: 272.2657, total_rewards: 5436.3261, mean_steps: 26.4400, mean_ecr: 0.0382 mean_entropies: 0.4219, took: 126.1246s
2022-10-11 04:05:44,889 [INFO] 	Process 1 - batch 73099: mean_policy_losses: -29.697, mean_net_lifetime: 6403.3056, mean_mc_travel_dist: 2022.1509, mean_rewards: 240.3531, total_rewards: 4403.4848, mean_steps: 25.8900, mean_ecr: 0.0382 mean_entropies: 0.9002, took: 121.6493s
2022-10-11 04:05:56,985 [INFO] 	Process 3 - batch 88199: mean_policy_losses: -32.061, mean_net_lifetime: 5105.2156, mean_mc_travel_dist: 1316.0095, mean_rewards: 270.6057, total_rewards: 3819.8137, mean_steps: 18.0100, mean_ecr: 0.0463 mean_entropies: 0.4771, took: 87.1263s
2022-10-11 04:06:22,580 [INFO] 	Process 7 - batch 81599: mean_policy_losses: -750.510, mean_net_lifetime: 4526.5294, mean_mc_travel_dist: 1400.5845, mean_rewards: 217.6728, total_rewards: 3164.8531, mean_steps: 20.1500, mean_ecr: 0.0412 mean_entropies: 1.3025, took: 100.5819s
2022-10-11 04:06:39,695 [INFO] 	Process 4 - batch 86699: mean_policy_losses: 105.301, mean_net_lifetime: 6195.6473, mean_mc_travel_dist: 1684.5565, mean_rewards: 288.1550, total_rewards: 4544.5218, mean_steps: 20.9800, mean_ecr: 0.0447 mean_entropies: 0.5217, took: 110.1470s
2022-10-11 04:07:22,150 [INFO] 	Process 3 - batch 88299: mean_policy_losses: -34.910, mean_net_lifetime: 5138.8251, mean_mc_travel_dist: 1321.1226, mean_rewards: 284.0478, total_rewards: 3850.6339, mean_steps: 17.1500, mean_ecr: 0.0463 mean_entropies: 0.4847, took: 85.1648s
2022-10-11 04:07:30,197 [INFO] 	Process 2 - batch 80099: mean_policy_losses: 7.767, mean_net_lifetime: 7604.5830, mean_mc_travel_dist: 2047.2836, mean_rewards: 279.0295, total_rewards: 5581.0493, mean_steps: 26.3900, mean_ecr: 0.0382 mean_entropies: 0.4302, took: 128.8226s
2022-10-11 04:07:44,322 [INFO] 	Process 1 - batch 73199: mean_policy_losses: -45.572, mean_net_lifetime: 6540.2307, mean_mc_travel_dist: 2080.7977, mean_rewards: 248.5683, total_rewards: 4491.3698, mean_steps: 25.5100, mean_ecr: 0.0382 mean_entropies: 0.9308, took: 119.4334s
2022-10-11 04:08:12,891 [INFO] 	Process 7 - batch 81699: mean_policy_losses: -569.361, mean_net_lifetime: 5107.7805, mean_mc_travel_dist: 1593.2047, mean_rewards: 210.1716, total_rewards: 3554.4100, mean_steps: 23.3600, mean_ecr: 0.0406 mean_entropies: 1.3187, took: 110.3117s
2022-10-11 04:08:29,668 [INFO] 	Process 4 - batch 86799: mean_policy_losses: 139.047, mean_net_lifetime: 6548.5604, mean_mc_travel_dist: 1819.8269, mean_rewards: 287.2889, total_rewards: 4756.5394, mean_steps: 22.5000, mean_ecr: 0.0442 mean_entropies: 0.4969, took: 109.9735s
2022-10-11 04:08:45,777 [INFO] 	Process 3 - batch 88399: mean_policy_losses: -36.921, mean_net_lifetime: 5017.6223, mean_mc_travel_dist: 1278.3934, mean_rewards: 280.2445, total_rewards: 3778.6195, mean_steps: 16.9300, mean_ecr: 0.0467 mean_entropies: 0.4693, took: 83.6265s
2022-10-11 04:09:32,848 [INFO] 	Process 2 - batch 80199: mean_policy_losses: 0.668, mean_net_lifetime: 7573.1263, mean_mc_travel_dist: 2066.9277, mean_rewards: 277.6332, total_rewards: 5526.9817, mean_steps: 26.4000, mean_ecr: 0.0381 mean_entropies: 0.4460, took: 122.6504s
2022-10-11 04:09:44,782 [INFO] 	Process 1 - batch 73299: mean_policy_losses: -30.630, mean_net_lifetime: 6513.3912, mean_mc_travel_dist: 2068.5973, mean_rewards: 244.2858, total_rewards: 4470.9305, mean_steps: 25.8600, mean_ecr: 0.0381 mean_entropies: 0.9077, took: 120.4583s
2022-10-11 04:10:05,253 [INFO] 	Process 7 - batch 81799: mean_policy_losses: -507.047, mean_net_lifetime: 5170.7720, mean_mc_travel_dist: 1577.9566, mean_rewards: 207.6557, total_rewards: 3625.1731, mean_steps: 24.1700, mean_ecr: 0.0407 mean_entropies: 1.2895, took: 112.3614s
2022-10-11 04:10:11,235 [INFO] 	Process 3 - batch 88499: mean_policy_losses: -25.723, mean_net_lifetime: 5018.6732, mean_mc_travel_dist: 1250.6185, mean_rewards: 283.1785, total_rewards: 3789.7437, mean_steps: 16.7500, mean_ecr: 0.0467 mean_entropies: 0.4555, took: 85.4575s
2022-10-11 04:10:32,189 [INFO] 	Process 4 - batch 86899: mean_policy_losses: 183.076, mean_net_lifetime: 7200.8217, mean_mc_travel_dist: 2003.1134, mean_rewards: 281.9372, total_rewards: 5225.5854, mean_steps: 25.5800, mean_ecr: 0.0427 mean_entropies: 0.5257, took: 122.5203s
2022-10-11 04:11:41,819 [INFO] 	Process 2 - batch 80299: mean_policy_losses: -12.890, mean_net_lifetime: 7655.7962, mean_mc_travel_dist: 2064.8015, mean_rewards: 274.6288, total_rewards: 5623.9319, mean_steps: 26.9600, mean_ecr: 0.0379 mean_entropies: 0.4247, took: 128.9718s
2022-10-11 04:11:43,546 [INFO] 	Process 1 - batch 73399: mean_policy_losses: -53.279, mean_net_lifetime: 6585.5587, mean_mc_travel_dist: 2081.5514, mean_rewards: 242.9006, total_rewards: 4523.6043, mean_steps: 26.2900, mean_ecr: 0.0381 mean_entropies: 0.8989, took: 118.7653s
2022-10-11 04:11:59,885 [INFO] 	Process 7 - batch 81899: mean_policy_losses: -521.513, mean_net_lifetime: 5082.5383, mean_mc_travel_dist: 1566.4000, mean_rewards: 202.5691, total_rewards: 3548.3186, mean_steps: 24.3500, mean_ecr: 0.0406 mean_entropies: 1.2688, took: 114.6329s
2022-10-11 04:12:57,435 [INFO] 	Process 4 - batch 86999: mean_policy_losses: 206.883, mean_net_lifetime: 8518.9425, mean_mc_travel_dist: 2484.5352, mean_rewards: 279.6874, total_rewards: 6060.7789, mean_steps: 32.0400, mean_ecr: 0.0411 mean_entropies: 0.5140, took: 145.2455s
2022-10-11 04:13:39,552 [INFO] 	Process 2 - batch 80399: mean_policy_losses: -12.991, mean_net_lifetime: 7613.1946, mean_mc_travel_dist: 2065.9264, mean_rewards: 277.9589, total_rewards: 5578.9978, mean_steps: 26.5000, mean_ecr: 0.0381 mean_entropies: 0.4427, took: 117.7329s
2022-10-11 04:13:45,755 [INFO] 	Process 1 - batch 73499: mean_policy_losses: -30.334, mean_net_lifetime: 6645.9123, mean_mc_travel_dist: 2118.1848, mean_rewards: 237.0030, total_rewards: 4546.7975, mean_steps: 27.3200, mean_ecr: 0.0380 mean_entropies: 0.9064, took: 122.2085s
2022-10-11 04:13:51,518 [INFO] 	Process 7 - batch 81999: mean_policy_losses: -397.653, mean_net_lifetime: 5479.7584, mean_mc_travel_dist: 1682.1187, mean_rewards: 207.8297, total_rewards: 3834.6051, mean_steps: 25.8400, mean_ecr: 0.0404 mean_entropies: 1.2834, took: 111.6335s
2022-10-11 04:13:51,728 [INFO] Process 6 - epoch 78: mean_policy_losses: -192.916, mean_net_lifetime: 3198.5240, mean_mc_travel_dist: 983.8893, mean_entropies: 0.5271, m_net_lifetime_valid: 4615.3250, took: 1538.5639s, (105.3378 / 100 batches)

2022-10-11 04:14:24,205 [INFO] Process 5 - epoch 51: mean_policy_losses: -193.507, mean_net_lifetime: 5497.8336, mean_mc_travel_dist: 2085.6242, mean_entropies: 1.1338, m_net_lifetime_valid: 4886.7168, took: 3641.3146s, (161.0516 / 100 batches)

2022-10-11 04:14:46,970 [INFO] 	Process 6 - batch 117099: mean_policy_losses: -50.132, mean_net_lifetime: 4100.3171, mean_mc_travel_dist: 1093.2771, mean_rewards: 337.7966, total_rewards: 3050.7948, mean_steps: 11.1100, mean_ecr: 0.0551 mean_entropies: 0.1822, took: 741.1229s
2022-10-11 04:15:38,954 [INFO] 	Process 2 - batch 80499: mean_policy_losses: 37.976, mean_net_lifetime: 7709.2752, mean_mc_travel_dist: 2078.1690, mean_rewards: 275.7181, total_rewards: 5659.9273, mean_steps: 27.0400, mean_ecr: 0.0379 mean_entropies: 0.4186, took: 119.4021s
2022-10-11 04:15:41,678 [INFO] 	Process 6 - batch 117199: mean_policy_losses: -68.688, mean_net_lifetime: 4028.0410, mean_mc_travel_dist: 1062.3663, mean_rewards: 337.5565, total_rewards: 3000.6134, mean_steps: 10.8500, mean_ecr: 0.0553 mean_entropies: 0.1800, took: 54.7086s
2022-10-11 04:15:46,834 [INFO] 	Process 7 - batch 82099: mean_policy_losses: -157.492, mean_net_lifetime: 5483.9544, mean_mc_travel_dist: 1669.0779, mean_rewards: 201.3065, total_rewards: 3846.0043, mean_steps: 26.6500, mean_ecr: 0.0402 mean_entropies: 1.2743, took: 115.3156s
2022-10-11 04:16:36,797 [INFO] 	Process 6 - batch 117299: mean_policy_losses: -73.910, mean_net_lifetime: 4063.2060, mean_mc_travel_dist: 1089.2594, mean_rewards: 342.6599, total_rewards: 3010.5142, mean_steps: 10.8400, mean_ecr: 0.0551 mean_entropies: 0.1628, took: 55.1188s
2022-10-11 04:17:08,519 [INFO] 	Process 5 - batch 76599: mean_policy_losses: -153.040, mean_net_lifetime: 9552.6184, mean_mc_travel_dist: 3081.6538, mean_rewards: 263.6430, total_rewards: 6520.0677, mean_steps: 36.6500, mean_ecr: 0.0295 mean_entropies: 0.5900, took: 868.1481s
2022-10-11 04:17:30,793 [INFO] 	Process 6 - batch 117399: mean_policy_losses: -82.937, mean_net_lifetime: 3947.0689, mean_mc_travel_dist: 1061.4230, mean_rewards: 340.0673, total_rewards: 2913.8491, mean_steps: 10.5600, mean_ecr: 0.0552 mean_entropies: 0.1677, took: 53.9964s
2022-10-11 04:17:34,262 [INFO] 	Process 7 - batch 82199: mean_policy_losses: -158.036, mean_net_lifetime: 5204.8221, mean_mc_travel_dist: 1601.2881, mean_rewards: 206.1191, total_rewards: 3641.2018, mean_steps: 24.3300, mean_ecr: 0.0405 mean_entropies: 1.2736, took: 107.4273s
2022-10-11 04:17:37,539 [INFO] 	Process 2 - batch 80599: mean_policy_losses: 50.828, mean_net_lifetime: 7683.4347, mean_mc_travel_dist: 2039.9824, mean_rewards: 281.1411, total_rewards: 5665.9561, mean_steps: 26.4000, mean_ecr: 0.0381 mean_entropies: 0.3951, took: 118.5844s
2022-10-11 04:18:26,379 [INFO] 	Process 6 - batch 117499: mean_policy_losses: -124.508, mean_net_lifetime: 4025.0453, mean_mc_travel_dist: 1066.2696, mean_rewards: 341.4920, total_rewards: 2993.8733, mean_steps: 10.7300, mean_ecr: 0.0549 mean_entropies: 0.1591, took: 55.5857s
2022-10-11 04:19:19,340 [INFO] 	Process 6 - batch 117599: mean_policy_losses: -111.879, mean_net_lifetime: 3927.8152, mean_mc_travel_dist: 1044.6178, mean_rewards: 343.4951, total_rewards: 2923.0425, mean_steps: 10.4100, mean_ecr: 0.0550 mean_entropies: 0.1593, took: 52.9617s
2022-10-11 04:19:26,804 [INFO] 	Process 7 - batch 82299: mean_policy_losses: -155.492, mean_net_lifetime: 5275.0888, mean_mc_travel_dist: 1640.6026, mean_rewards: 200.3900, total_rewards: 3667.7209, mean_steps: 25.6500, mean_ecr: 0.0403 mean_entropies: 1.2495, took: 112.5425s
2022-10-11 04:19:40,194 [INFO] 	Process 2 - batch 80699: mean_policy_losses: 57.672, mean_net_lifetime: 7770.4985, mean_mc_travel_dist: 2102.2185, mean_rewards: 278.4922, total_rewards: 5696.0243, mean_steps: 26.9900, mean_ecr: 0.0378 mean_entropies: 0.4212, took: 122.6555s
2022-10-11 04:19:51,942 [INFO] 	Process 5 - batch 76699: mean_policy_losses: -128.981, mean_net_lifetime: 9834.2595, mean_mc_travel_dist: 3119.5797, mean_rewards: 268.2038, total_rewards: 6767.1706, mean_steps: 37.0900, mean_ecr: 0.0297 mean_entropies: 0.5959, took: 163.4235s
2022-10-11 04:20:14,502 [INFO] 	Process 6 - batch 117699: mean_policy_losses: -52.698, mean_net_lifetime: 4088.4566, mean_mc_travel_dist: 1088.3601, mean_rewards: 345.2475, total_rewards: 3041.7786, mean_steps: 10.8300, mean_ecr: 0.0548 mean_entropies: 0.1563, took: 55.1617s
2022-10-11 04:21:05,913 [INFO] 	Process 6 - batch 117799: mean_policy_losses: -130.424, mean_net_lifetime: 3718.3988, mean_mc_travel_dist: 993.3184, mean_rewards: 344.3453, total_rewards: 2761.8220, mean_steps: 9.8000, mean_ecr: 0.0554 mean_entropies: 0.1937, took: 51.4102s
2022-10-11 04:21:12,217 [INFO] 	Process 7 - batch 82399: mean_policy_losses: -212.864, mean_net_lifetime: 5039.4241, mean_mc_travel_dist: 1546.0750, mean_rewards: 205.4294, total_rewards: 3520.1356, mean_steps: 23.8400, mean_ecr: 0.0408 mean_entropies: 1.2489, took: 105.4137s
2022-10-11 04:21:20,190 [INFO] Process 3 - epoch 59: mean_policy_losses: 50.372, mean_net_lifetime: 4409.5826, mean_mc_travel_dist: 1339.6599, mean_entropies: 0.8287, m_net_lifetime_valid: 4630.6791, took: 2002.0524s, (139.7469 / 100 batches)

2022-10-11 04:21:40,688 [INFO] 	Process 2 - batch 80799: mean_policy_losses: 56.264, mean_net_lifetime: 7580.8197, mean_mc_travel_dist: 2080.3425, mean_rewards: 273.0377, total_rewards: 5532.9408, mean_steps: 26.8500, mean_ecr: 0.0378 mean_entropies: 0.4616, took: 120.4933s
2022-10-11 04:22:03,104 [INFO] 	Process 6 - batch 117899: mean_policy_losses: -69.406, mean_net_lifetime: 4076.0806, mean_mc_travel_dist: 1087.2615, mean_rewards: 343.1428, total_rewards: 3024.2146, mean_steps: 10.8400, mean_ecr: 0.0553 mean_entropies: 0.1571, took: 57.1922s
2022-10-11 04:22:45,641 [INFO] 	Process 3 - batch 88599: mean_policy_losses: 31.948, mean_net_lifetime: 5097.6858, mean_mc_travel_dist: 1303.1896, mean_rewards: 279.7064, total_rewards: 3822.0085, mean_steps: 17.2600, mean_ecr: 0.0462 mean_entropies: 0.4593, took: 754.4066s
2022-10-11 04:22:50,119 [INFO] 	Process 5 - batch 76799: mean_policy_losses: -113.728, mean_net_lifetime: 10469.0962, mean_mc_travel_dist: 3314.0017, mean_rewards: 267.5666, total_rewards: 7195.6089, mean_steps: 39.6500, mean_ecr: 0.0297 mean_entropies: 0.5847, took: 178.1768s
2022-10-11 04:22:56,522 [INFO] 	Process 6 - batch 117999: mean_policy_losses: -150.408, mean_net_lifetime: 3810.9339, mean_mc_travel_dist: 1018.6809, mean_rewards: 341.6337, total_rewards: 2842.4052, mean_steps: 10.1100, mean_ecr: 0.0552 mean_entropies: 0.1809, took: 53.4169s
2022-10-11 04:23:02,025 [INFO] 	Process 7 - batch 82499: mean_policy_losses: -190.919, mean_net_lifetime: 5104.6704, mean_mc_travel_dist: 1569.3835, mean_rewards: 207.6115, total_rewards: 3562.4288, mean_steps: 24.0200, mean_ecr: 0.0407 mean_entropies: 1.2501, took: 109.8076s
2022-10-11 04:23:33,026 [INFO] Process 4 - epoch 58: mean_policy_losses: 101.201, mean_net_lifetime: 4726.8416, mean_mc_travel_dist: 1479.9747, mean_entropies: 1.0688, m_net_lifetime_valid: 4668.6595, took: 2445.2293s, (142.3450 / 100 batches)

2022-10-11 04:23:41,698 [INFO] Process 1 - epoch 49: mean_policy_losses: 20.828, mean_net_lifetime: 5309.4881, mean_mc_travel_dist: 2039.7224, mean_entropies: 1.1592, m_net_lifetime_valid: 4232.0383, took: 2428.2102s, (168.5203 / 100 batches)

2022-10-11 04:23:43,581 [INFO] 	Process 2 - batch 80899: mean_policy_losses: 39.706, mean_net_lifetime: 7581.5363, mean_mc_travel_dist: 2040.3314, mean_rewards: 276.1361, total_rewards: 5569.8337, mean_steps: 26.5500, mean_ecr: 0.0380 mean_entropies: 0.4147, took: 122.8933s
2022-10-11 04:23:45,918 [INFO] 	Process 6 - batch 118099: mean_policy_losses: -172.962, mean_net_lifetime: 3580.8804, mean_mc_travel_dist: 972.3565, mean_rewards: 340.5861, total_rewards: 2660.8898, mean_steps: 9.5300, mean_ecr: 0.0556 mean_entropies: 0.1704, took: 49.3965s
2022-10-11 04:24:08,761 [INFO] 	Process 3 - batch 88699: mean_policy_losses: 10.564, mean_net_lifetime: 4999.5080, mean_mc_travel_dist: 1280.4086, mean_rewards: 281.5564, total_rewards: 3755.4229, mean_steps: 16.8100, mean_ecr: 0.0465 mean_entropies: 0.4710, took: 83.1207s
2022-10-11 04:24:44,020 [INFO] 	Process 6 - batch 118199: mean_policy_losses: -128.012, mean_net_lifetime: 3984.1031, mean_mc_travel_dist: 1065.0646, mean_rewards: 339.1914, total_rewards: 2961.2045, mean_steps: 10.6800, mean_ecr: 0.0550 mean_entropies: 0.1765, took: 58.1017s
2022-10-11 04:25:37,356 [INFO] 	Process 3 - batch 88799: mean_policy_losses: 24.066, mean_net_lifetime: 5142.8981, mean_mc_travel_dist: 1306.8728, mean_rewards: 283.4176, total_rewards: 3867.2778, mean_steps: 17.1700, mean_ecr: 0.0463 mean_entropies: 0.4445, took: 88.5948s
2022-10-11 04:25:37,432 [INFO] 	Process 4 - batch 87099: mean_policy_losses: 266.585, mean_net_lifetime: 7041.0751, mean_mc_travel_dist: 2010.1089, mean_rewards: 281.1058, total_rewards: 5062.8654, mean_steps: 25.6600, mean_ecr: 0.0437 mean_entropies: 0.5001, took: 759.9984s
2022-10-11 04:25:41,898 [INFO] 	Process 1 - batch 73599: mean_policy_losses: -10.346, mean_net_lifetime: 6294.7110, mean_mc_travel_dist: 2040.6167, mean_rewards: 244.7271, total_rewards: 4271.7831, mean_steps: 24.9400, mean_ecr: 0.0382 mean_entropies: 0.8766, took: 716.1432s
2022-10-11 04:25:42,962 [INFO] 	Process 6 - batch 118299: mean_policy_losses: -78.071, mean_net_lifetime: 3974.3105, mean_mc_travel_dist: 1051.9058, mean_rewards: 336.6854, total_rewards: 2959.3972, mean_steps: 10.7700, mean_ecr: 0.0550 mean_entropies: 0.2067, took: 58.9422s
2022-10-11 04:25:47,257 [INFO] 	Process 5 - batch 76899: mean_policy_losses: -142.546, mean_net_lifetime: 10324.2614, mean_mc_travel_dist: 3390.3393, mean_rewards: 272.2393, total_rewards: 6972.2202, mean_steps: 38.5600, mean_ecr: 0.0295 mean_entropies: 0.5756, took: 177.1380s
2022-10-11 04:25:49,983 [INFO] 	Process 2 - batch 80999: mean_policy_losses: 22.842, mean_net_lifetime: 7479.9496, mean_mc_travel_dist: 1997.7409, mean_rewards: 276.0883, total_rewards: 5509.1328, mean_steps: 26.1900, mean_ecr: 0.0383 mean_entropies: 0.4076, took: 126.4029s
2022-10-11 04:26:39,383 [INFO] 	Process 6 - batch 118399: mean_policy_losses: -105.042, mean_net_lifetime: 3970.6728, mean_mc_travel_dist: 1052.9428, mean_rewards: 341.9319, total_rewards: 2956.2527, mean_steps: 10.5800, mean_ecr: 0.0550 mean_entropies: 0.1880, took: 56.4207s
2022-10-11 04:27:05,769 [INFO] 	Process 3 - batch 88899: mean_policy_losses: 29.935, mean_net_lifetime: 5245.8970, mean_mc_travel_dist: 1341.6058, mean_rewards: 284.0425, total_rewards: 3937.4693, mean_steps: 17.4900, mean_ecr: 0.0462 mean_entropies: 0.4422, took: 88.4122s
2022-10-11 04:27:37,652 [INFO] 	Process 6 - batch 118499: mean_policy_losses: -71.605, mean_net_lifetime: 4077.9386, mean_mc_travel_dist: 1086.4103, mean_rewards: 342.2243, total_rewards: 3019.5723, mean_steps: 10.9000, mean_ecr: 0.0550 mean_entropies: 0.1821, took: 58.2699s
2022-10-11 04:27:39,866 [INFO] 	Process 1 - batch 73699: mean_policy_losses: 2.766, mean_net_lifetime: 6397.1094, mean_mc_travel_dist: 2061.3378, mean_rewards: 248.1384, total_rewards: 4363.0496, mean_steps: 24.9400, mean_ecr: 0.0381 mean_entropies: 0.9167, took: 117.9678s
2022-10-11 04:27:49,300 [INFO] 	Process 4 - batch 87199: mean_policy_losses: 240.164, mean_net_lifetime: 7768.8660, mean_mc_travel_dist: 2201.7655, mean_rewards: 281.8838, total_rewards: 5593.2020, mean_steps: 28.3200, mean_ecr: 0.0430 mean_entropies: 0.4982, took: 131.8676s
2022-10-11 04:28:33,000 [INFO] 	Process 3 - batch 88999: mean_policy_losses: -10.814, mean_net_lifetime: 5252.7302, mean_mc_travel_dist: 1329.5188, mean_rewards: 281.1281, total_rewards: 3958.6617, mean_steps: 17.7500, mean_ecr: 0.0462 mean_entropies: 0.4578, took: 87.2319s
2022-10-11 04:29:02,526 [INFO] 	Process 5 - batch 76999: mean_policy_losses: -151.097, mean_net_lifetime: 11621.2092, mean_mc_travel_dist: 3719.8806, mean_rewards: 266.1175, total_rewards: 7937.7986, mean_steps: 44.2700, mean_ecr: 0.0289 mean_entropies: 0.6156, took: 195.2695s
2022-10-11 04:29:21,755 [INFO] 	Process 4 - batch 87299: mean_policy_losses: 88.762, mean_net_lifetime: 5783.0022, mean_mc_travel_dist: 1535.5172, mean_rewards: 288.9531, total_rewards: 4271.2485, mean_steps: 19.2900, mean_ecr: 0.0453 mean_entropies: 0.5101, took: 92.4553s
2022-10-11 04:29:38,758 [INFO] 	Process 1 - batch 73799: mean_policy_losses: -90.170, mean_net_lifetime: 6598.6079, mean_mc_travel_dist: 2100.3398, mean_rewards: 243.4924, total_rewards: 4526.5994, mean_steps: 26.3700, mean_ecr: 0.0380 mean_entropies: 0.9549, took: 118.8919s
2022-10-11 04:29:59,126 [INFO] 	Process 3 - batch 89099: mean_policy_losses: -33.498, mean_net_lifetime: 5205.5404, mean_mc_travel_dist: 1303.5183, mean_rewards: 282.1830, total_rewards: 3926.9324, mean_steps: 17.5000, mean_ecr: 0.0462 mean_entropies: 0.4631, took: 86.1256s
2022-10-11 04:31:14,740 [INFO] 	Process 4 - batch 87399: mean_policy_losses: 133.983, mean_net_lifetime: 7048.6278, mean_mc_travel_dist: 1938.7804, mean_rewards: 283.3158, total_rewards: 5144.3620, mean_steps: 24.7700, mean_ecr: 0.0430 mean_entropies: 0.4901, took: 112.9847s
2022-10-11 04:31:23,477 [INFO] 	Process 3 - batch 89199: mean_policy_losses: -22.978, mean_net_lifetime: 5176.7291, mean_mc_travel_dist: 1320.6359, mean_rewards: 277.5746, total_rewards: 3887.5643, mean_steps: 17.7200, mean_ecr: 0.0463 mean_entropies: 0.4588, took: 84.3512s
2022-10-11 04:31:28,134 [INFO] 	Process 1 - batch 73899: mean_policy_losses: -81.481, mean_net_lifetime: 6299.4193, mean_mc_travel_dist: 2011.1794, mean_rewards: 251.1271, total_rewards: 4309.3092, mean_steps: 24.2200, mean_ecr: 0.0384 mean_entropies: 0.8929, took: 109.3762s
2022-10-11 04:31:59,973 [INFO] 	Process 5 - batch 77099: mean_policy_losses: -232.996, mean_net_lifetime: 10621.9519, mean_mc_travel_dist: 3332.8598, mean_rewards: 266.8948, total_rewards: 7329.6445, mean_steps: 39.8200, mean_ecr: 0.0295 mean_entropies: 0.6103, took: 177.4467s
2022-10-11 04:32:50,918 [INFO] 	Process 3 - batch 89299: mean_policy_losses: -32.551, mean_net_lifetime: 5236.0217, mean_mc_travel_dist: 1344.9417, mean_rewards: 272.7073, total_rewards: 3916.9207, mean_steps: 18.2700, mean_ecr: 0.0459 mean_entropies: 0.4667, took: 87.4414s
2022-10-11 04:33:12,334 [INFO] 	Process 4 - batch 87499: mean_policy_losses: 117.266, mean_net_lifetime: 7441.4467, mean_mc_travel_dist: 2056.0364, mean_rewards: 285.4529, total_rewards: 5415.3290, mean_steps: 26.1600, mean_ecr: 0.0421 mean_entropies: 0.4572, took: 117.5940s
2022-10-11 04:33:25,416 [INFO] 	Process 1 - batch 73999: mean_policy_losses: -79.924, mean_net_lifetime: 6581.8193, mean_mc_travel_dist: 2081.4645, mean_rewards: 245.8720, total_rewards: 4524.8283, mean_steps: 25.9600, mean_ecr: 0.0380 mean_entropies: 0.9141, took: 117.2819s
2022-10-11 04:34:14,713 [INFO] 	Process 3 - batch 89399: mean_policy_losses: -32.303, mean_net_lifetime: 5188.4821, mean_mc_travel_dist: 1332.4789, mean_rewards: 276.0519, total_rewards: 3878.6027, mean_steps: 17.8700, mean_ecr: 0.0460 mean_entropies: 0.4779, took: 83.7930s
2022-10-11 04:35:05,224 [INFO] 	Process 5 - batch 77199: mean_policy_losses: -237.313, mean_net_lifetime: 10976.7555, mean_mc_travel_dist: 3428.3173, mean_rewards: 262.9273, total_rewards: 7585.1751, mean_steps: 42.2600, mean_ecr: 0.0293 mean_entropies: 0.6232, took: 185.2498s
2022-10-11 04:35:21,665 [INFO] 	Process 1 - batch 74099: mean_policy_losses: -70.565, mean_net_lifetime: 6549.6647, mean_mc_travel_dist: 2052.6515, mean_rewards: 246.8727, total_rewards: 4516.4517, mean_steps: 25.7800, mean_ecr: 0.0381 mean_entropies: 0.9171, took: 116.2493s
2022-10-11 04:35:26,970 [INFO] 	Process 4 - batch 87599: mean_policy_losses: 112.576, mean_net_lifetime: 8360.5964, mean_mc_travel_dist: 2378.0945, mean_rewards: 280.9231, total_rewards: 6010.2140, mean_steps: 30.2400, mean_ecr: 0.0405 mean_entropies: 0.4654, took: 134.6358s
2022-10-11 04:35:36,123 [INFO] Process 7 - epoch 55: mean_policy_losses: -364.988, mean_net_lifetime: 4253.7155, mean_mc_travel_dist: 1553.8775, mean_entropies: 1.5446, m_net_lifetime_valid: 4931.8768, took: 2437.2774s, (150.8319 / 100 batches)

2022-10-11 04:35:41,954 [INFO] 	Process 3 - batch 89499: mean_policy_losses: -22.484, mean_net_lifetime: 5294.2553, mean_mc_travel_dist: 1384.7003, mean_rewards: 276.1587, total_rewards: 3941.8349, mean_steps: 18.2400, mean_ecr: 0.0454 mean_entropies: 0.4901, took: 87.2430s
2022-10-11 04:36:48,683 [INFO] Process 2 - epoch 54: mean_policy_losses: -1.484, mean_net_lifetime: 5139.3169, mean_mc_travel_dist: 1667.4204, mean_entropies: 0.8658, m_net_lifetime_valid: 4522.4033, took: 2536.3429s, (153.8289 / 100 batches)

2022-10-11 04:37:11,316 [INFO] 	Process 3 - batch 89599: mean_policy_losses: -8.189, mean_net_lifetime: 5160.3961, mean_mc_travel_dist: 1403.7865, mean_rewards: 278.8083, total_rewards: 3786.5525, mean_steps: 17.5100, mean_ecr: 0.0453 mean_entropies: 0.5147, took: 89.3614s
2022-10-11 04:37:25,752 [INFO] 	Process 7 - batch 82599: mean_policy_losses: -634.984, mean_net_lifetime: 5120.2436, mean_mc_travel_dist: 1599.8947, mean_rewards: 208.2247, total_rewards: 3554.7816, mean_steps: 23.5200, mean_ecr: 0.0406 mean_entropies: 1.3796, took: 863.7264s
2022-10-11 04:37:31,927 [INFO] 	Process 1 - batch 74199: mean_policy_losses: -22.643, mean_net_lifetime: 6690.9669, mean_mc_travel_dist: 2077.4425, mean_rewards: 237.1936, total_rewards: 4637.2323, mean_steps: 27.4800, mean_ecr: 0.0382 mean_entropies: 0.9487, took: 130.2610s
2022-10-11 04:38:13,170 [INFO] 	Process 4 - batch 87699: mean_policy_losses: 157.601, mean_net_lifetime: 9394.1454, mean_mc_travel_dist: 2834.2285, mean_rewards: 278.0552, total_rewards: 6585.5177, mean_steps: 36.1300, mean_ecr: 0.0408 mean_entropies: 0.4952, took: 166.1998s
2022-10-11 04:38:22,252 [INFO] 	Process 5 - batch 77299: mean_policy_losses: -210.149, mean_net_lifetime: 11013.4431, mean_mc_travel_dist: 3568.0709, mean_rewards: 263.2902, total_rewards: 7481.8034, mean_steps: 42.5300, mean_ecr: 0.0290 mean_entropies: 0.6655, took: 197.0286s
2022-10-11 04:38:41,106 [INFO] 	Process 3 - batch 89699: mean_policy_losses: -1.100, mean_net_lifetime: 5238.1691, mean_mc_travel_dist: 1415.1564, mean_rewards: 282.2138, total_rewards: 3862.4146, mean_steps: 17.6000, mean_ecr: 0.0456 mean_entropies: 0.5090, took: 89.7903s
2022-10-11 04:38:54,229 [INFO] 	Process 2 - batch 81099: mean_policy_losses: 10.938, mean_net_lifetime: 7481.0193, mean_mc_travel_dist: 2004.5518, mean_rewards: 276.8806, total_rewards: 5502.7315, mean_steps: 26.0900, mean_ecr: 0.0383 mean_entropies: 0.4092, took: 784.2449s
2022-10-11 04:39:15,171 [INFO] Process 6 - epoch 79: mean_policy_losses: -191.715, mean_net_lifetime: 3208.1404, mean_mc_travel_dist: 984.7966, mean_entropies: 0.5227, m_net_lifetime_valid: 4525.9656, took: 1523.4407s, (105.2802 / 100 batches)

2022-10-11 04:39:19,465 [INFO] 	Process 7 - batch 82699: mean_policy_losses: -517.838, mean_net_lifetime: 5158.4136, mean_mc_travel_dist: 1616.5411, mean_rewards: 210.0071, total_rewards: 3570.1526, mean_steps: 23.8000, mean_ecr: 0.0404 mean_entropies: 1.2841, took: 113.7134s
2022-10-11 04:39:29,984 [INFO] 	Process 1 - batch 74299: mean_policy_losses: 10.019, mean_net_lifetime: 6409.1885, mean_mc_travel_dist: 2055.0696, mean_rewards: 256.6049, total_rewards: 4376.0782, mean_steps: 24.1500, mean_ecr: 0.0382 mean_entropies: 0.8875, took: 118.0570s
2022-10-11 04:40:11,917 [INFO] 	Process 6 - batch 118599: mean_policy_losses: -128.361, mean_net_lifetime: 3730.1269, mean_mc_travel_dist: 1007.9030, mean_rewards: 339.7135, total_rewards: 2761.8785, mean_steps: 9.9200, mean_ecr: 0.0555 mean_entropies: 0.1921, took: 754.2647s
2022-10-11 04:40:13,969 [INFO] 	Process 3 - batch 89799: mean_policy_losses: 26.973, mean_net_lifetime: 5179.7609, mean_mc_travel_dist: 1356.6355, mean_rewards: 281.3590, total_rewards: 3851.3558, mean_steps: 17.4500, mean_ecr: 0.0458 mean_entropies: 0.4846, took: 92.8631s
2022-10-11 04:41:02,719 [INFO] 	Process 2 - batch 81199: mean_policy_losses: 25.492, mean_net_lifetime: 7338.7318, mean_mc_travel_dist: 1988.5463, mean_rewards: 276.4579, total_rewards: 5370.5305, mean_steps: 25.7400, mean_ecr: 0.0382 mean_entropies: 0.4050, took: 128.4910s
2022-10-11 04:41:08,694 [INFO] 	Process 6 - batch 118699: mean_policy_losses: -156.044, mean_net_lifetime: 3703.9757, mean_mc_travel_dist: 997.1712, mean_rewards: 338.6640, total_rewards: 2745.2075, mean_steps: 9.8600, mean_ecr: 0.0554 mean_entropies: 0.1928, took: 56.7771s
2022-10-11 04:41:24,907 [INFO] 	Process 7 - batch 82799: mean_policy_losses: -352.255, mean_net_lifetime: 5353.0029, mean_mc_travel_dist: 1666.5074, mean_rewards: 207.2836, total_rewards: 3721.0235, mean_steps: 25.2800, mean_ecr: 0.0404 mean_entropies: 1.2722, took: 125.4419s
2022-10-11 04:41:33,802 [INFO] 	Process 1 - batch 74399: mean_policy_losses: 26.765, mean_net_lifetime: 6436.7006, mean_mc_travel_dist: 2034.6620, mean_rewards: 250.5842, total_rewards: 4423.9416, mean_steps: 24.8200, mean_ecr: 0.0382 mean_entropies: 0.9621, took: 123.8183s
2022-10-11 04:41:42,620 [INFO] 	Process 4 - batch 87799: mean_policy_losses: 250.591, mean_net_lifetime: 11130.3322, mean_mc_travel_dist: 3476.1227, mean_rewards: 273.8077, total_rewards: 7679.0699, mean_steps: 44.2100, mean_ecr: 0.0399 mean_entropies: 0.4547, took: 209.4507s
2022-10-11 04:41:47,451 [INFO] 	Process 3 - batch 89899: mean_policy_losses: 28.887, mean_net_lifetime: 5220.7257, mean_mc_travel_dist: 1361.3453, mean_rewards: 282.4415, total_rewards: 3890.7217, mean_steps: 17.5400, mean_ecr: 0.0458 mean_entropies: 0.4514, took: 93.4813s
2022-10-11 04:42:05,283 [INFO] 	Process 6 - batch 118799: mean_policy_losses: -134.977, mean_net_lifetime: 3720.8179, mean_mc_travel_dist: 1001.2589, mean_rewards: 341.4876, total_rewards: 2755.5776, mean_steps: 9.8600, mean_ecr: 0.0555 mean_entropies: 0.1878, took: 56.5886s
2022-10-11 04:42:25,696 [INFO] 	Process 5 - batch 77399: mean_policy_losses: -149.214, mean_net_lifetime: 12570.6051, mean_mc_travel_dist: 4078.9204, mean_rewards: 257.1492, total_rewards: 8543.2699, mean_steps: 50.3900, mean_ecr: 0.0288 mean_entropies: 0.6376, took: 243.4442s
2022-10-11 04:43:01,621 [INFO] 	Process 6 - batch 118899: mean_policy_losses: -151.251, mean_net_lifetime: 3763.3710, mean_mc_travel_dist: 995.7478, mean_rewards: 338.9560, total_rewards: 2797.1276, mean_steps: 10.0200, mean_ecr: 0.0553 mean_entropies: 0.1813, took: 56.3378s
2022-10-11 04:43:11,204 [INFO] 	Process 2 - batch 81299: mean_policy_losses: 35.669, mean_net_lifetime: 7501.1617, mean_mc_travel_dist: 2023.0581, mean_rewards: 280.5302, total_rewards: 5502.7477, mean_steps: 25.8800, mean_ecr: 0.0382 mean_entropies: 0.4368, took: 128.4842s
2022-10-11 04:43:18,128 [INFO] 	Process 3 - batch 89999: mean_policy_losses: 10.062, mean_net_lifetime: 5122.4811, mean_mc_travel_dist: 1310.6070, mean_rewards: 283.7829, total_rewards: 3843.6011, mean_steps: 17.0800, mean_ecr: 0.0462 mean_entropies: 0.4869, took: 90.6762s
2022-10-11 04:43:30,400 [INFO] 	Process 7 - batch 82899: mean_policy_losses: -377.279, mean_net_lifetime: 5356.0648, mean_mc_travel_dist: 1624.3376, mean_rewards: 204.1950, total_rewards: 3773.4840, mean_steps: 25.4100, mean_ecr: 0.0404 mean_entropies: 1.2875, took: 125.4930s
2022-10-11 04:43:35,784 [INFO] 	Process 1 - batch 74499: mean_policy_losses: -11.780, mean_net_lifetime: 6432.4798, mean_mc_travel_dist: 2068.6415, mean_rewards: 253.4404, total_rewards: 4384.3259, mean_steps: 24.5000, mean_ecr: 0.0382 mean_entropies: 0.9608, took: 121.9822s
2022-10-11 04:44:00,871 [INFO] 	Process 6 - batch 118999: mean_policy_losses: -81.311, mean_net_lifetime: 3974.1844, mean_mc_travel_dist: 1064.2220, mean_rewards: 340.6722, total_rewards: 2935.3921, mean_steps: 10.6100, mean_ecr: 0.0550 mean_entropies: 0.1718, took: 59.2505s
2022-10-11 04:44:03,497 [INFO] 	Process 4 - batch 87899: mean_policy_losses: 204.994, mean_net_lifetime: 7815.5470, mean_mc_travel_dist: 2243.7915, mean_rewards: 280.3710, total_rewards: 5601.4857, mean_steps: 28.6000, mean_ecr: 0.0433 mean_entropies: 0.5055, took: 140.8767s
2022-10-11 04:44:57,096 [INFO] 	Process 6 - batch 119099: mean_policy_losses: -160.111, mean_net_lifetime: 3849.8897, mean_mc_travel_dist: 1029.3862, mean_rewards: 339.5666, total_rewards: 2869.9455, mean_steps: 10.2400, mean_ecr: 0.0551 mean_entropies: 0.1512, took: 56.2247s
2022-10-11 04:45:16,004 [INFO] 	Process 2 - batch 81399: mean_policy_losses: 35.824, mean_net_lifetime: 7333.6185, mean_mc_travel_dist: 1957.1580, mean_rewards: 277.7714, total_rewards: 5405.1594, mean_steps: 25.4700, mean_ecr: 0.0385 mean_entropies: 0.4258, took: 124.8011s
2022-10-11 04:45:22,239 [INFO] 	Process 7 - batch 82999: mean_policy_losses: -502.813, mean_net_lifetime: 4932.2261, mean_mc_travel_dist: 1516.9383, mean_rewards: 204.4319, total_rewards: 3454.8685, mean_steps: 23.2500, mean_ecr: 0.0409 mean_entropies: 1.3571, took: 111.8391s
2022-10-11 04:45:35,937 [INFO] 	Process 1 - batch 74599: mean_policy_losses: -4.328, mean_net_lifetime: 6307.5301, mean_mc_travel_dist: 2013.7057, mean_rewards: 245.6920, total_rewards: 4312.3225, mean_steps: 24.8300, mean_ecr: 0.0383 mean_entropies: 0.9392, took: 120.1539s
2022-10-11 04:45:56,870 [INFO] 	Process 6 - batch 119199: mean_policy_losses: -77.503, mean_net_lifetime: 4043.4494, mean_mc_travel_dist: 1081.8770, mean_rewards: 343.1326, total_rewards: 2998.1432, mean_steps: 10.7500, mean_ecr: 0.0551 mean_entropies: 0.1583, took: 59.7734s
2022-10-11 04:46:11,632 [INFO] 	Process 5 - batch 77499: mean_policy_losses: -143.834, mean_net_lifetime: 12112.9494, mean_mc_travel_dist: 3926.5272, mean_rewards: 262.2130, total_rewards: 8227.9811, mean_steps: 47.8100, mean_ecr: 0.0291 mean_entropies: 0.6341, took: 225.9355s
2022-10-11 04:46:44,645 [INFO] 	Process 4 - batch 87999: mean_policy_losses: 272.138, mean_net_lifetime: 9057.0810, mean_mc_travel_dist: 2646.9564, mean_rewards: 277.1756, total_rewards: 6438.8413, mean_steps: 33.6600, mean_ecr: 0.0409 mean_entropies: 0.5125, took: 161.1483s
2022-10-11 04:46:54,679 [INFO] 	Process 6 - batch 119299: mean_policy_losses: -97.961, mean_net_lifetime: 3970.9773, mean_mc_travel_dist: 1072.6534, mean_rewards: 340.7901, total_rewards: 2947.1020, mean_steps: 10.6100, mean_ecr: 0.0551 mean_entropies: 0.1581, took: 57.8099s
2022-10-11 04:47:12,988 [INFO] 	Process 2 - batch 81499: mean_policy_losses: -12.442, mean_net_lifetime: 6683.4744, mean_mc_travel_dist: 1784.1588, mean_rewards: 271.3676, total_rewards: 4931.5256, mean_steps: 23.7000, mean_ecr: 0.0391 mean_entropies: 0.3916, took: 116.9834s
2022-10-11 04:47:19,647 [INFO] 	Process 7 - batch 83099: mean_policy_losses: -334.321, mean_net_lifetime: 5265.4529, mean_mc_travel_dist: 1596.1676, mean_rewards: 205.8998, total_rewards: 3705.6450, mean_steps: 24.6700, mean_ecr: 0.0404 mean_entropies: 1.2940, took: 117.4083s
2022-10-11 04:47:35,927 [INFO] 	Process 1 - batch 74699: mean_policy_losses: 17.531, mean_net_lifetime: 6434.7586, mean_mc_travel_dist: 2013.0019, mean_rewards: 250.8451, total_rewards: 4441.4088, mean_steps: 24.8600, mean_ecr: 0.0384 mean_entropies: 0.9664, took: 119.9892s
2022-10-11 04:47:52,422 [INFO] 	Process 6 - batch 119399: mean_policy_losses: -63.631, mean_net_lifetime: 4126.1837, mean_mc_travel_dist: 1088.3235, mean_rewards: 343.4173, total_rewards: 3067.7523, mean_steps: 11.0000, mean_ecr: 0.0551 mean_entropies: 0.1641, took: 57.7433s
2022-10-11 04:48:50,734 [INFO] 	Process 6 - batch 119499: mean_policy_losses: -146.800, mean_net_lifetime: 4022.8112, mean_mc_travel_dist: 1066.8104, mean_rewards: 342.2927, total_rewards: 2991.2005, mean_steps: 10.7100, mean_ecr: 0.0550 mean_entropies: 0.1668, took: 58.3122s
2022-10-11 04:49:13,556 [INFO] 	Process 7 - batch 83199: mean_policy_losses: -448.272, mean_net_lifetime: 5171.2831, mean_mc_travel_dist: 1582.7582, mean_rewards: 208.4015, total_rewards: 3627.9002, mean_steps: 23.9900, mean_ecr: 0.0406 mean_entropies: 1.3116, took: 113.9089s
2022-10-11 04:49:17,018 [INFO] 	Process 4 - batch 88099: mean_policy_losses: 266.566, mean_net_lifetime: 8574.6511, mean_mc_travel_dist: 2480.6436, mean_rewards: 279.2339, total_rewards: 6128.4608, mean_steps: 31.9400, mean_ecr: 0.0415 mean_entropies: 0.5441, took: 152.3725s
2022-10-11 04:49:20,561 [INFO] 	Process 2 - batch 81599: mean_policy_losses: 46.991, mean_net_lifetime: 7668.8566, mean_mc_travel_dist: 2050.4323, mean_rewards: 280.6126, total_rewards: 5641.4571, mean_steps: 26.4300, mean_ecr: 0.0381 mean_entropies: 0.4333, took: 127.5724s
2022-10-11 04:49:42,000 [INFO] 	Process 1 - batch 74799: mean_policy_losses: 63.994, mean_net_lifetime: 6734.0161, mean_mc_travel_dist: 2116.6746, mean_rewards: 252.2750, total_rewards: 4641.0045, mean_steps: 25.8200, mean_ecr: 0.0382 mean_entropies: 0.9990, took: 126.0732s
2022-10-11 04:49:46,103 [INFO] 	Process 5 - batch 77599: mean_policy_losses: -172.748, mean_net_lifetime: 11686.1433, mean_mc_travel_dist: 3722.8357, mean_rewards: 262.2326, total_rewards: 8009.7249, mean_steps: 45.3000, mean_ecr: 0.0290 mean_entropies: 0.6432, took: 214.4721s
2022-10-11 04:49:47,482 [INFO] 	Process 6 - batch 119599: mean_policy_losses: -110.720, mean_net_lifetime: 3927.1211, mean_mc_travel_dist: 1040.9954, mean_rewards: 340.7231, total_rewards: 2924.7650, mean_steps: 10.4800, mean_ecr: 0.0551 mean_entropies: 0.1779, took: 56.7468s
2022-10-11 04:50:45,636 [INFO] 	Process 6 - batch 119699: mean_policy_losses: -95.311, mean_net_lifetime: 4056.1320, mean_mc_travel_dist: 1070.5466, mean_rewards: 343.2805, total_rewards: 3019.3635, mean_steps: 10.7800, mean_ecr: 0.0550 mean_entropies: 0.1858, took: 58.1549s
2022-10-11 04:51:18,572 [INFO] 	Process 7 - batch 83299: mean_policy_losses: -386.714, mean_net_lifetime: 5330.9717, mean_mc_travel_dist: 1632.1964, mean_rewards: 197.1681, total_rewards: 3736.7658, mean_steps: 26.3900, mean_ecr: 0.0403 mean_entropies: 1.2821, took: 125.0157s
2022-10-11 04:51:27,093 [INFO] 	Process 2 - batch 81699: mean_policy_losses: 23.600, mean_net_lifetime: 7552.6284, mean_mc_travel_dist: 2042.4326, mean_rewards: 278.8035, total_rewards: 5540.5805, mean_steps: 26.1700, mean_ecr: 0.0380 mean_entropies: 0.4415, took: 126.5324s
2022-10-11 04:51:37,050 [INFO] 	Process 4 - batch 88199: mean_policy_losses: 262.225, mean_net_lifetime: 7928.0682, mean_mc_travel_dist: 2245.0897, mean_rewards: 275.6995, total_rewards: 5706.7575, mean_steps: 29.1600, mean_ecr: 0.0415 mean_entropies: 0.5457, took: 140.0322s
2022-10-11 04:51:45,578 [INFO] 	Process 6 - batch 119799: mean_policy_losses: -53.858, mean_net_lifetime: 4154.4130, mean_mc_travel_dist: 1096.5613, mean_rewards: 340.0855, total_rewards: 3095.9132, mean_steps: 11.2000, mean_ecr: 0.0548 mean_entropies: 0.1927, took: 59.9420s
2022-10-11 04:51:53,860 [INFO] 	Process 1 - batch 74899: mean_policy_losses: 67.384, mean_net_lifetime: 6862.9905, mean_mc_travel_dist: 2134.0071, mean_rewards: 249.1022, total_rewards: 4757.2002, mean_steps: 26.6900, mean_ecr: 0.0381 mean_entropies: 1.0218, took: 131.8596s
2022-10-11 04:52:41,002 [INFO] 	Process 6 - batch 119899: mean_policy_losses: -150.944, mean_net_lifetime: 3741.7437, mean_mc_travel_dist: 1010.2327, mean_rewards: 336.9426, total_rewards: 2774.2556, mean_steps: 10.0400, mean_ecr: 0.0554 mean_entropies: 0.2081, took: 55.4235s
2022-10-11 04:52:52,736 [INFO] 	Process 5 - batch 77699: mean_policy_losses: -164.265, mean_net_lifetime: 10356.7539, mean_mc_travel_dist: 3272.3478, mean_rewards: 264.4250, total_rewards: 7132.3591, mean_steps: 39.5700, mean_ecr: 0.0294 mean_entropies: 0.6439, took: 186.6327s
2022-10-11 04:53:16,855 [INFO] 	Process 7 - batch 83399: mean_policy_losses: -436.988, mean_net_lifetime: 5241.2116, mean_mc_travel_dist: 1596.9242, mean_rewards: 205.1941, total_rewards: 3676.1262, mean_steps: 25.0300, mean_ecr: 0.0405 mean_entropies: 1.2612, took: 118.2831s
2022-10-11 04:53:32,270 [INFO] 	Process 2 - batch 81799: mean_policy_losses: 33.869, mean_net_lifetime: 7564.1961, mean_mc_travel_dist: 2035.5180, mean_rewards: 281.5402, total_rewards: 5552.2442, mean_steps: 25.9500, mean_ecr: 0.0382 mean_entropies: 0.4347, took: 125.1773s
2022-10-11 04:53:36,977 [INFO] 	Process 4 - batch 88299: mean_policy_losses: 206.435, mean_net_lifetime: 6969.6421, mean_mc_travel_dist: 1938.5916, mean_rewards: 283.4942, total_rewards: 5060.1235, mean_steps: 24.5100, mean_ecr: 0.0433 mean_entropies: 0.5282, took: 119.9272s
2022-10-11 04:53:37,296 [INFO] 	Process 6 - batch 119999: mean_policy_losses: -99.426, mean_net_lifetime: 3929.2343, mean_mc_travel_dist: 1047.9352, mean_rewards: 339.6900, total_rewards: 2929.3981, mean_steps: 10.5200, mean_ecr: 0.0552 mean_entropies: 0.1778, took: 56.2940s
2022-10-11 04:53:57,245 [INFO] 	Process 1 - batch 74999: mean_policy_losses: 31.928, mean_net_lifetime: 6689.0053, mean_mc_travel_dist: 2105.6680, mean_rewards: 254.8145, total_rewards: 4618.8252, mean_steps: 25.3900, mean_ecr: 0.0380 mean_entropies: 0.9618, took: 123.3855s
2022-10-11 04:54:04,510 [INFO] Process 3 - epoch 60: mean_policy_losses: 49.531, mean_net_lifetime: 4422.4910, mean_mc_travel_dist: 1339.6605, mean_entropies: 0.8228, m_net_lifetime_valid: 4388.8305, took: 1964.3179s, (139.6256 / 100 batches)

2022-10-11 04:55:10,253 [INFO] 	Process 7 - batch 83499: mean_policy_losses: -471.294, mean_net_lifetime: 5159.0037, mean_mc_travel_dist: 1566.3176, mean_rewards: 203.6653, total_rewards: 3629.4921, mean_steps: 24.5900, mean_ecr: 0.0406 mean_entropies: 1.2544, took: 113.3979s
2022-10-11 04:55:28,688 [INFO] 	Process 5 - batch 77799: mean_policy_losses: -218.179, mean_net_lifetime: 8785.4596, mean_mc_travel_dist: 2730.2717, mean_rewards: 260.8356, total_rewards: 6096.6667, mean_steps: 33.3300, mean_ecr: 0.0297 mean_entropies: 0.6222, took: 155.9523s
2022-10-11 04:55:28,886 [INFO] 	Process 3 - batch 90099: mean_policy_losses: 2.368, mean_net_lifetime: 5077.9453, mean_mc_travel_dist: 1288.2048, mean_rewards: 278.0739, total_rewards: 3822.8340, mean_steps: 17.3200, mean_ecr: 0.0465 mean_entropies: 0.4549, took: 730.7589s
2022-10-11 04:55:33,388 [INFO] 	Process 4 - batch 88399: mean_policy_losses: 177.054, mean_net_lifetime: 7024.4314, mean_mc_travel_dist: 1964.0284, mean_rewards: 285.7246, total_rewards: 5092.2896, mean_steps: 24.8000, mean_ecr: 0.0432 mean_entropies: 0.5130, took: 116.4102s
2022-10-11 04:55:33,554 [INFO] 	Process 2 - batch 81899: mean_policy_losses: 23.560, mean_net_lifetime: 7498.3357, mean_mc_travel_dist: 2046.8414, mean_rewards: 277.5480, total_rewards: 5483.3533, mean_steps: 26.0900, mean_ecr: 0.0380 mean_entropies: 0.4490, took: 121.2834s
2022-10-11 04:56:59,071 [INFO] 	Process 3 - batch 90199: mean_policy_losses: 8.518, mean_net_lifetime: 5158.5129, mean_mc_travel_dist: 1313.1688, mean_rewards: 270.8351, total_rewards: 3867.9453, mean_steps: 18.1200, mean_ecr: 0.0459 mean_entropies: 0.4560, took: 90.1849s
2022-10-11 04:57:04,446 [INFO] 	Process 7 - batch 83599: mean_policy_losses: -393.086, mean_net_lifetime: 5099.4072, mean_mc_travel_dist: 1562.0198, mean_rewards: 199.2871, total_rewards: 3571.8931, mean_steps: 24.9300, mean_ecr: 0.0405 mean_entropies: 1.2182, took: 114.1936s
2022-10-11 04:57:35,881 [INFO] 	Process 2 - batch 81999: mean_policy_losses: 4.025, mean_net_lifetime: 7429.4439, mean_mc_travel_dist: 1997.4267, mean_rewards: 274.2154, total_rewards: 5461.8600, mean_steps: 26.2000, mean_ecr: 0.0382 mean_entropies: 0.3977, took: 122.3277s
2022-10-11 04:57:49,488 [INFO] 	Process 4 - batch 88499: mean_policy_losses: 190.392, mean_net_lifetime: 7902.2369, mean_mc_travel_dist: 2272.9399, mean_rewards: 281.8947, total_rewards: 5665.1993, mean_steps: 29.3200, mean_ecr: 0.0425 mean_entropies: 0.4809, took: 136.1000s
2022-10-11 04:58:09,064 [INFO] 	Process 5 - batch 77899: mean_policy_losses: -218.829, mean_net_lifetime: 9222.0187, mean_mc_travel_dist: 2921.6191, mean_rewards: 266.3042, total_rewards: 6348.7385, mean_steps: 34.5200, mean_ecr: 0.0295 mean_entropies: 0.6349, took: 160.3756s
2022-10-11 04:58:24,131 [INFO] 	Process 3 - batch 90299: mean_policy_losses: 24.242, mean_net_lifetime: 5303.5345, mean_mc_travel_dist: 1396.9497, mean_rewards: 280.6624, total_rewards: 3933.3810, mean_steps: 17.9400, mean_ecr: 0.0455 mean_entropies: 0.4984, took: 85.0608s
2022-10-11 04:58:49,240 [INFO] 	Process 7 - batch 83699: mean_policy_losses: -480.611, mean_net_lifetime: 4875.6936, mean_mc_travel_dist: 1462.9184, mean_rewards: 204.8477, total_rewards: 3441.2518, mean_steps: 23.1100, mean_ecr: 0.0409 mean_entropies: 1.2618, took: 104.7941s
2022-10-11 04:59:29,136 [INFO] 	Process 2 - batch 82099: mean_policy_losses: -17.255, mean_net_lifetime: 7264.1006, mean_mc_travel_dist: 1951.5993, mean_rewards: 282.2655, total_rewards: 5331.8292, mean_steps: 24.8500, mean_ecr: 0.0385 mean_entropies: 0.4331, took: 113.2534s
2022-10-11 04:59:51,341 [INFO] 	Process 3 - batch 90399: mean_policy_losses: 1.918, mean_net_lifetime: 5320.0702, mean_mc_travel_dist: 1380.6558, mean_rewards: 276.5320, total_rewards: 3968.5786, mean_steps: 18.3100, mean_ecr: 0.0457 mean_entropies: 0.4886, took: 87.2097s
2022-10-11 05:00:27,760 [INFO] 	Process 7 - batch 83799: mean_policy_losses: -444.510, mean_net_lifetime: 4693.9941, mean_mc_travel_dist: 1399.5679, mean_rewards: 207.3534, total_rewards: 3340.8791, mean_steps: 21.8400, mean_ecr: 0.0412 mean_entropies: 1.2905, took: 98.5197s
2022-10-11 05:01:13,158 [INFO] 	Process 3 - batch 90499: mean_policy_losses: 11.575, mean_net_lifetime: 5259.4719, mean_mc_travel_dist: 1373.0417, mean_rewards: 286.7493, total_rewards: 3919.7746, mean_steps: 17.3700, mean_ecr: 0.0457 mean_entropies: 0.4699, took: 81.8167s
2022-10-11 05:01:15,869 [INFO] 	Process 5 - batch 77999: mean_policy_losses: -112.933, mean_net_lifetime: 11305.2303, mean_mc_travel_dist: 3575.4107, mean_rewards: 266.0178, total_rewards: 7768.4715, mean_steps: 42.5900, mean_ecr: 0.0292 mean_entropies: 0.6859, took: 186.8053s
2022-10-11 05:01:23,780 [INFO] 	Process 2 - batch 82199: mean_policy_losses: 11.732, mean_net_lifetime: 7461.7395, mean_mc_travel_dist: 2019.5360, mean_rewards: 284.0190, total_rewards: 5475.2682, mean_steps: 25.4000, mean_ecr: 0.0383 mean_entropies: 0.4299, took: 114.6452s
2022-10-11 05:02:13,671 [INFO] 	Process 7 - batch 83899: mean_policy_losses: -344.543, mean_net_lifetime: 5016.3506, mean_mc_travel_dist: 1528.6534, mean_rewards: 198.1798, total_rewards: 3521.0411, mean_steps: 24.4300, mean_ecr: 0.0408 mean_entropies: 1.2460, took: 105.9107s
2022-10-11 05:02:34,150 [INFO] 	Process 3 - batch 90599: mean_policy_losses: -8.605, mean_net_lifetime: 5290.7529, mean_mc_travel_dist: 1371.1662, mean_rewards: 283.0275, total_rewards: 3951.4862, mean_steps: 17.7500, mean_ecr: 0.0457 mean_entropies: 0.4852, took: 80.9913s
2022-10-11 05:03:17,205 [INFO] 	Process 2 - batch 82299: mean_policy_losses: 5.541, mean_net_lifetime: 7669.8366, mean_mc_travel_dist: 2054.5438, mean_rewards: 279.5407, total_rewards: 5645.5189, mean_steps: 26.4900, mean_ecr: 0.0381 mean_entropies: 0.4118, took: 113.4244s
2022-10-11 05:03:49,845 [INFO] 	Process 7 - batch 83999: mean_policy_losses: -362.160, mean_net_lifetime: 4763.6744, mean_mc_travel_dist: 1387.0378, mean_rewards: 205.7972, total_rewards: 3404.8943, mean_steps: 22.5200, mean_ecr: 0.0411 mean_entropies: 1.2054, took: 96.1744s
2022-10-11 05:03:54,080 [INFO] Process 6 - epoch 80: mean_policy_losses: -190.742, mean_net_lifetime: 3216.9673, mean_mc_travel_dist: 985.5463, mean_entropies: 0.5183, m_net_lifetime_valid: 4528.1364, took: 1478.9076s, (105.2640 / 100 batches)

2022-10-11 05:03:58,341 [INFO] 	Process 3 - batch 90699: mean_policy_losses: -8.940, mean_net_lifetime: 5328.1243, mean_mc_travel_dist: 1385.6056, mean_rewards: 277.9285, total_rewards: 3971.8286, mean_steps: 18.2400, mean_ecr: 0.0456 mean_entropies: 0.4640, took: 84.1917s
2022-10-11 05:04:39,490 [INFO] Process 1 - epoch 50: mean_policy_losses: 20.211, mean_net_lifetime: 5333.5903, mean_mc_travel_dist: 2040.2166, mean_entropies: 1.1548, m_net_lifetime_valid: 4694.0533, took: 2457.7898s, (168.3654 / 100 batches)

2022-10-11 05:04:42,773 [INFO] 	Process 6 - batch 120099: mean_policy_losses: -94.489, mean_net_lifetime: 3734.7126, mean_mc_travel_dist: 1002.3205, mean_rewards: 341.3455, total_rewards: 2776.2204, mean_steps: 9.9200, mean_ecr: 0.0553 mean_entropies: 0.1826, took: 665.4760s
2022-10-11 05:05:09,979 [INFO] 	Process 2 - batch 82399: mean_policy_losses: 18.659, mean_net_lifetime: 7447.6957, mean_mc_travel_dist: 2000.4686, mean_rewards: 278.3424, total_rewards: 5479.0448, mean_steps: 25.8100, mean_ecr: 0.0382 mean_entropies: 0.4003, took: 112.7746s
2022-10-11 05:05:20,781 [INFO] 	Process 3 - batch 90799: mean_policy_losses: 38.832, mean_net_lifetime: 5285.2269, mean_mc_travel_dist: 1362.4663, mean_rewards: 281.5100, total_rewards: 3951.0915, mean_steps: 17.8400, mean_ecr: 0.0456 mean_entropies: 0.4705, took: 82.4404s
2022-10-11 05:05:32,801 [INFO] 	Process 6 - batch 120199: mean_policy_losses: -133.647, mean_net_lifetime: 3585.8771, mean_mc_travel_dist: 987.2864, mean_rewards: 337.2803, total_rewards: 2627.2278, mean_steps: 9.6400, mean_ecr: 0.0558 mean_entropies: 0.1849, took: 50.0296s
2022-10-11 05:06:25,213 [INFO] 	Process 6 - batch 120299: mean_policy_losses: -143.304, mean_net_lifetime: 3729.5585, mean_mc_travel_dist: 1006.7071, mean_rewards: 336.0217, total_rewards: 2765.5667, mean_steps: 10.0500, mean_ecr: 0.0554 mean_entropies: 0.2044, took: 52.4121s
2022-10-11 05:06:27,162 [INFO] 	Process 1 - batch 75099: mean_policy_losses: 1.564, mean_net_lifetime: 6225.6078, mean_mc_travel_dist: 1972.8409, mean_rewards: 251.0632, total_rewards: 4280.7621, mean_steps: 23.9100, mean_ecr: 0.0384 mean_entropies: 0.9107, took: 749.9173s
2022-10-11 05:06:48,112 [INFO] 	Process 3 - batch 90899: mean_policy_losses: 30.853, mean_net_lifetime: 5281.0895, mean_mc_travel_dist: 1360.5774, mean_rewards: 274.5831, total_rewards: 3954.9182, mean_steps: 18.3100, mean_ecr: 0.0457 mean_entropies: 0.4561, took: 87.3301s
2022-10-11 05:07:06,444 [INFO] 	Process 2 - batch 82499: mean_policy_losses: 55.306, mean_net_lifetime: 7493.8678, mean_mc_travel_dist: 2001.6607, mean_rewards: 280.1346, total_rewards: 5526.8948, mean_steps: 25.8400, mean_ecr: 0.0382 mean_entropies: 0.4125, took: 116.4652s
2022-10-11 05:07:16,419 [INFO] 	Process 6 - batch 120399: mean_policy_losses: -166.351, mean_net_lifetime: 3764.4690, mean_mc_travel_dist: 1009.3502, mean_rewards: 336.3293, total_rewards: 2797.9194, mean_steps: 10.1300, mean_ecr: 0.0553 mean_entropies: 0.2134, took: 51.2051s
2022-10-11 05:07:17,981 [INFO] Process 4 - epoch 59: mean_policy_losses: 102.816, mean_net_lifetime: 4781.4598, mean_mc_travel_dist: 1493.5601, mean_entropies: 1.0592, m_net_lifetime_valid: 4473.0950, took: 2624.9519s, (142.9736 / 100 batches)

2022-10-11 05:08:05,685 [INFO] 	Process 6 - batch 120499: mean_policy_losses: -168.053, mean_net_lifetime: 3581.9374, mean_mc_travel_dist: 942.7703, mean_rewards: 339.4768, total_rewards: 2688.9998, mean_steps: 9.5000, mean_ecr: 0.0555 mean_entropies: 0.2150, took: 49.2670s
2022-10-11 05:08:09,773 [INFO] 	Process 3 - batch 90999: mean_policy_losses: 23.674, mean_net_lifetime: 5158.9760, mean_mc_travel_dist: 1326.0720, mean_rewards: 281.4398, total_rewards: 3868.9199, mean_steps: 17.3500, mean_ecr: 0.0461 mean_entropies: 0.4814, took: 81.6616s
2022-10-11 05:08:21,480 [INFO] 	Process 1 - batch 75199: mean_policy_losses: -1.770, mean_net_lifetime: 6546.8056, mean_mc_travel_dist: 2068.8193, mean_rewards: 245.9881, total_rewards: 4514.1008, mean_steps: 25.7500, mean_ecr: 0.0383 mean_entropies: 0.9203, took: 114.3174s
2022-10-11 05:08:44,827 [INFO] 	Process 4 - batch 88599: mean_policy_losses: 183.747, mean_net_lifetime: 5270.6220, mean_mc_travel_dist: 1411.3455, mean_rewards: 276.9505, total_rewards: 3884.9247, mean_steps: 18.3200, mean_ecr: 0.0465 mean_entropies: 0.5222, took: 655.3404s
2022-10-11 05:08:55,681 [INFO] 	Process 6 - batch 120599: mean_policy_losses: -100.190, mean_net_lifetime: 3578.8694, mean_mc_travel_dist: 971.1769, mean_rewards: 333.0485, total_rewards: 2651.1380, mean_steps: 9.7800, mean_ecr: 0.0555 mean_entropies: 0.2261, took: 49.9950s
2022-10-11 05:09:33,803 [INFO] 	Process 3 - batch 91099: mean_policy_losses: 28.301, mean_net_lifetime: 5231.3333, mean_mc_travel_dist: 1318.6058, mean_rewards: 278.1524, total_rewards: 3934.3362, mean_steps: 17.8400, mean_ecr: 0.0459 mean_entropies: 0.4759, took: 84.0303s
2022-10-11 05:09:42,836 [INFO] 	Process 6 - batch 120699: mean_policy_losses: -176.310, mean_net_lifetime: 3463.1448, mean_mc_travel_dist: 930.8849, mean_rewards: 336.7579, total_rewards: 2580.7951, mean_steps: 9.2400, mean_ecr: 0.0555 mean_entropies: 0.2040, took: 47.1545s
2022-10-11 05:10:18,053 [INFO] 	Process 1 - batch 75299: mean_policy_losses: -4.369, mean_net_lifetime: 6618.5488, mean_mc_travel_dist: 2093.0476, mean_rewards: 245.7242, total_rewards: 4554.0990, mean_steps: 26.1400, mean_ecr: 0.0381 mean_entropies: 0.9044, took: 116.5721s
2022-10-11 05:10:21,319 [INFO] 	Process 4 - batch 88699: mean_policy_losses: 133.695, mean_net_lifetime: 6005.9001, mean_mc_travel_dist: 1614.7497, mean_rewards: 285.2732, total_rewards: 4421.8084, mean_steps: 20.5800, mean_ecr: 0.0447 mean_entropies: 0.5078, took: 96.4915s
2022-10-11 05:10:37,052 [INFO] 	Process 6 - batch 120799: mean_policy_losses: -68.108, mean_net_lifetime: 3953.8057, mean_mc_travel_dist: 1054.0111, mean_rewards: 342.5278, total_rewards: 2939.4273, mean_steps: 10.5200, mean_ecr: 0.0553 mean_entropies: 0.1783, took: 54.2165s
2022-10-11 05:11:01,011 [INFO] 	Process 3 - batch 91199: mean_policy_losses: 28.254, mean_net_lifetime: 5341.9835, mean_mc_travel_dist: 1368.2083, mean_rewards: 277.1635, total_rewards: 3997.4997, mean_steps: 18.3800, mean_ecr: 0.0455 mean_entropies: 0.4927, took: 87.2080s
2022-10-11 05:11:07,825 [INFO] Process 5 - epoch 52: mean_policy_losses: -193.055, mean_net_lifetime: 5597.8147, mean_mc_travel_dist: 2111.1348, mean_entropies: 1.1240, m_net_lifetime_valid: 4608.9728, took: 3403.6175s, (162.4597 / 100 batches)

2022-10-11 05:11:30,418 [INFO] 	Process 6 - batch 120899: mean_policy_losses: -125.584, mean_net_lifetime: 3886.8542, mean_mc_travel_dist: 1054.5627, mean_rewards: 341.0997, total_rewards: 2894.8134, mean_steps: 10.3500, mean_ecr: 0.0554 mean_entropies: 0.1736, took: 53.3660s
2022-10-11 05:12:15,197 [INFO] 	Process 1 - batch 75399: mean_policy_losses: -55.299, mean_net_lifetime: 6382.2255, mean_mc_travel_dist: 2013.7261, mean_rewards: 240.8203, total_rewards: 4389.9525, mean_steps: 25.6700, mean_ecr: 0.0384 mean_entropies: 0.9504, took: 117.1451s
2022-10-11 05:12:25,824 [INFO] 	Process 6 - batch 120999: mean_policy_losses: -97.061, mean_net_lifetime: 3959.3684, mean_mc_travel_dist: 1074.6094, mean_rewards: 341.3336, total_rewards: 2938.1879, mean_steps: 10.5600, mean_ecr: 0.0555 mean_entropies: 0.1679, took: 55.4038s
2022-10-11 05:12:28,274 [INFO] 	Process 4 - batch 88799: mean_policy_losses: 108.320, mean_net_lifetime: 7533.2129, mean_mc_travel_dist: 2150.1712, mean_rewards: 282.5558, total_rewards: 5411.9154, mean_steps: 27.5600, mean_ecr: 0.0429 mean_entropies: 0.4703, took: 126.9550s
2022-10-11 05:12:28,426 [INFO] 	Process 3 - batch 91299: mean_policy_losses: 34.059, mean_net_lifetime: 5228.8964, mean_mc_travel_dist: 1326.2638, mean_rewards: 278.9998, total_rewards: 3934.6542, mean_steps: 17.7900, mean_ecr: 0.0459 mean_entropies: 0.4724, took: 87.4147s
2022-10-11 05:13:21,197 [INFO] 	Process 6 - batch 121099: mean_policy_losses: -104.467, mean_net_lifetime: 4005.7654, mean_mc_travel_dist: 1074.9618, mean_rewards: 341.0307, total_rewards: 2983.1286, mean_steps: 10.6800, mean_ecr: 0.0550 mean_entropies: 0.1543, took: 55.3762s
2022-10-11 05:13:40,856 [INFO] 	Process 5 - batch 78099: mean_policy_losses: -237.730, mean_net_lifetime: 8802.2383, mean_mc_travel_dist: 2766.9456, mean_rewards: 267.3572, total_rewards: 6073.6406, mean_steps: 33.1900, mean_ecr: 0.0297 mean_entropies: 0.6206, took: 744.9863s
2022-10-11 05:13:56,249 [INFO] 	Process 3 - batch 91399: mean_policy_losses: 46.856, mean_net_lifetime: 5316.1096, mean_mc_travel_dist: 1344.0281, mean_rewards: 283.8560, total_rewards: 4005.7845, mean_steps: 17.7900, mean_ecr: 0.0458 mean_entropies: 0.4682, took: 87.8233s
2022-10-11 05:14:15,086 [INFO] 	Process 1 - batch 75499: mean_policy_losses: -34.032, mean_net_lifetime: 6598.4855, mean_mc_travel_dist: 2102.8906, mean_rewards: 244.0579, total_rewards: 4520.3514, mean_steps: 26.2100, mean_ecr: 0.0382 mean_entropies: 0.9233, took: 119.8887s
2022-10-11 05:14:17,379 [INFO] 	Process 6 - batch 121199: mean_policy_losses: -110.745, mean_net_lifetime: 4040.0519, mean_mc_travel_dist: 1085.4857, mean_rewards: 340.6395, total_rewards: 2994.2522, mean_steps: 10.8000, mean_ecr: 0.0551 mean_entropies: 0.1477, took: 56.1822s
2022-10-11 05:15:10,851 [INFO] 	Process 6 - batch 121299: mean_policy_losses: -88.127, mean_net_lifetime: 3917.5975, mean_mc_travel_dist: 1055.4837, mean_rewards: 340.4996, total_rewards: 2901.4258, mean_steps: 10.4200, mean_ecr: 0.0553 mean_entropies: 0.1471, took: 53.4710s
2022-10-11 05:15:12,167 [INFO] 	Process 4 - batch 88899: mean_policy_losses: 166.804, mean_net_lifetime: 9260.9073, mean_mc_travel_dist: 2806.0552, mean_rewards: 272.6650, total_rewards: 6492.3386, mean_steps: 36.5600, mean_ecr: 0.0413 mean_entropies: 0.4846, took: 163.8929s
2022-10-11 05:15:19,759 [INFO] Process 7 - epoch 56: mean_policy_losses: -366.194, mean_net_lifetime: 4268.8718, mean_mc_travel_dist: 1553.9139, mean_entropies: 1.5399, m_net_lifetime_valid: 4691.9674, took: 2383.6336s, (151.0523 / 100 batches)

2022-10-11 05:15:28,641 [INFO] 	Process 3 - batch 91499: mean_policy_losses: 25.481, mean_net_lifetime: 5297.4443, mean_mc_travel_dist: 1375.4526, mean_rewards: 276.7216, total_rewards: 3956.1071, mean_steps: 18.2100, mean_ecr: 0.0455 mean_entropies: 0.4731, took: 92.3914s
2022-10-11 05:16:09,933 [INFO] 	Process 6 - batch 121399: mean_policy_losses: -41.755, mean_net_lifetime: 4199.3926, mean_mc_travel_dist: 1125.6877, mean_rewards: 345.4681, total_rewards: 3128.5177, mean_steps: 11.1400, mean_ecr: 0.0548 mean_entropies: 0.1338, took: 59.0829s
2022-10-11 05:16:16,885 [INFO] 	Process 1 - batch 75599: mean_policy_losses: -19.836, mean_net_lifetime: 6534.4268, mean_mc_travel_dist: 2056.6379, mean_rewards: 242.5451, total_rewards: 4506.7055, mean_steps: 26.1900, mean_ecr: 0.0382 mean_entropies: 0.9397, took: 121.7993s
2022-10-11 05:16:50,878 [INFO] 	Process 5 - batch 78199: mean_policy_losses: -165.152, mean_net_lifetime: 10765.2590, mean_mc_travel_dist: 3310.0833, mean_rewards: 263.2761, total_rewards: 7494.6008, mean_steps: 41.1900, mean_ecr: 0.0293 mean_entropies: 0.6672, took: 190.0218s
2022-10-11 05:17:04,864 [INFO] 	Process 6 - batch 121499: mean_policy_losses: -104.114, mean_net_lifetime: 3976.8296, mean_mc_travel_dist: 1067.2156, mean_rewards: 342.9931, total_rewards: 2965.8225, mean_steps: 10.5500, mean_ecr: 0.0549 mean_entropies: 0.1478, took: 54.9297s
2022-10-11 05:17:06,837 [INFO] 	Process 4 - batch 88999: mean_policy_losses: 166.601, mean_net_lifetime: 6852.6426, mean_mc_travel_dist: 1919.2172, mean_rewards: 282.3581, total_rewards: 4970.8747, mean_steps: 24.0300, mean_ecr: 0.0437 mean_entropies: 0.5379, took: 114.6699s
2022-10-11 05:17:13,351 [INFO] 	Process 7 - batch 84099: mean_policy_losses: -433.618, mean_net_lifetime: 5351.0469, mean_mc_travel_dist: 1661.9152, mean_rewards: 207.4948, total_rewards: 3724.8663, mean_steps: 24.9200, mean_ecr: 0.0405 mean_entropies: 1.2893, took: 803.5042s
2022-10-11 05:17:38,012 [INFO] Process 2 - epoch 55: mean_policy_losses: -1.092, mean_net_lifetime: 5180.8914, mean_mc_travel_dist: 1673.4164, mean_entropies: 0.8577, m_net_lifetime_valid: 4521.5883, took: 2449.3267s, (154.0336 / 100 batches)

2022-10-11 05:18:19,796 [INFO] 	Process 1 - batch 75699: mean_policy_losses: -28.860, mean_net_lifetime: 6746.9790, mean_mc_travel_dist: 2123.0049, mean_rewards: 244.4958, total_rewards: 4649.5785, mean_steps: 26.7700, mean_ecr: 0.0381 mean_entropies: 0.9687, took: 122.9097s
2022-10-11 05:19:04,495 [INFO] 	Process 7 - batch 84199: mean_policy_losses: -544.568, mean_net_lifetime: 5147.1640, mean_mc_travel_dist: 1599.1284, mean_rewards: 204.0620, total_rewards: 3571.9685, mean_steps: 24.4200, mean_ecr: 0.0407 mean_entropies: 1.2993, took: 111.1455s
2022-10-11 05:19:24,184 [INFO] 	Process 4 - batch 89099: mean_policy_losses: 218.508, mean_net_lifetime: 8311.2638, mean_mc_travel_dist: 2384.4317, mean_rewards: 281.4823, total_rewards: 5949.8861, mean_steps: 29.8100, mean_ecr: 0.0405 mean_entropies: 0.4856, took: 137.3466s
2022-10-11 05:19:38,620 [INFO] 	Process 2 - batch 82599: mean_policy_losses: -28.807, mean_net_lifetime: 7238.4256, mean_mc_travel_dist: 1935.4410, mean_rewards: 273.0401, total_rewards: 5342.0764, mean_steps: 25.6300, mean_ecr: 0.0386 mean_entropies: 0.4088, took: 752.1762s
2022-10-11 05:20:14,610 [INFO] 	Process 5 - batch 78299: mean_policy_losses: -178.515, mean_net_lifetime: 11254.8635, mean_mc_travel_dist: 3417.2780, mean_rewards: 256.5964, total_rewards: 7872.0828, mean_steps: 44.3200, mean_ecr: 0.0293 mean_entropies: 0.6365, took: 203.7326s
2022-10-11 05:20:19,270 [INFO] 	Process 1 - batch 75799: mean_policy_losses: -49.337, mean_net_lifetime: 6530.5703, mean_mc_travel_dist: 2082.8986, mean_rewards: 251.9066, total_rewards: 4478.8235, mean_steps: 25.1500, mean_ecr: 0.0381 mean_entropies: 0.9270, took: 119.4754s
2022-10-11 05:20:53,806 [INFO] 	Process 7 - batch 84299: mean_policy_losses: -483.952, mean_net_lifetime: 5001.5120, mean_mc_travel_dist: 1531.1151, mean_rewards: 205.3691, total_rewards: 3502.3156, mean_steps: 23.5900, mean_ecr: 0.0407 mean_entropies: 1.1885, took: 109.3101s
2022-10-11 05:21:09,919 [INFO] 	Process 4 - batch 89199: mean_policy_losses: 197.481, mean_net_lifetime: 6339.9767, mean_mc_travel_dist: 1745.6695, mean_rewards: 285.4293, total_rewards: 4625.8264, mean_steps: 21.7600, mean_ecr: 0.0442 mean_entropies: 0.4712, took: 105.7356s
2022-10-11 05:21:45,924 [INFO] 	Process 2 - batch 82699: mean_policy_losses: -13.582, mean_net_lifetime: 7460.2066, mean_mc_travel_dist: 2004.3542, mean_rewards: 265.5269, total_rewards: 5480.2498, mean_steps: 27.1700, mean_ecr: 0.0382 mean_entropies: 0.3827, took: 127.3036s
2022-10-11 05:22:16,459 [INFO] 	Process 1 - batch 75899: mean_policy_losses: -61.222, mean_net_lifetime: 6422.9465, mean_mc_travel_dist: 2055.6728, mean_rewards: 246.7503, total_rewards: 4396.6536, mean_steps: 25.2900, mean_ecr: 0.0382 mean_entropies: 0.8877, took: 117.1891s
2022-10-11 05:22:44,992 [INFO] 	Process 7 - batch 84399: mean_policy_losses: -451.981, mean_net_lifetime: 4968.0207, mean_mc_travel_dist: 1527.8677, mean_rewards: 202.8352, total_rewards: 3466.8131, mean_steps: 23.9500, mean_ecr: 0.0407 mean_entropies: 1.1876, took: 111.1867s
2022-10-11 05:22:46,691 [INFO] 	Process 5 - batch 78399: mean_policy_losses: -288.786, mean_net_lifetime: 8370.5867, mean_mc_travel_dist: 2543.7495, mean_rewards: 258.2708, total_rewards: 5868.8598, mean_steps: 32.2400, mean_ecr: 0.0298 mean_entropies: 0.6090, took: 152.0810s
2022-10-11 05:23:28,063 [INFO] 	Process 4 - batch 89299: mean_policy_losses: 227.610, mean_net_lifetime: 8037.7413, mean_mc_travel_dist: 2286.1290, mean_rewards: 281.8286, total_rewards: 5776.2141, mean_steps: 29.6100, mean_ecr: 0.0414 mean_entropies: 0.4636, took: 138.1441s
2022-10-11 05:23:53,500 [INFO] 	Process 2 - batch 82799: mean_policy_losses: 8.839, mean_net_lifetime: 7612.1093, mean_mc_travel_dist: 2005.3379, mean_rewards: 269.0345, total_rewards: 5626.6809, mean_steps: 27.3400, mean_ecr: 0.0383 mean_entropies: 0.3592, took: 127.5755s
2022-10-11 05:24:18,786 [INFO] 	Process 1 - batch 75999: mean_policy_losses: -11.369, mean_net_lifetime: 6733.3723, mean_mc_travel_dist: 2134.5073, mean_rewards: 250.5809, total_rewards: 4629.6510, mean_steps: 26.0600, mean_ecr: 0.0380 mean_entropies: 0.9508, took: 122.3267s
2022-10-11 05:24:41,274 [INFO] 	Process 7 - batch 84499: mean_policy_losses: -463.556, mean_net_lifetime: 5257.4892, mean_mc_travel_dist: 1619.9302, mean_rewards: 200.5443, total_rewards: 3667.3656, mean_steps: 25.4100, mean_ecr: 0.0404 mean_entropies: 1.2288, took: 116.2821s
2022-10-11 05:25:33,217 [INFO] Process 3 - epoch 61: mean_policy_losses: 49.033, mean_net_lifetime: 4436.1982, mean_mc_travel_dist: 1339.8742, mean_entropies: 0.8171, m_net_lifetime_valid: 4146.0037, took: 1888.7047s, (139.4467 / 100 batches)

2022-10-11 05:25:35,537 [INFO] 	Process 4 - batch 89399: mean_policy_losses: 205.632, mean_net_lifetime: 7471.5482, mean_mc_travel_dist: 2092.3843, mean_rewards: 277.3876, total_rewards: 5405.1500, mean_steps: 27.3200, mean_ecr: 0.0424 mean_entropies: 0.5036, took: 127.4735s
2022-10-11 05:25:41,916 [INFO] 	Process 5 - batch 78499: mean_policy_losses: -175.948, mean_net_lifetime: 10198.9462, mean_mc_travel_dist: 3111.1180, mean_rewards: 263.5196, total_rewards: 7120.6982, mean_steps: 38.3700, mean_ecr: 0.0295 mean_entropies: 0.6481, took: 175.2246s
2022-10-11 05:25:56,773 [INFO] 	Process 2 - batch 82899: mean_policy_losses: -20.102, mean_net_lifetime: 7433.8083, mean_mc_travel_dist: 1976.5882, mean_rewards: 274.5345, total_rewards: 5479.9382, mean_steps: 26.1800, mean_ecr: 0.0383 mean_entropies: 0.4030, took: 123.2729s
2022-10-11 05:26:23,302 [INFO] 	Process 1 - batch 76099: mean_policy_losses: -37.948, mean_net_lifetime: 6621.6250, mean_mc_travel_dist: 2071.4562, mean_rewards: 244.8808, total_rewards: 4579.4541, mean_steps: 26.2200, mean_ecr: 0.0382 mean_entropies: 0.9440, took: 124.5161s
2022-10-11 05:26:36,461 [INFO] 	Process 7 - batch 84599: mean_policy_losses: -446.096, mean_net_lifetime: 4956.3551, mean_mc_travel_dist: 1481.1825, mean_rewards: 200.3876, total_rewards: 3496.5322, mean_steps: 24.3800, mean_ecr: 0.0407 mean_entropies: 1.2347, took: 115.1873s
2022-10-11 05:27:01,378 [INFO] 	Process 3 - batch 91599: mean_policy_losses: -30.180, mean_net_lifetime: 5033.8614, mean_mc_travel_dist: 1304.0437, mean_rewards: 278.7459, total_rewards: 3760.0516, mean_steps: 17.1400, mean_ecr: 0.0461 mean_entropies: 0.5081, took: 692.7376s
2022-10-11 05:27:22,899 [INFO] Process 6 - epoch 81: mean_policy_losses: -189.804, mean_net_lifetime: 3224.4766, mean_mc_travel_dist: 986.0890, mean_entropies: 0.5142, m_net_lifetime_valid: 4350.1705, took: 1408.8163s, (105.1230 / 100 batches)

2022-10-11 05:27:56,169 [INFO] 	Process 4 - batch 89499: mean_policy_losses: 256.527, mean_net_lifetime: 7824.9915, mean_mc_travel_dist: 2223.4781, mean_rewards: 275.1975, total_rewards: 5633.0895, mean_steps: 28.8200, mean_ecr: 0.0416 mean_entropies: 0.5120, took: 140.6325s
2022-10-11 05:27:58,755 [INFO] 	Process 2 - batch 82999: mean_policy_losses: -18.719, mean_net_lifetime: 7087.8902, mean_mc_travel_dist: 1895.0237, mean_rewards: 276.3927, total_rewards: 5220.8214, mean_steps: 24.6900, mean_ecr: 0.0387 mean_entropies: 0.3850, took: 121.9828s
2022-10-11 05:28:20,311 [INFO] 	Process 6 - batch 121599: mean_policy_losses: -112.533, mean_net_lifetime: 3814.7268, mean_mc_travel_dist: 1044.0955, mean_rewards: 342.0332, total_rewards: 2825.6425, mean_steps: 10.1400, mean_ecr: 0.0551 mean_entropies: 0.1892, took: 675.4478s
2022-10-11 05:28:29,992 [INFO] 	Process 7 - batch 84699: mean_policy_losses: -434.207, mean_net_lifetime: 4901.4002, mean_mc_travel_dist: 1481.2725, mean_rewards: 204.4712, total_rewards: 3440.0350, mean_steps: 23.2800, mean_ecr: 0.0408 mean_entropies: 1.2517, took: 113.5309s
2022-10-11 05:28:32,342 [INFO] 	Process 1 - batch 76199: mean_policy_losses: 31.205, mean_net_lifetime: 6749.3385, mean_mc_travel_dist: 2093.0628, mean_rewards: 251.0342, total_rewards: 4682.0787, mean_steps: 26.0100, mean_ecr: 0.0381 mean_entropies: 0.9261, took: 129.0399s
2022-10-11 05:28:33,639 [INFO] 	Process 5 - batch 78599: mean_policy_losses: -202.736, mean_net_lifetime: 9682.4617, mean_mc_travel_dist: 2963.0550, mean_rewards: 270.0490, total_rewards: 6761.1235, mean_steps: 35.4000, mean_ecr: 0.0299 mean_entropies: 0.6502, took: 171.7240s
2022-10-11 05:28:37,462 [INFO] 	Process 3 - batch 91699: mean_policy_losses: 16.546, mean_net_lifetime: 5273.2934, mean_mc_travel_dist: 1348.6608, mean_rewards: 279.1521, total_rewards: 3955.2910, mean_steps: 17.9700, mean_ecr: 0.0460 mean_entropies: 0.4921, took: 96.0827s
2022-10-11 05:29:17,971 [INFO] 	Process 6 - batch 121699: mean_policy_losses: -112.363, mean_net_lifetime: 3758.0453, mean_mc_travel_dist: 1023.0237, mean_rewards: 338.2593, total_rewards: 2774.8187, mean_steps: 10.0400, mean_ecr: 0.0557 mean_entropies: 0.1723, took: 57.6588s
2022-10-11 05:30:09,796 [INFO] 	Process 2 - batch 83099: mean_policy_losses: 18.795, mean_net_lifetime: 7435.4788, mean_mc_travel_dist: 1973.6888, mean_rewards: 273.1707, total_rewards: 5491.2839, mean_steps: 26.2700, mean_ecr: 0.0384 mean_entropies: 0.3939, took: 131.0394s
2022-10-11 05:30:11,439 [INFO] 	Process 3 - batch 91799: mean_policy_losses: 8.967, mean_net_lifetime: 5059.3454, mean_mc_travel_dist: 1271.7128, mean_rewards: 273.3790, total_rewards: 3819.8627, mean_steps: 17.5700, mean_ecr: 0.0465 mean_entropies: 0.4581, took: 93.9767s
2022-10-11 05:30:16,624 [INFO] 	Process 6 - batch 121799: mean_policy_losses: -112.076, mean_net_lifetime: 3813.3393, mean_mc_travel_dist: 1043.0225, mean_rewards: 339.1902, total_rewards: 2815.4708, mean_steps: 10.1900, mean_ecr: 0.0555 mean_entropies: 0.1602, took: 58.6543s
2022-10-11 05:30:19,731 [INFO] 	Process 7 - batch 84799: mean_policy_losses: -447.932, mean_net_lifetime: 4795.2885, mean_mc_travel_dist: 1430.1947, mean_rewards: 211.1051, total_rewards: 3391.0229, mean_steps: 22.2600, mean_ecr: 0.0412 mean_entropies: 1.2419, took: 109.7393s
2022-10-11 05:30:20,777 [INFO] 	Process 4 - batch 89599: mean_policy_losses: 243.595, mean_net_lifetime: 7850.5834, mean_mc_travel_dist: 2269.9932, mean_rewards: 279.8965, total_rewards: 5612.2661, mean_steps: 28.9400, mean_ecr: 0.0415 mean_entropies: 0.4659, took: 144.6071s
2022-10-11 05:30:41,651 [INFO] 	Process 1 - batch 76299: mean_policy_losses: 53.206, mean_net_lifetime: 6677.8052, mean_mc_travel_dist: 2063.3717, mean_rewards: 249.6533, total_rewards: 4642.7503, mean_steps: 25.9200, mean_ecr: 0.0382 mean_entropies: 0.9532, took: 129.3089s
2022-10-11 05:31:15,568 [INFO] 	Process 6 - batch 121899: mean_policy_losses: -91.883, mean_net_lifetime: 3951.3876, mean_mc_travel_dist: 1053.1989, mean_rewards: 340.3721, total_rewards: 2936.4537, mean_steps: 10.5400, mean_ecr: 0.0550 mean_entropies: 0.1775, took: 58.9435s
2022-10-11 05:31:35,730 [INFO] 	Process 5 - batch 78699: mean_policy_losses: -139.574, mean_net_lifetime: 9955.8873, mean_mc_travel_dist: 3024.8204, mean_rewards: 268.5089, total_rewards: 6960.7929, mean_steps: 37.1000, mean_ecr: 0.0296 mean_entropies: 0.6812, took: 182.0911s
2022-10-11 05:31:46,857 [INFO] 	Process 3 - batch 91899: mean_policy_losses: 16.443, mean_net_lifetime: 5215.5378, mean_mc_travel_dist: 1337.7565, mean_rewards: 277.7017, total_rewards: 3911.3927, mean_steps: 17.8500, mean_ecr: 0.0460 mean_entropies: 0.4831, took: 95.4184s
2022-10-11 05:32:11,618 [INFO] 	Process 7 - batch 84899: mean_policy_losses: -430.711, mean_net_lifetime: 4915.2597, mean_mc_travel_dist: 1476.1044, mean_rewards: 211.3837, total_rewards: 3475.5573, mean_steps: 22.5400, mean_ecr: 0.0410 mean_entropies: 1.2639, took: 111.8863s
2022-10-11 05:32:14,516 [INFO] 	Process 6 - batch 121999: mean_policy_losses: -184.335, mean_net_lifetime: 3877.0274, mean_mc_travel_dist: 1036.6291, mean_rewards: 339.8380, total_rewards: 2895.8153, mean_steps: 10.3600, mean_ecr: 0.0550 mean_entropies: 0.1867, took: 58.9485s
2022-10-11 05:32:18,212 [INFO] 	Process 2 - batch 83199: mean_policy_losses: 52.898, mean_net_lifetime: 7492.0136, mean_mc_travel_dist: 1987.6005, mean_rewards: 282.2258, total_rewards: 5526.8663, mean_steps: 25.6200, mean_ecr: 0.0383 mean_entropies: 0.4267, took: 128.4172s
2022-10-11 05:32:55,361 [INFO] 	Process 1 - batch 76399: mean_policy_losses: 22.688, mean_net_lifetime: 6602.6322, mean_mc_travel_dist: 2063.1186, mean_rewards: 242.0358, total_rewards: 4558.5714, mean_steps: 26.5000, mean_ecr: 0.0382 mean_entropies: 0.9159, took: 133.7105s
2022-10-11 05:33:10,226 [INFO] 	Process 4 - batch 89699: mean_policy_losses: 232.889, mean_net_lifetime: 8997.2231, mean_mc_travel_dist: 2644.3286, mean_rewards: 271.2656, total_rewards: 6381.2082, mean_steps: 34.5600, mean_ecr: 0.0409 mean_entropies: 0.5043, took: 169.4489s
2022-10-11 05:33:13,710 [INFO] 	Process 6 - batch 122099: mean_policy_losses: -126.650, mean_net_lifetime: 3881.0181, mean_mc_travel_dist: 1040.1075, mean_rewards: 336.8378, total_rewards: 2884.7043, mean_steps: 10.5200, mean_ecr: 0.0549 mean_entropies: 0.2247, took: 59.1928s
2022-10-11 05:33:24,825 [INFO] 	Process 3 - batch 91999: mean_policy_losses: 29.631, mean_net_lifetime: 5292.8807, mean_mc_travel_dist: 1359.2072, mean_rewards: 278.1919, total_rewards: 3962.4920, mean_steps: 18.1200, mean_ecr: 0.0457 mean_entropies: 0.4637, took: 97.9695s
2022-10-11 05:33:59,391 [INFO] 	Process 7 - batch 84999: mean_policy_losses: -442.321, mean_net_lifetime: 4753.7176, mean_mc_travel_dist: 1453.3664, mean_rewards: 211.8801, total_rewards: 3331.1131, mean_steps: 21.7600, mean_ecr: 0.0411 mean_entropies: 1.2357, took: 107.7729s
2022-10-11 05:34:10,873 [INFO] 	Process 6 - batch 122199: mean_policy_losses: -126.791, mean_net_lifetime: 3762.4968, mean_mc_travel_dist: 1015.3294, mean_rewards: 339.7064, total_rewards: 2802.9016, mean_steps: 10.0500, mean_ecr: 0.0555 mean_entropies: 0.1996, took: 57.1641s
2022-10-11 05:34:25,854 [INFO] 	Process 5 - batch 78799: mean_policy_losses: -185.573, mean_net_lifetime: 9098.2563, mean_mc_travel_dist: 2782.1657, mean_rewards: 266.6713, total_rewards: 6365.2130, mean_steps: 33.9500, mean_ecr: 0.0298 mean_entropies: 0.6644, took: 170.1231s
2022-10-11 05:34:26,937 [INFO] 	Process 2 - batch 83299: mean_policy_losses: 47.226, mean_net_lifetime: 7495.6377, mean_mc_travel_dist: 1998.2892, mean_rewards: 281.6066, total_rewards: 5518.2736, mean_steps: 25.7100, mean_ecr: 0.0383 mean_entropies: 0.4234, took: 128.7253s
2022-10-11 05:35:04,006 [INFO] 	Process 3 - batch 92099: mean_policy_losses: 26.801, mean_net_lifetime: 5349.8186, mean_mc_travel_dist: 1368.6309, mean_rewards: 272.2984, total_rewards: 4006.3771, mean_steps: 18.7500, mean_ecr: 0.0458 mean_entropies: 0.4823, took: 99.1807s
2022-10-11 05:35:06,866 [INFO] 	Process 1 - batch 76499: mean_policy_losses: 7.324, mean_net_lifetime: 6645.3667, mean_mc_travel_dist: 2062.7401, mean_rewards: 243.5412, total_rewards: 4601.5506, mean_steps: 26.4900, mean_ecr: 0.0382 mean_entropies: 0.9355, took: 131.5046s
2022-10-11 05:35:07,900 [INFO] 	Process 6 - batch 122299: mean_policy_losses: -222.613, mean_net_lifetime: 3806.4630, mean_mc_travel_dist: 1026.0890, mean_rewards: 340.0269, total_rewards: 2822.4649, mean_steps: 10.1200, mean_ecr: 0.0552 mean_entropies: 0.1754, took: 57.0273s
2022-10-11 05:35:42,063 [INFO] 	Process 4 - batch 89799: mean_policy_losses: 242.925, mean_net_lifetime: 8147.1297, mean_mc_travel_dist: 2389.3106, mean_rewards: 278.1832, total_rewards: 5792.2171, mean_steps: 30.7900, mean_ecr: 0.0420 mean_entropies: 0.5068, took: 151.8383s
2022-10-11 05:35:47,930 [INFO] 	Process 7 - batch 85099: mean_policy_losses: -510.306, mean_net_lifetime: 4759.0273, mean_mc_travel_dist: 1452.8750, mean_rewards: 209.1189, total_rewards: 3338.9282, mean_steps: 22.0800, mean_ecr: 0.0411 mean_entropies: 1.2802, took: 108.5390s
2022-10-11 05:36:02,892 [INFO] 	Process 6 - batch 122399: mean_policy_losses: -139.353, mean_net_lifetime: 3764.9138, mean_mc_travel_dist: 1034.4832, mean_rewards: 336.7148, total_rewards: 2761.7181, mean_steps: 10.1200, mean_ecr: 0.0557 mean_entropies: 0.1646, took: 54.9914s
2022-10-11 05:36:35,252 [INFO] 	Process 2 - batch 83399: mean_policy_losses: 45.153, mean_net_lifetime: 7568.0138, mean_mc_travel_dist: 2042.9586, mean_rewards: 274.8431, total_rewards: 5552.9683, mean_steps: 26.6100, mean_ecr: 0.0380 mean_entropies: 0.4287, took: 128.3144s
2022-10-11 05:36:35,458 [INFO] 	Process 3 - batch 92199: mean_policy_losses: 38.649, mean_net_lifetime: 5291.9260, mean_mc_travel_dist: 1342.0785, mean_rewards: 282.0532, total_rewards: 3977.5511, mean_steps: 17.8000, mean_ecr: 0.0458 mean_entropies: 0.4679, took: 91.4516s
2022-10-11 05:37:00,326 [INFO] 	Process 6 - batch 122499: mean_policy_losses: -130.110, mean_net_lifetime: 3882.4551, mean_mc_travel_dist: 1058.5867, mean_rewards: 335.6392, total_rewards: 2864.9190, mean_steps: 10.4300, mean_ecr: 0.0554 mean_entropies: 0.1655, took: 57.4335s
2022-10-11 05:37:15,693 [INFO] 	Process 5 - batch 78899: mean_policy_losses: -199.312, mean_net_lifetime: 9095.0336, mean_mc_travel_dist: 2749.8127, mean_rewards: 263.0808, total_rewards: 6388.8924, mean_steps: 34.7700, mean_ecr: 0.0301 mean_entropies: 0.6499, took: 169.8387s
2022-10-11 05:37:36,904 [INFO] 	Process 7 - batch 85199: mean_policy_losses: -477.267, mean_net_lifetime: 4873.5529, mean_mc_travel_dist: 1480.0612, mean_rewards: 205.9449, total_rewards: 3427.9338, mean_steps: 22.8400, mean_ecr: 0.0410 mean_entropies: 1.3096, took: 108.9737s
2022-10-11 05:37:58,129 [INFO] 	Process 6 - batch 122599: mean_policy_losses: -42.362, mean_net_lifetime: 3969.0652, mean_mc_travel_dist: 1095.4947, mean_rewards: 340.4735, total_rewards: 2915.2203, mean_steps: 10.6500, mean_ecr: 0.0553 mean_entropies: 0.1677, took: 57.8043s
2022-10-11 05:38:03,283 [INFO] 	Process 4 - batch 89899: mean_policy_losses: 258.392, mean_net_lifetime: 7980.9641, mean_mc_travel_dist: 2300.4939, mean_rewards: 275.2783, total_rewards: 5704.6287, mean_steps: 29.3400, mean_ecr: 0.0409 mean_entropies: 0.5061, took: 141.2195s
2022-10-11 05:38:06,825 [INFO] 	Process 3 - batch 92299: mean_policy_losses: 21.907, mean_net_lifetime: 5140.5017, mean_mc_travel_dist: 1307.0377, mean_rewards: 275.8153, total_rewards: 3856.3672, mean_steps: 17.7000, mean_ecr: 0.0459 mean_entropies: 0.4620, took: 91.3673s
2022-10-11 05:38:34,182 [INFO] 	Process 2 - batch 83499: mean_policy_losses: 6.665, mean_net_lifetime: 6954.4694, mean_mc_travel_dist: 1839.5309, mean_rewards: 274.8400, total_rewards: 5141.7442, mean_steps: 24.3800, mean_ecr: 0.0389 mean_entropies: 0.3840, took: 118.9310s
2022-10-11 05:38:53,925 [INFO] 	Process 6 - batch 122699: mean_policy_losses: -135.897, mean_net_lifetime: 3829.8700, mean_mc_travel_dist: 1031.0074, mean_rewards: 341.6616, total_rewards: 2841.4094, mean_steps: 10.1600, mean_ecr: 0.0555 mean_entropies: 0.1651, took: 55.7956s
2022-10-11 05:39:38,001 [INFO] 	Process 7 - batch 85299: mean_policy_losses: -306.789, mean_net_lifetime: 5369.2677, mean_mc_travel_dist: 1654.4926, mean_rewards: 203.7000, total_rewards: 3751.7844, mean_steps: 25.6800, mean_ecr: 0.0404 mean_entropies: 1.2007, took: 121.0959s
2022-10-11 05:39:38,361 [INFO] 	Process 3 - batch 92399: mean_policy_losses: 18.000, mean_net_lifetime: 5301.1474, mean_mc_travel_dist: 1354.6899, mean_rewards: 280.6633, total_rewards: 3973.8101, mean_steps: 17.9300, mean_ecr: 0.0456 mean_entropies: 0.4609, took: 91.5362s
2022-10-11 05:39:51,025 [INFO] 	Process 6 - batch 122799: mean_policy_losses: -88.877, mean_net_lifetime: 3955.8382, mean_mc_travel_dist: 1058.0875, mean_rewards: 342.9936, total_rewards: 2934.1394, mean_steps: 10.5100, mean_ecr: 0.0550 mean_entropies: 0.1576, took: 57.0997s
2022-10-11 05:39:58,761 [INFO] 	Process 5 - batch 78999: mean_policy_losses: -204.370, mean_net_lifetime: 8972.4472, mean_mc_travel_dist: 2737.8863, mean_rewards: 263.8898, total_rewards: 6272.8370, mean_steps: 33.9200, mean_ecr: 0.0298 mean_entropies: 0.6530, took: 163.0671s
2022-10-11 05:40:40,159 [INFO] 	Process 2 - batch 83599: mean_policy_losses: 50.458, mean_net_lifetime: 7568.2873, mean_mc_travel_dist: 2028.9507, mean_rewards: 279.0373, total_rewards: 5569.2024, mean_steps: 26.2400, mean_ecr: 0.0381 mean_entropies: 0.4043, took: 125.9769s
2022-10-11 05:40:47,326 [INFO] 	Process 6 - batch 122899: mean_policy_losses: -121.252, mean_net_lifetime: 3830.3528, mean_mc_travel_dist: 1021.1575, mean_rewards: 340.6205, total_rewards: 2848.8272, mean_steps: 10.1800, mean_ecr: 0.0554 mean_entropies: 0.1659, took: 56.3017s
2022-10-11 05:41:01,614 [INFO] 	Process 4 - batch 89999: mean_policy_losses: 213.644, mean_net_lifetime: 9724.2488, mean_mc_travel_dist: 2942.9564, mean_rewards: 276.0965, total_rewards: 6810.1590, mean_steps: 38.1200, mean_ecr: 0.0405 mean_entropies: 0.4806, took: 178.3313s
2022-10-11 05:41:12,066 [INFO] 	Process 3 - batch 92499: mean_policy_losses: 36.906, mean_net_lifetime: 5394.1723, mean_mc_travel_dist: 1380.6111, mean_rewards: 280.8034, total_rewards: 4035.1276, mean_steps: 18.2500, mean_ecr: 0.0453 mean_entropies: 0.4808, took: 93.7046s
2022-10-11 05:41:36,525 [INFO] 	Process 7 - batch 85399: mean_policy_losses: -345.958, mean_net_lifetime: 5213.0216, mean_mc_travel_dist: 1594.5285, mean_rewards: 203.3839, total_rewards: 3649.1326, mean_steps: 25.2400, mean_ecr: 0.0406 mean_entropies: 1.1743, took: 118.5259s
2022-10-11 05:41:42,598 [INFO] 	Process 6 - batch 122999: mean_policy_losses: -116.256, mean_net_lifetime: 3923.1376, mean_mc_travel_dist: 1050.5994, mean_rewards: 340.5396, total_rewards: 2906.7999, mean_steps: 10.4800, mean_ecr: 0.0552 mean_entropies: 0.1777, took: 55.2718s
2022-10-11 05:42:37,608 [INFO] 	Process 3 - batch 92599: mean_policy_losses: 11.157, mean_net_lifetime: 5294.5491, mean_mc_travel_dist: 1352.2185, mean_rewards: 281.5345, total_rewards: 3973.2581, mean_steps: 17.8600, mean_ecr: 0.0457 mean_entropies: 0.4386, took: 85.5422s
2022-10-11 05:42:38,186 [INFO] 	Process 2 - batch 83699: mean_policy_losses: 46.899, mean_net_lifetime: 7478.5384, mean_mc_travel_dist: 1972.2782, mean_rewards: 282.4385, total_rewards: 5534.2108, mean_steps: 25.5500, mean_ecr: 0.0384 mean_entropies: 0.3869, took: 118.0269s
2022-10-11 05:42:45,527 [INFO] 	Process 5 - batch 79099: mean_policy_losses: -118.852, mean_net_lifetime: 9722.0262, mean_mc_travel_dist: 3017.9968, mean_rewards: 267.8009, total_rewards: 6743.4471, mean_steps: 36.2400, mean_ecr: 0.0295 mean_entropies: 0.6307, took: 166.7669s
2022-10-11 05:43:16,239 [INFO] 	Process 7 - batch 85499: mean_policy_losses: -490.905, mean_net_lifetime: 4790.4273, mean_mc_travel_dist: 1459.8360, mean_rewards: 208.6376, total_rewards: 3353.8893, mean_steps: 22.5500, mean_ecr: 0.0408 mean_entropies: 1.2295, took: 99.7138s
2022-10-11 05:44:00,666 [INFO] 	Process 3 - batch 92699: mean_policy_losses: -13.766, mean_net_lifetime: 5248.3919, mean_mc_travel_dist: 1333.6549, mean_rewards: 278.8264, total_rewards: 3952.8048, mean_steps: 17.8700, mean_ecr: 0.0458 mean_entropies: 0.4726, took: 83.0584s
2022-10-11 05:44:29,801 [INFO] 	Process 2 - batch 83799: mean_policy_losses: 6.339, mean_net_lifetime: 7447.4102, mean_mc_travel_dist: 1963.8537, mean_rewards: 280.9999, total_rewards: 5507.9483, mean_steps: 25.5300, mean_ecr: 0.0383 mean_entropies: 0.3905, took: 111.6145s
2022-10-11 05:45:29,488 [INFO] 	Process 3 - batch 92799: mean_policy_losses: -46.337, mean_net_lifetime: 5438.1786, mean_mc_travel_dist: 1402.7242, mean_rewards: 273.1696, total_rewards: 4062.5532, mean_steps: 19.0200, mean_ecr: 0.0452 mean_entropies: 0.4624, took: 88.8211s
2022-10-11 05:45:31,909 [INFO] 	Process 5 - batch 79199: mean_policy_losses: -185.421, mean_net_lifetime: 10461.9124, mean_mc_travel_dist: 3252.6523, mean_rewards: 264.0135, total_rewards: 7251.3668, mean_steps: 40.1000, mean_ecr: 0.0296 mean_entropies: 0.6495, took: 166.3828s
2022-10-11 05:45:53,497 [INFO] Process 1 - epoch 51: mean_policy_losses: 19.569, mean_net_lifetime: 5357.9470, mean_mc_travel_dist: 2040.8107, mean_entropies: 1.1504, m_net_lifetime_valid: 4809.6657, took: 2474.0046s, (168.2925 / 100 batches)

2022-10-11 05:46:23,522 [INFO] 	Process 2 - batch 83899: mean_policy_losses: 4.464, mean_net_lifetime: 7557.7807, mean_mc_travel_dist: 2007.5204, mean_rewards: 279.1250, total_rewards: 5571.0942, mean_steps: 26.1400, mean_ecr: 0.0382 mean_entropies: 0.3874, took: 113.7211s
2022-10-11 05:46:56,692 [INFO] 	Process 3 - batch 92899: mean_policy_losses: -21.231, mean_net_lifetime: 5398.7149, mean_mc_travel_dist: 1396.7379, mean_rewards: 279.1469, total_rewards: 4039.0381, mean_steps: 18.3900, mean_ecr: 0.0452 mean_entropies: 0.4687, took: 87.2034s
2022-10-11 05:47:46,816 [INFO] 	Process 1 - batch 76599: mean_policy_losses: -52.301, mean_net_lifetime: 6632.0067, mean_mc_travel_dist: 2074.2283, mean_rewards: 251.1694, total_rewards: 4582.8735, mean_steps: 25.4700, mean_ecr: 0.0382 mean_entropies: 0.9018, took: 759.9501s
2022-10-11 05:47:58,900 [INFO] 	Process 5 - batch 79299: mean_policy_losses: -185.644, mean_net_lifetime: 8806.0168, mean_mc_travel_dist: 2767.7653, mean_rewards: 263.7256, total_rewards: 6078.9999, mean_steps: 33.0700, mean_ecr: 0.0297 mean_entropies: 0.6516, took: 146.9898s
2022-10-11 05:48:19,510 [INFO] 	Process 2 - batch 83999: mean_policy_losses: 21.682, mean_net_lifetime: 7589.7973, mean_mc_travel_dist: 2018.9237, mean_rewards: 283.3926, total_rewards: 5597.7050, mean_steps: 25.8700, mean_ecr: 0.0383 mean_entropies: 0.4224, took: 115.9881s
2022-10-11 05:48:22,992 [INFO] 	Process 3 - batch 92999: mean_policy_losses: -43.628, mean_net_lifetime: 5275.4394, mean_mc_travel_dist: 1355.0355, mean_rewards: 284.8539, total_rewards: 3948.6079, mean_steps: 17.5300, mean_ecr: 0.0456 mean_entropies: 0.4870, took: 86.3010s
2022-10-11 05:49:37,460 [INFO] 	Process 1 - batch 76699: mean_policy_losses: -38.037, mean_net_lifetime: 6715.8285, mean_mc_travel_dist: 2126.8733, mean_rewards: 250.3505, total_rewards: 4616.9055, mean_steps: 25.9100, mean_ecr: 0.0380 mean_entropies: 0.9571, took: 110.6438s
2022-10-11 05:50:57,702 [INFO] Process 4 - epoch 60: mean_policy_losses: 104.499, mean_net_lifetime: 4830.2232, mean_mc_travel_dist: 1505.5349, mean_entropies: 1.0498, m_net_lifetime_valid: 4633.4814, took: 2619.7194s, (143.4702 / 100 batches)

2022-10-11 05:51:07,261 [INFO] 	Process 5 - batch 79399: mean_policy_losses: -19.277, mean_net_lifetime: 12121.4987, mean_mc_travel_dist: 3783.3047, mean_rewards: 271.2593, total_rewards: 8386.1735, mean_steps: 45.1000, mean_ecr: 0.0293 mean_entropies: 0.6806, took: 188.3627s
2022-10-11 05:51:36,604 [INFO] 	Process 1 - batch 76799: mean_policy_losses: -76.874, mean_net_lifetime: 6897.4495, mean_mc_travel_dist: 2149.2752, mean_rewards: 241.8452, total_rewards: 4778.7084, mean_steps: 27.7000, mean_ecr: 0.0380 mean_entropies: 0.9803, took: 119.1443s
2022-10-11 05:51:52,497 [INFO] Process 6 - epoch 82: mean_policy_losses: -189.005, mean_net_lifetime: 3232.1619, mean_mc_travel_dist: 986.7715, mean_entropies: 0.5100, m_net_lifetime_valid: 4489.8240, took: 1469.5957s, (105.0425 / 100 batches)

2022-10-11 05:52:45,101 [INFO] 	Process 6 - batch 123099: mean_policy_losses: -133.642, mean_net_lifetime: 3734.5576, mean_mc_travel_dist: 980.9338, mean_rewards: 338.3826, total_rewards: 2783.2022, mean_steps: 9.9500, mean_ecr: 0.0554 mean_entropies: 0.1882, took: 662.5033s
2022-10-11 05:53:35,306 [INFO] 	Process 1 - batch 76899: mean_policy_losses: -3.106, mean_net_lifetime: 6583.9929, mean_mc_travel_dist: 2042.9991, mean_rewards: 239.1089, total_rewards: 4559.7863, mean_steps: 26.6700, mean_ecr: 0.0383 mean_entropies: 0.9488, took: 118.7026s
2022-10-11 05:53:38,299 [INFO] 	Process 6 - batch 123199: mean_policy_losses: -117.482, mean_net_lifetime: 3836.8082, mean_mc_travel_dist: 1029.8769, mean_rewards: 336.6902, total_rewards: 2861.1337, mean_steps: 10.3000, mean_ecr: 0.0551 mean_entropies: 0.1783, took: 53.1975s
2022-10-11 05:53:55,312 [INFO] 	Process 4 - batch 90099: mean_policy_losses: 345.816, mean_net_lifetime: 10111.1515, mean_mc_travel_dist: 3092.6998, mean_rewards: 271.9952, total_rewards: 7044.4508, mean_steps: 40.7900, mean_ecr: 0.0411 mean_entropies: 0.5028, took: 773.6982s
2022-10-11 05:54:11,328 [INFO] 	Process 5 - batch 79499: mean_policy_losses: -91.349, mean_net_lifetime: 11000.1423, mean_mc_travel_dist: 3402.8930, mean_rewards: 268.4164, total_rewards: 7637.4596, mean_steps: 41.2100, mean_ecr: 0.0294 mean_entropies: 0.6878, took: 184.0656s
2022-10-11 05:54:21,187 [INFO] Process 7 - epoch 57: mean_policy_losses: -367.617, mean_net_lifetime: 4281.7600, mean_mc_travel_dist: 1553.4404, mean_entropies: 1.5347, m_net_lifetime_valid: 4550.5195, took: 2341.4254s, (151.1698 / 100 batches)

2022-10-11 05:54:29,052 [INFO] 	Process 6 - batch 123299: mean_policy_losses: -136.969, mean_net_lifetime: 3719.4484, mean_mc_travel_dist: 1001.4041, mean_rewards: 342.2353, total_rewards: 2779.9668, mean_steps: 9.8400, mean_ecr: 0.0551 mean_entropies: 0.1760, took: 50.7531s
2022-10-11 05:55:20,786 [INFO] 	Process 6 - batch 123399: mean_policy_losses: -152.817, mean_net_lifetime: 3706.5542, mean_mc_travel_dist: 989.4411, mean_rewards: 337.1566, total_rewards: 2755.4702, mean_steps: 9.8300, mean_ecr: 0.0553 mean_entropies: 0.1928, took: 51.7341s
2022-10-11 05:55:34,772 [INFO] 	Process 1 - batch 76999: mean_policy_losses: -18.553, mean_net_lifetime: 6548.4765, mean_mc_travel_dist: 2045.9701, mean_rewards: 240.1716, total_rewards: 4526.6937, mean_steps: 26.4600, mean_ecr: 0.0383 mean_entropies: 0.9187, took: 119.4653s
2022-10-11 05:55:55,039 [INFO] 	Process 4 - batch 90199: mean_policy_losses: 309.006, mean_net_lifetime: 7415.8410, mean_mc_travel_dist: 2091.8500, mean_rewards: 281.2436, total_rewards: 5358.4347, mean_steps: 26.5400, mean_ecr: 0.0428 mean_entropies: 0.5186, took: 119.7265s
2022-10-11 05:56:02,348 [INFO] 	Process 7 - batch 85599: mean_policy_losses: -433.614, mean_net_lifetime: 4847.9124, mean_mc_travel_dist: 1470.4817, mean_rewards: 209.6574, total_rewards: 3401.2680, mean_steps: 22.7400, mean_ecr: 0.0410 mean_entropies: 1.2499, took: 766.1089s
2022-10-11 05:56:15,124 [INFO] 	Process 6 - batch 123499: mean_policy_losses: -108.904, mean_net_lifetime: 3999.9263, mean_mc_travel_dist: 1066.9421, mean_rewards: 342.6336, total_rewards: 2979.5218, mean_steps: 10.6100, mean_ecr: 0.0552 mean_entropies: 0.1510, took: 54.3378s
2022-10-11 05:57:07,613 [INFO] 	Process 6 - batch 123599: mean_policy_losses: -126.373, mean_net_lifetime: 3844.0717, mean_mc_travel_dist: 1036.4739, mean_rewards: 340.4378, total_rewards: 2855.8618, mean_steps: 10.2500, mean_ecr: 0.0553 mean_entropies: 0.1753, took: 52.4886s
2022-10-11 05:57:33,805 [INFO] 	Process 1 - batch 77099: mean_policy_losses: -12.760, mean_net_lifetime: 6473.8997, mean_mc_travel_dist: 2017.1880, mean_rewards: 242.4284, total_rewards: 4478.2945, mean_steps: 25.9700, mean_ecr: 0.0383 mean_entropies: 0.8945, took: 119.0334s
2022-10-11 05:57:56,950 [INFO] 	Process 7 - batch 85699: mean_policy_losses: -361.676, mean_net_lifetime: 5282.9614, mean_mc_travel_dist: 1604.8981, mean_rewards: 201.7637, total_rewards: 3701.2510, mean_steps: 25.6300, mean_ecr: 0.0405 mean_entropies: 1.2541, took: 114.6016s
2022-10-11 05:58:03,806 [INFO] 	Process 6 - batch 123699: mean_policy_losses: -84.943, mean_net_lifetime: 4099.2441, mean_mc_travel_dist: 1090.4300, mean_rewards: 344.1260, total_rewards: 3045.9526, mean_steps: 10.8800, mean_ecr: 0.0551 mean_entropies: 0.1669, took: 56.1937s
2022-10-11 05:58:08,785 [INFO] Process 3 - epoch 62: mean_policy_losses: 48.318, mean_net_lifetime: 4449.6012, mean_mc_travel_dist: 1339.9997, mean_entropies: 0.8115, m_net_lifetime_valid: 4408.2137, took: 1955.5653s, (139.3206 / 100 batches)

2022-10-11 05:58:39,525 [INFO] Process 2 - epoch 56: mean_policy_losses: -0.801, mean_net_lifetime: 5221.0182, mean_mc_travel_dist: 1678.8319, mean_entropies: 0.8495, m_net_lifetime_valid: 4428.4567, took: 2461.5105s, (154.2269 / 100 batches)

2022-10-11 05:58:50,992 [INFO] 	Process 4 - batch 90299: mean_policy_losses: 263.137, mean_net_lifetime: 10075.9692, mean_mc_travel_dist: 3036.1940, mean_rewards: 264.7523, total_rewards: 7059.6506, mean_steps: 39.8500, mean_ecr: 0.0381 mean_entropies: 0.5057, took: 175.9527s
2022-10-11 05:58:57,844 [INFO] 	Process 6 - batch 123799: mean_policy_losses: -108.740, mean_net_lifetime: 3781.8059, mean_mc_travel_dist: 1018.5985, mean_rewards: 341.2545, total_rewards: 2808.8218, mean_steps: 10.0500, mean_ecr: 0.0554 mean_entropies: 0.1834, took: 54.0382s
2022-10-11 05:59:35,186 [INFO] 	Process 1 - batch 77199: mean_policy_losses: 3.272, mean_net_lifetime: 6566.7645, mean_mc_travel_dist: 2058.8083, mean_rewards: 248.9600, total_rewards: 4538.4839, mean_steps: 25.5400, mean_ecr: 0.0383 mean_entropies: 0.9592, took: 121.3799s
2022-10-11 05:59:39,631 [INFO] 	Process 3 - batch 93099: mean_policy_losses: 11.315, mean_net_lifetime: 5230.5574, mean_mc_travel_dist: 1333.3432, mean_rewards: 279.3598, total_rewards: 3924.5908, mean_steps: 17.7700, mean_ecr: 0.0459 mean_entropies: 0.4879, took: 676.6386s
2022-10-11 05:59:48,729 [INFO] 	Process 7 - batch 85799: mean_policy_losses: -455.392, mean_net_lifetime: 5010.0010, mean_mc_travel_dist: 1541.2808, mean_rewards: 205.1795, total_rewards: 3499.5196, mean_steps: 23.8300, mean_ecr: 0.0407 mean_entropies: 1.2596, took: 111.7793s
2022-10-11 05:59:54,579 [INFO] 	Process 6 - batch 123899: mean_policy_losses: -134.730, mean_net_lifetime: 3799.9758, mean_mc_travel_dist: 1023.5989, mean_rewards: 340.4502, total_rewards: 2814.4215, mean_steps: 10.1200, mean_ecr: 0.0552 mean_entropies: 0.1851, took: 56.7349s
2022-10-11 06:00:40,439 [INFO] 	Process 2 - batch 84099: mean_policy_losses: 26.336, mean_net_lifetime: 7242.8626, mean_mc_travel_dist: 1907.9859, mean_rewards: 281.6106, total_rewards: 5356.2516, mean_steps: 24.8000, mean_ecr: 0.0386 mean_entropies: 0.3847, took: 740.9275s
2022-10-11 06:00:48,331 [INFO] 	Process 6 - batch 123999: mean_policy_losses: -120.461, mean_net_lifetime: 3669.6773, mean_mc_travel_dist: 984.3884, mean_rewards: 339.4337, total_rewards: 2718.1453, mean_steps: 9.7900, mean_ecr: 0.0557 mean_entropies: 0.1826, took: 53.7515s
2022-10-11 06:00:56,475 [INFO] 	Process 4 - batch 90399: mean_policy_losses: 198.327, mean_net_lifetime: 7307.0117, mean_mc_travel_dist: 2020.8222, mean_rewards: 280.6523, total_rewards: 5314.6459, mean_steps: 26.1400, mean_ecr: 0.0423 mean_entropies: 0.5035, took: 125.4827s
2022-10-11 06:01:12,034 [INFO] 	Process 3 - batch 93199: mean_policy_losses: 31.090, mean_net_lifetime: 5204.0580, mean_mc_travel_dist: 1314.3483, mean_rewards: 276.2903, total_rewards: 3914.7024, mean_steps: 17.9300, mean_ecr: 0.0459 mean_entropies: 0.4743, took: 92.4024s
2022-10-11 06:01:28,769 [INFO] 	Process 7 - batch 85899: mean_policy_losses: -595.750, mean_net_lifetime: 4365.4376, mean_mc_travel_dist: 1342.0291, mean_rewards: 205.8812, total_rewards: 3059.6956, mean_steps: 20.9100, mean_ecr: 0.0413 mean_entropies: 1.1868, took: 100.0405s
2022-10-11 06:01:39,862 [INFO] 	Process 1 - batch 77299: mean_policy_losses: 51.661, mean_net_lifetime: 6751.6551, mean_mc_travel_dist: 2146.9905, mean_rewards: 254.3706, total_rewards: 4639.5397, mean_steps: 25.7000, mean_ecr: 0.0379 mean_entropies: 0.9341, took: 124.6767s
2022-10-11 06:01:41,378 [INFO] 	Process 6 - batch 124099: mean_policy_losses: -134.011, mean_net_lifetime: 3471.5150, mean_mc_travel_dist: 973.4367, mean_rewards: 328.2943, total_rewards: 2522.4580, mean_steps: 9.5800, mean_ecr: 0.0561 mean_entropies: 0.2119, took: 53.0470s
2022-10-11 06:02:38,060 [INFO] 	Process 6 - batch 124199: mean_policy_losses: -76.386, mean_net_lifetime: 3706.3836, mean_mc_travel_dist: 1016.6511, mean_rewards: 335.3888, total_rewards: 2720.7814, mean_steps: 10.0400, mean_ecr: 0.0558 mean_entropies: 0.1971, took: 56.6819s
2022-10-11 06:02:42,142 [INFO] 	Process 3 - batch 93299: mean_policy_losses: 16.376, mean_net_lifetime: 5167.0358, mean_mc_travel_dist: 1298.6486, mean_rewards: 277.2369, total_rewards: 3886.9322, mean_steps: 17.6800, mean_ecr: 0.0460 mean_entropies: 0.4864, took: 90.1078s
2022-10-11 06:02:46,803 [INFO] 	Process 2 - batch 84199: mean_policy_losses: 43.928, mean_net_lifetime: 7481.4467, mean_mc_travel_dist: 1981.9554, mean_rewards: 276.3138, total_rewards: 5529.3987, mean_steps: 26.1700, mean_ecr: 0.0383 mean_entropies: 0.3593, took: 126.3658s
2022-10-11 06:03:00,413 [INFO] 	Process 4 - batch 90499: mean_policy_losses: 182.543, mean_net_lifetime: 7004.8634, mean_mc_travel_dist: 1994.6755, mean_rewards: 284.8144, total_rewards: 5050.3829, mean_steps: 25.2600, mean_ecr: 0.0437 mean_entropies: 0.5113, took: 123.9391s
2022-10-11 06:03:19,544 [INFO] 	Process 7 - batch 85999: mean_policy_losses: -513.844, mean_net_lifetime: 4787.3306, mean_mc_travel_dist: 1465.3152, mean_rewards: 200.1528, total_rewards: 3362.8196, mean_steps: 23.2500, mean_ecr: 0.0408 mean_entropies: 1.1823, took: 110.7748s
2022-10-11 06:03:35,726 [INFO] 	Process 6 - batch 124299: mean_policy_losses: -79.972, mean_net_lifetime: 3860.6686, mean_mc_travel_dist: 1051.1966, mean_rewards: 339.6594, total_rewards: 2854.5462, mean_steps: 10.3600, mean_ecr: 0.0555 mean_entropies: 0.1942, took: 57.6656s
2022-10-11 06:03:44,156 [INFO] 	Process 1 - batch 77399: mean_policy_losses: -12.120, mean_net_lifetime: 6525.2286, mean_mc_travel_dist: 2106.2508, mean_rewards: 246.6367, total_rewards: 4443.1177, mean_steps: 25.5900, mean_ecr: 0.0379 mean_entropies: 0.8540, took: 124.2945s
2022-10-11 06:04:16,415 [INFO] 	Process 3 - batch 93399: mean_policy_losses: 7.671, mean_net_lifetime: 5236.2685, mean_mc_travel_dist: 1318.1719, mean_rewards: 275.3569, total_rewards: 3949.2880, mean_steps: 18.1300, mean_ecr: 0.0459 mean_entropies: 0.4602, took: 94.2742s
2022-10-11 06:04:30,198 [INFO] 	Process 6 - batch 124399: mean_policy_losses: -135.887, mean_net_lifetime: 3727.5578, mean_mc_travel_dist: 1007.9194, mean_rewards: 339.5447, total_rewards: 2756.2452, mean_steps: 9.9400, mean_ecr: 0.0555 mean_entropies: 0.2108, took: 54.4729s
2022-10-11 06:04:53,344 [INFO] 	Process 2 - batch 84299: mean_policy_losses: 36.837, mean_net_lifetime: 7531.5639, mean_mc_travel_dist: 1997.5801, mean_rewards: 279.7868, total_rewards: 5553.8520, mean_steps: 26.0000, mean_ecr: 0.0383 mean_entropies: 0.3754, took: 126.5410s
2022-10-11 06:05:00,188 [INFO] Process 5 - epoch 53: mean_policy_losses: -192.655, mean_net_lifetime: 5678.7460, mean_mc_travel_dist: 2128.7002, mean_entropies: 1.1151, m_net_lifetime_valid: 4622.9199, took: 3232.3601s, (163.3876 / 100 batches)

2022-10-11 06:05:14,471 [INFO] 	Process 7 - batch 86099: mean_policy_losses: -424.372, mean_net_lifetime: 4948.9723, mean_mc_travel_dist: 1512.0036, mean_rewards: 197.0863, total_rewards: 3468.0760, mean_steps: 24.2200, mean_ecr: 0.0406 mean_entropies: 1.1603, took: 114.9267s
2022-10-11 06:05:26,326 [INFO] 	Process 6 - batch 124499: mean_policy_losses: -120.239, mean_net_lifetime: 3777.5689, mean_mc_travel_dist: 1030.6153, mean_rewards: 342.0880, total_rewards: 2783.8914, mean_steps: 10.0200, mean_ecr: 0.0555 mean_entropies: 0.1699, took: 56.1281s
2022-10-11 06:05:37,243 [INFO] 	Process 4 - batch 90599: mean_policy_losses: 210.039, mean_net_lifetime: 8494.8046, mean_mc_travel_dist: 2515.8643, mean_rewards: 274.7788, total_rewards: 6006.5182, mean_steps: 33.3000, mean_ecr: 0.0419 mean_entropies: 0.4768, took: 156.8297s
2022-10-11 06:05:47,693 [INFO] 	Process 3 - batch 93499: mean_policy_losses: -8.985, mean_net_lifetime: 5114.5821, mean_mc_travel_dist: 1293.5844, mean_rewards: 278.0341, total_rewards: 3852.2408, mean_steps: 17.4700, mean_ecr: 0.0460 mean_entropies: 0.4672, took: 91.2775s
2022-10-11 06:05:49,366 [INFO] 	Process 1 - batch 77499: mean_policy_losses: -19.865, mean_net_lifetime: 6550.6010, mean_mc_travel_dist: 2087.3295, mean_rewards: 248.1559, total_rewards: 4484.4851, mean_steps: 25.6400, mean_ecr: 0.0381 mean_entropies: 0.8915, took: 125.2097s
2022-10-11 06:06:58,681 [INFO] 	Process 2 - batch 84399: mean_policy_losses: 20.664, mean_net_lifetime: 7536.5000, mean_mc_travel_dist: 1992.1183, mean_rewards: 279.8706, total_rewards: 5573.1838, mean_steps: 26.0500, mean_ecr: 0.0382 mean_entropies: 0.3879, took: 125.3366s
2022-10-11 06:07:06,637 [INFO] 	Process 7 - batch 86199: mean_policy_losses: -446.779, mean_net_lifetime: 5048.3589, mean_mc_travel_dist: 1523.9816, mean_rewards: 207.5685, total_rewards: 3558.7692, mean_steps: 23.6600, mean_ecr: 0.0408 mean_entropies: 1.2333, took: 112.1660s
2022-10-11 06:07:18,761 [INFO] 	Process 3 - batch 93599: mean_policy_losses: -14.062, mean_net_lifetime: 5229.7736, mean_mc_travel_dist: 1296.7478, mean_rewards: 281.8209, total_rewards: 3955.5441, mean_steps: 17.6100, mean_ecr: 0.0463 mean_entropies: 0.4658, took: 91.0679s
2022-10-11 06:07:36,025 [INFO] 	Process 5 - batch 79599: mean_policy_losses: -213.627, mean_net_lifetime: 8665.0791, mean_mc_travel_dist: 2668.2639, mean_rewards: 269.9580, total_rewards: 6024.6437, mean_steps: 31.6600, mean_ecr: 0.0299 mean_entropies: 0.6527, took: 804.6975s
2022-10-11 06:07:54,283 [INFO] 	Process 4 - batch 90699: mean_policy_losses: 238.143, mean_net_lifetime: 7739.9543, mean_mc_travel_dist: 2218.4276, mean_rewards: 280.2546, total_rewards: 5553.2971, mean_steps: 28.5600, mean_ecr: 0.0423 mean_entropies: 0.5264, took: 137.0399s
2022-10-11 06:07:59,305 [INFO] 	Process 1 - batch 77599: mean_policy_losses: -32.398, mean_net_lifetime: 6785.8298, mean_mc_travel_dist: 2105.5430, mean_rewards: 244.5492, total_rewards: 4708.9009, mean_steps: 27.0400, mean_ecr: 0.0381 mean_entropies: 0.9244, took: 129.9384s
2022-10-11 06:08:48,288 [INFO] 	Process 3 - batch 93699: mean_policy_losses: -36.990, mean_net_lifetime: 5239.8396, mean_mc_travel_dist: 1342.2771, mean_rewards: 278.1419, total_rewards: 3926.4571, mean_steps: 17.8700, mean_ecr: 0.0457 mean_entropies: 0.4661, took: 89.5271s
2022-10-11 06:09:02,790 [INFO] 	Process 2 - batch 84499: mean_policy_losses: -13.697, mean_net_lifetime: 7484.3941, mean_mc_travel_dist: 2017.6155, mean_rewards: 281.2829, total_rewards: 5489.1358, mean_steps: 25.6900, mean_ecr: 0.0382 mean_entropies: 0.4217, took: 124.1096s
2022-10-11 06:09:07,715 [INFO] 	Process 7 - batch 86299: mean_policy_losses: -399.170, mean_net_lifetime: 5311.0166, mean_mc_travel_dist: 1604.5341, mean_rewards: 202.2533, total_rewards: 3740.5670, mean_steps: 25.6300, mean_ecr: 0.0406 mean_entropies: 1.2630, took: 121.0784s
2022-10-11 06:10:01,448 [INFO] 	Process 4 - batch 90799: mean_policy_losses: 205.670, mean_net_lifetime: 7309.4758, mean_mc_travel_dist: 2044.7944, mean_rewards: 286.3818, total_rewards: 5293.3846, mean_steps: 25.9100, mean_ecr: 0.0424 mean_entropies: 0.4770, took: 127.1648s
2022-10-11 06:10:07,420 [INFO] 	Process 1 - batch 77699: mean_policy_losses: -28.788, mean_net_lifetime: 6615.6778, mean_mc_travel_dist: 2047.9985, mean_rewards: 243.6920, total_rewards: 4583.0063, mean_steps: 26.3500, mean_ecr: 0.0383 mean_entropies: 0.9295, took: 128.1152s
2022-10-11 06:10:19,137 [INFO] 	Process 3 - batch 93799: mean_policy_losses: -30.119, mean_net_lifetime: 5187.6905, mean_mc_travel_dist: 1319.2938, mean_rewards: 275.1137, total_rewards: 3907.0937, mean_steps: 17.9400, mean_ecr: 0.0460 mean_entropies: 0.4574, took: 90.8494s
2022-10-11 06:10:21,256 [INFO] 	Process 5 - batch 79699: mean_policy_losses: -147.369, mean_net_lifetime: 9541.8567, mean_mc_travel_dist: 2918.0356, mean_rewards: 274.2199, total_rewards: 6668.6253, mean_steps: 34.6100, mean_ecr: 0.0298 mean_entropies: 0.6603, took: 165.2303s
2022-10-11 06:11:07,116 [INFO] 	Process 2 - batch 84599: mean_policy_losses: -9.107, mean_net_lifetime: 7400.5061, mean_mc_travel_dist: 1963.3240, mean_rewards: 276.9831, total_rewards: 5469.9619, mean_steps: 25.7700, mean_ecr: 0.0383 mean_entropies: 0.3944, took: 124.3250s
2022-10-11 06:11:08,374 [INFO] 	Process 7 - batch 86399: mean_policy_losses: -453.000, mean_net_lifetime: 5172.6854, mean_mc_travel_dist: 1548.5348, mean_rewards: 197.7107, total_rewards: 3668.7950, mean_steps: 25.4500, mean_ecr: 0.0405 mean_entropies: 1.2595, took: 120.6588s
2022-10-11 06:11:50,363 [INFO] 	Process 4 - batch 90899: mean_policy_losses: 167.519, mean_net_lifetime: 6272.8685, mean_mc_travel_dist: 1692.6973, mean_rewards: 289.7968, total_rewards: 4602.3563, mean_steps: 21.5300, mean_ecr: 0.0442 mean_entropies: 0.4564, took: 108.9151s
2022-10-11 06:11:52,945 [INFO] 	Process 3 - batch 93899: mean_policy_losses: -27.244, mean_net_lifetime: 5161.1404, mean_mc_travel_dist: 1309.8906, mean_rewards: 273.7047, total_rewards: 3879.1025, mean_steps: 17.9200, mean_ecr: 0.0458 mean_entropies: 0.4735, took: 93.8079s
2022-10-11 06:12:13,886 [INFO] 	Process 1 - batch 77799: mean_policy_losses: -34.137, mean_net_lifetime: 6550.5560, mean_mc_travel_dist: 2026.0603, mean_rewards: 241.7242, total_rewards: 4554.6612, mean_steps: 26.1900, mean_ecr: 0.0384 mean_entropies: 0.9118, took: 126.4645s
2022-10-11 06:12:57,379 [INFO] 	Process 5 - batch 79799: mean_policy_losses: -163.165, mean_net_lifetime: 8941.7257, mean_mc_travel_dist: 2738.1639, mean_rewards: 268.2922, total_rewards: 6237.9480, mean_steps: 32.6800, mean_ecr: 0.0300 mean_entropies: 0.6411, took: 156.1231s
2022-10-11 06:13:08,067 [INFO] 	Process 7 - batch 86499: mean_policy_losses: -423.874, mean_net_lifetime: 5156.6361, mean_mc_travel_dist: 1545.1204, mean_rewards: 198.4530, total_rewards: 3638.5899, mean_steps: 25.3400, mean_ecr: 0.0407 mean_entropies: 1.2472, took: 119.6930s
2022-10-11 06:13:12,989 [INFO] 	Process 2 - batch 84699: mean_policy_losses: 0.025, mean_net_lifetime: 7410.0014, mean_mc_travel_dist: 1984.8527, mean_rewards: 279.2802, total_rewards: 5459.4193, mean_steps: 25.6200, mean_ecr: 0.0383 mean_entropies: 0.4228, took: 125.8729s
2022-10-11 06:13:24,525 [INFO] 	Process 3 - batch 93999: mean_policy_losses: -27.181, mean_net_lifetime: 5209.7719, mean_mc_travel_dist: 1322.3585, mean_rewards: 281.5187, total_rewards: 3919.9045, mean_steps: 17.5800, mean_ecr: 0.0458 mean_entropies: 0.4709, took: 91.5795s
2022-10-11 06:14:04,962 [INFO] 	Process 4 - batch 90999: mean_policy_losses: 282.766, mean_net_lifetime: 7707.0724, mean_mc_travel_dist: 2152.5507, mean_rewards: 280.4527, total_rewards: 5585.5457, mean_steps: 27.8000, mean_ecr: 0.0421 mean_entropies: 0.5362, took: 134.5993s
2022-10-11 06:14:26,428 [INFO] 	Process 1 - batch 77899: mean_policy_losses: -52.987, mean_net_lifetime: 6810.7343, mean_mc_travel_dist: 2109.6878, mean_rewards: 239.5684, total_rewards: 4730.8939, mean_steps: 27.6900, mean_ecr: 0.0380 mean_entropies: 0.9349, took: 132.5438s
2022-10-11 06:14:56,707 [INFO] 	Process 3 - batch 94099: mean_policy_losses: -26.509, mean_net_lifetime: 5258.1241, mean_mc_travel_dist: 1329.2546, mean_rewards: 284.1178, total_rewards: 3952.3210, mean_steps: 17.5400, mean_ecr: 0.0457 mean_entropies: 0.4623, took: 92.1820s
2022-10-11 06:15:03,125 [INFO] 	Process 7 - batch 86599: mean_policy_losses: -429.282, mean_net_lifetime: 5144.5019, mean_mc_travel_dist: 1559.3174, mean_rewards: 206.6968, total_rewards: 3625.3524, mean_steps: 24.1400, mean_ecr: 0.0406 mean_entropies: 1.2893, took: 115.0573s
2022-10-11 06:15:18,637 [INFO] 	Process 2 - batch 84799: mean_policy_losses: 10.858, mean_net_lifetime: 7632.2925, mean_mc_travel_dist: 2032.8892, mean_rewards: 284.2976, total_rewards: 5627.9769, mean_steps: 25.9200, mean_ecr: 0.0382 mean_entropies: 0.4375, took: 125.6487s
2022-10-11 06:15:24,618 [INFO] 	Process 5 - batch 79899: mean_policy_losses: -226.187, mean_net_lifetime: 8435.7560, mean_mc_travel_dist: 2585.4226, mean_rewards: 275.2000, total_rewards: 5887.1830, mean_steps: 30.2200, mean_ecr: 0.0301 mean_entropies: 0.6927, took: 147.2391s
2022-10-11 06:16:32,484 [INFO] 	Process 3 - batch 94199: mean_policy_losses: -16.269, mean_net_lifetime: 5318.7817, mean_mc_travel_dist: 1343.6827, mean_rewards: 281.7802, total_rewards: 4007.2580, mean_steps: 17.9000, mean_ecr: 0.0456 mean_entropies: 0.4639, took: 95.7776s
2022-10-11 06:16:34,564 [INFO] 	Process 1 - batch 77999: mean_policy_losses: -32.551, mean_net_lifetime: 6658.8490, mean_mc_travel_dist: 2077.0884, mean_rewards: 244.4984, total_rewards: 4606.2701, mean_steps: 26.4500, mean_ecr: 0.0382 mean_entropies: 0.9159, took: 128.1359s
2022-10-11 06:16:36,196 [INFO] Process 6 - epoch 83: mean_policy_losses: -188.150, mean_net_lifetime: 3238.7911, mean_mc_travel_dist: 987.1734, mean_entropies: 0.5061, m_net_lifetime_valid: 4510.6272, took: 1483.6953s, (104.9206 / 100 batches)

2022-10-11 06:16:36,566 [INFO] 	Process 4 - batch 91099: mean_policy_losses: 284.154, mean_net_lifetime: 8716.8297, mean_mc_travel_dist: 2532.5916, mean_rewards: 283.8076, total_rewards: 6215.3536, mean_steps: 31.8600, mean_ecr: 0.0409 mean_entropies: 0.4986, took: 151.6028s
2022-10-11 06:17:01,953 [INFO] 	Process 7 - batch 86699: mean_policy_losses: -356.856, mean_net_lifetime: 5274.9781, mean_mc_travel_dist: 1605.2696, mean_rewards: 204.0563, total_rewards: 3710.4448, mean_steps: 25.1000, mean_ecr: 0.0406 mean_entropies: 1.2810, took: 118.8284s
2022-10-11 06:17:26,553 [INFO] 	Process 2 - batch 84899: mean_policy_losses: 19.324, mean_net_lifetime: 7611.6696, mean_mc_travel_dist: 2011.3000, mean_rewards: 280.2399, total_rewards: 5623.1457, mean_steps: 26.2300, mean_ecr: 0.0383 mean_entropies: 0.4249, took: 127.9159s
2022-10-11 06:17:32,412 [INFO] 	Process 6 - batch 124599: mean_policy_losses: -169.652, mean_net_lifetime: 3714.8199, mean_mc_travel_dist: 992.1112, mean_rewards: 339.6392, total_rewards: 2770.8643, mean_steps: 9.8600, mean_ecr: 0.0553 mean_entropies: 0.1888, took: 726.0856s
2022-10-11 06:18:06,574 [INFO] 	Process 3 - batch 94299: mean_policy_losses: -14.311, mean_net_lifetime: 5259.9340, mean_mc_travel_dist: 1350.2667, mean_rewards: 277.9385, total_rewards: 3935.9208, mean_steps: 17.9900, mean_ecr: 0.0455 mean_entropies: 0.4600, took: 94.0901s
2022-10-11 06:18:09,738 [INFO] 	Process 5 - batch 79999: mean_policy_losses: -151.858, mean_net_lifetime: 9449.0335, mean_mc_travel_dist: 2876.4818, mean_rewards: 270.0415, total_rewards: 6618.9085, mean_steps: 34.9100, mean_ecr: 0.0298 mean_entropies: 0.6622, took: 165.1212s
2022-10-11 06:18:27,542 [INFO] 	Process 6 - batch 124699: mean_policy_losses: -185.548, mean_net_lifetime: 3713.3356, mean_mc_travel_dist: 990.4976, mean_rewards: 342.1515, total_rewards: 2767.3362, mean_steps: 9.8200, mean_ecr: 0.0553 mean_entropies: 0.1874, took: 55.1305s
2022-10-11 06:19:00,844 [INFO] 	Process 7 - batch 86799: mean_policy_losses: -309.043, mean_net_lifetime: 5333.4769, mean_mc_travel_dist: 1640.1146, mean_rewards: 205.2291, total_rewards: 3735.1627, mean_steps: 25.2400, mean_ecr: 0.0406 mean_entropies: 1.3134, took: 118.8918s
2022-10-11 06:19:06,330 [INFO] 	Process 4 - batch 91199: mean_policy_losses: 284.343, mean_net_lifetime: 8588.1358, mean_mc_travel_dist: 2501.8003, mean_rewards: 278.5865, total_rewards: 6110.8142, mean_steps: 31.4300, mean_ecr: 0.0399 mean_entropies: 0.5088, took: 149.7653s
2022-10-11 06:19:23,502 [INFO] 	Process 6 - batch 124799: mean_policy_losses: -174.790, mean_net_lifetime: 3770.7221, mean_mc_travel_dist: 998.6287, mean_rewards: 340.8826, total_rewards: 2807.1282, mean_steps: 10.0100, mean_ecr: 0.0554 mean_entropies: 0.1803, took: 55.9599s
2022-10-11 06:19:27,966 [INFO] 	Process 2 - batch 84999: mean_policy_losses: 9.441, mean_net_lifetime: 7447.7932, mean_mc_travel_dist: 1987.2900, mean_rewards: 283.8192, total_rewards: 5485.5358, mean_steps: 25.3400, mean_ecr: 0.0384 mean_entropies: 0.4173, took: 121.4129s
2022-10-11 06:19:41,707 [INFO] 	Process 3 - batch 94399: mean_policy_losses: -5.962, mean_net_lifetime: 5205.8594, mean_mc_travel_dist: 1318.3100, mean_rewards: 272.1535, total_rewards: 3915.5239, mean_steps: 18.2000, mean_ecr: 0.0459 mean_entropies: 0.4448, took: 95.1331s
2022-10-11 06:20:21,462 [INFO] 	Process 6 - batch 124899: mean_policy_losses: -136.210, mean_net_lifetime: 3919.0942, mean_mc_travel_dist: 1045.2313, mean_rewards: 341.9236, total_rewards: 2911.7423, mean_steps: 10.4100, mean_ecr: 0.0554 mean_entropies: 0.1574, took: 57.9587s
2022-10-11 06:20:51,791 [INFO] 	Process 5 - batch 80099: mean_policy_losses: -176.395, mean_net_lifetime: 8796.7623, mean_mc_travel_dist: 2644.0539, mean_rewards: 260.1870, total_rewards: 6191.1927, mean_steps: 33.3400, mean_ecr: 0.0300 mean_entropies: 0.6878, took: 162.0524s
2022-10-11 06:20:55,862 [INFO] 	Process 7 - batch 86899: mean_policy_losses: -373.515, mean_net_lifetime: 5224.7254, mean_mc_travel_dist: 1614.7137, mean_rewards: 207.5544, total_rewards: 3649.5025, mean_steps: 24.3600, mean_ecr: 0.0407 mean_entropies: 1.3340, took: 115.0167s
2022-10-11 06:21:15,729 [INFO] 	Process 3 - batch 94499: mean_policy_losses: -7.703, mean_net_lifetime: 5376.9260, mean_mc_travel_dist: 1376.0123, mean_rewards: 278.1842, total_rewards: 4022.9401, mean_steps: 18.4000, mean_ecr: 0.0453 mean_entropies: 0.4601, took: 94.0215s
2022-10-11 06:21:18,496 [INFO] 	Process 6 - batch 124999: mean_policy_losses: -130.656, mean_net_lifetime: 3898.1202, mean_mc_travel_dist: 1033.4270, mean_rewards: 343.4824, total_rewards: 2899.8800, mean_steps: 10.3300, mean_ecr: 0.0553 mean_entropies: 0.1793, took: 57.0348s
2022-10-11 06:21:26,061 [INFO] 	Process 4 - batch 91299: mean_policy_losses: 225.508, mean_net_lifetime: 8144.0083, mean_mc_travel_dist: 2380.3581, mean_rewards: 279.1684, total_rewards: 5787.0713, mean_steps: 29.6200, mean_ecr: 0.0408 mean_entropies: 0.4848, took: 139.7307s
2022-10-11 06:21:28,367 [INFO] 	Process 2 - batch 85099: mean_policy_losses: -1.692, mean_net_lifetime: 7394.9114, mean_mc_travel_dist: 1965.7209, mean_rewards: 283.4575, total_rewards: 5466.0222, mean_steps: 25.1300, mean_ecr: 0.0385 mean_entropies: 0.4186, took: 120.4016s
2022-10-11 06:22:14,653 [INFO] 	Process 6 - batch 125099: mean_policy_losses: -50.489, mean_net_lifetime: 3935.2265, mean_mc_travel_dist: 1060.2494, mean_rewards: 342.3429, total_rewards: 2918.5937, mean_steps: 10.4700, mean_ecr: 0.0552 mean_entropies: 0.1545, took: 56.1573s
2022-10-11 06:22:48,877 [INFO] 	Process 7 - batch 86999: mean_policy_losses: -361.111, mean_net_lifetime: 5257.4901, mean_mc_travel_dist: 1602.3186, mean_rewards: 209.6056, total_rewards: 3691.0872, mean_steps: 24.3200, mean_ecr: 0.0405 mean_entropies: 1.3173, took: 113.0158s
2022-10-11 06:23:10,080 [INFO] 	Process 6 - batch 125199: mean_policy_losses: -87.497, mean_net_lifetime: 3986.1668, mean_mc_travel_dist: 1071.1989, mean_rewards: 343.4226, total_rewards: 2962.3872, mean_steps: 10.6000, mean_ecr: 0.0551 mean_entropies: 0.1693, took: 55.4272s
2022-10-11 06:23:26,861 [INFO] 	Process 2 - batch 85199: mean_policy_losses: 33.135, mean_net_lifetime: 7589.3268, mean_mc_travel_dist: 1999.5560, mean_rewards: 287.0087, total_rewards: 5621.0172, mean_steps: 25.5400, mean_ecr: 0.0383 mean_entropies: 0.4088, took: 118.4933s
2022-10-11 06:23:47,187 [INFO] 	Process 4 - batch 91399: mean_policy_losses: 189.312, mean_net_lifetime: 8505.5065, mean_mc_travel_dist: 2454.6894, mean_rewards: 281.6067, total_rewards: 6079.6280, mean_steps: 31.2800, mean_ecr: 0.0410 mean_entropies: 0.5177, took: 141.1258s
2022-10-11 06:23:49,965 [INFO] 	Process 5 - batch 80199: mean_policy_losses: -149.271, mean_net_lifetime: 10175.6436, mean_mc_travel_dist: 3122.4306, mean_rewards: 262.9801, total_rewards: 7101.6651, mean_steps: 38.6800, mean_ecr: 0.0298 mean_entropies: 0.6816, took: 178.1736s
2022-10-11 06:24:03,597 [INFO] 	Process 6 - batch 125299: mean_policy_losses: -132.101, mean_net_lifetime: 3904.6579, mean_mc_travel_dist: 1042.3075, mean_rewards: 343.7448, total_rewards: 2895.7154, mean_steps: 10.3300, mean_ecr: 0.0553 mean_entropies: 0.1589, took: 53.5168s
2022-10-11 06:24:54,959 [INFO] 	Process 6 - batch 125399: mean_policy_losses: -148.773, mean_net_lifetime: 3784.4816, mean_mc_travel_dist: 1019.6616, mean_rewards: 341.9414, total_rewards: 2803.5699, mean_steps: 10.0400, mean_ecr: 0.0553 mean_entropies: 0.1738, took: 51.3615s
2022-10-11 06:25:23,736 [INFO] 	Process 2 - batch 85299: mean_policy_losses: 11.669, mean_net_lifetime: 7604.4608, mean_mc_travel_dist: 2022.1119, mean_rewards: 281.4121, total_rewards: 5612.7228, mean_steps: 26.1000, mean_ecr: 0.0383 mean_entropies: 0.3973, took: 116.8746s
2022-10-11 06:25:48,374 [INFO] 	Process 6 - batch 125499: mean_policy_losses: -152.690, mean_net_lifetime: 3928.2167, mean_mc_travel_dist: 1039.2387, mean_rewards: 341.2298, total_rewards: 2922.5702, mean_steps: 10.4200, mean_ecr: 0.0552 mean_entropies: 0.1580, took: 53.4154s
2022-10-11 06:26:40,373 [INFO] 	Process 4 - batch 91499: mean_policy_losses: 184.474, mean_net_lifetime: 10351.0256, mean_mc_travel_dist: 3105.5500, mean_rewards: 277.3387, total_rewards: 7280.2964, mean_steps: 39.8600, mean_ecr: 0.0391 mean_entropies: 0.4897, took: 173.1862s
2022-10-11 06:26:40,414 [INFO] 	Process 6 - batch 125599: mean_policy_losses: -66.696, mean_net_lifetime: 3859.2514, mean_mc_travel_dist: 1053.1794, mean_rewards: 339.9192, total_rewards: 2842.2051, mean_steps: 10.3300, mean_ecr: 0.0555 mean_entropies: 0.1763, took: 52.0395s
2022-10-11 06:26:51,944 [INFO] 	Process 5 - batch 80299: mean_policy_losses: -193.497, mean_net_lifetime: 10596.2843, mean_mc_travel_dist: 3285.0076, mean_rewards: 262.0455, total_rewards: 7359.5701, mean_steps: 40.8800, mean_ecr: 0.0295 mean_entropies: 0.6604, took: 181.9799s
2022-10-11 06:27:17,888 [INFO] Process 1 - epoch 52: mean_policy_losses: 18.731, mean_net_lifetime: 5382.6885, mean_mc_travel_dist: 2041.5930, mean_entropies: 1.1461, m_net_lifetime_valid: 4435.1534, took: 2484.3866s, (168.2455 / 100 batches)

2022-10-11 06:27:20,585 [INFO] 	Process 2 - batch 85399: mean_policy_losses: 23.911, mean_net_lifetime: 7650.4299, mean_mc_travel_dist: 2021.7763, mean_rewards: 280.9387, total_rewards: 5656.7140, mean_steps: 26.3000, mean_ecr: 0.0382 mean_entropies: 0.3935, took: 116.8493s
2022-10-11 06:27:31,805 [INFO] 	Process 6 - batch 125699: mean_policy_losses: -117.514, mean_net_lifetime: 3923.6476, mean_mc_travel_dist: 1045.1660, mean_rewards: 341.7790, total_rewards: 2916.2563, mean_steps: 10.4100, mean_ecr: 0.0553 mean_entropies: 0.1552, took: 51.3916s
2022-10-11 06:28:24,743 [INFO] 	Process 6 - batch 125799: mean_policy_losses: -98.132, mean_net_lifetime: 3909.3145, mean_mc_travel_dist: 1046.1329, mean_rewards: 339.6657, total_rewards: 2917.1062, mean_steps: 10.4300, mean_ecr: 0.0554 mean_entropies: 0.1651, took: 52.9381s
2022-10-11 06:29:15,426 [INFO] 	Process 2 - batch 85499: mean_policy_losses: 31.111, mean_net_lifetime: 7551.1925, mean_mc_travel_dist: 1998.6737, mean_rewards: 283.2174, total_rewards: 5585.4651, mean_steps: 25.7300, mean_ecr: 0.0384 mean_entropies: 0.4228, took: 114.8416s
2022-10-11 06:29:16,879 [INFO] 	Process 1 - batch 78099: mean_policy_losses: -18.479, mean_net_lifetime: 6588.0244, mean_mc_travel_dist: 2051.4443, mean_rewards: 241.2104, total_rewards: 4554.9511, mean_steps: 26.5300, mean_ecr: 0.0384 mean_entropies: 0.9407, took: 762.3154s
2022-10-11 06:29:18,024 [INFO] 	Process 6 - batch 125899: mean_policy_losses: -76.727, mean_net_lifetime: 3889.5593, mean_mc_travel_dist: 1048.6183, mean_rewards: 338.3241, total_rewards: 2887.1942, mean_steps: 10.4400, mean_ecr: 0.0555 mean_entropies: 0.1694, took: 53.2810s
2022-10-11 06:29:39,170 [INFO] 	Process 5 - batch 80399: mean_policy_losses: -161.041, mean_net_lifetime: 10194.5239, mean_mc_travel_dist: 3115.4806, mean_rewards: 262.2273, total_rewards: 7127.1193, mean_steps: 38.9700, mean_ecr: 0.0296 mean_entropies: 0.6771, took: 167.2255s
2022-10-11 06:30:10,027 [INFO] 	Process 6 - batch 125999: mean_policy_losses: -112.015, mean_net_lifetime: 3941.6225, mean_mc_travel_dist: 1054.3008, mean_rewards: 341.4763, total_rewards: 2937.3056, mean_steps: 10.4900, mean_ecr: 0.0552 mean_entropies: 0.1663, took: 52.0023s
2022-10-11 06:31:03,533 [INFO] 	Process 1 - batch 78199: mean_policy_losses: 5.677, mean_net_lifetime: 6703.9566, mean_mc_travel_dist: 2101.9214, mean_rewards: 250.8929, total_rewards: 4633.1465, mean_steps: 25.8500, mean_ecr: 0.0382 mean_entropies: 0.9530, took: 106.6538s
2022-10-11 06:31:21,136 [INFO] Process 3 - epoch 63: mean_policy_losses: 47.393, mean_net_lifetime: 4461.9360, mean_mc_travel_dist: 1339.7522, mean_entropies: 0.8060, m_net_lifetime_valid: 4199.6567, took: 1992.3496s, (139.1969 / 100 batches)

2022-10-11 06:31:38,168 [INFO] 	Process 5 - batch 80499: mean_policy_losses: -158.364, mean_net_lifetime: 8030.8418, mean_mc_travel_dist: 2436.2291, mean_rewards: 273.9051, total_rewards: 5633.8852, mean_steps: 28.8600, mean_ecr: 0.0302 mean_entropies: 0.6536, took: 118.9983s
2022-10-11 06:32:42,924 [INFO] 	Process 3 - batch 94599: mean_policy_losses: -0.535, mean_net_lifetime: 5151.7372, mean_mc_travel_dist: 1295.3220, mean_rewards: 276.2878, total_rewards: 3882.0718, mean_steps: 17.7300, mean_ecr: 0.0460 mean_entropies: 0.4856, took: 687.1949s
2022-10-11 06:32:50,542 [INFO] 	Process 1 - batch 78299: mean_policy_losses: -4.943, mean_net_lifetime: 6528.3170, mean_mc_travel_dist: 2075.8289, mean_rewards: 253.5613, total_rewards: 4477.8371, mean_steps: 24.8200, mean_ecr: 0.0383 mean_entropies: 0.9659, took: 107.0085s
2022-10-11 06:33:54,623 [INFO] Process 7 - epoch 58: mean_policy_losses: -368.563, mean_net_lifetime: 4295.4843, mean_mc_travel_dist: 1553.3005, mean_entropies: 1.5299, m_net_lifetime_valid: 4748.8877, took: 2373.4333s, (151.2905 / 100 batches)

2022-10-11 06:33:58,108 [INFO] 	Process 5 - batch 80599: mean_policy_losses: -70.863, mean_net_lifetime: 8917.8059, mean_mc_travel_dist: 2738.4538, mean_rewards: 275.8452, total_rewards: 6227.0372, mean_steps: 32.3200, mean_ecr: 0.0298 mean_entropies: 0.6588, took: 139.9397s
2022-10-11 06:34:08,813 [INFO] 	Process 3 - batch 94699: mean_policy_losses: -16.288, mean_net_lifetime: 5323.9819, mean_mc_travel_dist: 1379.9901, mean_rewards: 277.7097, total_rewards: 3964.6512, mean_steps: 18.2600, mean_ecr: 0.0451 mean_entropies: 0.5009, took: 85.8888s
2022-10-11 06:34:48,886 [INFO] 	Process 1 - batch 78399: mean_policy_losses: -41.430, mean_net_lifetime: 6733.4594, mean_mc_travel_dist: 2066.0541, mean_rewards: 245.2948, total_rewards: 4697.5839, mean_steps: 26.5700, mean_ecr: 0.0383 mean_entropies: 0.9908, took: 118.3438s
2022-10-11 06:35:35,905 [INFO] 	Process 3 - batch 94799: mean_policy_losses: -20.669, mean_net_lifetime: 5296.4557, mean_mc_travel_dist: 1365.4435, mean_rewards: 280.8805, total_rewards: 3955.6163, mean_steps: 17.8700, mean_ecr: 0.0452 mean_entropies: 0.4907, took: 87.0924s
2022-10-11 06:35:49,568 [INFO] 	Process 7 - batch 87099: mean_policy_losses: -249.983, mean_net_lifetime: 5327.5850, mean_mc_travel_dist: 1612.0798, mean_rewards: 201.3725, total_rewards: 3752.1556, mean_steps: 26.1200, mean_ecr: 0.0406 mean_entropies: 1.2562, took: 780.6907s
2022-10-11 06:36:49,489 [INFO] 	Process 1 - batch 78499: mean_policy_losses: -17.918, mean_net_lifetime: 6670.6021, mean_mc_travel_dist: 2051.6138, mean_rewards: 245.7834, total_rewards: 4653.6104, mean_steps: 26.3300, mean_ecr: 0.0383 mean_entropies: 0.9495, took: 120.6037s
2022-10-11 06:36:52,812 [INFO] Process 4 - epoch 61: mean_policy_losses: 106.688, mean_net_lifetime: 4886.2792, mean_mc_travel_dist: 1520.0185, mean_entropies: 1.0408, m_net_lifetime_valid: 4409.0721, took: 2755.1070s, (144.1108 / 100 batches)

2022-10-11 06:37:07,165 [INFO] 	Process 3 - batch 94899: mean_policy_losses: -11.128, mean_net_lifetime: 5405.6335, mean_mc_travel_dist: 1408.1983, mean_rewards: 276.8697, total_rewards: 4027.5871, mean_steps: 18.5800, mean_ecr: 0.0452 mean_entropies: 0.4747, took: 91.2595s
2022-10-11 06:37:09,282 [INFO] 	Process 5 - batch 80699: mean_policy_losses: -31.577, mean_net_lifetime: 11432.1904, mean_mc_travel_dist: 3564.1210, mean_rewards: 265.6690, total_rewards: 7897.8882, mean_steps: 43.6800, mean_ecr: 0.0294 mean_entropies: 0.6791, took: 191.1738s
2022-10-11 06:37:36,175 [INFO] 	Process 7 - batch 87199: mean_policy_losses: -321.104, mean_net_lifetime: 4885.0435, mean_mc_travel_dist: 1446.5875, mean_rewards: 202.0393, total_rewards: 3470.7444, mean_steps: 23.6800, mean_ecr: 0.0409 mean_entropies: 1.1843, took: 106.6070s
2022-10-11 06:38:38,022 [INFO] 	Process 3 - batch 94999: mean_policy_losses: -23.771, mean_net_lifetime: 5280.5389, mean_mc_travel_dist: 1375.2132, mean_rewards: 278.3244, total_rewards: 3933.6599, mean_steps: 18.0400, mean_ecr: 0.0453 mean_entropies: 0.4688, took: 90.8574s
2022-10-11 06:38:48,729 [INFO] 	Process 1 - batch 78599: mean_policy_losses: -69.374, mean_net_lifetime: 6519.0224, mean_mc_travel_dist: 2015.4050, mean_rewards: 244.3803, total_rewards: 4538.5159, mean_steps: 25.8400, mean_ecr: 0.0385 mean_entropies: 0.9295, took: 119.2392s
2022-10-11 06:39:15,440 [INFO] 	Process 4 - batch 91599: mean_policy_losses: 327.053, mean_net_lifetime: 8101.9327, mean_mc_travel_dist: 2321.2296, mean_rewards: 268.8782, total_rewards: 5809.5588, mean_steps: 30.9100, mean_ecr: 0.0404 mean_entropies: 0.5289, took: 755.0669s
2022-10-11 06:39:38,832 [INFO] 	Process 7 - batch 87299: mean_policy_losses: -254.296, mean_net_lifetime: 5252.5037, mean_mc_travel_dist: 1563.0706, mean_rewards: 191.6250, total_rewards: 3720.8977, mean_steps: 26.9900, mean_ecr: 0.0406 mean_entropies: 1.2137, took: 122.6566s
2022-10-11 06:39:50,930 [INFO] Process 2 - epoch 57: mean_policy_losses: -0.503, mean_net_lifetime: 5261.0814, mean_mc_travel_dist: 1684.3317, mean_entropies: 0.8417, m_net_lifetime_valid: 4333.1523, took: 2471.4035s, (154.3934 / 100 batches)

2022-10-11 06:40:06,997 [INFO] 	Process 3 - batch 95099: mean_policy_losses: -34.385, mean_net_lifetime: 5392.9691, mean_mc_travel_dist: 1405.7368, mean_rewards: 283.5610, total_rewards: 4013.6052, mean_steps: 18.0700, mean_ecr: 0.0453 mean_entropies: 0.4941, took: 88.9754s
2022-10-11 06:40:29,098 [INFO] 	Process 5 - batch 80799: mean_policy_losses: -53.138, mean_net_lifetime: 11506.2795, mean_mc_travel_dist: 3676.0045, mean_rewards: 271.5634, total_rewards: 7877.4306, mean_steps: 42.7700, mean_ecr: 0.0291 mean_entropies: 0.6378, took: 199.8164s
2022-10-11 06:40:30,422 [INFO] Process 6 - epoch 84: mean_policy_losses: -187.370, mean_net_lifetime: 3246.3279, mean_mc_travel_dist: 987.7547, mean_entropies: 0.5021, m_net_lifetime_valid: 4509.7975, took: 1434.2232s, (104.8491 / 100 batches)

2022-10-11 06:41:03,499 [INFO] 	Process 1 - batch 78699: mean_policy_losses: -77.551, mean_net_lifetime: 6911.9770, mean_mc_travel_dist: 2141.6675, mean_rewards: 243.2528, total_rewards: 4800.0656, mean_steps: 27.6800, mean_ecr: 0.0381 mean_entropies: 0.9670, took: 134.7709s
2022-10-11 06:41:25,318 [INFO] 	Process 4 - batch 91699: mean_policy_losses: 264.269, mean_net_lifetime: 7247.0572, mean_mc_travel_dist: 2050.8064, mean_rewards: 271.0954, total_rewards: 5223.2993, mean_steps: 27.0100, mean_ecr: 0.0427 mean_entropies: 0.5311, took: 129.8786s
2022-10-11 06:41:29,659 [INFO] 	Process 6 - batch 126099: mean_policy_losses: -98.957, mean_net_lifetime: 3924.8443, mean_mc_travel_dist: 1040.7709, mean_rewards: 342.3920, total_rewards: 2924.8778, mean_steps: 10.4200, mean_ecr: 0.0550 mean_entropies: 0.1794, took: 679.6324s
2022-10-11 06:41:37,725 [INFO] 	Process 7 - batch 87399: mean_policy_losses: -403.157, mean_net_lifetime: 5129.3946, mean_mc_travel_dist: 1532.9685, mean_rewards: 203.3320, total_rewards: 3623.7958, mean_steps: 24.8400, mean_ecr: 0.0408 mean_entropies: 1.2734, took: 118.8937s
2022-10-11 06:41:41,712 [INFO] 	Process 3 - batch 95199: mean_policy_losses: -14.990, mean_net_lifetime: 5340.3270, mean_mc_travel_dist: 1387.6580, mean_rewards: 281.4116, total_rewards: 3984.7031, mean_steps: 18.0300, mean_ecr: 0.0454 mean_entropies: 0.4950, took: 94.7150s
2022-10-11 06:41:58,288 [INFO] 	Process 2 - batch 85599: mean_policy_losses: 22.938, mean_net_lifetime: 7606.9518, mean_mc_travel_dist: 2042.0279, mean_rewards: 282.0298, total_rewards: 5588.4335, mean_steps: 26.0800, mean_ecr: 0.0382 mean_entropies: 0.4307, took: 762.8612s
2022-10-11 06:42:28,872 [INFO] 	Process 6 - batch 126199: mean_policy_losses: -72.332, mean_net_lifetime: 3929.4003, mean_mc_travel_dist: 1075.1116, mean_rewards: 342.4166, total_rewards: 2904.6913, mean_steps: 10.4400, mean_ecr: 0.0551 mean_entropies: 0.1609, took: 59.2130s
2022-10-11 06:43:16,660 [INFO] 	Process 3 - batch 95299: mean_policy_losses: -4.506, mean_net_lifetime: 5310.8131, mean_mc_travel_dist: 1381.2379, mean_rewards: 281.0543, total_rewards: 3972.6913, mean_steps: 17.9300, mean_ecr: 0.0453 mean_entropies: 0.4738, took: 94.9484s
2022-10-11 06:43:17,892 [INFO] 	Process 1 - batch 78799: mean_policy_losses: -25.645, mean_net_lifetime: 6776.3740, mean_mc_travel_dist: 2112.3144, mean_rewards: 244.5080, total_rewards: 4690.6996, mean_steps: 26.9200, mean_ecr: 0.0380 mean_entropies: 0.9646, took: 134.3924s
2022-10-11 06:43:23,225 [INFO] 	Process 6 - batch 126299: mean_policy_losses: -158.070, mean_net_lifetime: 3555.1726, mean_mc_travel_dist: 987.0801, mean_rewards: 336.0430, total_rewards: 2616.3684, mean_steps: 9.5400, mean_ecr: 0.0557 mean_entropies: 0.1978, took: 54.3525s
2022-10-11 06:43:32,757 [INFO] 	Process 7 - batch 87499: mean_policy_losses: -348.224, mean_net_lifetime: 5061.3343, mean_mc_travel_dist: 1519.0624, mean_rewards: 208.4657, total_rewards: 3578.4132, mean_steps: 23.6100, mean_ecr: 0.0408 mean_entropies: 1.2237, took: 115.0320s
2022-10-11 06:43:45,090 [INFO] 	Process 4 - batch 91799: mean_policy_losses: 242.961, mean_net_lifetime: 7659.4580, mean_mc_travel_dist: 2165.2895, mean_rewards: 273.1919, total_rewards: 5523.4081, mean_steps: 28.3200, mean_ecr: 0.0414 mean_entropies: 0.5193, took: 139.7713s
2022-10-11 06:43:57,490 [INFO] 	Process 5 - batch 80899: mean_policy_losses: -70.235, mean_net_lifetime: 11355.7101, mean_mc_travel_dist: 3540.6001, mean_rewards: 267.9900, total_rewards: 7851.0710, mean_steps: 42.6700, mean_ecr: 0.0294 mean_entropies: 0.6617, took: 208.3920s
2022-10-11 06:44:03,195 [INFO] 	Process 2 - batch 85699: mean_policy_losses: 18.483, mean_net_lifetime: 7342.6404, mean_mc_travel_dist: 1940.3581, mean_rewards: 281.3068, total_rewards: 5436.8265, mean_steps: 25.1900, mean_ecr: 0.0385 mean_entropies: 0.3826, took: 124.9069s
2022-10-11 06:44:20,520 [INFO] 	Process 6 - batch 126399: mean_policy_losses: -89.875, mean_net_lifetime: 3883.7780, mean_mc_travel_dist: 1031.1117, mean_rewards: 342.2173, total_rewards: 2888.8066, mean_steps: 10.3500, mean_ecr: 0.0549 mean_entropies: 0.1881, took: 57.2951s
2022-10-11 06:44:50,082 [INFO] 	Process 3 - batch 95399: mean_policy_losses: -8.162, mean_net_lifetime: 5288.4060, mean_mc_travel_dist: 1384.4513, mean_rewards: 283.2529, total_rewards: 3937.9349, mean_steps: 17.7000, mean_ecr: 0.0454 mean_entropies: 0.5009, took: 93.4216s
2022-10-11 06:45:17,708 [INFO] 	Process 6 - batch 126499: mean_policy_losses: -98.396, mean_net_lifetime: 3857.0481, mean_mc_travel_dist: 1043.7923, mean_rewards: 337.7798, total_rewards: 2860.7110, mean_steps: 10.3400, mean_ecr: 0.0552 mean_entropies: 0.1756, took: 57.1882s
2022-10-11 06:45:27,349 [INFO] 	Process 1 - batch 78899: mean_policy_losses: -49.101, mean_net_lifetime: 6634.2380, mean_mc_travel_dist: 2063.0249, mean_rewards: 249.1113, total_rewards: 4607.3021, mean_steps: 25.8200, mean_ecr: 0.0382 mean_entropies: 0.9416, took: 129.4570s
2022-10-11 06:45:39,474 [INFO] 	Process 7 - batch 87599: mean_policy_losses: -307.947, mean_net_lifetime: 5329.5698, mean_mc_travel_dist: 1561.0518, mean_rewards: 199.1312, total_rewards: 3800.5824, mean_steps: 26.0800, mean_ecr: 0.0406 mean_entropies: 1.2121, took: 126.7178s
2022-10-11 06:46:08,642 [INFO] 	Process 2 - batch 85799: mean_policy_losses: 7.335, mean_net_lifetime: 7422.0090, mean_mc_travel_dist: 1981.7294, mean_rewards: 281.7180, total_rewards: 5472.1923, mean_steps: 25.4000, mean_ecr: 0.0383 mean_entropies: 0.4038, took: 125.4477s
2022-10-11 06:46:17,975 [INFO] 	Process 6 - batch 126599: mean_policy_losses: -71.708, mean_net_lifetime: 4038.3002, mean_mc_travel_dist: 1087.6535, mean_rewards: 341.0283, total_rewards: 2996.0655, mean_steps: 10.8000, mean_ecr: 0.0551 mean_entropies: 0.1622, took: 60.2673s
2022-10-11 06:46:18,719 [INFO] 	Process 4 - batch 91899: mean_policy_losses: 239.296, mean_net_lifetime: 8208.4747, mean_mc_travel_dist: 2360.9762, mean_rewards: 267.4503, total_rewards: 5869.8730, mean_steps: 31.2900, mean_ecr: 0.0400 mean_entropies: 0.5128, took: 153.6298s
2022-10-11 06:46:27,368 [INFO] 	Process 3 - batch 95499: mean_policy_losses: -1.514, mean_net_lifetime: 5390.9216, mean_mc_travel_dist: 1401.2703, mean_rewards: 280.8518, total_rewards: 4030.4213, mean_steps: 18.2600, mean_ecr: 0.0455 mean_entropies: 0.4702, took: 97.2861s
2022-10-11 06:46:53,290 [INFO] 	Process 5 - batch 80999: mean_policy_losses: -120.276, mean_net_lifetime: 9729.8215, mean_mc_travel_dist: 3039.9567, mean_rewards: 270.9332, total_rewards: 6721.8557, mean_steps: 35.6800, mean_ecr: 0.0295 mean_entropies: 0.6392, took: 175.7993s
2022-10-11 06:47:13,872 [INFO] 	Process 6 - batch 126699: mean_policy_losses: -128.037, mean_net_lifetime: 3707.6723, mean_mc_travel_dist: 1000.2699, mean_rewards: 338.0643, total_rewards: 2750.3839, mean_steps: 9.9300, mean_ecr: 0.0556 mean_entropies: 0.1857, took: 55.8971s
2022-10-11 06:47:21,844 [INFO] 	Process 7 - batch 87699: mean_policy_losses: -468.621, mean_net_lifetime: 4284.3731, mean_mc_travel_dist: 1255.4692, mean_rewards: 199.9006, total_rewards: 3060.5612, mean_steps: 20.9100, mean_ecr: 0.0415 mean_entropies: 1.2048, took: 102.3696s
2022-10-11 06:47:33,906 [INFO] 	Process 1 - batch 78999: mean_policy_losses: -44.030, mean_net_lifetime: 6587.6200, mean_mc_travel_dist: 2058.7285, mean_rewards: 245.1764, total_rewards: 4554.7278, mean_steps: 26.0200, mean_ecr: 0.0382 mean_entropies: 0.8945, took: 126.5576s
2022-10-11 06:47:57,934 [INFO] 	Process 3 - batch 95599: mean_policy_losses: -16.995, mean_net_lifetime: 5247.7008, mean_mc_travel_dist: 1344.4434, mean_rewards: 284.6441, total_rewards: 3930.9520, mean_steps: 17.4900, mean_ecr: 0.0458 mean_entropies: 0.4947, took: 90.5653s
2022-10-11 06:48:13,092 [INFO] 	Process 6 - batch 126799: mean_policy_losses: -115.267, mean_net_lifetime: 4097.1265, mean_mc_travel_dist: 1098.6091, mean_rewards: 342.7736, total_rewards: 3045.9501, mean_steps: 10.9100, mean_ecr: 0.0550 mean_entropies: 0.1646, took: 59.2201s
2022-10-11 06:48:14,377 [INFO] 	Process 2 - batch 85899: mean_policy_losses: 15.170, mean_net_lifetime: 7545.4790, mean_mc_travel_dist: 2030.7988, mean_rewards: 282.0119, total_rewards: 5541.0814, mean_steps: 25.8900, mean_ecr: 0.0382 mean_entropies: 0.4352, took: 125.7347s
2022-10-11 06:48:33,681 [INFO] 	Process 4 - batch 91999: mean_policy_losses: 230.271, mean_net_lifetime: 7487.8536, mean_mc_travel_dist: 2103.3329, mean_rewards: 270.0499, total_rewards: 5412.9827, mean_steps: 28.0100, mean_ecr: 0.0416 mean_entropies: 0.5292, took: 134.9601s
2022-10-11 06:49:06,122 [INFO] 	Process 6 - batch 126899: mean_policy_losses: -123.961, mean_net_lifetime: 3619.3408, mean_mc_travel_dist: 976.2885, mean_rewards: 340.8013, total_rewards: 2709.5343, mean_steps: 9.5900, mean_ecr: 0.0551 mean_entropies: 0.1818, took: 53.0303s
2022-10-11 06:49:16,990 [INFO] 	Process 7 - batch 87799: mean_policy_losses: -339.229, mean_net_lifetime: 5156.6056, mean_mc_travel_dist: 1553.4199, mean_rewards: 204.0736, total_rewards: 3639.6714, mean_steps: 24.5400, mean_ecr: 0.0407 mean_entropies: 1.1778, took: 115.1456s
2022-10-11 06:49:26,081 [INFO] 	Process 3 - batch 95699: mean_policy_losses: -25.796, mean_net_lifetime: 5286.6454, mean_mc_travel_dist: 1357.0952, mean_rewards: 285.5160, total_rewards: 3953.8677, mean_steps: 17.5700, mean_ecr: 0.0459 mean_entropies: 0.4906, took: 88.1474s
2022-10-11 06:49:35,919 [INFO] 	Process 1 - batch 79099: mean_policy_losses: -62.093, mean_net_lifetime: 6670.1714, mean_mc_travel_dist: 2099.4963, mean_rewards: 252.5516, total_rewards: 4598.1177, mean_steps: 25.5500, mean_ecr: 0.0381 mean_entropies: 0.9811, took: 122.0127s
2022-10-11 06:50:02,559 [INFO] 	Process 6 - batch 126999: mean_policy_losses: -77.610, mean_net_lifetime: 3944.0131, mean_mc_travel_dist: 1061.7382, mean_rewards: 342.3424, total_rewards: 2933.0504, mean_steps: 10.4900, mean_ecr: 0.0551 mean_entropies: 0.1681, took: 56.4366s
2022-10-11 06:50:20,535 [INFO] 	Process 2 - batch 85999: mean_policy_losses: 34.738, mean_net_lifetime: 7720.7009, mean_mc_travel_dist: 2063.0632, mean_rewards: 286.3457, total_rewards: 5679.0393, mean_steps: 26.0400, mean_ecr: 0.0380 mean_entropies: 0.4416, took: 126.1575s
2022-10-11 06:50:40,095 [INFO] 	Process 4 - batch 92099: mean_policy_losses: 209.027, mean_net_lifetime: 7232.9671, mean_mc_travel_dist: 2038.6014, mean_rewards: 275.6132, total_rewards: 5221.2795, mean_steps: 26.2600, mean_ecr: 0.0418 mean_entropies: 0.5339, took: 126.4151s
2022-10-11 06:50:55,868 [INFO] 	Process 6 - batch 127099: mean_policy_losses: -171.235, mean_net_lifetime: 3684.4439, mean_mc_travel_dist: 993.0189, mean_rewards: 339.5427, total_rewards: 2748.1701, mean_steps: 9.7800, mean_ecr: 0.0554 mean_entropies: 0.1944, took: 53.3094s
2022-10-11 06:50:58,962 [INFO] 	Process 3 - batch 95799: mean_policy_losses: -22.716, mean_net_lifetime: 5309.4685, mean_mc_travel_dist: 1359.4538, mean_rewards: 277.3092, total_rewards: 3977.3637, mean_steps: 18.2600, mean_ecr: 0.0457 mean_entropies: 0.4714, took: 92.8809s
2022-10-11 06:51:20,877 [INFO] 	Process 7 - batch 87899: mean_policy_losses: -302.020, mean_net_lifetime: 5287.8713, mean_mc_travel_dist: 1592.4987, mean_rewards: 196.1216, total_rewards: 3727.0949, mean_steps: 26.4900, mean_ecr: 0.0405 mean_entropies: 1.1877, took: 123.8877s
2022-10-11 06:51:35,925 [INFO] 	Process 1 - batch 79199: mean_policy_losses: -31.668, mean_net_lifetime: 6581.1188, mean_mc_travel_dist: 2056.0228, mean_rewards: 255.3355, total_rewards: 4547.6014, mean_steps: 24.8900, mean_ecr: 0.0383 mean_entropies: 0.9910, took: 120.0058s
2022-10-11 06:51:48,180 [INFO] 	Process 6 - batch 127199: mean_policy_losses: -131.090, mean_net_lifetime: 3681.9297, mean_mc_travel_dist: 990.9416, mean_rewards: 340.0772, total_rewards: 2751.3454, mean_steps: 9.7700, mean_ecr: 0.0554 mean_entropies: 0.1732, took: 52.3110s
2022-10-11 06:52:21,144 [INFO] 	Process 2 - batch 86099: mean_policy_losses: 2.190, mean_net_lifetime: 7447.8705, mean_mc_travel_dist: 1985.9457, mean_rewards: 286.8513, total_rewards: 5495.7014, mean_steps: 25.0700, mean_ecr: 0.0384 mean_entropies: 0.3975, took: 120.6094s
2022-10-11 06:52:31,117 [INFO] 	Process 3 - batch 95899: mean_policy_losses: -25.523, mean_net_lifetime: 5265.8464, mean_mc_travel_dist: 1339.2993, mean_rewards: 282.9160, total_rewards: 3963.4718, mean_steps: 17.6500, mean_ecr: 0.0457 mean_entropies: 0.4785, took: 92.1548s
2022-10-11 06:52:45,756 [INFO] 	Process 6 - batch 127299: mean_policy_losses: -76.338, mean_net_lifetime: 4006.5575, mean_mc_travel_dist: 1085.3244, mean_rewards: 342.3294, total_rewards: 2973.7217, mean_steps: 10.6600, mean_ecr: 0.0551 mean_entropies: 0.1513, took: 57.5762s
2022-10-11 06:53:07,087 [INFO] 	Process 4 - batch 92199: mean_policy_losses: 220.206, mean_net_lifetime: 8386.2474, mean_mc_travel_dist: 2398.3864, mean_rewards: 273.9873, total_rewards: 6013.7217, mean_steps: 31.1900, mean_ecr: 0.0398 mean_entropies: 0.5130, took: 146.9922s
2022-10-11 06:53:25,918 [INFO] 	Process 7 - batch 87999: mean_policy_losses: -340.744, mean_net_lifetime: 5397.1818, mean_mc_travel_dist: 1593.9195, mean_rewards: 198.5292, total_rewards: 3830.4293, mean_steps: 26.7700, mean_ecr: 0.0405 mean_entropies: 1.2060, took: 125.0404s
2022-10-11 06:53:38,912 [INFO] 	Process 1 - batch 79299: mean_policy_losses: -58.842, mean_net_lifetime: 6554.2996, mean_mc_travel_dist: 2052.1866, mean_rewards: 248.7579, total_rewards: 4529.1953, mean_steps: 25.5500, mean_ecr: 0.0382 mean_entropies: 0.9836, took: 122.9873s
2022-10-11 06:53:41,255 [INFO] 	Process 6 - batch 127399: mean_policy_losses: -124.038, mean_net_lifetime: 3859.3590, mean_mc_travel_dist: 1048.2967, mean_rewards: 341.8724, total_rewards: 2880.4419, mean_steps: 10.2600, mean_ecr: 0.0552 mean_entropies: 0.1645, took: 55.4987s
2022-10-11 06:54:02,413 [INFO] 	Process 3 - batch 95999: mean_policy_losses: -7.673, mean_net_lifetime: 5245.2365, mean_mc_travel_dist: 1343.5843, mean_rewards: 273.6257, total_rewards: 3937.3740, mean_steps: 18.2100, mean_ecr: 0.0457 mean_entropies: 0.4807, took: 91.2963s
2022-10-11 06:54:22,438 [INFO] 	Process 2 - batch 86199: mean_policy_losses: 29.994, mean_net_lifetime: 7545.4208, mean_mc_travel_dist: 1990.1498, mean_rewards: 287.0130, total_rewards: 5577.2574, mean_steps: 25.3500, mean_ecr: 0.0382 mean_entropies: 0.4101, took: 121.2939s
2022-10-11 06:54:32,657 [INFO] 	Process 6 - batch 127499: mean_policy_losses: -84.699, mean_net_lifetime: 3591.3242, mean_mc_travel_dist: 978.1634, mean_rewards: 338.0255, total_rewards: 2669.4586, mean_steps: 9.6100, mean_ecr: 0.0553 mean_entropies: 0.1925, took: 51.4030s
2022-10-11 06:55:07,100 [INFO] 	Process 7 - batch 88099: mean_policy_losses: -477.170, mean_net_lifetime: 4633.8027, mean_mc_travel_dist: 1416.1526, mean_rewards: 202.5892, total_rewards: 3243.2988, mean_steps: 22.0300, mean_ecr: 0.0411 mean_entropies: 1.1665, took: 101.1823s
2022-10-11 06:55:30,644 [INFO] 	Process 1 - batch 79399: mean_policy_losses: -77.058, mean_net_lifetime: 6465.4277, mean_mc_travel_dist: 2075.0788, mean_rewards: 257.2427, total_rewards: 4408.8201, mean_steps: 24.2100, mean_ecr: 0.0383 mean_entropies: 0.9358, took: 111.7313s
2022-10-11 06:55:34,785 [INFO] 	Process 4 - batch 92299: mean_policy_losses: 207.484, mean_net_lifetime: 8691.5717, mean_mc_travel_dist: 2497.7820, mean_rewards: 272.9210, total_rewards: 6225.3319, mean_steps: 32.7100, mean_ecr: 0.0403 mean_entropies: 0.5207, took: 147.6985s
2022-10-11 06:56:17,559 [INFO] 	Process 2 - batch 86299: mean_policy_losses: 16.281, mean_net_lifetime: 7654.1795, mean_mc_travel_dist: 2032.7906, mean_rewards: 289.8387, total_rewards: 5644.3247, mean_steps: 25.4900, mean_ecr: 0.0382 mean_entropies: 0.4106, took: 115.1205s
2022-10-11 06:57:03,089 [INFO] 	Process 7 - batch 88199: mean_policy_losses: -345.951, mean_net_lifetime: 5426.8028, mean_mc_travel_dist: 1644.7381, mean_rewards: 199.3664, total_rewards: 3818.8955, mean_steps: 26.5100, mean_ecr: 0.0406 mean_entropies: 1.2066, took: 115.9887s
2022-10-11 06:57:25,078 [INFO] 	Process 1 - batch 79499: mean_policy_losses: -98.382, mean_net_lifetime: 6535.3554, mean_mc_travel_dist: 2046.0035, mean_rewards: 250.7790, total_rewards: 4511.9948, mean_steps: 25.1300, mean_ecr: 0.0383 mean_entropies: 0.9121, took: 114.4337s
2022-10-11 06:57:44,725 [INFO] Process 5 - epoch 54: mean_policy_losses: -191.664, mean_net_lifetime: 5753.5461, mean_mc_travel_dist: 2144.7721, mean_entropies: 1.1067, m_net_lifetime_valid: 4558.7995, took: 3164.5345s, (164.2644 / 100 batches)

2022-10-11 06:58:13,471 [INFO] 	Process 2 - batch 86399: mean_policy_losses: -13.220, mean_net_lifetime: 7643.7663, mean_mc_travel_dist: 2027.8571, mean_rewards: 284.1169, total_rewards: 5640.0837, mean_steps: 26.0000, mean_ecr: 0.0382 mean_entropies: 0.3953, took: 115.9128s
2022-10-11 06:58:13,850 [INFO] 	Process 4 - batch 92399: mean_policy_losses: 203.801, mean_net_lifetime: 9393.4669, mean_mc_travel_dist: 2740.5663, mean_rewards: 269.3192, total_rewards: 6683.8093, mean_steps: 36.4300, mean_ecr: 0.0395 mean_entropies: 0.5190, took: 159.0643s
2022-10-11 06:58:50,654 [INFO] 	Process 7 - batch 88299: mean_policy_losses: -364.306, mean_net_lifetime: 5234.3619, mean_mc_travel_dist: 1606.1276, mean_rewards: 209.6221, total_rewards: 3664.9503, mean_steps: 24.2900, mean_ecr: 0.0407 mean_entropies: 1.2323, took: 107.5647s
2022-10-11 07:00:07,754 [INFO] 	Process 5 - batch 81099: mean_policy_losses: -225.684, mean_net_lifetime: 8701.1406, mean_mc_travel_dist: 2727.9182, mean_rewards: 268.3614, total_rewards: 6014.7166, mean_steps: 32.3100, mean_ecr: 0.0299 mean_entropies: 0.6397, took: 794.4641s
2022-10-11 07:00:10,506 [INFO] 	Process 2 - batch 86499: mean_policy_losses: -5.072, mean_net_lifetime: 7645.0516, mean_mc_travel_dist: 2009.2353, mean_rewards: 283.6536, total_rewards: 5669.3693, mean_steps: 26.0400, mean_ecr: 0.0383 mean_entropies: 0.3899, took: 117.0348s
2022-10-11 07:00:38,671 [INFO] 	Process 7 - batch 88399: mean_policy_losses: -358.035, mean_net_lifetime: 5229.3527, mean_mc_travel_dist: 1603.8118, mean_rewards: 207.0584, total_rewards: 3656.4872, mean_steps: 24.5700, mean_ecr: 0.0405 mean_entropies: 1.2066, took: 108.0175s
2022-10-11 07:00:57,835 [INFO] 	Process 4 - batch 92499: mean_policy_losses: 226.112, mean_net_lifetime: 9565.9179, mean_mc_travel_dist: 2789.5803, mean_rewards: 276.6579, total_rewards: 6804.3603, mean_steps: 36.6800, mean_ecr: 0.0404 mean_entropies: 0.5068, took: 163.9850s
2022-10-11 07:02:05,608 [INFO] 	Process 2 - batch 86599: mean_policy_losses: -18.978, mean_net_lifetime: 7438.1048, mean_mc_travel_dist: 1962.9632, mean_rewards: 280.2537, total_rewards: 5501.1051, mean_steps: 25.5900, mean_ecr: 0.0384 mean_entropies: 0.3954, took: 115.1021s
2022-10-11 07:02:19,092 [INFO] 	Process 5 - batch 81199: mean_policy_losses: -310.218, mean_net_lifetime: 7779.8856, mean_mc_travel_dist: 2368.7717, mean_rewards: 266.0249, total_rewards: 5450.2006, mean_steps: 28.8800, mean_ecr: 0.0301 mean_entropies: 0.6633, took: 131.3375s
2022-10-11 07:02:24,342 [INFO] 	Process 7 - batch 88499: mean_policy_losses: -381.892, mean_net_lifetime: 5071.9575, mean_mc_travel_dist: 1533.4902, mean_rewards: 204.9861, total_rewards: 3576.7732, mean_steps: 24.0200, mean_ecr: 0.0407 mean_entropies: 1.2546, took: 105.6706s
2022-10-11 07:03:33,098 [INFO] 	Process 4 - batch 92599: mean_policy_losses: 198.907, mean_net_lifetime: 9469.3066, mean_mc_travel_dist: 2800.8566, mean_rewards: 276.1582, total_rewards: 6701.2315, mean_steps: 36.3900, mean_ecr: 0.0401 mean_entropies: 0.5096, took: 155.2631s
2022-10-11 07:03:52,379 [INFO] 	Process 2 - batch 86699: mean_policy_losses: -62.526, mean_net_lifetime: 7190.1988, mean_mc_travel_dist: 1909.8707, mean_rewards: 284.4908, total_rewards: 5315.7140, mean_steps: 24.3900, mean_ecr: 0.0387 mean_entropies: 0.3937, took: 106.7711s
2022-10-11 07:03:58,895 [INFO] Process 3 - epoch 64: mean_policy_losses: 46.408, mean_net_lifetime: 4475.0689, mean_mc_travel_dist: 1340.2024, mean_entropies: 0.8010, m_net_lifetime_valid: 4646.5604, took: 1957.7561s, (139.0707 / 100 batches)

2022-10-11 07:04:36,339 [INFO] Process 6 - epoch 85: mean_policy_losses: -186.438, mean_net_lifetime: 3253.1400, mean_mc_travel_dist: 988.2894, mean_entropies: 0.4983, m_net_lifetime_valid: 4563.6563, took: 1445.9138s, (104.7628 / 100 batches)

2022-10-11 07:05:02,358 [INFO] 	Process 5 - batch 81299: mean_policy_losses: -199.803, mean_net_lifetime: 9749.5383, mean_mc_travel_dist: 3065.4621, mean_rewards: 267.9857, total_rewards: 6723.1344, mean_steps: 36.4600, mean_ecr: 0.0295 mean_entropies: 0.6302, took: 163.2673s
2022-10-11 07:05:25,352 [INFO] 	Process 3 - batch 96099: mean_policy_losses: -15.674, mean_net_lifetime: 5299.7989, mean_mc_travel_dist: 1385.2693, mean_rewards: 283.0338, total_rewards: 3947.1432, mean_steps: 17.7700, mean_ecr: 0.0453 mean_entropies: 0.4888, took: 682.9381s
2022-10-11 07:05:27,393 [INFO] 	Process 6 - batch 127599: mean_policy_losses: -131.621, mean_net_lifetime: 3696.7098, mean_mc_travel_dist: 994.6668, mean_rewards: 341.8561, total_rewards: 2753.4604, mean_steps: 9.7800, mean_ecr: 0.0555 mean_entropies: 0.1782, took: 654.7362s
2022-10-11 07:05:47,840 [INFO] 	Process 2 - batch 86799: mean_policy_losses: -20.853, mean_net_lifetime: 7359.8072, mean_mc_travel_dist: 1930.0301, mean_rewards: 281.7094, total_rewards: 5457.2466, mean_steps: 25.1700, mean_ecr: 0.0385 mean_entropies: 0.3873, took: 115.4613s
2022-10-11 07:06:21,200 [INFO] 	Process 6 - batch 127699: mean_policy_losses: -147.734, mean_net_lifetime: 3796.4856, mean_mc_travel_dist: 1017.8990, mean_rewards: 340.9237, total_rewards: 2833.8821, mean_steps: 10.0700, mean_ecr: 0.0552 mean_entropies: 0.1836, took: 53.8062s
2022-10-11 07:06:31,114 [INFO] 	Process 4 - batch 92699: mean_policy_losses: 187.782, mean_net_lifetime: 10471.0757, mean_mc_travel_dist: 3144.3182, mean_rewards: 271.5679, total_rewards: 7358.1535, mean_steps: 40.9800, mean_ecr: 0.0387 mean_entropies: 0.5042, took: 178.0165s
2022-10-11 07:06:55,599 [INFO] 	Process 3 - batch 96199: mean_policy_losses: -18.486, mean_net_lifetime: 5390.3417, mean_mc_travel_dist: 1389.5774, mean_rewards: 283.1784, total_rewards: 4028.1239, mean_steps: 18.0900, mean_ecr: 0.0452 mean_entropies: 0.4980, took: 90.2481s
2022-10-11 07:07:09,021 [INFO] Process 1 - epoch 53: mean_policy_losses: 17.534, mean_net_lifetime: 5406.2352, mean_mc_travel_dist: 2042.1501, mean_entropies: 1.1425, m_net_lifetime_valid: 4494.8080, took: 2391.1306s, (168.1536 / 100 batches)

2022-10-11 07:07:14,525 [INFO] 	Process 6 - batch 127799: mean_policy_losses: -177.231, mean_net_lifetime: 3786.6185, mean_mc_travel_dist: 1012.8714, mean_rewards: 340.1644, total_rewards: 2827.3006, mean_steps: 10.0600, mean_ecr: 0.0553 mean_entropies: 0.1716, took: 53.3257s
2022-10-11 07:07:46,690 [INFO] 	Process 2 - batch 86899: mean_policy_losses: 7.782, mean_net_lifetime: 7541.0282, mean_mc_travel_dist: 2000.8272, mean_rewards: 286.8246, total_rewards: 5570.7882, mean_steps: 25.3800, mean_ecr: 0.0384 mean_entropies: 0.3946, took: 118.8497s
2022-10-11 07:07:59,473 [INFO] 	Process 5 - batch 81399: mean_policy_losses: -163.554, mean_net_lifetime: 10286.8834, mean_mc_travel_dist: 3243.0612, mean_rewards: 270.6662, total_rewards: 7087.5877, mean_steps: 38.2100, mean_ecr: 0.0295 mean_entropies: 0.6061, took: 177.1142s
2022-10-11 07:08:11,440 [INFO] 	Process 6 - batch 127899: mean_policy_losses: -77.926, mean_net_lifetime: 3858.8638, mean_mc_travel_dist: 1049.2499, mean_rewards: 337.2474, total_rewards: 2867.0905, mean_steps: 10.4300, mean_ecr: 0.0554 mean_entropies: 0.1773, took: 56.9145s
2022-10-11 07:08:27,185 [INFO] 	Process 3 - batch 96299: mean_policy_losses: -27.305, mean_net_lifetime: 5269.9711, mean_mc_travel_dist: 1352.6981, mean_rewards: 278.2926, total_rewards: 3942.6226, mean_steps: 18.0400, mean_ecr: 0.0455 mean_entropies: 0.4933, took: 91.5853s
2022-10-11 07:09:08,426 [INFO] 	Process 6 - batch 127999: mean_policy_losses: -106.626, mean_net_lifetime: 3942.0074, mean_mc_travel_dist: 1066.8594, mean_rewards: 339.3668, total_rewards: 2939.9598, mean_steps: 10.5500, mean_ecr: 0.0552 mean_entropies: 0.1776, took: 56.9859s
2022-10-11 07:09:12,530 [INFO] 	Process 1 - batch 79599: mean_policy_losses: -62.836, mean_net_lifetime: 6558.0437, mean_mc_travel_dist: 2052.9723, mean_rewards: 250.2060, total_rewards: 4534.6244, mean_steps: 25.3200, mean_ecr: 0.0383 mean_entropies: 0.9316, took: 707.4527s
2022-10-11 07:09:25,929 [INFO] 	Process 4 - batch 92799: mean_policy_losses: 181.895, mean_net_lifetime: 10055.7297, mean_mc_travel_dist: 2930.6406, mean_rewards: 274.8216, total_rewards: 7154.3658, mean_steps: 38.1400, mean_ecr: 0.0389 mean_entropies: 0.5319, took: 174.8154s
2022-10-11 07:09:50,613 [INFO] 	Process 2 - batch 86999: mean_policy_losses: 27.212, mean_net_lifetime: 7656.5897, mean_mc_travel_dist: 2006.9280, mean_rewards: 286.2506, total_rewards: 5676.9314, mean_steps: 25.8600, mean_ecr: 0.0383 mean_entropies: 0.3977, took: 123.9223s
2022-10-11 07:09:56,372 [INFO] 	Process 3 - batch 96399: mean_policy_losses: -23.240, mean_net_lifetime: 5246.7262, mean_mc_travel_dist: 1308.2828, mean_rewards: 282.9343, total_rewards: 3962.3659, mean_steps: 17.5900, mean_ecr: 0.0458 mean_entropies: 0.4816, took: 89.1873s
2022-10-11 07:10:03,658 [INFO] 	Process 6 - batch 128099: mean_policy_losses: -78.051, mean_net_lifetime: 3796.2818, mean_mc_travel_dist: 1031.6777, mean_rewards: 339.2678, total_rewards: 2824.8432, mean_steps: 10.1400, mean_ecr: 0.0552 mean_entropies: 0.1745, took: 55.2319s
2022-10-11 07:10:44,397 [INFO] 	Process 5 - batch 81499: mean_policy_losses: -227.791, mean_net_lifetime: 9450.0230, mean_mc_travel_dist: 2963.8149, mean_rewards: 272.5142, total_rewards: 6525.9375, mean_steps: 35.1400, mean_ecr: 0.0296 mean_entropies: 0.6098, took: 164.9243s
2022-10-11 07:10:59,891 [INFO] 	Process 6 - batch 128199: mean_policy_losses: -70.128, mean_net_lifetime: 3941.7617, mean_mc_travel_dist: 1057.6965, mean_rewards: 342.7804, total_rewards: 2918.0246, mean_steps: 10.4800, mean_ecr: 0.0552 mean_entropies: 0.1655, took: 56.2323s
2022-10-11 07:11:12,661 [INFO] 	Process 1 - batch 79699: mean_policy_losses: -42.860, mean_net_lifetime: 6509.8550, mean_mc_travel_dist: 2047.3784, mean_rewards: 247.4483, total_rewards: 4485.1920, mean_steps: 25.4100, mean_ecr: 0.0383 mean_entropies: 0.9379, took: 120.1311s
2022-10-11 07:11:23,945 [INFO] 	Process 3 - batch 96499: mean_policy_losses: 5.912, mean_net_lifetime: 5306.3136, mean_mc_travel_dist: 1352.5339, mean_rewards: 283.5288, total_rewards: 3978.4457, mean_steps: 17.7400, mean_ecr: 0.0455 mean_entropies: 0.4879, took: 87.5727s
2022-10-11 07:11:56,646 [INFO] 	Process 6 - batch 128299: mean_policy_losses: -108.044, mean_net_lifetime: 4044.7937, mean_mc_travel_dist: 1078.4048, mean_rewards: 344.1992, total_rewards: 3004.7306, mean_steps: 10.7000, mean_ecr: 0.0551 mean_entropies: 0.1392, took: 56.7560s
2022-10-11 07:12:14,159 [INFO] 	Process 4 - batch 92899: mean_policy_losses: 182.577, mean_net_lifetime: 9783.9416, mean_mc_travel_dist: 2855.6628, mean_rewards: 272.2026, total_rewards: 6955.5703, mean_steps: 37.1200, mean_ecr: 0.0387 mean_entropies: 0.5362, took: 168.2295s
2022-10-11 07:12:52,219 [INFO] 	Process 6 - batch 128399: mean_policy_losses: -51.009, mean_net_lifetime: 3953.2677, mean_mc_travel_dist: 1073.2777, mean_rewards: 340.1691, total_rewards: 2929.9494, mean_steps: 10.5600, mean_ecr: 0.0555 mean_entropies: 0.1439, took: 55.5727s
2022-10-11 07:12:52,431 [INFO] 	Process 3 - batch 96599: mean_policy_losses: -14.924, mean_net_lifetime: 5305.1188, mean_mc_travel_dist: 1350.2390, mean_rewards: 282.1338, total_rewards: 3977.7059, mean_steps: 17.8800, mean_ecr: 0.0453 mean_entropies: 0.4825, took: 88.4865s
2022-10-11 07:13:15,109 [INFO] 	Process 1 - batch 79799: mean_policy_losses: -73.613, mean_net_lifetime: 6522.7167, mean_mc_travel_dist: 2031.4256, mean_rewards: 241.2226, total_rewards: 4522.7858, mean_steps: 26.2600, mean_ecr: 0.0383 mean_entropies: 0.9248, took: 122.4476s
2022-10-11 07:13:37,995 [INFO] 	Process 5 - batch 81599: mean_policy_losses: -166.689, mean_net_lifetime: 10205.4796, mean_mc_travel_dist: 3178.5366, mean_rewards: 269.9459, total_rewards: 7070.7390, mean_steps: 37.9700, mean_ecr: 0.0294 mean_entropies: 0.6229, took: 173.5985s
2022-10-11 07:13:48,569 [INFO] 	Process 6 - batch 128499: mean_policy_losses: -164.138, mean_net_lifetime: 3935.2992, mean_mc_travel_dist: 1058.0438, mean_rewards: 341.7239, total_rewards: 2932.1796, mean_steps: 10.4700, mean_ecr: 0.0552 mean_entropies: 0.1457, took: 56.3502s
2022-10-11 07:14:04,147 [INFO] Process 7 - epoch 59: mean_policy_losses: -368.263, mean_net_lifetime: 4309.3549, mean_mc_travel_dist: 1553.0010, mean_entropies: 1.5245, m_net_lifetime_valid: 4699.6442, took: 2409.5206s, (151.4102 / 100 batches)

2022-10-11 07:14:23,457 [INFO] 	Process 3 - batch 96699: mean_policy_losses: 14.818, mean_net_lifetime: 5354.2812, mean_mc_travel_dist: 1377.1762, mean_rewards: 282.0894, total_rewards: 4009.5391, mean_steps: 18.0500, mean_ecr: 0.0454 mean_entropies: 0.4748, took: 91.0260s
2022-10-11 07:14:45,787 [INFO] 	Process 6 - batch 128599: mean_policy_losses: -128.047, mean_net_lifetime: 3954.0371, mean_mc_travel_dist: 1052.3774, mean_rewards: 341.9695, total_rewards: 2939.7871, mean_steps: 10.5000, mean_ecr: 0.0552 mean_entropies: 0.1443, took: 57.2180s
2022-10-11 07:15:18,654 [INFO] 	Process 1 - batch 79899: mean_policy_losses: -103.438, mean_net_lifetime: 6426.2736, mean_mc_travel_dist: 2016.5797, mean_rewards: 241.2950, total_rewards: 4432.8142, mean_steps: 25.8100, mean_ecr: 0.0383 mean_entropies: 0.9171, took: 123.5451s
2022-10-11 07:15:47,792 [INFO] 	Process 6 - batch 128699: mean_policy_losses: -29.189, mean_net_lifetime: 4259.3669, mean_mc_travel_dist: 1140.8060, mean_rewards: 345.2424, total_rewards: 3168.3621, mean_steps: 11.3200, mean_ecr: 0.0549 mean_entropies: 0.1268, took: 62.0043s
2022-10-11 07:15:50,133 [INFO] 	Process 4 - batch 92999: mean_policy_losses: 195.913, mean_net_lifetime: 11998.4972, mean_mc_travel_dist: 3736.2936, mean_rewards: 270.9726, total_rewards: 8290.8962, mean_steps: 48.3500, mean_ecr: 0.0385 mean_entropies: 0.5011, took: 215.9744s
2022-10-11 07:15:52,484 [INFO] 	Process 5 - batch 81699: mean_policy_losses: -200.603, mean_net_lifetime: 7674.4125, mean_mc_travel_dist: 2403.6793, mean_rewards: 267.5460, total_rewards: 5323.1047, mean_steps: 28.1600, mean_ecr: 0.0301 mean_entropies: 0.5896, took: 134.4879s
2022-10-11 07:15:57,475 [INFO] 	Process 7 - batch 88599: mean_policy_losses: -503.531, mean_net_lifetime: 4815.9122, mean_mc_travel_dist: 1493.1117, mean_rewards: 195.3994, total_rewards: 3355.4894, mean_steps: 24.0100, mean_ecr: 0.0407 mean_entropies: 1.2204, took: 813.1331s
2022-10-11 07:15:58,539 [INFO] 	Process 3 - batch 96799: mean_policy_losses: 28.428, mean_net_lifetime: 5400.4283, mean_mc_travel_dist: 1375.6212, mean_rewards: 278.5074, total_rewards: 4053.2380, mean_steps: 18.4700, mean_ecr: 0.0453 mean_entropies: 0.4463, took: 95.0823s
2022-10-11 07:16:42,605 [INFO] 	Process 6 - batch 128799: mean_policy_losses: -133.192, mean_net_lifetime: 3932.5648, mean_mc_travel_dist: 1053.6497, mean_rewards: 341.0498, total_rewards: 2925.0115, mean_steps: 10.4400, mean_ecr: 0.0550 mean_entropies: 0.1327, took: 54.8140s
2022-10-11 07:17:23,840 [INFO] 	Process 1 - batch 79999: mean_policy_losses: -31.631, mean_net_lifetime: 6558.7892, mean_mc_travel_dist: 2080.4784, mean_rewards: 237.0264, total_rewards: 4506.5661, mean_steps: 27.0100, mean_ecr: 0.0381 mean_entropies: 0.8983, took: 125.1859s
2022-10-11 07:17:30,879 [INFO] 	Process 3 - batch 96899: mean_policy_losses: 40.600, mean_net_lifetime: 5371.8825, mean_mc_travel_dist: 1384.4068, mean_rewards: 279.8110, total_rewards: 4018.8178, mean_steps: 18.3000, mean_ecr: 0.0454 mean_entropies: 0.4602, took: 92.3394s
2022-10-11 07:17:36,526 [INFO] 	Process 7 - batch 88699: mean_policy_losses: -414.805, mean_net_lifetime: 4614.9399, mean_mc_travel_dist: 1403.4203, mean_rewards: 206.5822, total_rewards: 3240.2440, mean_steps: 21.5600, mean_ecr: 0.0413 mean_entropies: 1.3096, took: 99.0508s
2022-10-11 07:17:39,892 [INFO] 	Process 6 - batch 128899: mean_policy_losses: -86.252, mean_net_lifetime: 4189.6499, mean_mc_travel_dist: 1115.8324, mean_rewards: 345.5812, total_rewards: 3109.4703, mean_steps: 11.1100, mean_ecr: 0.0549 mean_entropies: 0.1219, took: 57.2872s
2022-10-11 07:17:59,498 [INFO] 	Process 5 - batch 81799: mean_policy_losses: -189.999, mean_net_lifetime: 7540.8805, mean_mc_travel_dist: 2321.3467, mean_rewards: 271.8704, total_rewards: 5251.8574, mean_steps: 27.1900, mean_ecr: 0.0303 mean_entropies: 0.6278, took: 127.0139s
2022-10-11 07:18:39,248 [INFO] 	Process 6 - batch 128999: mean_policy_losses: -78.323, mean_net_lifetime: 4220.5982, mean_mc_travel_dist: 1128.3368, mean_rewards: 344.8823, total_rewards: 3134.8887, mean_steps: 11.2100, mean_ecr: 0.0550 mean_entropies: 0.1194, took: 59.3552s
2022-10-11 07:19:02,183 [INFO] 	Process 3 - batch 96999: mean_policy_losses: 32.640, mean_net_lifetime: 5296.2086, mean_mc_travel_dist: 1351.7232, mean_rewards: 269.7575, total_rewards: 3976.9724, mean_steps: 18.7200, mean_ecr: 0.0455 mean_entropies: 0.4638, took: 91.3042s
2022-10-11 07:19:14,600 [INFO] 	Process 7 - batch 88799: mean_policy_losses: -295.719, mean_net_lifetime: 4546.8617, mean_mc_travel_dist: 1322.4613, mean_rewards: 206.2201, total_rewards: 3250.8762, mean_steps: 21.6100, mean_ecr: 0.0415 mean_entropies: 1.2670, took: 98.0741s
2022-10-11 07:19:22,118 [INFO] 	Process 1 - batch 80099: mean_policy_losses: -73.085, mean_net_lifetime: 6298.6734, mean_mc_travel_dist: 1991.8716, mean_rewards: 239.4791, total_rewards: 4334.2495, mean_steps: 25.5600, mean_ecr: 0.0383 mean_entropies: 0.9158, took: 118.2783s
2022-10-11 07:19:58,627 [INFO] 	Process 5 - batch 81899: mean_policy_losses: -129.417, mean_net_lifetime: 7185.6240, mean_mc_travel_dist: 2228.5138, mean_rewards: 269.9456, total_rewards: 5004.6167, mean_steps: 26.0000, mean_ecr: 0.0303 mean_entropies: 0.6158, took: 119.1295s
2022-10-11 07:20:29,046 [INFO] 	Process 3 - batch 97099: mean_policy_losses: 45.886, mean_net_lifetime: 5353.6450, mean_mc_travel_dist: 1358.8320, mean_rewards: 284.0791, total_rewards: 4019.1292, mean_steps: 17.8900, mean_ecr: 0.0456 mean_entropies: 0.4622, took: 86.8630s
2022-10-11 07:20:44,185 [INFO] 	Process 7 - batch 88899: mean_policy_losses: -340.821, mean_net_lifetime: 4436.1886, mean_mc_travel_dist: 1291.4137, mean_rewards: 215.0682, total_rewards: 3178.3207, mean_steps: 19.9000, mean_ecr: 0.0415 mean_entropies: 1.2923, took: 89.5856s
2022-10-11 07:21:18,516 [INFO] 	Process 1 - batch 80199: mean_policy_losses: -61.371, mean_net_lifetime: 6439.4237, mean_mc_travel_dist: 2016.2501, mean_rewards: 244.3592, total_rewards: 4444.6952, mean_steps: 25.5500, mean_ecr: 0.0383 mean_entropies: 0.9110, took: 116.3968s
2022-10-11 07:21:27,839 [INFO] Process 2 - epoch 58: mean_policy_losses: -0.423, mean_net_lifetime: 5299.9821, mean_mc_travel_dist: 1689.6760, mean_entropies: 0.8342, m_net_lifetime_valid: 4744.0597, took: 2496.9064s, (154.5303 / 100 batches)

2022-10-11 07:21:55,855 [INFO] 	Process 3 - batch 97199: mean_policy_losses: -15.148, mean_net_lifetime: 5191.4649, mean_mc_travel_dist: 1322.4648, mean_rewards: 280.4242, total_rewards: 3898.0088, mean_steps: 17.5700, mean_ecr: 0.0455 mean_entropies: 0.4733, took: 86.8092s
2022-10-11 07:22:34,103 [INFO] 	Process 7 - batch 88999: mean_policy_losses: -370.669, mean_net_lifetime: 4963.6967, mean_mc_travel_dist: 1501.7603, mean_rewards: 199.2966, total_rewards: 3489.0821, mean_steps: 24.2300, mean_ecr: 0.0409 mean_entropies: 1.2975, took: 109.9170s
2022-10-11 07:22:43,947 [INFO] 	Process 5 - batch 81999: mean_policy_losses: -50.695, mean_net_lifetime: 10068.1151, mean_mc_travel_dist: 3057.1312, mean_rewards: 274.4246, total_rewards: 7050.5366, mean_steps: 36.6200, mean_ecr: 0.0297 mean_entropies: 0.6913, took: 165.3199s
2022-10-11 07:23:21,569 [INFO] 	Process 1 - batch 80299: mean_policy_losses: -123.031, mean_net_lifetime: 6640.9482, mean_mc_travel_dist: 2067.7098, mean_rewards: 241.0643, total_rewards: 4601.8683, mean_steps: 26.6600, mean_ecr: 0.0384 mean_entropies: 0.9817, took: 123.0543s
2022-10-11 07:23:24,282 [INFO] 	Process 3 - batch 97299: mean_policy_losses: -53.458, mean_net_lifetime: 5180.0826, mean_mc_travel_dist: 1318.3190, mean_rewards: 279.2971, total_rewards: 3887.1996, mean_steps: 17.5700, mean_ecr: 0.0457 mean_entropies: 0.4720, took: 88.4252s
2022-10-11 07:23:25,650 [INFO] 	Process 2 - batch 87099: mean_policy_losses: 61.892, mean_net_lifetime: 7418.5746, mean_mc_travel_dist: 2019.4036, mean_rewards: 285.1076, total_rewards: 5424.7005, mean_steps: 25.1100, mean_ecr: 0.0383 mean_entropies: 0.4711, took: 815.0373s
2022-10-11 07:24:33,828 [INFO] 	Process 7 - batch 89099: mean_policy_losses: -326.389, mean_net_lifetime: 5250.6467, mean_mc_travel_dist: 1595.5096, mean_rewards: 196.3876, total_rewards: 3685.1460, mean_steps: 26.2500, mean_ecr: 0.0405 mean_entropies: 1.1962, took: 119.7255s
2022-10-11 07:24:55,642 [INFO] 	Process 3 - batch 97399: mean_policy_losses: -28.984, mean_net_lifetime: 5364.3927, mean_mc_travel_dist: 1348.4903, mean_rewards: 282.9478, total_rewards: 4040.9875, mean_steps: 18.0100, mean_ecr: 0.0455 mean_entropies: 0.4787, took: 91.3619s
2022-10-11 07:25:23,268 [INFO] 	Process 5 - batch 82099: mean_policy_losses: -85.636, mean_net_lifetime: 9538.1337, mean_mc_travel_dist: 2950.8512, mean_rewards: 275.1456, total_rewards: 6639.4817, mean_steps: 34.3100, mean_ecr: 0.0298 mean_entropies: 0.6852, took: 159.3213s
2022-10-11 07:25:27,631 [INFO] 	Process 2 - batch 87199: mean_policy_losses: 70.020, mean_net_lifetime: 7603.7369, mean_mc_travel_dist: 2016.9636, mean_rewards: 283.4627, total_rewards: 5617.4606, mean_steps: 25.9300, mean_ecr: 0.0383 mean_entropies: 0.4443, took: 121.9807s
2022-10-11 07:25:28,333 [INFO] 	Process 1 - batch 80399: mean_policy_losses: -56.268, mean_net_lifetime: 6907.0042, mean_mc_travel_dist: 2166.3021, mean_rewards: 248.7518, total_rewards: 4769.9773, mean_steps: 26.9600, mean_ecr: 0.0379 mean_entropies: 0.9574, took: 126.7640s
2022-10-11 07:26:08,165 [INFO] Process 4 - epoch 62: mean_policy_losses: 108.535, mean_net_lifetime: 4951.2892, mean_mc_travel_dist: 1537.3670, mean_entropies: 1.0324, m_net_lifetime_valid: 4699.6917, took: 2955.3509s, (144.9573 / 100 batches)

2022-10-11 07:26:27,310 [INFO] 	Process 3 - batch 97499: mean_policy_losses: -73.855, mean_net_lifetime: 5248.2373, mean_mc_travel_dist: 1354.9431, mean_rewards: 276.1399, total_rewards: 3926.4559, mean_steps: 18.0400, mean_ecr: 0.0451 mean_entropies: 0.4837, took: 91.6672s
2022-10-11 07:26:40,567 [INFO] 	Process 7 - batch 89199: mean_policy_losses: -263.916, mean_net_lifetime: 5472.5678, mean_mc_travel_dist: 1660.7167, mean_rewards: 194.6149, total_rewards: 3841.8498, mean_steps: 27.7400, mean_ecr: 0.0405 mean_entropies: 1.2167, took: 126.7390s
2022-10-11 07:27:31,386 [INFO] 	Process 2 - batch 87299: mean_policy_losses: 48.819, mean_net_lifetime: 7715.2725, mean_mc_travel_dist: 2074.5083, mean_rewards: 283.1770, total_rewards: 5680.4852, mean_steps: 26.3100, mean_ecr: 0.0381 mean_entropies: 0.4331, took: 123.7562s
2022-10-11 07:27:32,480 [INFO] 	Process 1 - batch 80499: mean_policy_losses: -100.142, mean_net_lifetime: 6775.9879, mean_mc_travel_dist: 2108.5681, mean_rewards: 248.5776, total_rewards: 4689.8928, mean_steps: 26.4400, mean_ecr: 0.0382 mean_entropies: 0.9595, took: 124.1472s
2022-10-11 07:28:06,672 [INFO] 	Process 4 - batch 93099: mean_policy_losses: 150.668, mean_net_lifetime: 6797.2666, mean_mc_travel_dist: 1895.7995, mean_rewards: 270.8770, total_rewards: 4928.6890, mean_steps: 25.0800, mean_ecr: 0.0428 mean_entropies: 0.5072, took: 736.5390s
2022-10-11 07:28:08,857 [INFO] 	Process 5 - batch 82199: mean_policy_losses: -93.011, mean_net_lifetime: 9864.5234, mean_mc_travel_dist: 3071.5117, mean_rewards: 274.0547, total_rewards: 6837.3327, mean_steps: 35.7300, mean_ecr: 0.0297 mean_entropies: 0.6540, took: 165.5889s
2022-10-11 07:28:35,051 [INFO] 	Process 7 - batch 89299: mean_policy_losses: -466.080, mean_net_lifetime: 4995.1527, mean_mc_travel_dist: 1509.3208, mean_rewards: 195.6795, total_rewards: 3521.5906, mean_steps: 25.0800, mean_ecr: 0.0407 mean_entropies: 1.2094, took: 114.4839s
2022-10-11 07:29:31,942 [INFO] Process 6 - epoch 86: mean_policy_losses: -185.485, mean_net_lifetime: 3261.2882, mean_mc_travel_dist: 989.1478, mean_entropies: 0.4943, m_net_lifetime_valid: 4293.9040, took: 1495.6001s, (104.6661 / 100 batches)

2022-10-11 07:29:32,494 [INFO] 	Process 1 - batch 80599: mean_policy_losses: -98.323, mean_net_lifetime: 6542.6788, mean_mc_travel_dist: 2034.7590, mean_rewards: 245.2341, total_rewards: 4540.4912, mean_steps: 25.9700, mean_ecr: 0.0383 mean_entropies: 0.9460, took: 120.0139s
2022-10-11 07:29:34,715 [INFO] 	Process 2 - batch 87399: mean_policy_losses: 28.096, mean_net_lifetime: 7633.7596, mean_mc_travel_dist: 2048.2931, mean_rewards: 282.5079, total_rewards: 5607.5313, mean_steps: 26.1400, mean_ecr: 0.0381 mean_entropies: 0.4143, took: 123.3286s
2022-10-11 07:30:31,387 [INFO] 	Process 6 - batch 129099: mean_policy_losses: -82.465, mean_net_lifetime: 4046.7548, mean_mc_travel_dist: 1071.7043, mean_rewards: 345.2694, total_rewards: 3006.1284, mean_steps: 10.7000, mean_ecr: 0.0552 mean_entropies: 0.1475, took: 712.1391s
2022-10-11 07:30:34,027 [INFO] 	Process 4 - batch 93199: mean_policy_losses: 182.643, mean_net_lifetime: 8430.5693, mean_mc_travel_dist: 2405.8459, mean_rewards: 268.7692, total_rewards: 6051.2450, mean_steps: 31.5500, mean_ecr: 0.0395 mean_entropies: 0.5132, took: 147.3549s
2022-10-11 07:30:41,911 [INFO] 	Process 7 - batch 89399: mean_policy_losses: -376.045, mean_net_lifetime: 5465.3470, mean_mc_travel_dist: 1639.5538, mean_rewards: 195.6799, total_rewards: 3853.2836, mean_steps: 27.4500, mean_ecr: 0.0404 mean_entropies: 1.1968, took: 126.8600s
2022-10-11 07:31:01,231 [INFO] 	Process 5 - batch 82299: mean_policy_losses: -101.237, mean_net_lifetime: 9709.3429, mean_mc_travel_dist: 2968.4500, mean_rewards: 267.2589, total_rewards: 6773.3540, mean_steps: 36.0600, mean_ecr: 0.0297 mean_entropies: 0.6423, took: 172.3741s
2022-10-11 07:31:30,631 [INFO] 	Process 6 - batch 129199: mean_policy_losses: -63.812, mean_net_lifetime: 4035.1450, mean_mc_travel_dist: 1081.8409, mean_rewards: 343.0770, total_rewards: 2990.6666, mean_steps: 10.7200, mean_ecr: 0.0550 mean_entropies: 0.1573, took: 59.2445s
2022-10-11 07:31:39,384 [INFO] 	Process 1 - batch 80699: mean_policy_losses: -58.035, mean_net_lifetime: 6429.4206, mean_mc_travel_dist: 2012.7075, mean_rewards: 240.9471, total_rewards: 4438.4000, mean_steps: 26.0300, mean_ecr: 0.0383 mean_entropies: 0.8993, took: 126.8904s
2022-10-11 07:31:39,870 [INFO] 	Process 2 - batch 87499: mean_policy_losses: 24.549, mean_net_lifetime: 7455.1263, mean_mc_travel_dist: 1974.0035, mean_rewards: 281.0441, total_rewards: 5509.5988, mean_steps: 25.6000, mean_ecr: 0.0384 mean_entropies: 0.3713, took: 125.1549s
2022-10-11 07:32:27,527 [INFO] 	Process 6 - batch 129299: mean_policy_losses: -103.990, mean_net_lifetime: 3956.6066, mean_mc_travel_dist: 1056.5722, mean_rewards: 342.1176, total_rewards: 2944.4740, mean_steps: 10.5100, mean_ecr: 0.0551 mean_entropies: 0.1656, took: 56.8952s
2022-10-11 07:32:51,409 [INFO] 	Process 7 - batch 89499: mean_policy_losses: -292.461, mean_net_lifetime: 5464.2302, mean_mc_travel_dist: 1641.2681, mean_rewards: 195.7550, total_rewards: 3859.4963, mean_steps: 27.3100, mean_ecr: 0.0404 mean_entropies: 1.2349, took: 129.4981s
2022-10-11 07:33:22,839 [INFO] 	Process 6 - batch 129399: mean_policy_losses: -117.838, mean_net_lifetime: 3819.9177, mean_mc_travel_dist: 1022.6376, mean_rewards: 341.0515, total_rewards: 2829.8693, mean_steps: 10.1500, mean_ecr: 0.0555 mean_entropies: 0.1597, took: 55.3121s
2022-10-11 07:33:23,836 [INFO] 	Process 4 - batch 93299: mean_policy_losses: 173.672, mean_net_lifetime: 9252.5962, mean_mc_travel_dist: 2696.0141, mean_rewards: 266.5831, total_rewards: 6579.0274, mean_steps: 36.1700, mean_ecr: 0.0388 mean_entropies: 0.5010, took: 169.8076s
2022-10-11 07:33:43,399 [INFO] 	Process 1 - batch 80799: mean_policy_losses: -32.793, mean_net_lifetime: 6580.7669, mean_mc_travel_dist: 2042.3012, mean_rewards: 246.6402, total_rewards: 4572.5603, mean_steps: 25.8700, mean_ecr: 0.0383 mean_entropies: 0.9282, took: 124.0140s
2022-10-11 07:33:48,044 [INFO] 	Process 2 - batch 87599: mean_policy_losses: 38.226, mean_net_lifetime: 7691.8052, mean_mc_travel_dist: 2069.5893, mean_rewards: 281.6494, total_rewards: 5646.4073, mean_steps: 26.4100, mean_ecr: 0.0380 mean_entropies: 0.3826, took: 128.1741s
2022-10-11 07:34:15,515 [INFO] 	Process 5 - batch 82399: mean_policy_losses: -101.063, mean_net_lifetime: 10632.4703, mean_mc_travel_dist: 3401.2604, mean_rewards: 260.3955, total_rewards: 7279.6428, mean_steps: 41.0500, mean_ecr: 0.0292 mean_entropies: 0.6506, took: 194.2840s
2022-10-11 07:34:20,311 [INFO] 	Process 6 - batch 129499: mean_policy_losses: -55.840, mean_net_lifetime: 4007.7291, mean_mc_travel_dist: 1075.6810, mean_rewards: 342.1412, total_rewards: 2984.1114, mean_steps: 10.6800, mean_ecr: 0.0553 mean_entropies: 0.1493, took: 57.4726s
2022-10-11 07:34:58,508 [INFO] 	Process 7 - batch 89599: mean_policy_losses: -334.459, mean_net_lifetime: 5417.2195, mean_mc_travel_dist: 1617.4072, mean_rewards: 198.3976, total_rewards: 3830.5996, mean_steps: 26.7500, mean_ecr: 0.0403 mean_entropies: 1.1907, took: 127.0987s
2022-10-11 07:35:15,000 [INFO] 	Process 6 - batch 129599: mean_policy_losses: -77.668, mean_net_lifetime: 3780.8224, mean_mc_travel_dist: 1023.4814, mean_rewards: 341.9832, total_rewards: 2808.1171, mean_steps: 10.0400, mean_ecr: 0.0555 mean_entropies: 0.1714, took: 54.6886s
2022-10-11 07:35:30,458 [INFO] 	Process 4 - batch 93399: mean_policy_losses: 114.869, mean_net_lifetime: 7120.5440, mean_mc_travel_dist: 1951.5064, mean_rewards: 274.2728, total_rewards: 5193.1261, mean_steps: 26.1000, mean_ecr: 0.0423 mean_entropies: 0.4884, took: 126.6230s
2022-10-11 07:35:46,851 [INFO] 	Process 1 - batch 80899: mean_policy_losses: -16.560, mean_net_lifetime: 6634.3523, mean_mc_travel_dist: 2096.4002, mean_rewards: 250.0395, total_rewards: 4557.4464, mean_steps: 25.7400, mean_ecr: 0.0381 mean_entropies: 0.9073, took: 123.4526s
2022-10-11 07:35:55,007 [INFO] 	Process 2 - batch 87699: mean_policy_losses: 45.980, mean_net_lifetime: 7665.7587, mean_mc_travel_dist: 2072.2559, mean_rewards: 281.2315, total_rewards: 5629.6180, mean_steps: 26.3400, mean_ecr: 0.0380 mean_entropies: 0.4109, took: 126.9627s
2022-10-11 07:36:11,851 [INFO] 	Process 6 - batch 129699: mean_policy_losses: -104.411, mean_net_lifetime: 3883.8415, mean_mc_travel_dist: 1053.7210, mean_rewards: 341.8044, total_rewards: 2884.5091, mean_steps: 10.3300, mean_ecr: 0.0553 mean_entropies: 0.1698, took: 56.8511s
2022-10-11 07:36:57,146 [INFO] 	Process 7 - batch 89699: mean_policy_losses: -434.419, mean_net_lifetime: 4982.2882, mean_mc_travel_dist: 1530.2053, mean_rewards: 192.9413, total_rewards: 3485.3819, mean_steps: 25.1900, mean_ecr: 0.0407 mean_entropies: 1.2184, took: 118.6376s
2022-10-11 07:37:05,210 [INFO] 	Process 5 - batch 82499: mean_policy_losses: -153.650, mean_net_lifetime: 9352.8380, mean_mc_travel_dist: 2942.1491, mean_rewards: 261.2600, total_rewards: 6456.5487, mean_steps: 35.4700, mean_ecr: 0.0295 mean_entropies: 0.6832, took: 169.6959s
2022-10-11 07:37:09,580 [INFO] 	Process 6 - batch 129799: mean_policy_losses: -60.927, mean_net_lifetime: 4015.7086, mean_mc_travel_dist: 1092.0673, mean_rewards: 343.5911, total_rewards: 2978.5729, mean_steps: 10.6700, mean_ecr: 0.0551 mean_entropies: 0.1661, took: 57.7287s
2022-10-11 07:37:27,075 [INFO] Process 3 - epoch 65: mean_policy_losses: 45.589, mean_net_lifetime: 4487.8411, mean_mc_travel_dist: 1340.4357, mean_entropies: 0.7960, m_net_lifetime_valid: 4494.1775, took: 2008.1776s, (138.9261 / 100 batches)

2022-10-11 07:37:42,792 [INFO] 	Process 4 - batch 93499: mean_policy_losses: 130.079, mean_net_lifetime: 7637.2111, mean_mc_travel_dist: 2114.7188, mean_rewards: 281.9881, total_rewards: 5550.6565, mean_steps: 27.6200, mean_ecr: 0.0423 mean_entropies: 0.4664, took: 132.3337s
2022-10-11 07:37:45,906 [INFO] 	Process 1 - batch 80999: mean_policy_losses: -17.589, mean_net_lifetime: 6613.9758, mean_mc_travel_dist: 2068.4201, mean_rewards: 254.6972, total_rewards: 4580.6298, mean_steps: 25.0900, mean_ecr: 0.0381 mean_entropies: 0.9262, took: 119.0551s
2022-10-11 07:38:01,980 [INFO] 	Process 2 - batch 87799: mean_policy_losses: 43.081, mean_net_lifetime: 7758.4267, mean_mc_travel_dist: 2074.7082, mean_rewards: 281.3436, total_rewards: 5711.7602, mean_steps: 26.6500, mean_ecr: 0.0379 mean_entropies: 0.4125, took: 126.9731s
2022-10-11 07:38:05,614 [INFO] 	Process 6 - batch 129899: mean_policy_losses: -106.087, mean_net_lifetime: 3940.1580, mean_mc_travel_dist: 1066.3045, mean_rewards: 342.5762, total_rewards: 2924.5815, mean_steps: 10.4700, mean_ecr: 0.0552 mean_entropies: 0.1678, took: 56.0343s
2022-10-11 07:38:41,697 [INFO] 	Process 7 - batch 89799: mean_policy_losses: -461.696, mean_net_lifetime: 4813.7887, mean_mc_travel_dist: 1479.0004, mean_rewards: 207.7836, total_rewards: 3370.1952, mean_steps: 22.5700, mean_ecr: 0.0409 mean_entropies: 1.2008, took: 104.5509s
2022-10-11 07:38:55,291 [INFO] 	Process 3 - batch 97599: mean_policy_losses: -38.160, mean_net_lifetime: 5170.5818, mean_mc_travel_dist: 1283.0065, mean_rewards: 278.5612, total_rewards: 3915.0232, mean_steps: 17.6700, mean_ecr: 0.0461 mean_entropies: 0.4656, took: 747.9815s
2022-10-11 07:39:01,749 [INFO] 	Process 6 - batch 129999: mean_policy_losses: -119.986, mean_net_lifetime: 3948.1100, mean_mc_travel_dist: 1067.6203, mean_rewards: 342.6969, total_rewards: 2943.8037, mean_steps: 10.4800, mean_ecr: 0.0551 mean_entropies: 0.1549, took: 56.1351s
2022-10-11 07:39:58,830 [INFO] 	Process 6 - batch 130099: mean_policy_losses: -72.569, mean_net_lifetime: 3971.5981, mean_mc_travel_dist: 1068.9512, mean_rewards: 339.7804, total_rewards: 2959.6450, mean_steps: 10.6100, mean_ecr: 0.0553 mean_entropies: 0.1532, took: 57.0809s
2022-10-11 07:40:02,511 [INFO] 	Process 2 - batch 87899: mean_policy_losses: 14.760, mean_net_lifetime: 7570.0799, mean_mc_travel_dist: 2013.1851, mean_rewards: 283.3357, total_rewards: 5576.4748, mean_steps: 25.8200, mean_ecr: 0.0382 mean_entropies: 0.3922, took: 120.5314s
2022-10-11 07:40:27,657 [INFO] 	Process 3 - batch 97699: mean_policy_losses: -39.195, mean_net_lifetime: 5256.1394, mean_mc_travel_dist: 1330.5734, mean_rewards: 266.6989, total_rewards: 3963.9423, mean_steps: 18.9200, mean_ecr: 0.0457 mean_entropies: 0.4725, took: 92.3658s
2022-10-11 07:40:34,798 [INFO] 	Process 7 - batch 89899: mean_policy_losses: -306.682, mean_net_lifetime: 5187.9586, mean_mc_travel_dist: 1561.5265, mean_rewards: 206.9038, total_rewards: 3662.5291, mean_steps: 24.5700, mean_ecr: 0.0407 mean_entropies: 1.2050, took: 113.1017s
2022-10-11 07:40:55,631 [INFO] 	Process 6 - batch 130199: mean_policy_losses: -87.025, mean_net_lifetime: 4004.7666, mean_mc_travel_dist: 1077.8218, mean_rewards: 342.6677, total_rewards: 2970.5120, mean_steps: 10.6600, mean_ecr: 0.0552 mean_entropies: 0.1545, took: 56.8009s
2022-10-11 07:41:52,169 [INFO] 	Process 6 - batch 130299: mean_policy_losses: -71.005, mean_net_lifetime: 4045.2442, mean_mc_travel_dist: 1095.7239, mean_rewards: 341.3873, total_rewards: 3004.6165, mean_steps: 10.8100, mean_ecr: 0.0552 mean_entropies: 0.1518, took: 56.5384s
2022-10-11 07:41:57,456 [INFO] 	Process 3 - batch 97799: mean_policy_losses: -52.488, mean_net_lifetime: 5232.2969, mean_mc_travel_dist: 1305.2578, mean_rewards: 271.4295, total_rewards: 3955.9379, mean_steps: 18.3800, mean_ecr: 0.0459 mean_entropies: 0.4579, took: 89.7980s
2022-10-11 07:42:02,388 [INFO] 	Process 4 - batch 93599: mean_policy_losses: 177.127, mean_net_lifetime: 14135.2599, mean_mc_travel_dist: 4504.1864, mean_rewards: 268.1076, total_rewards: 9665.6233, mean_steps: 59.7500, mean_ecr: 0.0382 mean_entropies: 0.4894, took: 259.5963s
2022-10-11 07:42:04,827 [INFO] 	Process 2 - batch 87999: mean_policy_losses: 24.776, mean_net_lifetime: 7593.7844, mean_mc_travel_dist: 2032.3165, mean_rewards: 279.6167, total_rewards: 5585.0057, mean_steps: 26.2500, mean_ecr: 0.0381 mean_entropies: 0.3876, took: 122.3161s
2022-10-11 07:42:29,310 [INFO] 	Process 7 - batch 89999: mean_policy_losses: -331.603, mean_net_lifetime: 5264.0777, mean_mc_travel_dist: 1592.1829, mean_rewards: 203.3897, total_rewards: 3714.1726, mean_steps: 25.2100, mean_ecr: 0.0404 mean_entropies: 1.2141, took: 114.5119s
2022-10-11 07:42:44,504 [INFO] 	Process 6 - batch 130399: mean_policy_losses: -91.116, mean_net_lifetime: 3785.6631, mean_mc_travel_dist: 1028.3686, mean_rewards: 340.5010, total_rewards: 2822.5479, mean_steps: 10.0900, mean_ecr: 0.0552 mean_entropies: 0.1642, took: 52.3349s
2022-10-11 07:43:24,848 [INFO] 	Process 3 - batch 97899: mean_policy_losses: -37.926, mean_net_lifetime: 5262.9972, mean_mc_travel_dist: 1318.2204, mean_rewards: 280.7717, total_rewards: 3975.2615, mean_steps: 17.8300, mean_ecr: 0.0459 mean_entropies: 0.4551, took: 87.3927s
2022-10-11 07:43:35,897 [INFO] 	Process 6 - batch 130499: mean_policy_losses: -112.678, mean_net_lifetime: 3839.6945, mean_mc_travel_dist: 1048.8345, mean_rewards: 341.6827, total_rewards: 2854.4670, mean_steps: 10.2000, mean_ecr: 0.0554 mean_entropies: 0.1541, took: 51.3926s
2022-10-11 07:44:03,453 [INFO] 	Process 2 - batch 88099: mean_policy_losses: 19.178, mean_net_lifetime: 7699.7692, mean_mc_travel_dist: 2031.7466, mean_rewards: 278.9745, total_rewards: 5692.1246, mean_steps: 26.6900, mean_ecr: 0.0380 mean_entropies: 0.4091, took: 118.6257s
2022-10-11 07:44:45,059 [INFO] 	Process 3 - batch 97999: mean_policy_losses: -79.460, mean_net_lifetime: 5203.0322, mean_mc_travel_dist: 1285.5227, mean_rewards: 278.2867, total_rewards: 3941.1786, mean_steps: 17.7600, mean_ecr: 0.0464 mean_entropies: 0.4719, took: 80.2112s
2022-10-11 07:44:52,084 [INFO] 	Process 4 - batch 93699: mean_policy_losses: 100.441, mean_net_lifetime: 10328.3146, mean_mc_travel_dist: 3084.5906, mean_rewards: 278.7187, total_rewards: 7278.9245, mean_steps: 39.9900, mean_ecr: 0.0397 mean_entropies: 0.4871, took: 169.6961s
2022-10-11 07:45:55,084 [INFO] 	Process 2 - batch 88199: mean_policy_losses: -15.541, mean_net_lifetime: 7548.1205, mean_mc_travel_dist: 1996.3635, mean_rewards: 280.9133, total_rewards: 5580.6920, mean_steps: 25.9500, mean_ecr: 0.0383 mean_entropies: 0.3955, took: 111.6309s
2022-10-11 07:46:09,384 [INFO] 	Process 3 - batch 98099: mean_policy_losses: -77.853, mean_net_lifetime: 5315.7503, mean_mc_travel_dist: 1328.9474, mean_rewards: 283.0319, total_rewards: 4015.2632, mean_steps: 17.8200, mean_ecr: 0.0459 mean_entropies: 0.4569, took: 84.3251s
2022-10-11 07:47:30,888 [INFO] 	Process 3 - batch 98199: mean_policy_losses: -75.646, mean_net_lifetime: 5298.1714, mean_mc_travel_dist: 1341.0221, mean_rewards: 286.6368, total_rewards: 3987.8697, mean_steps: 17.5200, mean_ecr: 0.0459 mean_entropies: 0.4626, took: 81.5036s
2022-10-11 07:47:43,256 [INFO] Process 1 - epoch 54: mean_policy_losses: 16.035, mean_net_lifetime: 5427.6492, mean_mc_travel_dist: 2042.3993, mean_entropies: 1.1385, m_net_lifetime_valid: 4469.3062, took: 2434.2326s, (168.0285 / 100 batches)

2022-10-11 07:47:49,288 [INFO] 	Process 2 - batch 88299: mean_policy_losses: -6.643, mean_net_lifetime: 7723.8657, mean_mc_travel_dist: 2031.9810, mean_rewards: 283.0283, total_rewards: 5712.2258, mean_steps: 26.4000, mean_ecr: 0.0381 mean_entropies: 0.4031, took: 114.2041s
2022-10-11 07:47:57,655 [INFO] Process 5 - epoch 55: mean_policy_losses: -191.087, mean_net_lifetime: 5815.8929, mean_mc_travel_dist: 2157.7671, mean_entropies: 1.0982, m_net_lifetime_valid: 4877.7141, took: 3012.9274s, (164.9278 / 100 batches)

2022-10-11 07:48:57,865 [INFO] 	Process 3 - batch 98299: mean_policy_losses: -58.813, mean_net_lifetime: 5250.8886, mean_mc_travel_dist: 1345.4777, mean_rewards: 277.5876, total_rewards: 3935.4468, mean_steps: 17.9900, mean_ecr: 0.0457 mean_entropies: 0.4520, took: 86.9776s
2022-10-11 07:49:37,837 [INFO] 	Process 1 - batch 81099: mean_policy_losses: -80.768, mean_net_lifetime: 6326.6741, mean_mc_travel_dist: 2008.4249, mean_rewards: 246.1770, total_rewards: 4341.0961, mean_steps: 24.8200, mean_ecr: 0.0384 mean_entropies: 0.8694, took: 711.9307s
2022-10-11 07:49:50,655 [INFO] 	Process 4 - batch 93799: mean_policy_losses: 96.534, mean_net_lifetime: 16909.0895, mean_mc_travel_dist: 5603.7911, mean_rewards: 271.1131, total_rewards: 11337.5519, mean_steps: 72.8900, mean_ecr: 0.0383 mean_entropies: 0.4815, took: 298.5709s
2022-10-11 07:49:51,733 [INFO] 	Process 2 - batch 88399: mean_policy_losses: 10.287, mean_net_lifetime: 7600.4576, mean_mc_travel_dist: 1992.6290, mean_rewards: 280.9605, total_rewards: 5640.0340, mean_steps: 26.1500, mean_ecr: 0.0383 mean_entropies: 0.3568, took: 122.4447s
2022-10-11 07:50:26,252 [INFO] 	Process 3 - batch 98399: mean_policy_losses: -41.311, mean_net_lifetime: 5377.7476, mean_mc_travel_dist: 1355.8598, mean_rewards: 285.8775, total_rewards: 4046.5272, mean_steps: 17.8600, mean_ecr: 0.0456 mean_entropies: 0.4559, took: 88.3868s
2022-10-11 07:51:37,654 [INFO] 	Process 5 - batch 82599: mean_policy_losses: -152.638, mean_net_lifetime: 12314.7003, mean_mc_travel_dist: 3990.0717, mean_rewards: 262.9182, total_rewards: 8363.1674, mean_steps: 47.7600, mean_ecr: 0.0286 mean_entropies: 0.6293, took: 872.4426s
2022-10-11 07:51:39,880 [INFO] 	Process 1 - batch 81199: mean_policy_losses: -88.228, mean_net_lifetime: 6539.5866, mean_mc_travel_dist: 2056.9786, mean_rewards: 244.9554, total_rewards: 4515.9185, mean_steps: 25.8800, mean_ecr: 0.0382 mean_entropies: 0.9310, took: 122.0434s
2022-10-11 07:51:51,056 [INFO] 	Process 2 - batch 88499: mean_policy_losses: -17.001, mean_net_lifetime: 7566.0883, mean_mc_travel_dist: 2000.8392, mean_rewards: 288.8282, total_rewards: 5593.4387, mean_steps: 25.3000, mean_ecr: 0.0383 mean_entropies: 0.4014, took: 119.3229s
2022-10-11 07:51:57,670 [INFO] 	Process 3 - batch 98499: mean_policy_losses: -49.913, mean_net_lifetime: 5397.3096, mean_mc_travel_dist: 1384.5254, mean_rewards: 281.9338, total_rewards: 4046.8268, mean_steps: 18.1500, mean_ecr: 0.0455 mean_entropies: 0.4833, took: 91.4180s
2022-10-11 07:53:24,593 [INFO] 	Process 3 - batch 98599: mean_policy_losses: -26.594, mean_net_lifetime: 5333.2635, mean_mc_travel_dist: 1346.8282, mean_rewards: 283.9172, total_rewards: 4011.6749, mean_steps: 17.8400, mean_ecr: 0.0455 mean_entropies: 0.4615, took: 86.9226s
2022-10-11 07:53:34,016 [INFO] 	Process 1 - batch 81299: mean_policy_losses: -56.163, mean_net_lifetime: 6288.5156, mean_mc_travel_dist: 1975.9846, mean_rewards: 243.5506, total_rewards: 4336.0029, mean_steps: 25.1100, mean_ecr: 0.0384 mean_entropies: 0.9087, took: 114.1347s
2022-10-11 07:53:53,912 [INFO] Process 7 - epoch 60: mean_policy_losses: -368.258, mean_net_lifetime: 4321.6333, mean_mc_travel_dist: 1552.4942, mean_entropies: 1.5196, m_net_lifetime_valid: 4626.6990, took: 2389.7629s, (151.5588 / 100 batches)

2022-10-11 07:54:10,525 [INFO] 	Process 4 - batch 93899: mean_policy_losses: 132.428, mean_net_lifetime: 14576.7439, mean_mc_travel_dist: 4737.4268, mean_rewards: 267.6362, total_rewards: 9870.1443, mean_steps: 61.2000, mean_ecr: 0.0382 mean_entropies: 0.4942, took: 259.8697s
2022-10-11 07:54:18,453 [INFO] Process 6 - epoch 87: mean_policy_losses: -184.370, mean_net_lifetime: 3269.0755, mean_mc_travel_dist: 989.9862, mean_entropies: 0.4904, m_net_lifetime_valid: 4769.3369, took: 1486.5080s, (104.6100 / 100 batches)

2022-10-11 07:54:55,903 [INFO] 	Process 3 - batch 98699: mean_policy_losses: 0.907, mean_net_lifetime: 5318.6519, mean_mc_travel_dist: 1356.4345, mean_rewards: 283.4144, total_rewards: 3990.0445, mean_steps: 17.7900, mean_ecr: 0.0456 mean_entropies: 0.4715, took: 91.3106s
2022-10-11 07:54:56,434 [INFO] 	Process 5 - batch 82699: mean_policy_losses: -142.619, mean_net_lifetime: 11645.3632, mean_mc_travel_dist: 3725.2131, mean_rewards: 266.8324, total_rewards: 7958.7221, mean_steps: 44.3300, mean_ecr: 0.0289 mean_entropies: 0.6524, took: 198.7800s
2022-10-11 07:55:14,717 [INFO] 	Process 6 - batch 130599: mean_policy_losses: -78.990, mean_net_lifetime: 3838.3413, mean_mc_travel_dist: 1034.6215, mean_rewards: 342.2949, total_rewards: 2875.9587, mean_steps: 10.1900, mean_ecr: 0.0552 mean_entropies: 0.1714, took: 698.8203s
2022-10-11 07:55:31,374 [INFO] 	Process 7 - batch 90099: mean_policy_losses: -470.515, mean_net_lifetime: 4607.1450, mean_mc_travel_dist: 1422.7743, mean_rewards: 217.3304, total_rewards: 3222.1155, mean_steps: 20.2700, mean_ecr: 0.0409 mean_entropies: 1.2649, took: 782.0636s
2022-10-11 07:55:37,619 [INFO] 	Process 1 - batch 81399: mean_policy_losses: 6.104, mean_net_lifetime: 6580.7859, mean_mc_travel_dist: 2084.3888, mean_rewards: 246.1336, total_rewards: 4526.4803, mean_steps: 26.0300, mean_ecr: 0.0382 mean_entropies: 0.9096, took: 123.6042s
2022-10-11 07:56:13,411 [INFO] 	Process 6 - batch 130699: mean_policy_losses: -81.604, mean_net_lifetime: 4123.7018, mean_mc_travel_dist: 1104.4684, mean_rewards: 344.8909, total_rewards: 3073.0615, mean_steps: 10.9400, mean_ecr: 0.0550 mean_entropies: 0.1358, took: 58.6943s
2022-10-11 07:56:29,797 [INFO] 	Process 3 - batch 98799: mean_policy_losses: -7.336, mean_net_lifetime: 5434.3786, mean_mc_travel_dist: 1396.9246, mean_rewards: 284.0264, total_rewards: 4064.9571, mean_steps: 18.1900, mean_ecr: 0.0455 mean_entropies: 0.4644, took: 93.8939s
2022-10-11 07:57:11,003 [INFO] 	Process 6 - batch 130799: mean_policy_losses: -91.847, mean_net_lifetime: 3971.5051, mean_mc_travel_dist: 1074.3636, mean_rewards: 342.2594, total_rewards: 2964.2938, mean_steps: 10.5600, mean_ecr: 0.0551 mean_entropies: 0.1377, took: 57.5922s
2022-10-11 07:57:17,117 [INFO] 	Process 7 - batch 90199: mean_policy_losses: -426.022, mean_net_lifetime: 4728.8459, mean_mc_travel_dist: 1443.7401, mean_rewards: 209.2035, total_rewards: 3313.8435, mean_steps: 22.0300, mean_ecr: 0.0410 mean_entropies: 1.3215, took: 105.7432s
2022-10-11 07:57:42,661 [INFO] 	Process 1 - batch 81499: mean_policy_losses: -49.835, mean_net_lifetime: 6298.1939, mean_mc_travel_dist: 1987.7163, mean_rewards: 240.0259, total_rewards: 4343.0950, mean_steps: 25.4900, mean_ecr: 0.0384 mean_entropies: 0.9129, took: 125.0424s
2022-10-11 07:57:49,919 [INFO] 	Process 5 - batch 82799: mean_policy_losses: -183.748, mean_net_lifetime: 9713.9250, mean_mc_travel_dist: 3079.2923, mean_rewards: 270.2389, total_rewards: 6686.5575, mean_steps: 35.9100, mean_ecr: 0.0292 mean_entropies: 0.6582, took: 173.4853s
2022-10-11 07:58:07,892 [INFO] 	Process 3 - batch 98899: mean_policy_losses: -7.060, mean_net_lifetime: 5421.0502, mean_mc_travel_dist: 1400.3997, mean_rewards: 274.2624, total_rewards: 4050.5821, mean_steps: 18.8400, mean_ecr: 0.0455 mean_entropies: 0.4629, took: 98.0953s
2022-10-11 07:58:11,001 [INFO] 	Process 6 - batch 130899: mean_policy_losses: -58.333, mean_net_lifetime: 4143.4728, mean_mc_travel_dist: 1121.8125, mean_rewards: 343.9444, total_rewards: 3091.4544, mean_steps: 11.0200, mean_ecr: 0.0549 mean_entropies: 0.1185, took: 59.9977s
2022-10-11 07:59:02,140 [INFO] 	Process 4 - batch 93999: mean_policy_losses: 187.335, mean_net_lifetime: 14881.7644, mean_mc_travel_dist: 4981.4857, mean_rewards: 264.3304, total_rewards: 9928.9139, mean_steps: 64.4200, mean_ecr: 0.0377 mean_entropies: 0.4891, took: 291.6154s
2022-10-11 07:59:10,858 [INFO] 	Process 6 - batch 130999: mean_policy_losses: -40.858, mean_net_lifetime: 4210.4504, mean_mc_travel_dist: 1141.5647, mean_rewards: 343.0341, total_rewards: 3146.1689, mean_steps: 11.2300, mean_ecr: 0.0547 mean_entropies: 0.1221, took: 59.8576s
2022-10-11 07:59:22,799 [INFO] 	Process 7 - batch 90299: mean_policy_losses: -251.587, mean_net_lifetime: 5325.1361, mean_mc_travel_dist: 1622.6940, mean_rewards: 198.7249, total_rewards: 3731.0942, mean_steps: 26.2700, mean_ecr: 0.0404 mean_entropies: 1.2727, took: 125.6812s
2022-10-11 07:59:40,798 [INFO] 	Process 3 - batch 98999: mean_policy_losses: -28.044, mean_net_lifetime: 5293.8632, mean_mc_travel_dist: 1384.0992, mean_rewards: 277.5013, total_rewards: 3941.5983, mean_steps: 18.1200, mean_ecr: 0.0454 mean_entropies: 0.4672, took: 92.9062s
2022-10-11 07:59:46,524 [INFO] 	Process 1 - batch 81599: mean_policy_losses: -34.412, mean_net_lifetime: 6312.6157, mean_mc_travel_dist: 1996.2428, mean_rewards: 241.1086, total_rewards: 4350.4768, mean_steps: 25.4000, mean_ecr: 0.0384 mean_entropies: 0.8665, took: 123.8625s
2022-10-11 08:00:12,343 [INFO] 	Process 6 - batch 131099: mean_policy_losses: -38.224, mean_net_lifetime: 4217.3192, mean_mc_travel_dist: 1156.5150, mean_rewards: 342.3719, total_rewards: 3154.8837, mean_steps: 11.3000, mean_ecr: 0.0549 mean_entropies: 0.1287, took: 61.4845s
2022-10-11 08:00:29,307 [INFO] 	Process 5 - batch 82899: mean_policy_losses: -183.474, mean_net_lifetime: 9257.9265, mean_mc_travel_dist: 2900.4054, mean_rewards: 274.7988, total_rewards: 6402.2749, mean_steps: 33.5400, mean_ecr: 0.0297 mean_entropies: 0.6252, took: 159.3881s
2022-10-11 08:01:09,004 [INFO] 	Process 6 - batch 131199: mean_policy_losses: -82.993, mean_net_lifetime: 4060.5882, mean_mc_travel_dist: 1091.4555, mean_rewards: 341.4131, total_rewards: 3022.9347, mean_steps: 10.8100, mean_ecr: 0.0551 mean_entropies: 0.1277, took: 56.6612s
2022-10-11 08:01:30,896 [INFO] 	Process 7 - batch 90399: mean_policy_losses: -263.971, mean_net_lifetime: 5472.7243, mean_mc_travel_dist: 1649.0410, mean_rewards: 197.7577, total_rewards: 3859.2872, mean_steps: 27.3100, mean_ecr: 0.0402 mean_entropies: 1.2604, took: 128.0979s
2022-10-11 08:01:52,523 [INFO] 	Process 1 - batch 81699: mean_policy_losses: -29.354, mean_net_lifetime: 6608.0876, mean_mc_travel_dist: 2080.6295, mean_rewards: 241.1381, total_rewards: 4558.1618, mean_steps: 26.6700, mean_ecr: 0.0382 mean_entropies: 0.8545, took: 125.9990s
2022-10-11 08:02:04,520 [INFO] 	Process 6 - batch 131299: mean_policy_losses: -66.850, mean_net_lifetime: 3990.4404, mean_mc_travel_dist: 1086.6639, mean_rewards: 340.3795, total_rewards: 2966.1472, mean_steps: 10.6700, mean_ecr: 0.0553 mean_entropies: 0.1434, took: 55.5153s
2022-10-11 08:02:09,322 [INFO] 	Process 4 - batch 94099: mean_policy_losses: 201.661, mean_net_lifetime: 10614.8934, mean_mc_travel_dist: 3147.6662, mean_rewards: 266.6877, total_rewards: 7495.9842, mean_steps: 41.6200, mean_ecr: 0.0376 mean_entropies: 0.5383, took: 187.1817s
2022-10-11 08:02:39,070 [INFO] Process 2 - epoch 59: mean_policy_losses: 0.025, mean_net_lifetime: 5339.2419, mean_mc_travel_dist: 1695.4429, mean_entropies: 0.8269, m_net_lifetime_valid: 4371.8781, took: 2471.2292s, (154.7589 / 100 batches)

2022-10-11 08:03:03,831 [INFO] 	Process 6 - batch 131399: mean_policy_losses: -64.908, mean_net_lifetime: 4087.5038, mean_mc_travel_dist: 1110.6600, mean_rewards: 342.0184, total_rewards: 3056.3079, mean_steps: 10.9400, mean_ecr: 0.0547 mean_entropies: 0.1283, took: 59.3110s
2022-10-11 08:03:34,929 [INFO] 	Process 5 - batch 82999: mean_policy_losses: -201.753, mean_net_lifetime: 10547.0476, mean_mc_travel_dist: 3364.2403, mean_rewards: 269.7436, total_rewards: 7222.4441, mean_steps: 39.5300, mean_ecr: 0.0294 mean_entropies: 0.6701, took: 185.6216s
2022-10-11 08:03:40,012 [INFO] 	Process 7 - batch 90499: mean_policy_losses: -235.648, mean_net_lifetime: 5608.3936, mean_mc_travel_dist: 1682.8088, mean_rewards: 199.6268, total_rewards: 3954.1837, mean_steps: 27.6800, mean_ecr: 0.0402 mean_entropies: 1.2633, took: 129.1160s
2022-10-11 08:04:00,946 [INFO] 	Process 1 - batch 81799: mean_policy_losses: 11.293, mean_net_lifetime: 6678.1506, mean_mc_travel_dist: 2072.2067, mean_rewards: 241.9572, total_rewards: 4628.9463, mean_steps: 26.8600, mean_ecr: 0.0382 mean_entropies: 0.8862, took: 128.4225s
2022-10-11 08:04:05,550 [INFO] 	Process 6 - batch 131499: mean_policy_losses: -33.515, mean_net_lifetime: 4202.3272, mean_mc_travel_dist: 1144.9318, mean_rewards: 340.9020, total_rewards: 3132.8938, mean_steps: 11.3100, mean_ecr: 0.0550 mean_entropies: 0.1321, took: 61.7191s
2022-10-11 08:04:48,131 [INFO] 	Process 2 - batch 88599: mean_policy_losses: -3.659, mean_net_lifetime: 7588.1773, mean_mc_travel_dist: 2048.9062, mean_rewards: 276.5661, total_rewards: 5562.8119, mean_steps: 26.4900, mean_ecr: 0.0381 mean_entropies: 0.3838, took: 777.0756s
2022-10-11 08:05:08,976 [INFO] 	Process 6 - batch 131599: mean_policy_losses: -48.350, mean_net_lifetime: 4315.9164, mean_mc_travel_dist: 1167.4903, mean_rewards: 344.1335, total_rewards: 3217.6491, mean_steps: 11.5100, mean_ecr: 0.0548 mean_entropies: 0.1169, took: 63.4258s
2022-10-11 08:05:36,158 [INFO] 	Process 4 - batch 94199: mean_policy_losses: 146.217, mean_net_lifetime: 11033.7008, mean_mc_travel_dist: 3363.3358, mean_rewards: 266.6432, total_rewards: 7695.2129, mean_steps: 44.5200, mean_ecr: 0.0379 mean_entropies: 0.5414, took: 206.8363s
2022-10-11 08:05:45,087 [INFO] 	Process 7 - batch 90599: mean_policy_losses: -357.899, mean_net_lifetime: 5321.0969, mean_mc_travel_dist: 1614.9400, mean_rewards: 197.0432, total_rewards: 3739.8085, mean_steps: 26.2700, mean_ecr: 0.0407 mean_entropies: 1.2788, took: 125.0748s
2022-10-11 08:06:07,781 [INFO] 	Process 1 - batch 81899: mean_policy_losses: -59.223, mean_net_lifetime: 6591.1512, mean_mc_travel_dist: 2037.5081, mean_rewards: 242.1133, total_rewards: 4574.5103, mean_steps: 26.3900, mean_ecr: 0.0383 mean_entropies: 0.9187, took: 126.8356s
2022-10-11 08:06:10,870 [INFO] 	Process 6 - batch 131699: mean_policy_losses: -38.843, mean_net_lifetime: 4251.8175, mean_mc_travel_dist: 1148.1808, mean_rewards: 343.7445, total_rewards: 3172.8876, mean_steps: 11.3400, mean_ecr: 0.0549 mean_entropies: 0.1213, took: 61.8948s
2022-10-11 08:06:34,455 [INFO] 	Process 5 - batch 83099: mean_policy_losses: -159.507, mean_net_lifetime: 10064.3982, mean_mc_travel_dist: 3193.2561, mean_rewards: 267.8491, total_rewards: 6911.4414, mean_steps: 37.7900, mean_ecr: 0.0294 mean_entropies: 0.6321, took: 179.5263s
2022-10-11 08:06:52,952 [INFO] 	Process 2 - batch 88699: mean_policy_losses: 9.314, mean_net_lifetime: 7578.0185, mean_mc_travel_dist: 2023.7617, mean_rewards: 283.4793, total_rewards: 5573.9622, mean_steps: 25.8000, mean_ecr: 0.0382 mean_entropies: 0.3804, took: 124.8208s
2022-10-11 08:07:13,521 [INFO] 	Process 6 - batch 131799: mean_policy_losses: -44.120, mean_net_lifetime: 4191.8288, mean_mc_travel_dist: 1135.3519, mean_rewards: 341.9795, total_rewards: 3127.0961, mean_steps: 11.2100, mean_ecr: 0.0550 mean_entropies: 0.1324, took: 62.6509s
2022-10-11 08:07:47,091 [INFO] 	Process 7 - batch 90699: mean_policy_losses: -334.375, mean_net_lifetime: 5216.6789, mean_mc_travel_dist: 1564.8497, mean_rewards: 199.1931, total_rewards: 3679.9953, mean_steps: 25.4200, mean_ecr: 0.0406 mean_entropies: 1.2755, took: 122.0043s
2022-10-11 08:08:13,275 [INFO] 	Process 6 - batch 131899: mean_policy_losses: -73.841, mean_net_lifetime: 4073.8262, mean_mc_travel_dist: 1115.2637, mean_rewards: 338.8935, total_rewards: 3031.9380, mean_steps: 11.0100, mean_ecr: 0.0548 mean_entropies: 0.1604, took: 59.7537s
2022-10-11 08:08:17,810 [INFO] 	Process 1 - batch 81999: mean_policy_losses: 22.249, mean_net_lifetime: 6890.5256, mean_mc_travel_dist: 2099.2048, mean_rewards: 250.7463, total_rewards: 4808.2850, mean_steps: 26.6000, mean_ecr: 0.0381 mean_entropies: 0.9324, took: 130.0291s
2022-10-11 08:08:34,270 [INFO] 	Process 4 - batch 94299: mean_policy_losses: 183.600, mean_net_lifetime: 9826.0996, mean_mc_travel_dist: 2839.7046, mean_rewards: 272.3097, total_rewards: 7016.9693, mean_steps: 37.6600, mean_ecr: 0.0387 mean_entropies: 0.5152, took: 178.1103s
2022-10-11 08:09:00,562 [INFO] 	Process 2 - batch 88799: mean_policy_losses: -2.372, mean_net_lifetime: 7598.5532, mean_mc_travel_dist: 2038.4732, mean_rewards: 278.0106, total_rewards: 5587.0922, mean_steps: 26.4600, mean_ecr: 0.0381 mean_entropies: 0.3581, took: 127.6096s
2022-10-11 08:09:09,604 [INFO] 	Process 5 - batch 83199: mean_policy_losses: -198.521, mean_net_lifetime: 8478.4924, mean_mc_travel_dist: 2640.8941, mean_rewards: 264.7141, total_rewards: 5880.8274, mean_steps: 31.5400, mean_ecr: 0.0299 mean_entropies: 0.6052, took: 155.1484s
2022-10-11 08:09:16,461 [INFO] 	Process 6 - batch 131999: mean_policy_losses: -58.378, mean_net_lifetime: 4125.4408, mean_mc_travel_dist: 1150.1550, mean_rewards: 330.6667, total_rewards: 3037.4993, mean_steps: 11.4800, mean_ecr: 0.0549 mean_entropies: 0.1677, took: 63.1860s
2022-10-11 08:09:48,395 [INFO] 	Process 7 - batch 90799: mean_policy_losses: -324.906, mean_net_lifetime: 5294.2118, mean_mc_travel_dist: 1589.0598, mean_rewards: 201.5873, total_rewards: 3734.1969, mean_steps: 25.9100, mean_ecr: 0.0405 mean_entropies: 1.2826, took: 121.3039s
2022-10-11 08:10:04,126 [INFO] Process 3 - epoch 66: mean_policy_losses: 44.273, mean_net_lifetime: 4500.2133, mean_mc_travel_dist: 1340.4929, mean_entropies: 0.7910, m_net_lifetime_valid: 4294.3864, took: 1957.0492s, (138.8348 / 100 batches)

2022-10-11 08:10:23,499 [INFO] 	Process 1 - batch 82099: mean_policy_losses: -22.295, mean_net_lifetime: 6618.6462, mean_mc_travel_dist: 2061.9394, mean_rewards: 246.3570, total_rewards: 4583.0701, mean_steps: 26.1000, mean_ecr: 0.0382 mean_entropies: 0.9371, took: 125.6884s
2022-10-11 08:11:04,267 [INFO] 	Process 2 - batch 88899: mean_policy_losses: -11.448, mean_net_lifetime: 7449.9968, mean_mc_travel_dist: 1988.9547, mean_rewards: 279.8676, total_rewards: 5490.9471, mean_steps: 25.7500, mean_ecr: 0.0383 mean_entropies: 0.3797, took: 123.7042s
2022-10-11 08:11:26,461 [INFO] 	Process 4 - batch 94399: mean_policy_losses: 212.595, mean_net_lifetime: 9719.1492, mean_mc_travel_dist: 2869.5811, mean_rewards: 271.5975, total_rewards: 6873.2703, mean_steps: 37.4400, mean_ecr: 0.0395 mean_entropies: 0.5344, took: 172.1919s
2022-10-11 08:11:35,502 [INFO] 	Process 3 - batch 99099: mean_policy_losses: -35.872, mean_net_lifetime: 5248.1350, mean_mc_travel_dist: 1341.4957, mean_rewards: 279.8222, total_rewards: 3938.0749, mean_steps: 17.8000, mean_ecr: 0.0458 mean_entropies: 0.4849, took: 714.7036s
2022-10-11 08:11:36,603 [INFO] 	Process 5 - batch 83299: mean_policy_losses: -195.436, mean_net_lifetime: 8476.6799, mean_mc_travel_dist: 2699.1880, mean_rewards: 271.9984, total_rewards: 5820.6985, mean_steps: 30.7700, mean_ecr: 0.0299 mean_entropies: 0.6136, took: 146.9994s
2022-10-11 08:11:43,164 [INFO] 	Process 7 - batch 90899: mean_policy_losses: -348.353, mean_net_lifetime: 4851.2669, mean_mc_travel_dist: 1441.0127, mean_rewards: 198.5799, total_rewards: 3452.7323, mean_steps: 24.1600, mean_ecr: 0.0409 mean_entropies: 1.2224, took: 114.7689s
2022-10-11 08:12:31,753 [INFO] 	Process 1 - batch 82199: mean_policy_losses: -47.829, mean_net_lifetime: 6764.0474, mean_mc_travel_dist: 2112.4662, mean_rewards: 250.7445, total_rewards: 4675.9743, mean_steps: 26.0500, mean_ecr: 0.0382 mean_entropies: 0.9267, took: 128.2541s
2022-10-11 08:13:06,628 [INFO] 	Process 3 - batch 99199: mean_policy_losses: -33.477, mean_net_lifetime: 5351.6386, mean_mc_travel_dist: 1380.1149, mean_rewards: 286.7116, total_rewards: 4007.2234, mean_steps: 17.7100, mean_ecr: 0.0457 mean_entropies: 0.5106, took: 91.1256s
2022-10-11 08:13:10,737 [INFO] 	Process 2 - batch 88999: mean_policy_losses: -5.078, mean_net_lifetime: 7573.2948, mean_mc_travel_dist: 2043.2242, mean_rewards: 282.1145, total_rewards: 5555.7445, mean_steps: 25.9400, mean_ecr: 0.0382 mean_entropies: 0.3991, took: 126.4709s
2022-10-11 08:13:39,058 [INFO] 	Process 7 - batch 90999: mean_policy_losses: -359.973, mean_net_lifetime: 4991.1135, mean_mc_travel_dist: 1491.8546, mean_rewards: 197.5925, total_rewards: 3537.6905, mean_steps: 24.3600, mean_ecr: 0.0407 mean_entropies: 1.2739, took: 115.8935s
2022-10-11 08:14:05,259 [INFO] 	Process 4 - batch 94499: mean_policy_losses: 219.756, mean_net_lifetime: 8857.3131, mean_mc_travel_dist: 2535.9771, mean_rewards: 273.2893, total_rewards: 6345.0818, mean_steps: 33.2000, mean_ecr: 0.0401 mean_entropies: 0.5179, took: 158.7991s
2022-10-11 08:14:21,002 [INFO] 	Process 5 - batch 83399: mean_policy_losses: -131.646, mean_net_lifetime: 9484.8574, mean_mc_travel_dist: 2969.4014, mean_rewards: 272.5200, total_rewards: 6557.7690, mean_steps: 34.3800, mean_ecr: 0.0297 mean_entropies: 0.6232, took: 164.3986s
2022-10-11 08:14:36,432 [INFO] 	Process 1 - batch 82299: mean_policy_losses: -3.134, mean_net_lifetime: 6727.6041, mean_mc_travel_dist: 2087.1841, mean_rewards: 251.7929, total_rewards: 4672.2722, mean_steps: 25.9600, mean_ecr: 0.0381 mean_entropies: 0.9310, took: 124.6790s
2022-10-11 08:14:37,943 [INFO] 	Process 3 - batch 99299: mean_policy_losses: -30.240, mean_net_lifetime: 5248.1353, mean_mc_travel_dist: 1369.8929, mean_rewards: 280.3204, total_rewards: 3909.2001, mean_steps: 17.8000, mean_ecr: 0.0457 mean_entropies: 0.4832, took: 91.3156s
2022-10-11 08:15:10,854 [INFO] 	Process 2 - batch 89099: mean_policy_losses: 5.598, mean_net_lifetime: 7462.4359, mean_mc_travel_dist: 1985.2820, mean_rewards: 283.2084, total_rewards: 5503.7727, mean_steps: 25.4500, mean_ecr: 0.0383 mean_entropies: 0.3858, took: 120.1165s
2022-10-11 08:15:29,060 [INFO] 	Process 7 - batch 91099: mean_policy_losses: -262.645, mean_net_lifetime: 5129.4017, mean_mc_travel_dist: 1495.7996, mean_rewards: 209.1189, total_rewards: 3661.7946, mean_steps: 23.7400, mean_ecr: 0.0408 mean_entropies: 1.3060, took: 110.0014s
2022-10-11 08:16:03,873 [INFO] 	Process 3 - batch 99399: mean_policy_losses: -42.729, mean_net_lifetime: 5249.5474, mean_mc_travel_dist: 1354.5756, mean_rewards: 289.7132, total_rewards: 3923.9867, mean_steps: 17.1500, mean_ecr: 0.0459 mean_entropies: 0.4970, took: 85.9291s
2022-10-11 08:16:34,025 [INFO] 	Process 1 - batch 82399: mean_policy_losses: -46.552, mean_net_lifetime: 6568.4507, mean_mc_travel_dist: 2051.3370, mean_rewards: 253.1886, total_rewards: 4544.7899, mean_steps: 25.0200, mean_ecr: 0.0383 mean_entropies: 0.9413, took: 117.5929s
2022-10-11 08:17:02,986 [INFO] 	Process 5 - batch 83499: mean_policy_losses: -129.215, mean_net_lifetime: 9499.7795, mean_mc_travel_dist: 3008.7873, mean_rewards: 274.8493, total_rewards: 6537.0503, mean_steps: 34.4500, mean_ecr: 0.0296 mean_entropies: 0.6364, took: 161.9833s
2022-10-11 08:17:13,150 [INFO] 	Process 2 - batch 89199: mean_policy_losses: 3.155, mean_net_lifetime: 7602.6204, mean_mc_travel_dist: 2028.3598, mean_rewards: 286.0849, total_rewards: 5594.5260, mean_steps: 25.6500, mean_ecr: 0.0382 mean_entropies: 0.3975, took: 122.2959s
2022-10-11 08:17:20,809 [INFO] 	Process 7 - batch 91199: mean_policy_losses: -238.909, mean_net_lifetime: 5205.6458, mean_mc_travel_dist: 1540.3104, mean_rewards: 209.9445, total_rewards: 3687.0832, mean_steps: 23.9600, mean_ecr: 0.0406 mean_entropies: 1.3054, took: 111.7497s
2022-10-11 08:17:32,717 [INFO] 	Process 3 - batch 99499: mean_policy_losses: -42.953, mean_net_lifetime: 5321.8937, mean_mc_travel_dist: 1353.0025, mean_rewards: 285.8226, total_rewards: 3992.6614, mean_steps: 17.6600, mean_ecr: 0.0458 mean_entropies: 0.4709, took: 88.8445s
2022-10-11 08:18:38,367 [INFO] 	Process 1 - batch 82499: mean_policy_losses: 13.702, mean_net_lifetime: 6713.6936, mean_mc_travel_dist: 2054.8540, mean_rewards: 247.2510, total_rewards: 4684.9004, mean_steps: 26.2900, mean_ecr: 0.0382 mean_entropies: 0.9778, took: 124.3427s
2022-10-11 08:19:01,250 [INFO] 	Process 3 - batch 99599: mean_policy_losses: -32.254, mean_net_lifetime: 5244.3057, mean_mc_travel_dist: 1321.7387, mean_rewards: 284.3685, total_rewards: 3952.0119, mean_steps: 17.5100, mean_ecr: 0.0459 mean_entropies: 0.4505, took: 88.5328s
2022-10-11 08:19:09,890 [INFO] 	Process 7 - batch 91299: mean_policy_losses: -271.886, mean_net_lifetime: 4992.3536, mean_mc_travel_dist: 1485.4550, mean_rewards: 207.1085, total_rewards: 3545.5139, mean_steps: 23.5200, mean_ecr: 0.0410 mean_entropies: 1.3394, took: 109.0818s
2022-10-11 08:19:11,236 [INFO] 	Process 2 - batch 89299: mean_policy_losses: -12.349, mean_net_lifetime: 7485.6939, mean_mc_travel_dist: 2019.8903, mean_rewards: 285.2388, total_rewards: 5496.7594, mean_steps: 25.3100, mean_ecr: 0.0383 mean_entropies: 0.4277, took: 118.0872s
2022-10-11 08:19:24,172 [INFO] 	Process 5 - batch 83599: mean_policy_losses: -103.200, mean_net_lifetime: 8557.6778, mean_mc_travel_dist: 2666.2408, mean_rewards: 277.6099, total_rewards: 5931.9848, mean_steps: 30.2400, mean_ecr: 0.0298 mean_entropies: 0.6902, took: 141.1877s
2022-10-11 08:19:31,321 [INFO] Process 6 - epoch 88: mean_policy_losses: -182.958, mean_net_lifetime: 3278.7485, mean_mc_travel_dist: 991.4511, mean_entropies: 0.4864, m_net_lifetime_valid: 4233.6743, took: 1512.8651s, (104.5883 / 100 batches)

2022-10-11 08:20:26,667 [INFO] 	Process 6 - batch 132099: mean_policy_losses: -74.425, mean_net_lifetime: 3919.3055, mean_mc_travel_dist: 1048.7874, mean_rewards: 343.0009, total_rewards: 2932.8982, mean_steps: 10.4200, mean_ecr: 0.0548 mean_entropies: 0.1721, took: 670.2059s
2022-10-11 08:20:29,176 [INFO] 	Process 3 - batch 99699: mean_policy_losses: -34.632, mean_net_lifetime: 5330.0864, mean_mc_travel_dist: 1376.5363, mean_rewards: 284.6927, total_rewards: 3992.1910, mean_steps: 17.7700, mean_ecr: 0.0453 mean_entropies: 0.4854, took: 87.9252s
2022-10-11 08:21:09,742 [INFO] 	Process 7 - batch 91399: mean_policy_losses: -162.051, mean_net_lifetime: 5371.0788, mean_mc_travel_dist: 1585.4465, mean_rewards: 201.4920, total_rewards: 3816.1299, mean_steps: 26.0700, mean_ecr: 0.0404 mean_entropies: 1.2806, took: 119.8516s
2022-10-11 08:21:12,579 [INFO] 	Process 2 - batch 89399: mean_policy_losses: 11.311, mean_net_lifetime: 7578.1843, mean_mc_travel_dist: 2027.2266, mean_rewards: 285.3822, total_rewards: 5576.3292, mean_steps: 25.6600, mean_ecr: 0.0382 mean_entropies: 0.4198, took: 121.3416s
2022-10-11 08:21:24,887 [INFO] 	Process 6 - batch 132199: mean_policy_losses: -51.944, mean_net_lifetime: 4139.8081, mean_mc_travel_dist: 1116.2582, mean_rewards: 344.6614, total_rewards: 3088.6407, mean_steps: 11.0000, mean_ecr: 0.0548 mean_entropies: 0.1342, took: 58.2204s
2022-10-11 08:22:00,051 [INFO] 	Process 5 - batch 83699: mean_policy_losses: -92.570, mean_net_lifetime: 9224.5277, mean_mc_travel_dist: 2875.0368, mean_rewards: 273.0886, total_rewards: 6398.0354, mean_steps: 33.3100, mean_ecr: 0.0297 mean_entropies: 0.6800, took: 155.8792s
2022-10-11 08:22:01,016 [INFO] 	Process 3 - batch 99799: mean_policy_losses: -38.505, mean_net_lifetime: 5474.8240, mean_mc_travel_dist: 1410.3785, mean_rewards: 285.1116, total_rewards: 4091.1414, mean_steps: 18.2400, mean_ecr: 0.0452 mean_entropies: 0.4916, took: 91.8407s
2022-10-11 08:22:17,860 [INFO] 	Process 6 - batch 132299: mean_policy_losses: -169.410, mean_net_lifetime: 3697.4115, mean_mc_travel_dist: 994.9492, mean_rewards: 341.4213, total_rewards: 2771.9095, mean_steps: 9.8000, mean_ecr: 0.0553 mean_entropies: 0.1605, took: 52.9723s
2022-10-11 08:22:59,506 [INFO] 	Process 7 - batch 91499: mean_policy_losses: -270.426, mean_net_lifetime: 4989.3819, mean_mc_travel_dist: 1459.2938, mean_rewards: 207.5937, total_rewards: 3568.2772, mean_steps: 23.2700, mean_ecr: 0.0408 mean_entropies: 1.2705, took: 109.7645s
2022-10-11 08:23:12,384 [INFO] 	Process 6 - batch 132399: mean_policy_losses: -85.509, mean_net_lifetime: 3871.8565, mean_mc_travel_dist: 1050.4702, mean_rewards: 342.5559, total_rewards: 2893.6321, mean_steps: 10.2700, mean_ecr: 0.0553 mean_entropies: 0.1572, took: 54.5241s
2022-10-11 08:23:14,183 [INFO] 	Process 2 - batch 89499: mean_policy_losses: 13.319, mean_net_lifetime: 7663.6770, mean_mc_travel_dist: 2011.8015, mean_rewards: 286.4067, total_rewards: 5673.7724, mean_steps: 25.8200, mean_ecr: 0.0382 mean_entropies: 0.4134, took: 121.6043s
2022-10-11 08:23:27,207 [INFO] 	Process 3 - batch 99899: mean_policy_losses: -39.625, mean_net_lifetime: 5285.3794, mean_mc_travel_dist: 1356.1793, mean_rewards: 286.2507, total_rewards: 3965.2746, mean_steps: 17.5300, mean_ecr: 0.0457 mean_entropies: 0.4947, took: 86.1913s
2022-10-11 08:23:48,246 [INFO] Process 4 - epoch 63: mean_policy_losses: 109.362, mean_net_lifetime: 5042.1370, mean_mc_travel_dist: 1564.5322, mean_entropies: 1.0240, m_net_lifetime_valid: 4234.7589, took: 3460.0782s, (146.3534 / 100 batches)

2022-10-11 08:24:09,926 [INFO] 	Process 6 - batch 132499: mean_policy_losses: -74.508, mean_net_lifetime: 4057.2314, mean_mc_travel_dist: 1101.0600, mean_rewards: 343.0192, total_rewards: 3024.0528, mean_steps: 10.8000, mean_ecr: 0.0551 mean_entropies: 0.1405, took: 57.5414s
2022-10-11 08:24:23,387 [INFO] 	Process 5 - batch 83799: mean_policy_losses: -164.606, mean_net_lifetime: 8556.5628, mean_mc_travel_dist: 2688.2053, mean_rewards: 274.9110, total_rewards: 5916.9484, mean_steps: 30.8200, mean_ecr: 0.0300 mean_entropies: 0.6671, took: 143.3364s
2022-10-11 08:24:57,355 [INFO] 	Process 3 - batch 99999: mean_policy_losses: -51.406, mean_net_lifetime: 5374.9194, mean_mc_travel_dist: 1382.0016, mean_rewards: 284.1860, total_rewards: 4025.8289, mean_steps: 17.9500, mean_ecr: 0.0453 mean_entropies: 0.4604, took: 90.1472s
2022-10-11 08:25:08,668 [INFO] 	Process 6 - batch 132599: mean_policy_losses: -112.877, mean_net_lifetime: 4140.0500, mean_mc_travel_dist: 1123.1474, mean_rewards: 343.7849, total_rewards: 3087.8667, mean_steps: 11.0200, mean_ecr: 0.0548 mean_entropies: 0.1281, took: 58.7425s
2022-10-11 08:25:14,756 [INFO] 	Process 2 - batch 89599: mean_policy_losses: 4.831, mean_net_lifetime: 7662.8311, mean_mc_travel_dist: 2029.1899, mean_rewards: 282.3787, total_rewards: 5658.8022, mean_steps: 26.1900, mean_ecr: 0.0382 mean_entropies: 0.4034, took: 120.5731s
2022-10-11 08:25:37,043 [INFO] 	Process 4 - batch 94599: mean_policy_losses: 233.442, mean_net_lifetime: 6496.4105, mean_mc_travel_dist: 1739.2690, mean_rewards: 283.1887, total_rewards: 4780.0331, mean_steps: 22.5600, mean_ecr: 0.0440 mean_entropies: 0.5679, took: 691.7827s
2022-10-11 08:26:05,152 [INFO] 	Process 6 - batch 132699: mean_policy_losses: -85.743, mean_net_lifetime: 4008.1753, mean_mc_travel_dist: 1085.4518, mean_rewards: 342.4743, total_rewards: 2994.9731, mean_steps: 10.6700, mean_ecr: 0.0551 mean_entropies: 0.1436, took: 56.4841s
2022-10-11 08:26:25,036 [INFO] 	Process 3 - batch 100099: mean_policy_losses: -77.096, mean_net_lifetime: 5269.7308, mean_mc_travel_dist: 1350.1819, mean_rewards: 285.7853, total_rewards: 3942.4767, mean_steps: 17.4800, mean_ecr: 0.0455 mean_entropies: 0.4640, took: 87.6817s
2022-10-11 08:27:02,114 [INFO] 	Process 6 - batch 132799: mean_policy_losses: -71.198, mean_net_lifetime: 4020.8716, mean_mc_travel_dist: 1091.4066, mean_rewards: 340.5317, total_rewards: 2999.3740, mean_steps: 10.7900, mean_ecr: 0.0548 mean_entropies: 0.1459, took: 56.9625s
2022-10-11 08:27:04,592 [INFO] 	Process 5 - batch 83899: mean_policy_losses: -155.367, mean_net_lifetime: 9692.7048, mean_mc_travel_dist: 3061.0788, mean_rewards: 272.7519, total_rewards: 6676.4414, mean_steps: 35.4200, mean_ecr: 0.0298 mean_entropies: 0.6953, took: 161.2039s
2022-10-11 08:27:14,537 [INFO] 	Process 2 - batch 89699: mean_policy_losses: -8.081, mean_net_lifetime: 7515.8426, mean_mc_travel_dist: 1991.7608, mean_rewards: 280.5215, total_rewards: 5552.3367, mean_steps: 25.8800, mean_ecr: 0.0383 mean_entropies: 0.3955, took: 119.7814s
2022-10-11 08:27:38,760 [INFO] 	Process 4 - batch 94699: mean_policy_losses: 126.600, mean_net_lifetime: 7337.9717, mean_mc_travel_dist: 2009.4635, mean_rewards: 283.0331, total_rewards: 5360.6963, mean_steps: 25.8600, mean_ecr: 0.0425 mean_entropies: 0.5153, took: 121.7164s
2022-10-11 08:27:59,549 [INFO] 	Process 6 - batch 132899: mean_policy_losses: -66.616, mean_net_lifetime: 4075.5803, mean_mc_travel_dist: 1102.7174, mean_rewards: 341.8485, total_rewards: 3037.7096, mean_steps: 10.9100, mean_ecr: 0.0550 mean_entropies: 0.1296, took: 57.4345s
2022-10-11 08:27:59,585 [INFO] 	Process 3 - batch 100199: mean_policy_losses: -40.107, mean_net_lifetime: 5469.1340, mean_mc_travel_dist: 1402.2692, mean_rewards: 280.0485, total_rewards: 4094.9220, mean_steps: 18.5900, mean_ecr: 0.0451 mean_entropies: 0.4527, took: 94.5485s
2022-10-11 08:29:00,300 [INFO] 	Process 6 - batch 132999: mean_policy_losses: -42.771, mean_net_lifetime: 4277.2354, mean_mc_travel_dist: 1154.0064, mean_rewards: 344.8773, total_rewards: 3187.1694, mean_steps: 11.3900, mean_ecr: 0.0549 mean_entropies: 0.1051, took: 60.7509s
2022-10-11 08:29:13,207 [INFO] Process 1 - epoch 55: mean_policy_losses: 15.180, mean_net_lifetime: 5448.3668, mean_mc_travel_dist: 2042.5582, mean_entropies: 1.1344, m_net_lifetime_valid: 4599.9437, took: 2489.9487s, (167.9462 / 100 batches)

2022-10-11 08:29:13,381 [INFO] 	Process 2 - batch 89799: mean_policy_losses: -26.679, mean_net_lifetime: 7406.7098, mean_mc_travel_dist: 1969.7972, mean_rewards: 279.8618, total_rewards: 5461.2657, mean_steps: 25.5400, mean_ecr: 0.0384 mean_entropies: 0.3767, took: 118.8427s
2022-10-11 08:29:29,418 [INFO] 	Process 5 - batch 83999: mean_policy_losses: -256.386, mean_net_lifetime: 8553.1818, mean_mc_travel_dist: 2676.8647, mean_rewards: 272.9702, total_rewards: 5905.7072, mean_steps: 31.0500, mean_ecr: 0.0299 mean_entropies: 0.6609, took: 144.8261s
2022-10-11 08:29:31,460 [INFO] 	Process 3 - batch 100299: mean_policy_losses: -50.838, mean_net_lifetime: 5336.4405, mean_mc_travel_dist: 1350.6285, mean_rewards: 276.6398, total_rewards: 4011.8156, mean_steps: 18.3500, mean_ecr: 0.0454 mean_entropies: 0.4651, took: 91.8752s
2022-10-11 08:29:55,722 [INFO] 	Process 4 - batch 94799: mean_policy_losses: 114.353, mean_net_lifetime: 7938.7913, mean_mc_travel_dist: 2237.2788, mean_rewards: 278.2667, total_rewards: 5730.0036, mean_steps: 29.0400, mean_ecr: 0.0414 mean_entropies: 0.5073, took: 136.9628s
2022-10-11 08:29:57,301 [INFO] 	Process 6 - batch 133099: mean_policy_losses: -40.659, mean_net_lifetime: 4095.7641, mean_mc_travel_dist: 1109.8982, mean_rewards: 343.2305, total_rewards: 3065.2774, mean_steps: 10.9200, mean_ecr: 0.0549 mean_entropies: 0.1275, took: 57.0014s
2022-10-11 08:30:53,343 [INFO] 	Process 6 - batch 133199: mean_policy_losses: -73.557, mean_net_lifetime: 4087.2685, mean_mc_travel_dist: 1105.3719, mean_rewards: 343.0477, total_rewards: 3058.1179, mean_steps: 10.8900, mean_ecr: 0.0549 mean_entropies: 0.1338, took: 56.0417s
2022-10-11 08:31:01,189 [INFO] 	Process 3 - batch 100399: mean_policy_losses: -56.165, mean_net_lifetime: 5381.8271, mean_mc_travel_dist: 1369.7828, mean_rewards: 280.9963, total_rewards: 4039.4681, mean_steps: 18.3200, mean_ecr: 0.0453 mean_entropies: 0.4693, took: 89.7293s
2022-10-11 08:31:15,670 [INFO] 	Process 2 - batch 89899: mean_policy_losses: -30.242, mean_net_lifetime: 7329.8882, mean_mc_travel_dist: 1940.0195, mean_rewards: 279.3111, total_rewards: 5421.0860, mean_steps: 25.3600, mean_ecr: 0.0385 mean_entropies: 0.3677, took: 122.2896s
2022-10-11 08:31:15,772 [INFO] 	Process 1 - batch 82599: mean_policy_losses: 15.764, mean_net_lifetime: 6712.8276, mean_mc_travel_dist: 2012.7119, mean_rewards: 246.4150, total_rewards: 4731.4457, mean_steps: 26.4300, mean_ecr: 0.0383 mean_entropies: 0.9858, took: 757.4042s
2022-10-11 08:31:51,150 [INFO] 	Process 6 - batch 133299: mean_policy_losses: -63.324, mean_net_lifetime: 4088.6750, mean_mc_travel_dist: 1113.5951, mean_rewards: 342.0794, total_rewards: 3046.5500, mean_steps: 10.9300, mean_ecr: 0.0551 mean_entropies: 0.1402, took: 57.8072s
2022-10-11 08:32:45,804 [INFO] 	Process 4 - batch 94899: mean_policy_losses: 52.495, mean_net_lifetime: 8001.6938, mean_mc_travel_dist: 2250.6228, mean_rewards: 277.8816, total_rewards: 5782.7403, mean_steps: 29.3100, mean_ecr: 0.0410 mean_entropies: 0.5141, took: 170.0829s
2022-10-11 08:33:03,181 [INFO] 	Process 3 - batch 100499: mean_policy_losses: -54.444, mean_net_lifetime: 5259.7199, mean_mc_travel_dist: 1319.3018, mean_rewards: 275.2323, total_rewards: 3980.7578, mean_steps: 18.2200, mean_ecr: 0.0457 mean_entropies: 0.4874, took: 121.9921s
2022-10-11 08:33:21,344 [INFO] 	Process 6 - batch 133399: mean_policy_losses: -76.921, mean_net_lifetime: 3879.8200, mean_mc_travel_dist: 1057.7138, mean_rewards: 341.1788, total_rewards: 2885.8213, mean_steps: 10.3500, mean_ecr: 0.0554 mean_entropies: 0.1436, took: 90.1936s
2022-10-11 08:34:16,136 [INFO] 	Process 1 - batch 82699: mean_policy_losses: -45.701, mean_net_lifetime: 6426.1473, mean_mc_travel_dist: 1975.0666, mean_rewards: 248.5020, total_rewards: 4469.2972, mean_steps: 25.0300, mean_ecr: 0.0384 mean_entropies: 0.9299, took: 180.3648s
2022-10-11 08:34:26,641 [INFO] 	Process 2 - batch 89999: mean_policy_losses: -4.636, mean_net_lifetime: 7675.0210, mean_mc_travel_dist: 2016.3410, mean_rewards: 277.2204, total_rewards: 5683.3511, mean_steps: 26.7700, mean_ecr: 0.0381 mean_entropies: 0.3653, took: 190.9714s
2022-10-11 08:34:42,645 [INFO] 	Process 6 - batch 133499: mean_policy_losses: -72.524, mean_net_lifetime: 3970.3993, mean_mc_travel_dist: 1085.9958, mean_rewards: 337.8421, total_rewards: 2960.3262, mean_steps: 10.7400, mean_ecr: 0.0551 mean_entropies: 0.1617, took: 81.3014s
2022-10-11 08:35:18,077 [INFO] Process 7 - epoch 61: mean_policy_losses: -367.225, mean_net_lifetime: 4335.0540, mean_mc_travel_dist: 1552.2774, mean_entropies: 1.5157, m_net_lifetime_valid: 4524.6994, took: 2484.1620s, (151.7300 / 100 batches)

2022-10-11 08:36:02,329 [INFO] 	Process 4 - batch 94999: mean_policy_losses: 65.672, mean_net_lifetime: 9832.4605, mean_mc_travel_dist: 2882.5552, mean_rewards: 278.5613, total_rewards: 6983.9946, mean_steps: 37.7400, mean_ecr: 0.0401 mean_entropies: 0.5382, took: 196.5246s
2022-10-11 08:36:07,131 [INFO] 	Process 1 - batch 82799: mean_policy_losses: 6.612, mean_net_lifetime: 6667.2135, mean_mc_travel_dist: 2067.3025, mean_rewards: 248.6173, total_rewards: 4627.6289, mean_steps: 26.0100, mean_ecr: 0.0382 mean_entropies: 0.9338, took: 110.9946s
2022-10-11 08:37:14,276 [INFO] 	Process 7 - batch 91599: mean_policy_losses: -397.616, mean_net_lifetime: 5211.9846, mean_mc_travel_dist: 1574.8086, mean_rewards: 193.2700, total_rewards: 3676.5807, mean_steps: 26.5000, mean_ecr: 0.0405 mean_entropies: 1.2781, took: 854.7692s
2022-10-11 08:37:59,208 [INFO] 	Process 1 - batch 82899: mean_policy_losses: -10.356, mean_net_lifetime: 6645.2882, mean_mc_travel_dist: 2065.1617, mean_rewards: 246.8446, total_rewards: 4608.2338, mean_steps: 26.1400, mean_ecr: 0.0381 mean_entropies: 0.9110, took: 112.0775s
2022-10-11 08:38:58,197 [INFO] 	Process 7 - batch 91699: mean_policy_losses: -471.775, mean_net_lifetime: 4881.6154, mean_mc_travel_dist: 1441.7175, mean_rewards: 201.7546, total_rewards: 3466.4112, mean_steps: 23.7100, mean_ecr: 0.0409 mean_entropies: 1.2542, took: 103.9216s
2022-10-11 08:39:47,653 [INFO] 	Process 1 - batch 82999: mean_policy_losses: -12.508, mean_net_lifetime: 6305.9659, mean_mc_travel_dist: 1978.4476, mean_rewards: 251.3617, total_rewards: 4353.7534, mean_steps: 24.2300, mean_ecr: 0.0384 mean_entropies: 0.8670, took: 108.4442s
2022-10-11 08:40:41,679 [INFO] 	Process 4 - batch 95099: mean_policy_losses: 163.537, mean_net_lifetime: 15598.6749, mean_mc_travel_dist: 5052.9076, mean_rewards: 253.3251, total_rewards: 10575.6732, mean_steps: 67.9000, mean_ecr: 0.0347 mean_entropies: 0.5377, took: 279.3503s
2022-10-11 08:40:46,967 [INFO] 	Process 7 - batch 91799: mean_policy_losses: -395.306, mean_net_lifetime: 5059.6142, mean_mc_travel_dist: 1501.9473, mean_rewards: 200.8628, total_rewards: 3598.5853, mean_steps: 24.5000, mean_ecr: 0.0407 mean_entropies: 1.2600, took: 108.7691s
2022-10-11 08:41:01,439 [INFO] Process 5 - epoch 56: mean_policy_losses: -190.592, mean_net_lifetime: 5883.5470, mean_mc_travel_dist: 2173.4477, mean_entropies: 1.0902, m_net_lifetime_valid: 4544.7211, took: 3183.7820s, (165.7248 / 100 batches)

2022-10-11 08:41:39,949 [INFO] 	Process 1 - batch 83099: mean_policy_losses: 17.914, mean_net_lifetime: 6440.2221, mean_mc_travel_dist: 2008.5893, mean_rewards: 249.5689, total_rewards: 4459.3872, mean_steps: 24.9100, mean_ecr: 0.0382 mean_entropies: 0.8879, took: 112.2957s
2022-10-11 08:43:18,711 [INFO] 	Process 7 - batch 91899: mean_policy_losses: -374.890, mean_net_lifetime: 5045.4541, mean_mc_travel_dist: 1476.4227, mean_rewards: 205.1280, total_rewards: 3600.1763, mean_steps: 23.8300, mean_ecr: 0.0406 mean_entropies: 1.2850, took: 151.7438s
2022-10-11 08:44:21,264 [INFO] 	Process 5 - batch 84099: mean_policy_losses: -236.766, mean_net_lifetime: 8013.6923, mean_mc_travel_dist: 2529.1956, mean_rewards: 266.8820, total_rewards: 5519.6972, mean_steps: 29.7100, mean_ecr: 0.0299 mean_entropies: 0.6569, took: 891.8461s
2022-10-11 08:44:38,338 [INFO] 	Process 1 - batch 83199: mean_policy_losses: 21.249, mean_net_lifetime: 6501.0334, mean_mc_travel_dist: 2059.3386, mean_rewards: 255.6144, total_rewards: 4468.3081, mean_steps: 24.6000, mean_ecr: 0.0381 mean_entropies: 0.8823, took: 178.3891s
2022-10-11 08:45:13,972 [INFO] Process 3 - epoch 67: mean_policy_losses: 42.955, mean_net_lifetime: 4512.4944, mean_mc_travel_dist: 1340.8219, mean_entropies: 0.7863, m_net_lifetime_valid: 4616.3744, took: 2109.8426s, (138.7552 / 100 batches)

2022-10-11 08:45:23,095 [INFO] 	Process 7 - batch 91999: mean_policy_losses: -350.347, mean_net_lifetime: 4490.3949, mean_mc_travel_dist: 1330.2605, mean_rewards: 197.9108, total_rewards: 3189.4959, mean_steps: 22.3100, mean_ecr: 0.0410 mean_entropies: 1.1917, took: 124.3841s
2022-10-11 08:45:41,590 [INFO] 	Process 4 - batch 95199: mean_policy_losses: 210.780, mean_net_lifetime: 13060.5178, mean_mc_travel_dist: 4096.2329, mean_rewards: 267.3048, total_rewards: 8988.4777, mean_steps: 54.1400, mean_ecr: 0.0373 mean_entropies: 0.5105, took: 299.9104s
2022-10-11 08:46:13,367 [INFO] Process 6 - epoch 89: mean_policy_losses: -181.773, mean_net_lifetime: 3287.0992, mean_mc_travel_dist: 992.5516, mean_entropies: 0.4825, m_net_lifetime_valid: 4645.1487, took: 1602.0428s, (104.5564 / 100 batches)

2022-10-11 08:46:33,910 [INFO] 	Process 1 - batch 83299: mean_policy_losses: 25.242, mean_net_lifetime: 6408.8447, mean_mc_travel_dist: 2020.4870, mean_rewards: 255.8833, total_rewards: 4411.9189, mean_steps: 24.1500, mean_ecr: 0.0382 mean_entropies: 0.8744, took: 115.5721s
2022-10-11 08:46:37,507 [INFO] Process 2 - epoch 60: mean_policy_losses: -0.039, mean_net_lifetime: 5376.0000, mean_mc_travel_dist: 1700.6999, mean_entropies: 0.8196, m_net_lifetime_valid: 4501.1010, took: 2638.4341s, (155.0188 / 100 batches)

2022-10-11 08:46:43,306 [INFO] 	Process 3 - batch 100599: mean_policy_losses: 7.872, mean_net_lifetime: 5195.5333, mean_mc_travel_dist: 1287.3983, mean_rewards: 279.7315, total_rewards: 3936.0230, mean_steps: 17.6400, mean_ecr: 0.0461 mean_entropies: 0.4604, took: 820.1249s
2022-10-11 08:46:56,062 [INFO] 	Process 5 - batch 84199: mean_policy_losses: -175.066, mean_net_lifetime: 8530.6820, mean_mc_travel_dist: 2668.9376, mean_rewards: 262.3948, total_rewards: 5896.2963, mean_steps: 32.1300, mean_ecr: 0.0299 mean_entropies: 0.6436, took: 154.7980s
2022-10-11 08:47:09,969 [INFO] 	Process 7 - batch 92099: mean_policy_losses: -362.588, mean_net_lifetime: 4695.9572, mean_mc_travel_dist: 1415.9667, mean_rewards: 206.0401, total_rewards: 3312.9168, mean_steps: 22.2800, mean_ecr: 0.0409 mean_entropies: 1.2383, took: 106.8743s
2022-10-11 08:47:12,749 [INFO] 	Process 6 - batch 133599: mean_policy_losses: -85.105, mean_net_lifetime: 3933.5206, mean_mc_travel_dist: 1063.6376, mean_rewards: 340.1286, total_rewards: 2942.6468, mean_steps: 10.5100, mean_ecr: 0.0549 mean_entropies: 0.1434, took: 750.1042s
2022-10-11 08:48:12,824 [INFO] 	Process 6 - batch 133699: mean_policy_losses: -79.957, mean_net_lifetime: 3944.9758, mean_mc_travel_dist: 1075.4354, mean_rewards: 339.7683, total_rewards: 2940.5151, mean_steps: 10.5800, mean_ecr: 0.0551 mean_entropies: 0.1644, took: 60.0737s
2022-10-11 08:48:18,637 [INFO] 	Process 3 - batch 100699: mean_policy_losses: -35.469, mean_net_lifetime: 5289.6576, mean_mc_travel_dist: 1309.3288, mean_rewards: 282.6146, total_rewards: 4007.8463, mean_steps: 17.7800, mean_ecr: 0.0460 mean_entropies: 0.4670, took: 95.3309s
2022-10-11 08:48:38,107 [INFO] 	Process 1 - batch 83399: mean_policy_losses: -8.953, mean_net_lifetime: 6593.7358, mean_mc_travel_dist: 2075.5337, mean_rewards: 259.1153, total_rewards: 4546.3251, mean_steps: 24.5600, mean_ecr: 0.0381 mean_entropies: 0.9141, took: 124.1973s
2022-10-11 08:48:40,361 [INFO] 	Process 4 - batch 95299: mean_policy_losses: 162.448, mean_net_lifetime: 9742.7832, mean_mc_travel_dist: 2935.7240, mean_rewards: 282.1738, total_rewards: 6833.4532, mean_steps: 37.6500, mean_ecr: 0.0415 mean_entropies: 0.5174, took: 178.7713s
2022-10-11 08:48:46,878 [INFO] 	Process 2 - batch 90099: mean_policy_losses: -20.481, mean_net_lifetime: 7410.4200, mean_mc_travel_dist: 1926.7715, mean_rewards: 281.0307, total_rewards: 5516.4247, mean_steps: 25.4900, mean_ecr: 0.0386 mean_entropies: 0.3664, took: 860.2370s
2022-10-11 08:49:00,411 [INFO] 	Process 7 - batch 92199: mean_policy_losses: -447.455, mean_net_lifetime: 4673.3510, mean_mc_travel_dist: 1448.0737, mean_rewards: 203.7484, total_rewards: 3257.8112, mean_steps: 22.1100, mean_ecr: 0.0411 mean_entropies: 1.2629, took: 110.4419s
2022-10-11 08:49:11,778 [INFO] 	Process 6 - batch 133799: mean_policy_losses: -141.044, mean_net_lifetime: 3921.9725, mean_mc_travel_dist: 1056.8736, mean_rewards: 341.0526, total_rewards: 2929.7073, mean_steps: 10.4500, mean_ecr: 0.0549 mean_entropies: 0.1590, took: 58.9548s
2022-10-11 08:49:50,969 [INFO] 	Process 5 - batch 84299: mean_policy_losses: -156.374, mean_net_lifetime: 9524.8332, mean_mc_travel_dist: 2948.9510, mean_rewards: 269.6664, total_rewards: 6619.7842, mean_steps: 35.1500, mean_ecr: 0.0297 mean_entropies: 0.6681, took: 174.9071s
2022-10-11 08:49:56,913 [INFO] 	Process 3 - batch 100799: mean_policy_losses: -30.866, mean_net_lifetime: 5389.7830, mean_mc_travel_dist: 1356.2027, mean_rewards: 281.9227, total_rewards: 4061.7996, mean_steps: 18.1700, mean_ecr: 0.0458 mean_entropies: 0.4820, took: 98.2759s
2022-10-11 08:50:09,038 [INFO] 	Process 6 - batch 133899: mean_policy_losses: -130.769, mean_net_lifetime: 3780.2866, mean_mc_travel_dist: 1025.8352, mean_rewards: 340.8146, total_rewards: 2820.5414, mean_steps: 10.0700, mean_ecr: 0.0552 mean_entropies: 0.1622, took: 57.2606s
2022-10-11 08:50:42,006 [INFO] 	Process 1 - batch 83499: mean_policy_losses: -24.008, mean_net_lifetime: 6635.9596, mean_mc_travel_dist: 2083.6920, mean_rewards: 259.8639, total_rewards: 4584.5808, mean_steps: 24.6100, mean_ecr: 0.0382 mean_entropies: 0.9285, took: 123.8988s
2022-10-11 08:50:49,522 [INFO] 	Process 7 - batch 92299: mean_policy_losses: -349.539, mean_net_lifetime: 4802.8407, mean_mc_travel_dist: 1478.6536, mean_rewards: 213.6585, total_rewards: 3358.4303, mean_steps: 21.5900, mean_ecr: 0.0411 mean_entropies: 1.2497, took: 109.1112s
2022-10-11 08:50:58,721 [INFO] 	Process 2 - batch 90199: mean_policy_losses: 2.437, mean_net_lifetime: 7601.1561, mean_mc_travel_dist: 1989.4506, mean_rewards: 283.0311, total_rewards: 5633.0188, mean_steps: 25.9000, mean_ecr: 0.0383 mean_entropies: 0.4044, took: 131.8430s
2022-10-11 08:51:07,982 [INFO] 	Process 6 - batch 133999: mean_policy_losses: -86.235, mean_net_lifetime: 3962.7790, mean_mc_travel_dist: 1068.5434, mean_rewards: 343.9408, total_rewards: 2967.7966, mean_steps: 10.5000, mean_ecr: 0.0549 mean_entropies: 0.1465, took: 58.9439s
2022-10-11 08:51:08,662 [INFO] 	Process 4 - batch 95399: mean_policy_losses: 193.383, mean_net_lifetime: 8164.2249, mean_mc_travel_dist: 2317.4932, mean_rewards: 287.2100, total_rewards: 5878.0303, mean_steps: 29.4100, mean_ecr: 0.0429 mean_entropies: 0.5546, took: 148.3004s
2022-10-11 08:51:30,850 [INFO] 	Process 3 - batch 100899: mean_policy_losses: -22.405, mean_net_lifetime: 5326.1114, mean_mc_travel_dist: 1357.5228, mean_rewards: 286.8064, total_rewards: 3994.0637, mean_steps: 17.6200, mean_ecr: 0.0457 mean_entropies: 0.4983, took: 93.9368s
2022-10-11 08:52:06,404 [INFO] 	Process 6 - batch 134099: mean_policy_losses: -130.073, mean_net_lifetime: 3804.8370, mean_mc_travel_dist: 1028.7355, mean_rewards: 341.6416, total_rewards: 2845.9107, mean_steps: 10.0600, mean_ecr: 0.0550 mean_entropies: 0.1479, took: 58.4212s
2022-10-11 08:52:22,901 [INFO] 	Process 5 - batch 84399: mean_policy_losses: -234.870, mean_net_lifetime: 8482.1926, mean_mc_travel_dist: 2634.2978, mean_rewards: 279.2732, total_rewards: 5888.3761, mean_steps: 30.2700, mean_ecr: 0.0300 mean_entropies: 0.6873, took: 151.9312s
2022-10-11 08:52:49,834 [INFO] 	Process 1 - batch 83599: mean_policy_losses: -54.955, mean_net_lifetime: 6620.5926, mean_mc_travel_dist: 2060.7684, mean_rewards: 253.4571, total_rewards: 4584.6214, mean_steps: 25.2300, mean_ecr: 0.0383 mean_entropies: 0.9355, took: 127.8279s
2022-10-11 08:52:56,165 [INFO] 	Process 7 - batch 92399: mean_policy_losses: -297.820, mean_net_lifetime: 5118.1787, mean_mc_travel_dist: 1580.1281, mean_rewards: 200.5956, total_rewards: 3567.8721, mean_steps: 24.9600, mean_ecr: 0.0406 mean_entropies: 1.2443, took: 126.6425s
2022-10-11 08:53:08,529 [INFO] 	Process 2 - batch 90299: mean_policy_losses: -16.328, mean_net_lifetime: 7370.8782, mean_mc_travel_dist: 1957.9813, mean_rewards: 284.5343, total_rewards: 5436.8556, mean_steps: 25.0300, mean_ecr: 0.0384 mean_entropies: 0.3864, took: 129.8077s
2022-10-11 08:53:08,911 [INFO] 	Process 6 - batch 134199: mean_policy_losses: -40.985, mean_net_lifetime: 4202.9732, mean_mc_travel_dist: 1129.7071, mean_rewards: 344.0821, total_rewards: 3129.0063, mean_steps: 11.2000, mean_ecr: 0.0549 mean_entropies: 0.1367, took: 62.5079s
2022-10-11 08:53:10,578 [INFO] 	Process 3 - batch 100999: mean_policy_losses: -52.381, mean_net_lifetime: 5401.3104, mean_mc_travel_dist: 1405.9420, mean_rewards: 276.9986, total_rewards: 4025.4252, mean_steps: 18.6300, mean_ecr: 0.0452 mean_entropies: 0.4690, took: 99.7269s
2022-10-11 08:54:07,906 [INFO] 	Process 6 - batch 134299: mean_policy_losses: -101.710, mean_net_lifetime: 3943.0421, mean_mc_travel_dist: 1058.4063, mean_rewards: 344.7111, total_rewards: 2949.4509, mean_steps: 10.4100, mean_ecr: 0.0548 mean_entropies: 0.1492, took: 58.9940s
2022-10-11 08:54:46,697 [INFO] 	Process 4 - batch 95499: mean_policy_losses: 184.374, mean_net_lifetime: 10969.9796, mean_mc_travel_dist: 3389.3335, mean_rewards: 274.6309, total_rewards: 7606.2724, mean_steps: 44.4900, mean_ecr: 0.0410 mean_entropies: 0.5113, took: 218.0356s
2022-10-11 08:54:48,058 [INFO] 	Process 3 - batch 101099: mean_policy_losses: -27.125, mean_net_lifetime: 5398.3002, mean_mc_travel_dist: 1378.4590, mean_rewards: 282.4444, total_rewards: 4051.9383, mean_steps: 18.1800, mean_ecr: 0.0453 mean_entropies: 0.4834, took: 97.4806s
2022-10-11 08:54:53,564 [INFO] 	Process 7 - batch 92499: mean_policy_losses: -344.005, mean_net_lifetime: 4877.7745, mean_mc_travel_dist: 1488.8140, mean_rewards: 204.8544, total_rewards: 3416.4188, mean_steps: 23.1800, mean_ecr: 0.0409 mean_entropies: 1.1921, took: 117.3990s
2022-10-11 08:54:57,291 [INFO] 	Process 1 - batch 83699: mean_policy_losses: -52.178, mean_net_lifetime: 6688.1290, mean_mc_travel_dist: 2093.3575, mean_rewards: 255.9309, total_rewards: 4624.1293, mean_steps: 25.2700, mean_ecr: 0.0382 mean_entropies: 0.9566, took: 127.4577s
2022-10-11 08:55:09,867 [INFO] 	Process 5 - batch 84499: mean_policy_losses: -196.250, mean_net_lifetime: 9315.3822, mean_mc_travel_dist: 2919.5963, mean_rewards: 272.6402, total_rewards: 6430.0301, mean_steps: 34.0000, mean_ecr: 0.0297 mean_entropies: 0.6625, took: 166.9653s
2022-10-11 08:55:10,297 [INFO] 	Process 6 - batch 134399: mean_policy_losses: -136.373, mean_net_lifetime: 4022.1774, mean_mc_travel_dist: 1088.4306, mean_rewards: 340.5309, total_rewards: 2995.6490, mean_steps: 10.7300, mean_ecr: 0.0551 mean_entropies: 0.1427, took: 62.3924s
2022-10-11 08:55:23,464 [INFO] 	Process 2 - batch 90399: mean_policy_losses: 0.657, mean_net_lifetime: 7630.2124, mean_mc_travel_dist: 2016.9894, mean_rewards: 284.5650, total_rewards: 5641.2316, mean_steps: 25.9000, mean_ecr: 0.0382 mean_entropies: 0.3863, took: 134.9339s
2022-10-11 08:56:10,176 [INFO] 	Process 6 - batch 134499: mean_policy_losses: -103.153, mean_net_lifetime: 3904.8795, mean_mc_travel_dist: 1044.4018, mean_rewards: 338.8676, total_rewards: 2919.1294, mean_steps: 10.4400, mean_ecr: 0.0552 mean_entropies: 0.1528, took: 59.8784s
2022-10-11 08:56:31,084 [INFO] 	Process 3 - batch 101199: mean_policy_losses: -53.978, mean_net_lifetime: 5507.5403, mean_mc_travel_dist: 1420.7602, mean_rewards: 272.3108, total_rewards: 4112.0661, mean_steps: 19.3100, mean_ecr: 0.0450 mean_entropies: 0.4764, took: 103.0271s
2022-10-11 08:56:57,283 [INFO] 	Process 7 - batch 92599: mean_policy_losses: -246.802, mean_net_lifetime: 5166.4480, mean_mc_travel_dist: 1572.1340, mean_rewards: 204.5341, total_rewards: 3627.6956, mean_steps: 24.4900, mean_ecr: 0.0407 mean_entropies: 1.2530, took: 123.7203s
2022-10-11 08:57:08,549 [INFO] 	Process 1 - batch 83799: mean_policy_losses: -47.681, mean_net_lifetime: 6595.1854, mean_mc_travel_dist: 2060.7816, mean_rewards: 247.0621, total_rewards: 4565.3744, mean_steps: 25.8400, mean_ecr: 0.0381 mean_entropies: 0.9363, took: 131.2576s
2022-10-11 08:57:08,698 [INFO] 	Process 6 - batch 134599: mean_policy_losses: -98.893, mean_net_lifetime: 3789.7669, mean_mc_travel_dist: 1040.3241, mean_rewards: 335.4457, total_rewards: 2817.3258, mean_steps: 10.2400, mean_ecr: 0.0553 mean_entropies: 0.1644, took: 58.5224s
2022-10-11 08:57:39,849 [INFO] 	Process 2 - batch 90499: mean_policy_losses: -5.517, mean_net_lifetime: 7637.4207, mean_mc_travel_dist: 2021.4127, mean_rewards: 280.9934, total_rewards: 5640.3963, mean_steps: 26.2500, mean_ecr: 0.0382 mean_entropies: 0.3856, took: 136.3862s
2022-10-11 08:57:54,809 [INFO] 	Process 5 - batch 84599: mean_policy_losses: -124.586, mean_net_lifetime: 8941.8246, mean_mc_travel_dist: 2766.4347, mean_rewards: 270.1888, total_rewards: 6211.9957, mean_steps: 32.9400, mean_ecr: 0.0298 mean_entropies: 0.6500, took: 164.9422s
2022-10-11 08:58:03,036 [INFO] 	Process 4 - batch 95599: mean_policy_losses: 185.561, mean_net_lifetime: 10135.6489, mean_mc_travel_dist: 3056.1562, mean_rewards: 276.6439, total_rewards: 7111.5697, mean_steps: 39.9900, mean_ecr: 0.0412 mean_entropies: 0.4888, took: 196.3394s
2022-10-11 08:58:11,120 [INFO] 	Process 6 - batch 134699: mean_policy_losses: -59.810, mean_net_lifetime: 4200.8584, mean_mc_travel_dist: 1123.9347, mean_rewards: 345.6640, total_rewards: 3123.6930, mean_steps: 11.1400, mean_ecr: 0.0548 mean_entropies: 0.1311, took: 62.4215s
2022-10-11 08:58:13,707 [INFO] 	Process 3 - batch 101299: mean_policy_losses: -29.869, mean_net_lifetime: 5409.2230, mean_mc_travel_dist: 1386.5362, mean_rewards: 268.3653, total_rewards: 4055.3692, mean_steps: 19.2700, mean_ecr: 0.0450 mean_entropies: 0.4793, took: 102.6227s
2022-10-11 08:59:09,675 [INFO] 	Process 7 - batch 92699: mean_policy_losses: -252.127, mean_net_lifetime: 5357.2605, mean_mc_travel_dist: 1629.8619, mean_rewards: 198.2618, total_rewards: 3762.6745, mean_steps: 26.4100, mean_ecr: 0.0404 mean_entropies: 1.2206, took: 132.3911s
2022-10-11 08:59:10,850 [INFO] 	Process 6 - batch 134799: mean_policy_losses: -68.089, mean_net_lifetime: 3981.6979, mean_mc_travel_dist: 1065.6090, mean_rewards: 344.3627, total_rewards: 2955.8370, mean_steps: 10.5400, mean_ecr: 0.0551 mean_entropies: 0.1439, took: 59.7298s
2022-10-11 08:59:22,106 [INFO] 	Process 1 - batch 83899: mean_policy_losses: -49.698, mean_net_lifetime: 6529.4555, mean_mc_travel_dist: 2022.2118, mean_rewards: 242.8168, total_rewards: 4537.5084, mean_steps: 26.1600, mean_ecr: 0.0383 mean_entropies: 0.9065, took: 133.5568s
2022-10-11 08:59:51,049 [INFO] 	Process 3 - batch 101399: mean_policy_losses: -38.060, mean_net_lifetime: 5363.1745, mean_mc_travel_dist: 1378.7455, mean_rewards: 276.0684, total_rewards: 4008.3139, mean_steps: 18.4800, mean_ecr: 0.0452 mean_entropies: 0.4838, took: 97.3422s
2022-10-11 08:59:59,974 [INFO] 	Process 2 - batch 90599: mean_policy_losses: 10.344, mean_net_lifetime: 7756.5315, mean_mc_travel_dist: 2063.9668, mean_rewards: 273.9625, total_rewards: 5712.0918, mean_steps: 27.3900, mean_ecr: 0.0380 mean_entropies: 0.3809, took: 140.1260s
2022-10-11 09:00:10,544 [INFO] 	Process 6 - batch 134899: mean_policy_losses: -105.466, mean_net_lifetime: 3885.7607, mean_mc_travel_dist: 1066.4958, mean_rewards: 338.9936, total_rewards: 2882.1927, mean_steps: 10.4400, mean_ecr: 0.0553 mean_entropies: 0.1499, took: 59.6930s
2022-10-11 09:00:46,262 [INFO] 	Process 5 - batch 84699: mean_policy_losses: -165.516, mean_net_lifetime: 9042.4928, mean_mc_travel_dist: 2806.2667, mean_rewards: 264.3854, total_rewards: 6276.2282, mean_steps: 34.0800, mean_ecr: 0.0299 mean_entropies: 0.6434, took: 171.4533s
2022-10-11 09:01:14,778 [INFO] 	Process 6 - batch 134999: mean_policy_losses: -32.117, mean_net_lifetime: 4303.1821, mean_mc_travel_dist: 1149.5848, mean_rewards: 345.9176, total_rewards: 3194.9510, mean_steps: 11.4200, mean_ecr: 0.0548 mean_entropies: 0.1151, took: 64.2357s
2022-10-11 09:01:15,689 [INFO] 	Process 4 - batch 95699: mean_policy_losses: 176.370, mean_net_lifetime: 10016.2111, mean_mc_travel_dist: 2981.6755, mean_rewards: 274.8449, total_rewards: 7063.4070, mean_steps: 39.0800, mean_ecr: 0.0402 mean_entropies: 0.4977, took: 192.6522s
2022-10-11 09:01:25,780 [INFO] 	Process 7 - batch 92799: mean_policy_losses: -262.231, mean_net_lifetime: 5451.3618, mean_mc_travel_dist: 1650.9817, mean_rewards: 194.5264, total_rewards: 3832.6231, mean_steps: 27.4500, mean_ecr: 0.0403 mean_entropies: 1.1824, took: 136.1047s
2022-10-11 09:01:28,292 [INFO] 	Process 1 - batch 83999: mean_policy_losses: -49.426, mean_net_lifetime: 6336.3967, mean_mc_travel_dist: 1957.9434, mean_rewards: 245.3200, total_rewards: 4403.4080, mean_steps: 25.0800, mean_ecr: 0.0384 mean_entropies: 0.8930, took: 126.1870s
2022-10-11 09:01:33,655 [INFO] 	Process 3 - batch 101499: mean_policy_losses: -22.388, mean_net_lifetime: 5453.4895, mean_mc_travel_dist: 1404.2750, mean_rewards: 272.6114, total_rewards: 4077.2761, mean_steps: 19.1100, mean_ecr: 0.0448 mean_entropies: 0.4524, took: 102.6047s
2022-10-11 09:02:10,824 [INFO] 	Process 2 - batch 90699: mean_policy_losses: -21.305, mean_net_lifetime: 7469.9725, mean_mc_travel_dist: 2013.6617, mean_rewards: 276.8460, total_rewards: 5480.4414, mean_steps: 26.1100, mean_ecr: 0.0382 mean_entropies: 0.4012, took: 130.8496s
2022-10-11 09:03:08,342 [INFO] 	Process 3 - batch 101599: mean_policy_losses: -45.912, mean_net_lifetime: 5365.0430, mean_mc_travel_dist: 1385.7615, mean_rewards: 273.8215, total_rewards: 4012.8507, mean_steps: 18.6400, mean_ecr: 0.0450 mean_entropies: 0.4605, took: 94.6879s
2022-10-11 09:03:20,723 [INFO] 	Process 5 - batch 84799: mean_policy_losses: -184.917, mean_net_lifetime: 8847.3436, mean_mc_travel_dist: 2736.5290, mean_rewards: 268.6030, total_rewards: 6142.1302, mean_steps: 32.5600, mean_ecr: 0.0299 mean_entropies: 0.6576, took: 154.4618s
2022-10-11 09:03:28,166 [INFO] 	Process 7 - batch 92899: mean_policy_losses: -234.159, mean_net_lifetime: 5335.7012, mean_mc_travel_dist: 1623.3767, mean_rewards: 202.7842, total_rewards: 3752.8369, mean_steps: 25.6300, mean_ecr: 0.0403 mean_entropies: 1.2194, took: 122.3867s
2022-10-11 09:04:03,524 [INFO] 	Process 4 - batch 95799: mean_policy_losses: 144.969, mean_net_lifetime: 9286.4516, mean_mc_travel_dist: 2728.6575, mean_rewards: 280.0079, total_rewards: 6587.8743, mean_steps: 35.1500, mean_ecr: 0.0408 mean_entropies: 0.4656, took: 167.8358s
2022-10-11 09:04:15,428 [INFO] 	Process 2 - batch 90799: mean_policy_losses: -24.470, mean_net_lifetime: 7394.6625, mean_mc_travel_dist: 1955.6357, mean_rewards: 281.5600, total_rewards: 5471.6202, mean_steps: 25.3800, mean_ecr: 0.0384 mean_entropies: 0.3691, took: 124.6034s
2022-10-11 09:04:42,985 [INFO] 	Process 3 - batch 101699: mean_policy_losses: -30.229, mean_net_lifetime: 5443.3227, mean_mc_travel_dist: 1377.5740, mean_rewards: 274.1211, total_rewards: 4096.6030, mean_steps: 18.9600, mean_ecr: 0.0452 mean_entropies: 0.4641, took: 94.6431s
2022-10-11 09:05:23,914 [INFO] 	Process 7 - batch 92999: mean_policy_losses: -281.123, mean_net_lifetime: 5225.1690, mean_mc_travel_dist: 1545.5981, mean_rewards: 209.0243, total_rewards: 3702.9908, mean_steps: 24.3200, mean_ecr: 0.0407 mean_entropies: 1.2114, took: 115.7475s
2022-10-11 09:05:45,885 [INFO] 	Process 5 - batch 84899: mean_policy_losses: -186.461, mean_net_lifetime: 8454.3652, mean_mc_travel_dist: 2660.4337, mean_rewards: 266.9791, total_rewards: 5838.5558, mean_steps: 31.2500, mean_ecr: 0.0299 mean_entropies: 0.6400, took: 145.1620s
2022-10-11 09:06:13,685 [INFO] 	Process 3 - batch 101799: mean_policy_losses: -44.639, mean_net_lifetime: 5509.8326, mean_mc_travel_dist: 1435.9117, mean_rewards: 275.9536, total_rewards: 4102.8332, mean_steps: 19.0400, mean_ecr: 0.0447 mean_entropies: 0.4649, took: 90.6994s
2022-10-11 09:06:16,398 [INFO] 	Process 2 - batch 90899: mean_policy_losses: -14.450, mean_net_lifetime: 7551.7310, mean_mc_travel_dist: 1987.0137, mean_rewards: 281.4932, total_rewards: 5593.5320, mean_steps: 25.9000, mean_ecr: 0.0383 mean_entropies: 0.3684, took: 120.9697s
2022-10-11 09:06:43,676 [INFO] 	Process 4 - batch 95899: mean_policy_losses: 119.660, mean_net_lifetime: 8924.5948, mean_mc_travel_dist: 2605.4140, mean_rewards: 278.9166, total_rewards: 6354.4633, mean_steps: 34.0700, mean_ecr: 0.0412 mean_entropies: 0.4617, took: 160.1515s
2022-10-11 09:07:42,037 [INFO] 	Process 3 - batch 101899: mean_policy_losses: -40.486, mean_net_lifetime: 5504.7631, mean_mc_travel_dist: 1442.3296, mean_rewards: 279.9611, total_rewards: 4085.8129, mean_steps: 18.7400, mean_ecr: 0.0447 mean_entropies: 0.4645, took: 88.3524s
2022-10-11 09:08:09,527 [INFO] 	Process 5 - batch 84999: mean_policy_losses: -179.157, mean_net_lifetime: 8773.6649, mean_mc_travel_dist: 2737.3475, mean_rewards: 271.6217, total_rewards: 6076.6532, mean_steps: 31.8800, mean_ecr: 0.0299 mean_entropies: 0.6508, took: 143.6422s
2022-10-11 09:08:16,118 [INFO] 	Process 2 - batch 90999: mean_policy_losses: 0.247, mean_net_lifetime: 7713.6985, mean_mc_travel_dist: 2029.9430, mean_rewards: 285.2849, total_rewards: 5703.7740, mean_steps: 26.1300, mean_ecr: 0.0381 mean_entropies: 0.3537, took: 119.7204s
2022-10-11 09:09:13,576 [INFO] 	Process 4 - batch 95999: mean_policy_losses: 140.041, mean_net_lifetime: 8849.2316, mean_mc_travel_dist: 2511.8897, mean_rewards: 277.1497, total_rewards: 6359.5942, mean_steps: 33.3800, mean_ecr: 0.0401 mean_entropies: 0.4873, took: 149.9004s
2022-10-11 09:09:15,119 [INFO] 	Process 3 - batch 101999: mean_policy_losses: -55.633, mean_net_lifetime: 5549.5388, mean_mc_travel_dist: 1461.2129, mean_rewards: 268.2629, total_rewards: 4113.2081, mean_steps: 19.8100, mean_ecr: 0.0442 mean_entropies: 0.4610, took: 93.0826s
2022-10-11 09:10:08,307 [INFO] 	Process 2 - batch 91099: mean_policy_losses: -10.684, mean_net_lifetime: 7509.1144, mean_mc_travel_dist: 1984.7756, mean_rewards: 284.0764, total_rewards: 5551.1395, mean_steps: 25.5900, mean_ecr: 0.0383 mean_entropies: 0.3619, took: 112.1891s
2022-10-11 09:10:21,630 [INFO] 	Process 5 - batch 85099: mean_policy_losses: -149.322, mean_net_lifetime: 8503.8054, mean_mc_travel_dist: 2657.5927, mean_rewards: 272.0894, total_rewards: 5888.6746, mean_steps: 30.7000, mean_ecr: 0.0298 mean_entropies: 0.6423, took: 132.1024s
2022-10-11 09:12:54,352 [INFO] 	Process 2 - batch 91199: mean_policy_losses: -18.256, mean_net_lifetime: 7617.5123, mean_mc_travel_dist: 2004.7419, mean_rewards: 284.3873, total_rewards: 5635.3093, mean_steps: 25.8700, mean_ecr: 0.0383 mean_entropies: 0.3951, took: 166.0447s
2022-10-11 09:12:59,853 [INFO] Process 1 - epoch 56: mean_policy_losses: 14.589, mean_net_lifetime: 5467.8686, mean_mc_travel_dist: 2042.4427, mean_entropies: 1.1305, m_net_lifetime_valid: 4620.9121, took: 2626.6440s, (168.0065 / 100 batches)

2022-10-11 09:12:59,951 [INFO] Process 6 - epoch 90: mean_policy_losses: -180.790, mean_net_lifetime: 3294.7112, mean_mc_travel_dist: 993.4387, mean_entropies: 0.4788, m_net_lifetime_valid: 4531.8247, took: 1606.5815s, (104.5740 / 100 batches)

2022-10-11 09:13:59,695 [INFO] 	Process 6 - batch 135099: mean_policy_losses: -92.032, mean_net_lifetime: 3901.5464, mean_mc_travel_dist: 1053.3257, mean_rewards: 341.5938, total_rewards: 2912.0549, mean_steps: 10.3900, mean_ecr: 0.0549 mean_entropies: 0.1593, took: 764.9164s
2022-10-11 09:14:05,858 [INFO] 	Process 5 - batch 85199: mean_policy_losses: -92.101, mean_net_lifetime: 10211.4735, mean_mc_travel_dist: 3184.6048, mean_rewards: 270.8784, total_rewards: 7067.1106, mean_steps: 37.5000, mean_ecr: 0.0294 mean_entropies: 0.6525, took: 224.2290s
2022-10-11 09:14:51,419 [INFO] 	Process 6 - batch 135199: mean_policy_losses: -118.248, mean_net_lifetime: 3744.0271, mean_mc_travel_dist: 1011.7079, mean_rewards: 341.7676, total_rewards: 2801.2454, mean_steps: 9.9200, mean_ecr: 0.0552 mean_entropies: 0.1582, took: 51.7239s
2022-10-11 09:15:00,373 [INFO] 	Process 1 - batch 84099: mean_policy_losses: -62.643, mean_net_lifetime: 6517.8704, mean_mc_travel_dist: 2016.0321, mean_rewards: 258.4473, total_rewards: 4520.3797, mean_steps: 24.3300, mean_ecr: 0.0384 mean_entropies: 0.9491, took: 812.0806s
2022-10-11 09:15:02,303 [INFO] 	Process 2 - batch 91299: mean_policy_losses: -18.039, mean_net_lifetime: 7503.2644, mean_mc_travel_dist: 1959.1140, mean_rewards: 288.8542, total_rewards: 5567.5121, mean_steps: 25.0500, mean_ecr: 0.0384 mean_entropies: 0.3929, took: 127.9516s
2022-10-11 09:15:43,981 [INFO] 	Process 6 - batch 135299: mean_policy_losses: -128.693, mean_net_lifetime: 3908.6418, mean_mc_travel_dist: 1056.6655, mean_rewards: 341.1384, total_rewards: 2916.5764, mean_steps: 10.3600, mean_ecr: 0.0550 mean_entropies: 0.1378, took: 52.5625s
2022-10-11 09:16:36,535 [INFO] 	Process 6 - batch 135399: mean_policy_losses: -137.318, mean_net_lifetime: 3863.6086, mean_mc_travel_dist: 1046.7851, mean_rewards: 342.0966, total_rewards: 2883.6740, mean_steps: 10.2500, mean_ecr: 0.0551 mean_entropies: 0.1391, took: 52.5533s
2022-10-11 09:16:51,851 [INFO] 	Process 1 - batch 84199: mean_policy_losses: -80.225, mean_net_lifetime: 6546.1934, mean_mc_travel_dist: 2077.4976, mean_rewards: 255.2472, total_rewards: 4492.3641, mean_steps: 24.8200, mean_ecr: 0.0382 mean_entropies: 0.9217, took: 111.4775s
2022-10-11 09:16:59,186 [INFO] 	Process 2 - batch 91399: mean_policy_losses: -34.816, mean_net_lifetime: 7423.0027, mean_mc_travel_dist: 1953.6575, mean_rewards: 286.2972, total_rewards: 5495.8046, mean_steps: 25.0400, mean_ecr: 0.0385 mean_entropies: 0.3843, took: 116.8816s
2022-10-11 09:17:03,716 [INFO] 	Process 5 - batch 85299: mean_policy_losses: -89.230, mean_net_lifetime: 10731.6599, mean_mc_travel_dist: 3351.9802, mean_rewards: 269.3020, total_rewards: 7421.0611, mean_steps: 40.1700, mean_ecr: 0.0294 mean_entropies: 0.6660, took: 177.8583s
2022-10-11 09:17:32,955 [INFO] 	Process 6 - batch 135499: mean_policy_losses: -80.058, mean_net_lifetime: 4144.7902, mean_mc_travel_dist: 1109.6746, mean_rewards: 344.3040, total_rewards: 3090.8112, mean_steps: 11.0100, mean_ecr: 0.0549 mean_entropies: 0.1274, took: 56.4201s
2022-10-11 09:18:15,057 [INFO] Process 7 - epoch 62: mean_policy_losses: -366.752, mean_net_lifetime: 4346.2016, mean_mc_travel_dist: 1551.7125, mean_entropies: 1.5112, m_net_lifetime_valid: 4578.8266, took: 2576.9777s, (152.0183 / 100 batches)

2022-10-11 09:18:27,295 [INFO] 	Process 6 - batch 135599: mean_policy_losses: -59.683, mean_net_lifetime: 3923.0104, mean_mc_travel_dist: 1061.4270, mean_rewards: 342.5553, total_rewards: 2916.1994, mean_steps: 10.4400, mean_ecr: 0.0550 mean_entropies: 0.1585, took: 54.3399s
2022-10-11 09:18:43,537 [INFO] 	Process 1 - batch 84299: mean_policy_losses: -43.652, mean_net_lifetime: 6630.7040, mean_mc_travel_dist: 2098.6833, mean_rewards: 259.4864, total_rewards: 4561.4366, mean_steps: 24.6300, mean_ecr: 0.0380 mean_entropies: 0.8966, took: 111.6862s
2022-10-11 09:19:04,016 [INFO] 	Process 2 - batch 91499: mean_policy_losses: 0.229, mean_net_lifetime: 7676.6888, mean_mc_travel_dist: 2023.5265, mean_rewards: 285.3832, total_rewards: 5671.6098, mean_steps: 25.9700, mean_ecr: 0.0381 mean_entropies: 0.3924, took: 124.8317s
2022-10-11 09:19:22,876 [INFO] 	Process 6 - batch 135699: mean_policy_losses: -126.773, mean_net_lifetime: 3990.5730, mean_mc_travel_dist: 1079.7170, mean_rewards: 342.1782, total_rewards: 2970.9305, mean_steps: 10.6000, mean_ecr: 0.0551 mean_entropies: 0.1394, took: 55.5814s
2022-10-11 09:19:38,926 [INFO] 	Process 5 - batch 85399: mean_policy_losses: -68.542, mean_net_lifetime: 9338.9041, mean_mc_travel_dist: 2887.6949, mean_rewards: 272.1249, total_rewards: 6493.6978, mean_steps: 33.9800, mean_ecr: 0.0297 mean_entropies: 0.6472, took: 155.2097s
2022-10-11 09:19:58,195 [INFO] Process 4 - epoch 64: mean_policy_losses: 110.021, mean_net_lifetime: 5113.7241, mean_mc_travel_dist: 1584.6642, mean_entropies: 1.0160, m_net_lifetime_valid: 4258.5908, took: 3369.9474s, (147.5116 / 100 batches)

2022-10-11 09:20:17,683 [INFO] 	Process 7 - batch 93099: mean_policy_losses: -176.407, mean_net_lifetime: 5134.3506, mean_mc_travel_dist: 1580.8478, mean_rewards: 195.0334, total_rewards: 3586.8724, mean_steps: 25.8500, mean_ecr: 0.0407 mean_entropies: 1.1503, took: 893.7701s
2022-10-11 09:20:18,959 [INFO] 	Process 6 - batch 135799: mean_policy_losses: -53.314, mean_net_lifetime: 4061.7804, mean_mc_travel_dist: 1105.5061, mean_rewards: 343.9211, total_rewards: 3024.4611, mean_steps: 10.7900, mean_ecr: 0.0548 mean_entropies: 0.1264, took: 56.0826s
2022-10-11 09:20:39,404 [INFO] 	Process 1 - batch 84399: mean_policy_losses: -37.822, mean_net_lifetime: 6600.3720, mean_mc_travel_dist: 2053.0441, mean_rewards: 256.1485, total_rewards: 4572.1856, mean_steps: 24.8500, mean_ecr: 0.0384 mean_entropies: 0.9531, took: 115.8668s
2022-10-11 09:20:44,262 [INFO] Process 3 - epoch 68: mean_policy_losses: 41.812, mean_net_lifetime: 4525.6505, mean_mc_travel_dist: 1341.4843, mean_entropies: 0.7817, m_net_lifetime_valid: 4595.9589, took: 2130.2881s, (138.8439 / 100 batches)

2022-10-11 09:21:15,920 [INFO] 	Process 6 - batch 135899: mean_policy_losses: -63.676, mean_net_lifetime: 3962.5856, mean_mc_travel_dist: 1086.2053, mean_rewards: 343.3589, total_rewards: 2951.8893, mean_steps: 10.5300, mean_ecr: 0.0550 mean_entropies: 0.1357, took: 56.9614s
2022-10-11 09:22:14,190 [INFO] 	Process 7 - batch 93199: mean_policy_losses: -330.124, mean_net_lifetime: 4867.3544, mean_mc_travel_dist: 1495.8031, mean_rewards: 201.3242, total_rewards: 3418.6979, mean_steps: 23.6200, mean_ecr: 0.0409 mean_entropies: 1.1815, took: 116.5068s
2022-10-11 09:22:15,307 [INFO] 	Process 6 - batch 135999: mean_policy_losses: -41.462, mean_net_lifetime: 4071.6214, mean_mc_travel_dist: 1124.9688, mean_rewards: 342.3521, total_rewards: 3017.0427, mean_steps: 10.8800, mean_ecr: 0.0551 mean_entropies: 0.1320, took: 59.3865s
2022-10-11 09:22:17,634 [INFO] 	Process 3 - batch 102099: mean_policy_losses: -39.460, mean_net_lifetime: 5366.1965, mean_mc_travel_dist: 1360.2294, mean_rewards: 280.4332, total_rewards: 4041.9800, mean_steps: 18.2300, mean_ecr: 0.0454 mean_entropies: 0.4801, took: 782.5140s
2022-10-11 09:22:26,408 [INFO] 	Process 4 - batch 96099: mean_policy_losses: 177.367, mean_net_lifetime: 7894.3161, mean_mc_travel_dist: 2285.3996, mean_rewards: 274.6722, total_rewards: 5636.0753, mean_steps: 30.0000, mean_ecr: 0.0423 mean_entropies: 0.4905, took: 792.8314s
2022-10-11 09:22:39,656 [INFO] 	Process 1 - batch 84499: mean_policy_losses: -49.470, mean_net_lifetime: 6457.6153, mean_mc_travel_dist: 1995.2507, mean_rewards: 253.5600, total_rewards: 4486.0691, mean_steps: 24.5900, mean_ecr: 0.0384 mean_entropies: 0.9749, took: 120.2522s
2022-10-11 09:22:54,292 [INFO] 	Process 5 - batch 85499: mean_policy_losses: -44.356, mean_net_lifetime: 11092.4612, mean_mc_travel_dist: 3450.9318, mean_rewards: 267.4691, total_rewards: 7697.5108, mean_steps: 41.8700, mean_ecr: 0.0292 mean_entropies: 0.6383, took: 195.3658s
2022-10-11 09:23:11,046 [INFO] 	Process 6 - batch 136099: mean_policy_losses: -127.757, mean_net_lifetime: 3827.2254, mean_mc_travel_dist: 1044.7214, mean_rewards: 340.2470, total_rewards: 2858.8026, mean_steps: 10.2000, mean_ecr: 0.0552 mean_entropies: 0.1413, took: 55.7392s
2022-10-11 09:23:49,878 [INFO] 	Process 3 - batch 102199: mean_policy_losses: -37.446, mean_net_lifetime: 5413.1541, mean_mc_travel_dist: 1380.7366, mean_rewards: 279.6508, total_rewards: 4071.0969, mean_steps: 18.4200, mean_ecr: 0.0453 mean_entropies: 0.4679, took: 92.2450s
2022-10-11 09:24:06,815 [INFO] 	Process 6 - batch 136199: mean_policy_losses: -97.697, mean_net_lifetime: 3960.7127, mean_mc_travel_dist: 1076.4504, mean_rewards: 343.9982, total_rewards: 2960.1784, mean_steps: 10.4900, mean_ecr: 0.0549 mean_entropies: 0.1389, took: 55.7686s
2022-10-11 09:24:12,995 [INFO] 	Process 7 - batch 93299: mean_policy_losses: -345.212, mean_net_lifetime: 4914.2822, mean_mc_travel_dist: 1481.4014, mean_rewards: 195.8188, total_rewards: 3466.2407, mean_steps: 24.6000, mean_ecr: 0.0407 mean_entropies: 1.1974, took: 118.8042s
2022-10-11 09:24:38,493 [INFO] 	Process 1 - batch 84599: mean_policy_losses: -42.514, mean_net_lifetime: 6539.6501, mean_mc_travel_dist: 2039.7537, mean_rewards: 253.5975, total_rewards: 4526.0255, mean_steps: 24.9500, mean_ecr: 0.0383 mean_entropies: 0.9624, took: 118.8369s
2022-10-11 09:24:59,495 [INFO] 	Process 6 - batch 136299: mean_policy_losses: -102.401, mean_net_lifetime: 3684.2055, mean_mc_travel_dist: 1001.4064, mean_rewards: 340.9774, total_rewards: 2748.5949, mean_steps: 9.7600, mean_ecr: 0.0553 mean_entropies: 0.1592, took: 52.6806s
2022-10-11 09:25:14,256 [INFO] 	Process 4 - batch 96199: mean_policy_losses: 147.166, mean_net_lifetime: 9136.1075, mean_mc_travel_dist: 2684.1672, mean_rewards: 273.1328, total_rewards: 6479.9552, mean_steps: 35.0300, mean_ecr: 0.0402 mean_entropies: 0.4828, took: 167.8483s
2022-10-11 09:25:24,704 [INFO] 	Process 3 - batch 102299: mean_policy_losses: -33.893, mean_net_lifetime: 5468.0007, mean_mc_travel_dist: 1366.4302, mean_rewards: 270.7657, total_rewards: 4124.1681, mean_steps: 19.3000, mean_ecr: 0.0452 mean_entropies: 0.4627, took: 94.8253s
2022-10-11 09:25:55,252 [INFO] 	Process 6 - batch 136399: mean_policy_losses: -88.579, mean_net_lifetime: 4028.9797, mean_mc_travel_dist: 1095.3641, mean_rewards: 342.6692, total_rewards: 2991.9814, mean_steps: 10.7500, mean_ecr: 0.0550 mean_entropies: 0.1189, took: 55.7572s
2022-10-11 09:26:19,880 [INFO] 	Process 7 - batch 93399: mean_policy_losses: -289.380, mean_net_lifetime: 5247.7992, mean_mc_travel_dist: 1592.0798, mean_rewards: 195.5182, total_rewards: 3688.9625, mean_steps: 26.2400, mean_ecr: 0.0405 mean_entropies: 1.2491, took: 126.8848s
2022-10-11 09:26:38,986 [INFO] 	Process 1 - batch 84699: mean_policy_losses: 2.037, mean_net_lifetime: 6584.8713, mean_mc_travel_dist: 1985.2696, mean_rewards: 249.3987, total_rewards: 4617.2307, mean_steps: 25.5500, mean_ecr: 0.0386 mean_entropies: 0.9970, took: 120.4927s
2022-10-11 09:26:52,852 [INFO] 	Process 6 - batch 136499: mean_policy_losses: -106.782, mean_net_lifetime: 4040.3517, mean_mc_travel_dist: 1084.2506, mean_rewards: 343.7421, total_rewards: 3011.1858, mean_steps: 10.7100, mean_ecr: 0.0551 mean_entropies: 0.1352, took: 57.5993s
2022-10-11 09:26:56,868 [INFO] 	Process 3 - batch 102399: mean_policy_losses: -22.550, mean_net_lifetime: 5424.7822, mean_mc_travel_dist: 1386.6252, mean_rewards: 277.8039, total_rewards: 4067.1478, mean_steps: 18.6100, mean_ecr: 0.0450 mean_entropies: 0.4935, took: 92.1637s
2022-10-11 09:28:32,721 [INFO] 	Process 7 - batch 93499: mean_policy_losses: -260.573, mean_net_lifetime: 5410.7747, mean_mc_travel_dist: 1671.6555, mean_rewards: 196.0936, total_rewards: 3766.3476, mean_steps: 27.2800, mean_ecr: 0.0405 mean_entropies: 1.2631, took: 132.8412s
2022-10-11 09:28:37,421 [INFO] 	Process 3 - batch 102499: mean_policy_losses: -39.116, mean_net_lifetime: 5450.2100, mean_mc_travel_dist: 1427.6754, mean_rewards: 277.0075, total_rewards: 4060.6500, mean_steps: 18.7500, mean_ecr: 0.0447 mean_entropies: 0.4605, took: 100.5525s
2022-10-11 09:28:59,756 [INFO] 	Process 1 - batch 84799: mean_policy_losses: -44.275, mean_net_lifetime: 6482.7318, mean_mc_travel_dist: 1964.4249, mean_rewards: 242.2577, total_rewards: 4539.4730, mean_steps: 25.9100, mean_ecr: 0.0386 mean_entropies: 0.9508, took: 140.7704s
2022-10-11 09:29:31,293 [INFO] 	Process 4 - batch 96299: mean_policy_losses: 145.735, mean_net_lifetime: 12228.7550, mean_mc_travel_dist: 3802.2377, mean_rewards: 259.4485, total_rewards: 8449.0309, mean_steps: 51.2200, mean_ecr: 0.0365 mean_entropies: 0.5378, took: 257.0368s
2022-10-11 09:30:56,778 [INFO] 	Process 3 - batch 102599: mean_policy_losses: -42.297, mean_net_lifetime: 5142.6201, mean_mc_travel_dist: 1322.4298, mean_rewards: 272.7785, total_rewards: 3847.0989, mean_steps: 17.9200, mean_ecr: 0.0454 mean_entropies: 0.4720, took: 139.3572s
2022-10-11 09:31:17,899 [INFO] 	Process 7 - batch 93599: mean_policy_losses: -347.696, mean_net_lifetime: 4956.8706, mean_mc_travel_dist: 1489.2562, mean_rewards: 202.5977, total_rewards: 3504.8203, mean_steps: 23.9500, mean_ecr: 0.0408 mean_entropies: 1.2030, took: 165.1785s
2022-10-11 09:31:32,225 [INFO] Process 2 - epoch 61: mean_policy_losses: -0.224, mean_net_lifetime: 5411.6571, mean_mc_travel_dist: 1705.4848, mean_entropies: 0.8125, m_net_lifetime_valid: 4480.6663, took: 2694.7150s, (155.4032 / 100 batches)

2022-10-11 09:31:32,665 [INFO] 	Process 1 - batch 84899: mean_policy_losses: 13.837, mean_net_lifetime: 6512.3593, mean_mc_travel_dist: 2041.5400, mean_rewards: 254.1262, total_rewards: 4494.5787, mean_steps: 24.7600, mean_ecr: 0.0382 mean_entropies: 0.8676, took: 152.9090s
2022-10-11 09:32:27,345 [INFO] 	Process 3 - batch 102699: mean_policy_losses: -18.892, mean_net_lifetime: 5306.7632, mean_mc_travel_dist: 1341.5409, mean_rewards: 274.0214, total_rewards: 3994.7536, mean_steps: 18.4400, mean_ecr: 0.0454 mean_entropies: 0.4662, took: 90.5684s
2022-10-11 09:33:22,223 [INFO] 	Process 7 - batch 93699: mean_policy_losses: -376.923, mean_net_lifetime: 5311.1946, mean_mc_travel_dist: 1618.1111, mean_rewards: 195.9656, total_rewards: 3725.0300, mean_steps: 26.5800, mean_ecr: 0.0404 mean_entropies: 1.2315, took: 124.3238s
2022-10-11 09:33:33,333 [INFO] 	Process 1 - batch 84999: mean_policy_losses: -54.507, mean_net_lifetime: 6441.1124, mean_mc_travel_dist: 1991.4517, mean_rewards: 241.2981, total_rewards: 4479.8170, mean_steps: 25.8700, mean_ecr: 0.0382 mean_entropies: 0.9139, took: 120.6674s
2022-10-11 09:33:34,040 [INFO] 	Process 2 - batch 91599: mean_policy_losses: -36.496, mean_net_lifetime: 7243.9189, mean_mc_travel_dist: 1908.9207, mean_rewards: 278.0577, total_rewards: 5363.7553, mean_steps: 25.1300, mean_ecr: 0.0386 mean_entropies: 0.3579, took: 870.0229s
2022-10-11 09:33:34,736 [INFO] 	Process 4 - batch 96399: mean_policy_losses: 115.269, mean_net_lifetime: 11651.6412, mean_mc_travel_dist: 3646.0255, mean_rewards: 269.9151, total_rewards: 8029.4259, mean_steps: 47.3800, mean_ecr: 0.0381 mean_entropies: 0.4918, took: 243.4436s
2022-10-11 09:33:57,403 [INFO] 	Process 3 - batch 102799: mean_policy_losses: -24.188, mean_net_lifetime: 5432.5262, mean_mc_travel_dist: 1389.0417, mean_rewards: 280.5139, total_rewards: 4073.0917, mean_steps: 18.4300, mean_ecr: 0.0451 mean_entropies: 0.4860, took: 90.0571s
2022-10-11 09:34:21,259 [INFO] Process 5 - epoch 57: mean_policy_losses: -189.919, mean_net_lifetime: 5941.5021, mean_mc_travel_dist: 2185.5402, mean_entropies: 1.0825, m_net_lifetime_valid: 4476.8029, took: 3199.8173s, (166.5648 / 100 batches)

2022-10-11 09:35:13,215 [INFO] 	Process 7 - batch 93799: mean_policy_losses: -411.667, mean_net_lifetime: 4943.3030, mean_mc_travel_dist: 1512.5316, mean_rewards: 206.9172, total_rewards: 3460.3306, mean_steps: 22.9300, mean_ecr: 0.0409 mean_entropies: 1.2694, took: 110.9919s
2022-10-11 09:35:28,092 [INFO] 	Process 3 - batch 102899: mean_policy_losses: -31.996, mean_net_lifetime: 5375.1322, mean_mc_travel_dist: 1383.1687, mean_rewards: 284.7526, total_rewards: 4027.5080, mean_steps: 17.9400, mean_ecr: 0.0452 mean_entropies: 0.4987, took: 90.6890s
2022-10-11 09:35:32,950 [INFO] 	Process 1 - batch 85099: mean_policy_losses: -57.903, mean_net_lifetime: 6470.3375, mean_mc_travel_dist: 2025.6069, mean_rewards: 251.8961, total_rewards: 4467.8972, mean_steps: 24.8300, mean_ecr: 0.0383 mean_entropies: 0.9211, took: 119.6160s
2022-10-11 09:35:41,687 [INFO] 	Process 2 - batch 91699: mean_policy_losses: -7.112, mean_net_lifetime: 7605.6850, mean_mc_travel_dist: 2011.1006, mean_rewards: 284.3468, total_rewards: 5620.7523, mean_steps: 25.8500, mean_ecr: 0.0384 mean_entropies: 0.3948, took: 127.6475s
2022-10-11 09:37:07,457 [INFO] 	Process 3 - batch 102999: mean_policy_losses: -12.708, mean_net_lifetime: 5482.1191, mean_mc_travel_dist: 1413.7511, mean_rewards: 279.6988, total_rewards: 4098.6731, mean_steps: 18.6400, mean_ecr: 0.0449 mean_entropies: 0.4687, took: 99.3656s
2022-10-11 09:37:10,904 [INFO] 	Process 7 - batch 93899: mean_policy_losses: -362.073, mean_net_lifetime: 5012.1594, mean_mc_travel_dist: 1511.8027, mean_rewards: 204.3106, total_rewards: 3535.6994, mean_steps: 23.7500, mean_ecr: 0.0406 mean_entropies: 1.2746, took: 117.6893s
2022-10-11 09:37:23,287 [INFO] 	Process 5 - batch 85599: mean_policy_losses: -166.524, mean_net_lifetime: 9906.3284, mean_mc_travel_dist: 3114.4540, mean_rewards: 263.0073, total_rewards: 6841.4695, mean_steps: 38.2300, mean_ecr: 0.0294 mean_entropies: 0.6340, took: 868.9954s
2022-10-11 09:37:33,313 [INFO] 	Process 4 - batch 96499: mean_policy_losses: 130.870, mean_net_lifetime: 12568.1619, mean_mc_travel_dist: 3979.2913, mean_rewards: 274.7992, total_rewards: 8620.3421, mean_steps: 51.3800, mean_ecr: 0.0397 mean_entropies: 0.5235, took: 238.5757s
2022-10-11 09:37:34,565 [INFO] 	Process 1 - batch 85199: mean_policy_losses: -20.226, mean_net_lifetime: 6366.3730, mean_mc_travel_dist: 1962.4909, mean_rewards: 248.1981, total_rewards: 4429.0301, mean_steps: 24.8300, mean_ecr: 0.0385 mean_entropies: 0.8775, took: 121.6171s
2022-10-11 09:37:43,428 [INFO] 	Process 2 - batch 91799: mean_policy_losses: -44.909, mean_net_lifetime: 7059.0999, mean_mc_travel_dist: 1856.5848, mean_rewards: 278.6127, total_rewards: 5231.6582, mean_steps: 24.4400, mean_ecr: 0.0388 mean_entropies: 0.3652, took: 121.7413s
2022-10-11 09:38:42,435 [INFO] 	Process 3 - batch 103099: mean_policy_losses: -15.893, mean_net_lifetime: 5409.8245, mean_mc_travel_dist: 1385.4835, mean_rewards: 283.8023, total_rewards: 4052.9668, mean_steps: 18.1200, mean_ecr: 0.0452 mean_entropies: 0.4870, took: 94.9782s
2022-10-11 09:38:47,474 [INFO] Process 6 - epoch 91: mean_policy_losses: -179.847, mean_net_lifetime: 3301.8123, mean_mc_travel_dist: 994.2714, mean_entropies: 0.4751, m_net_lifetime_valid: 4134.8811, took: 1547.5192s, (104.5517 / 100 batches)

2022-10-11 09:39:02,101 [INFO] 	Process 7 - batch 93999: mean_policy_losses: -319.222, mean_net_lifetime: 4775.1984, mean_mc_travel_dist: 1446.0446, mean_rewards: 204.6035, total_rewards: 3366.4492, mean_steps: 22.7800, mean_ecr: 0.0408 mean_entropies: 1.2230, took: 111.1967s
2022-10-11 09:39:37,946 [INFO] 	Process 1 - batch 85299: mean_policy_losses: -18.661, mean_net_lifetime: 6379.6300, mean_mc_travel_dist: 2001.7878, mean_rewards: 246.7688, total_rewards: 4406.7940, mean_steps: 24.9900, mean_ecr: 0.0383 mean_entropies: 0.8771, took: 123.3806s
2022-10-11 09:39:41,828 [INFO] 	Process 6 - batch 136599: mean_policy_losses: -70.397, mean_net_lifetime: 3543.9013, mean_mc_travel_dist: 970.3417, mean_rewards: 338.5963, total_rewards: 2621.5370, mean_steps: 9.4400, mean_ecr: 0.0559 mean_entropies: 0.1833, took: 768.9764s
2022-10-11 09:39:56,878 [INFO] 	Process 2 - batch 91899: mean_policy_losses: 0.367, mean_net_lifetime: 7543.2286, mean_mc_travel_dist: 1994.1677, mean_rewards: 276.4609, total_rewards: 5578.1042, mean_steps: 26.3800, mean_ecr: 0.0383 mean_entropies: 0.3684, took: 133.4498s
2022-10-11 09:40:20,889 [INFO] 	Process 3 - batch 103199: mean_policy_losses: 14.368, mean_net_lifetime: 5384.9229, mean_mc_travel_dist: 1384.3157, mean_rewards: 275.0343, total_rewards: 4040.8720, mean_steps: 18.6600, mean_ecr: 0.0449 mean_entropies: 0.4968, took: 98.4529s
2022-10-11 09:40:24,828 [INFO] 	Process 5 - batch 85699: mean_policy_losses: -94.648, mean_net_lifetime: 9575.3819, mean_mc_travel_dist: 2981.7138, mean_rewards: 260.3223, total_rewards: 6631.8372, mean_steps: 36.8300, mean_ecr: 0.0293 mean_entropies: 0.6034, took: 181.5405s
2022-10-11 09:40:41,867 [INFO] 	Process 6 - batch 136699: mean_policy_losses: -59.320, mean_net_lifetime: 3990.4575, mean_mc_travel_dist: 1074.3541, mean_rewards: 345.0707, total_rewards: 2972.1225, mean_steps: 10.5500, mean_ecr: 0.0551 mean_entropies: 0.1376, took: 60.0381s
2022-10-11 09:41:00,225 [INFO] 	Process 7 - batch 94099: mean_policy_losses: -295.445, mean_net_lifetime: 4857.5203, mean_mc_travel_dist: 1491.3559, mean_rewards: 203.7662, total_rewards: 3395.2836, mean_steps: 23.1900, mean_ecr: 0.0409 mean_entropies: 1.2505, took: 118.1241s
2022-10-11 09:41:00,291 [INFO] 	Process 4 - batch 96599: mean_policy_losses: 86.041, mean_net_lifetime: 10363.3742, mean_mc_travel_dist: 3267.7333, mean_rewards: 277.7184, total_rewards: 7122.7454, mean_steps: 43.1500, mean_ecr: 0.0439 mean_entropies: 0.5440, took: 206.9791s
2022-10-11 09:41:40,640 [INFO] 	Process 6 - batch 136799: mean_policy_losses: -56.356, mean_net_lifetime: 3929.8242, mean_mc_travel_dist: 1073.9151, mean_rewards: 341.8776, total_rewards: 2912.2974, mean_steps: 10.4600, mean_ecr: 0.0553 mean_entropies: 0.1477, took: 58.7736s
2022-10-11 09:41:50,897 [INFO] 	Process 1 - batch 85399: mean_policy_losses: -1.113, mean_net_lifetime: 6852.7911, mean_mc_travel_dist: 2123.2168, mean_rewards: 248.7216, total_rewards: 4760.4215, mean_steps: 26.6600, mean_ecr: 0.0380 mean_entropies: 0.8820, took: 132.9511s
2022-10-11 09:41:59,917 [INFO] 	Process 3 - batch 103299: mean_policy_losses: -25.954, mean_net_lifetime: 5455.1715, mean_mc_travel_dist: 1390.9905, mean_rewards: 277.3544, total_rewards: 4097.4054, mean_steps: 18.7900, mean_ecr: 0.0449 mean_entropies: 0.4715, took: 99.0291s
2022-10-11 09:42:15,779 [INFO] 	Process 2 - batch 91999: mean_policy_losses: -6.861, mean_net_lifetime: 7689.0320, mean_mc_travel_dist: 2026.1124, mean_rewards: 282.4848, total_rewards: 5683.2688, mean_steps: 26.3100, mean_ecr: 0.0382 mean_entropies: 0.3797, took: 138.9006s
2022-10-11 09:43:12,643 [INFO] 	Process 6 - batch 136899: mean_policy_losses: -92.302, mean_net_lifetime: 4051.4055, mean_mc_travel_dist: 1094.2376, mean_rewards: 341.9426, total_rewards: 3012.1121, mean_steps: 10.7800, mean_ecr: 0.0551 mean_entropies: 0.1428, took: 92.0030s
2022-10-11 09:43:32,179 [INFO] 	Process 7 - batch 94199: mean_policy_losses: -274.212, mean_net_lifetime: 5108.9423, mean_mc_travel_dist: 1577.0150, mean_rewards: 211.2944, total_rewards: 3563.4478, mean_steps: 23.6800, mean_ecr: 0.0408 mean_entropies: 1.2375, took: 151.9542s
2022-10-11 09:43:42,884 [INFO] 	Process 5 - batch 85799: mean_policy_losses: -158.951, mean_net_lifetime: 8951.7365, mean_mc_travel_dist: 2766.5473, mean_rewards: 266.9532, total_rewards: 6231.8487, mean_steps: 33.2900, mean_ecr: 0.0299 mean_entropies: 0.6201, took: 198.0565s
2022-10-11 09:44:10,026 [INFO] 	Process 3 - batch 103399: mean_policy_losses: -41.722, mean_net_lifetime: 5384.9915, mean_mc_travel_dist: 1395.1074, mean_rewards: 274.8979, total_rewards: 4025.4045, mean_steps: 18.6600, mean_ecr: 0.0448 mean_entropies: 0.4576, took: 130.1089s
2022-10-11 09:44:11,905 [INFO] 	Process 6 - batch 136999: mean_policy_losses: -86.000, mean_net_lifetime: 4002.0432, mean_mc_travel_dist: 1082.4224, mean_rewards: 342.8266, total_rewards: 2993.8265, mean_steps: 10.6300, mean_ecr: 0.0549 mean_entropies: 0.1321, took: 59.2620s
2022-10-11 09:44:31,958 [INFO] 	Process 1 - batch 85499: mean_policy_losses: -45.266, mean_net_lifetime: 6533.0509, mean_mc_travel_dist: 2008.0633, mean_rewards: 244.4449, total_rewards: 4551.9109, mean_steps: 25.8200, mean_ecr: 0.0384 mean_entropies: 0.9477, took: 161.0610s
2022-10-11 09:44:49,004 [INFO] 	Process 4 - batch 96699: mean_policy_losses: 184.650, mean_net_lifetime: 10074.8689, mean_mc_travel_dist: 3045.1596, mean_rewards: 269.6617, total_rewards: 7057.3043, mean_steps: 40.1000, mean_ecr: 0.0395 mean_entropies: 0.5240, took: 228.7122s
2022-10-11 09:45:01,436 [INFO] 	Process 2 - batch 92099: mean_policy_losses: -19.745, mean_net_lifetime: 7608.3050, mean_mc_travel_dist: 2018.8612, mean_rewards: 278.0184, total_rewards: 5608.0003, mean_steps: 26.4500, mean_ecr: 0.0381 mean_entropies: 0.3805, took: 165.6560s
2022-10-11 09:45:11,029 [INFO] 	Process 6 - batch 137099: mean_policy_losses: -96.900, mean_net_lifetime: 3991.6707, mean_mc_travel_dist: 1081.7032, mean_rewards: 340.8092, total_rewards: 2970.1045, mean_steps: 10.6200, mean_ecr: 0.0551 mean_entropies: 0.1332, took: 59.1251s
2022-10-11 09:45:33,872 [INFO] 	Process 7 - batch 94299: mean_policy_losses: -323.492, mean_net_lifetime: 5150.9260, mean_mc_travel_dist: 1593.0239, mean_rewards: 206.1840, total_rewards: 3585.2425, mean_steps: 24.4900, mean_ecr: 0.0405 mean_entropies: 1.2406, took: 121.6927s
2022-10-11 09:45:46,994 [INFO] 	Process 3 - batch 103499: mean_policy_losses: -25.159, mean_net_lifetime: 5487.6902, mean_mc_travel_dist: 1393.3961, mean_rewards: 275.3953, total_rewards: 4129.3844, mean_steps: 19.0500, mean_ecr: 0.0449 mean_entropies: 0.4497, took: 96.9682s
2022-10-11 09:46:08,304 [INFO] 	Process 6 - batch 137199: mean_policy_losses: -80.449, mean_net_lifetime: 3973.3207, mean_mc_travel_dist: 1087.0001, mean_rewards: 342.0843, total_rewards: 2958.7530, mean_steps: 10.5700, mean_ecr: 0.0550 mean_entropies: 0.1395, took: 57.2737s
2022-10-11 09:47:00,134 [INFO] 	Process 5 - batch 85899: mean_policy_losses: -99.846, mean_net_lifetime: 10797.3069, mean_mc_travel_dist: 3310.0483, mean_rewards: 264.1069, total_rewards: 7529.9551, mean_steps: 41.4800, mean_ecr: 0.0294 mean_entropies: 0.6363, took: 197.2502s
2022-10-11 09:47:08,313 [INFO] 	Process 2 - batch 92199: mean_policy_losses: -22.023, mean_net_lifetime: 7579.5257, mean_mc_travel_dist: 1979.5551, mean_rewards: 284.9480, total_rewards: 5618.4946, mean_steps: 25.6500, mean_ecr: 0.0383 mean_entropies: 0.3694, took: 126.8786s
2022-10-11 09:47:09,496 [INFO] 	Process 6 - batch 137299: mean_policy_losses: -32.986, mean_net_lifetime: 4265.1397, mean_mc_travel_dist: 1153.7568, mean_rewards: 344.3988, total_rewards: 3178.9534, mean_steps: 11.3700, mean_ecr: 0.0547 mean_entropies: 0.1205, took: 61.1926s
2022-10-11 09:47:39,791 [INFO] 	Process 7 - batch 94399: mean_policy_losses: -281.023, mean_net_lifetime: 5469.7323, mean_mc_travel_dist: 1643.2672, mean_rewards: 200.1509, total_rewards: 3860.8031, mean_steps: 26.6900, mean_ecr: 0.0403 mean_entropies: 1.2408, took: 125.9191s
2022-10-11 09:48:05,593 [INFO] 	Process 6 - batch 137399: mean_policy_losses: -74.339, mean_net_lifetime: 4001.4109, mean_mc_travel_dist: 1088.9376, mean_rewards: 342.8587, total_rewards: 2985.8973, mean_steps: 10.6400, mean_ecr: 0.0552 mean_entropies: 0.1350, took: 56.0975s
2022-10-11 09:48:15,092 [INFO] 	Process 4 - batch 96799: mean_policy_losses: 147.149, mean_net_lifetime: 11104.3088, mean_mc_travel_dist: 3454.9292, mean_rewards: 265.8648, total_rewards: 7668.9837, mean_steps: 44.7200, mean_ecr: 0.0385 mean_entropies: 0.5119, took: 206.0885s
2022-10-11 09:49:01,335 [INFO] 	Process 6 - batch 137499: mean_policy_losses: -53.395, mean_net_lifetime: 3992.6488, mean_mc_travel_dist: 1085.0124, mean_rewards: 341.8231, total_rewards: 2968.0922, mean_steps: 10.6400, mean_ecr: 0.0553 mean_entropies: 0.1271, took: 55.7407s
2022-10-11 09:49:14,814 [INFO] 	Process 2 - batch 92299: mean_policy_losses: -18.452, mean_net_lifetime: 7544.7894, mean_mc_travel_dist: 1987.1174, mean_rewards: 281.4685, total_rewards: 5578.6536, mean_steps: 25.8800, mean_ecr: 0.0383 mean_entropies: 0.3749, took: 126.5002s
2022-10-11 09:49:37,877 [INFO] 	Process 7 - batch 94499: mean_policy_losses: -246.752, mean_net_lifetime: 5309.2687, mean_mc_travel_dist: 1616.5016, mean_rewards: 202.0098, total_rewards: 3717.2747, mean_steps: 25.3200, mean_ecr: 0.0407 mean_entropies: 1.2545, took: 118.0863s
2022-10-11 09:50:01,255 [INFO] 	Process 5 - batch 85999: mean_policy_losses: -118.809, mean_net_lifetime: 10126.2927, mean_mc_travel_dist: 3117.3132, mean_rewards: 259.8422, total_rewards: 7050.1751, mean_steps: 39.0300, mean_ecr: 0.0293 mean_entropies: 0.6497, took: 181.1198s
2022-10-11 09:50:01,503 [INFO] 	Process 6 - batch 137599: mean_policy_losses: -7.030, mean_net_lifetime: 4405.1240, mean_mc_travel_dist: 1194.2587, mean_rewards: 345.7009, total_rewards: 3280.4383, mean_steps: 11.7400, mean_ecr: 0.0547 mean_entropies: 0.1060, took: 60.1680s
2022-10-11 09:50:58,483 [INFO] 	Process 6 - batch 137699: mean_policy_losses: -53.401, mean_net_lifetime: 4191.4427, mean_mc_travel_dist: 1142.5404, mean_rewards: 344.2368, total_rewards: 3121.6818, mean_steps: 11.1600, mean_ecr: 0.0548 mean_entropies: 0.1211, took: 56.9806s
2022-10-11 09:51:22,733 [INFO] 	Process 2 - batch 92399: mean_policy_losses: -49.569, mean_net_lifetime: 7299.2932, mean_mc_travel_dist: 1913.0483, mean_rewards: 282.3489, total_rewards: 5409.9304, mean_steps: 24.9000, mean_ecr: 0.0386 mean_entropies: 0.3500, took: 127.9189s
2022-10-11 09:52:22,636 [INFO] 	Process 6 - batch 137799: mean_policy_losses: -92.179, mean_net_lifetime: 3883.8704, mean_mc_travel_dist: 1072.0634, mean_rewards: 340.6360, total_rewards: 2882.4607, mean_steps: 10.3600, mean_ecr: 0.0554 mean_entropies: 0.1402, took: 84.1533s
2022-10-11 09:52:30,487 [INFO] 	Process 4 - batch 96899: mean_policy_losses: 159.821, mean_net_lifetime: 12211.9640, mean_mc_travel_dist: 3888.1854, mean_rewards: 266.2432, total_rewards: 8363.2196, mean_steps: 50.5500, mean_ecr: 0.0377 mean_entropies: 0.5016, took: 255.3955s
2022-10-11 09:53:18,858 [INFO] 	Process 6 - batch 137899: mean_policy_losses: -44.828, mean_net_lifetime: 4213.9543, mean_mc_travel_dist: 1136.5613, mean_rewards: 344.7166, total_rewards: 3135.3990, mean_steps: 11.2100, mean_ecr: 0.0548 mean_entropies: 0.1205, took: 56.2216s
2022-10-11 09:53:32,197 [INFO] 	Process 5 - batch 86099: mean_policy_losses: -134.935, mean_net_lifetime: 10395.0418, mean_mc_travel_dist: 3217.7879, mean_rewards: 261.8086, total_rewards: 7219.9647, mean_steps: 40.2000, mean_ecr: 0.0293 mean_entropies: 0.6188, took: 210.9430s
2022-10-11 09:53:44,357 [INFO] 	Process 2 - batch 92499: mean_policy_losses: -29.765, mean_net_lifetime: 7341.2613, mean_mc_travel_dist: 1929.4262, mean_rewards: 280.3667, total_rewards: 5438.4622, mean_steps: 25.2400, mean_ecr: 0.0385 mean_entropies: 0.3504, took: 141.6243s
2022-10-11 09:54:14,685 [INFO] 	Process 6 - batch 137999: mean_policy_losses: -68.881, mean_net_lifetime: 4084.1715, mean_mc_travel_dist: 1111.1193, mean_rewards: 343.6929, total_rewards: 3050.0433, mean_steps: 10.8600, mean_ecr: 0.0548 mean_entropies: 0.1286, took: 55.8269s
2022-10-11 09:56:17,912 [INFO] 	Process 2 - batch 92599: mean_policy_losses: -19.702, mean_net_lifetime: 7686.4324, mean_mc_travel_dist: 2037.3943, mean_rewards: 280.4318, total_rewards: 5675.9006, mean_steps: 26.4800, mean_ecr: 0.0380 mean_entropies: 0.3727, took: 153.5554s
2022-10-11 09:56:56,094 [INFO] Process 1 - epoch 57: mean_policy_losses: 13.699, mean_net_lifetime: 5486.4623, mean_mc_travel_dist: 2042.1474, mean_entropies: 1.1269, m_net_lifetime_valid: 4599.3352, took: 2636.2385s, (168.0808 / 100 batches)

2022-10-11 09:56:56,158 [INFO] 	Process 4 - batch 96999: mean_policy_losses: 129.675, mean_net_lifetime: 13065.4749, mean_mc_travel_dist: 4178.8708, mean_rewards: 267.9904, total_rewards: 8920.8944, mean_steps: 54.8300, mean_ecr: 0.0382 mean_entropies: 0.4923, took: 265.6703s
2022-10-11 09:57:00,020 [INFO] 	Process 5 - batch 86199: mean_policy_losses: -120.575, mean_net_lifetime: 10682.6562, mean_mc_travel_dist: 3336.0751, mean_rewards: 264.2318, total_rewards: 7383.5877, mean_steps: 40.6700, mean_ecr: 0.0291 mean_entropies: 0.6146, took: 207.8222s
2022-10-11 09:58:29,733 [INFO] Process 3 - epoch 69: mean_policy_losses: 40.823, mean_net_lifetime: 4538.3069, mean_mc_travel_dist: 1342.0627, mean_entropies: 0.7772, m_net_lifetime_valid: 4585.0070, took: 2265.4685s, (138.9493 / 100 batches)

2022-10-11 09:58:55,638 [INFO] 	Process 2 - batch 92699: mean_policy_losses: -39.401, mean_net_lifetime: 7523.7458, mean_mc_travel_dist: 1993.5731, mean_rewards: 287.4927, total_rewards: 5557.4401, mean_steps: 25.2600, mean_ecr: 0.0383 mean_entropies: 0.3804, took: 157.7256s
2022-10-11 10:00:03,103 [INFO] 	Process 1 - batch 85599: mean_policy_losses: -84.782, mean_net_lifetime: 6611.5034, mean_mc_travel_dist: 2027.1804, mean_rewards: 241.2124, total_rewards: 4612.5176, mean_steps: 26.6000, mean_ecr: 0.0383 mean_entropies: 0.9430, took: 931.1453s
2022-10-11 10:00:31,736 [INFO] 	Process 3 - batch 103599: mean_policy_losses: -26.104, mean_net_lifetime: 5457.2959, mean_mc_travel_dist: 1426.0320, mean_rewards: 286.6423, total_rewards: 4053.0011, mean_steps: 18.0800, mean_ecr: 0.0448 mean_entropies: 0.4705, took: 884.7410s
2022-10-11 10:01:03,131 [INFO] 	Process 5 - batch 86299: mean_policy_losses: -107.761, mean_net_lifetime: 10440.6659, mean_mc_travel_dist: 3179.7457, mean_rewards: 267.9163, total_rewards: 7294.6188, mean_steps: 38.9700, mean_ecr: 0.0293 mean_entropies: 0.6424, took: 243.1114s
2022-10-11 10:01:23,050 [INFO] 	Process 4 - batch 97099: mean_policy_losses: 120.656, mean_net_lifetime: 11204.0980, mean_mc_travel_dist: 3421.0559, mean_rewards: 279.0079, total_rewards: 7810.4148, mean_steps: 44.2200, mean_ecr: 0.0397 mean_entropies: 0.5085, took: 266.8914s
2022-10-11 10:01:33,698 [INFO] 	Process 2 - batch 92799: mean_policy_losses: -8.382, mean_net_lifetime: 7715.3333, mean_mc_travel_dist: 2042.1416, mean_rewards: 283.0137, total_rewards: 5696.6233, mean_steps: 26.3200, mean_ecr: 0.0381 mean_entropies: 0.3837, took: 158.0597s
2022-10-11 10:02:03,057 [INFO] 	Process 1 - batch 85699: mean_policy_losses: -82.898, mean_net_lifetime: 6567.3420, mean_mc_travel_dist: 2048.8254, mean_rewards: 248.5452, total_rewards: 4548.0273, mean_steps: 25.6300, mean_ecr: 0.0382 mean_entropies: 0.9183, took: 119.9538s
2022-10-11 10:02:03,178 [INFO] 	Process 3 - batch 103699: mean_policy_losses: -31.632, mean_net_lifetime: 5477.0360, mean_mc_travel_dist: 1424.3058, mean_rewards: 282.4627, total_rewards: 4078.7949, mean_steps: 18.4600, mean_ecr: 0.0447 mean_entropies: 0.4641, took: 91.4424s
2022-10-11 10:03:33,922 [INFO] 	Process 3 - batch 103799: mean_policy_losses: -31.628, mean_net_lifetime: 5434.4899, mean_mc_travel_dist: 1412.0625, mean_rewards: 285.1541, total_rewards: 4047.2644, mean_steps: 18.0900, mean_ecr: 0.0449 mean_entropies: 0.4839, took: 90.7445s
2022-10-11 10:03:36,368 [INFO] Process 7 - epoch 63: mean_policy_losses: -365.840, mean_net_lifetime: 4358.1346, mean_mc_travel_dist: 1551.7601, mean_entropies: 1.5067, m_net_lifetime_valid: 4388.2414, took: 2721.3087s, (152.4133 / 100 batches)

2022-10-11 10:03:41,595 [INFO] 	Process 2 - batch 92899: mean_policy_losses: -12.542, mean_net_lifetime: 7707.6073, mean_mc_travel_dist: 2038.2126, mean_rewards: 286.3160, total_rewards: 5697.2542, mean_steps: 26.0300, mean_ecr: 0.0381 mean_entropies: 0.3880, took: 127.8982s
2022-10-11 10:04:07,099 [INFO] 	Process 1 - batch 85799: mean_policy_losses: -80.916, mean_net_lifetime: 6670.3342, mean_mc_travel_dist: 2078.9952, mean_rewards: 249.3176, total_rewards: 4619.4423, mean_steps: 25.9000, mean_ecr: 0.0381 mean_entropies: 0.9188, took: 124.0424s
2022-10-11 10:04:32,278 [INFO] 	Process 5 - batch 86399: mean_policy_losses: -139.679, mean_net_lifetime: 11622.2314, mean_mc_travel_dist: 3706.3638, mean_rewards: 265.2658, total_rewards: 7955.3269, mean_steps: 44.9700, mean_ecr: 0.0287 mean_entropies: 0.6259, took: 209.1466s
2022-10-11 10:05:11,008 [INFO] 	Process 3 - batch 103899: mean_policy_losses: -23.639, mean_net_lifetime: 5520.6584, mean_mc_travel_dist: 1454.3135, mean_rewards: 278.8948, total_rewards: 4092.0481, mean_steps: 18.8700, mean_ecr: 0.0445 mean_entropies: 0.4921, took: 97.0849s
2022-10-11 10:05:35,330 [INFO] 	Process 7 - batch 94599: mean_policy_losses: -347.474, mean_net_lifetime: 5197.4743, mean_mc_travel_dist: 1569.1995, mean_rewards: 209.4280, total_rewards: 3667.3902, mean_steps: 24.2200, mean_ecr: 0.0407 mean_entropies: 1.2522, took: 957.4535s
2022-10-11 10:05:52,594 [INFO] 	Process 2 - batch 92999: mean_policy_losses: 1.983, mean_net_lifetime: 7671.7440, mean_mc_travel_dist: 2022.3816, mean_rewards: 282.3799, total_rewards: 5669.4524, mean_steps: 26.2600, mean_ecr: 0.0381 mean_entropies: 0.3692, took: 130.9986s
2022-10-11 10:05:56,080 [INFO] 	Process 4 - batch 97199: mean_policy_losses: 115.198, mean_net_lifetime: 13868.3477, mean_mc_travel_dist: 4562.3115, mean_rewards: 266.4163, total_rewards: 9335.9520, mean_steps: 59.6700, mean_ecr: 0.0383 mean_entropies: 0.5000, took: 273.0305s
2022-10-11 10:06:11,800 [INFO] 	Process 1 - batch 85899: mean_policy_losses: -66.206, mean_net_lifetime: 6516.4203, mean_mc_travel_dist: 2024.2135, mean_rewards: 247.3487, total_rewards: 4522.3151, mean_steps: 25.5100, mean_ecr: 0.0384 mean_entropies: 0.9197, took: 124.7002s
2022-10-11 10:06:15,922 [INFO] Process 6 - epoch 92: mean_policy_losses: -178.594, mean_net_lifetime: 3309.7784, mean_mc_travel_dist: 995.3831, mean_entropies: 0.4714, m_net_lifetime_valid: 4139.2067, took: 1648.4440s, (104.6049 / 100 batches)

2022-10-11 10:07:02,558 [INFO] 	Process 3 - batch 103999: mean_policy_losses: -5.013, mean_net_lifetime: 5425.7296, mean_mc_travel_dist: 1436.0861, mean_rewards: 284.0623, total_rewards: 4025.3424, mean_steps: 18.1500, mean_ecr: 0.0446 mean_entropies: 0.4754, took: 111.5511s
2022-10-11 10:07:38,899 [INFO] 	Process 6 - batch 138099: mean_policy_losses: -92.876, mean_net_lifetime: 3820.5132, mean_mc_travel_dist: 1055.3000, mean_rewards: 339.7888, total_rewards: 2838.4482, mean_steps: 10.2200, mean_ecr: 0.0552 mean_entropies: 0.1556, took: 804.2139s
2022-10-11 10:08:02,507 [INFO] 	Process 7 - batch 94699: mean_policy_losses: -390.123, mean_net_lifetime: 4922.5666, mean_mc_travel_dist: 1486.0264, mean_rewards: 212.5908, total_rewards: 3466.7643, mean_steps: 22.4900, mean_ecr: 0.0409 mean_entropies: 1.2542, took: 147.1768s
2022-10-11 10:08:42,505 [INFO] 	Process 6 - batch 138199: mean_policy_losses: -97.433, mean_net_lifetime: 3760.6745, mean_mc_travel_dist: 1030.2925, mean_rewards: 341.8665, total_rewards: 2804.8398, mean_steps: 9.9800, mean_ecr: 0.0554 mean_entropies: 0.1451, took: 63.6066s
2022-10-11 10:08:54,559 [INFO] 	Process 1 - batch 85999: mean_policy_losses: 31.319, mean_net_lifetime: 6682.8286, mean_mc_travel_dist: 2053.5179, mean_rewards: 252.3789, total_rewards: 4659.7960, mean_steps: 25.6000, mean_ecr: 0.0383 mean_entropies: 0.9598, took: 162.7594s
2022-10-11 10:08:56,856 [INFO] 	Process 5 - batch 86499: mean_policy_losses: -110.020, mean_net_lifetime: 12289.0134, mean_mc_travel_dist: 3928.0472, mean_rewards: 258.0334, total_rewards: 8411.5234, mean_steps: 48.9100, mean_ecr: 0.0285 mean_entropies: 0.6254, took: 264.5774s
2022-10-11 10:08:57,437 [INFO] 	Process 3 - batch 104099: mean_policy_losses: -21.571, mean_net_lifetime: 5441.6880, mean_mc_travel_dist: 1410.8966, mean_rewards: 275.8676, total_rewards: 4060.5405, mean_steps: 18.8100, mean_ecr: 0.0447 mean_entropies: 0.4715, took: 114.8778s
2022-10-11 10:09:39,096 [INFO] 	Process 6 - batch 138299: mean_policy_losses: -102.943, mean_net_lifetime: 3865.2324, mean_mc_travel_dist: 1046.9070, mean_rewards: 343.0466, total_rewards: 2892.5748, mean_steps: 10.2400, mean_ecr: 0.0551 mean_entropies: 0.1346, took: 56.5902s
2022-10-11 10:09:58,639 [INFO] 	Process 7 - batch 94799: mean_policy_losses: -367.189, mean_net_lifetime: 5068.0334, mean_mc_travel_dist: 1536.0549, mean_rewards: 208.2854, total_rewards: 3561.9709, mean_steps: 23.6900, mean_ecr: 0.0408 mean_entropies: 1.2903, took: 116.1311s
2022-10-11 10:10:34,981 [INFO] 	Process 3 - batch 104199: mean_policy_losses: -21.746, mean_net_lifetime: 5531.6263, mean_mc_travel_dist: 1415.6984, mean_rewards: 277.2444, total_rewards: 4137.4778, mean_steps: 19.0500, mean_ecr: 0.0449 mean_entropies: 0.4716, took: 97.5446s
2022-10-11 10:10:36,722 [INFO] 	Process 6 - batch 138399: mean_policy_losses: -77.469, mean_net_lifetime: 3950.4025, mean_mc_travel_dist: 1074.3748, mean_rewards: 342.8629, total_rewards: 2957.8345, mean_steps: 10.4900, mean_ecr: 0.0550 mean_entropies: 0.1450, took: 57.6270s
2022-10-11 10:10:57,907 [INFO] 	Process 1 - batch 86099: mean_policy_losses: -88.241, mean_net_lifetime: 6385.4964, mean_mc_travel_dist: 1960.0555, mean_rewards: 244.9487, total_rewards: 4453.6457, mean_steps: 25.1800, mean_ecr: 0.0385 mean_entropies: 0.9398, took: 123.3473s
2022-10-11 10:11:26,687 [INFO] 	Process 4 - batch 97299: mean_policy_losses: 150.261, mean_net_lifetime: 14573.0330, mean_mc_travel_dist: 4898.1157, mean_rewards: 269.5510, total_rewards: 9706.1177, mean_steps: 63.1400, mean_ecr: 0.0382 mean_entropies: 0.4497, took: 330.6072s
2022-10-11 10:11:33,721 [INFO] 	Process 6 - batch 138499: mean_policy_losses: -62.805, mean_net_lifetime: 3937.8310, mean_mc_travel_dist: 1070.9532, mean_rewards: 343.4816, total_rewards: 2949.6338, mean_steps: 10.4400, mean_ecr: 0.0550 mean_entropies: 0.1422, took: 56.9987s
2022-10-11 10:12:07,427 [INFO] 	Process 7 - batch 94899: mean_policy_losses: -223.752, mean_net_lifetime: 5476.7765, mean_mc_travel_dist: 1673.8573, mean_rewards: 204.4799, total_rewards: 3832.8932, mean_steps: 26.0900, mean_ecr: 0.0402 mean_entropies: 1.2309, took: 128.7888s
2022-10-11 10:12:09,364 [INFO] 	Process 3 - batch 104299: mean_policy_losses: -28.391, mean_net_lifetime: 5380.1311, mean_mc_travel_dist: 1370.6916, mean_rewards: 281.3740, total_rewards: 4033.6190, mean_steps: 18.1900, mean_ecr: 0.0452 mean_entropies: 0.4638, took: 94.3837s
2022-10-11 10:12:29,405 [INFO] 	Process 6 - batch 138599: mean_policy_losses: -102.665, mean_net_lifetime: 3835.7922, mean_mc_travel_dist: 1043.9142, mean_rewards: 342.4220, total_rewards: 2865.1606, mean_steps: 10.1500, mean_ecr: 0.0551 mean_entropies: 0.1432, took: 55.6839s
2022-10-11 10:12:48,626 [INFO] 	Process 5 - batch 86599: mean_policy_losses: -94.244, mean_net_lifetime: 12266.0574, mean_mc_travel_dist: 3879.9612, mean_rewards: 252.9229, total_rewards: 8430.0512, mean_steps: 49.4100, mean_ecr: 0.0288 mean_entropies: 0.6119, took: 231.7709s
2022-10-11 10:13:05,150 [INFO] 	Process 1 - batch 86199: mean_policy_losses: -33.746, mean_net_lifetime: 6652.7452, mean_mc_travel_dist: 2059.8635, mean_rewards: 246.7381, total_rewards: 4619.7617, mean_steps: 26.1000, mean_ecr: 0.0381 mean_entropies: 0.9049, took: 127.2440s
2022-10-11 10:13:30,612 [INFO] 	Process 6 - batch 138699: mean_policy_losses: -43.476, mean_net_lifetime: 4066.5676, mean_mc_travel_dist: 1118.2225, mean_rewards: 340.6897, total_rewards: 3016.2771, mean_steps: 10.9000, mean_ecr: 0.0550 mean_entropies: 0.1238, took: 61.2074s
2022-10-11 10:13:46,567 [INFO] 	Process 3 - batch 104399: mean_policy_losses: 15.822, mean_net_lifetime: 5534.9014, mean_mc_travel_dist: 1404.1736, mean_rewards: 277.6892, total_rewards: 4164.9439, mean_steps: 18.9800, mean_ecr: 0.0448 mean_entropies: 0.4695, took: 97.2027s
2022-10-11 10:14:10,398 [INFO] 	Process 7 - batch 94999: mean_policy_losses: -273.392, mean_net_lifetime: 5079.2700, mean_mc_travel_dist: 1548.2951, mean_rewards: 205.7808, total_rewards: 3551.4043, mean_steps: 24.3900, mean_ecr: 0.0408 mean_entropies: 1.2452, took: 122.9711s
2022-10-11 10:14:29,821 [INFO] 	Process 6 - batch 138799: mean_policy_losses: -70.950, mean_net_lifetime: 4014.4940, mean_mc_travel_dist: 1089.0072, mean_rewards: 342.8781, total_rewards: 3004.4809, mean_steps: 10.6900, mean_ecr: 0.0548 mean_entropies: 0.1354, took: 59.2082s
2022-10-11 10:15:04,968 [INFO] 	Process 1 - batch 86299: mean_policy_losses: -75.209, mean_net_lifetime: 6465.7581, mean_mc_travel_dist: 1996.9178, mean_rewards: 252.1574, total_rewards: 4492.3761, mean_steps: 24.7200, mean_ecr: 0.0385 mean_entropies: 0.9018, took: 119.8167s
2022-10-11 10:15:20,048 [INFO] 	Process 3 - batch 104499: mean_policy_losses: -34.341, mean_net_lifetime: 5310.2153, mean_mc_travel_dist: 1336.0412, mean_rewards: 279.9506, total_rewards: 3995.7468, mean_steps: 18.0700, mean_ecr: 0.0452 mean_entropies: 0.4763, took: 93.4809s
2022-10-11 10:15:28,345 [INFO] 	Process 6 - batch 138899: mean_policy_losses: -94.376, mean_net_lifetime: 4032.2413, mean_mc_travel_dist: 1089.1575, mean_rewards: 343.3597, total_rewards: 3006.7118, mean_steps: 10.7000, mean_ecr: 0.0550 mean_entropies: 0.1386, took: 58.5244s
2022-10-11 10:16:08,732 [INFO] 	Process 5 - batch 86699: mean_policy_losses: -62.379, mean_net_lifetime: 10650.2117, mean_mc_travel_dist: 3315.9752, mean_rewards: 262.4530, total_rewards: 7371.4095, mean_steps: 41.3100, mean_ecr: 0.0292 mean_entropies: 0.6147, took: 200.1063s
2022-10-11 10:16:09,319 [INFO] 	Process 7 - batch 95099: mean_policy_losses: -238.916, mean_net_lifetime: 5162.4938, mean_mc_travel_dist: 1595.7382, mean_rewards: 207.0725, total_rewards: 3604.2863, mean_steps: 24.2000, mean_ecr: 0.0406 mean_entropies: 1.2374, took: 118.9200s
2022-10-11 10:16:27,710 [INFO] 	Process 6 - batch 138999: mean_policy_losses: -61.264, mean_net_lifetime: 4044.1022, mean_mc_travel_dist: 1090.3672, mean_rewards: 344.3955, total_rewards: 3008.9001, mean_steps: 10.7200, mean_ecr: 0.0550 mean_entropies: 0.1418, took: 59.3648s
2022-10-11 10:16:54,288 [INFO] 	Process 3 - batch 104599: mean_policy_losses: -21.218, mean_net_lifetime: 5318.2879, mean_mc_travel_dist: 1329.0117, mean_rewards: 276.2227, total_rewards: 4019.5099, mean_steps: 18.4000, mean_ecr: 0.0455 mean_entropies: 0.4563, took: 94.2395s
2022-10-11 10:17:12,765 [INFO] 	Process 1 - batch 86399: mean_policy_losses: -26.269, mean_net_lifetime: 6730.2440, mean_mc_travel_dist: 2086.7244, mean_rewards: 250.0158, total_rewards: 4667.7969, mean_steps: 26.0200, mean_ecr: 0.0380 mean_entropies: 0.8926, took: 127.7973s
2022-10-11 10:17:28,337 [INFO] 	Process 6 - batch 139099: mean_policy_losses: -66.781, mean_net_lifetime: 4122.0881, mean_mc_travel_dist: 1111.7095, mean_rewards: 343.8442, total_rewards: 3080.4399, mean_steps: 10.9600, mean_ecr: 0.0549 mean_entropies: 0.1317, took: 60.6274s
2022-10-11 10:17:46,574 [INFO] 	Process 4 - batch 97399: mean_policy_losses: 205.684, mean_net_lifetime: 18479.0022, mean_mc_travel_dist: 6273.6850, mean_rewards: 262.2107, total_rewards: 12239.7398, mean_steps: 82.5700, mean_ecr: 0.0372 mean_entropies: 0.4982, took: 379.8872s
2022-10-11 10:18:03,557 [INFO] Process 2 - epoch 62: mean_policy_losses: -0.557, mean_net_lifetime: 5445.6831, mean_mc_travel_dist: 1709.9755, mean_entropies: 0.8054, m_net_lifetime_valid: 4493.1185, took: 2791.3295s, (155.9161 / 100 batches)

2022-10-11 10:18:04,981 [INFO] 	Process 7 - batch 95199: mean_policy_losses: -337.972, mean_net_lifetime: 4952.7247, mean_mc_travel_dist: 1512.4868, mean_rewards: 205.4087, total_rewards: 3478.8641, mean_steps: 23.4200, mean_ecr: 0.0409 mean_entropies: 1.2940, took: 115.6630s
2022-10-11 10:18:27,468 [INFO] 	Process 6 - batch 139199: mean_policy_losses: -84.453, mean_net_lifetime: 4029.3456, mean_mc_travel_dist: 1090.8133, mean_rewards: 344.6096, total_rewards: 3015.0915, mean_steps: 10.6800, mean_ecr: 0.0548 mean_entropies: 0.1285, took: 59.1311s
2022-10-11 10:18:33,099 [INFO] 	Process 3 - batch 104699: mean_policy_losses: -15.831, mean_net_lifetime: 5477.7939, mean_mc_travel_dist: 1397.6925, mean_rewards: 280.5246, total_rewards: 4106.8060, mean_steps: 18.6100, mean_ecr: 0.0450 mean_entropies: 0.4734, took: 98.8111s
2022-10-11 10:19:19,183 [INFO] 	Process 1 - batch 86499: mean_policy_losses: -51.843, mean_net_lifetime: 6679.9680, mean_mc_travel_dist: 2059.8430, mean_rewards: 255.1389, total_rewards: 4646.1376, mean_steps: 25.2400, mean_ecr: 0.0383 mean_entropies: 0.9454, took: 126.4190s
2022-10-11 10:19:26,694 [INFO] 	Process 6 - batch 139299: mean_policy_losses: -107.851, mean_net_lifetime: 3909.5554, mean_mc_travel_dist: 1064.6336, mean_rewards: 339.7854, total_rewards: 2911.9796, mean_steps: 10.4500, mean_ecr: 0.0552 mean_entropies: 0.1524, took: 59.2256s
2022-10-11 10:19:29,939 [INFO] 	Process 5 - batch 86799: mean_policy_losses: -80.354, mean_net_lifetime: 10589.6846, mean_mc_travel_dist: 3318.2819, mean_rewards: 262.2269, total_rewards: 7301.3824, mean_steps: 41.1500, mean_ecr: 0.0289 mean_entropies: 0.6123, took: 201.2065s
2022-10-11 10:19:57,019 [INFO] 	Process 7 - batch 95299: mean_policy_losses: -389.319, mean_net_lifetime: 4843.3133, mean_mc_travel_dist: 1481.0338, mean_rewards: 213.9176, total_rewards: 3400.2931, mean_steps: 22.0400, mean_ecr: 0.0411 mean_entropies: 1.2959, took: 112.0379s
2022-10-11 10:20:09,422 [INFO] 	Process 3 - batch 104799: mean_policy_losses: -35.599, mean_net_lifetime: 5325.3743, mean_mc_travel_dist: 1369.7459, mean_rewards: 283.2382, total_rewards: 3986.6418, mean_steps: 17.8400, mean_ecr: 0.0452 mean_entropies: 0.4766, took: 96.3233s
2022-10-11 10:20:18,295 [INFO] 	Process 2 - batch 93099: mean_policy_losses: 9.457, mean_net_lifetime: 7652.4183, mean_mc_travel_dist: 2020.9084, mean_rewards: 283.0196, total_rewards: 5659.7138, mean_steps: 26.1300, mean_ecr: 0.0382 mean_entropies: 0.3722, took: 865.7014s
2022-10-11 10:20:26,306 [INFO] 	Process 6 - batch 139399: mean_policy_losses: -70.631, mean_net_lifetime: 3947.2911, mean_mc_travel_dist: 1071.0545, mean_rewards: 342.4610, total_rewards: 2948.8779, mean_steps: 10.4900, mean_ecr: 0.0549 mean_entropies: 0.1354, took: 59.6123s
2022-10-11 10:21:25,169 [INFO] 	Process 6 - batch 139499: mean_policy_losses: -79.338, mean_net_lifetime: 3866.2554, mean_mc_travel_dist: 1061.6446, mean_rewards: 340.8605, total_rewards: 2873.3422, mean_steps: 10.3100, mean_ecr: 0.0553 mean_entropies: 0.1279, took: 58.8629s
2022-10-11 10:21:30,311 [INFO] 	Process 1 - batch 86599: mean_policy_losses: -19.989, mean_net_lifetime: 6610.0575, mean_mc_travel_dist: 2038.1519, mean_rewards: 248.3530, total_rewards: 4600.0618, mean_steps: 25.7800, mean_ecr: 0.0384 mean_entropies: 0.9204, took: 131.1271s
2022-10-11 10:21:44,616 [INFO] 	Process 4 - batch 97499: mean_policy_losses: 158.766, mean_net_lifetime: 12214.0607, mean_mc_travel_dist: 3857.2737, mean_rewards: 271.1343, total_rewards: 8385.6263, mean_steps: 49.8300, mean_ecr: 0.0382 mean_entropies: 0.5031, took: 238.0422s
2022-10-11 10:21:47,984 [INFO] 	Process 3 - batch 104899: mean_policy_losses: -14.442, mean_net_lifetime: 5404.3582, mean_mc_travel_dist: 1398.2049, mean_rewards: 272.2918, total_rewards: 4038.2881, mean_steps: 18.9600, mean_ecr: 0.0448 mean_entropies: 0.4800, took: 98.5625s
2022-10-11 10:22:15,919 [INFO] 	Process 7 - batch 95399: mean_policy_losses: -168.819, mean_net_lifetime: 5672.2273, mean_mc_travel_dist: 1755.0554, mean_rewards: 196.6260, total_rewards: 3952.5235, mean_steps: 28.2900, mean_ecr: 0.0401 mean_entropies: 1.2301, took: 138.8996s
2022-10-11 10:22:27,158 [INFO] 	Process 2 - batch 93199: mean_policy_losses: -27.000, mean_net_lifetime: 7307.5468, mean_mc_travel_dist: 1933.9523, mean_rewards: 277.1184, total_rewards: 5400.8072, mean_steps: 25.4700, mean_ecr: 0.0385 mean_entropies: 0.3396, took: 128.8627s
2022-10-11 10:22:37,906 [INFO] 	Process 5 - batch 86899: mean_policy_losses: -169.043, mean_net_lifetime: 9684.2982, mean_mc_travel_dist: 3079.3835, mean_rewards: 255.4505, total_rewards: 6653.4364, mean_steps: 39.0800, mean_ecr: 0.0293 mean_entropies: 0.5987, took: 187.9666s
2022-10-11 10:23:17,104 [INFO] 	Process 3 - batch 104999: mean_policy_losses: -13.963, mean_net_lifetime: 5200.7187, mean_mc_travel_dist: 1316.1235, mean_rewards: 277.4512, total_rewards: 3916.7469, mean_steps: 17.8000, mean_ecr: 0.0455 mean_entropies: 0.4756, took: 89.1193s
2022-10-11 10:23:23,532 [INFO] 	Process 1 - batch 86699: mean_policy_losses: -13.064, mean_net_lifetime: 6499.2080, mean_mc_travel_dist: 2041.7177, mean_rewards: 258.9592, total_rewards: 4488.8203, mean_steps: 24.1600, mean_ecr: 0.0383 mean_entropies: 0.8670, took: 113.2213s
2022-10-11 10:24:11,996 [INFO] 	Process 7 - batch 95499: mean_policy_losses: -234.178, mean_net_lifetime: 5014.9116, mean_mc_travel_dist: 1518.1478, mean_rewards: 198.7129, total_rewards: 3526.3860, mean_steps: 24.5500, mean_ecr: 0.0406 mean_entropies: 1.2084, took: 116.0771s
2022-10-11 10:24:30,953 [INFO] 	Process 2 - batch 93299: mean_policy_losses: -2.887, mean_net_lifetime: 7490.4071, mean_mc_travel_dist: 1948.3777, mean_rewards: 282.7828, total_rewards: 5568.4048, mean_steps: 25.5600, mean_ecr: 0.0384 mean_entropies: 0.3527, took: 123.7943s
2022-10-11 10:25:16,606 [INFO] 	Process 1 - batch 86799: mean_policy_losses: -81.517, mean_net_lifetime: 6486.5599, mean_mc_travel_dist: 2013.5872, mean_rewards: 249.7700, total_rewards: 4502.7719, mean_steps: 25.0900, mean_ecr: 0.0384 mean_entropies: 0.9001, took: 113.0738s
2022-10-11 10:25:28,525 [INFO] 	Process 5 - batch 86999: mean_policy_losses: -114.233, mean_net_lifetime: 9815.9924, mean_mc_travel_dist: 3019.4971, mean_rewards: 259.7415, total_rewards: 6833.6524, mean_steps: 38.4400, mean_ecr: 0.0294 mean_entropies: 0.6256, took: 170.6190s
2022-10-11 10:26:05,141 [INFO] 	Process 7 - batch 95599: mean_policy_losses: -207.865, mean_net_lifetime: 5118.2378, mean_mc_travel_dist: 1563.3697, mean_rewards: 198.8854, total_rewards: 3588.7605, mean_steps: 24.9800, mean_ecr: 0.0407 mean_entropies: 1.2751, took: 113.1443s
2022-10-11 10:26:28,458 [INFO] 	Process 2 - batch 93399: mean_policy_losses: -16.980, mean_net_lifetime: 7549.6549, mean_mc_travel_dist: 1988.5141, mean_rewards: 291.8618, total_rewards: 5582.4932, mean_steps: 24.9500, mean_ecr: 0.0384 mean_entropies: 0.3854, took: 117.5055s
2022-10-11 10:27:09,018 [INFO] 	Process 1 - batch 86899: mean_policy_losses: -51.940, mean_net_lifetime: 6620.0120, mean_mc_travel_dist: 2026.4635, mean_rewards: 250.2286, total_rewards: 4613.4821, mean_steps: 25.5700, mean_ecr: 0.0383 mean_entropies: 0.9008, took: 112.4124s
2022-10-11 10:27:53,999 [INFO] 	Process 7 - batch 95699: mean_policy_losses: -234.633, mean_net_lifetime: 4981.7487, mean_mc_travel_dist: 1501.0453, mean_rewards: 199.2166, total_rewards: 3519.3314, mean_steps: 24.5300, mean_ecr: 0.0407 mean_entropies: 1.1759, took: 108.8586s
2022-10-11 10:28:29,109 [INFO] 	Process 2 - batch 93499: mean_policy_losses: -12.750, mean_net_lifetime: 7596.7422, mean_mc_travel_dist: 1971.6496, mean_rewards: 275.9113, total_rewards: 5652.0947, mean_steps: 26.6400, mean_ecr: 0.0383 mean_entropies: 0.3184, took: 120.6512s
2022-10-11 10:28:58,559 [INFO] 	Process 1 - batch 86999: mean_policy_losses: -100.522, mean_net_lifetime: 6442.2175, mean_mc_travel_dist: 1979.4937, mean_rewards: 249.9509, total_rewards: 4484.8391, mean_steps: 24.9000, mean_ecr: 0.0384 mean_entropies: 0.8901, took: 109.5411s
2022-10-11 10:29:48,624 [INFO] 	Process 7 - batch 95799: mean_policy_losses: -189.869, mean_net_lifetime: 5322.9311, mean_mc_travel_dist: 1629.1255, mean_rewards: 197.0200, total_rewards: 3727.6825, mean_steps: 26.5300, mean_ecr: 0.0405 mean_entropies: 1.1624, took: 114.6247s
2022-10-11 10:30:27,866 [INFO] 	Process 2 - batch 93599: mean_policy_losses: -20.718, mean_net_lifetime: 7706.4419, mean_mc_travel_dist: 2044.5276, mean_rewards: 280.3361, total_rewards: 5684.2874, mean_steps: 26.5500, mean_ecr: 0.0381 mean_entropies: 0.3836, took: 118.7562s
2022-10-11 10:31:40,608 [INFO] 	Process 7 - batch 95899: mean_policy_losses: -230.922, mean_net_lifetime: 5352.7237, mean_mc_travel_dist: 1649.5645, mean_rewards: 196.7317, total_rewards: 3738.1578, mean_steps: 26.7400, mean_ecr: 0.0404 mean_entropies: 1.1759, took: 111.9851s
2022-10-11 10:31:43,919 [INFO] Process 6 - epoch 93: mean_policy_losses: -177.545, mean_net_lifetime: 3316.6284, mean_mc_travel_dist: 996.2273, mean_entropies: 0.4678, m_net_lifetime_valid: 4346.9084, took: 1527.9939s, (104.6489 / 100 batches)

2022-10-11 10:31:58,479 [INFO] Process 4 - epoch 65: mean_policy_losses: 110.559, mean_net_lifetime: 5220.3206, mean_mc_travel_dist: 1618.9970, mean_entropies: 1.0081, m_net_lifetime_valid: 4436.2893, took: 4320.2812s, (149.7026 / 100 batches)

2022-10-11 10:32:23,613 [INFO] 	Process 2 - batch 93699: mean_policy_losses: -13.139, mean_net_lifetime: 7743.9855, mean_mc_travel_dist: 2030.6273, mean_rewards: 283.3914, total_rewards: 5741.0973, mean_steps: 26.4200, mean_ecr: 0.0381 mean_entropies: 0.3547, took: 115.7473s
2022-10-11 10:32:36,908 [INFO] 	Process 6 - batch 139599: mean_policy_losses: -111.178, mean_net_lifetime: 3874.0384, mean_mc_travel_dist: 1045.8292, mean_rewards: 340.6815, total_rewards: 2885.8143, mean_steps: 10.3000, mean_ecr: 0.0551 mean_entropies: 0.1550, took: 671.7389s
2022-10-11 10:33:28,841 [INFO] Process 3 - epoch 70: mean_policy_losses: 39.945, mean_net_lifetime: 4550.8456, mean_mc_travel_dist: 1342.7962, mean_entropies: 0.7729, m_net_lifetime_valid: 4561.5301, took: 2099.1052s, (139.1072 / 100 batches)

2022-10-11 10:33:32,262 [INFO] 	Process 6 - batch 139699: mean_policy_losses: -95.181, mean_net_lifetime: 3915.3093, mean_mc_travel_dist: 1059.0459, mean_rewards: 334.4969, total_rewards: 2907.9128, mean_steps: 10.6100, mean_ecr: 0.0555 mean_entropies: 0.1783, took: 55.3542s
2022-10-11 10:33:41,253 [INFO] 	Process 7 - batch 95999: mean_policy_losses: -224.596, mean_net_lifetime: 5350.3390, mean_mc_travel_dist: 1653.3519, mean_rewards: 193.1956, total_rewards: 3734.9531, mean_steps: 26.9300, mean_ecr: 0.0405 mean_entropies: 1.1538, took: 120.6444s
2022-10-11 10:34:25,113 [INFO] 	Process 2 - batch 93799: mean_policy_losses: -29.464, mean_net_lifetime: 7554.6519, mean_mc_travel_dist: 1989.7535, mean_rewards: 283.0122, total_rewards: 5588.9757, mean_steps: 25.7700, mean_ecr: 0.0384 mean_entropies: 0.3527, took: 121.5004s
2022-10-11 10:34:25,811 [INFO] 	Process 6 - batch 139799: mean_policy_losses: -98.859, mean_net_lifetime: 3909.5263, mean_mc_travel_dist: 1061.2167, mean_rewards: 339.6199, total_rewards: 2909.8271, mean_steps: 10.4500, mean_ecr: 0.0553 mean_entropies: 0.1750, took: 53.5493s
2022-10-11 10:34:30,081 [INFO] 	Process 4 - batch 97599: mean_policy_losses: 101.476, mean_net_lifetime: 8375.6753, mean_mc_travel_dist: 2509.4243, mean_rewards: 274.9284, total_rewards: 5900.7943, mean_steps: 33.3200, mean_ecr: 0.0421 mean_entropies: 0.4768, took: 765.4646s
2022-10-11 10:35:00,343 [INFO] 	Process 3 - batch 105099: mean_policy_losses: -52.625, mean_net_lifetime: 5502.6425, mean_mc_travel_dist: 1430.8683, mean_rewards: 270.2083, total_rewards: 4099.0380, mean_steps: 19.5300, mean_ecr: 0.0444 mean_entropies: 0.4840, took: 703.2390s
2022-10-11 10:35:19,617 [INFO] 	Process 6 - batch 139899: mean_policy_losses: -113.573, mean_net_lifetime: 4000.6221, mean_mc_travel_dist: 1067.0261, mean_rewards: 339.5777, total_rewards: 2982.3740, mean_steps: 10.7000, mean_ecr: 0.0552 mean_entropies: 0.1577, took: 53.8055s
2022-10-11 10:35:58,561 [INFO] Process 5 - epoch 58: mean_policy_losses: -188.682, mean_net_lifetime: 6020.4335, mean_mc_travel_dist: 2204.4920, mean_entropies: 1.0746, m_net_lifetime_valid: 4645.9536, took: 3697.2998s, (168.0065 / 100 batches)

2022-10-11 10:36:13,998 [INFO] 	Process 6 - batch 139999: mean_policy_losses: -80.352, mean_net_lifetime: 4051.9378, mean_mc_travel_dist: 1087.7378, mean_rewards: 340.0690, total_rewards: 3020.3762, mean_steps: 10.8400, mean_ecr: 0.0553 mean_entropies: 0.1478, took: 54.3809s
2022-10-11 10:36:22,901 [INFO] 	Process 2 - batch 93899: mean_policy_losses: -31.899, mean_net_lifetime: 7379.8433, mean_mc_travel_dist: 1932.0892, mean_rewards: 287.8107, total_rewards: 5467.1144, mean_steps: 24.7300, mean_ecr: 0.0386 mean_entropies: 0.3575, took: 117.7887s
2022-10-11 10:36:34,968 [INFO] 	Process 3 - batch 105199: mean_policy_losses: -34.811, mean_net_lifetime: 5482.4790, mean_mc_travel_dist: 1410.8889, mean_rewards: 267.3039, total_rewards: 4103.5315, mean_steps: 19.6800, mean_ecr: 0.0446 mean_entropies: 0.4482, took: 94.6249s
2022-10-11 10:37:10,084 [INFO] 	Process 6 - batch 140099: mean_policy_losses: -90.181, mean_net_lifetime: 3939.4438, mean_mc_travel_dist: 1071.1028, mean_rewards: 340.9278, total_rewards: 2931.4981, mean_steps: 10.5100, mean_ecr: 0.0552 mean_entropies: 0.1420, took: 56.0865s
2022-10-11 10:38:07,040 [INFO] 	Process 6 - batch 140199: mean_policy_losses: -73.530, mean_net_lifetime: 4113.9386, mean_mc_travel_dist: 1104.5957, mean_rewards: 340.4752, total_rewards: 3060.7858, mean_steps: 11.0200, mean_ecr: 0.0551 mean_entropies: 0.1437, took: 56.9553s
2022-10-11 10:38:12,781 [INFO] 	Process 3 - batch 105299: mean_policy_losses: -34.806, mean_net_lifetime: 5529.6728, mean_mc_travel_dist: 1439.1414, mean_rewards: 269.5157, total_rewards: 4118.2571, mean_steps: 19.8500, mean_ecr: 0.0447 mean_entropies: 0.4371, took: 97.8138s
2022-10-11 10:38:24,158 [INFO] 	Process 2 - batch 93999: mean_policy_losses: -21.599, mean_net_lifetime: 7378.6566, mean_mc_travel_dist: 1927.5653, mean_rewards: 288.3370, total_rewards: 5483.5984, mean_steps: 24.6300, mean_ecr: 0.0386 mean_entropies: 0.3468, took: 121.2561s
2022-10-11 10:38:30,108 [INFO] 	Process 5 - batch 87099: mean_policy_losses: -219.536, mean_net_lifetime: 8532.7696, mean_mc_travel_dist: 2619.4633, mean_rewards: 260.3143, total_rewards: 5957.7946, mean_steps: 32.6400, mean_ecr: 0.0299 mean_entropies: 0.6305, took: 781.5840s
2022-10-11 10:38:42,684 [INFO] 	Process 4 - batch 97699: mean_policy_losses: 135.101, mean_net_lifetime: 13279.0384, mean_mc_travel_dist: 4304.5366, mean_rewards: 254.3706, total_rewards: 9002.4298, mean_steps: 57.7300, mean_ecr: 0.0368 mean_entropies: 0.5104, took: 252.6026s
2022-10-11 10:39:03,124 [INFO] 	Process 6 - batch 140299: mean_policy_losses: -109.538, mean_net_lifetime: 4006.0413, mean_mc_travel_dist: 1084.8076, mean_rewards: 340.8778, total_rewards: 2985.0178, mean_steps: 10.6900, mean_ecr: 0.0550 mean_entropies: 0.1250, took: 56.0842s
2022-10-11 10:39:44,839 [INFO] 	Process 3 - batch 105399: mean_policy_losses: -46.862, mean_net_lifetime: 5392.0755, mean_mc_travel_dist: 1380.1724, mean_rewards: 279.3104, total_rewards: 4033.8596, mean_steps: 18.3500, mean_ecr: 0.0449 mean_entropies: 0.4407, took: 92.0580s
2022-10-11 10:39:45,017 [INFO] Process 1 - epoch 58: mean_policy_losses: 12.513, mean_net_lifetime: 5505.2252, mean_mc_travel_dist: 2041.9903, mean_entropies: 1.1233, m_net_lifetime_valid: 4474.4513, took: 2568.9203s, (168.2477 / 100 batches)

2022-10-11 10:40:00,249 [INFO] 	Process 6 - batch 140399: mean_policy_losses: -56.938, mean_net_lifetime: 4008.2533, mean_mc_travel_dist: 1097.3710, mean_rewards: 342.9669, total_rewards: 2987.8792, mean_steps: 10.6700, mean_ecr: 0.0551 mean_entropies: 0.1265, took: 57.1253s
2022-10-11 10:40:30,528 [INFO] 	Process 2 - batch 94099: mean_policy_losses: -8.288, mean_net_lifetime: 7711.1214, mean_mc_travel_dist: 1997.7108, mean_rewards: 287.0864, total_rewards: 5729.2592, mean_steps: 25.9000, mean_ecr: 0.0383 mean_entropies: 0.3549, took: 126.3708s
2022-10-11 10:40:56,372 [INFO] 	Process 6 - batch 140499: mean_policy_losses: -95.996, mean_net_lifetime: 3960.3698, mean_mc_travel_dist: 1073.2313, mean_rewards: 343.6275, total_rewards: 2947.1248, mean_steps: 10.5000, mean_ecr: 0.0551 mean_entropies: 0.1489, took: 56.1230s
2022-10-11 10:41:15,009 [INFO] 	Process 5 - batch 87199: mean_policy_losses: -142.962, mean_net_lifetime: 9308.4475, mean_mc_travel_dist: 2815.7140, mean_rewards: 259.9696, total_rewards: 6532.1141, mean_steps: 35.5100, mean_ecr: 0.0297 mean_entropies: 0.6351, took: 164.9007s
2022-10-11 10:41:19,771 [INFO] 	Process 3 - batch 105499: mean_policy_losses: -37.984, mean_net_lifetime: 5350.3166, mean_mc_travel_dist: 1350.9506, mean_rewards: 276.1686, total_rewards: 4029.4309, mean_steps: 18.4500, mean_ecr: 0.0452 mean_entropies: 0.4290, took: 94.9316s
2022-10-11 10:41:47,869 [INFO] 	Process 1 - batch 87099: mean_policy_losses: -74.153, mean_net_lifetime: 6502.1092, mean_mc_travel_dist: 2002.5686, mean_rewards: 244.2118, total_rewards: 4519.7018, mean_steps: 25.7700, mean_ecr: 0.0383 mean_entropies: 0.9294, took: 769.3097s
2022-10-11 10:41:51,447 [INFO] 	Process 4 - batch 97799: mean_policy_losses: 100.433, mean_net_lifetime: 10101.8975, mean_mc_travel_dist: 3050.2590, mean_rewards: 278.1926, total_rewards: 7086.5451, mean_steps: 39.5800, mean_ecr: 0.0407 mean_entropies: 0.4961, took: 188.7630s
2022-10-11 10:41:54,329 [INFO] 	Process 6 - batch 140599: mean_policy_losses: -61.612, mean_net_lifetime: 3967.9104, mean_mc_travel_dist: 1077.6728, mean_rewards: 342.8415, total_rewards: 2968.8795, mean_steps: 10.5500, mean_ecr: 0.0548 mean_entropies: 0.1417, took: 57.9568s
2022-10-11 10:42:37,204 [INFO] 	Process 2 - batch 94199: mean_policy_losses: -17.056, mean_net_lifetime: 7591.6626, mean_mc_travel_dist: 1981.5275, mean_rewards: 286.7736, total_rewards: 5632.6006, mean_steps: 25.5600, mean_ecr: 0.0383 mean_entropies: 0.3756, took: 126.6759s
2022-10-11 10:42:49,413 [INFO] 	Process 3 - batch 105599: mean_policy_losses: -19.029, mean_net_lifetime: 5324.9236, mean_mc_travel_dist: 1346.1985, mean_rewards: 281.4182, total_rewards: 4010.5765, mean_steps: 18.0100, mean_ecr: 0.0454 mean_entropies: 0.4454, took: 89.6421s
2022-10-11 10:42:51,007 [INFO] 	Process 6 - batch 140699: mean_policy_losses: -47.641, mean_net_lifetime: 3973.7679, mean_mc_travel_dist: 1078.0395, mean_rewards: 343.2819, total_rewards: 2953.9843, mean_steps: 10.5500, mean_ecr: 0.0550 mean_entropies: 0.1231, took: 56.6779s
2022-10-11 10:43:37,536 [INFO] 	Process 5 - batch 87299: mean_policy_losses: -188.480, mean_net_lifetime: 7858.3322, mean_mc_travel_dist: 2336.6576, mean_rewards: 264.2307, total_rewards: 5551.6761, mean_steps: 29.2400, mean_ecr: 0.0303 mean_entropies: 0.6413, took: 142.5273s
2022-10-11 10:43:50,938 [INFO] 	Process 6 - batch 140799: mean_policy_losses: -67.555, mean_net_lifetime: 4084.4682, mean_mc_travel_dist: 1114.6081, mean_rewards: 340.8882, total_rewards: 3046.8302, mean_steps: 10.9300, mean_ecr: 0.0550 mean_entropies: 0.1283, took: 59.9311s
2022-10-11 10:43:54,481 [INFO] 	Process 1 - batch 87199: mean_policy_losses: -58.049, mean_net_lifetime: 6505.7916, mean_mc_travel_dist: 2034.6331, mean_rewards: 245.9569, total_rewards: 4499.2082, mean_steps: 25.7000, mean_ecr: 0.0382 mean_entropies: 0.8992, took: 126.6118s
2022-10-11 10:44:23,665 [INFO] 	Process 3 - batch 105699: mean_policy_losses: -25.885, mean_net_lifetime: 5440.3078, mean_mc_travel_dist: 1359.7143, mean_rewards: 282.3908, total_rewards: 4106.9874, mean_steps: 18.3100, mean_ecr: 0.0451 mean_entropies: 0.4449, took: 94.2514s
2022-10-11 10:44:42,776 [INFO] 	Process 2 - batch 94299: mean_policy_losses: -33.919, mean_net_lifetime: 7316.1688, mean_mc_travel_dist: 1920.3935, mean_rewards: 282.9197, total_rewards: 5431.9935, mean_steps: 24.9300, mean_ecr: 0.0385 mean_entropies: 0.3597, took: 125.5718s
2022-10-11 10:44:47,157 [INFO] 	Process 4 - batch 97899: mean_policy_losses: 126.258, mean_net_lifetime: 9574.7540, mean_mc_travel_dist: 2859.5209, mean_rewards: 274.5272, total_rewards: 6746.1736, mean_steps: 36.4200, mean_ecr: 0.0401 mean_entropies: 0.5289, took: 175.7108s
2022-10-11 10:44:49,391 [INFO] 	Process 6 - batch 140899: mean_policy_losses: -62.897, mean_net_lifetime: 4016.8320, mean_mc_travel_dist: 1095.9402, mean_rewards: 342.7074, total_rewards: 3003.4551, mean_steps: 10.7000, mean_ecr: 0.0548 mean_entropies: 0.1370, took: 58.4512s
2022-10-11 10:45:48,900 [INFO] 	Process 6 - batch 140999: mean_policy_losses: -107.929, mean_net_lifetime: 3963.1313, mean_mc_travel_dist: 1063.1698, mean_rewards: 338.9007, total_rewards: 2954.8529, mean_steps: 10.6000, mean_ecr: 0.0552 mean_entropies: 0.1466, took: 59.5101s
2022-10-11 10:45:55,408 [INFO] 	Process 1 - batch 87299: mean_policy_losses: -90.043, mean_net_lifetime: 6507.2007, mean_mc_travel_dist: 2034.1099, mean_rewards: 250.1052, total_rewards: 4505.6934, mean_steps: 25.1900, mean_ecr: 0.0382 mean_entropies: 0.8976, took: 120.9269s
2022-10-11 10:45:56,503 [INFO] 	Process 3 - batch 105799: mean_policy_losses: -50.046, mean_net_lifetime: 5318.3392, mean_mc_travel_dist: 1347.7722, mean_rewards: 275.0553, total_rewards: 3997.3451, mean_steps: 18.4200, mean_ecr: 0.0452 mean_entropies: 0.4807, took: 92.8383s
2022-10-11 10:46:09,331 [INFO] 	Process 5 - batch 87399: mean_policy_losses: -175.499, mean_net_lifetime: 8461.8612, mean_mc_travel_dist: 2545.7379, mean_rewards: 265.3894, total_rewards: 5952.7687, mean_steps: 31.4000, mean_ecr: 0.0301 mean_entropies: 0.6421, took: 151.7950s
2022-10-11 10:46:28,445 [INFO] Process 7 - epoch 64: mean_policy_losses: -364.352, mean_net_lifetime: 4370.7843, mean_mc_travel_dist: 1552.1726, mean_entropies: 1.5025, m_net_lifetime_valid: 4405.2017, took: 2572.0740s, (152.7850 / 100 batches)

2022-10-11 10:46:51,480 [INFO] 	Process 2 - batch 94399: mean_policy_losses: -7.612, mean_net_lifetime: 7692.3403, mean_mc_travel_dist: 2025.0284, mean_rewards: 284.0760, total_rewards: 5688.0608, mean_steps: 26.2100, mean_ecr: 0.0382 mean_entropies: 0.3710, took: 128.7034s
2022-10-11 10:47:30,003 [INFO] 	Process 3 - batch 105899: mean_policy_losses: -45.289, mean_net_lifetime: 5366.8423, mean_mc_travel_dist: 1351.6794, mean_rewards: 277.4382, total_rewards: 4037.8088, mean_steps: 18.4200, mean_ecr: 0.0451 mean_entropies: 0.4642, took: 93.5008s
2022-10-11 10:47:35,352 [INFO] 	Process 4 - batch 97999: mean_policy_losses: 97.501, mean_net_lifetime: 9070.7871, mean_mc_travel_dist: 2684.5163, mean_rewards: 278.2768, total_rewards: 6411.6781, mean_steps: 35.2900, mean_ecr: 0.0420 mean_entropies: 0.5156, took: 168.1947s
2022-10-11 10:47:57,236 [INFO] 	Process 1 - batch 87399: mean_policy_losses: -64.680, mean_net_lifetime: 6639.5752, mean_mc_travel_dist: 2055.2787, mean_rewards: 250.5689, total_rewards: 4609.7586, mean_steps: 25.6400, mean_ecr: 0.0383 mean_entropies: 0.9053, took: 121.8281s
2022-10-11 10:48:28,053 [INFO] 	Process 7 - batch 96099: mean_policy_losses: -327.787, mean_net_lifetime: 5209.7316, mean_mc_travel_dist: 1613.2777, mean_rewards: 207.9948, total_rewards: 3633.5038, mean_steps: 24.4700, mean_ecr: 0.0405 mean_entropies: 1.2339, took: 886.7999s
2022-10-11 10:49:03,522 [INFO] 	Process 2 - batch 94499: mean_policy_losses: 1.065, mean_net_lifetime: 7644.7919, mean_mc_travel_dist: 1998.0645, mean_rewards: 281.5712, total_rewards: 5671.2161, mean_steps: 26.2200, mean_ecr: 0.0383 mean_entropies: 0.3551, took: 132.0419s
2022-10-11 10:49:07,469 [INFO] 	Process 3 - batch 105999: mean_policy_losses: -35.544, mean_net_lifetime: 5430.4290, mean_mc_travel_dist: 1396.1882, mean_rewards: 271.7038, total_rewards: 4061.3467, mean_steps: 19.0600, mean_ecr: 0.0449 mean_entropies: 0.4532, took: 97.4653s
2022-10-11 10:49:43,519 [INFO] 	Process 5 - batch 87499: mean_policy_losses: -68.630, mean_net_lifetime: 11719.0974, mean_mc_travel_dist: 3624.9985, mean_rewards: 259.9331, total_rewards: 8144.6347, mean_steps: 46.0800, mean_ecr: 0.0292 mean_entropies: 0.6193, took: 214.1875s
2022-10-11 10:49:56,930 [INFO] 	Process 1 - batch 87499: mean_policy_losses: -76.739, mean_net_lifetime: 6385.8503, mean_mc_travel_dist: 2001.4639, mean_rewards: 249.5171, total_rewards: 4406.8329, mean_steps: 24.7600, mean_ecr: 0.0383 mean_entropies: 0.9168, took: 119.6936s
2022-10-11 10:50:25,624 [INFO] 	Process 7 - batch 96199: mean_policy_losses: -361.403, mean_net_lifetime: 5008.4089, mean_mc_travel_dist: 1555.1557, mean_rewards: 202.4662, total_rewards: 3486.5530, mean_steps: 24.1000, mean_ecr: 0.0406 mean_entropies: 1.2233, took: 117.5708s
2022-10-11 10:50:37,141 [INFO] 	Process 3 - batch 106099: mean_policy_losses: -9.078, mean_net_lifetime: 5356.1412, mean_mc_travel_dist: 1348.9807, mean_rewards: 283.4988, total_rewards: 4033.9326, mean_steps: 17.9600, mean_ecr: 0.0452 mean_entropies: 0.4454, took: 89.6722s
2022-10-11 10:51:20,565 [INFO] 	Process 4 - batch 98099: mean_policy_losses: 152.190, mean_net_lifetime: 12095.7704, mean_mc_travel_dist: 3728.0758, mean_rewards: 278.8383, total_rewards: 8401.8318, mean_steps: 48.2800, mean_ecr: 0.0398 mean_entropies: 0.4714, took: 225.2132s
2022-10-11 10:51:54,158 [INFO] 	Process 1 - batch 87599: mean_policy_losses: -6.295, mean_net_lifetime: 6617.2606, mean_mc_travel_dist: 2056.9182, mean_rewards: 257.7190, total_rewards: 4586.1821, mean_steps: 24.8200, mean_ecr: 0.0383 mean_entropies: 0.9070, took: 117.2290s
2022-10-11 10:52:04,899 [INFO] 	Process 3 - batch 106199: mean_policy_losses: -8.530, mean_net_lifetime: 5309.1680, mean_mc_travel_dist: 1363.0806, mean_rewards: 285.2798, total_rewards: 3973.2541, mean_steps: 17.6300, mean_ecr: 0.0453 mean_entropies: 0.4728, took: 87.7573s
2022-10-11 10:52:10,613 [INFO] 	Process 7 - batch 96299: mean_policy_losses: -401.727, mean_net_lifetime: 4723.4537, mean_mc_travel_dist: 1460.5608, mean_rewards: 209.0663, total_rewards: 3303.2570, mean_steps: 21.7800, mean_ecr: 0.0410 mean_entropies: 1.2837, took: 104.9889s
2022-10-11 10:52:33,074 [INFO] 	Process 5 - batch 87599: mean_policy_losses: -146.818, mean_net_lifetime: 9667.3822, mean_mc_travel_dist: 2950.4780, mean_rewards: 268.0055, total_rewards: 6751.5081, mean_steps: 37.1900, mean_ecr: 0.0296 mean_entropies: 0.6332, took: 169.5557s
2022-10-11 10:53:37,036 [INFO] 	Process 3 - batch 106299: mean_policy_losses: 0.197, mean_net_lifetime: 5420.9613, mean_mc_travel_dist: 1367.1216, mean_rewards: 284.7087, total_rewards: 4085.5658, mean_steps: 18.1100, mean_ecr: 0.0453 mean_entropies: 0.4644, took: 92.1374s
2022-10-11 10:53:46,908 [INFO] 	Process 1 - batch 87699: mean_policy_losses: -12.910, mean_net_lifetime: 6491.4154, mean_mc_travel_dist: 2037.8544, mean_rewards: 259.9476, total_rewards: 4482.6842, mean_steps: 24.0400, mean_ecr: 0.0383 mean_entropies: 0.9147, took: 112.7494s
2022-10-11 10:53:59,192 [INFO] 	Process 4 - batch 98199: mean_policy_losses: 129.320, mean_net_lifetime: 9173.1185, mean_mc_travel_dist: 2688.4021, mean_rewards: 284.7195, total_rewards: 6509.8345, mean_steps: 33.6500, mean_ecr: 0.0413 mean_entropies: 0.5006, took: 158.6268s
2022-10-11 10:53:59,957 [INFO] 	Process 7 - batch 96399: mean_policy_losses: -379.218, mean_net_lifetime: 4958.6522, mean_mc_travel_dist: 1513.0759, mean_rewards: 211.6313, total_rewards: 3474.7594, mean_steps: 22.6300, mean_ecr: 0.0408 mean_entropies: 1.2268, took: 109.3443s
2022-10-11 10:55:08,757 [INFO] 	Process 3 - batch 106399: mean_policy_losses: -24.686, mean_net_lifetime: 5378.0741, mean_mc_travel_dist: 1329.9938, mean_rewards: 282.9120, total_rewards: 4069.6974, mean_steps: 18.0600, mean_ecr: 0.0456 mean_entropies: 0.4563, took: 91.7218s
2022-10-11 10:55:46,948 [INFO] 	Process 1 - batch 87799: mean_policy_losses: -23.796, mean_net_lifetime: 6651.7319, mean_mc_travel_dist: 2072.1014, mean_rewards: 254.2881, total_rewards: 4602.3342, mean_steps: 25.2700, mean_ecr: 0.0382 mean_entropies: 0.9340, took: 120.0401s
2022-10-11 10:55:49,659 [INFO] 	Process 5 - batch 87699: mean_policy_losses: -120.671, mean_net_lifetime: 10801.4317, mean_mc_travel_dist: 3297.5279, mean_rewards: 260.4199, total_rewards: 7534.2828, mean_steps: 42.5800, mean_ecr: 0.0293 mean_entropies: 0.6427, took: 196.5846s
2022-10-11 10:55:55,872 [INFO] 	Process 7 - batch 96499: mean_policy_losses: -328.493, mean_net_lifetime: 5109.7093, mean_mc_travel_dist: 1578.0013, mean_rewards: 206.8770, total_rewards: 3561.5740, mean_steps: 23.8100, mean_ecr: 0.0407 mean_entropies: 1.3039, took: 115.9147s
2022-10-11 10:56:40,318 [INFO] 	Process 3 - batch 106499: mean_policy_losses: -5.739, mean_net_lifetime: 5262.2584, mean_mc_travel_dist: 1309.9112, mean_rewards: 278.8984, total_rewards: 3978.4180, mean_steps: 17.9000, mean_ecr: 0.0455 mean_entropies: 0.4516, took: 91.5591s
2022-10-11 10:56:52,730 [INFO] Process 6 - epoch 94: mean_policy_losses: -176.559, mean_net_lifetime: 3323.7462, mean_mc_travel_dist: 997.1053, mean_entropies: 0.4644, m_net_lifetime_valid: 4143.6189, took: 1508.8077s, (104.5738 / 100 batches)

2022-10-11 10:57:43,254 [INFO] 	Process 1 - batch 87899: mean_policy_losses: -38.306, mean_net_lifetime: 6622.1037, mean_mc_travel_dist: 2050.7950, mean_rewards: 254.9818, total_rewards: 4596.9502, mean_steps: 25.0500, mean_ecr: 0.0383 mean_entropies: 0.9495, took: 116.3061s
2022-10-11 10:57:46,040 [INFO] 	Process 7 - batch 96599: mean_policy_losses: -342.513, mean_net_lifetime: 5077.4856, mean_mc_travel_dist: 1546.8451, mean_rewards: 214.9017, total_rewards: 3570.6142, mean_steps: 22.6700, mean_ecr: 0.0408 mean_entropies: 1.2926, took: 110.1686s
2022-10-11 10:57:47,891 [INFO] 	Process 6 - batch 141099: mean_policy_losses: -158.754, mean_net_lifetime: 3888.6651, mean_mc_travel_dist: 1057.7620, mean_rewards: 343.3726, total_rewards: 2904.4734, mean_steps: 10.3000, mean_ecr: 0.0552 mean_entropies: 0.1408, took: 718.9916s
2022-10-11 10:58:41,132 [INFO] 	Process 4 - batch 98299: mean_policy_losses: 186.589, mean_net_lifetime: 14899.5008, mean_mc_travel_dist: 4700.9822, mean_rewards: 264.6241, total_rewards: 10225.7969, mean_steps: 62.2000, mean_ecr: 0.0370 mean_entropies: 0.5400, took: 281.9399s
2022-10-11 10:58:41,691 [INFO] 	Process 6 - batch 141199: mean_policy_losses: -83.618, mean_net_lifetime: 3842.2946, mean_mc_travel_dist: 1034.3798, mean_rewards: 342.9199, total_rewards: 2874.4831, mean_steps: 10.1700, mean_ecr: 0.0551 mean_entropies: 0.1600, took: 53.7999s
2022-10-11 10:58:50,178 [INFO] 	Process 5 - batch 87799: mean_policy_losses: -93.039, mean_net_lifetime: 9967.5081, mean_mc_travel_dist: 3039.3973, mean_rewards: 256.9023, total_rewards: 6964.7678, mean_steps: 39.0600, mean_ecr: 0.0296 mean_entropies: 0.6497, took: 180.5187s
2022-10-11 10:59:37,499 [INFO] 	Process 7 - batch 96699: mean_policy_losses: -352.562, mean_net_lifetime: 4987.1109, mean_mc_travel_dist: 1512.8930, mean_rewards: 213.4794, total_rewards: 3507.7060, mean_steps: 22.8100, mean_ecr: 0.0409 mean_entropies: 1.2822, took: 111.4588s
2022-10-11 10:59:41,955 [INFO] 	Process 6 - batch 141299: mean_policy_losses: -58.810, mean_net_lifetime: 4224.6026, mean_mc_travel_dist: 1138.4953, mean_rewards: 343.2489, total_rewards: 3141.9831, mean_steps: 11.2600, mean_ecr: 0.0549 mean_entropies: 0.1332, took: 60.2639s
2022-10-11 10:59:46,251 [INFO] 	Process 1 - batch 87999: mean_policy_losses: -22.758, mean_net_lifetime: 6718.5447, mean_mc_travel_dist: 2090.8492, mean_rewards: 251.5454, total_rewards: 4656.9289, mean_steps: 25.8400, mean_ecr: 0.0382 mean_entropies: 0.9423, took: 122.9962s
2022-10-11 11:00:39,932 [INFO] 	Process 6 - batch 141399: mean_policy_losses: -76.198, mean_net_lifetime: 3995.6049, mean_mc_travel_dist: 1081.9382, mean_rewards: 339.2084, total_rewards: 2982.2712, mean_steps: 10.7100, mean_ecr: 0.0551 mean_entropies: 0.1614, took: 57.9771s
2022-10-11 11:01:03,694 [INFO] Process 2 - epoch 63: mean_policy_losses: -0.794, mean_net_lifetime: 5479.1552, mean_mc_travel_dist: 1714.2729, mean_entropies: 0.7983, m_net_lifetime_valid: 4478.0197, took: 2580.1343s, (156.1827 / 100 batches)

2022-10-11 11:01:29,885 [INFO] 	Process 7 - batch 96799: mean_policy_losses: -400.830, mean_net_lifetime: 4811.4173, mean_mc_travel_dist: 1482.7276, mean_rewards: 201.7072, total_rewards: 3364.1543, mean_steps: 23.1400, mean_ecr: 0.0410 mean_entropies: 1.2624, took: 112.3848s
2022-10-11 11:01:36,609 [INFO] 	Process 6 - batch 141499: mean_policy_losses: -118.682, mean_net_lifetime: 3913.9810, mean_mc_travel_dist: 1045.3314, mean_rewards: 337.9177, total_rewards: 2919.4256, mean_steps: 10.4700, mean_ecr: 0.0553 mean_entropies: 0.1624, took: 56.6770s
2022-10-11 11:01:43,523 [INFO] 	Process 5 - batch 87899: mean_policy_losses: -137.171, mean_net_lifetime: 9481.3742, mean_mc_travel_dist: 2853.6786, mean_rewards: 255.9585, total_rewards: 6655.0294, mean_steps: 36.9800, mean_ecr: 0.0298 mean_entropies: 0.6444, took: 173.3453s
2022-10-11 11:01:49,234 [INFO] 	Process 1 - batch 88099: mean_policy_losses: -44.653, mean_net_lifetime: 6628.4429, mean_mc_travel_dist: 2034.5821, mean_rewards: 250.0088, total_rewards: 4612.4233, mean_steps: 25.6000, mean_ecr: 0.0383 mean_entropies: 0.9442, took: 122.9828s
2022-10-11 11:01:55,991 [INFO] 	Process 4 - batch 98399: mean_policy_losses: 139.161, mean_net_lifetime: 10116.9238, mean_mc_travel_dist: 3021.1104, mean_rewards: 259.4555, total_rewards: 7117.4778, mean_steps: 41.0000, mean_ecr: 0.0381 mean_entropies: 0.5122, took: 194.8589s
2022-10-11 11:02:34,479 [INFO] 	Process 6 - batch 141599: mean_policy_losses: -91.469, mean_net_lifetime: 3967.1473, mean_mc_travel_dist: 1067.0505, mean_rewards: 338.6293, total_rewards: 2959.1059, mean_steps: 10.6500, mean_ecr: 0.0553 mean_entropies: 0.1628, took: 57.8698s
2022-10-11 11:03:11,550 [INFO] 	Process 2 - batch 94599: mean_policy_losses: -23.544, mean_net_lifetime: 7444.1301, mean_mc_travel_dist: 1948.9146, mean_rewards: 281.9146, total_rewards: 5520.7472, mean_steps: 25.4800, mean_ecr: 0.0385 mean_entropies: 0.3627, took: 848.0270s
2022-10-11 11:03:26,352 [INFO] 	Process 7 - batch 96899: mean_policy_losses: -382.597, mean_net_lifetime: 4863.8196, mean_mc_travel_dist: 1489.7126, mean_rewards: 203.7642, total_rewards: 3416.2934, mean_steps: 23.2600, mean_ecr: 0.0410 mean_entropies: 1.2149, took: 116.4683s
2022-10-11 11:03:32,244 [INFO] 	Process 6 - batch 141699: mean_policy_losses: -88.724, mean_net_lifetime: 3992.7759, mean_mc_travel_dist: 1073.9470, mean_rewards: 338.9405, total_rewards: 2981.4817, mean_steps: 10.7000, mean_ecr: 0.0554 mean_entropies: 0.1747, took: 57.7649s
2022-10-11 11:03:57,730 [INFO] 	Process 1 - batch 88199: mean_policy_losses: -49.652, mean_net_lifetime: 6653.5994, mean_mc_travel_dist: 2052.5665, mean_rewards: 248.3401, total_rewards: 4624.7931, mean_steps: 25.9400, mean_ecr: 0.0383 mean_entropies: 0.9124, took: 128.4971s
2022-10-11 11:04:30,683 [INFO] 	Process 6 - batch 141799: mean_policy_losses: -78.515, mean_net_lifetime: 4040.2675, mean_mc_travel_dist: 1092.6879, mean_rewards: 341.8659, total_rewards: 3010.5571, mean_steps: 10.7600, mean_ecr: 0.0550 mean_entropies: 0.1584, took: 58.4393s
2022-10-11 11:04:33,537 [INFO] 	Process 5 - batch 87999: mean_policy_losses: -148.030, mean_net_lifetime: 9153.9644, mean_mc_travel_dist: 2769.3985, mean_rewards: 258.3850, total_rewards: 6426.3069, mean_steps: 35.1100, mean_ecr: 0.0299 mean_entropies: 0.6501, took: 170.0141s
2022-10-11 11:05:11,667 [INFO] 	Process 7 - batch 96999: mean_policy_losses: -463.160, mean_net_lifetime: 4582.3667, mean_mc_travel_dist: 1360.3950, mean_rewards: 211.2457, total_rewards: 3260.4747, mean_steps: 21.1600, mean_ecr: 0.0414 mean_entropies: 1.2899, took: 105.3150s
2022-10-11 11:05:12,837 [INFO] 	Process 2 - batch 94699: mean_policy_losses: -53.801, mean_net_lifetime: 7125.3130, mean_mc_travel_dist: 1846.1258, mean_rewards: 285.0324, total_rewards: 5304.9475, mean_steps: 24.0700, mean_ecr: 0.0389 mean_entropies: 0.3710, took: 121.2873s
2022-10-11 11:05:30,406 [INFO] 	Process 6 - batch 141899: mean_policy_losses: -87.474, mean_net_lifetime: 4139.2404, mean_mc_travel_dist: 1118.5462, mean_rewards: 342.3538, total_rewards: 3084.8504, mean_steps: 11.0500, mean_ecr: 0.0550 mean_entropies: 0.1447, took: 59.7232s
2022-10-11 11:05:46,584 [INFO] 	Process 4 - batch 98499: mean_policy_losses: 170.648, mean_net_lifetime: 11660.6097, mean_mc_travel_dist: 3662.5811, mean_rewards: 262.6538, total_rewards: 8021.2197, mean_steps: 48.4200, mean_ecr: 0.0383 mean_entropies: 0.5117, took: 230.5928s
2022-10-11 11:06:00,385 [INFO] 	Process 1 - batch 88299: mean_policy_losses: -41.268, mean_net_lifetime: 6619.6251, mean_mc_travel_dist: 2060.3409, mean_rewards: 255.8341, total_rewards: 4583.9050, mean_steps: 25.0900, mean_ecr: 0.0381 mean_entropies: 0.9243, took: 122.6538s
2022-10-11 11:06:28,190 [INFO] 	Process 6 - batch 141999: mean_policy_losses: -102.882, mean_net_lifetime: 3989.0757, mean_mc_travel_dist: 1065.0326, mean_rewards: 340.1829, total_rewards: 2972.9537, mean_steps: 10.6400, mean_ecr: 0.0550 mean_entropies: 0.1465, took: 57.7844s
2022-10-11 11:06:53,108 [INFO] 	Process 7 - batch 97099: mean_policy_losses: -401.176, mean_net_lifetime: 4487.1325, mean_mc_travel_dist: 1355.4624, mean_rewards: 211.5762, total_rewards: 3173.5590, mean_steps: 20.3800, mean_ecr: 0.0413 mean_entropies: 1.3029, took: 101.4414s
2022-10-11 11:07:01,091 [INFO] 	Process 5 - batch 88099: mean_policy_losses: -146.606, mean_net_lifetime: 8140.8530, mean_mc_travel_dist: 2480.7567, mean_rewards: 267.7482, total_rewards: 5701.9074, mean_steps: 29.9600, mean_ecr: 0.0301 mean_entropies: 0.6977, took: 147.5527s
2022-10-11 11:07:19,349 [INFO] 	Process 2 - batch 94799: mean_policy_losses: -20.098, mean_net_lifetime: 7447.4587, mean_mc_travel_dist: 1948.9783, mean_rewards: 287.3222, total_rewards: 5524.5090, mean_steps: 25.0400, mean_ecr: 0.0385 mean_entropies: 0.3900, took: 126.5135s
2022-10-11 11:07:23,649 [INFO] 	Process 6 - batch 142099: mean_policy_losses: -135.101, mean_net_lifetime: 3932.1148, mean_mc_travel_dist: 1049.8416, mean_rewards: 344.1922, total_rewards: 2925.1597, mean_steps: 10.3900, mean_ecr: 0.0549 mean_entropies: 0.1424, took: 55.4580s
2022-10-11 11:08:04,805 [INFO] 	Process 1 - batch 88399: mean_policy_losses: -33.267, mean_net_lifetime: 6730.1902, mean_mc_travel_dist: 2086.9813, mean_rewards: 254.3712, total_rewards: 4667.9023, mean_steps: 25.6300, mean_ecr: 0.0381 mean_entropies: 0.9058, took: 124.4209s
2022-10-11 11:08:22,152 [INFO] 	Process 6 - batch 142199: mean_policy_losses: -86.585, mean_net_lifetime: 4001.7174, mean_mc_travel_dist: 1068.4305, mean_rewards: 340.0521, total_rewards: 2963.9855, mean_steps: 10.6600, mean_ecr: 0.0552 mean_entropies: 0.1502, took: 58.5028s
2022-10-11 11:08:23,146 [INFO] Process 3 - epoch 71: mean_policy_losses: 38.978, mean_net_lifetime: 4562.6785, mean_mc_travel_dist: 1343.1631, mean_entropies: 0.7684, m_net_lifetime_valid: 4616.8319, took: 2094.3019s, (139.0289 / 100 batches)

2022-10-11 11:09:01,078 [INFO] 	Process 7 - batch 97199: mean_policy_losses: -217.702, mean_net_lifetime: 5336.0058, mean_mc_travel_dist: 1635.0218, mean_rewards: 201.7480, total_rewards: 3739.0779, mean_steps: 25.8300, mean_ecr: 0.0405 mean_entropies: 1.2387, took: 127.9694s
2022-10-11 11:09:20,142 [INFO] 	Process 6 - batch 142299: mean_policy_losses: -94.395, mean_net_lifetime: 3842.5351, mean_mc_travel_dist: 1021.8824, mean_rewards: 337.6398, total_rewards: 2857.2760, mean_steps: 10.2700, mean_ecr: 0.0553 mean_entropies: 0.1615, took: 57.9906s
2022-10-11 11:09:21,934 [INFO] 	Process 4 - batch 98599: mean_policy_losses: 200.493, mean_net_lifetime: 11187.0248, mean_mc_travel_dist: 3420.5515, mean_rewards: 268.7679, total_rewards: 7799.2965, mean_steps: 45.1100, mean_ecr: 0.0392 mean_entropies: 0.5250, took: 215.3507s
2022-10-11 11:09:32,532 [INFO] 	Process 2 - batch 94899: mean_policy_losses: -23.827, mean_net_lifetime: 7580.3166, mean_mc_travel_dist: 1985.9197, mean_rewards: 281.0960, total_rewards: 5613.8355, mean_steps: 26.0400, mean_ecr: 0.0383 mean_entropies: 0.3919, took: 133.1830s
2022-10-11 11:09:55,673 [INFO] 	Process 5 - batch 88199: mean_policy_losses: -84.002, mean_net_lifetime: 9391.4457, mean_mc_travel_dist: 2854.9548, mean_rewards: 261.7152, total_rewards: 6570.0909, mean_steps: 35.5100, mean_ecr: 0.0297 mean_entropies: 0.6652, took: 174.5836s
2022-10-11 11:10:05,553 [INFO] 	Process 3 - batch 106599: mean_policy_losses: -34.310, mean_net_lifetime: 5497.0783, mean_mc_travel_dist: 1415.6861, mean_rewards: 273.1521, total_rewards: 4124.9577, mean_steps: 19.2100, mean_ecr: 0.0447 mean_entropies: 0.4606, took: 805.2365s
2022-10-11 11:10:14,199 [INFO] 	Process 1 - batch 88499: mean_policy_losses: -58.457, mean_net_lifetime: 6703.5710, mean_mc_travel_dist: 2063.0887, mean_rewards: 251.5838, total_rewards: 4663.1877, mean_steps: 25.8100, mean_ecr: 0.0382 mean_entropies: 0.9419, took: 129.3941s
2022-10-11 11:10:22,575 [INFO] 	Process 6 - batch 142399: mean_policy_losses: -97.722, mean_net_lifetime: 4164.5059, mean_mc_travel_dist: 1098.4895, mean_rewards: 344.0541, total_rewards: 3086.3562, mean_steps: 11.0500, mean_ecr: 0.0550 mean_entropies: 0.1298, took: 62.4329s
2022-10-11 11:10:53,001 [INFO] 	Process 7 - batch 97299: mean_policy_losses: -412.956, mean_net_lifetime: 4718.2991, mean_mc_travel_dist: 1429.5266, mean_rewards: 208.7250, total_rewards: 3321.4325, mean_steps: 21.9200, mean_ecr: 0.0412 mean_entropies: 1.3028, took: 111.9234s
2022-10-11 11:11:22,583 [INFO] 	Process 6 - batch 142499: mean_policy_losses: -68.323, mean_net_lifetime: 4092.9190, mean_mc_travel_dist: 1079.3249, mean_rewards: 345.3404, total_rewards: 3031.8986, mean_steps: 10.8200, mean_ecr: 0.0551 mean_entropies: 0.1243, took: 60.0079s
2022-10-11 11:11:38,645 [INFO] 	Process 3 - batch 106699: mean_policy_losses: -29.360, mean_net_lifetime: 5322.7812, mean_mc_travel_dist: 1314.0943, mean_rewards: 280.8525, total_rewards: 4039.5081, mean_steps: 17.9900, mean_ecr: 0.0457 mean_entropies: 0.4626, took: 93.0913s
2022-10-11 11:11:42,410 [INFO] 	Process 2 - batch 94999: mean_policy_losses: -36.481, mean_net_lifetime: 7489.2151, mean_mc_travel_dist: 1979.6168, mean_rewards: 283.9571, total_rewards: 5531.3558, mean_steps: 25.5100, mean_ecr: 0.0384 mean_entropies: 0.3998, took: 129.8778s
2022-10-11 11:12:00,157 [INFO] 	Process 4 - batch 98699: mean_policy_losses: 162.888, mean_net_lifetime: 8352.7202, mean_mc_travel_dist: 2407.6790, mean_rewards: 272.4423, total_rewards: 5969.4096, mean_steps: 31.6100, mean_ecr: 0.0410 mean_entropies: 0.5497, took: 158.2232s
2022-10-11 11:12:37,870 [INFO] 	Process 5 - batch 88299: mean_policy_losses: -154.392, mean_net_lifetime: 9218.9360, mean_mc_travel_dist: 2794.8860, mean_rewards: 268.4077, total_rewards: 6459.8659, mean_steps: 34.2000, mean_ecr: 0.0300 mean_entropies: 0.6667, took: 162.1960s
2022-10-11 11:12:38,653 [INFO] 	Process 7 - batch 97399: mean_policy_losses: -410.850, mean_net_lifetime: 4782.5826, mean_mc_travel_dist: 1443.8979, mean_rewards: 210.4519, total_rewards: 3362.8818, mean_steps: 21.9700, mean_ecr: 0.0411 mean_entropies: 1.2712, took: 105.6515s
2022-10-11 11:13:08,570 [INFO] 	Process 3 - batch 106799: mean_policy_losses: -28.134, mean_net_lifetime: 5240.1197, mean_mc_travel_dist: 1291.4201, mean_rewards: 275.4779, total_rewards: 3977.1494, mean_steps: 18.1200, mean_ecr: 0.0459 mean_entropies: 0.4699, took: 89.9255s
2022-10-11 11:13:46,702 [INFO] 	Process 2 - batch 95099: mean_policy_losses: -24.787, mean_net_lifetime: 7247.0243, mean_mc_travel_dist: 1875.3805, mean_rewards: 281.0290, total_rewards: 5396.2106, mean_steps: 24.8300, mean_ecr: 0.0386 mean_entropies: 0.3508, took: 124.2919s
2022-10-11 11:14:42,285 [INFO] 	Process 3 - batch 106899: mean_policy_losses: -25.843, mean_net_lifetime: 5317.7295, mean_mc_travel_dist: 1341.3074, mean_rewards: 269.8831, total_rewards: 4007.2528, mean_steps: 18.7900, mean_ecr: 0.0455 mean_entropies: 0.4640, took: 93.7147s
2022-10-11 11:14:43,526 [INFO] 	Process 7 - batch 97499: mean_policy_losses: -204.455, mean_net_lifetime: 5162.8909, mean_mc_travel_dist: 1585.7344, mean_rewards: 194.5978, total_rewards: 3613.3809, mean_steps: 26.0400, mean_ecr: 0.0404 mean_entropies: 1.1766, took: 124.8735s
2022-10-11 11:14:57,525 [INFO] 	Process 5 - batch 88399: mean_policy_losses: -149.176, mean_net_lifetime: 7854.2989, mean_mc_travel_dist: 2381.1907, mean_rewards: 263.8333, total_rewards: 5520.4456, mean_steps: 29.2300, mean_ecr: 0.0302 mean_entropies: 0.6311, took: 139.6554s
2022-10-11 11:15:10,369 [INFO] 	Process 4 - batch 98799: mean_policy_losses: 166.514, mean_net_lifetime: 10198.0131, mean_mc_travel_dist: 3042.4946, mean_rewards: 268.6359, total_rewards: 7184.9399, mean_steps: 40.9100, mean_ecr: 0.0390 mean_entropies: 0.5235, took: 190.2112s
2022-10-11 11:15:51,229 [INFO] 	Process 2 - batch 95199: mean_policy_losses: -29.845, mean_net_lifetime: 7513.9998, mean_mc_travel_dist: 1985.5386, mean_rewards: 284.4374, total_rewards: 5558.1002, mean_steps: 25.5100, mean_ecr: 0.0384 mean_entropies: 0.3678, took: 124.5267s
2022-10-11 11:16:09,959 [INFO] 	Process 3 - batch 106999: mean_policy_losses: -42.500, mean_net_lifetime: 5447.4295, mean_mc_travel_dist: 1372.1812, mean_rewards: 280.0855, total_rewards: 4102.6551, mean_steps: 18.5700, mean_ecr: 0.0451 mean_entropies: 0.4565, took: 87.6737s
2022-10-11 11:17:40,433 [INFO] 	Process 3 - batch 107099: mean_policy_losses: -47.786, mean_net_lifetime: 5411.3224, mean_mc_travel_dist: 1388.9426, mean_rewards: 272.0143, total_rewards: 4048.2331, mean_steps: 19.0200, mean_ecr: 0.0448 mean_entropies: 0.4621, took: 90.4748s
2022-10-11 11:17:48,731 [INFO] 	Process 5 - batch 88499: mean_policy_losses: -93.405, mean_net_lifetime: 10155.4009, mean_mc_travel_dist: 3078.0543, mean_rewards: 262.7652, total_rewards: 7124.9091, mean_steps: 38.7100, mean_ecr: 0.0297 mean_entropies: 0.6620, took: 171.2058s
2022-10-11 11:17:51,627 [INFO] 	Process 2 - batch 95299: mean_policy_losses: -27.951, mean_net_lifetime: 7457.5516, mean_mc_travel_dist: 1980.9990, mean_rewards: 284.7201, total_rewards: 5498.6302, mean_steps: 25.2900, mean_ecr: 0.0383 mean_entropies: 0.3724, took: 120.3972s
2022-10-11 11:18:45,511 [INFO] 	Process 4 - batch 98899: mean_policy_losses: 119.031, mean_net_lifetime: 11724.0612, mean_mc_travel_dist: 3650.9114, mean_rewards: 263.2147, total_rewards: 8098.1495, mean_steps: 49.2300, mean_ecr: 0.0375 mean_entropies: 0.5067, took: 215.1428s
2022-10-11 11:19:04,868 [INFO] 	Process 3 - batch 107199: mean_policy_losses: -66.236, mean_net_lifetime: 5387.0148, mean_mc_travel_dist: 1377.1799, mean_rewards: 279.2731, total_rewards: 4044.3035, mean_steps: 18.3300, mean_ecr: 0.0451 mean_entropies: 0.4659, took: 84.4351s
2022-10-11 11:19:46,750 [INFO] 	Process 2 - batch 95399: mean_policy_losses: -41.134, mean_net_lifetime: 7481.4258, mean_mc_travel_dist: 1957.6172, mean_rewards: 286.6282, total_rewards: 5549.4694, mean_steps: 25.1700, mean_ecr: 0.0384 mean_entropies: 0.3759, took: 115.1238s
2022-10-11 11:20:26,774 [INFO] 	Process 3 - batch 107299: mean_policy_losses: -73.945, mean_net_lifetime: 5246.1037, mean_mc_travel_dist: 1321.1097, mean_rewards: 281.7767, total_rewards: 3957.7111, mean_steps: 17.7400, mean_ecr: 0.0457 mean_entropies: 0.4693, took: 81.9055s
2022-10-11 11:20:40,994 [INFO] Process 1 - epoch 59: mean_policy_losses: 11.516, mean_net_lifetime: 5523.7548, mean_mc_travel_dist: 2042.1081, mean_entropies: 1.1199, m_net_lifetime_valid: 4437.6293, took: 2455.9752s, (168.1935 / 100 batches)

2022-10-11 11:21:33,437 [INFO] Process 6 - epoch 95: mean_policy_losses: -175.702, mean_net_lifetime: 3330.8840, mean_mc_travel_dist: 997.9029, mean_entropies: 0.4610, m_net_lifetime_valid: 4196.6333, took: 1480.7041s, (104.5493 / 100 batches)

2022-10-11 11:21:48,884 [INFO] 	Process 2 - batch 95499: mean_policy_losses: -32.884, mean_net_lifetime: 7530.6709, mean_mc_travel_dist: 1967.7710, mean_rewards: 280.1450, total_rewards: 5584.0116, mean_steps: 25.9400, mean_ecr: 0.0382 mean_entropies: 0.3529, took: 122.1346s
2022-10-11 11:21:54,381 [INFO] 	Process 3 - batch 107399: mean_policy_losses: -55.161, mean_net_lifetime: 5293.6056, mean_mc_travel_dist: 1315.9772, mean_rewards: 275.7664, total_rewards: 4001.1468, mean_steps: 18.2300, mean_ecr: 0.0454 mean_entropies: 0.4657, took: 87.6069s
2022-10-11 11:22:27,450 [INFO] 	Process 6 - batch 142599: mean_policy_losses: -148.063, mean_net_lifetime: 3749.1182, mean_mc_travel_dist: 1008.9048, mean_rewards: 339.8171, total_rewards: 2785.0443, mean_steps: 9.9500, mean_ecr: 0.0554 mean_entropies: 0.1650, took: 664.8669s
2022-10-11 11:22:36,385 [INFO] 	Process 1 - batch 88599: mean_policy_losses: -86.020, mean_net_lifetime: 6503.9877, mean_mc_travel_dist: 2020.8367, mean_rewards: 253.0246, total_rewards: 4509.0795, mean_steps: 24.8400, mean_ecr: 0.0383 mean_entropies: 0.9239, took: 742.1860s
2022-10-11 11:22:54,541 [INFO] 	Process 4 - batch 98999: mean_policy_losses: 103.422, mean_net_lifetime: 13844.3874, mean_mc_travel_dist: 4401.6447, mean_rewards: 263.7400, total_rewards: 9464.7823, mean_steps: 57.9300, mean_ecr: 0.0365 mean_entropies: 0.5009, took: 249.0291s
2022-10-11 11:23:18,806 [INFO] 	Process 6 - batch 142699: mean_policy_losses: -178.310, mean_net_lifetime: 3635.5552, mean_mc_travel_dist: 977.8117, mean_rewards: 338.6431, total_rewards: 2710.5590, mean_steps: 9.7000, mean_ecr: 0.0555 mean_entropies: 0.1662, took: 51.3568s
2022-10-11 11:23:23,235 [INFO] 	Process 3 - batch 107499: mean_policy_losses: -37.013, mean_net_lifetime: 5330.7864, mean_mc_travel_dist: 1343.2013, mean_rewards: 277.5105, total_rewards: 4016.8221, mean_steps: 18.3600, mean_ecr: 0.0453 mean_entropies: 0.4542, took: 88.8534s
2022-10-11 11:23:51,064 [INFO] 	Process 2 - batch 95599: mean_policy_losses: -12.704, mean_net_lifetime: 7619.1167, mean_mc_travel_dist: 1976.9761, mean_rewards: 283.7724, total_rewards: 5663.1914, mean_steps: 25.9300, mean_ecr: 0.0382 mean_entropies: 0.3701, took: 122.1797s
2022-10-11 11:24:13,758 [INFO] 	Process 6 - batch 142799: mean_policy_losses: -75.236, mean_net_lifetime: 3956.7828, mean_mc_travel_dist: 1048.8529, mean_rewards: 343.6009, total_rewards: 2950.8861, mean_steps: 10.4900, mean_ecr: 0.0550 mean_entropies: 0.1427, took: 54.9513s
2022-10-11 11:24:28,573 [INFO] 	Process 1 - batch 88699: mean_policy_losses: -49.154, mean_net_lifetime: 6631.2947, mean_mc_travel_dist: 2053.2068, mean_rewards: 254.6458, total_rewards: 4603.9854, mean_steps: 25.0800, mean_ecr: 0.0383 mean_entropies: 0.9430, took: 112.1877s
2022-10-11 11:24:49,950 [INFO] 	Process 3 - batch 107599: mean_policy_losses: -52.464, mean_net_lifetime: 5342.2566, mean_mc_travel_dist: 1364.9394, mean_rewards: 282.2776, total_rewards: 4009.7844, mean_steps: 17.9600, mean_ecr: 0.0453 mean_entropies: 0.4713, took: 86.7157s
2022-10-11 11:25:06,638 [INFO] 	Process 6 - batch 142899: mean_policy_losses: -98.384, mean_net_lifetime: 3995.3745, mean_mc_travel_dist: 1070.7510, mean_rewards: 343.1425, total_rewards: 2969.8453, mean_steps: 10.6000, mean_ecr: 0.0550 mean_entropies: 0.1380, took: 52.8802s
2022-10-11 11:25:47,479 [INFO] 	Process 2 - batch 95699: mean_policy_losses: -13.661, mean_net_lifetime: 7539.0808, mean_mc_travel_dist: 1975.3701, mean_rewards: 286.0729, total_rewards: 5586.4642, mean_steps: 25.4000, mean_ecr: 0.0383 mean_entropies: 0.3684, took: 116.4146s
2022-10-11 11:25:58,350 [INFO] 	Process 6 - batch 142999: mean_policy_losses: -56.929, mean_net_lifetime: 3861.5594, mean_mc_travel_dist: 1037.9401, mean_rewards: 342.7400, total_rewards: 2878.2186, mean_steps: 10.2600, mean_ecr: 0.0552 mean_entropies: 0.1577, took: 51.7120s
2022-10-11 11:26:16,869 [INFO] Process 7 - epoch 65: mean_policy_losses: -364.272, mean_net_lifetime: 4379.2534, mean_mc_travel_dist: 1551.4338, mean_entropies: 1.4987, m_net_lifetime_valid: 4460.0172, took: 2388.4221s, (152.9597 / 100 batches)

2022-10-11 11:26:17,458 [INFO] 	Process 3 - batch 107699: mean_policy_losses: -43.199, mean_net_lifetime: 5215.3774, mean_mc_travel_dist: 1331.7953, mean_rewards: 270.4825, total_rewards: 3911.1382, mean_steps: 18.3800, mean_ecr: 0.0450 mean_entropies: 0.4469, took: 87.5084s
2022-10-11 11:26:24,398 [INFO] 	Process 1 - batch 88799: mean_policy_losses: -91.868, mean_net_lifetime: 6394.6909, mean_mc_travel_dist: 1978.2858, mean_rewards: 245.9435, total_rewards: 4443.1738, mean_steps: 25.2400, mean_ecr: 0.0384 mean_entropies: 0.9184, took: 115.8248s
2022-10-11 11:26:54,320 [INFO] 	Process 6 - batch 143099: mean_policy_losses: -88.528, mean_net_lifetime: 4056.6884, mean_mc_travel_dist: 1076.4564, mean_rewards: 345.2221, total_rewards: 3012.8754, mean_steps: 10.7100, mean_ecr: 0.0551 mean_entropies: 0.1243, took: 55.9695s
2022-10-11 11:27:48,134 [INFO] 	Process 3 - batch 107799: mean_policy_losses: -35.021, mean_net_lifetime: 5334.3853, mean_mc_travel_dist: 1347.5065, mean_rewards: 276.9446, total_rewards: 4016.7169, mean_steps: 18.3600, mean_ecr: 0.0451 mean_entropies: 0.4594, took: 90.6764s
2022-10-11 11:27:51,806 [INFO] 	Process 2 - batch 95799: mean_policy_losses: -15.297, mean_net_lifetime: 7639.5986, mean_mc_travel_dist: 1997.8625, mean_rewards: 282.7715, total_rewards: 5667.1336, mean_steps: 26.1400, mean_ecr: 0.0382 mean_entropies: 0.3600, took: 124.3270s
2022-10-11 11:27:52,294 [INFO] 	Process 6 - batch 143199: mean_policy_losses: -48.853, mean_net_lifetime: 4271.1660, mean_mc_travel_dist: 1127.8682, mean_rewards: 345.3140, total_rewards: 3166.7503, mean_steps: 11.3300, mean_ecr: 0.0549 mean_entropies: 0.1057, took: 57.9746s
2022-10-11 11:28:07,677 [INFO] 	Process 7 - batch 97599: mean_policy_losses: -400.766, mean_net_lifetime: 5015.9442, mean_mc_travel_dist: 1508.8718, mean_rewards: 207.8232, total_rewards: 3533.2956, mean_steps: 23.4100, mean_ecr: 0.0409 mean_entropies: 1.2567, took: 804.1497s
2022-10-11 11:28:23,966 [INFO] 	Process 1 - batch 88899: mean_policy_losses: -98.097, mean_net_lifetime: 6470.3600, mean_mc_travel_dist: 2005.9111, mean_rewards: 242.9988, total_rewards: 4483.7226, mean_steps: 25.8500, mean_ecr: 0.0384 mean_entropies: 0.9143, took: 119.5685s
2022-10-11 11:28:31,568 [INFO] Process 5 - epoch 59: mean_policy_losses: -187.821, mean_net_lifetime: 6076.2602, mean_mc_travel_dist: 2215.0858, mean_entropies: 1.0674, m_net_lifetime_valid: 4414.9459, took: 3153.0033s, (168.7064 / 100 batches)

2022-10-11 11:28:47,542 [INFO] 	Process 6 - batch 143299: mean_policy_losses: -112.578, mean_net_lifetime: 3873.3545, mean_mc_travel_dist: 1033.5285, mean_rewards: 341.8289, total_rewards: 2880.4690, mean_steps: 10.2600, mean_ecr: 0.0552 mean_entropies: 0.1290, took: 55.2476s
2022-10-11 11:29:21,364 [INFO] 	Process 3 - batch 107899: mean_policy_losses: -25.736, mean_net_lifetime: 5432.9184, mean_mc_travel_dist: 1383.8615, mean_rewards: 279.8185, total_rewards: 4074.4420, mean_steps: 18.5300, mean_ecr: 0.0451 mean_entropies: 0.4418, took: 93.2293s
2022-10-11 11:29:44,534 [INFO] 	Process 6 - batch 143399: mean_policy_losses: -77.837, mean_net_lifetime: 3982.1327, mean_mc_travel_dist: 1047.3651, mean_rewards: 343.7864, total_rewards: 2959.8875, mean_steps: 10.5400, mean_ecr: 0.0549 mean_entropies: 0.1257, took: 56.9920s
2022-10-11 11:29:56,332 [INFO] 	Process 7 - batch 97699: mean_policy_losses: -306.719, mean_net_lifetime: 4751.0704, mean_mc_travel_dist: 1456.9978, mean_rewards: 203.2616, total_rewards: 3329.9690, mean_steps: 22.4800, mean_ecr: 0.0409 mean_entropies: 1.2891, took: 108.6560s
2022-10-11 11:30:00,445 [INFO] 	Process 2 - batch 95899: mean_policy_losses: 4.507, mean_net_lifetime: 7539.4835, mean_mc_travel_dist: 1957.3237, mean_rewards: 282.5381, total_rewards: 5610.5952, mean_steps: 25.7400, mean_ecr: 0.0384 mean_entropies: 0.3741, took: 128.6384s
2022-10-11 11:30:27,184 [INFO] 	Process 1 - batch 88999: mean_policy_losses: 6.327, mean_net_lifetime: 6636.9265, mean_mc_travel_dist: 2069.0445, mean_rewards: 251.0874, total_rewards: 4589.6185, mean_steps: 25.5600, mean_ecr: 0.0381 mean_entropies: 0.9093, took: 123.2179s
2022-10-11 11:30:34,027 [INFO] 	Process 6 - batch 143499: mean_policy_losses: -108.767, mean_net_lifetime: 3389.8378, mean_mc_travel_dist: 915.3628, mean_rewards: 340.3440, total_rewards: 2525.7652, mean_steps: 8.9300, mean_ecr: 0.0554 mean_entropies: 0.2135, took: 49.4938s
2022-10-11 11:30:52,635 [INFO] 	Process 3 - batch 107999: mean_policy_losses: 12.809, mean_net_lifetime: 5231.8597, mean_mc_travel_dist: 1315.5513, mean_rewards: 275.8891, total_rewards: 3936.9520, mean_steps: 18.0700, mean_ecr: 0.0456 mean_entropies: 0.5050, took: 91.2712s
2022-10-11 11:31:11,796 [INFO] 	Process 5 - batch 88599: mean_policy_losses: -92.702, mean_net_lifetime: 8880.6120, mean_mc_travel_dist: 2678.2274, mean_rewards: 263.5739, total_rewards: 6241.3842, mean_steps: 33.6200, mean_ecr: 0.0300 mean_entropies: 0.6736, took: 803.0635s
2022-10-11 11:31:26,342 [INFO] 	Process 6 - batch 143599: mean_policy_losses: -115.419, mean_net_lifetime: 3632.1890, mean_mc_travel_dist: 974.1881, mean_rewards: 339.5181, total_rewards: 2705.8619, mean_steps: 9.6500, mean_ecr: 0.0555 mean_entropies: 0.1872, took: 52.3147s
2022-10-11 11:31:31,570 [INFO] 	Process 7 - batch 97799: mean_policy_losses: -232.888, mean_net_lifetime: 4431.1930, mean_mc_travel_dist: 1389.7137, mean_rewards: 218.1074, total_rewards: 3082.5020, mean_steps: 19.2900, mean_ecr: 0.0413 mean_entropies: 1.2949, took: 95.2378s
2022-10-11 11:32:08,261 [INFO] 	Process 2 - batch 95999: mean_policy_losses: -2.794, mean_net_lifetime: 7555.0976, mean_mc_travel_dist: 2017.0948, mean_rewards: 283.1752, total_rewards: 5560.4986, mean_steps: 25.7500, mean_ecr: 0.0382 mean_entropies: 0.4565, took: 127.8162s
2022-10-11 11:32:20,707 [INFO] 	Process 6 - batch 143699: mean_policy_losses: -111.569, mean_net_lifetime: 3934.9373, mean_mc_travel_dist: 1057.1872, mean_rewards: 339.4458, total_rewards: 2912.6972, mean_steps: 10.5500, mean_ecr: 0.0551 mean_entropies: 0.1478, took: 54.3655s
2022-10-11 11:32:26,450 [INFO] 	Process 1 - batch 89099: mean_policy_losses: 10.441, mean_net_lifetime: 6688.1224, mean_mc_travel_dist: 2091.8834, mean_rewards: 252.7276, total_rewards: 4618.9450, mean_steps: 25.6000, mean_ecr: 0.0381 mean_entropies: 0.9038, took: 119.2663s
2022-10-11 11:33:15,074 [INFO] 	Process 6 - batch 143799: mean_policy_losses: -111.218, mean_net_lifetime: 4031.9570, mean_mc_travel_dist: 1071.1489, mean_rewards: 341.9678, total_rewards: 2989.5337, mean_steps: 10.7200, mean_ecr: 0.0551 mean_entropies: 0.1161, took: 54.3666s
2022-10-11 11:33:28,655 [INFO] 	Process 7 - batch 97899: mean_policy_losses: -196.847, mean_net_lifetime: 5123.9234, mean_mc_travel_dist: 1556.5560, mean_rewards: 200.9466, total_rewards: 3598.1068, mean_steps: 25.2000, mean_ecr: 0.0407 mean_entropies: 1.2130, took: 117.0842s
2022-10-11 11:33:45,593 [INFO] Process 4 - epoch 66: mean_policy_losses: 110.996, mean_net_lifetime: 5306.5322, mean_mc_travel_dist: 1645.1058, mean_entropies: 1.0006, m_net_lifetime_valid: 4600.2183, took: 3707.1102s, (151.1399 / 100 batches)

2022-10-11 11:33:48,406 [INFO] 	Process 5 - batch 88699: mean_policy_losses: -56.598, mean_net_lifetime: 9175.0721, mean_mc_travel_dist: 2752.9456, mean_rewards: 261.7623, total_rewards: 6465.8513, mean_steps: 34.7400, mean_ecr: 0.0300 mean_entropies: 0.6268, took: 156.6110s
2022-10-11 11:34:10,768 [INFO] 	Process 6 - batch 143899: mean_policy_losses: -74.783, mean_net_lifetime: 3968.4110, mean_mc_travel_dist: 1072.6431, mean_rewards: 340.0360, total_rewards: 2942.5778, mean_steps: 10.6200, mean_ecr: 0.0551 mean_entropies: 0.1227, took: 55.6937s
2022-10-11 11:34:21,315 [INFO] 	Process 1 - batch 89199: mean_policy_losses: -64.042, mean_net_lifetime: 6471.0935, mean_mc_travel_dist: 1983.7289, mean_rewards: 245.7640, total_rewards: 4508.8056, mean_steps: 25.4700, mean_ecr: 0.0384 mean_entropies: 0.8753, took: 114.8646s
2022-10-11 11:35:06,712 [INFO] 	Process 6 - batch 143999: mean_policy_losses: -76.227, mean_net_lifetime: 3972.8458, mean_mc_travel_dist: 1046.3597, mean_rewards: 344.2217, total_rewards: 2960.8453, mean_steps: 10.5100, mean_ecr: 0.0548 mean_entropies: 0.1253, took: 55.9448s
2022-10-11 11:35:25,893 [INFO] 	Process 7 - batch 97999: mean_policy_losses: -164.171, mean_net_lifetime: 5360.5921, mean_mc_travel_dist: 1654.6632, mean_rewards: 208.4015, total_rewards: 3746.3020, mean_steps: 25.1500, mean_ecr: 0.0404 mean_entropies: 1.2172, took: 117.2395s
2022-10-11 11:36:22,919 [INFO] 	Process 1 - batch 89299: mean_policy_losses: -58.981, mean_net_lifetime: 6833.4643, mean_mc_travel_dist: 2102.9113, mean_rewards: 246.8696, total_rewards: 4760.6192, mean_steps: 26.8200, mean_ecr: 0.0381 mean_entropies: 0.9339, took: 121.6044s
2022-10-11 11:36:24,920 [INFO] 	Process 5 - batch 88799: mean_policy_losses: -53.816, mean_net_lifetime: 9304.9951, mean_mc_travel_dist: 2805.4869, mean_rewards: 266.4825, total_rewards: 6542.0087, mean_steps: 34.4800, mean_ecr: 0.0298 mean_entropies: 0.6707, took: 156.5148s
2022-10-11 11:36:58,873 [INFO] 	Process 4 - batch 99099: mean_policy_losses: 187.366, mean_net_lifetime: 10428.7955, mean_mc_travel_dist: 3217.0726, mean_rewards: 265.2269, total_rewards: 7242.9370, mean_steps: 41.9700, mean_ecr: 0.0390 mean_entropies: 0.5348, took: 844.3323s
2022-10-11 11:37:03,952 [INFO] 	Process 7 - batch 98099: mean_policy_losses: -405.834, mean_net_lifetime: 4536.7541, mean_mc_travel_dist: 1398.2668, mean_rewards: 211.6866, total_rewards: 3170.7328, mean_steps: 20.7900, mean_ecr: 0.0413 mean_entropies: 1.2901, took: 98.0585s
2022-10-11 11:38:21,188 [INFO] 	Process 1 - batch 89399: mean_policy_losses: -35.954, mean_net_lifetime: 6555.1354, mean_mc_travel_dist: 2014.1174, mean_rewards: 243.0480, total_rewards: 4568.8471, mean_steps: 26.1100, mean_ecr: 0.0383 mean_entropies: 0.9105, took: 118.2689s
2022-10-11 11:38:47,793 [INFO] 	Process 7 - batch 98199: mean_policy_losses: -392.765, mean_net_lifetime: 4718.5049, mean_mc_travel_dist: 1431.1255, mean_rewards: 207.0255, total_rewards: 3322.3110, mean_steps: 22.0200, mean_ecr: 0.0412 mean_entropies: 1.2991, took: 103.8410s
2022-10-11 11:39:09,966 [INFO] 	Process 5 - batch 88899: mean_policy_losses: -43.914, mean_net_lifetime: 9816.7544, mean_mc_travel_dist: 2985.5968, mean_rewards: 264.3553, total_rewards: 6876.1323, mean_steps: 36.9100, mean_ecr: 0.0296 mean_entropies: 0.6671, took: 165.0450s
2022-10-11 11:40:14,862 [INFO] 	Process 1 - batch 89499: mean_policy_losses: -34.374, mean_net_lifetime: 6448.5306, mean_mc_travel_dist: 2004.3745, mean_rewards: 249.2736, total_rewards: 4473.5673, mean_steps: 24.9800, mean_ecr: 0.0384 mean_entropies: 0.8923, took: 113.6736s
2022-10-11 11:40:24,375 [INFO] 	Process 4 - batch 99199: mean_policy_losses: 102.889, mean_net_lifetime: 10862.0838, mean_mc_travel_dist: 3510.5747, mean_rewards: 266.0043, total_rewards: 7380.5146, mean_steps: 46.0200, mean_ecr: 0.0391 mean_entropies: 0.4820, took: 205.5020s
2022-10-11 11:40:32,397 [INFO] 	Process 7 - batch 98299: mean_policy_losses: -294.532, mean_net_lifetime: 4836.0207, mean_mc_travel_dist: 1483.5106, mean_rewards: 208.5579, total_rewards: 3394.2021, mean_steps: 22.4700, mean_ecr: 0.0412 mean_entropies: 1.2683, took: 104.6043s
2022-10-11 11:41:25,363 [INFO] Process 3 - epoch 72: mean_policy_losses: 37.896, mean_net_lifetime: 4573.4290, mean_mc_travel_dist: 1343.2346, mean_entropies: 0.7642, m_net_lifetime_valid: 4427.7150, took: 1982.2143s, (138.9983 / 100 batches)

2022-10-11 11:42:00,004 [INFO] 	Process 5 - batch 88999: mean_policy_losses: -28.629, mean_net_lifetime: 10151.1267, mean_mc_travel_dist: 3073.8581, mean_rewards: 266.9227, total_rewards: 7111.9158, mean_steps: 37.7400, mean_ecr: 0.0294 mean_entropies: 0.6296, took: 170.0388s
2022-10-11 11:42:18,643 [INFO] 	Process 1 - batch 89599: mean_policy_losses: -48.405, mean_net_lifetime: 6844.4896, mean_mc_travel_dist: 2099.2020, mean_rewards: 242.0847, total_rewards: 4768.2320, mean_steps: 27.4100, mean_ecr: 0.0381 mean_entropies: 0.9399, took: 123.7812s
2022-10-11 11:42:36,023 [INFO] 	Process 7 - batch 98399: mean_policy_losses: -265.280, mean_net_lifetime: 5318.3724, mean_mc_travel_dist: 1617.5817, mean_rewards: 199.0629, total_rewards: 3727.9212, mean_steps: 26.6300, mean_ecr: 0.0407 mean_entropies: 1.2695, took: 123.6250s
2022-10-11 11:42:56,592 [INFO] 	Process 3 - batch 108099: mean_policy_losses: -48.841, mean_net_lifetime: 5359.3952, mean_mc_travel_dist: 1407.1371, mean_rewards: 278.6366, total_rewards: 3982.6082, mean_steps: 18.2800, mean_ecr: 0.0447 mean_entropies: 0.5159, took: 723.9571s
2022-10-11 11:43:42,400 [INFO] 	Process 4 - batch 99299: mean_policy_losses: 105.661, mean_net_lifetime: 10644.8434, mean_mc_travel_dist: 3265.5205, mean_rewards: 262.6295, total_rewards: 7401.1792, mean_steps: 43.6500, mean_ecr: 0.0374 mean_entropies: 0.5068, took: 198.0249s
2022-10-11 11:44:22,381 [INFO] 	Process 7 - batch 98499: mean_policy_losses: -445.474, mean_net_lifetime: 4807.7719, mean_mc_travel_dist: 1469.2927, mean_rewards: 208.5395, total_rewards: 3380.6057, mean_steps: 22.4900, mean_ecr: 0.0411 mean_entropies: 1.2738, took: 106.3592s
2022-10-11 11:44:22,527 [INFO] 	Process 1 - batch 89699: mean_policy_losses: -14.170, mean_net_lifetime: 6721.8315, mean_mc_travel_dist: 2059.3914, mean_rewards: 249.0507, total_rewards: 4690.1111, mean_steps: 26.0900, mean_ecr: 0.0382 mean_entropies: 0.9440, took: 123.8835s
2022-10-11 11:44:24,656 [INFO] Process 2 - epoch 64: mean_policy_losses: -1.151, mean_net_lifetime: 5510.4283, mean_mc_travel_dist: 1718.1139, mean_entropies: 0.7917, m_net_lifetime_valid: 4695.3271, took: 2600.9593s, (156.4345 / 100 batches)

2022-10-11 11:44:26,710 [INFO] 	Process 3 - batch 108199: mean_policy_losses: -36.843, mean_net_lifetime: 5360.0579, mean_mc_travel_dist: 1363.7854, mean_rewards: 281.4903, total_rewards: 4029.3679, mean_steps: 18.1100, mean_ecr: 0.0451 mean_entropies: 0.4516, took: 90.1179s
2022-10-11 11:45:04,400 [INFO] 	Process 5 - batch 89099: mean_policy_losses: -63.234, mean_net_lifetime: 10305.6437, mean_mc_travel_dist: 3116.9534, mean_rewards: 263.8493, total_rewards: 7226.8181, mean_steps: 38.8100, mean_ecr: 0.0295 mean_entropies: 0.6474, took: 184.3957s
2022-10-11 11:45:34,416 [INFO] Process 6 - epoch 96: mean_policy_losses: -174.902, mean_net_lifetime: 3336.6816, mean_mc_travel_dist: 998.3180, mean_entropies: 0.4577, m_net_lifetime_valid: 4294.2664, took: 1440.9748s, (104.4493 / 100 batches)

2022-10-11 11:45:57,254 [INFO] 	Process 3 - batch 108299: mean_policy_losses: -33.550, mean_net_lifetime: 5284.1547, mean_mc_travel_dist: 1354.1852, mean_rewards: 281.7141, total_rewards: 3954.6091, mean_steps: 17.8100, mean_ecr: 0.0449 mean_entropies: 0.4761, took: 90.5436s
2022-10-11 11:46:15,338 [INFO] 	Process 7 - batch 98599: mean_policy_losses: -419.125, mean_net_lifetime: 4808.3039, mean_mc_travel_dist: 1455.5268, mean_rewards: 206.9226, total_rewards: 3382.1288, mean_steps: 22.6600, mean_ecr: 0.0411 mean_entropies: 1.3018, took: 112.9562s
2022-10-11 11:46:28,280 [INFO] 	Process 1 - batch 89799: mean_policy_losses: -59.859, mean_net_lifetime: 6562.6565, mean_mc_travel_dist: 2016.4900, mean_rewards: 247.7045, total_rewards: 4573.1820, mean_steps: 25.7200, mean_ecr: 0.0382 mean_entropies: 0.9244, took: 125.7533s
2022-10-11 11:46:31,593 [INFO] 	Process 2 - batch 96099: mean_policy_losses: -54.472, mean_net_lifetime: 7174.0623, mean_mc_travel_dist: 1922.4848, mean_rewards: 278.3447, total_rewards: 5277.8584, mean_steps: 24.8400, mean_ecr: 0.0384 mean_entropies: 0.4134, took: 863.3321s
2022-10-11 11:46:31,751 [INFO] 	Process 6 - batch 144099: mean_policy_losses: -99.578, mean_net_lifetime: 3794.9594, mean_mc_travel_dist: 1010.5917, mean_rewards: 344.2024, total_rewards: 2825.6742, mean_steps: 9.9900, mean_ecr: 0.0551 mean_entropies: 0.1508, took: 685.0384s
2022-10-11 11:47:03,053 [INFO] 	Process 4 - batch 99399: mean_policy_losses: 111.984, mean_net_lifetime: 10757.9529, mean_mc_travel_dist: 3314.7058, mean_rewards: 267.0809, total_rewards: 7461.6213, mean_steps: 42.4400, mean_ecr: 0.0381 mean_entropies: 0.5263, took: 200.6523s
2022-10-11 11:47:34,157 [INFO] 	Process 6 - batch 144199: mean_policy_losses: -40.001, mean_net_lifetime: 4205.3118, mean_mc_travel_dist: 1119.0394, mean_rewards: 345.9851, total_rewards: 3113.4028, mean_steps: 11.1300, mean_ecr: 0.0547 mean_entropies: 0.1217, took: 62.4059s
2022-10-11 11:47:34,543 [INFO] 	Process 3 - batch 108399: mean_policy_losses: -30.926, mean_net_lifetime: 5313.6698, mean_mc_travel_dist: 1340.8113, mean_rewards: 280.0907, total_rewards: 4001.2243, mean_steps: 18.0000, mean_ecr: 0.0453 mean_entropies: 0.4428, took: 97.2888s
2022-10-11 11:48:01,222 [INFO] 	Process 5 - batch 89199: mean_policy_losses: -135.057, mean_net_lifetime: 9568.2857, mean_mc_travel_dist: 2879.3855, mean_rewards: 266.1044, total_rewards: 6726.7944, mean_steps: 35.8400, mean_ecr: 0.0300 mean_entropies: 0.6637, took: 176.8226s
2022-10-11 11:48:15,295 [INFO] 	Process 7 - batch 98699: mean_policy_losses: -377.551, mean_net_lifetime: 4934.8235, mean_mc_travel_dist: 1464.2099, mean_rewards: 205.7200, total_rewards: 3496.5155, mean_steps: 23.2700, mean_ecr: 0.0409 mean_entropies: 1.2443, took: 119.9560s
2022-10-11 11:48:33,926 [INFO] 	Process 6 - batch 144299: mean_policy_losses: -76.954, mean_net_lifetime: 4010.7681, mean_mc_travel_dist: 1060.2443, mean_rewards: 344.4986, total_rewards: 2976.6765, mean_steps: 10.6000, mean_ecr: 0.0550 mean_entropies: 0.1499, took: 59.7696s
2022-10-11 11:48:35,840 [INFO] 	Process 1 - batch 89899: mean_policy_losses: -15.220, mean_net_lifetime: 6633.0491, mean_mc_travel_dist: 2032.7999, mean_rewards: 253.7317, total_rewards: 4620.9444, mean_steps: 25.3200, mean_ecr: 0.0383 mean_entropies: 0.9116, took: 127.5595s
2022-10-11 11:48:42,179 [INFO] 	Process 2 - batch 96199: mean_policy_losses: -31.362, mean_net_lifetime: 7302.2005, mean_mc_travel_dist: 1912.5267, mean_rewards: 281.6268, total_rewards: 5412.6841, mean_steps: 24.9900, mean_ecr: 0.0386 mean_entropies: 0.3844, took: 130.5862s
2022-10-11 11:49:12,629 [INFO] 	Process 3 - batch 108499: mean_policy_losses: -41.117, mean_net_lifetime: 5384.2002, mean_mc_travel_dist: 1366.4685, mean_rewards: 280.1645, total_rewards: 4041.2586, mean_steps: 18.2700, mean_ecr: 0.0453 mean_entropies: 0.4612, took: 98.0857s
2022-10-11 11:49:31,886 [INFO] 	Process 6 - batch 144399: mean_policy_losses: -103.335, mean_net_lifetime: 3871.0137, mean_mc_travel_dist: 1031.6712, mean_rewards: 343.1419, total_rewards: 2879.3789, mean_steps: 10.2300, mean_ecr: 0.0553 mean_entropies: 0.1366, took: 57.9593s
2022-10-11 11:50:21,018 [INFO] 	Process 7 - batch 98799: mean_policy_losses: -307.269, mean_net_lifetime: 5174.5985, mean_mc_travel_dist: 1564.2814, mean_rewards: 204.0083, total_rewards: 3646.1055, mean_steps: 24.5800, mean_ecr: 0.0406 mean_entropies: 1.2615, took: 125.7240s
2022-10-11 11:50:30,085 [INFO] 	Process 6 - batch 144499: mean_policy_losses: -109.683, mean_net_lifetime: 3822.8977, mean_mc_travel_dist: 1016.3890, mean_rewards: 343.0687, total_rewards: 2851.1150, mean_steps: 10.0900, mean_ecr: 0.0551 mean_entropies: 0.1414, took: 58.1991s
2022-10-11 11:50:47,680 [INFO] 	Process 1 - batch 89999: mean_policy_losses: -37.630, mean_net_lifetime: 6716.5079, mean_mc_travel_dist: 2070.7536, mean_rewards: 248.5629, total_rewards: 4672.5961, mean_steps: 26.1900, mean_ecr: 0.0383 mean_entropies: 0.9124, took: 131.8401s
2022-10-11 11:50:51,732 [INFO] 	Process 3 - batch 108599: mean_policy_losses: -34.247, mean_net_lifetime: 5475.3829, mean_mc_travel_dist: 1397.9584, mean_rewards: 276.2698, total_rewards: 4100.0889, mean_steps: 18.8800, mean_ecr: 0.0451 mean_entropies: 0.4604, took: 99.1039s
2022-10-11 11:50:52,731 [INFO] 	Process 5 - batch 89299: mean_policy_losses: -152.001, mean_net_lifetime: 9055.1322, mean_mc_travel_dist: 2720.2813, mean_rewards: 261.8222, total_rewards: 6380.8893, mean_steps: 34.3200, mean_ecr: 0.0298 mean_entropies: 0.6310, took: 171.5089s
2022-10-11 11:50:57,528 [INFO] 	Process 2 - batch 96299: mean_policy_losses: -23.892, mean_net_lifetime: 7520.5922, mean_mc_travel_dist: 1952.6083, mean_rewards: 283.4964, total_rewards: 5596.7656, mean_steps: 25.6100, mean_ecr: 0.0384 mean_entropies: 0.3523, took: 135.3496s
2022-10-11 11:51:05,761 [INFO] 	Process 4 - batch 99499: mean_policy_losses: 123.678, mean_net_lifetime: 11975.7287, mean_mc_travel_dist: 3768.3966, mean_rewards: 260.8592, total_rewards: 8233.9874, mean_steps: 49.7000, mean_ecr: 0.0375 mean_entropies: 0.4974, took: 242.7094s
2022-10-11 11:51:27,853 [INFO] 	Process 6 - batch 144599: mean_policy_losses: -125.070, mean_net_lifetime: 3885.4547, mean_mc_travel_dist: 1038.8685, mean_rewards: 343.5891, total_rewards: 2903.9013, mean_steps: 10.2800, mean_ecr: 0.0549 mean_entropies: 0.1408, took: 57.7690s
2022-10-11 11:52:21,330 [INFO] 	Process 7 - batch 98899: mean_policy_losses: -376.274, mean_net_lifetime: 4965.9777, mean_mc_travel_dist: 1482.1235, mean_rewards: 202.8323, total_rewards: 3509.8068, mean_steps: 23.9800, mean_ecr: 0.0407 mean_entropies: 1.2763, took: 120.3127s
2022-10-11 11:52:25,627 [INFO] 	Process 6 - batch 144699: mean_policy_losses: -69.671, mean_net_lifetime: 3980.5151, mean_mc_travel_dist: 1056.1932, mean_rewards: 344.6077, total_rewards: 2974.3261, mean_steps: 10.5400, mean_ecr: 0.0550 mean_entropies: 0.1334, took: 57.7733s
2022-10-11 11:52:27,370 [INFO] 	Process 3 - batch 108699: mean_policy_losses: -42.675, mean_net_lifetime: 5450.1738, mean_mc_travel_dist: 1388.8307, mean_rewards: 278.8957, total_rewards: 4089.6675, mean_steps: 18.6600, mean_ecr: 0.0451 mean_entropies: 0.4543, took: 95.6374s
2022-10-11 11:52:58,705 [INFO] 	Process 2 - batch 96399: mean_policy_losses: -61.942, mean_net_lifetime: 7131.1218, mean_mc_travel_dist: 1860.7212, mean_rewards: 287.2285, total_rewards: 5293.8475, mean_steps: 23.9600, mean_ecr: 0.0388 mean_entropies: 0.3653, took: 121.1774s
2022-10-11 11:53:23,249 [INFO] 	Process 6 - batch 144799: mean_policy_losses: -84.994, mean_net_lifetime: 3980.1608, mean_mc_travel_dist: 1059.4556, mean_rewards: 344.5308, total_rewards: 2967.3834, mean_steps: 10.5200, mean_ecr: 0.0549 mean_entropies: 0.1345, took: 57.6220s
2022-10-11 11:53:55,619 [INFO] 	Process 5 - batch 89399: mean_policy_losses: -81.797, mean_net_lifetime: 9930.6423, mean_mc_travel_dist: 3039.9936, mean_rewards: 261.5078, total_rewards: 6941.9967, mean_steps: 38.2200, mean_ecr: 0.0296 mean_entropies: 0.6201, took: 182.8877s
2022-10-11 11:54:04,734 [INFO] 	Process 3 - batch 108799: mean_policy_losses: -21.845, mean_net_lifetime: 5587.6247, mean_mc_travel_dist: 1421.8655, mean_rewards: 279.8446, total_rewards: 4197.5755, mean_steps: 19.0500, mean_ecr: 0.0448 mean_entropies: 0.4341, took: 97.3647s
2022-10-11 11:54:12,026 [INFO] 	Process 4 - batch 99599: mean_policy_losses: 107.999, mean_net_lifetime: 9627.0560, mean_mc_travel_dist: 2946.7670, mean_rewards: 263.8721, total_rewards: 6697.7714, mean_steps: 38.4100, mean_ecr: 0.0380 mean_entropies: 0.4798, took: 186.2636s
2022-10-11 11:54:19,925 [INFO] 	Process 6 - batch 144899: mean_policy_losses: -85.677, mean_net_lifetime: 3844.7274, mean_mc_travel_dist: 1038.0710, mean_rewards: 343.7430, total_rewards: 2876.6548, mean_steps: 10.1700, mean_ecr: 0.0550 mean_entropies: 0.1504, took: 56.6760s
2022-10-11 11:54:22,971 [INFO] 	Process 7 - batch 98999: mean_policy_losses: -347.924, mean_net_lifetime: 5180.1707, mean_mc_travel_dist: 1569.1447, mean_rewards: 205.5410, total_rewards: 3642.0035, mean_steps: 24.7400, mean_ecr: 0.0407 mean_entropies: 1.2475, took: 121.6410s
2022-10-11 11:55:04,667 [INFO] 	Process 2 - batch 96499: mean_policy_losses: -31.334, mean_net_lifetime: 7445.0497, mean_mc_travel_dist: 1945.5644, mean_rewards: 285.2942, total_rewards: 5525.2493, mean_steps: 25.2200, mean_ecr: 0.0384 mean_entropies: 0.3499, took: 125.9618s
2022-10-11 11:55:16,925 [INFO] 	Process 6 - batch 144999: mean_policy_losses: -93.377, mean_net_lifetime: 3960.1733, mean_mc_travel_dist: 1066.9287, mean_rewards: 344.2652, total_rewards: 2961.8328, mean_steps: 10.4800, mean_ecr: 0.0550 mean_entropies: 0.1441, took: 56.9992s
2022-10-11 11:55:37,543 [INFO] 	Process 3 - batch 108899: mean_policy_losses: -63.993, mean_net_lifetime: 5367.7278, mean_mc_travel_dist: 1378.3327, mean_rewards: 275.6517, total_rewards: 4023.8173, mean_steps: 18.5600, mean_ecr: 0.0450 mean_entropies: 0.4352, took: 92.8084s
2022-10-11 11:56:13,214 [INFO] 	Process 6 - batch 145099: mean_policy_losses: -63.341, mean_net_lifetime: 3834.1351, mean_mc_travel_dist: 1030.6787, mean_rewards: 339.4913, total_rewards: 2855.9828, mean_steps: 10.2600, mean_ecr: 0.0551 mean_entropies: 0.1566, took: 56.2894s
2022-10-11 11:56:38,314 [INFO] 	Process 5 - batch 89499: mean_policy_losses: -113.005, mean_net_lifetime: 9112.1718, mean_mc_travel_dist: 2736.1428, mean_rewards: 260.0896, total_rewards: 6429.1632, mean_steps: 34.7400, mean_ecr: 0.0299 mean_entropies: 0.6257, took: 162.6950s
2022-10-11 11:57:10,002 [INFO] 	Process 2 - batch 96599: mean_policy_losses: -17.697, mean_net_lifetime: 7589.2562, mean_mc_travel_dist: 1977.6057, mean_rewards: 283.6975, total_rewards: 5634.5051, mean_steps: 25.8100, mean_ecr: 0.0382 mean_entropies: 0.3472, took: 125.3345s
2022-10-11 11:57:10,496 [INFO] 	Process 3 - batch 108999: mean_policy_losses: -41.501, mean_net_lifetime: 5426.3955, mean_mc_travel_dist: 1348.6628, mean_rewards: 276.0236, total_rewards: 4102.2009, mean_steps: 18.7800, mean_ecr: 0.0452 mean_entropies: 0.4472, took: 92.9527s
2022-10-11 11:57:11,172 [INFO] 	Process 6 - batch 145199: mean_policy_losses: -62.731, mean_net_lifetime: 4125.7376, mean_mc_travel_dist: 1108.6162, mean_rewards: 344.2174, total_rewards: 3072.0743, mean_steps: 10.9500, mean_ecr: 0.0551 mean_entropies: 0.1179, took: 57.9584s
2022-10-11 11:57:52,032 [INFO] 	Process 4 - batch 99699: mean_policy_losses: 111.159, mean_net_lifetime: 11997.5362, mean_mc_travel_dist: 3715.8258, mean_rewards: 265.8378, total_rewards: 8308.3866, mean_steps: 48.7200, mean_ecr: 0.0373 mean_entropies: 0.4935, took: 220.0065s
2022-10-11 11:58:09,597 [INFO] 	Process 6 - batch 145299: mean_policy_losses: -63.895, mean_net_lifetime: 4217.7925, mean_mc_travel_dist: 1119.6488, mean_rewards: 345.0248, total_rewards: 3136.9625, mean_steps: 11.1900, mean_ecr: 0.0548 mean_entropies: 0.1038, took: 58.4256s
2022-10-11 11:58:44,048 [INFO] 	Process 3 - batch 109099: mean_policy_losses: -48.292, mean_net_lifetime: 5501.6308, mean_mc_travel_dist: 1398.7603, mean_rewards: 277.4293, total_rewards: 4128.7616, mean_steps: 18.8900, mean_ecr: 0.0446 mean_entropies: 0.4504, took: 93.5518s
2022-10-11 11:59:08,447 [INFO] 	Process 6 - batch 145399: mean_policy_losses: -54.501, mean_net_lifetime: 4145.2599, mean_mc_travel_dist: 1105.9320, mean_rewards: 345.0296, total_rewards: 3081.8875, mean_steps: 10.9900, mean_ecr: 0.0548 mean_entropies: 0.1103, took: 58.8495s
2022-10-11 11:59:14,942 [INFO] 	Process 2 - batch 96699: mean_policy_losses: -19.001, mean_net_lifetime: 7619.3750, mean_mc_travel_dist: 1984.2239, mean_rewards: 286.0071, total_rewards: 5652.5695, mean_steps: 25.7000, mean_ecr: 0.0383 mean_entropies: 0.3435, took: 124.9403s
2022-10-11 11:59:16,462 [INFO] 	Process 5 - batch 89599: mean_policy_losses: -136.570, mean_net_lifetime: 9056.9011, mean_mc_travel_dist: 2712.8575, mean_rewards: 263.4791, total_rewards: 6372.1642, mean_steps: 34.1000, mean_ecr: 0.0300 mean_entropies: 0.6188, took: 158.1479s
2022-10-11 12:00:04,415 [INFO] 	Process 6 - batch 145499: mean_policy_losses: -127.419, mean_net_lifetime: 3902.7613, mean_mc_travel_dist: 1032.0885, mean_rewards: 344.7412, total_rewards: 2909.3786, mean_steps: 10.2800, mean_ecr: 0.0549 mean_entropies: 0.1314, took: 55.9679s
2022-10-11 12:00:16,352 [INFO] 	Process 3 - batch 109199: mean_policy_losses: -24.875, mean_net_lifetime: 5476.5684, mean_mc_travel_dist: 1364.3468, mean_rewards: 284.6952, total_rewards: 4136.0111, mean_steps: 18.3400, mean_ecr: 0.0454 mean_entropies: 0.4256, took: 92.3047s
2022-10-11 12:01:13,064 [INFO] 	Process 2 - batch 96799: mean_policy_losses: -18.539, mean_net_lifetime: 7566.4710, mean_mc_travel_dist: 1959.5471, mean_rewards: 287.1145, total_rewards: 5630.7529, mean_steps: 25.4400, mean_ecr: 0.0384 mean_entropies: 0.3359, took: 118.1215s
2022-10-11 12:01:44,752 [INFO] 	Process 4 - batch 99799: mean_policy_losses: 114.143, mean_net_lifetime: 12803.8790, mean_mc_travel_dist: 4023.5757, mean_rewards: 261.2455, total_rewards: 8798.7435, mean_steps: 53.3600, mean_ecr: 0.0371 mean_entropies: 0.4924, took: 232.7192s
2022-10-11 12:01:47,377 [INFO] 	Process 3 - batch 109299: mean_policy_losses: -61.805, mean_net_lifetime: 5322.4484, mean_mc_travel_dist: 1357.6021, mean_rewards: 270.6813, total_rewards: 3983.8836, mean_steps: 18.7600, mean_ecr: 0.0450 mean_entropies: 0.4562, took: 91.0246s
2022-10-11 12:01:57,203 [INFO] Process 1 - epoch 60: mean_policy_losses: 10.572, mean_net_lifetime: 5541.8168, mean_mc_travel_dist: 2042.0762, mean_entropies: 1.1165, m_net_lifetime_valid: 4532.4966, took: 2476.2064s, (168.0942 / 100 batches)

2022-10-11 12:02:03,089 [INFO] 	Process 5 - batch 89699: mean_policy_losses: -123.262, mean_net_lifetime: 9444.7595, mean_mc_travel_dist: 2841.2101, mean_rewards: 255.4656, total_rewards: 6632.9592, mean_steps: 37.1300, mean_ecr: 0.0299 mean_entropies: 0.6007, took: 166.6264s
2022-10-11 12:03:11,957 [INFO] 	Process 2 - batch 96899: mean_policy_losses: -27.630, mean_net_lifetime: 7501.5334, mean_mc_travel_dist: 1952.1852, mean_rewards: 286.4644, total_rewards: 5566.1201, mean_steps: 25.2700, mean_ecr: 0.0385 mean_entropies: 0.3491, took: 118.8933s
2022-10-11 12:03:23,261 [INFO] 	Process 3 - batch 109399: mean_policy_losses: -44.084, mean_net_lifetime: 5480.0581, mean_mc_travel_dist: 1398.1068, mean_rewards: 280.8425, total_rewards: 4108.3242, mean_steps: 18.5600, mean_ecr: 0.0448 mean_entropies: 0.4483, took: 95.8839s
2022-10-11 12:04:04,871 [INFO] 	Process 1 - batch 90099: mean_policy_losses: -99.784, mean_net_lifetime: 6577.9581, mean_mc_travel_dist: 2020.7561, mean_rewards: 241.9871, total_rewards: 4574.8868, mean_steps: 26.2700, mean_ecr: 0.0383 mean_entropies: 0.9114, took: 797.1922s
2022-10-11 12:04:56,605 [INFO] 	Process 3 - batch 109499: mean_policy_losses: -40.713, mean_net_lifetime: 5508.9034, mean_mc_travel_dist: 1396.2766, mean_rewards: 283.2227, total_rewards: 4138.7047, mean_steps: 18.4900, mean_ecr: 0.0448 mean_entropies: 0.4565, took: 93.3446s
2022-10-11 12:05:16,114 [INFO] 	Process 2 - batch 96999: mean_policy_losses: -16.019, mean_net_lifetime: 7681.1672, mean_mc_travel_dist: 2019.2330, mean_rewards: 285.1256, total_rewards: 5685.7431, mean_steps: 25.9800, mean_ecr: 0.0382 mean_entropies: 0.3736, took: 124.1571s
2022-10-11 12:05:18,277 [INFO] 	Process 5 - batch 89799: mean_policy_losses: -72.610, mean_net_lifetime: 11241.7748, mean_mc_travel_dist: 3393.6744, mean_rewards: 263.3913, total_rewards: 7892.5142, mean_steps: 43.0600, mean_ecr: 0.0294 mean_entropies: 0.6283, took: 195.1891s
2022-10-11 12:05:59,007 [INFO] 	Process 4 - batch 99899: mean_policy_losses: 129.158, mean_net_lifetime: 14000.8551, mean_mc_travel_dist: 4408.9659, mean_rewards: 264.5253, total_rewards: 9613.3262, mean_steps: 57.7600, mean_ecr: 0.0367 mean_entropies: 0.5428, took: 254.2564s
2022-10-11 12:06:02,482 [INFO] 	Process 1 - batch 90199: mean_policy_losses: -91.879, mean_net_lifetime: 6667.4905, mean_mc_travel_dist: 2045.1670, mean_rewards: 252.3965, total_rewards: 4640.9956, mean_steps: 25.5000, mean_ecr: 0.0383 mean_entropies: 0.9558, took: 117.6100s
2022-10-11 12:06:36,667 [INFO] Process 7 - epoch 66: mean_policy_losses: -363.736, mean_net_lifetime: 4387.6122, mean_mc_travel_dist: 1550.6564, mean_entropies: 1.4952, m_net_lifetime_valid: 4511.3135, took: 2419.7955s, (153.0455 / 100 batches)

2022-10-11 12:07:19,387 [INFO] 	Process 2 - batch 97099: mean_policy_losses: -20.258, mean_net_lifetime: 7694.5251, mean_mc_travel_dist: 2020.2516, mean_rewards: 289.9948, total_rewards: 5694.2439, mean_steps: 25.6000, mean_ecr: 0.0382 mean_entropies: 0.3633, took: 123.2721s
2022-10-11 12:07:56,752 [INFO] 	Process 5 - batch 89899: mean_policy_losses: -93.550, mean_net_lifetime: 9419.2300, mean_mc_travel_dist: 2827.7582, mean_rewards: 268.5213, total_rewards: 6633.3150, mean_steps: 34.5800, mean_ecr: 0.0300 mean_entropies: 0.6502, took: 158.4748s
2022-10-11 12:08:07,480 [INFO] 	Process 1 - batch 90299: mean_policy_losses: -29.930, mean_net_lifetime: 6717.1255, mean_mc_travel_dist: 2050.1618, mean_rewards: 245.3366, total_rewards: 4693.1910, mean_steps: 26.5300, mean_ecr: 0.0381 mean_entropies: 0.9593, took: 124.9978s
2022-10-11 12:08:32,486 [INFO] 	Process 4 - batch 99999: mean_policy_losses: 50.538, mean_net_lifetime: 8587.5171, mean_mc_travel_dist: 2508.6099, mean_rewards: 282.2553, total_rewards: 6109.7457, mean_steps: 32.2200, mean_ecr: 0.0411 mean_entropies: 0.5316, took: 153.4788s
2022-10-11 12:08:32,936 [INFO] 	Process 7 - batch 99099: mean_policy_losses: -326.325, mean_net_lifetime: 5207.6669, mean_mc_travel_dist: 1584.8849, mean_rewards: 209.2505, total_rewards: 3656.7784, mean_steps: 24.1800, mean_ecr: 0.0408 mean_entropies: 1.2873, took: 849.9649s
2022-10-11 12:09:25,694 [INFO] 	Process 2 - batch 97199: mean_policy_losses: -27.543, mean_net_lifetime: 7631.8465, mean_mc_travel_dist: 1993.8987, mean_rewards: 287.8774, total_rewards: 5663.0409, mean_steps: 25.6200, mean_ecr: 0.0383 mean_entropies: 0.3801, took: 126.3075s
2022-10-11 12:10:10,762 [INFO] 	Process 1 - batch 90399: mean_policy_losses: -20.266, mean_net_lifetime: 6647.0840, mean_mc_travel_dist: 2031.1500, mean_rewards: 253.6227, total_rewards: 4640.7000, mean_steps: 25.3300, mean_ecr: 0.0384 mean_entropies: 0.9961, took: 123.2828s
2022-10-11 12:10:14,679 [INFO] 	Process 7 - batch 99199: mean_policy_losses: -469.006, mean_net_lifetime: 4569.2569, mean_mc_travel_dist: 1412.4689, mean_rewards: 210.9566, total_rewards: 3195.1115, mean_steps: 20.7900, mean_ecr: 0.0415 mean_entropies: 1.3024, took: 101.7430s
2022-10-11 12:10:25,617 [INFO] 	Process 5 - batch 89999: mean_policy_losses: -137.349, mean_net_lifetime: 8705.1293, mean_mc_travel_dist: 2608.0214, mean_rewards: 269.2111, total_rewards: 6144.5670, mean_steps: 31.7400, mean_ecr: 0.0302 mean_entropies: 0.6762, took: 148.8644s
2022-10-11 12:10:31,244 [INFO] 	Process 4 - batch 100099: mean_policy_losses: 76.816, mean_net_lifetime: 7028.8229, mean_mc_travel_dist: 1909.3541, mean_rewards: 290.1537, total_rewards: 5144.1447, mean_steps: 24.0600, mean_ecr: 0.0427 mean_entropies: 0.5393, took: 118.7578s
2022-10-11 12:11:17,128 [INFO] Process 6 - epoch 97: mean_policy_losses: -173.965, mean_net_lifetime: 3343.2325, mean_mc_travel_dist: 998.9501, mean_entropies: 0.4544, m_net_lifetime_valid: 4370.3643, took: 1542.7090s, (104.4019 / 100 batches)

2022-10-11 12:11:32,312 [INFO] 	Process 2 - batch 97299: mean_policy_losses: -5.417, mean_net_lifetime: 7728.3825, mean_mc_travel_dist: 2003.5826, mean_rewards: 288.2549, total_rewards: 5748.9679, mean_steps: 25.8500, mean_ecr: 0.0383 mean_entropies: 0.3557, took: 126.6176s
2022-10-11 12:11:59,690 [INFO] 	Process 7 - batch 99299: mean_policy_losses: -421.587, mean_net_lifetime: 4738.8239, mean_mc_travel_dist: 1416.2556, mean_rewards: 207.1429, total_rewards: 3368.6295, mean_steps: 22.1800, mean_ecr: 0.0410 mean_entropies: 1.2093, took: 105.0113s
2022-10-11 12:12:06,732 [INFO] 	Process 1 - batch 90499: mean_policy_losses: -24.924, mean_net_lifetime: 6579.5504, mean_mc_travel_dist: 2023.0823, mean_rewards: 253.4443, total_rewards: 4581.2178, mean_steps: 25.0200, mean_ecr: 0.0383 mean_entropies: 0.8820, took: 115.9695s
2022-10-11 12:12:11,131 [INFO] 	Process 6 - batch 145599: mean_policy_losses: -135.277, mean_net_lifetime: 3797.7566, mean_mc_travel_dist: 1020.3416, mean_rewards: 341.7727, total_rewards: 2823.0511, mean_steps: 10.0700, mean_ecr: 0.0552 mean_entropies: 0.1610, took: 726.7158s
2022-10-11 12:13:11,314 [INFO] 	Process 6 - batch 145699: mean_policy_losses: -60.682, mean_net_lifetime: 4136.5867, mean_mc_travel_dist: 1102.7148, mean_rewards: 342.3569, total_rewards: 3075.1992, mean_steps: 11.0100, mean_ecr: 0.0549 mean_entropies: 0.1381, took: 60.1828s
2022-10-11 12:13:38,528 [INFO] 	Process 2 - batch 97399: mean_policy_losses: -42.852, mean_net_lifetime: 7399.6279, mean_mc_travel_dist: 1927.7963, mean_rewards: 283.4047, total_rewards: 5488.2708, mean_steps: 25.2300, mean_ecr: 0.0385 mean_entropies: 0.3506, took: 126.2166s
2022-10-11 12:13:51,783 [INFO] 	Process 7 - batch 99399: mean_policy_losses: -397.729, mean_net_lifetime: 4558.1026, mean_mc_travel_dist: 1360.9402, mean_rewards: 196.2884, total_rewards: 3228.0847, mean_steps: 22.9400, mean_ecr: 0.0411 mean_entropies: 1.2108, took: 112.0925s
2022-10-11 12:14:06,604 [INFO] 	Process 6 - batch 145799: mean_policy_losses: -102.097, mean_net_lifetime: 3938.6981, mean_mc_travel_dist: 1045.0770, mean_rewards: 343.2748, total_rewards: 2929.1646, mean_steps: 10.4300, mean_ecr: 0.0550 mean_entropies: 0.1493, took: 55.2902s
2022-10-11 12:14:11,861 [INFO] 	Process 1 - batch 90599: mean_policy_losses: -32.812, mean_net_lifetime: 6625.5416, mean_mc_travel_dist: 2057.3206, mean_rewards: 243.2397, total_rewards: 4589.6812, mean_steps: 26.4300, mean_ecr: 0.0381 mean_entropies: 0.9078, took: 125.1278s
2022-10-11 12:14:18,448 [INFO] 	Process 4 - batch 100199: mean_policy_losses: 140.798, mean_net_lifetime: 11916.5505, mean_mc_travel_dist: 3705.3005, mean_rewards: 264.3306, total_rewards: 8232.1471, mean_steps: 49.6300, mean_ecr: 0.0375 mean_entropies: 0.4810, took: 227.2037s
2022-10-11 12:15:04,312 [INFO] 	Process 6 - batch 145899: mean_policy_losses: -108.210, mean_net_lifetime: 4046.6568, mean_mc_travel_dist: 1073.9803, mean_rewards: 342.3525, total_rewards: 3002.0568, mean_steps: 10.7400, mean_ecr: 0.0551 mean_entropies: 0.1481, took: 57.7087s
2022-10-11 12:15:45,188 [INFO] 	Process 7 - batch 99499: mean_policy_losses: -273.509, mean_net_lifetime: 4923.8261, mean_mc_travel_dist: 1504.6848, mean_rewards: 202.1790, total_rewards: 3457.2871, mean_steps: 23.5900, mean_ecr: 0.0409 mean_entropies: 1.2016, took: 113.4052s
2022-10-11 12:15:45,640 [INFO] 	Process 2 - batch 97499: mean_policy_losses: -11.646, mean_net_lifetime: 7677.8240, mean_mc_travel_dist: 2019.3846, mean_rewards: 286.5867, total_rewards: 5685.5449, mean_steps: 25.8900, mean_ecr: 0.0383 mean_entropies: 0.3784, took: 127.1116s
2022-10-11 12:16:01,160 [INFO] 	Process 6 - batch 145999: mean_policy_losses: -164.932, mean_net_lifetime: 3912.0433, mean_mc_travel_dist: 1038.2049, mean_rewards: 342.0547, total_rewards: 2907.5589, mean_steps: 10.3700, mean_ecr: 0.0551 mean_entropies: 0.1562, took: 56.8478s
2022-10-11 12:16:07,526 [INFO] Process 3 - epoch 73: mean_policy_losses: 36.815, mean_net_lifetime: 4585.0244, mean_mc_travel_dist: 1343.7229, mean_entropies: 0.7599, m_net_lifetime_valid: 4537.1308, took: 2082.1609s, (138.9609 / 100 batches)

2022-10-11 12:16:15,101 [INFO] 	Process 1 - batch 90699: mean_policy_losses: -54.903, mean_net_lifetime: 6668.3251, mean_mc_travel_dist: 2052.4830, mean_rewards: 247.5129, total_rewards: 4636.0186, mean_steps: 26.0400, mean_ecr: 0.0382 mean_entropies: 0.9113, took: 123.2409s
2022-10-11 12:16:57,162 [INFO] 	Process 6 - batch 146099: mean_policy_losses: -94.617, mean_net_lifetime: 3980.1318, mean_mc_travel_dist: 1055.4875, mean_rewards: 340.4799, total_rewards: 2948.2279, mean_steps: 10.6000, mean_ecr: 0.0552 mean_entropies: 0.1376, took: 56.0020s
2022-10-11 12:17:41,241 [INFO] 	Process 3 - batch 109599: mean_policy_losses: -39.462, mean_net_lifetime: 5423.4220, mean_mc_travel_dist: 1387.1331, mean_rewards: 277.9196, total_rewards: 4066.2205, mean_steps: 18.5800, mean_ecr: 0.0449 mean_entropies: 0.4654, took: 764.6363s
2022-10-11 12:17:44,490 [INFO] 	Process 7 - batch 99599: mean_policy_losses: -251.272, mean_net_lifetime: 5152.7507, mean_mc_travel_dist: 1560.1313, mean_rewards: 199.8035, total_rewards: 3627.7623, mean_steps: 25.0600, mean_ecr: 0.0406 mean_entropies: 1.2274, took: 119.3021s
2022-10-11 12:17:53,798 [INFO] 	Process 6 - batch 146199: mean_policy_losses: -80.229, mean_net_lifetime: 3987.9009, mean_mc_travel_dist: 1055.4612, mean_rewards: 340.5187, total_rewards: 2957.1408, mean_steps: 10.6300, mean_ecr: 0.0552 mean_entropies: 0.1419, took: 56.6361s
2022-10-11 12:18:06,623 [INFO] 	Process 4 - batch 100299: mean_policy_losses: 159.472, mean_net_lifetime: 12232.3361, mean_mc_travel_dist: 3733.6873, mean_rewards: 265.6300, total_rewards: 8532.7185, mean_steps: 50.1500, mean_ecr: 0.0378 mean_entropies: 0.5206, took: 228.1751s
2022-10-11 12:18:18,321 [INFO] 	Process 1 - batch 90799: mean_policy_losses: -44.575, mean_net_lifetime: 6682.0829, mean_mc_travel_dist: 2082.5560, mean_rewards: 248.3592, total_rewards: 4616.0048, mean_steps: 26.0200, mean_ecr: 0.0381 mean_entropies: 0.9401, took: 123.2214s
2022-10-11 12:18:48,527 [INFO] 	Process 6 - batch 146299: mean_policy_losses: -145.424, mean_net_lifetime: 3878.9304, mean_mc_travel_dist: 1037.5132, mean_rewards: 339.8536, total_rewards: 2868.1623, mean_steps: 10.3200, mean_ecr: 0.0554 mean_entropies: 0.1280, took: 54.7291s
2022-10-11 12:19:12,347 [INFO] 	Process 3 - batch 109699: mean_policy_losses: -52.840, mean_net_lifetime: 5346.6767, mean_mc_travel_dist: 1357.7466, mean_rewards: 277.1538, total_rewards: 4017.9019, mean_steps: 18.3800, mean_ecr: 0.0451 mean_entropies: 0.4612, took: 91.1060s
2022-10-11 12:19:44,742 [INFO] 	Process 6 - batch 146399: mean_policy_losses: -81.173, mean_net_lifetime: 4085.7956, mean_mc_travel_dist: 1073.2284, mean_rewards: 344.0069, total_rewards: 3036.5000, mean_steps: 10.8300, mean_ecr: 0.0548 mean_entropies: 0.1217, took: 56.2143s
2022-10-11 12:19:46,583 [INFO] 	Process 7 - batch 99699: mean_policy_losses: -200.565, mean_net_lifetime: 5443.5697, mean_mc_travel_dist: 1647.4723, mean_rewards: 205.1009, total_rewards: 3824.4649, mean_steps: 25.9200, mean_ecr: 0.0406 mean_entropies: 1.2370, took: 122.0929s
2022-10-11 12:20:21,163 [INFO] 	Process 1 - batch 90899: mean_policy_losses: -46.774, mean_net_lifetime: 6566.1825, mean_mc_travel_dist: 2020.5971, mean_rewards: 247.2186, total_rewards: 4578.0744, mean_steps: 25.7700, mean_ecr: 0.0384 mean_entropies: 0.9601, took: 122.8398s
2022-10-11 12:20:42,984 [INFO] 	Process 6 - batch 146499: mean_policy_losses: -65.504, mean_net_lifetime: 4118.4847, mean_mc_travel_dist: 1090.7458, mean_rewards: 343.8689, total_rewards: 3054.2691, mean_steps: 10.9100, mean_ecr: 0.0550 mean_entropies: 0.1285, took: 58.2411s
2022-10-11 12:20:48,351 [INFO] 	Process 3 - batch 109799: mean_policy_losses: -66.463, mean_net_lifetime: 5375.5658, mean_mc_travel_dist: 1365.4872, mean_rewards: 266.9511, total_rewards: 4030.5460, mean_steps: 19.2500, mean_ecr: 0.0447 mean_entropies: 0.4752, took: 96.0039s
2022-10-11 12:21:39,255 [INFO] 	Process 6 - batch 146599: mean_policy_losses: -78.381, mean_net_lifetime: 3959.2270, mean_mc_travel_dist: 1063.8049, mean_rewards: 338.9407, total_rewards: 2924.0808, mean_steps: 10.6100, mean_ecr: 0.0553 mean_entropies: 0.1343, took: 56.2721s
2022-10-11 12:21:42,149 [INFO] 	Process 7 - batch 99799: mean_policy_losses: -280.842, mean_net_lifetime: 5162.0525, mean_mc_travel_dist: 1554.9407, mean_rewards: 204.7034, total_rewards: 3641.4595, mean_steps: 24.5900, mean_ecr: 0.0407 mean_entropies: 1.2432, took: 115.5656s
2022-10-11 12:21:44,298 [INFO] 	Process 4 - batch 100399: mean_policy_losses: 150.241, mean_net_lifetime: 11973.5681, mean_mc_travel_dist: 3597.5679, mean_rewards: 262.9136, total_rewards: 8397.0092, mean_steps: 48.0900, mean_ecr: 0.0364 mean_entropies: 0.5208, took: 217.6762s
2022-10-11 12:22:05,730 [INFO] Process 5 - epoch 60: mean_policy_losses: -186.228, mean_net_lifetime: 6134.0650, mean_mc_travel_dist: 2226.1370, mean_entropies: 1.0603, m_net_lifetime_valid: 4600.2913, took: 3214.1588s, (169.4015 / 100 batches)

2022-10-11 12:22:18,839 [INFO] 	Process 1 - batch 90999: mean_policy_losses: -4.892, mean_net_lifetime: 6471.9221, mean_mc_travel_dist: 2004.5348, mean_rewards: 255.7428, total_rewards: 4496.0523, mean_steps: 24.4700, mean_ecr: 0.0383 mean_entropies: 0.8971, took: 117.6778s
2022-10-11 12:22:27,161 [INFO] 	Process 3 - batch 109899: mean_policy_losses: -30.845, mean_net_lifetime: 5272.6776, mean_mc_travel_dist: 1315.2969, mean_rewards: 264.2519, total_rewards: 3985.3337, mean_steps: 19.1900, mean_ecr: 0.0454 mean_entropies: 0.4525, took: 98.8105s
2022-10-11 12:22:38,143 [INFO] 	Process 6 - batch 146699: mean_policy_losses: -42.484, mean_net_lifetime: 4109.6904, mean_mc_travel_dist: 1102.0017, mean_rewards: 343.8214, total_rewards: 3050.4567, mean_steps: 10.9300, mean_ecr: 0.0549 mean_entropies: 0.1304, took: 58.8879s
2022-10-11 12:23:37,297 [INFO] 	Process 6 - batch 146799: mean_policy_losses: -83.681, mean_net_lifetime: 3987.7354, mean_mc_travel_dist: 1053.1620, mean_rewards: 342.2403, total_rewards: 2965.1786, mean_steps: 10.6000, mean_ecr: 0.0553 mean_entropies: 0.1305, took: 59.1537s
2022-10-11 12:23:40,671 [INFO] 	Process 7 - batch 99899: mean_policy_losses: -324.349, mean_net_lifetime: 5067.3518, mean_mc_travel_dist: 1546.2405, mean_rewards: 201.8517, total_rewards: 3553.3625, mean_steps: 24.3900, mean_ecr: 0.0408 mean_entropies: 1.2423, took: 118.5221s
2022-10-11 12:24:02,900 [INFO] 	Process 3 - batch 109999: mean_policy_losses: -50.623, mean_net_lifetime: 5280.7139, mean_mc_travel_dist: 1324.5345, mean_rewards: 276.5440, total_rewards: 3983.6124, mean_steps: 18.1800, mean_ecr: 0.0453 mean_entropies: 0.4593, took: 95.7375s
2022-10-11 12:24:23,510 [INFO] 	Process 1 - batch 91099: mean_policy_losses: -11.422, mean_net_lifetime: 6694.7277, mean_mc_travel_dist: 2056.8631, mean_rewards: 254.1657, total_rewards: 4663.6073, mean_steps: 25.5200, mean_ecr: 0.0382 mean_entropies: 0.9200, took: 124.6703s
2022-10-11 12:24:36,384 [INFO] 	Process 6 - batch 146899: mean_policy_losses: -57.929, mean_net_lifetime: 4150.4664, mean_mc_travel_dist: 1094.8210, mean_rewards: 346.9398, total_rewards: 3081.1749, mean_steps: 10.9500, mean_ecr: 0.0548 mean_entropies: 0.1158, took: 59.0866s
2022-10-11 12:24:49,351 [INFO] 	Process 4 - batch 100499: mean_policy_losses: 136.029, mean_net_lifetime: 10213.2244, mean_mc_travel_dist: 2980.5784, mean_rewards: 273.0744, total_rewards: 7263.6217, mean_steps: 39.3400, mean_ecr: 0.0386 mean_entropies: 0.5445, took: 185.0516s
2022-10-11 12:24:56,648 [INFO] 	Process 5 - batch 90099: mean_policy_losses: -98.752, mean_net_lifetime: 9421.3854, mean_mc_travel_dist: 2877.8815, mean_rewards: 266.8607, total_rewards: 6583.7658, mean_steps: 35.1400, mean_ecr: 0.0301 mean_entropies: 0.6507, took: 871.0310s
2022-10-11 12:25:35,310 [INFO] 	Process 6 - batch 146999: mean_policy_losses: -38.041, mean_net_lifetime: 4185.6548, mean_mc_travel_dist: 1113.3932, mean_rewards: 344.9900, total_rewards: 3098.2542, mean_steps: 11.1000, mean_ecr: 0.0550 mean_entropies: 0.1141, took: 58.9270s
2022-10-11 12:25:35,329 [INFO] 	Process 3 - batch 110099: mean_policy_losses: -30.838, mean_net_lifetime: 5323.4053, mean_mc_travel_dist: 1337.3101, mean_rewards: 277.3345, total_rewards: 4016.2352, mean_steps: 18.2700, mean_ecr: 0.0453 mean_entropies: 0.4722, took: 92.4303s
2022-10-11 12:25:36,808 [INFO] 	Process 7 - batch 99999: mean_policy_losses: -258.848, mean_net_lifetime: 5126.9818, mean_mc_travel_dist: 1573.6056, mean_rewards: 202.6496, total_rewards: 3592.1771, mean_steps: 24.6700, mean_ecr: 0.0406 mean_entropies: 1.2247, took: 116.1373s
2022-10-11 12:26:30,394 [INFO] 	Process 1 - batch 91199: mean_policy_losses: 7.472, mean_net_lifetime: 6773.3668, mean_mc_travel_dist: 2070.9502, mean_rewards: 242.2461, total_rewards: 4724.7871, mean_steps: 27.0900, mean_ecr: 0.0381 mean_entropies: 0.9575, took: 126.8838s
2022-10-11 12:27:05,502 [INFO] 	Process 3 - batch 110199: mean_policy_losses: -51.369, mean_net_lifetime: 5307.9848, mean_mc_travel_dist: 1358.9998, mean_rewards: 273.4926, total_rewards: 3979.7715, mean_steps: 18.5100, mean_ecr: 0.0450 mean_entropies: 0.4777, took: 90.1718s
2022-10-11 12:27:33,597 [INFO] 	Process 7 - batch 100099: mean_policy_losses: -231.733, mean_net_lifetime: 5367.8479, mean_mc_travel_dist: 1629.5590, mean_rewards: 197.9684, total_rewards: 3756.6782, mean_steps: 26.6700, mean_ecr: 0.0404 mean_entropies: 1.2390, took: 116.7892s
2022-10-11 12:27:40,430 [INFO] 	Process 5 - batch 90199: mean_policy_losses: -68.274, mean_net_lifetime: 9519.8479, mean_mc_travel_dist: 2881.2648, mean_rewards: 260.1698, total_rewards: 6669.3551, mean_steps: 36.1600, mean_ecr: 0.0299 mean_entropies: 0.6508, took: 163.7818s
2022-10-11 12:27:52,437 [INFO] Process 2 - epoch 65: mean_policy_losses: -1.553, mean_net_lifetime: 5541.2043, mean_mc_travel_dist: 1721.8882, mean_entropies: 0.7851, m_net_lifetime_valid: 4517.9966, took: 2607.7783s, (156.7120 / 100 batches)

2022-10-11 12:28:26,974 [INFO] 	Process 1 - batch 91299: mean_policy_losses: -20.012, mean_net_lifetime: 6755.5220, mean_mc_travel_dist: 2080.8313, mean_rewards: 254.6627, total_rewards: 4709.4911, mean_steps: 25.6100, mean_ecr: 0.0382 mean_entropies: 0.9333, took: 116.5805s
2022-10-11 12:28:33,719 [INFO] 	Process 3 - batch 110299: mean_policy_losses: -53.557, mean_net_lifetime: 5379.3719, mean_mc_travel_dist: 1372.6340, mean_rewards: 285.0850, total_rewards: 4037.1163, mean_steps: 17.9100, mean_ecr: 0.0452 mean_entropies: 0.4805, took: 88.2183s
2022-10-11 12:29:38,703 [INFO] 	Process 7 - batch 100199: mean_policy_losses: -204.289, mean_net_lifetime: 5494.4135, mean_mc_travel_dist: 1662.3055, mean_rewards: 200.6063, total_rewards: 3864.2175, mean_steps: 26.8800, mean_ecr: 0.0402 mean_entropies: 1.2008, took: 125.1054s
2022-10-11 12:29:51,381 [INFO] 	Process 2 - batch 97599: mean_policy_losses: -22.499, mean_net_lifetime: 7430.7303, mean_mc_travel_dist: 1940.9563, mean_rewards: 290.4575, total_rewards: 5510.1119, mean_steps: 24.6600, mean_ecr: 0.0385 mean_entropies: 0.3449, took: 845.7411s
2022-10-11 12:30:03,718 [INFO] 	Process 3 - batch 110399: mean_policy_losses: -59.407, mean_net_lifetime: 5329.1423, mean_mc_travel_dist: 1371.1449, mean_rewards: 278.7688, total_rewards: 3983.1320, mean_steps: 18.1700, mean_ecr: 0.0450 mean_entropies: 0.4740, took: 89.9993s
2022-10-11 12:30:33,282 [INFO] 	Process 1 - batch 91399: mean_policy_losses: -53.439, mean_net_lifetime: 6821.8394, mean_mc_travel_dist: 2117.4062, mean_rewards: 242.8368, total_rewards: 4729.8077, mean_steps: 27.2500, mean_ecr: 0.0380 mean_entropies: 0.9061, took: 126.3087s
2022-10-11 12:31:18,409 [INFO] 	Process 5 - batch 90299: mean_policy_losses: -20.449, mean_net_lifetime: 12405.6753, mean_mc_travel_dist: 3811.1040, mean_rewards: 261.5796, total_rewards: 8635.2893, mean_steps: 47.9900, mean_ecr: 0.0292 mean_entropies: 0.6256, took: 217.9803s
2022-10-11 12:31:39,631 [INFO] 	Process 3 - batch 110499: mean_policy_losses: -36.052, mean_net_lifetime: 5454.2536, mean_mc_travel_dist: 1407.4645, mean_rewards: 278.9343, total_rewards: 4067.3010, mean_steps: 18.6200, mean_ecr: 0.0446 mean_entropies: 0.4859, took: 95.9124s
2022-10-11 12:31:42,878 [INFO] 	Process 7 - batch 100299: mean_policy_losses: -215.674, mean_net_lifetime: 5448.2078, mean_mc_travel_dist: 1641.4860, mean_rewards: 197.7487, total_rewards: 3830.4512, mean_steps: 26.7900, mean_ecr: 0.0404 mean_entropies: 1.2387, took: 124.1747s
2022-10-11 12:31:51,782 [INFO] 	Process 2 - batch 97699: mean_policy_losses: -17.976, mean_net_lifetime: 7453.7172, mean_mc_travel_dist: 1989.4623, mean_rewards: 284.3229, total_rewards: 5494.1576, mean_steps: 25.3000, mean_ecr: 0.0384 mean_entropies: 0.3762, took: 120.4012s
2022-10-11 12:32:36,704 [INFO] 	Process 1 - batch 91499: mean_policy_losses: -74.786, mean_net_lifetime: 6695.2151, mean_mc_travel_dist: 2040.4419, mean_rewards: 247.9230, total_rewards: 4673.7945, mean_steps: 26.0800, mean_ecr: 0.0384 mean_entropies: 0.9266, took: 123.4217s
2022-10-11 12:33:10,774 [INFO] 	Process 3 - batch 110599: mean_policy_losses: -39.727, mean_net_lifetime: 5452.8534, mean_mc_travel_dist: 1406.3376, mean_rewards: 280.3738, total_rewards: 4069.4193, mean_steps: 18.5000, mean_ecr: 0.0447 mean_entropies: 0.4820, took: 91.1429s
2022-10-11 12:33:45,791 [INFO] 	Process 7 - batch 100399: mean_policy_losses: -234.954, mean_net_lifetime: 5388.4542, mean_mc_travel_dist: 1626.0269, mean_rewards: 195.4368, total_rewards: 3788.3344, mean_steps: 27.4300, mean_ecr: 0.0405 mean_entropies: 1.1873, took: 122.9138s
2022-10-11 12:33:54,069 [INFO] 	Process 2 - batch 97799: mean_policy_losses: -15.028, mean_net_lifetime: 7675.7896, mean_mc_travel_dist: 2008.5403, mean_rewards: 283.9522, total_rewards: 5686.3626, mean_steps: 26.1100, mean_ecr: 0.0381 mean_entropies: 0.3590, took: 122.2873s
2022-10-11 12:34:39,716 [INFO] 	Process 3 - batch 110699: mean_policy_losses: -46.265, mean_net_lifetime: 5473.6646, mean_mc_travel_dist: 1399.8537, mean_rewards: 283.7426, total_rewards: 4097.2472, mean_steps: 18.3500, mean_ecr: 0.0448 mean_entropies: 0.4548, took: 88.9412s
2022-10-11 12:34:45,910 [INFO] 	Process 5 - batch 90399: mean_policy_losses: 13.268, mean_net_lifetime: 12048.1786, mean_mc_travel_dist: 3656.9292, mean_rewards: 262.0834, total_rewards: 8431.3725, mean_steps: 46.0100, mean_ecr: 0.0293 mean_entropies: 0.6334, took: 207.5000s
2022-10-11 12:35:49,878 [INFO] 	Process 7 - batch 100499: mean_policy_losses: -304.969, mean_net_lifetime: 5256.2114, mean_mc_travel_dist: 1586.1472, mean_rewards: 193.8566, total_rewards: 3703.3140, mean_steps: 26.5300, mean_ecr: 0.0405 mean_entropies: 1.1998, took: 124.0863s
2022-10-11 12:35:50,476 [INFO] Process 4 - epoch 67: mean_policy_losses: 111.138, mean_net_lifetime: 5391.5598, mean_mc_travel_dist: 1670.9067, mean_entropies: 0.9933, m_net_lifetime_valid: 4465.0115, took: 3724.8805s, (152.5790 / 100 batches)

2022-10-11 12:35:52,241 [INFO] 	Process 2 - batch 97899: mean_policy_losses: -36.323, mean_net_lifetime: 7576.7097, mean_mc_travel_dist: 1991.9066, mean_rewards: 291.9420, total_rewards: 5604.8628, mean_steps: 25.0100, mean_ecr: 0.0384 mean_entropies: 0.3663, took: 118.1720s
2022-10-11 12:36:09,329 [INFO] 	Process 3 - batch 110799: mean_policy_losses: -48.120, mean_net_lifetime: 5498.8249, mean_mc_travel_dist: 1413.0646, mean_rewards: 286.1977, total_rewards: 4121.2592, mean_steps: 18.2400, mean_ecr: 0.0448 mean_entropies: 0.4635, took: 89.6138s
2022-10-11 12:36:29,036 [INFO] Process 6 - epoch 98: mean_policy_losses: -173.100, mean_net_lifetime: 3350.1218, mean_mc_travel_dist: 999.6546, mean_entropies: 0.4512, m_net_lifetime_valid: 4221.9624, took: 1511.9040s, (104.3780 / 100 batches)

2022-10-11 12:37:25,599 [INFO] 	Process 6 - batch 147099: mean_policy_losses: -84.004, mean_net_lifetime: 4008.5640, mean_mc_travel_dist: 1062.2037, mean_rewards: 342.7473, total_rewards: 2987.3406, mean_steps: 10.6600, mean_ecr: 0.0549 mean_entropies: 0.1384, took: 710.2890s
2022-10-11 12:37:38,758 [INFO] 	Process 3 - batch 110899: mean_policy_losses: -55.640, mean_net_lifetime: 5455.6646, mean_mc_travel_dist: 1400.3206, mean_rewards: 283.0748, total_rewards: 4081.2416, mean_steps: 18.3200, mean_ecr: 0.0449 mean_entropies: 0.4748, took: 89.4288s
2022-10-11 12:37:50,598 [INFO] 	Process 2 - batch 97999: mean_policy_losses: -47.378, mean_net_lifetime: 7468.8945, mean_mc_travel_dist: 1977.0215, mean_rewards: 289.1762, total_rewards: 5520.1630, mean_steps: 24.9900, mean_ecr: 0.0385 mean_entropies: 0.3640, took: 118.3568s
2022-10-11 12:37:56,039 [INFO] 	Process 5 - batch 90499: mean_policy_losses: -43.216, mean_net_lifetime: 11347.6641, mean_mc_travel_dist: 3479.0411, mean_rewards: 270.9390, total_rewards: 7904.9862, mean_steps: 42.1000, mean_ecr: 0.0295 mean_entropies: 0.6736, took: 190.1297s
2022-10-11 12:38:21,295 [INFO] 	Process 6 - batch 147199: mean_policy_losses: -78.062, mean_net_lifetime: 3996.8828, mean_mc_travel_dist: 1060.9703, mean_rewards: 344.6974, total_rewards: 2980.7637, mean_steps: 10.5700, mean_ecr: 0.0548 mean_entropies: 0.1201, took: 55.6956s
2022-10-11 12:38:21,508 [INFO] 	Process 4 - batch 100599: mean_policy_losses: 76.997, mean_net_lifetime: 8679.9417, mean_mc_travel_dist: 2474.9724, mean_rewards: 272.3648, total_rewards: 6224.1358, mean_steps: 32.9400, mean_ecr: 0.0403 mean_entropies: 0.4934, took: 812.1571s
2022-10-11 12:39:08,374 [INFO] 	Process 3 - batch 110999: mean_policy_losses: -67.961, mean_net_lifetime: 5260.2267, mean_mc_travel_dist: 1338.0329, mean_rewards: 280.8906, total_rewards: 3953.3050, mean_steps: 17.7600, mean_ecr: 0.0452 mean_entropies: 0.4636, took: 89.6161s
2022-10-11 12:39:16,151 [INFO] 	Process 6 - batch 147299: mean_policy_losses: -50.715, mean_net_lifetime: 4058.8698, mean_mc_travel_dist: 1087.5665, mean_rewards: 343.1590, total_rewards: 3010.2184, mean_steps: 10.7900, mean_ecr: 0.0552 mean_entropies: 0.1150, took: 54.8564s
2022-10-11 12:39:47,017 [INFO] 	Process 2 - batch 98099: mean_policy_losses: -74.047, mean_net_lifetime: 7272.6292, mean_mc_travel_dist: 1888.4999, mean_rewards: 287.4674, total_rewards: 5405.3740, mean_steps: 24.4100, mean_ecr: 0.0387 mean_entropies: 0.3483, took: 116.4188s
2022-10-11 12:40:10,822 [INFO] 	Process 6 - batch 147399: mean_policy_losses: -72.590, mean_net_lifetime: 4143.6503, mean_mc_travel_dist: 1092.8778, mean_rewards: 345.5590, total_rewards: 3080.8708, mean_steps: 10.9700, mean_ecr: 0.0548 mean_entropies: 0.1160, took: 54.6713s
2022-10-11 12:41:04,253 [INFO] 	Process 6 - batch 147499: mean_policy_losses: -91.269, mean_net_lifetime: 3873.9190, mean_mc_travel_dist: 1022.0472, mean_rewards: 344.8678, total_rewards: 2890.6080, mean_steps: 10.2200, mean_ecr: 0.0548 mean_entropies: 0.1402, took: 53.4308s
2022-10-11 12:41:07,392 [INFO] 	Process 5 - batch 90599: mean_policy_losses: -76.287, mean_net_lifetime: 11356.7950, mean_mc_travel_dist: 3535.1186, mean_rewards: 263.3010, total_rewards: 7860.1261, mean_steps: 43.4200, mean_ecr: 0.0293 mean_entropies: 0.6392, took: 191.3532s
2022-10-11 12:41:09,614 [INFO] 	Process 4 - batch 100699: mean_policy_losses: 69.211, mean_net_lifetime: 9857.8537, mean_mc_travel_dist: 2871.8954, mean_rewards: 275.8387, total_rewards: 7006.5414, mean_steps: 37.6200, mean_ecr: 0.0389 mean_entropies: 0.4696, took: 168.1063s
2022-10-11 12:41:42,400 [INFO] 	Process 2 - batch 98199: mean_policy_losses: -27.263, mean_net_lifetime: 7530.1959, mean_mc_travel_dist: 1963.0445, mean_rewards: 291.2491, total_rewards: 5587.7008, mean_steps: 24.9200, mean_ecr: 0.0385 mean_entropies: 0.3520, took: 115.3830s
2022-10-11 12:42:01,141 [INFO] 	Process 6 - batch 147599: mean_policy_losses: -63.977, mean_net_lifetime: 4112.9683, mean_mc_travel_dist: 1080.1000, mean_rewards: 343.8189, total_rewards: 3051.2908, mean_steps: 10.9300, mean_ecr: 0.0550 mean_entropies: 0.1201, took: 56.8881s
2022-10-11 12:42:55,709 [INFO] 	Process 6 - batch 147699: mean_policy_losses: -65.066, mean_net_lifetime: 4119.4862, mean_mc_travel_dist: 1084.3634, mean_rewards: 344.0023, total_rewards: 3058.6641, mean_steps: 10.9300, mean_ecr: 0.0548 mean_entropies: 0.1243, took: 54.5678s
2022-10-11 12:43:03,744 [INFO] Process 1 - epoch 61: mean_policy_losses: 9.740, mean_net_lifetime: 5560.1957, mean_mc_travel_dist: 2042.2108, mean_entropies: 1.1134, m_net_lifetime_valid: 4286.9671, took: 2466.5384s, (168.0807 / 100 batches)

2022-10-11 12:43:39,977 [INFO] 	Process 2 - batch 98299: mean_policy_losses: -31.589, mean_net_lifetime: 7470.0021, mean_mc_travel_dist: 1943.3105, mean_rewards: 287.2089, total_rewards: 5549.8813, mean_steps: 25.1000, mean_ecr: 0.0386 mean_entropies: 0.3626, took: 117.5772s
2022-10-11 12:43:49,621 [INFO] 	Process 6 - batch 147799: mean_policy_losses: -153.777, mean_net_lifetime: 3891.1583, mean_mc_travel_dist: 1056.4320, mean_rewards: 339.2338, total_rewards: 2866.9258, mean_steps: 10.4500, mean_ecr: 0.0553 mean_entropies: 0.1282, took: 53.9117s
2022-10-11 12:43:50,141 [INFO] 	Process 4 - batch 100799: mean_policy_losses: 74.461, mean_net_lifetime: 9445.6532, mean_mc_travel_dist: 2706.7824, mean_rewards: 269.9954, total_rewards: 6754.3366, mean_steps: 36.0300, mean_ecr: 0.0379 mean_entropies: 0.4962, took: 160.5251s
2022-10-11 12:44:00,709 [INFO] 	Process 5 - batch 90699: mean_policy_losses: -109.615, mean_net_lifetime: 10114.9584, mean_mc_travel_dist: 3089.3878, mean_rewards: 263.8136, total_rewards: 7084.8310, mean_steps: 38.1600, mean_ecr: 0.0296 mean_entropies: 0.6636, took: 173.3157s
2022-10-11 12:44:45,978 [INFO] 	Process 6 - batch 147899: mean_policy_losses: -112.185, mean_net_lifetime: 4002.7300, mean_mc_travel_dist: 1059.8024, mean_rewards: 341.4217, total_rewards: 2960.9214, mean_steps: 10.6800, mean_ecr: 0.0550 mean_entropies: 0.1261, took: 56.3574s
2022-10-11 12:45:13,917 [INFO] 	Process 1 - batch 91599: mean_policy_losses: -18.129, mean_net_lifetime: 6577.1691, mean_mc_travel_dist: 1960.2801, mean_rewards: 240.1971, total_rewards: 4648.4376, mean_steps: 26.5800, mean_ecr: 0.0386 mean_entropies: 0.9397, took: 757.2129s
2022-10-11 12:45:42,735 [INFO] 	Process 6 - batch 147999: mean_policy_losses: -56.720, mean_net_lifetime: 3971.7869, mean_mc_travel_dist: 1063.2411, mean_rewards: 340.8611, total_rewards: 2928.7910, mean_steps: 10.6200, mean_ecr: 0.0553 mean_entropies: 0.1433, took: 56.7565s
2022-10-11 12:45:44,406 [INFO] 	Process 2 - batch 98399: mean_policy_losses: -12.828, mean_net_lifetime: 7754.5777, mean_mc_travel_dist: 2035.7816, mean_rewards: 286.8602, total_rewards: 5736.6867, mean_steps: 26.1400, mean_ecr: 0.0382 mean_entropies: 0.3541, took: 124.4298s
2022-10-11 12:46:38,248 [INFO] 	Process 6 - batch 148099: mean_policy_losses: -79.462, mean_net_lifetime: 3956.0594, mean_mc_travel_dist: 1051.1099, mean_rewards: 336.8537, total_rewards: 2935.8853, mean_steps: 10.6700, mean_ecr: 0.0552 mean_entropies: 0.1460, took: 55.5136s
2022-10-11 12:46:46,410 [INFO] 	Process 4 - batch 100899: mean_policy_losses: 66.513, mean_net_lifetime: 9897.3396, mean_mc_travel_dist: 2875.9049, mean_rewards: 266.8477, total_rewards: 7039.9939, mean_steps: 38.6500, mean_ecr: 0.0379 mean_entropies: 0.4901, took: 176.2707s
2022-10-11 12:46:58,063 [INFO] 	Process 5 - batch 90799: mean_policy_losses: -61.348, mean_net_lifetime: 10101.9526, mean_mc_travel_dist: 3012.2725, mean_rewards: 259.9095, total_rewards: 7130.1652, mean_steps: 38.3600, mean_ecr: 0.0298 mean_entropies: 0.6563, took: 177.3546s
2022-10-11 12:47:21,546 [INFO] 	Process 1 - batch 91699: mean_policy_losses: -23.143, mean_net_lifetime: 6649.6492, mean_mc_travel_dist: 2002.0886, mean_rewards: 240.5926, total_rewards: 4677.9950, mean_steps: 26.8400, mean_ecr: 0.0384 mean_entropies: 0.9336, took: 127.6289s
2022-10-11 12:47:35,214 [INFO] 	Process 6 - batch 148199: mean_policy_losses: -90.609, mean_net_lifetime: 3980.2713, mean_mc_travel_dist: 1052.8924, mean_rewards: 344.2403, total_rewards: 2949.5720, mean_steps: 10.5200, mean_ecr: 0.0550 mean_entropies: 0.1369, took: 56.9654s
2022-10-11 12:47:48,100 [INFO] 	Process 2 - batch 98499: mean_policy_losses: -25.674, mean_net_lifetime: 7658.1807, mean_mc_travel_dist: 1994.0366, mean_rewards: 285.2226, total_rewards: 5689.1113, mean_steps: 25.9200, mean_ecr: 0.0383 mean_entropies: 0.3608, took: 123.6931s
2022-10-11 12:48:07,199 [INFO] Process 7 - epoch 67: mean_policy_losses: -362.681, mean_net_lifetime: 4398.6483, mean_mc_travel_dist: 1550.7034, mean_entropies: 1.4913, m_net_lifetime_valid: 4583.1637, took: 2490.5291s, (153.2356 / 100 batches)

2022-10-11 12:48:29,654 [INFO] 	Process 6 - batch 148299: mean_policy_losses: -83.531, mean_net_lifetime: 3837.9126, mean_mc_travel_dist: 1022.4794, mean_rewards: 341.3011, total_rewards: 2846.3707, mean_steps: 10.2000, mean_ecr: 0.0552 mean_entropies: 0.1421, took: 54.4408s
2022-10-11 12:49:25,587 [INFO] 	Process 6 - batch 148399: mean_policy_losses: -78.617, mean_net_lifetime: 3943.3187, mean_mc_travel_dist: 1037.3469, mean_rewards: 344.6501, total_rewards: 2936.6499, mean_steps: 10.4000, mean_ecr: 0.0549 mean_entropies: 0.1312, took: 55.9322s
2022-10-11 12:49:27,900 [INFO] 	Process 1 - batch 91799: mean_policy_losses: 0.013, mean_net_lifetime: 6721.4654, mean_mc_travel_dist: 2066.0689, mean_rewards: 249.5099, total_rewards: 4677.9111, mean_steps: 26.0600, mean_ecr: 0.0381 mean_entropies: 0.8951, took: 126.3536s
2022-10-11 12:49:55,234 [INFO] 	Process 2 - batch 98599: mean_policy_losses: -11.900, mean_net_lifetime: 7647.4521, mean_mc_travel_dist: 2000.2884, mean_rewards: 288.1791, total_rewards: 5670.4408, mean_steps: 25.6100, mean_ecr: 0.0382 mean_entropies: 0.3555, took: 127.1344s
2022-10-11 12:50:03,546 [INFO] 	Process 7 - batch 100599: mean_policy_losses: -380.458, mean_net_lifetime: 5063.2944, mean_mc_travel_dist: 1529.7082, mean_rewards: 205.4385, total_rewards: 3563.2187, mean_steps: 23.9800, mean_ecr: 0.0409 mean_entropies: 1.2445, took: 853.6685s
2022-10-11 12:50:18,067 [INFO] 	Process 5 - batch 90899: mean_policy_losses: -72.591, mean_net_lifetime: 11070.0404, mean_mc_travel_dist: 3346.2241, mean_rewards: 259.4590, total_rewards: 7766.2144, mean_steps: 42.6000, mean_ecr: 0.0295 mean_entropies: 0.6436, took: 200.0038s
2022-10-11 12:50:23,435 [INFO] 	Process 6 - batch 148499: mean_policy_losses: -81.418, mean_net_lifetime: 4047.6591, mean_mc_travel_dist: 1061.6425, mean_rewards: 346.1773, total_rewards: 3003.4659, mean_steps: 10.6600, mean_ecr: 0.0549 mean_entropies: 0.1201, took: 57.8481s
2022-10-11 12:50:38,155 [INFO] 	Process 4 - batch 100999: mean_policy_losses: 116.629, mean_net_lifetime: 12510.8460, mean_mc_travel_dist: 3751.9624, mean_rewards: 262.8775, total_rewards: 8786.9842, mean_steps: 50.7000, mean_ecr: 0.0375 mean_entropies: 0.5308, took: 231.7450s
2022-10-11 12:51:03,631 [INFO] Process 3 - epoch 74: mean_policy_losses: 35.660, mean_net_lifetime: 4595.7083, mean_mc_travel_dist: 1344.0828, mean_entropies: 0.7560, m_net_lifetime_valid: 4382.0790, took: 2096.1014s, (138.9315 / 100 batches)

2022-10-11 12:51:33,423 [INFO] 	Process 1 - batch 91899: mean_policy_losses: -61.951, mean_net_lifetime: 6528.8292, mean_mc_travel_dist: 1976.6317, mean_rewards: 239.8267, total_rewards: 4580.3324, mean_steps: 26.4100, mean_ecr: 0.0386 mean_entropies: 0.9667, took: 125.5234s
2022-10-11 12:52:00,228 [INFO] 	Process 2 - batch 98699: mean_policy_losses: -16.843, mean_net_lifetime: 7620.4366, mean_mc_travel_dist: 2003.0946, mean_rewards: 291.3391, total_rewards: 5640.4080, mean_steps: 25.3000, mean_ecr: 0.0385 mean_entropies: 0.3555, took: 124.9940s
2022-10-11 12:52:08,357 [INFO] 	Process 7 - batch 100699: mean_policy_losses: -291.223, mean_net_lifetime: 5304.6723, mean_mc_travel_dist: 1601.1848, mean_rewards: 196.7559, total_rewards: 3743.7464, mean_steps: 26.1900, mean_ecr: 0.0406 mean_entropies: 1.2626, took: 124.8102s
2022-10-11 12:52:39,037 [INFO] 	Process 3 - batch 111099: mean_policy_losses: -46.461, mean_net_lifetime: 5351.5724, mean_mc_travel_dist: 1359.8179, mean_rewards: 278.4460, total_rewards: 4018.8523, mean_steps: 18.2700, mean_ecr: 0.0449 mean_entropies: 0.4749, took: 810.6631s
2022-10-11 12:53:44,416 [INFO] 	Process 1 - batch 91999: mean_policy_losses: -1.482, mean_net_lifetime: 6843.4361, mean_mc_travel_dist: 2064.9718, mean_rewards: 244.4715, total_rewards: 4797.5558, mean_steps: 27.1600, mean_ecr: 0.0382 mean_entropies: 0.9553, took: 130.9913s
2022-10-11 12:53:51,821 [INFO] 	Process 5 - batch 90999: mean_policy_losses: -89.020, mean_net_lifetime: 11924.1721, mean_mc_travel_dist: 3689.9166, mean_rewards: 263.0322, total_rewards: 8277.7176, mean_steps: 45.9500, mean_ecr: 0.0293 mean_entropies: 0.6405, took: 213.7545s
2022-10-11 12:54:04,526 [INFO] 	Process 2 - batch 98799: mean_policy_losses: -19.546, mean_net_lifetime: 7565.3008, mean_mc_travel_dist: 1990.2872, mean_rewards: 288.5442, total_rewards: 5602.6714, mean_steps: 25.3000, mean_ecr: 0.0383 mean_entropies: 0.3565, took: 124.2975s
2022-10-11 12:54:13,273 [INFO] 	Process 3 - batch 111199: mean_policy_losses: -33.692, mean_net_lifetime: 5435.9299, mean_mc_travel_dist: 1355.3744, mean_rewards: 282.9139, total_rewards: 4111.1770, mean_steps: 18.2600, mean_ecr: 0.0454 mean_entropies: 0.4347, took: 94.2356s
2022-10-11 12:54:14,244 [INFO] 	Process 7 - batch 100799: mean_policy_losses: -246.666, mean_net_lifetime: 5432.1300, mean_mc_travel_dist: 1607.2880, mean_rewards: 201.5170, total_rewards: 3853.8978, mean_steps: 26.4100, mean_ecr: 0.0405 mean_entropies: 1.2080, took: 125.8867s
2022-10-11 12:55:20,765 [INFO] 	Process 4 - batch 101099: mean_policy_losses: 125.148, mean_net_lifetime: 14562.8884, mean_mc_travel_dist: 4566.6018, mean_rewards: 260.9368, total_rewards: 10019.8799, mean_steps: 61.9800, mean_ecr: 0.0370 mean_entropies: 0.4883, took: 282.6107s
2022-10-11 12:55:49,322 [INFO] 	Process 3 - batch 111299: mean_policy_losses: -50.520, mean_net_lifetime: 5407.3956, mean_mc_travel_dist: 1376.7426, mean_rewards: 273.2962, total_rewards: 4055.2625, mean_steps: 18.9200, mean_ecr: 0.0449 mean_entropies: 0.4586, took: 96.0495s
2022-10-11 12:56:00,052 [INFO] 	Process 1 - batch 92099: mean_policy_losses: -1.647, mean_net_lifetime: 6785.4844, mean_mc_travel_dist: 2022.4532, mean_rewards: 237.2329, total_rewards: 4785.8401, mean_steps: 27.8500, mean_ecr: 0.0384 mean_entropies: 0.9432, took: 135.6369s
2022-10-11 12:56:11,117 [INFO] 	Process 2 - batch 98899: mean_policy_losses: -23.675, mean_net_lifetime: 7671.7526, mean_mc_travel_dist: 2018.2400, mean_rewards: 287.3197, total_rewards: 5673.3610, mean_steps: 25.7900, mean_ecr: 0.0381 mean_entropies: 0.3497, took: 126.5916s
2022-10-11 12:56:25,120 [INFO] 	Process 7 - batch 100899: mean_policy_losses: -208.216, mean_net_lifetime: 5443.4892, mean_mc_travel_dist: 1636.3194, mean_rewards: 195.3441, total_rewards: 3843.0211, mean_steps: 27.2100, mean_ecr: 0.0405 mean_entropies: 1.2158, took: 130.8762s
2022-10-11 12:56:45,520 [INFO] 	Process 5 - batch 91099: mean_policy_losses: -75.848, mean_net_lifetime: 9557.4190, mean_mc_travel_dist: 2884.0036, mean_rewards: 264.9557, total_rewards: 6719.9780, mean_steps: 35.8500, mean_ecr: 0.0298 mean_entropies: 0.6206, took: 173.6994s
2022-10-11 12:57:25,011 [INFO] 	Process 3 - batch 111399: mean_policy_losses: -53.567, mean_net_lifetime: 5499.3878, mean_mc_travel_dist: 1400.8367, mean_rewards: 281.9549, total_rewards: 4129.3340, mean_steps: 18.5700, mean_ecr: 0.0449 mean_entropies: 0.4538, took: 95.6891s
2022-10-11 12:58:09,947 [INFO] 	Process 1 - batch 92199: mean_policy_losses: -13.001, mean_net_lifetime: 6758.7770, mean_mc_travel_dist: 2020.4094, mean_rewards: 244.8876, total_rewards: 4757.9406, mean_steps: 26.7300, mean_ecr: 0.0384 mean_entropies: 0.9549, took: 129.8963s
2022-10-11 12:58:20,160 [INFO] 	Process 2 - batch 98999: mean_policy_losses: -22.674, mean_net_lifetime: 7673.3281, mean_mc_travel_dist: 2013.3093, mean_rewards: 288.5774, total_rewards: 5681.9696, mean_steps: 25.6800, mean_ecr: 0.0382 mean_entropies: 0.3457, took: 129.0423s
2022-10-11 12:58:26,037 [INFO] 	Process 7 - batch 100999: mean_policy_losses: -269.578, mean_net_lifetime: 5183.6935, mean_mc_travel_dist: 1577.8419, mean_rewards: 204.2203, total_rewards: 3635.5768, mean_steps: 24.5700, mean_ecr: 0.0406 mean_entropies: 1.2435, took: 120.9167s
2022-10-11 12:58:37,738 [INFO] 	Process 4 - batch 101199: mean_policy_losses: 115.774, mean_net_lifetime: 10702.0693, mean_mc_travel_dist: 3162.9465, mean_rewards: 272.8211, total_rewards: 7567.7596, mean_steps: 41.9100, mean_ecr: 0.0382 mean_entropies: 0.4700, took: 196.9726s
2022-10-11 12:58:59,150 [INFO] 	Process 3 - batch 111499: mean_policy_losses: -45.201, mean_net_lifetime: 5472.2277, mean_mc_travel_dist: 1409.5885, mean_rewards: 278.3086, total_rewards: 4085.0404, mean_steps: 18.7200, mean_ecr: 0.0445 mean_entropies: 0.4293, took: 94.1385s
2022-10-11 13:00:02,933 [INFO] 	Process 5 - batch 91199: mean_policy_losses: -64.622, mean_net_lifetime: 10806.8842, mean_mc_travel_dist: 3260.9957, mean_rewards: 258.9302, total_rewards: 7573.8651, mean_steps: 41.8200, mean_ecr: 0.0293 mean_entropies: 0.6234, took: 197.4121s
2022-10-11 13:00:17,718 [INFO] 	Process 1 - batch 92299: mean_policy_losses: -5.374, mean_net_lifetime: 6685.0058, mean_mc_travel_dist: 1999.4973, mean_rewards: 242.4623, total_rewards: 4715.3683, mean_steps: 26.7300, mean_ecr: 0.0385 mean_entropies: 0.9667, took: 127.7701s
2022-10-11 13:00:27,681 [INFO] 	Process 7 - batch 101099: mean_policy_losses: -271.059, mean_net_lifetime: 5371.1256, mean_mc_travel_dist: 1599.6705, mean_rewards: 199.7814, total_rewards: 3808.0437, mean_steps: 26.0800, mean_ecr: 0.0405 mean_entropies: 1.2778, took: 121.6452s
2022-10-11 13:00:34,175 [INFO] 	Process 3 - batch 111599: mean_policy_losses: -41.680, mean_net_lifetime: 5582.0334, mean_mc_travel_dist: 1423.1262, mean_rewards: 281.2387, total_rewards: 4181.9935, mean_steps: 18.8800, mean_ecr: 0.0446 mean_entropies: 0.4499, took: 95.0255s
2022-10-11 13:01:38,791 [INFO] Process 6 - epoch 99: mean_policy_losses: -172.188, mean_net_lifetime: 3356.6493, mean_mc_travel_dist: 1000.2609, mean_entropies: 0.4479, m_net_lifetime_valid: 4127.9851, took: 1509.7519s, (104.3258 / 100 batches)

2022-10-11 13:02:08,225 [INFO] 	Process 3 - batch 111699: mean_policy_losses: -56.900, mean_net_lifetime: 5387.8716, mean_mc_travel_dist: 1345.5905, mean_rewards: 276.4201, total_rewards: 4073.2076, mean_steps: 18.5600, mean_ecr: 0.0451 mean_entropies: 0.4465, took: 94.0495s
2022-10-11 13:02:29,710 [INFO] 	Process 1 - batch 92399: mean_policy_losses: 11.250, mean_net_lifetime: 6742.2615, mean_mc_travel_dist: 2026.1424, mean_rewards: 241.7571, total_rewards: 4740.4764, mean_steps: 27.1000, mean_ecr: 0.0382 mean_entropies: 0.9082, took: 131.9924s
2022-10-11 13:02:30,666 [INFO] 	Process 7 - batch 101199: mean_policy_losses: -278.545, mean_net_lifetime: 5371.5601, mean_mc_travel_dist: 1559.4389, mean_rewards: 200.4098, total_rewards: 3840.2603, mean_steps: 26.0400, mean_ecr: 0.0406 mean_entropies: 1.2181, took: 122.9850s
2022-10-11 13:02:35,867 [INFO] 	Process 6 - batch 148599: mean_policy_losses: -98.115, mean_net_lifetime: 3843.5921, mean_mc_travel_dist: 1021.2968, mean_rewards: 344.4319, total_rewards: 2853.4408, mean_steps: 10.1300, mean_ecr: 0.0551 mean_entropies: 0.1422, took: 732.4317s
2022-10-11 13:02:39,786 [INFO] 	Process 4 - batch 101299: mean_policy_losses: 99.506, mean_net_lifetime: 12987.3399, mean_mc_travel_dist: 4018.3767, mean_rewards: 260.7168, total_rewards: 8991.9157, mean_steps: 54.0600, mean_ecr: 0.0365 mean_entropies: 0.4861, took: 242.0483s
2022-10-11 13:03:24,708 [INFO] 	Process 5 - batch 91299: mean_policy_losses: -111.049, mean_net_lifetime: 10982.2170, mean_mc_travel_dist: 3345.3199, mean_rewards: 256.8127, total_rewards: 7671.8120, mean_steps: 43.4700, mean_ecr: 0.0294 mean_entropies: 0.6525, took: 201.7758s
2022-10-11 13:03:32,248 [INFO] 	Process 6 - batch 148699: mean_policy_losses: -94.575, mean_net_lifetime: 3916.8789, mean_mc_travel_dist: 1035.2715, mean_rewards: 344.6430, total_rewards: 2905.2856, mean_steps: 10.3200, mean_ecr: 0.0551 mean_entropies: 0.1215, took: 56.3808s
2022-10-11 13:03:42,911 [INFO] 	Process 3 - batch 111799: mean_policy_losses: -38.920, mean_net_lifetime: 5402.9915, mean_mc_travel_dist: 1402.3213, mean_rewards: 280.0064, total_rewards: 4036.4110, mean_steps: 18.3500, mean_ecr: 0.0447 mean_entropies: 0.4608, took: 94.6860s
2022-10-11 13:04:27,577 [INFO] 	Process 7 - batch 101299: mean_policy_losses: -303.416, mean_net_lifetime: 4916.0814, mean_mc_travel_dist: 1437.2144, mean_rewards: 200.7337, total_rewards: 3506.2805, mean_steps: 23.7700, mean_ecr: 0.0410 mean_entropies: 1.2402, took: 116.9112s
2022-10-11 13:04:34,013 [INFO] 	Process 6 - batch 148799: mean_policy_losses: -41.018, mean_net_lifetime: 4259.4913, mean_mc_travel_dist: 1121.3928, mean_rewards: 347.0401, total_rewards: 3153.5700, mean_steps: 11.2500, mean_ecr: 0.0549 mean_entropies: 0.0955, took: 61.7648s
2022-10-11 13:04:39,094 [INFO] 	Process 1 - batch 92499: mean_policy_losses: -32.622, mean_net_lifetime: 6603.1920, mean_mc_travel_dist: 2024.1324, mean_rewards: 241.6462, total_rewards: 4602.4247, mean_steps: 26.5000, mean_ecr: 0.0383 mean_entropies: 0.8625, took: 129.3841s
2022-10-11 13:05:19,080 [INFO] 	Process 3 - batch 111899: mean_policy_losses: -58.618, mean_net_lifetime: 5293.2138, mean_mc_travel_dist: 1372.0790, mean_rewards: 272.4770, total_rewards: 3945.4057, mean_steps: 18.5400, mean_ecr: 0.0448 mean_entropies: 0.4615, took: 96.1695s
2022-10-11 13:05:31,388 [INFO] 	Process 6 - batch 148899: mean_policy_losses: -97.085, mean_net_lifetime: 3902.0253, mean_mc_travel_dist: 1023.0463, mean_rewards: 342.8049, total_rewards: 2901.1815, mean_steps: 10.3300, mean_ecr: 0.0553 mean_entropies: 0.1589, took: 57.3757s
2022-10-11 13:06:22,704 [INFO] 	Process 5 - batch 91399: mean_policy_losses: -86.857, mean_net_lifetime: 9569.4074, mean_mc_travel_dist: 2870.9806, mean_rewards: 259.1472, total_rewards: 6745.0042, mean_steps: 36.6400, mean_ecr: 0.0301 mean_entropies: 0.6424, took: 177.9956s
2022-10-11 13:06:29,657 [INFO] 	Process 7 - batch 101399: mean_policy_losses: -238.319, mean_net_lifetime: 5285.3023, mean_mc_travel_dist: 1541.2021, mean_rewards: 203.8366, total_rewards: 3779.4941, mean_steps: 25.3800, mean_ecr: 0.0408 mean_entropies: 1.2421, took: 122.0795s
2022-10-11 13:06:30,866 [INFO] 	Process 6 - batch 148999: mean_policy_losses: -61.073, mean_net_lifetime: 4062.6817, mean_mc_travel_dist: 1073.0808, mean_rewards: 342.1879, total_rewards: 3011.2862, mean_steps: 10.8100, mean_ecr: 0.0552 mean_entropies: 0.1240, took: 59.4779s
2022-10-11 13:06:52,710 [INFO] 	Process 1 - batch 92599: mean_policy_losses: -21.431, mean_net_lifetime: 6558.5683, mean_mc_travel_dist: 2015.8069, mean_rewards: 232.8725, total_rewards: 4562.2644, mean_steps: 27.5600, mean_ecr: 0.0382 mean_entropies: 0.8775, took: 133.6161s
2022-10-11 13:06:56,063 [INFO] 	Process 3 - batch 111999: mean_policy_losses: -26.719, mean_net_lifetime: 5459.8502, mean_mc_travel_dist: 1393.0702, mean_rewards: 276.4225, total_rewards: 4082.6354, mean_steps: 18.8800, mean_ecr: 0.0447 mean_entropies: 0.4657, took: 96.9828s
2022-10-11 13:07:26,780 [INFO] 	Process 6 - batch 149099: mean_policy_losses: -84.628, mean_net_lifetime: 3865.0505, mean_mc_travel_dist: 1015.4995, mean_rewards: 343.0322, total_rewards: 2871.4462, mean_steps: 10.2400, mean_ecr: 0.0551 mean_entropies: 0.1364, took: 55.9144s
2022-10-11 13:07:49,441 [INFO] 	Process 4 - batch 101399: mean_policy_losses: 148.595, mean_net_lifetime: 15575.4056, mean_mc_travel_dist: 5028.5570, mean_rewards: 250.9178, total_rewards: 10575.5609, mean_steps: 67.5400, mean_ecr: 0.0353 mean_entropies: 0.5053, took: 309.6547s
2022-10-11 13:08:13,647 [INFO] 	Process 7 - batch 101499: mean_policy_losses: -401.332, mean_net_lifetime: 4664.0769, mean_mc_travel_dist: 1384.2337, mean_rewards: 214.3598, total_rewards: 3321.9881, mean_steps: 20.9700, mean_ecr: 0.0414 mean_entropies: 1.2896, took: 103.9905s
2022-10-11 13:08:26,414 [INFO] 	Process 6 - batch 149199: mean_policy_losses: -75.777, mean_net_lifetime: 4005.5956, mean_mc_travel_dist: 1072.0411, mean_rewards: 340.0381, total_rewards: 2954.7859, mean_steps: 10.7200, mean_ecr: 0.0551 mean_entropies: 0.1304, took: 59.6332s
2022-10-11 13:08:35,141 [INFO] 	Process 3 - batch 112099: mean_policy_losses: -23.034, mean_net_lifetime: 5565.3844, mean_mc_travel_dist: 1413.8452, mean_rewards: 278.1593, total_rewards: 4182.0139, mean_steps: 19.0600, mean_ecr: 0.0446 mean_entropies: 0.4510, took: 99.0785s
2022-10-11 13:08:58,368 [INFO] 	Process 1 - batch 92699: mean_policy_losses: 14.299, mean_net_lifetime: 6565.9617, mean_mc_travel_dist: 1970.2053, mean_rewards: 249.3949, total_rewards: 4617.9338, mean_steps: 25.4600, mean_ecr: 0.0385 mean_entropies: 0.9425, took: 125.6574s
2022-10-11 13:09:23,166 [INFO] 	Process 6 - batch 149299: mean_policy_losses: -62.625, mean_net_lifetime: 3953.1109, mean_mc_travel_dist: 1052.4065, mean_rewards: 341.6394, total_rewards: 2922.0095, mean_steps: 10.5500, mean_ecr: 0.0552 mean_entropies: 0.1348, took: 56.7521s
2022-10-11 13:09:28,974 [INFO] 	Process 5 - batch 91499: mean_policy_losses: -82.227, mean_net_lifetime: 10005.3677, mean_mc_travel_dist: 3003.8461, mean_rewards: 255.0912, total_rewards: 7037.4948, mean_steps: 39.0900, mean_ecr: 0.0296 mean_entropies: 0.6432, took: 186.2694s
2022-10-11 13:10:00,824 [INFO] 	Process 7 - batch 101599: mean_policy_losses: -351.471, mean_net_lifetime: 4696.3538, mean_mc_travel_dist: 1427.6336, mean_rewards: 203.8618, total_rewards: 3299.6836, mean_steps: 22.1200, mean_ecr: 0.0412 mean_entropies: 1.2894, took: 107.1772s
2022-10-11 13:10:09,609 [INFO] 	Process 3 - batch 112199: mean_policy_losses: -37.726, mean_net_lifetime: 5446.5725, mean_mc_travel_dist: 1383.0833, mean_rewards: 277.1891, total_rewards: 4089.2828, mean_steps: 18.7600, mean_ecr: 0.0449 mean_entropies: 0.4646, took: 94.4674s
2022-10-11 13:10:12,257 [INFO] Process 2 - epoch 66: mean_policy_losses: -1.939, mean_net_lifetime: 5571.8625, mean_mc_travel_dist: 1725.8573, mean_entropies: 0.7786, m_net_lifetime_valid: 4444.8420, took: 2539.8182s, (156.9177 / 100 batches)

2022-10-11 13:10:17,488 [INFO] 	Process 6 - batch 149399: mean_policy_losses: -83.000, mean_net_lifetime: 3855.1793, mean_mc_travel_dist: 1022.4840, mean_rewards: 341.4543, total_rewards: 2857.5446, mean_steps: 10.2500, mean_ecr: 0.0553 mean_entropies: 0.1479, took: 54.3215s
2022-10-11 13:11:10,007 [INFO] 	Process 1 - batch 92799: mean_policy_losses: 62.853, mean_net_lifetime: 6893.9557, mean_mc_travel_dist: 2094.4846, mean_rewards: 251.0495, total_rewards: 4819.9569, mean_steps: 26.5600, mean_ecr: 0.0381 mean_entropies: 0.9109, took: 131.6388s
2022-10-11 13:11:16,572 [INFO] 	Process 6 - batch 149499: mean_policy_losses: -65.038, mean_net_lifetime: 4073.0112, mean_mc_travel_dist: 1071.5340, mean_rewards: 344.4983, total_rewards: 3021.3239, mean_steps: 10.7800, mean_ecr: 0.0551 mean_entropies: 0.1180, took: 59.0850s
2022-10-11 13:11:45,761 [INFO] 	Process 3 - batch 112299: mean_policy_losses: -39.916, mean_net_lifetime: 5403.9952, mean_mc_travel_dist: 1371.5449, mean_rewards: 277.4015, total_rewards: 4061.4844, mean_steps: 18.5600, mean_ecr: 0.0450 mean_entropies: 0.4559, took: 96.1526s
2022-10-11 13:11:53,114 [INFO] 	Process 7 - batch 101699: mean_policy_losses: -314.226, mean_net_lifetime: 4917.9207, mean_mc_travel_dist: 1472.5883, mean_rewards: 207.1481, total_rewards: 3482.7772, mean_steps: 22.9900, mean_ecr: 0.0410 mean_entropies: 1.2686, took: 112.2897s
2022-10-11 13:12:12,493 [INFO] 	Process 2 - batch 99099: mean_policy_losses: -46.909, mean_net_lifetime: 7175.1907, mean_mc_travel_dist: 1886.9896, mean_rewards: 287.0404, total_rewards: 5310.5322, mean_steps: 24.1200, mean_ecr: 0.0388 mean_entropies: 0.3533, took: 832.3340s
2022-10-11 13:12:13,572 [INFO] 	Process 6 - batch 149599: mean_policy_losses: -97.703, mean_net_lifetime: 3935.7212, mean_mc_travel_dist: 1032.0467, mean_rewards: 345.0719, total_rewards: 2921.0537, mean_steps: 10.3800, mean_ecr: 0.0550 mean_entropies: 0.1437, took: 56.9992s
2022-10-11 13:12:33,421 [INFO] 	Process 4 - batch 101499: mean_policy_losses: 141.841, mean_net_lifetime: 14550.3060, mean_mc_travel_dist: 4654.0250, mean_rewards: 260.8279, total_rewards: 9919.9756, mean_steps: 62.2800, mean_ecr: 0.0367 mean_entropies: 0.4846, took: 283.9803s
2022-10-11 13:13:12,619 [INFO] 	Process 6 - batch 149699: mean_policy_losses: -66.983, mean_net_lifetime: 4137.6902, mean_mc_travel_dist: 1087.9090, mean_rewards: 344.4970, total_rewards: 3065.8612, mean_steps: 10.9500, mean_ecr: 0.0550 mean_entropies: 0.1170, took: 59.0477s
2022-10-11 13:13:18,938 [INFO] 	Process 1 - batch 92899: mean_policy_losses: 17.606, mean_net_lifetime: 6868.9083, mean_mc_travel_dist: 2065.5691, mean_rewards: 246.6070, total_rewards: 4827.8240, mean_steps: 26.9900, mean_ecr: 0.0383 mean_entropies: 0.9520, took: 128.9315s
2022-10-11 13:13:25,529 [INFO] 	Process 3 - batch 112399: mean_policy_losses: -40.022, mean_net_lifetime: 5542.4804, mean_mc_travel_dist: 1416.4765, mean_rewards: 274.5586, total_rewards: 4152.2812, mean_steps: 19.2400, mean_ecr: 0.0445 mean_entropies: 0.4487, took: 99.7675s
2022-10-11 13:13:43,672 [INFO] 	Process 7 - batch 101799: mean_policy_losses: -377.071, mean_net_lifetime: 4813.6030, mean_mc_travel_dist: 1477.6148, mean_rewards: 204.7984, total_rewards: 3361.2423, mean_steps: 22.5200, mean_ecr: 0.0413 mean_entropies: 1.2828, took: 110.5569s
2022-10-11 13:14:11,126 [INFO] 	Process 6 - batch 149799: mean_policy_losses: -63.124, mean_net_lifetime: 4078.7356, mean_mc_travel_dist: 1080.2293, mean_rewards: 345.3210, total_rewards: 3018.7940, mean_steps: 10.7900, mean_ecr: 0.0551 mean_entropies: 0.1317, took: 58.5069s
2022-10-11 13:14:22,107 [INFO] 	Process 2 - batch 99199: mean_policy_losses: -25.041, mean_net_lifetime: 7572.4246, mean_mc_travel_dist: 1977.7327, mean_rewards: 283.3102, total_rewards: 5613.9846, mean_steps: 25.8600, mean_ecr: 0.0383 mean_entropies: 0.3403, took: 129.6119s
2022-10-11 13:15:03,402 [INFO] 	Process 3 - batch 112499: mean_policy_losses: -60.127, mean_net_lifetime: 5345.7317, mean_mc_travel_dist: 1355.9024, mean_rewards: 269.9341, total_rewards: 4018.2405, mean_steps: 18.9600, mean_ecr: 0.0451 mean_entropies: 0.4515, took: 97.8719s
2022-10-11 13:15:09,228 [INFO] 	Process 6 - batch 149899: mean_policy_losses: -75.204, mean_net_lifetime: 4121.2259, mean_mc_travel_dist: 1088.8308, mean_rewards: 342.9265, total_rewards: 3052.7558, mean_steps: 10.9700, mean_ecr: 0.0550 mean_entropies: 0.1344, took: 58.1026s
2022-10-11 13:15:16,031 [INFO] 	Process 7 - batch 101899: mean_policy_losses: -487.174, mean_net_lifetime: 4188.6033, mean_mc_travel_dist: 1296.0023, mean_rewards: 218.0752, total_rewards: 2932.7758, mean_steps: 18.2900, mean_ecr: 0.0418 mean_entropies: 1.2841, took: 92.3596s
2022-10-11 13:15:25,064 [INFO] 	Process 1 - batch 92999: mean_policy_losses: 25.487, mean_net_lifetime: 6751.8773, mean_mc_travel_dist: 2006.1915, mean_rewards: 247.1339, total_rewards: 4765.0492, mean_steps: 26.4300, mean_ecr: 0.0383 mean_entropies: 0.9640, took: 126.1262s
2022-10-11 13:16:07,109 [INFO] 	Process 6 - batch 149999: mean_policy_losses: -98.077, mean_net_lifetime: 4199.5088, mean_mc_travel_dist: 1103.2427, mean_rewards: 344.2834, total_rewards: 3111.1767, mean_steps: 11.1300, mean_ecr: 0.0549 mean_entropies: 0.1177, took: 57.8790s
2022-10-11 13:16:24,973 [INFO] 	Process 2 - batch 99299: mean_policy_losses: -33.684, mean_net_lifetime: 7548.0199, mean_mc_travel_dist: 1988.3323, mean_rewards: 279.6278, total_rewards: 5581.3673, mean_steps: 26.1000, mean_ecr: 0.0383 mean_entropies: 0.3554, took: 122.8682s
2022-10-11 13:16:58,226 [INFO] 	Process 7 - batch 101999: mean_policy_losses: -276.625, mean_net_lifetime: 4878.5379, mean_mc_travel_dist: 1491.6055, mean_rewards: 207.1214, total_rewards: 3427.3066, mean_steps: 22.9400, mean_ecr: 0.0413 mean_entropies: 1.2284, took: 102.1945s
2022-10-11 13:17:41,501 [INFO] 	Process 4 - batch 101599: mean_policy_losses: 142.406, mean_net_lifetime: 16361.8825, mean_mc_travel_dist: 5308.0679, mean_rewards: 250.0871, total_rewards: 11078.3100, mean_steps: 72.0300, mean_ecr: 0.0349 mean_entropies: 0.5014, took: 308.0802s
2022-10-11 13:18:06,899 [INFO] 	Process 2 - batch 99399: mean_policy_losses: -76.440, mean_net_lifetime: 6944.2911, mean_mc_travel_dist: 1834.5161, mean_rewards: 282.5734, total_rewards: 5136.1817, mean_steps: 23.6700, mean_ecr: 0.0389 mean_entropies: 0.3550, took: 101.9258s
2022-10-11 13:19:52,607 [INFO] 	Process 2 - batch 99499: mean_policy_losses: -49.465, mean_net_lifetime: 7302.9627, mean_mc_travel_dist: 1926.9491, mean_rewards: 288.4196, total_rewards: 5400.1474, mean_steps: 24.4900, mean_ecr: 0.0386 mean_entropies: 0.3707, took: 105.7076s
2022-10-11 13:20:13,078 [INFO] Process 5 - epoch 61: mean_policy_losses: -184.320, mean_net_lifetime: 6208.6235, mean_mc_travel_dist: 2242.9154, mean_entropies: 1.0535, m_net_lifetime_valid: 4670.1062, took: 3487.3456s, (170.4958 / 100 batches)

2022-10-11 13:21:49,110 [INFO] 	Process 2 - batch 99599: mean_policy_losses: -32.787, mean_net_lifetime: 7615.5122, mean_mc_travel_dist: 2000.9901, mean_rewards: 287.9848, total_rewards: 5635.0165, mean_steps: 25.5300, mean_ecr: 0.0383 mean_entropies: 0.3539, took: 116.5028s
2022-10-11 13:22:04,988 [INFO] 	Process 4 - batch 101699: mean_policy_losses: 44.910, mean_net_lifetime: 14956.2469, mean_mc_travel_dist: 4812.3262, mean_rewards: 252.9034, total_rewards: 10172.6204, mean_steps: 66.0700, mean_ecr: 0.0368 mean_entropies: 0.4975, took: 263.4870s
2022-10-11 13:23:12,326 [INFO] 	Process 5 - batch 91599: mean_policy_losses: -79.048, mean_net_lifetime: 10798.6588, mean_mc_travel_dist: 3240.4448, mean_rewards: 259.8334, total_rewards: 7600.2186, mean_steps: 41.5300, mean_ecr: 0.0295 mean_entropies: 0.6146, took: 823.3527s
2022-10-11 13:23:44,675 [INFO] 	Process 2 - batch 99699: mean_policy_losses: -33.519, mean_net_lifetime: 7511.9548, mean_mc_travel_dist: 1980.3439, mean_rewards: 287.9502, total_rewards: 5552.2220, mean_steps: 25.1900, mean_ecr: 0.0384 mean_entropies: 0.3507, took: 115.5657s
2022-10-11 13:25:33,147 [INFO] Process 1 - epoch 62: mean_policy_losses: 9.532, mean_net_lifetime: 5578.6168, mean_mc_travel_dist: 2041.8687, mean_entropies: 1.1105, m_net_lifetime_valid: 4463.8248, took: 2549.3999s, (168.1313 / 100 batches)

2022-10-11 13:25:38,750 [INFO] 	Process 2 - batch 99799: mean_policy_losses: -32.725, mean_net_lifetime: 7611.2942, mean_mc_travel_dist: 1993.3920, mean_rewards: 285.0866, total_rewards: 5632.6423, mean_steps: 25.7800, mean_ecr: 0.0383 mean_entropies: 0.3482, took: 114.0745s
2022-10-11 13:26:15,222 [INFO] Process 6 - epoch 100: mean_policy_losses: -171.242, mean_net_lifetime: 3363.2225, mean_mc_travel_dist: 1000.8585, mean_entropies: 0.4447, m_net_lifetime_valid: 4208.4186, took: 1476.4272s, (104.3117 / 100 batches)

2022-10-11 13:26:26,180 [INFO] Process 3 - epoch 75: mean_policy_losses: 34.604, mean_net_lifetime: 4606.9625, mean_mc_travel_dist: 1344.6323, mean_entropies: 0.7520, m_net_lifetime_valid: 4471.0901, took: 2122.5458s, (138.9946 / 100 batches)

2022-10-11 13:26:27,997 [INFO] 	Process 4 - batch 101799: mean_policy_losses: 47.720, mean_net_lifetime: 14338.1969, mean_mc_travel_dist: 4600.5004, mean_rewards: 246.9815, total_rewards: 9761.2699, mean_steps: 63.9600, mean_ecr: 0.0356 mean_entropies: 0.4874, took: 263.0086s
2022-10-11 13:26:48,384 [INFO] 	Process 5 - batch 91699: mean_policy_losses: -42.126, mean_net_lifetime: 12643.3238, mean_mc_travel_dist: 3893.5363, mean_rewards: 256.8577, total_rewards: 8787.3291, mean_steps: 49.9300, mean_ecr: 0.0288 mean_entropies: 0.6244, took: 216.0577s
2022-10-11 13:27:12,206 [INFO] 	Process 6 - batch 150099: mean_policy_losses: -90.895, mean_net_lifetime: 3872.2870, mean_mc_travel_dist: 1025.6573, mean_rewards: 339.6060, total_rewards: 2872.6036, mean_steps: 10.3400, mean_ecr: 0.0552 mean_entropies: 0.1714, took: 665.0978s
2022-10-11 13:27:37,802 [INFO] 	Process 1 - batch 93099: mean_policy_losses: 13.935, mean_net_lifetime: 6688.0605, mean_mc_travel_dist: 1996.4297, mean_rewards: 248.3988, total_rewards: 4713.7345, mean_steps: 26.0700, mean_ecr: 0.0384 mean_entropies: 0.9805, took: 732.7385s
2022-10-11 13:27:43,024 [INFO] 	Process 2 - batch 99899: mean_policy_losses: -31.984, mean_net_lifetime: 7565.4898, mean_mc_travel_dist: 2000.3797, mean_rewards: 282.6551, total_rewards: 5588.5776, mean_steps: 25.8200, mean_ecr: 0.0382 mean_entropies: 0.3720, took: 124.2735s
2022-10-11 13:28:03,080 [INFO] 	Process 3 - batch 112599: mean_policy_losses: -51.310, mean_net_lifetime: 5401.5606, mean_mc_travel_dist: 1383.2707, mean_rewards: 280.9728, total_rewards: 4051.6972, mean_steps: 18.2800, mean_ecr: 0.0449 mean_entropies: 0.4540, took: 779.6792s
2022-10-11 13:28:03,092 [INFO] Process 7 - epoch 68: mean_policy_losses: -361.951, mean_net_lifetime: 4408.0118, mean_mc_travel_dist: 1550.0946, mean_entropies: 1.4878, m_net_lifetime_valid: 4384.6246, took: 2395.8900s, (153.4019 / 100 batches)

2022-10-11 13:28:09,184 [INFO] 	Process 6 - batch 150199: mean_policy_losses: -102.724, mean_net_lifetime: 3774.1667, mean_mc_travel_dist: 1003.8703, mean_rewards: 339.8349, total_rewards: 2813.3077, mean_steps: 10.0700, mean_ecr: 0.0550 mean_entropies: 0.1767, took: 56.9784s
2022-10-11 13:29:06,151 [INFO] 	Process 6 - batch 150299: mean_policy_losses: -151.352, mean_net_lifetime: 3673.2999, mean_mc_travel_dist: 977.2449, mean_rewards: 340.5516, total_rewards: 2738.9195, mean_steps: 9.7000, mean_ecr: 0.0552 mean_entropies: 0.1740, took: 56.9665s
2022-10-11 13:29:42,782 [INFO] 	Process 3 - batch 112699: mean_policy_losses: -43.697, mean_net_lifetime: 5422.5404, mean_mc_travel_dist: 1368.0063, mean_rewards: 277.3981, total_rewards: 4082.0114, mean_steps: 18.6200, mean_ecr: 0.0449 mean_entropies: 0.4457, took: 99.7022s
2022-10-11 13:29:45,108 [INFO] 	Process 1 - batch 93199: mean_policy_losses: -38.244, mean_net_lifetime: 6551.2419, mean_mc_travel_dist: 2014.1481, mean_rewards: 243.6482, total_rewards: 4562.8775, mean_steps: 25.9700, mean_ecr: 0.0382 mean_entropies: 0.9132, took: 127.3055s
2022-10-11 13:29:52,060 [INFO] 	Process 2 - batch 99999: mean_policy_losses: -22.186, mean_net_lifetime: 7467.0888, mean_mc_travel_dist: 1937.3182, mean_rewards: 285.2886, total_rewards: 5556.0582, mean_steps: 25.2400, mean_ecr: 0.0384 mean_entropies: 0.3492, took: 129.0367s
2022-10-11 13:30:08,027 [INFO] 	Process 6 - batch 150399: mean_policy_losses: -84.500, mean_net_lifetime: 4055.8553, mean_mc_travel_dist: 1079.1635, mean_rewards: 343.1873, total_rewards: 3014.9397, mean_steps: 10.7700, mean_ecr: 0.0550 mean_entropies: 0.1358, took: 61.8763s
2022-10-11 13:30:11,727 [INFO] 	Process 7 - batch 102099: mean_policy_losses: -235.687, mean_net_lifetime: 5281.0534, mean_mc_travel_dist: 1611.0105, mean_rewards: 201.4950, total_rewards: 3698.4829, mean_steps: 25.5400, mean_ecr: 0.0405 mean_entropies: 1.2066, took: 793.5016s
2022-10-11 13:30:37,638 [INFO] 	Process 5 - batch 91799: mean_policy_losses: -57.155, mean_net_lifetime: 11604.5043, mean_mc_travel_dist: 3602.6861, mean_rewards: 249.6950, total_rewards: 8045.6892, mean_steps: 47.5100, mean_ecr: 0.0288 mean_entropies: 0.6106, took: 229.2532s
2022-10-11 13:31:08,784 [INFO] 	Process 6 - batch 150499: mean_policy_losses: -116.260, mean_net_lifetime: 4096.1016, mean_mc_travel_dist: 1086.3352, mean_rewards: 343.7391, total_rewards: 3029.2884, mean_steps: 10.8500, mean_ecr: 0.0550 mean_entropies: 0.1149, took: 60.7570s
2022-10-11 13:31:20,298 [INFO] 	Process 3 - batch 112799: mean_policy_losses: -15.561, mean_net_lifetime: 5488.2410, mean_mc_travel_dist: 1358.4608, mean_rewards: 284.2521, total_rewards: 4145.8666, mean_steps: 18.3600, mean_ecr: 0.0454 mean_entropies: 0.4662, took: 97.5159s
2022-10-11 13:31:51,256 [INFO] 	Process 1 - batch 93299: mean_policy_losses: -50.656, mean_net_lifetime: 6401.0301, mean_mc_travel_dist: 2006.8336, mean_rewards: 248.6558, total_rewards: 4419.3970, mean_steps: 24.9900, mean_ecr: 0.0383 mean_entropies: 0.9077, took: 126.1474s
2022-10-11 13:31:56,452 [INFO] 	Process 4 - batch 101899: mean_policy_losses: 89.658, mean_net_lifetime: 16359.9827, mean_mc_travel_dist: 5351.3579, mean_rewards: 270.1757, total_rewards: 11037.9994, mean_steps: 70.5100, mean_ecr: 0.0389 mean_entropies: 0.4774, took: 328.4548s
2022-10-11 13:32:04,820 [INFO] 	Process 2 - batch 100099: mean_policy_losses: -4.526, mean_net_lifetime: 7627.8961, mean_mc_travel_dist: 1988.0826, mean_rewards: 286.5529, total_rewards: 5660.9889, mean_steps: 25.7000, mean_ecr: 0.0382 mean_entropies: 0.3650, took: 132.7591s
2022-10-11 13:32:08,973 [INFO] 	Process 6 - batch 150599: mean_policy_losses: -66.359, mean_net_lifetime: 4016.7507, mean_mc_travel_dist: 1056.7692, mean_rewards: 345.7547, total_rewards: 2982.2283, mean_steps: 10.5800, mean_ecr: 0.0548 mean_entropies: 0.1363, took: 60.1889s
2022-10-11 13:32:17,690 [INFO] 	Process 7 - batch 102199: mean_policy_losses: -253.717, mean_net_lifetime: 5156.2670, mean_mc_travel_dist: 1527.9193, mean_rewards: 198.5685, total_rewards: 3668.5258, mean_steps: 25.2700, mean_ecr: 0.0408 mean_entropies: 1.2108, took: 125.9627s
2022-10-11 13:32:59,405 [INFO] 	Process 3 - batch 112899: mean_policy_losses: -46.910, mean_net_lifetime: 5476.0656, mean_mc_travel_dist: 1362.6467, mean_rewards: 278.9651, total_rewards: 4142.0073, mean_steps: 18.7000, mean_ecr: 0.0451 mean_entropies: 0.4529, took: 99.1065s
2022-10-11 13:33:08,119 [INFO] 	Process 6 - batch 150699: mean_policy_losses: -81.794, mean_net_lifetime: 3952.8725, mean_mc_travel_dist: 1045.7600, mean_rewards: 342.4325, total_rewards: 2934.1822, mean_steps: 10.4900, mean_ecr: 0.0552 mean_entropies: 0.1502, took: 59.1460s
2022-10-11 13:34:00,832 [INFO] 	Process 1 - batch 93399: mean_policy_losses: -42.839, mean_net_lifetime: 6615.1820, mean_mc_travel_dist: 2033.2138, mean_rewards: 245.4730, total_rewards: 4605.9746, mean_steps: 26.0700, mean_ecr: 0.0382 mean_entropies: 0.9113, took: 129.5764s
2022-10-11 13:34:02,491 [INFO] 	Process 5 - batch 91899: mean_policy_losses: -117.244, mean_net_lifetime: 10435.7263, mean_mc_travel_dist: 3194.2408, mean_rewards: 258.3177, total_rewards: 7285.4099, mean_steps: 41.4400, mean_ecr: 0.0293 mean_entropies: 0.6255, took: 204.8540s
2022-10-11 13:34:09,534 [INFO] 	Process 6 - batch 150799: mean_policy_losses: -50.574, mean_net_lifetime: 4154.7956, mean_mc_travel_dist: 1102.1151, mean_rewards: 343.4821, total_rewards: 3067.5954, mean_steps: 11.0600, mean_ecr: 0.0551 mean_entropies: 0.1310, took: 61.4156s
2022-10-11 13:34:16,186 [INFO] 	Process 2 - batch 100199: mean_policy_losses: -5.539, mean_net_lifetime: 7666.2715, mean_mc_travel_dist: 2002.1451, mean_rewards: 288.0413, total_rewards: 5689.3381, mean_steps: 25.7000, mean_ecr: 0.0383 mean_entropies: 0.3565, took: 131.3659s
2022-10-11 13:34:26,475 [INFO] 	Process 7 - batch 102299: mean_policy_losses: -252.073, mean_net_lifetime: 5224.6321, mean_mc_travel_dist: 1562.0279, mean_rewards: 194.6616, total_rewards: 3698.3756, mean_steps: 26.0200, mean_ecr: 0.0407 mean_entropies: 1.1764, took: 128.7842s
2022-10-11 13:34:39,627 [INFO] 	Process 3 - batch 112999: mean_policy_losses: -34.915, mean_net_lifetime: 5427.6349, mean_mc_travel_dist: 1334.4253, mean_rewards: 272.0062, total_rewards: 4114.0974, mean_steps: 19.0400, mean_ecr: 0.0452 mean_entropies: 0.4360, took: 100.2226s
2022-10-11 13:35:07,917 [INFO] 	Process 6 - batch 150899: mean_policy_losses: -84.056, mean_net_lifetime: 3864.6551, mean_mc_travel_dist: 1032.9403, mean_rewards: 340.4468, total_rewards: 2859.4010, mean_steps: 10.3000, mean_ecr: 0.0552 mean_entropies: 0.1598, took: 58.3826s
2022-10-11 13:35:29,584 [INFO] 	Process 4 - batch 101999: mean_policy_losses: 122.874, mean_net_lifetime: 11051.6962, mean_mc_travel_dist: 3217.1912, mean_rewards: 267.6014, total_rewards: 7854.5052, mean_steps: 43.4100, mean_ecr: 0.0380 mean_entropies: 0.5054, took: 213.1319s
2022-10-11 13:36:04,291 [INFO] 	Process 6 - batch 150999: mean_policy_losses: -89.053, mean_net_lifetime: 3838.1135, mean_mc_travel_dist: 1020.3106, mean_rewards: 343.7831, total_rewards: 2847.1949, mean_steps: 10.1300, mean_ecr: 0.0552 mean_entropies: 0.1531, took: 56.3741s
2022-10-11 13:36:13,011 [INFO] 	Process 1 - batch 93499: mean_policy_losses: -4.882, mean_net_lifetime: 6625.1303, mean_mc_travel_dist: 2036.9819, mean_rewards: 242.6184, total_rewards: 4614.3229, mean_steps: 26.4800, mean_ecr: 0.0383 mean_entropies: 0.8925, took: 132.1789s
2022-10-11 13:36:17,487 [INFO] 	Process 3 - batch 113099: mean_policy_losses: -29.700, mean_net_lifetime: 5466.4367, mean_mc_travel_dist: 1358.3033, mean_rewards: 273.7976, total_rewards: 4146.0332, mean_steps: 19.0500, mean_ecr: 0.0452 mean_entropies: 0.4451, took: 97.8590s
2022-10-11 13:36:25,215 [INFO] 	Process 2 - batch 100299: mean_policy_losses: -5.405, mean_net_lifetime: 7659.6945, mean_mc_travel_dist: 2004.9360, mean_rewards: 286.4679, total_rewards: 5679.0617, mean_steps: 25.8400, mean_ecr: 0.0382 mean_entropies: 0.3624, took: 129.0298s
2022-10-11 13:36:34,890 [INFO] 	Process 7 - batch 102399: mean_policy_losses: -213.838, mean_net_lifetime: 5207.9887, mean_mc_travel_dist: 1567.8671, mean_rewards: 195.0249, total_rewards: 3682.3909, mean_steps: 26.1100, mean_ecr: 0.0408 mean_entropies: 1.1739, took: 128.4147s
2022-10-11 13:37:01,728 [INFO] 	Process 5 - batch 91999: mean_policy_losses: -79.335, mean_net_lifetime: 9610.0767, mean_mc_travel_dist: 2896.7119, mean_rewards: 258.5181, total_rewards: 6772.5380, mean_steps: 37.1100, mean_ecr: 0.0299 mean_entropies: 0.6118, took: 179.2366s
2022-10-11 13:37:04,783 [INFO] 	Process 6 - batch 151099: mean_policy_losses: -69.228, mean_net_lifetime: 4071.7204, mean_mc_travel_dist: 1083.5477, mean_rewards: 343.3343, total_rewards: 3017.9441, mean_steps: 10.8100, mean_ecr: 0.0549 mean_entropies: 0.1429, took: 60.4925s
2022-10-11 13:37:51,382 [INFO] 	Process 3 - batch 113199: mean_policy_losses: -21.883, mean_net_lifetime: 5500.4289, mean_mc_travel_dist: 1380.5496, mean_rewards: 281.4364, total_rewards: 4146.4913, mean_steps: 18.5900, mean_ecr: 0.0450 mean_entropies: 0.4708, took: 93.8960s
2022-10-11 13:38:01,663 [INFO] 	Process 6 - batch 151199: mean_policy_losses: -81.173, mean_net_lifetime: 3999.8229, mean_mc_travel_dist: 1052.4311, mean_rewards: 343.6675, total_rewards: 2966.0749, mean_steps: 10.5800, mean_ecr: 0.0552 mean_entropies: 0.1265, took: 56.8800s
2022-10-11 13:38:17,982 [INFO] 	Process 1 - batch 93599: mean_policy_losses: -44.235, mean_net_lifetime: 6557.3556, mean_mc_travel_dist: 2014.8881, mean_rewards: 245.8277, total_rewards: 4566.9704, mean_steps: 25.8100, mean_ecr: 0.0383 mean_entropies: 0.9313, took: 124.9715s
2022-10-11 13:38:25,003 [INFO] 	Process 7 - batch 102499: mean_policy_losses: -311.951, mean_net_lifetime: 4816.0199, mean_mc_travel_dist: 1454.7752, mean_rewards: 205.2804, total_rewards: 3402.3727, mean_steps: 22.7700, mean_ecr: 0.0412 mean_entropies: 1.2223, took: 110.1144s
2022-10-11 13:38:33,041 [INFO] 	Process 2 - batch 100399: mean_policy_losses: 2.804, mean_net_lifetime: 7762.9335, mean_mc_travel_dist: 2034.4382, mean_rewards: 291.1955, total_rewards: 5744.0543, mean_steps: 25.7500, mean_ecr: 0.0382 mean_entropies: 0.3699, took: 127.8256s
2022-10-11 13:38:59,191 [INFO] 	Process 6 - batch 151299: mean_policy_losses: -73.851, mean_net_lifetime: 3957.5404, mean_mc_travel_dist: 1047.9290, mean_rewards: 342.6891, total_rewards: 2936.0714, mean_steps: 10.4800, mean_ecr: 0.0551 mean_entropies: 0.1375, took: 57.5278s
2022-10-11 13:39:27,450 [INFO] 	Process 3 - batch 113299: mean_policy_losses: -34.922, mean_net_lifetime: 5488.3642, mean_mc_travel_dist: 1365.3141, mean_rewards: 280.1661, total_rewards: 4149.9362, mean_steps: 18.6400, mean_ecr: 0.0452 mean_entropies: 0.4355, took: 96.0676s
2022-10-11 13:39:57,812 [INFO] 	Process 6 - batch 151399: mean_policy_losses: -103.118, mean_net_lifetime: 4096.3086, mean_mc_travel_dist: 1080.7318, mean_rewards: 345.3420, total_rewards: 3034.1922, mean_steps: 10.8200, mean_ecr: 0.0548 mean_entropies: 0.1247, took: 58.6205s
2022-10-11 13:40:11,492 [INFO] 	Process 7 - batch 102599: mean_policy_losses: -335.171, mean_net_lifetime: 4728.2674, mean_mc_travel_dist: 1416.4579, mean_rewards: 207.0198, total_rewards: 3345.8380, mean_steps: 21.9200, mean_ecr: 0.0414 mean_entropies: 1.2170, took: 106.4892s
2022-10-11 13:40:20,532 [INFO] 	Process 5 - batch 92099: mean_policy_losses: -30.677, mean_net_lifetime: 10876.8232, mean_mc_travel_dist: 3292.1509, mean_rewards: 259.5350, total_rewards: 7631.6270, mean_steps: 42.2200, mean_ecr: 0.0296 mean_entropies: 0.6254, took: 198.8050s
2022-10-11 13:40:24,663 [INFO] 	Process 1 - batch 93699: mean_policy_losses: 19.353, mean_net_lifetime: 6860.3523, mean_mc_travel_dist: 2056.5706, mean_rewards: 250.8440, total_rewards: 4827.5608, mean_steps: 26.5000, mean_ecr: 0.0384 mean_entropies: 0.9640, took: 126.6789s
2022-10-11 13:40:38,089 [INFO] 	Process 2 - batch 100499: mean_policy_losses: -21.484, mean_net_lifetime: 7569.9421, mean_mc_travel_dist: 1973.0002, mean_rewards: 287.6823, total_rewards: 5621.2982, mean_steps: 25.4100, mean_ecr: 0.0384 mean_entropies: 0.3625, took: 125.0483s
2022-10-11 13:40:48,960 [INFO] 	Process 6 - batch 151499: mean_policy_losses: -99.942, mean_net_lifetime: 3544.7716, mean_mc_travel_dist: 963.4580, mean_rewards: 337.3280, total_rewards: 2625.0210, mean_steps: 9.4200, mean_ecr: 0.0558 mean_entropies: 0.1594, took: 51.1480s
2022-10-11 13:41:02,488 [INFO] 	Process 3 - batch 113399: mean_policy_losses: -28.337, mean_net_lifetime: 5393.5906, mean_mc_travel_dist: 1375.6366, mean_rewards: 274.1902, total_rewards: 4038.9638, mean_steps: 18.8200, mean_ecr: 0.0452 mean_entropies: 0.4251, took: 95.0375s
2022-10-11 13:42:04,792 [INFO] 	Process 7 - batch 102699: mean_policy_losses: -160.889, mean_net_lifetime: 5026.0273, mean_mc_travel_dist: 1502.1602, mean_rewards: 198.7795, total_rewards: 3552.6706, mean_steps: 24.7300, mean_ecr: 0.0409 mean_entropies: 1.1359, took: 113.2992s
2022-10-11 13:42:27,543 [INFO] 	Process 1 - batch 93799: mean_policy_losses: 18.901, mean_net_lifetime: 6593.2944, mean_mc_travel_dist: 2016.8365, mean_rewards: 244.3657, total_rewards: 4598.8400, mean_steps: 26.2500, mean_ecr: 0.0382 mean_entropies: 0.8903, took: 122.8813s
2022-10-11 13:42:32,441 [INFO] 	Process 3 - batch 113499: mean_policy_losses: -28.419, mean_net_lifetime: 5433.3393, mean_mc_travel_dist: 1366.1623, mean_rewards: 278.8104, total_rewards: 4097.6281, mean_steps: 18.5700, mean_ecr: 0.0450 mean_entropies: 0.4488, took: 89.9535s
2022-10-11 13:43:14,101 [INFO] 	Process 5 - batch 92199: mean_policy_losses: 4.091, mean_net_lifetime: 10115.3625, mean_mc_travel_dist: 3054.8134, mean_rewards: 259.6971, total_rewards: 7098.8439, mean_steps: 38.8200, mean_ecr: 0.0297 mean_entropies: 0.6162, took: 173.5686s
2022-10-11 13:44:02,341 [INFO] 	Process 3 - batch 113599: mean_policy_losses: -30.863, mean_net_lifetime: 5466.6326, mean_mc_travel_dist: 1387.7368, mean_rewards: 285.9834, total_rewards: 4109.8727, mean_steps: 18.1800, mean_ecr: 0.0451 mean_entropies: 0.4555, took: 89.8995s
2022-10-11 13:44:03,134 [INFO] 	Process 7 - batch 102799: mean_policy_losses: -208.788, mean_net_lifetime: 5161.3293, mean_mc_travel_dist: 1574.2061, mean_rewards: 191.2071, total_rewards: 3615.9027, mean_steps: 26.5600, mean_ecr: 0.0407 mean_entropies: 1.1123, took: 118.3434s
2022-10-11 13:44:25,495 [INFO] 	Process 1 - batch 93899: mean_policy_losses: -34.451, mean_net_lifetime: 6702.7518, mean_mc_travel_dist: 2073.4704, mean_rewards: 248.6757, total_rewards: 4664.6533, mean_steps: 26.1000, mean_ecr: 0.0381 mean_entropies: 0.9264, took: 117.9529s
2022-10-11 13:45:31,641 [INFO] 	Process 3 - batch 113699: mean_policy_losses: -37.183, mean_net_lifetime: 5465.3511, mean_mc_travel_dist: 1399.9201, mean_rewards: 276.7587, total_rewards: 4097.5153, mean_steps: 18.8200, mean_ecr: 0.0446 mean_entropies: 0.4336, took: 89.3002s
2022-10-11 13:46:01,127 [INFO] 	Process 5 - batch 92299: mean_policy_losses: -23.891, mean_net_lifetime: 9934.1045, mean_mc_travel_dist: 2950.0793, mean_rewards: 262.9731, total_rewards: 7020.2402, mean_steps: 37.5100, mean_ecr: 0.0301 mean_entropies: 0.6290, took: 167.0255s
2022-10-11 13:46:07,191 [INFO] 	Process 7 - batch 102899: mean_policy_losses: -141.313, mean_net_lifetime: 5408.6646, mean_mc_travel_dist: 1648.8639, mean_rewards: 190.2408, total_rewards: 3792.7764, mean_steps: 27.9200, mean_ecr: 0.0403 mean_entropies: 1.0928, took: 124.0562s
2022-10-11 13:46:25,009 [INFO] 	Process 1 - batch 93999: mean_policy_losses: -8.644, mean_net_lifetime: 6625.6368, mean_mc_travel_dist: 1994.1596, mean_rewards: 245.1754, total_rewards: 4654.8821, mean_steps: 26.1800, mean_ecr: 0.0384 mean_entropies: 0.9118, took: 119.5144s
2022-10-11 13:46:31,446 [INFO] Process 4 - epoch 68: mean_policy_losses: 110.957, mean_net_lifetime: 5500.3483, mean_mc_travel_dist: 1704.5713, mean_entropies: 0.9859, m_net_lifetime_valid: 4669.8549, took: 4240.9672s, (154.4904 / 100 batches)

2022-10-11 13:47:04,640 [INFO] 	Process 3 - batch 113799: mean_policy_losses: -38.227, mean_net_lifetime: 5532.7618, mean_mc_travel_dist: 1389.8843, mean_rewards: 284.4340, total_rewards: 4170.2930, mean_steps: 18.5200, mean_ecr: 0.0449 mean_entropies: 0.4352, took: 92.9999s
2022-10-11 13:48:02,354 [INFO] 	Process 7 - batch 102999: mean_policy_losses: -249.227, mean_net_lifetime: 5250.8367, mean_mc_travel_dist: 1570.1886, mean_rewards: 203.9685, total_rewards: 3711.4719, mean_steps: 25.1900, mean_ecr: 0.0408 mean_entropies: 1.1857, took: 115.1620s
2022-10-11 13:48:30,285 [INFO] 	Process 1 - batch 94099: mean_policy_losses: -18.780, mean_net_lifetime: 6793.7597, mean_mc_travel_dist: 2029.0337, mean_rewards: 248.6365, total_rewards: 4787.8061, mean_steps: 26.4500, mean_ecr: 0.0383 mean_entropies: 0.9477, took: 125.2751s
2022-10-11 13:48:37,851 [INFO] 	Process 3 - batch 113899: mean_policy_losses: -54.207, mean_net_lifetime: 5561.6885, mean_mc_travel_dist: 1414.8363, mean_rewards: 283.0307, total_rewards: 4176.9191, mean_steps: 18.6900, mean_ecr: 0.0444 mean_entropies: 0.4215, took: 93.2105s
2022-10-11 13:49:16,106 [INFO] 	Process 4 - batch 102099: mean_policy_losses: 113.208, mean_net_lifetime: 9177.0191, mean_mc_travel_dist: 2671.2308, mean_rewards: 267.7936, total_rewards: 6525.2736, mean_steps: 35.7700, mean_ecr: 0.0394 mean_entropies: 0.4743, took: 826.5230s
2022-10-11 13:49:23,175 [INFO] 	Process 5 - batch 92399: mean_policy_losses: -33.842, mean_net_lifetime: 11254.8269, mean_mc_travel_dist: 3351.1027, mean_rewards: 260.9222, total_rewards: 7941.9501, mean_steps: 43.4600, mean_ecr: 0.0297 mean_entropies: 0.6494, took: 202.0489s
2022-10-11 13:50:05,188 [INFO] 	Process 7 - batch 103099: mean_policy_losses: -188.082, mean_net_lifetime: 5433.3155, mean_mc_travel_dist: 1655.5771, mean_rewards: 202.9714, total_rewards: 3816.3526, mean_steps: 26.0300, mean_ecr: 0.0406 mean_entropies: 1.1542, took: 122.8353s
2022-10-11 13:50:10,344 [INFO] 	Process 3 - batch 113999: mean_policy_losses: -45.522, mean_net_lifetime: 5588.8331, mean_mc_travel_dist: 1424.3508, mean_rewards: 280.4547, total_rewards: 4191.2030, mean_steps: 18.9900, mean_ecr: 0.0445 mean_entropies: 0.4227, took: 92.4933s
2022-10-11 13:50:30,476 [INFO] 	Process 1 - batch 94199: mean_policy_losses: -14.929, mean_net_lifetime: 6617.3114, mean_mc_travel_dist: 1951.0722, mean_rewards: 249.0988, total_rewards: 4685.4648, mean_steps: 25.7900, mean_ecr: 0.0386 mean_entropies: 0.9362, took: 120.1912s
2022-10-11 13:51:23,097 [INFO] Process 6 - epoch 101: mean_policy_losses: -170.434, mean_net_lifetime: 3368.8467, mean_mc_travel_dist: 1001.2845, mean_entropies: 0.4418, m_net_lifetime_valid: 4277.5760, took: 1507.8723s, (104.2570 / 100 batches)

2022-10-11 13:51:52,560 [INFO] 	Process 7 - batch 103199: mean_policy_losses: -274.264, mean_net_lifetime: 5056.2526, mean_mc_travel_dist: 1561.3372, mean_rewards: 210.3026, total_rewards: 3533.3797, mean_steps: 23.3500, mean_ecr: 0.0409 mean_entropies: 1.1985, took: 107.3723s
2022-10-11 13:52:11,888 [INFO] Process 2 - epoch 67: mean_policy_losses: -2.327, mean_net_lifetime: 5600.7412, mean_mc_travel_dist: 1729.4809, mean_entropies: 0.7723, m_net_lifetime_valid: 4526.4423, took: 2519.6284s, (157.1008 / 100 batches)

2022-10-11 13:52:15,644 [INFO] 	Process 6 - batch 151599: mean_policy_losses: -117.328, mean_net_lifetime: 3637.1797, mean_mc_travel_dist: 974.9580, mean_rewards: 339.9619, total_rewards: 2706.3950, mean_steps: 9.6600, mean_ecr: 0.0552 mean_entropies: 0.1621, took: 686.6844s
2022-10-11 13:52:36,518 [INFO] 	Process 1 - batch 94299: mean_policy_losses: 56.108, mean_net_lifetime: 6756.3275, mean_mc_travel_dist: 1997.0703, mean_rewards: 248.5089, total_rewards: 4780.4164, mean_steps: 26.2800, mean_ecr: 0.0384 mean_entropies: 0.9310, took: 126.0414s
2022-10-11 13:52:57,629 [INFO] 	Process 4 - batch 102199: mean_policy_losses: 97.684, mean_net_lifetime: 11931.5915, mean_mc_travel_dist: 3710.9102, mean_rewards: 267.1024, total_rewards: 8239.4645, mean_steps: 48.8000, mean_ecr: 0.0374 mean_entropies: 0.4618, took: 221.5220s
2022-10-11 13:53:06,247 [INFO] 	Process 5 - batch 92499: mean_policy_losses: -40.460, mean_net_lifetime: 12131.4883, mean_mc_travel_dist: 3774.1586, mean_rewards: 251.2068, total_rewards: 8400.2166, mean_steps: 48.7300, mean_ecr: 0.0291 mean_entropies: 0.6117, took: 223.0711s
2022-10-11 13:53:13,367 [INFO] 	Process 6 - batch 151699: mean_policy_losses: -95.484, mean_net_lifetime: 3799.5036, mean_mc_travel_dist: 1017.0359, mean_rewards: 341.8270, total_rewards: 2816.9927, mean_steps: 10.0800, mean_ecr: 0.0551 mean_entropies: 0.1508, took: 57.7231s
2022-10-11 13:53:57,833 [INFO] 	Process 7 - batch 103299: mean_policy_losses: -239.716, mean_net_lifetime: 5284.0381, mean_mc_travel_dist: 1624.2498, mean_rewards: 197.9656, total_rewards: 3699.1468, mean_steps: 25.8700, mean_ecr: 0.0406 mean_entropies: 1.1667, took: 125.2725s
2022-10-11 13:54:08,858 [INFO] 	Process 6 - batch 151799: mean_policy_losses: -90.603, mean_net_lifetime: 3707.8090, mean_mc_travel_dist: 998.0159, mean_rewards: 341.3321, total_rewards: 2752.1728, mean_steps: 9.8400, mean_ecr: 0.0551 mean_entropies: 0.1654, took: 55.4900s
2022-10-11 13:54:21,505 [INFO] 	Process 2 - batch 100599: mean_policy_losses: -21.078, mean_net_lifetime: 7608.0873, mean_mc_travel_dist: 1993.9310, mean_rewards: 283.7682, total_rewards: 5641.1579, mean_steps: 25.9100, mean_ecr: 0.0384 mean_entropies: 0.3583, took: 823.4146s
2022-10-11 13:54:46,022 [INFO] 	Process 1 - batch 94399: mean_policy_losses: 53.876, mean_net_lifetime: 6802.0339, mean_mc_travel_dist: 2014.4049, mean_rewards: 247.2247, total_rewards: 4814.4139, mean_steps: 26.6100, mean_ecr: 0.0383 mean_entropies: 0.9563, took: 129.5043s
2022-10-11 13:55:06,589 [INFO] 	Process 6 - batch 151899: mean_policy_losses: -107.433, mean_net_lifetime: 3874.4017, mean_mc_travel_dist: 1033.4644, mean_rewards: 342.7172, total_rewards: 2888.3286, mean_steps: 10.2400, mean_ecr: 0.0550 mean_entropies: 0.1464, took: 57.7314s
2022-10-11 13:56:06,126 [INFO] 	Process 6 - batch 151999: mean_policy_losses: -104.301, mean_net_lifetime: 3997.9557, mean_mc_travel_dist: 1053.4265, mean_rewards: 344.1110, total_rewards: 2977.0398, mean_steps: 10.5800, mean_ecr: 0.0551 mean_entropies: 0.1463, took: 59.5374s
2022-10-11 13:56:13,884 [INFO] 	Process 7 - batch 103399: mean_policy_losses: -131.949, mean_net_lifetime: 5621.7410, mean_mc_travel_dist: 1729.8801, mean_rewards: 193.9885, total_rewards: 3923.8773, mean_steps: 28.4900, mean_ecr: 0.0402 mean_entropies: 1.1626, took: 136.0507s
2022-10-11 13:56:30,049 [INFO] 	Process 2 - batch 100699: mean_policy_losses: -31.274, mean_net_lifetime: 7563.9119, mean_mc_travel_dist: 2012.8221, mean_rewards: 286.9967, total_rewards: 5578.4942, mean_steps: 25.4600, mean_ecr: 0.0383 mean_entropies: 0.3538, took: 128.5449s
2022-10-11 13:56:53,732 [INFO] 	Process 5 - batch 92599: mean_policy_losses: -34.817, mean_net_lifetime: 12057.8901, mean_mc_travel_dist: 3777.1642, mean_rewards: 257.7003, total_rewards: 8318.6488, mean_steps: 47.7100, mean_ecr: 0.0291 mean_entropies: 0.6122, took: 227.4854s
2022-10-11 13:56:58,555 [INFO] 	Process 1 - batch 94499: mean_policy_losses: 49.900, mean_net_lifetime: 6820.7008, mean_mc_travel_dist: 1993.2789, mean_rewards: 243.3829, total_rewards: 4854.2801, mean_steps: 27.1500, mean_ecr: 0.0385 mean_entropies: 0.9623, took: 132.5331s
2022-10-11 13:57:12,118 [INFO] 	Process 6 - batch 152099: mean_policy_losses: -84.816, mean_net_lifetime: 4033.5377, mean_mc_travel_dist: 1176.1155, mean_rewards: 315.0969, total_rewards: 2878.4994, mean_steps: 11.9300, mean_ecr: 0.0551 mean_entropies: 0.1762, took: 65.9915s
2022-10-11 13:57:49,714 [INFO] 	Process 4 - batch 102299: mean_policy_losses: 127.997, mean_net_lifetime: 14489.0357, mean_mc_travel_dist: 4680.0888, mean_rewards: 252.0116, total_rewards: 9835.0557, mean_steps: 63.8100, mean_ecr: 0.0348 mean_entropies: 0.4838, took: 292.0848s
2022-10-11 13:58:11,955 [INFO] 	Process 6 - batch 152199: mean_policy_losses: -88.453, mean_net_lifetime: 4187.2767, mean_mc_travel_dist: 1107.7918, mean_rewards: 346.5178, total_rewards: 3107.3821, mean_steps: 11.0500, mean_ecr: 0.0548 mean_entropies: 0.1149, took: 59.8374s
2022-10-11 13:58:24,431 [INFO] 	Process 7 - batch 103499: mean_policy_losses: -232.079, mean_net_lifetime: 5318.7887, mean_mc_travel_dist: 1617.3075, mean_rewards: 193.0303, total_rewards: 3727.7047, mean_steps: 27.5200, mean_ecr: 0.0405 mean_entropies: 1.2128, took: 130.5480s
2022-10-11 13:58:37,478 [INFO] 	Process 2 - batch 100799: mean_policy_losses: -30.197, mean_net_lifetime: 7600.3619, mean_mc_travel_dist: 2027.4993, mean_rewards: 280.3421, total_rewards: 5594.3721, mean_steps: 26.3500, mean_ecr: 0.0384 mean_entropies: 0.3477, took: 127.4290s
2022-10-11 13:59:08,042 [INFO] 	Process 6 - batch 152299: mean_policy_losses: -101.991, mean_net_lifetime: 3923.5675, mean_mc_travel_dist: 1037.3838, mean_rewards: 344.2958, total_rewards: 2924.6358, mean_steps: 10.3600, mean_ecr: 0.0549 mean_entropies: 0.1450, took: 56.0870s
2022-10-11 14:00:04,757 [INFO] 	Process 6 - batch 152399: mean_policy_losses: -67.233, mean_net_lifetime: 4129.7765, mean_mc_travel_dist: 1095.6637, mean_rewards: 344.8806, total_rewards: 3064.3318, mean_steps: 10.9400, mean_ecr: 0.0551 mean_entropies: 0.1153, took: 56.7149s
2022-10-11 14:00:28,765 [INFO] 	Process 5 - batch 92699: mean_policy_losses: -22.807, mean_net_lifetime: 12265.0675, mean_mc_travel_dist: 3725.0733, mean_rewards: 253.9102, total_rewards: 8574.2143, mean_steps: 48.4400, mean_ecr: 0.0291 mean_entropies: 0.6356, took: 215.0318s
2022-10-11 14:00:32,744 [INFO] 	Process 2 - batch 100899: mean_policy_losses: -38.173, mean_net_lifetime: 7512.0372, mean_mc_travel_dist: 1963.7378, mean_rewards: 286.6517, total_rewards: 5578.0022, mean_steps: 25.3200, mean_ecr: 0.0384 mean_entropies: 0.3485, took: 115.2664s
2022-10-11 14:01:00,957 [INFO] 	Process 6 - batch 152499: mean_policy_losses: -66.331, mean_net_lifetime: 4049.6963, mean_mc_travel_dist: 1078.5258, mean_rewards: 344.9387, total_rewards: 3007.4215, mean_steps: 10.7200, mean_ecr: 0.0549 mean_entropies: 0.1298, took: 56.2006s
2022-10-11 14:01:09,276 [INFO] Process 3 - epoch 76: mean_policy_losses: 33.674, mean_net_lifetime: 4618.3739, mean_mc_travel_dist: 1345.0709, mean_entropies: 0.7479, m_net_lifetime_valid: 4460.5123, took: 2083.0936s, (139.0139 / 100 batches)

2022-10-11 14:02:00,063 [INFO] 	Process 6 - batch 152599: mean_policy_losses: -63.572, mean_net_lifetime: 4102.0546, mean_mc_travel_dist: 1104.3342, mean_rewards: 344.6843, total_rewards: 3036.9459, mean_steps: 10.8900, mean_ecr: 0.0550 mean_entropies: 0.1147, took: 59.1055s
2022-10-11 14:02:32,709 [INFO] 	Process 2 - batch 100999: mean_policy_losses: -18.447, mean_net_lifetime: 7623.9395, mean_mc_travel_dist: 1995.8362, mean_rewards: 290.1354, total_rewards: 5654.9381, mean_steps: 25.3700, mean_ecr: 0.0384 mean_entropies: 0.3458, took: 119.9652s
2022-10-11 14:02:44,582 [INFO] 	Process 3 - batch 114099: mean_policy_losses: -40.286, mean_net_lifetime: 5565.7009, mean_mc_travel_dist: 1405.0815, mean_rewards: 273.2601, total_rewards: 4179.5979, mean_steps: 19.4400, mean_ecr: 0.0443 mean_entropies: 0.4649, took: 754.2374s
2022-10-11 14:03:01,200 [INFO] 	Process 6 - batch 152699: mean_policy_losses: -82.309, mean_net_lifetime: 4146.5313, mean_mc_travel_dist: 1109.4334, mean_rewards: 344.5980, total_rewards: 3080.5958, mean_steps: 11.0000, mean_ecr: 0.0549 mean_entropies: 0.1306, took: 61.1374s
2022-10-11 14:03:18,188 [INFO] 	Process 4 - batch 102399: mean_policy_losses: 91.043, mean_net_lifetime: 17235.8055, mean_mc_travel_dist: 5714.0923, mean_rewards: 250.2897, total_rewards: 11546.7843, mean_steps: 76.9300, mean_ecr: 0.0355 mean_entropies: 0.4937, took: 328.4749s
2022-10-11 14:03:57,687 [INFO] 	Process 6 - batch 152799: mean_policy_losses: -54.695, mean_net_lifetime: 4050.3007, mean_mc_travel_dist: 1098.4185, mean_rewards: 343.3401, total_rewards: 3008.1767, mean_steps: 10.7700, mean_ecr: 0.0547 mean_entropies: 0.1385, took: 56.4868s
2022-10-11 14:04:04,177 [INFO] 	Process 5 - batch 92799: mean_policy_losses: -63.803, mean_net_lifetime: 12024.2584, mean_mc_travel_dist: 3681.3853, mean_rewards: 259.3874, total_rewards: 8384.2476, mean_steps: 47.2300, mean_ecr: 0.0291 mean_entropies: 0.6072, took: 215.4137s
2022-10-11 14:04:16,893 [INFO] 	Process 3 - batch 114199: mean_policy_losses: -39.277, mean_net_lifetime: 5530.7288, mean_mc_travel_dist: 1387.4450, mean_rewards: 279.4390, total_rewards: 4166.7692, mean_steps: 18.8700, mean_ecr: 0.0449 mean_entropies: 0.4788, took: 92.3117s
2022-10-11 14:04:34,570 [INFO] 	Process 2 - batch 101099: mean_policy_losses: -21.680, mean_net_lifetime: 7617.4083, mean_mc_travel_dist: 1986.3296, mean_rewards: 289.0049, total_rewards: 5652.6119, mean_steps: 25.4300, mean_ecr: 0.0384 mean_entropies: 0.3580, took: 121.8603s
2022-10-11 14:04:52,570 [INFO] 	Process 6 - batch 152899: mean_policy_losses: -82.508, mean_net_lifetime: 3891.0610, mean_mc_travel_dist: 1044.2555, mean_rewards: 344.4179, total_rewards: 2896.2683, mean_steps: 10.2800, mean_ecr: 0.0551 mean_entropies: 0.1404, took: 54.8836s
2022-10-11 14:05:47,020 [INFO] 	Process 6 - batch 152999: mean_policy_losses: -63.173, mean_net_lifetime: 3984.7140, mean_mc_travel_dist: 1064.8985, mean_rewards: 345.7798, total_rewards: 2964.9090, mean_steps: 10.5100, mean_ecr: 0.0550 mean_entropies: 0.1414, took: 54.4499s
2022-10-11 14:05:48,652 [INFO] 	Process 3 - batch 114299: mean_policy_losses: -41.189, mean_net_lifetime: 5522.3878, mean_mc_travel_dist: 1435.5322, mean_rewards: 279.7367, total_rewards: 4123.1863, mean_steps: 18.8100, mean_ecr: 0.0445 mean_entropies: 0.4406, took: 91.7586s
2022-10-11 14:06:31,003 [INFO] 	Process 2 - batch 101199: mean_policy_losses: -38.917, mean_net_lifetime: 7328.6437, mean_mc_travel_dist: 1932.4979, mean_rewards: 289.9213, total_rewards: 5426.2074, mean_steps: 24.4100, mean_ecr: 0.0387 mean_entropies: 0.3445, took: 116.4328s
2022-10-11 14:07:15,042 [INFO] Process 1 - epoch 63: mean_policy_losses: 9.332, mean_net_lifetime: 5595.8982, mean_mc_travel_dist: 2041.4458, mean_entropies: 1.1077, m_net_lifetime_valid: 4304.0486, took: 2501.8925s, (168.1012 / 100 batches)

2022-10-11 14:07:18,517 [INFO] 	Process 5 - batch 92899: mean_policy_losses: -55.664, mean_net_lifetime: 11023.0219, mean_mc_travel_dist: 3392.9362, mean_rewards: 260.6098, total_rewards: 7669.3783, mean_steps: 42.6000, mean_ecr: 0.0292 mean_entropies: 0.6075, took: 194.3396s
2022-10-11 14:07:19,842 [INFO] 	Process 3 - batch 114399: mean_policy_losses: -50.399, mean_net_lifetime: 5464.0902, mean_mc_travel_dist: 1398.7124, mean_rewards: 278.4819, total_rewards: 4093.4897, mean_steps: 18.6700, mean_ecr: 0.0447 mean_entropies: 0.4363, took: 91.1905s
2022-10-11 14:08:25,736 [INFO] 	Process 2 - batch 101299: mean_policy_losses: -39.417, mean_net_lifetime: 7280.5493, mean_mc_travel_dist: 1887.4678, mean_rewards: 290.9783, total_rewards: 5414.6253, mean_steps: 24.1500, mean_ecr: 0.0388 mean_entropies: 0.3384, took: 114.7332s
2022-10-11 14:08:54,350 [INFO] 	Process 3 - batch 114499: mean_policy_losses: -44.945, mean_net_lifetime: 5424.1787, mean_mc_travel_dist: 1367.0964, mean_rewards: 276.3654, total_rewards: 4083.5523, mean_steps: 18.6800, mean_ecr: 0.0449 mean_entropies: 0.4264, took: 94.5070s
2022-10-11 14:09:18,452 [INFO] 	Process 1 - batch 94599: mean_policy_losses: 2.434, mean_net_lifetime: 6592.8359, mean_mc_travel_dist: 1974.2165, mean_rewards: 246.0008, total_rewards: 4640.7422, mean_steps: 26.0600, mean_ecr: 0.0385 mean_entropies: 0.9231, took: 739.8972s
2022-10-11 14:09:25,177 [INFO] Process 7 - epoch 69: mean_policy_losses: -360.018, mean_net_lifetime: 4419.4659, mean_mc_travel_dist: 1550.4544, mean_entropies: 1.4832, m_net_lifetime_valid: 4471.3235, took: 2482.0827s, (153.5807 / 100 batches)

2022-10-11 14:10:03,660 [INFO] 	Process 4 - batch 102499: mean_policy_losses: 84.195, mean_net_lifetime: 20285.4526, mean_mc_travel_dist: 7007.2641, mean_rewards: 250.6993, total_rewards: 13311.4480, mean_steps: 94.0600, mean_ecr: 0.0349 mean_entropies: 0.5009, took: 405.4693s
2022-10-11 14:10:26,215 [INFO] 	Process 3 - batch 114599: mean_policy_losses: -37.449, mean_net_lifetime: 5447.8308, mean_mc_travel_dist: 1371.2202, mean_rewards: 285.5070, total_rewards: 4111.5837, mean_steps: 18.1200, mean_ecr: 0.0451 mean_entropies: 0.4322, took: 91.8645s
2022-10-11 14:10:26,443 [INFO] 	Process 2 - batch 101399: mean_policy_losses: -47.629, mean_net_lifetime: 7222.1101, mean_mc_travel_dist: 1878.5927, mean_rewards: 288.5513, total_rewards: 5365.2563, mean_steps: 24.1000, mean_ecr: 0.0388 mean_entropies: 0.3551, took: 120.7078s
2022-10-11 14:11:08,777 [INFO] 	Process 7 - batch 103599: mean_policy_losses: -375.114, mean_net_lifetime: 4554.8952, mean_mc_travel_dist: 1392.3388, mean_rewards: 211.1041, total_rewards: 3204.9241, mean_steps: 20.7300, mean_ecr: 0.0415 mean_entropies: 1.2717, took: 764.3458s
2022-10-11 14:11:30,404 [INFO] 	Process 1 - batch 94699: mean_policy_losses: -18.180, mean_net_lifetime: 6700.0832, mean_mc_travel_dist: 2030.2479, mean_rewards: 246.2750, total_rewards: 4691.4979, mean_steps: 26.3300, mean_ecr: 0.0385 mean_entropies: 0.9742, took: 131.9521s
2022-10-11 14:11:37,556 [INFO] 	Process 5 - batch 92999: mean_policy_losses: -16.839, mean_net_lifetime: 13883.8416, mean_mc_travel_dist: 4403.6363, mean_rewards: 251.5743, total_rewards: 9524.1798, mean_steps: 56.2200, mean_ecr: 0.0286 mean_entropies: 0.6124, took: 259.0380s
2022-10-11 14:12:00,345 [INFO] 	Process 3 - batch 114699: mean_policy_losses: -49.300, mean_net_lifetime: 5455.4795, mean_mc_travel_dist: 1380.9527, mean_rewards: 279.6415, total_rewards: 4098.8677, mean_steps: 18.5700, mean_ecr: 0.0449 mean_entropies: 0.4472, took: 94.1305s
2022-10-11 14:12:30,136 [INFO] 	Process 2 - batch 101499: mean_policy_losses: -13.902, mean_net_lifetime: 7581.3579, mean_mc_travel_dist: 1979.7590, mean_rewards: 289.7810, total_rewards: 5622.0185, mean_steps: 25.2900, mean_ecr: 0.0385 mean_entropies: 0.3574, took: 123.6920s
2022-10-11 14:13:05,456 [INFO] 	Process 7 - batch 103699: mean_policy_losses: -230.700, mean_net_lifetime: 5039.9380, mean_mc_travel_dist: 1512.7561, mean_rewards: 198.9603, total_rewards: 3563.6893, mean_steps: 24.5700, mean_ecr: 0.0410 mean_entropies: 1.2207, took: 116.6780s
2022-10-11 14:13:37,532 [INFO] 	Process 3 - batch 114799: mean_policy_losses: -48.212, mean_net_lifetime: 5506.3629, mean_mc_travel_dist: 1397.5128, mean_rewards: 272.6808, total_rewards: 4146.5038, mean_steps: 19.2800, mean_ecr: 0.0446 mean_entropies: 0.4311, took: 97.1871s
2022-10-11 14:13:41,290 [INFO] 	Process 1 - batch 94799: mean_policy_losses: -66.866, mean_net_lifetime: 6529.2744, mean_mc_travel_dist: 1996.7272, mean_rewards: 237.8015, total_rewards: 4553.2558, mean_steps: 26.8400, mean_ecr: 0.0384 mean_entropies: 0.8925, took: 130.8853s
2022-10-11 14:14:34,733 [INFO] 	Process 2 - batch 101599: mean_policy_losses: -12.051, mean_net_lifetime: 7691.9448, mean_mc_travel_dist: 2008.9804, mean_rewards: 288.3475, total_rewards: 5704.3265, mean_steps: 25.7600, mean_ecr: 0.0382 mean_entropies: 0.3612, took: 124.5980s
2022-10-11 14:14:55,655 [INFO] 	Process 7 - batch 103799: mean_policy_losses: -269.995, mean_net_lifetime: 4862.0144, mean_mc_travel_dist: 1469.3595, mean_rewards: 201.1282, total_rewards: 3434.3279, mean_steps: 23.2800, mean_ecr: 0.0412 mean_entropies: 1.2184, took: 110.1997s
2022-10-11 14:15:12,659 [INFO] 	Process 3 - batch 114899: mean_policy_losses: -50.074, mean_net_lifetime: 5474.7254, mean_mc_travel_dist: 1397.0302, mean_rewards: 277.6779, total_rewards: 4105.1942, mean_steps: 18.7400, mean_ecr: 0.0448 mean_entropies: 0.4297, took: 95.1282s
2022-10-11 14:15:45,627 [INFO] 	Process 1 - batch 94899: mean_policy_losses: -33.192, mean_net_lifetime: 6676.2299, mean_mc_travel_dist: 2034.9088, mean_rewards: 239.8563, total_rewards: 4662.2202, mean_steps: 27.0500, mean_ecr: 0.0384 mean_entropies: 0.9140, took: 124.3380s
2022-10-11 14:16:05,282 [INFO] Process 6 - epoch 102: mean_policy_losses: -169.594, mean_net_lifetime: 3374.7177, mean_mc_travel_dist: 1001.9214, mean_entropies: 0.4388, m_net_lifetime_valid: 4112.4065, took: 1482.1813s, (104.2141 / 100 batches)

2022-10-11 14:16:35,412 [INFO] 	Process 2 - batch 101699: mean_policy_losses: -34.956, mean_net_lifetime: 7523.4616, mean_mc_travel_dist: 1983.5973, mean_rewards: 292.4053, total_rewards: 5561.4818, mean_steps: 24.8000, mean_ecr: 0.0384 mean_entropies: 0.3481, took: 120.6789s
2022-10-11 14:16:48,664 [INFO] 	Process 3 - batch 114999: mean_policy_losses: -34.125, mean_net_lifetime: 5601.5675, mean_mc_travel_dist: 1419.0714, mean_rewards: 280.9432, total_rewards: 4202.3729, mean_steps: 19.0300, mean_ecr: 0.0446 mean_entropies: 0.4414, took: 96.0029s
2022-10-11 14:16:54,276 [INFO] 	Process 7 - batch 103899: mean_policy_losses: -254.039, mean_net_lifetime: 5222.6519, mean_mc_travel_dist: 1597.0863, mean_rewards: 201.6479, total_rewards: 3657.9600, mean_steps: 25.2300, mean_ecr: 0.0406 mean_entropies: 1.1866, took: 118.6207s
2022-10-11 14:16:59,676 [INFO] 	Process 6 - batch 153099: mean_policy_losses: -160.903, mean_net_lifetime: 3633.8495, mean_mc_travel_dist: 990.1917, mean_rewards: 338.7553, total_rewards: 2705.1462, mean_steps: 9.6400, mean_ecr: 0.0554 mean_entropies: 0.1533, took: 672.6556s
2022-10-11 14:17:49,292 [INFO] 	Process 1 - batch 94999: mean_policy_losses: -6.856, mean_net_lifetime: 6642.5389, mean_mc_travel_dist: 2017.1398, mean_rewards: 249.4071, total_rewards: 4649.0279, mean_steps: 25.7700, mean_ecr: 0.0383 mean_entropies: 0.8886, took: 123.6644s
2022-10-11 14:17:56,454 [INFO] 	Process 6 - batch 153199: mean_policy_losses: -82.322, mean_net_lifetime: 3782.2368, mean_mc_travel_dist: 1022.2786, mean_rewards: 341.0094, total_rewards: 2805.0776, mean_steps: 10.0500, mean_ecr: 0.0551 mean_entropies: 0.1370, took: 56.7785s
2022-10-11 14:18:15,070 [INFO] 	Process 4 - batch 102599: mean_policy_losses: 190.275, mean_net_lifetime: 24192.1419, mean_mc_travel_dist: 8333.0482, mean_rewards: 253.3263, total_rewards: 15890.4972, mean_steps: 112.4500, mean_ecr: 0.0356 mean_entropies: 0.5041, took: 491.4120s
2022-10-11 14:18:25,119 [INFO] 	Process 3 - batch 115099: mean_policy_losses: -28.498, mean_net_lifetime: 5373.2661, mean_mc_travel_dist: 1388.1623, mean_rewards: 277.8948, total_rewards: 4013.4361, mean_steps: 18.4000, mean_ecr: 0.0447 mean_entropies: 0.4614, took: 96.4560s
2022-10-11 14:18:40,917 [INFO] 	Process 2 - batch 101799: mean_policy_losses: -6.106, mean_net_lifetime: 7549.3355, mean_mc_travel_dist: 1970.7388, mean_rewards: 285.6885, total_rewards: 5603.3053, mean_steps: 25.5200, mean_ecr: 0.0384 mean_entropies: 0.3395, took: 125.5048s
2022-10-11 14:18:44,854 [INFO] 	Process 7 - batch 103999: mean_policy_losses: -296.644, mean_net_lifetime: 4697.7450, mean_mc_travel_dist: 1436.2229, mean_rewards: 198.3543, total_rewards: 3291.0563, mean_steps: 22.8300, mean_ecr: 0.0411 mean_entropies: 1.1904, took: 110.5775s
2022-10-11 14:18:51,088 [INFO] 	Process 6 - batch 153299: mean_policy_losses: -95.457, mean_net_lifetime: 3793.5850, mean_mc_travel_dist: 1007.9465, mean_rewards: 342.8023, total_rewards: 2815.4584, mean_steps: 10.0100, mean_ecr: 0.0553 mean_entropies: 0.1423, took: 54.6336s
2022-10-11 14:19:46,893 [INFO] 	Process 6 - batch 153399: mean_policy_losses: -145.037, mean_net_lifetime: 3785.7176, mean_mc_travel_dist: 1006.2576, mean_rewards: 341.0085, total_rewards: 2815.5503, mean_steps: 10.0200, mean_ecr: 0.0553 mean_entropies: 0.1452, took: 55.8042s
2022-10-11 14:19:56,406 [INFO] 	Process 1 - batch 95099: mean_policy_losses: -2.837, mean_net_lifetime: 6502.6011, mean_mc_travel_dist: 2018.2763, mean_rewards: 242.8941, total_rewards: 4511.3362, mean_steps: 26.0400, mean_ecr: 0.0384 mean_entropies: 0.8384, took: 127.1139s
2022-10-11 14:19:59,985 [INFO] 	Process 3 - batch 115199: mean_policy_losses: -40.540, mean_net_lifetime: 5455.2088, mean_mc_travel_dist: 1388.7663, mean_rewards: 277.4560, total_rewards: 4095.7520, mean_steps: 18.7000, mean_ecr: 0.0446 mean_entropies: 0.4596, took: 94.8664s
2022-10-11 14:20:41,598 [INFO] 	Process 6 - batch 153499: mean_policy_losses: -112.386, mean_net_lifetime: 3722.5551, mean_mc_travel_dist: 1005.1845, mean_rewards: 343.0613, total_rewards: 2768.8041, mean_steps: 9.8200, mean_ecr: 0.0551 mean_entropies: 0.1620, took: 54.7053s
2022-10-11 14:20:48,471 [INFO] 	Process 2 - batch 101899: mean_policy_losses: -20.508, mean_net_lifetime: 7656.1019, mean_mc_travel_dist: 1997.5131, mean_rewards: 287.1066, total_rewards: 5681.4335, mean_steps: 25.7300, mean_ecr: 0.0382 mean_entropies: 0.3350, took: 127.5534s
2022-10-11 14:20:55,000 [INFO] 	Process 7 - batch 104099: mean_policy_losses: -223.176, mean_net_lifetime: 5453.6717, mean_mc_travel_dist: 1672.4827, mean_rewards: 195.8210, total_rewards: 3816.5039, mean_steps: 27.3200, mean_ecr: 0.0404 mean_entropies: 1.1583, took: 130.1470s
2022-10-11 14:21:37,726 [INFO] 	Process 3 - batch 115299: mean_policy_losses: -53.572, mean_net_lifetime: 5496.6690, mean_mc_travel_dist: 1384.3407, mean_rewards: 273.8603, total_rewards: 4134.9491, mean_steps: 19.1200, mean_ecr: 0.0446 mean_entropies: 0.4446, took: 97.7411s
2022-10-11 14:21:38,750 [INFO] 	Process 6 - batch 153599: mean_policy_losses: -88.529, mean_net_lifetime: 3976.1472, mean_mc_travel_dist: 1075.8090, mean_rewards: 341.8320, total_rewards: 2965.8558, mean_steps: 10.5600, mean_ecr: 0.0550 mean_entropies: 0.1357, took: 57.1492s
2022-10-11 14:22:01,367 [INFO] 	Process 1 - batch 95199: mean_policy_losses: 22.892, mean_net_lifetime: 6663.6940, mean_mc_travel_dist: 1979.8977, mean_rewards: 247.3161, total_rewards: 4709.7629, mean_steps: 26.0900, mean_ecr: 0.0384 mean_entropies: 0.9378, took: 124.9607s
2022-10-11 14:22:04,901 [INFO] Process 5 - epoch 62: mean_policy_losses: -182.093, mean_net_lifetime: 6291.9887, mean_mc_travel_dist: 2262.9008, mean_entropies: 1.0465, m_net_lifetime_valid: 4295.3851, took: 3711.8214s, (171.7537 / 100 batches)

2022-10-11 14:22:27,490 [INFO] 	Process 4 - batch 102699: mean_policy_losses: 108.124, mean_net_lifetime: 13055.0741, mean_mc_travel_dist: 4029.9003, mean_rewards: 264.7026, total_rewards: 9050.5715, mean_steps: 54.4600, mean_ecr: 0.0382 mean_entropies: 0.4984, took: 252.4198s
2022-10-11 14:22:36,052 [INFO] 	Process 6 - batch 153699: mean_policy_losses: -96.454, mean_net_lifetime: 3932.2647, mean_mc_travel_dist: 1057.8259, mean_rewards: 342.5446, total_rewards: 2927.9002, mean_steps: 10.4400, mean_ecr: 0.0550 mean_entropies: 0.1486, took: 57.3047s
2022-10-11 14:22:58,738 [INFO] 	Process 2 - batch 101999: mean_policy_losses: -15.550, mean_net_lifetime: 7698.3365, mean_mc_travel_dist: 2005.6033, mean_rewards: 288.0705, total_rewards: 5717.4651, mean_steps: 25.8300, mean_ecr: 0.0383 mean_entropies: 0.3493, took: 130.2677s
2022-10-11 14:23:04,181 [INFO] 	Process 7 - batch 104199: mean_policy_losses: -185.457, mean_net_lifetime: 5471.4232, mean_mc_travel_dist: 1663.4246, mean_rewards: 201.7431, total_rewards: 3839.0337, mean_steps: 26.5600, mean_ecr: 0.0404 mean_entropies: 1.1868, took: 129.1800s
2022-10-11 14:23:15,532 [INFO] 	Process 3 - batch 115399: mean_policy_losses: -35.585, mean_net_lifetime: 5545.9109, mean_mc_travel_dist: 1397.1583, mean_rewards: 277.4387, total_rewards: 4178.9025, mean_steps: 19.0300, mean_ecr: 0.0444 mean_entropies: 0.4375, took: 97.8056s
2022-10-11 14:23:31,433 [INFO] 	Process 6 - batch 153799: mean_policy_losses: -124.687, mean_net_lifetime: 3702.9152, mean_mc_travel_dist: 1003.4149, mean_rewards: 342.3270, total_rewards: 2750.8808, mean_steps: 9.7700, mean_ecr: 0.0553 mean_entropies: 0.1561, took: 55.3813s
2022-10-11 14:24:12,132 [INFO] 	Process 1 - batch 95299: mean_policy_losses: 74.856, mean_net_lifetime: 6818.8864, mean_mc_travel_dist: 1981.5919, mean_rewards: 246.2198, total_rewards: 4856.8555, mean_steps: 26.8700, mean_ecr: 0.0384 mean_entropies: 0.9812, took: 130.7656s
2022-10-11 14:24:33,231 [INFO] 	Process 6 - batch 153899: mean_policy_losses: -55.818, mean_net_lifetime: 4146.8824, mean_mc_travel_dist: 1113.1390, mean_rewards: 344.5357, total_rewards: 3075.4048, mean_steps: 11.0000, mean_ecr: 0.0550 mean_entropies: 0.1283, took: 61.7983s
2022-10-11 14:24:53,348 [INFO] 	Process 7 - batch 104299: mean_policy_losses: -390.477, mean_net_lifetime: 4729.3348, mean_mc_travel_dist: 1434.3273, mean_rewards: 203.2545, total_rewards: 3338.3272, mean_steps: 22.6400, mean_ecr: 0.0412 mean_entropies: 1.2327, took: 109.1665s
2022-10-11 14:24:54,306 [INFO] 	Process 3 - batch 115499: mean_policy_losses: -35.980, mean_net_lifetime: 5534.4715, mean_mc_travel_dist: 1395.1290, mean_rewards: 277.3376, total_rewards: 4164.0666, mean_steps: 19.0600, mean_ecr: 0.0445 mean_entropies: 0.4396, took: 98.7742s
2022-10-11 14:25:15,147 [INFO] 	Process 5 - batch 93099: mean_policy_losses: -123.632, mean_net_lifetime: 9931.8652, mean_mc_travel_dist: 2987.6763, mean_rewards: 254.9214, total_rewards: 6987.3047, mean_steps: 39.7600, mean_ecr: 0.0297 mean_entropies: 0.6309, took: 817.5927s
2022-10-11 14:25:28,748 [INFO] 	Process 6 - batch 153999: mean_policy_losses: -71.827, mean_net_lifetime: 3616.1893, mean_mc_travel_dist: 1004.7655, mean_rewards: 326.3710, total_rewards: 2665.0389, mean_steps: 10.1300, mean_ecr: 0.0557 mean_entropies: 0.1634, took: 55.5175s
2022-10-11 14:25:31,659 [INFO] 	Process 4 - batch 102799: mean_policy_losses: 96.209, mean_net_lifetime: 10058.0270, mean_mc_travel_dist: 2927.8814, mean_rewards: 274.9730, total_rewards: 7145.4747, mean_steps: 38.8000, mean_ecr: 0.0394 mean_entropies: 0.4708, took: 184.1699s
2022-10-11 14:26:11,802 [INFO] 	Process 1 - batch 95399: mean_policy_losses: 95.732, mean_net_lifetime: 6666.8526, mean_mc_travel_dist: 2002.4793, mean_rewards: 256.2171, total_rewards: 4682.9705, mean_steps: 25.1300, mean_ecr: 0.0385 mean_entropies: 0.9366, took: 119.6700s
2022-10-11 14:26:24,653 [INFO] 	Process 6 - batch 154099: mean_policy_losses: -74.470, mean_net_lifetime: 3902.1294, mean_mc_travel_dist: 1055.0547, mean_rewards: 337.4427, total_rewards: 2916.5828, mean_steps: 10.5900, mean_ecr: 0.0550 mean_entropies: 0.1645, took: 55.9038s
2022-10-11 14:26:28,377 [INFO] 	Process 7 - batch 104399: mean_policy_losses: -355.578, mean_net_lifetime: 4210.6513, mean_mc_travel_dist: 1249.3768, mean_rewards: 201.9161, total_rewards: 2989.8399, mean_steps: 20.0900, mean_ecr: 0.0415 mean_entropies: 1.2173, took: 95.0292s
2022-10-11 14:27:22,052 [INFO] 	Process 6 - batch 154199: mean_policy_losses: -35.336, mean_net_lifetime: 4083.3182, mean_mc_travel_dist: 1109.8283, mean_rewards: 341.8064, total_rewards: 3011.4858, mean_steps: 10.9200, mean_ecr: 0.0552 mean_entropies: 0.1188, took: 57.3994s
2022-10-11 14:28:15,589 [INFO] 	Process 7 - batch 104499: mean_policy_losses: -309.998, mean_net_lifetime: 4835.0012, mean_mc_travel_dist: 1428.8270, mean_rewards: 204.9210, total_rewards: 3436.9484, mean_steps: 22.6900, mean_ecr: 0.0412 mean_entropies: 1.2618, took: 107.2122s
2022-10-11 14:28:17,138 [INFO] 	Process 1 - batch 95499: mean_policy_losses: 57.067, mean_net_lifetime: 6793.7515, mean_mc_travel_dist: 2041.3634, mean_rewards: 244.3652, total_rewards: 4786.7568, mean_steps: 27.0300, mean_ecr: 0.0383 mean_entropies: 0.9542, took: 125.3364s
2022-10-11 14:28:18,718 [INFO] 	Process 6 - batch 154299: mean_policy_losses: -75.349, mean_net_lifetime: 3975.6338, mean_mc_travel_dist: 1068.3585, mean_rewards: 344.7342, total_rewards: 2972.5487, mean_steps: 10.5100, mean_ecr: 0.0549 mean_entropies: 0.1331, took: 56.6663s
2022-10-11 14:28:30,168 [INFO] 	Process 4 - batch 102899: mean_policy_losses: 60.534, mean_net_lifetime: 10033.6902, mean_mc_travel_dist: 2931.4826, mean_rewards: 276.8098, total_rewards: 7126.1165, mean_steps: 39.0900, mean_ecr: 0.0411 mean_entropies: 0.5074, took: 178.5082s
2022-10-11 14:28:56,584 [INFO] 	Process 5 - batch 93199: mean_policy_losses: -16.251, mean_net_lifetime: 12347.5284, mean_mc_travel_dist: 3787.3716, mean_rewards: 257.3350, total_rewards: 8599.6906, mean_steps: 48.5800, mean_ecr: 0.0292 mean_entropies: 0.6340, took: 221.4360s
2022-10-11 14:29:20,026 [INFO] 	Process 6 - batch 154399: mean_policy_losses: -42.023, mean_net_lifetime: 4312.7633, mean_mc_travel_dist: 1142.3165, mean_rewards: 346.8763, total_rewards: 3193.8265, mean_steps: 11.4200, mean_ecr: 0.0548 mean_entropies: 0.0997, took: 61.3079s
2022-10-11 14:30:06,509 [INFO] 	Process 7 - batch 104599: mean_policy_losses: -329.730, mean_net_lifetime: 4918.7079, mean_mc_travel_dist: 1487.2520, mean_rewards: 203.0844, total_rewards: 3465.7473, mean_steps: 23.6200, mean_ecr: 0.0411 mean_entropies: 1.2114, took: 110.9193s
2022-10-11 14:30:17,347 [INFO] 	Process 6 - batch 154499: mean_policy_losses: -68.331, mean_net_lifetime: 4013.2434, mean_mc_travel_dist: 1077.8149, mean_rewards: 342.9731, total_rewards: 2979.9237, mean_steps: 10.6700, mean_ecr: 0.0551 mean_entropies: 0.1378, took: 57.3203s
2022-10-11 14:30:24,010 [INFO] 	Process 1 - batch 95599: mean_policy_losses: 19.327, mean_net_lifetime: 6873.1343, mean_mc_travel_dist: 2050.3211, mean_rewards: 247.0187, total_rewards: 4844.3656, mean_steps: 27.0100, mean_ecr: 0.0383 mean_entropies: 0.9343, took: 126.8725s
2022-10-11 14:31:50,953 [INFO] 	Process 7 - batch 104699: mean_policy_losses: -309.220, mean_net_lifetime: 4976.3342, mean_mc_travel_dist: 1473.5855, mean_rewards: 210.6751, total_rewards: 3536.4158, mean_steps: 23.1600, mean_ecr: 0.0409 mean_entropies: 1.2347, took: 104.4452s
2022-10-11 14:31:54,233 [INFO] 	Process 4 - batch 102999: mean_policy_losses: 80.974, mean_net_lifetime: 11207.4519, mean_mc_travel_dist: 3407.2616, mean_rewards: 269.6327, total_rewards: 7825.5267, mean_steps: 45.5500, mean_ecr: 0.0385 mean_entropies: 0.4661, took: 204.0637s
2022-10-11 14:32:24,156 [INFO] 	Process 1 - batch 95699: mean_policy_losses: 9.678, mean_net_lifetime: 6751.5261, mean_mc_travel_dist: 1991.9211, mean_rewards: 249.4877, total_rewards: 4780.0296, mean_steps: 26.2100, mean_ecr: 0.0385 mean_entropies: 0.9417, took: 120.1454s
2022-10-11 14:32:44,813 [INFO] 	Process 5 - batch 93299: mean_policy_losses: -57.059, mean_net_lifetime: 12654.6556, mean_mc_travel_dist: 3879.4386, mean_rewards: 250.4376, total_rewards: 8813.5735, mean_steps: 51.1300, mean_ecr: 0.0290 mean_entropies: 0.6144, took: 228.2297s
2022-10-11 14:33:46,473 [INFO] 	Process 7 - batch 104799: mean_policy_losses: -259.866, mean_net_lifetime: 5346.2252, mean_mc_travel_dist: 1621.6436, mean_rewards: 202.1227, total_rewards: 3772.9879, mean_steps: 25.7600, mean_ecr: 0.0405 mean_entropies: 1.2158, took: 115.5196s
2022-10-11 14:34:26,188 [INFO] Process 2 - epoch 68: mean_policy_losses: -2.675, mean_net_lifetime: 5629.2181, mean_mc_travel_dist: 1733.0914, mean_entropies: 0.7661, m_net_lifetime_valid: 4416.4890, took: 2534.2970s, (157.2811 / 100 batches)

2022-10-11 14:34:27,878 [INFO] 	Process 1 - batch 95799: mean_policy_losses: -0.387, mean_net_lifetime: 6903.4188, mean_mc_travel_dist: 2009.4599, mean_rewards: 247.7111, total_rewards: 4916.9001, mean_steps: 26.9800, mean_ecr: 0.0384 mean_entropies: 0.9558, took: 123.7216s
2022-10-11 14:34:59,646 [INFO] 	Process 4 - batch 103099: mean_policy_losses: 76.723, mean_net_lifetime: 10436.3382, mean_mc_travel_dist: 3059.9292, mean_rewards: 267.8761, total_rewards: 7397.4288, mean_steps: 40.9600, mean_ecr: 0.0384 mean_entropies: 0.4935, took: 185.4137s
2022-10-11 14:35:34,451 [INFO] 	Process 7 - batch 104899: mean_policy_losses: -342.668, mean_net_lifetime: 4900.9981, mean_mc_travel_dist: 1468.5487, mean_rewards: 202.2247, total_rewards: 3467.0638, mean_steps: 23.5600, mean_ecr: 0.0410 mean_entropies: 1.2191, took: 107.9790s
2022-10-11 14:35:57,532 [INFO] Process 3 - epoch 77: mean_policy_losses: 32.692, mean_net_lifetime: 4629.7358, mean_mc_travel_dist: 1345.7091, mean_entropies: 0.7440, m_net_lifetime_valid: 4368.3482, took: 2088.2531s, (139.0128 / 100 batches)

2022-10-11 14:36:30,329 [INFO] 	Process 2 - batch 102099: mean_policy_losses: -41.875, mean_net_lifetime: 7572.4467, mean_mc_travel_dist: 1976.3944, mean_rewards: 285.7306, total_rewards: 5624.9175, mean_steps: 25.5800, mean_ecr: 0.0383 mean_entropies: 0.3442, took: 811.5912s
2022-10-11 14:36:33,051 [INFO] 	Process 1 - batch 95899: mean_policy_losses: 12.522, mean_net_lifetime: 6835.8650, mean_mc_travel_dist: 2006.1184, mean_rewards: 246.9686, total_rewards: 4851.2479, mean_steps: 26.7900, mean_ecr: 0.0386 mean_entropies: 1.0022, took: 125.1728s
2022-10-11 14:37:09,681 [INFO] 	Process 5 - batch 93399: mean_policy_losses: -48.360, mean_net_lifetime: 14452.9398, mean_mc_travel_dist: 4543.5007, mean_rewards: 251.0536, total_rewards: 9943.4244, mean_steps: 59.0400, mean_ecr: 0.0287 mean_entropies: 0.6200, took: 264.8672s
2022-10-11 14:37:29,853 [INFO] 	Process 3 - batch 115599: mean_policy_losses: -47.109, mean_net_lifetime: 5314.7724, mean_mc_travel_dist: 1359.2017, mean_rewards: 282.7475, total_rewards: 3981.6657, mean_steps: 17.8500, mean_ecr: 0.0448 mean_entropies: 0.4569, took: 755.5473s
2022-10-11 14:37:36,329 [INFO] 	Process 7 - batch 104999: mean_policy_losses: -223.944, mean_net_lifetime: 5147.5577, mean_mc_travel_dist: 1555.5633, mean_rewards: 197.0363, total_rewards: 3630.0279, mean_steps: 25.4400, mean_ecr: 0.0407 mean_entropies: 1.1995, took: 121.8778s
2022-10-11 14:38:37,135 [INFO] 	Process 2 - batch 102199: mean_policy_losses: -34.222, mean_net_lifetime: 7596.8232, mean_mc_travel_dist: 1985.8348, mean_rewards: 282.8786, total_rewards: 5631.7122, mean_steps: 25.9400, mean_ecr: 0.0383 mean_entropies: 0.3401, took: 126.8056s
2022-10-11 14:38:40,434 [INFO] 	Process 1 - batch 95999: mean_policy_losses: 11.120, mean_net_lifetime: 6735.9751, mean_mc_travel_dist: 1980.0485, mean_rewards: 246.7722, total_rewards: 4777.9981, mean_steps: 26.4000, mean_ecr: 0.0386 mean_entropies: 0.9663, took: 127.3832s
2022-10-11 14:38:56,454 [INFO] 	Process 4 - batch 103199: mean_policy_losses: 109.040, mean_net_lifetime: 12673.3759, mean_mc_travel_dist: 3816.6065, mean_rewards: 268.5428, total_rewards: 8882.4389, mean_steps: 51.7900, mean_ecr: 0.0382 mean_entropies: 0.4884, took: 236.8093s
2022-10-11 14:38:59,813 [INFO] 	Process 3 - batch 115699: mean_policy_losses: -34.144, mean_net_lifetime: 5523.4675, mean_mc_travel_dist: 1404.7652, mean_rewards: 282.4929, total_rewards: 4146.6793, mean_steps: 18.6100, mean_ecr: 0.0448 mean_entropies: 0.4592, took: 89.9603s
2022-10-11 14:40:10,460 [INFO] 	Process 5 - batch 93499: mean_policy_losses: -55.690, mean_net_lifetime: 10199.3231, mean_mc_travel_dist: 3049.3198, mean_rewards: 254.7724, total_rewards: 7195.2633, mean_steps: 39.9300, mean_ecr: 0.0297 mean_entropies: 0.6148, took: 180.7793s
2022-10-11 14:40:30,686 [INFO] 	Process 3 - batch 115799: mean_policy_losses: -62.694, mean_net_lifetime: 5392.3352, mean_mc_travel_dist: 1363.8228, mean_rewards: 275.5667, total_rewards: 4052.8589, mean_steps: 18.6900, mean_ecr: 0.0447 mean_entropies: 0.4412, took: 90.8724s
2022-10-11 14:40:36,533 [INFO] 	Process 2 - batch 102299: mean_policy_losses: -25.243, mean_net_lifetime: 7525.8860, mean_mc_travel_dist: 1969.7170, mean_rewards: 282.6186, total_rewards: 5582.2314, mean_steps: 25.6900, mean_ecr: 0.0384 mean_entropies: 0.3602, took: 119.3976s
2022-10-11 14:41:26,150 [INFO] Process 6 - epoch 103: mean_policy_losses: -168.807, mean_net_lifetime: 3379.7395, mean_mc_travel_dist: 1002.3818, mean_entropies: 0.4360, m_net_lifetime_valid: 4588.8317, took: 1520.8647s, (104.1540 / 100 batches)

2022-10-11 14:42:00,455 [INFO] 	Process 3 - batch 115899: mean_policy_losses: -18.969, mean_net_lifetime: 5600.8180, mean_mc_travel_dist: 1425.1831, mean_rewards: 283.7256, total_rewards: 4198.4439, mean_steps: 18.8000, mean_ecr: 0.0446 mean_entropies: 0.4422, took: 89.7688s
2022-10-11 14:42:23,955 [INFO] 	Process 6 - batch 154599: mean_policy_losses: -67.083, mean_net_lifetime: 3957.4400, mean_mc_travel_dist: 1055.8259, mean_rewards: 344.5514, total_rewards: 2946.1721, mean_steps: 10.4500, mean_ecr: 0.0550 mean_entropies: 0.1402, took: 726.6082s
2022-10-11 14:42:40,290 [INFO] 	Process 2 - batch 102399: mean_policy_losses: -6.936, mean_net_lifetime: 7802.3269, mean_mc_travel_dist: 2030.3479, mean_rewards: 285.2086, total_rewards: 5787.8907, mean_steps: 26.4300, mean_ecr: 0.0382 mean_entropies: 0.3509, took: 123.7577s
2022-10-11 14:42:41,481 [INFO] 	Process 4 - batch 103299: mean_policy_losses: 99.458, mean_net_lifetime: 12641.3662, mean_mc_travel_dist: 3820.8168, mean_rewards: 270.5508, total_rewards: 8859.7827, mean_steps: 51.4700, mean_ecr: 0.0390 mean_entropies: 0.4782, took: 225.0270s
2022-10-11 14:43:17,455 [INFO] 	Process 6 - batch 154699: mean_policy_losses: -92.563, mean_net_lifetime: 3631.4522, mean_mc_travel_dist: 974.0207, mean_rewards: 340.7122, total_rewards: 2691.2847, mean_steps: 9.6300, mean_ecr: 0.0555 mean_entropies: 0.1493, took: 53.5002s
2022-10-11 14:43:25,008 [INFO] 	Process 5 - batch 93599: mean_policy_losses: -120.065, mean_net_lifetime: 10759.7421, mean_mc_travel_dist: 3243.7719, mean_rewards: 255.3309, total_rewards: 7556.1181, mean_steps: 43.0200, mean_ecr: 0.0297 mean_entropies: 0.6078, took: 194.5477s
2022-10-11 14:43:31,339 [INFO] 	Process 3 - batch 115999: mean_policy_losses: -27.411, mean_net_lifetime: 5496.1978, mean_mc_travel_dist: 1410.7303, mean_rewards: 280.3295, total_rewards: 4110.0065, mean_steps: 18.7400, mean_ecr: 0.0445 mean_entropies: 0.4349, took: 90.8849s
2022-10-11 14:44:14,096 [INFO] 	Process 6 - batch 154799: mean_policy_losses: -57.934, mean_net_lifetime: 4019.6248, mean_mc_travel_dist: 1070.1296, mean_rewards: 342.4602, total_rewards: 2969.3757, mean_steps: 10.6800, mean_ecr: 0.0552 mean_entropies: 0.1165, took: 56.6410s
2022-10-11 14:44:38,887 [INFO] 	Process 2 - batch 102499: mean_policy_losses: -30.722, mean_net_lifetime: 7326.4126, mean_mc_travel_dist: 1900.3342, mean_rewards: 283.9100, total_rewards: 5446.2517, mean_steps: 24.9400, mean_ecr: 0.0386 mean_entropies: 0.3151, took: 118.5967s
2022-10-11 14:45:02,539 [INFO] 	Process 3 - batch 116099: mean_policy_losses: -29.872, mean_net_lifetime: 5533.5255, mean_mc_travel_dist: 1404.2902, mean_rewards: 281.1699, total_rewards: 4145.2354, mean_steps: 18.7300, mean_ecr: 0.0446 mean_entropies: 0.4086, took: 91.1994s
2022-10-11 14:45:09,825 [INFO] 	Process 6 - batch 154899: mean_policy_losses: -46.309, mean_net_lifetime: 4138.3477, mean_mc_travel_dist: 1092.0536, mean_rewards: 345.8093, total_rewards: 3068.1495, mean_steps: 10.9400, mean_ecr: 0.0548 mean_entropies: 0.1182, took: 55.7292s
2022-10-11 14:46:02,278 [INFO] 	Process 6 - batch 154999: mean_policy_losses: -61.889, mean_net_lifetime: 3798.8994, mean_mc_travel_dist: 1010.4160, mean_rewards: 344.0012, total_rewards: 2816.1744, mean_steps: 10.0000, mean_ecr: 0.0551 mean_entropies: 0.1323, took: 52.4530s
2022-10-11 14:46:35,806 [INFO] 	Process 3 - batch 116199: mean_policy_losses: -33.954, mean_net_lifetime: 5591.5292, mean_mc_travel_dist: 1441.9416, mean_rewards: 280.3477, total_rewards: 4184.2092, mean_steps: 19.0000, mean_ecr: 0.0444 mean_entropies: 0.4360, took: 93.2671s
2022-10-11 14:46:37,106 [INFO] 	Process 2 - batch 102599: mean_policy_losses: -29.831, mean_net_lifetime: 7464.7232, mean_mc_travel_dist: 1958.8337, mean_rewards: 290.7760, total_rewards: 5530.0543, mean_steps: 24.7600, mean_ecr: 0.0384 mean_entropies: 0.3441, took: 118.2195s
2022-10-11 14:46:41,337 [INFO] 	Process 5 - batch 93699: mean_policy_losses: -99.395, mean_net_lifetime: 10840.6384, mean_mc_travel_dist: 3275.2657, mean_rewards: 255.9497, total_rewards: 7604.5006, mean_steps: 42.6800, mean_ecr: 0.0295 mean_entropies: 0.6146, took: 196.3294s
2022-10-11 14:46:57,591 [INFO] 	Process 6 - batch 155099: mean_policy_losses: -102.507, mean_net_lifetime: 3955.8739, mean_mc_travel_dist: 1043.3346, mean_rewards: 342.8304, total_rewards: 2928.6237, mean_steps: 10.4600, mean_ecr: 0.0553 mean_entropies: 0.1175, took: 55.3131s
2022-10-11 14:46:58,381 [INFO] 	Process 4 - batch 103399: mean_policy_losses: 102.395, mean_net_lifetime: 14221.1460, mean_mc_travel_dist: 4360.8633, mean_rewards: 271.4660, total_rewards: 9894.5728, mean_steps: 57.6800, mean_ecr: 0.0374 mean_entropies: 0.4871, took: 256.9002s
2022-10-11 14:47:55,596 [INFO] 	Process 6 - batch 155199: mean_policy_losses: -57.050, mean_net_lifetime: 3975.3844, mean_mc_travel_dist: 1057.9301, mean_rewards: 344.8493, total_rewards: 2935.3011, mean_steps: 10.5100, mean_ecr: 0.0551 mean_entropies: 0.1312, took: 58.0047s
2022-10-11 14:48:08,547 [INFO] 	Process 3 - batch 116299: mean_policy_losses: -25.262, mean_net_lifetime: 5469.0338, mean_mc_travel_dist: 1387.3822, mean_rewards: 276.2529, total_rewards: 4105.9949, mean_steps: 18.8800, mean_ecr: 0.0446 mean_entropies: 0.4238, took: 92.7406s
2022-10-11 14:48:38,184 [INFO] 	Process 2 - batch 102699: mean_policy_losses: -11.459, mean_net_lifetime: 7514.2011, mean_mc_travel_dist: 1992.0632, mean_rewards: 289.4251, total_rewards: 5545.3633, mean_steps: 25.0800, mean_ecr: 0.0383 mean_entropies: 0.3378, took: 121.0782s
2022-10-11 14:48:53,895 [INFO] 	Process 6 - batch 155299: mean_policy_losses: -56.349, mean_net_lifetime: 4209.4725, mean_mc_travel_dist: 1114.3171, mean_rewards: 345.1941, total_rewards: 3114.4648, mean_steps: 11.1500, mean_ecr: 0.0549 mean_entropies: 0.1001, took: 58.2995s
2022-10-11 14:49:40,153 [INFO] 	Process 3 - batch 116399: mean_policy_losses: -54.903, mean_net_lifetime: 5434.9082, mean_mc_travel_dist: 1374.1566, mean_rewards: 282.2131, total_rewards: 4094.2701, mean_steps: 18.3100, mean_ecr: 0.0446 mean_entropies: 0.4152, took: 91.6065s
2022-10-11 14:49:49,725 [INFO] 	Process 6 - batch 155399: mean_policy_losses: -67.238, mean_net_lifetime: 4040.6562, mean_mc_travel_dist: 1067.7484, mean_rewards: 343.6302, total_rewards: 2994.7004, mean_steps: 10.7300, mean_ecr: 0.0550 mean_entropies: 0.1265, took: 55.8297s
2022-10-11 14:49:54,806 [INFO] Process 7 - epoch 70: mean_policy_losses: -359.024, mean_net_lifetime: 4427.1566, mean_mc_travel_dist: 1549.6982, mean_entropies: 1.4794, m_net_lifetime_valid: 4621.5581, took: 2429.6258s, (153.6265 / 100 batches)

2022-10-11 14:49:57,308 [INFO] 	Process 5 - batch 93799: mean_policy_losses: -21.276, mean_net_lifetime: 10956.4994, mean_mc_travel_dist: 3281.6419, mean_rewards: 254.2491, total_rewards: 7713.2121, mean_steps: 42.9100, mean_ecr: 0.0294 mean_entropies: 0.6301, took: 195.9708s
2022-10-11 14:50:06,489 [INFO] Process 1 - epoch 64: mean_policy_losses: 9.371, mean_net_lifetime: 5613.3442, mean_mc_travel_dist: 2040.9177, mean_entropies: 1.1050, m_net_lifetime_valid: 4872.6601, took: 2571.4440s, (168.0808 / 100 batches)

2022-10-11 14:50:41,392 [INFO] 	Process 2 - batch 102799: mean_policy_losses: -19.620, mean_net_lifetime: 7629.3198, mean_mc_travel_dist: 1994.9798, mean_rewards: 291.1887, total_rewards: 5659.4090, mean_steps: 25.3000, mean_ecr: 0.0384 mean_entropies: 0.3351, took: 123.2077s
2022-10-11 14:50:48,976 [INFO] 	Process 6 - batch 155499: mean_policy_losses: -68.759, mean_net_lifetime: 4070.5290, mean_mc_travel_dist: 1080.8202, mean_rewards: 344.0921, total_rewards: 3013.1180, mean_steps: 10.7800, mean_ecr: 0.0550 mean_entropies: 0.1223, took: 59.2505s
2022-10-11 14:51:13,266 [INFO] 	Process 4 - batch 103499: mean_policy_losses: 53.835, mean_net_lifetime: 13796.8440, mean_mc_travel_dist: 4228.4478, mean_rewards: 274.0535, total_rewards: 9597.9741, mean_steps: 56.0800, mean_ecr: 0.0383 mean_entropies: 0.4784, took: 254.8841s
2022-10-11 14:51:18,875 [INFO] 	Process 3 - batch 116499: mean_policy_losses: -36.031, mean_net_lifetime: 5554.2613, mean_mc_travel_dist: 1420.9554, mean_rewards: 280.7561, total_rewards: 4160.3261, mean_steps: 18.8300, mean_ecr: 0.0444 mean_entropies: 0.4444, took: 98.7222s
2022-10-11 14:51:40,035 [INFO] 	Process 7 - batch 105099: mean_policy_losses: -383.847, mean_net_lifetime: 4571.7650, mean_mc_travel_dist: 1413.5444, mean_rewards: 206.7978, total_rewards: 3210.9369, mean_steps: 21.2800, mean_ecr: 0.0415 mean_entropies: 1.2203, took: 843.7051s
2022-10-11 14:51:47,056 [INFO] 	Process 6 - batch 155599: mean_policy_losses: -87.463, mean_net_lifetime: 3876.4131, mean_mc_travel_dist: 1044.4190, mean_rewards: 338.5707, total_rewards: 2879.6496, mean_steps: 10.4400, mean_ecr: 0.0551 mean_entropies: 0.1577, took: 58.0807s
2022-10-11 14:52:20,011 [INFO] 	Process 1 - batch 96099: mean_policy_losses: 64.282, mean_net_lifetime: 6946.7587, mean_mc_travel_dist: 2044.8607, mean_rewards: 247.6759, total_rewards: 4926.1258, mean_steps: 27.1800, mean_ecr: 0.0384 mean_entropies: 0.9691, took: 819.5769s
2022-10-11 14:52:43,295 [INFO] 	Process 6 - batch 155699: mean_policy_losses: -145.590, mean_net_lifetime: 3928.2524, mean_mc_travel_dist: 1046.7581, mean_rewards: 342.3550, total_rewards: 2904.1221, mean_steps: 10.4100, mean_ecr: 0.0551 mean_entropies: 0.1316, took: 56.2392s
2022-10-11 14:52:49,423 [INFO] 	Process 2 - batch 102899: mean_policy_losses: -5.080, mean_net_lifetime: 7761.0563, mean_mc_travel_dist: 2019.1827, mean_rewards: 289.7577, total_rewards: 5761.8637, mean_steps: 25.8600, mean_ecr: 0.0382 mean_entropies: 0.3296, took: 128.0299s
2022-10-11 14:52:56,064 [INFO] 	Process 3 - batch 116599: mean_policy_losses: -36.338, mean_net_lifetime: 5563.0163, mean_mc_travel_dist: 1405.2703, mean_rewards: 281.3790, total_rewards: 4185.3783, mean_steps: 18.8500, mean_ecr: 0.0445 mean_entropies: 0.4626, took: 97.1874s
2022-10-11 14:53:30,806 [INFO] 	Process 7 - batch 105199: mean_policy_losses: -291.832, mean_net_lifetime: 4816.3387, mean_mc_travel_dist: 1500.9415, mean_rewards: 202.8246, total_rewards: 3346.6135, mean_steps: 23.1700, mean_ecr: 0.0410 mean_entropies: 1.1303, took: 110.7716s
2022-10-11 14:53:31,873 [INFO] 	Process 5 - batch 93899: mean_policy_losses: -64.358, mean_net_lifetime: 11680.4437, mean_mc_travel_dist: 3606.0348, mean_rewards: 264.4231, total_rewards: 8109.4562, mean_steps: 44.9700, mean_ecr: 0.0293 mean_entropies: 0.5982, took: 214.5639s
2022-10-11 14:53:39,486 [INFO] 	Process 6 - batch 155799: mean_policy_losses: -88.923, mean_net_lifetime: 3809.9119, mean_mc_travel_dist: 1010.9333, mean_rewards: 342.1764, total_rewards: 2826.6388, mean_steps: 10.1100, mean_ecr: 0.0551 mean_entropies: 0.1485, took: 56.1905s
2022-10-11 14:54:30,355 [INFO] 	Process 1 - batch 96199: mean_policy_losses: 3.459, mean_net_lifetime: 6768.3257, mean_mc_travel_dist: 2050.2714, mean_rewards: 243.5880, total_rewards: 4736.7502, mean_steps: 26.9000, mean_ecr: 0.0383 mean_entropies: 0.8853, took: 130.3443s
2022-10-11 14:54:33,721 [INFO] 	Process 3 - batch 116699: mean_policy_losses: -38.058, mean_net_lifetime: 5491.4358, mean_mc_travel_dist: 1390.2959, mean_rewards: 276.9556, total_rewards: 4125.8872, mean_steps: 18.8800, mean_ecr: 0.0445 mean_entropies: 0.4498, took: 97.6580s
2022-10-11 14:54:37,817 [INFO] 	Process 6 - batch 155899: mean_policy_losses: -99.664, mean_net_lifetime: 3915.1440, mean_mc_travel_dist: 1036.6554, mean_rewards: 344.4950, total_rewards: 2898.4345, mean_steps: 10.3200, mean_ecr: 0.0550 mean_entropies: 0.1261, took: 58.3305s
2022-10-11 14:54:52,254 [INFO] 	Process 2 - batch 102999: mean_policy_losses: -18.977, mean_net_lifetime: 7526.1651, mean_mc_travel_dist: 1981.2517, mean_rewards: 290.0405, total_rewards: 5559.6784, mean_steps: 25.0300, mean_ecr: 0.0383 mean_entropies: 0.3339, took: 122.8323s
2022-10-11 14:55:06,373 [INFO] 	Process 7 - batch 105299: mean_policy_losses: -288.042, mean_net_lifetime: 4347.6771, mean_mc_travel_dist: 1312.1891, mean_rewards: 211.8914, total_rewards: 3066.7525, mean_steps: 19.7600, mean_ecr: 0.0418 mean_entropies: 1.1833, took: 95.5665s
2022-10-11 14:55:37,697 [INFO] 	Process 6 - batch 155999: mean_policy_losses: -49.764, mean_net_lifetime: 4129.7191, mean_mc_travel_dist: 1082.2281, mean_rewards: 347.2170, total_rewards: 3062.0921, mean_steps: 10.8800, mean_ecr: 0.0548 mean_entropies: 0.1186, took: 59.8801s
2022-10-11 14:56:06,754 [INFO] 	Process 3 - batch 116799: mean_policy_losses: -26.718, mean_net_lifetime: 5439.9740, mean_mc_travel_dist: 1359.6927, mean_rewards: 276.4986, total_rewards: 4103.8815, mean_steps: 18.7300, mean_ecr: 0.0448 mean_entropies: 0.4325, took: 93.0332s
2022-10-11 14:56:36,007 [INFO] 	Process 7 - batch 105399: mean_policy_losses: -305.846, mean_net_lifetime: 4025.5797, mean_mc_travel_dist: 1230.3276, mean_rewards: 211.2053, total_rewards: 2831.2280, mean_steps: 18.3200, mean_ecr: 0.0420 mean_entropies: 1.2211, took: 89.6343s
2022-10-11 14:56:36,932 [INFO] 	Process 5 - batch 93999: mean_policy_losses: -67.050, mean_net_lifetime: 10167.8004, mean_mc_travel_dist: 3185.5456, mean_rewards: 268.1402, total_rewards: 7014.9289, mean_steps: 38.5600, mean_ecr: 0.0297 mean_entropies: 0.5650, took: 185.0601s
2022-10-11 14:56:37,444 [INFO] 	Process 1 - batch 96299: mean_policy_losses: 14.011, mean_net_lifetime: 6671.2106, mean_mc_travel_dist: 2041.0535, mean_rewards: 242.5866, total_rewards: 4660.5335, mean_steps: 26.6500, mean_ecr: 0.0384 mean_entropies: 0.9123, took: 127.0885s
2022-10-11 14:56:49,947 [INFO] 	Process 2 - batch 103099: mean_policy_losses: -25.983, mean_net_lifetime: 7294.0605, mean_mc_travel_dist: 1899.9945, mean_rewards: 292.3238, total_rewards: 5409.9382, mean_steps: 24.1100, mean_ecr: 0.0386 mean_entropies: 0.3263, took: 117.6921s
2022-10-11 14:57:40,269 [INFO] 	Process 3 - batch 116899: mean_policy_losses: -45.590, mean_net_lifetime: 5457.8705, mean_mc_travel_dist: 1355.8438, mean_rewards: 273.1343, total_rewards: 4127.6904, mean_steps: 19.0600, mean_ecr: 0.0450 mean_entropies: 0.4434, took: 93.5155s
2022-10-11 14:58:18,409 [INFO] 	Process 7 - batch 105499: mean_policy_losses: -222.845, mean_net_lifetime: 4626.1943, mean_mc_travel_dist: 1389.2067, mean_rewards: 207.3238, total_rewards: 3267.5694, mean_steps: 21.7800, mean_ecr: 0.0415 mean_entropies: 1.1646, took: 102.4021s
2022-10-11 14:58:45,728 [INFO] 	Process 1 - batch 96399: mean_policy_losses: 3.762, mean_net_lifetime: 6801.9052, mean_mc_travel_dist: 2012.2709, mean_rewards: 242.1402, total_rewards: 4817.1685, mean_steps: 27.2500, mean_ecr: 0.0384 mean_entropies: 0.9528, took: 128.2840s
2022-10-11 14:58:53,133 [INFO] 	Process 2 - batch 103199: mean_policy_losses: -14.180, mean_net_lifetime: 7710.5568, mean_mc_travel_dist: 2020.4834, mean_rewards: 287.4582, total_rewards: 5705.0361, mean_steps: 25.8800, mean_ecr: 0.0381 mean_entropies: 0.3425, took: 123.1870s
2022-10-11 14:59:14,691 [INFO] 	Process 3 - batch 116999: mean_policy_losses: -38.040, mean_net_lifetime: 5547.0964, mean_mc_travel_dist: 1387.9982, mean_rewards: 277.0558, total_rewards: 4184.7332, mean_steps: 19.0900, mean_ecr: 0.0446 mean_entropies: 0.4586, took: 94.4217s
2022-10-11 14:59:39,565 [INFO] 	Process 5 - batch 94099: mean_policy_losses: -10.571, mean_net_lifetime: 10573.3260, mean_mc_travel_dist: 3226.6767, mean_rewards: 265.8127, total_rewards: 7390.1737, mean_steps: 39.8800, mean_ecr: 0.0296 mean_entropies: 0.5880, took: 182.6332s
2022-10-11 14:59:46,072 [INFO] 	Process 7 - batch 105599: mean_policy_losses: -298.832, mean_net_lifetime: 4090.4797, mean_mc_travel_dist: 1215.8355, mean_rewards: 212.2180, total_rewards: 2916.4387, mean_steps: 18.4800, mean_ecr: 0.0421 mean_entropies: 1.2267, took: 87.6630s
2022-10-11 15:00:46,236 [INFO] 	Process 1 - batch 96499: mean_policy_losses: -23.191, mean_net_lifetime: 6771.6300, mean_mc_travel_dist: 2041.0494, mean_rewards: 243.9420, total_rewards: 4757.7238, mean_steps: 26.9400, mean_ecr: 0.0383 mean_entropies: 0.9250, took: 120.5072s
2022-10-11 15:00:56,942 [INFO] 	Process 2 - batch 103299: mean_policy_losses: -1.537, mean_net_lifetime: 7748.8390, mean_mc_travel_dist: 2061.9343, mean_rewards: 284.2897, total_rewards: 5705.5944, mean_steps: 26.3400, mean_ecr: 0.0379 mean_entropies: 0.3740, took: 123.8089s
2022-10-11 15:01:12,275 [INFO] 	Process 7 - batch 105699: mean_policy_losses: -296.747, mean_net_lifetime: 4033.2327, mean_mc_travel_dist: 1203.5050, mean_rewards: 207.8307, total_rewards: 2858.2020, mean_steps: 18.5600, mean_ecr: 0.0421 mean_entropies: 1.2387, took: 86.2033s
2022-10-11 15:02:37,257 [INFO] 	Process 5 - batch 94199: mean_policy_losses: -7.427, mean_net_lifetime: 10465.1135, mean_mc_travel_dist: 3232.8252, mean_rewards: 268.6426, total_rewards: 7265.5502, mean_steps: 39.2900, mean_ecr: 0.0293 mean_entropies: 0.5784, took: 177.6915s
2022-10-11 15:02:46,139 [INFO] Process 4 - epoch 69: mean_policy_losses: 110.790, mean_net_lifetime: 5619.1204, mean_mc_travel_dist: 1742.3792, mean_entropies: 0.9787, m_net_lifetime_valid: 4730.6429, took: 4574.6895s, (156.6393 / 100 batches)

2022-10-11 15:02:46,920 [INFO] 	Process 1 - batch 96599: mean_policy_losses: -52.062, mean_net_lifetime: 6603.9221, mean_mc_travel_dist: 2006.1587, mean_rewards: 240.5749, total_rewards: 4621.7458, mean_steps: 26.6400, mean_ecr: 0.0384 mean_entropies: 0.9104, took: 120.6850s
2022-10-11 15:02:49,786 [INFO] 	Process 7 - batch 105799: mean_policy_losses: -198.109, mean_net_lifetime: 4380.1548, mean_mc_travel_dist: 1324.4627, mean_rewards: 202.4113, total_rewards: 3090.8560, mean_steps: 21.1000, mean_ecr: 0.0417 mean_entropies: 1.1687, took: 97.5112s
2022-10-11 15:03:00,567 [INFO] 	Process 2 - batch 103399: mean_policy_losses: -14.321, mean_net_lifetime: 7737.4016, mean_mc_travel_dist: 2014.8662, mean_rewards: 286.1474, total_rewards: 5750.9956, mean_steps: 26.1100, mean_ecr: 0.0381 mean_entropies: 0.3359, took: 123.6233s
2022-10-11 15:04:25,930 [INFO] 	Process 7 - batch 105899: mean_policy_losses: -247.054, mean_net_lifetime: 4421.6632, mean_mc_travel_dist: 1311.2434, mean_rewards: 209.1622, total_rewards: 3144.6001, mean_steps: 20.0500, mean_ecr: 0.0418 mean_entropies: 1.2193, took: 96.1434s
2022-10-11 15:04:53,565 [INFO] 	Process 1 - batch 96699: mean_policy_losses: -42.502, mean_net_lifetime: 6605.9899, mean_mc_travel_dist: 2006.7192, mean_rewards: 236.7827, total_rewards: 4617.6604, mean_steps: 27.2700, mean_ecr: 0.0384 mean_entropies: 0.8792, took: 126.6449s
2022-10-11 15:05:05,314 [INFO] 	Process 2 - batch 103499: mean_policy_losses: -37.750, mean_net_lifetime: 7582.8953, mean_mc_travel_dist: 1980.9190, mean_rewards: 285.6786, total_rewards: 5626.5929, mean_steps: 25.6100, mean_ecr: 0.0383 mean_entropies: 0.3322, took: 124.7486s
2022-10-11 15:05:45,627 [INFO] 	Process 5 - batch 94299: mean_policy_losses: -5.621, mean_net_lifetime: 10588.2452, mean_mc_travel_dist: 3253.8096, mean_rewards: 259.9797, total_rewards: 7371.1190, mean_steps: 40.8200, mean_ecr: 0.0293 mean_entropies: 0.5823, took: 188.3702s
2022-10-11 15:06:05,116 [INFO] 	Process 4 - batch 103599: mean_policy_losses: 152.918, mean_net_lifetime: 10697.4726, mean_mc_travel_dist: 3237.6849, mean_rewards: 263.1895, total_rewards: 7485.8115, mean_steps: 44.3100, mean_ecr: 0.0387 mean_entropies: 0.5299, took: 891.8505s
2022-10-11 15:06:07,310 [INFO] Process 6 - epoch 104: mean_policy_losses: -167.921, mean_net_lifetime: 3385.3556, mean_mc_travel_dist: 1002.8638, mean_entropies: 0.4330, m_net_lifetime_valid: 4161.4616, took: 1481.1565s, (104.1271 / 100 batches)

2022-10-11 15:06:14,217 [INFO] 	Process 7 - batch 105999: mean_policy_losses: -221.536, mean_net_lifetime: 4633.2365, mean_mc_travel_dist: 1372.6180, mean_rewards: 198.5485, total_rewards: 3299.9705, mean_steps: 22.9200, mean_ecr: 0.0415 mean_entropies: 1.1969, took: 108.2865s
2022-10-11 15:06:59,836 [INFO] 	Process 1 - batch 96799: mean_policy_losses: -20.792, mean_net_lifetime: 6702.2730, mean_mc_travel_dist: 2022.7897, mean_rewards: 236.0724, total_rewards: 4701.1933, mean_steps: 27.6200, mean_ecr: 0.0384 mean_entropies: 0.9130, took: 126.2716s
2022-10-11 15:07:00,588 [INFO] 	Process 6 - batch 156099: mean_policy_losses: -94.477, mean_net_lifetime: 3716.7000, mean_mc_travel_dist: 982.5945, mean_rewards: 343.3282, total_rewards: 2779.9744, mean_steps: 9.7900, mean_ecr: 0.0549 mean_entropies: 0.1656, took: 682.8915s
2022-10-11 15:07:53,576 [INFO] 	Process 6 - batch 156199: mean_policy_losses: -100.326, mean_net_lifetime: 3743.4661, mean_mc_travel_dist: 999.1146, mean_rewards: 343.8001, total_rewards: 2777.8753, mean_steps: 9.8600, mean_ecr: 0.0553 mean_entropies: 0.1520, took: 52.9875s
2022-10-11 15:08:07,707 [INFO] 	Process 7 - batch 106099: mean_policy_losses: -146.005, mean_net_lifetime: 4881.2481, mean_mc_travel_dist: 1455.5830, mean_rewards: 200.1180, total_rewards: 3453.8049, mean_steps: 23.9100, mean_ecr: 0.0412 mean_entropies: 1.2092, took: 113.4909s
2022-10-11 15:08:50,132 [INFO] 	Process 6 - batch 156299: mean_policy_losses: -95.060, mean_net_lifetime: 3937.1521, mean_mc_travel_dist: 1042.9109, mean_rewards: 344.4505, total_rewards: 2926.0576, mean_steps: 10.3900, mean_ecr: 0.0549 mean_entropies: 0.1326, took: 56.5566s
2022-10-11 15:09:09,140 [INFO] 	Process 1 - batch 96899: mean_policy_losses: 2.266, mean_net_lifetime: 6536.0044, mean_mc_travel_dist: 1990.9419, mean_rewards: 232.8629, total_rewards: 4568.8641, mean_steps: 27.3500, mean_ecr: 0.0383 mean_entropies: 0.8827, took: 129.3036s
2022-10-11 15:09:37,400 [INFO] 	Process 5 - batch 94399: mean_policy_losses: -51.662, mean_net_lifetime: 12345.6276, mean_mc_travel_dist: 3943.4362, mean_rewards: 253.7386, total_rewards: 8439.8987, mean_steps: 50.2300, mean_ecr: 0.0286 mean_entropies: 0.5927, took: 231.7731s
2022-10-11 15:09:46,103 [INFO] 	Process 6 - batch 156399: mean_policy_losses: -86.610, mean_net_lifetime: 3975.5771, mean_mc_travel_dist: 1054.7634, mean_rewards: 344.9261, total_rewards: 2953.0295, mean_steps: 10.5000, mean_ecr: 0.0549 mean_entropies: 0.1333, took: 55.9715s
2022-10-11 15:10:06,822 [INFO] Process 3 - epoch 78: mean_policy_losses: 31.798, mean_net_lifetime: 4640.8163, mean_mc_travel_dist: 1346.3124, mean_entropies: 0.7401, m_net_lifetime_valid: 4557.5486, took: 2049.2864s, (138.9916 / 100 batches)

2022-10-11 15:10:08,110 [INFO] 	Process 7 - batch 106199: mean_policy_losses: -179.423, mean_net_lifetime: 5090.4944, mean_mc_travel_dist: 1509.8772, mean_rewards: 195.9981, total_rewards: 3605.3043, mean_steps: 25.9700, mean_ecr: 0.0409 mean_entropies: 1.2005, took: 120.4020s
2022-10-11 15:10:40,645 [INFO] 	Process 4 - batch 103699: mean_policy_losses: 140.485, mean_net_lifetime: 14265.9533, mean_mc_travel_dist: 4584.2609, mean_rewards: 253.1814, total_rewards: 9702.4100, mean_steps: 62.1600, mean_ecr: 0.0359 mean_entropies: 0.4977, took: 275.5282s
2022-10-11 15:10:44,154 [INFO] 	Process 6 - batch 156499: mean_policy_losses: -78.588, mean_net_lifetime: 4008.4777, mean_mc_travel_dist: 1059.2029, mean_rewards: 344.0464, total_rewards: 2984.9914, mean_steps: 10.6200, mean_ecr: 0.0550 mean_entropies: 0.1281, took: 58.0504s
2022-10-11 15:11:20,181 [INFO] 	Process 1 - batch 96999: mean_policy_losses: 31.689, mean_net_lifetime: 6630.1512, mean_mc_travel_dist: 1981.3849, mean_rewards: 240.1427, total_rewards: 4672.8833, mean_steps: 26.9300, mean_ecr: 0.0385 mean_entropies: 0.9125, took: 131.0396s
2022-10-11 15:11:43,120 [INFO] 	Process 6 - batch 156599: mean_policy_losses: -54.166, mean_net_lifetime: 4034.5680, mean_mc_travel_dist: 1072.6087, mean_rewards: 344.5080, total_rewards: 2978.4836, mean_steps: 10.6900, mean_ecr: 0.0548 mean_entropies: 0.1193, took: 58.9657s
2022-10-11 15:11:44,633 [INFO] 	Process 3 - batch 117099: mean_policy_losses: -45.034, mean_net_lifetime: 5445.6706, mean_mc_travel_dist: 1365.2598, mean_rewards: 276.3494, total_rewards: 4102.8039, mean_steps: 18.8200, mean_ecr: 0.0446 mean_entropies: 0.4419, took: 749.9417s
2022-10-11 15:11:59,211 [INFO] 	Process 7 - batch 106299: mean_policy_losses: -246.131, mean_net_lifetime: 4789.1683, mean_mc_travel_dist: 1412.4386, mean_rewards: 200.7631, total_rewards: 3411.8510, mean_steps: 23.1300, mean_ecr: 0.0413 mean_entropies: 1.2083, took: 111.1010s
2022-10-11 15:12:42,646 [INFO] 	Process 6 - batch 156699: mean_policy_losses: -68.245, mean_net_lifetime: 4073.2553, mean_mc_travel_dist: 1076.0692, mean_rewards: 345.3472, total_rewards: 3013.7482, mean_steps: 10.7600, mean_ecr: 0.0551 mean_entropies: 0.1220, took: 59.5259s
2022-10-11 15:13:02,351 [INFO] 	Process 5 - batch 94499: mean_policy_losses: -50.781, mean_net_lifetime: 10417.2415, mean_mc_travel_dist: 3219.2023, mean_rewards: 249.5131, total_rewards: 7228.9509, mean_steps: 42.3300, mean_ecr: 0.0290 mean_entropies: 0.5745, took: 204.9504s
2022-10-11 15:13:26,143 [INFO] 	Process 3 - batch 117199: mean_policy_losses: -34.051, mean_net_lifetime: 5609.4310, mean_mc_travel_dist: 1419.7332, mean_rewards: 270.2083, total_rewards: 4216.5857, mean_steps: 19.8200, mean_ecr: 0.0441 mean_entropies: 0.4358, took: 101.5103s
2022-10-11 15:13:31,524 [INFO] 	Process 1 - batch 97099: mean_policy_losses: 61.784, mean_net_lifetime: 6866.4271, mean_mc_travel_dist: 2026.3081, mean_rewards: 243.2982, total_rewards: 4864.8568, mean_steps: 27.4800, mean_ecr: 0.0384 mean_entropies: 0.9574, took: 131.3439s
2022-10-11 15:13:39,895 [INFO] 	Process 6 - batch 156799: mean_policy_losses: -85.688, mean_net_lifetime: 3941.1887, mean_mc_travel_dist: 1040.8941, mean_rewards: 344.5899, total_rewards: 2927.8768, mean_steps: 10.3900, mean_ecr: 0.0547 mean_entropies: 0.1314, took: 57.2484s
2022-10-11 15:13:48,516 [INFO] 	Process 7 - batch 106399: mean_policy_losses: -254.454, mean_net_lifetime: 4693.2006, mean_mc_travel_dist: 1414.5772, mean_rewards: 199.8356, total_rewards: 3315.6945, mean_steps: 22.7200, mean_ecr: 0.0415 mean_entropies: 1.2472, took: 109.3063s
2022-10-11 15:14:33,937 [INFO] 	Process 6 - batch 156899: mean_policy_losses: -91.935, mean_net_lifetime: 3827.3262, mean_mc_travel_dist: 1015.2570, mean_rewards: 342.4875, total_rewards: 2845.9022, mean_steps: 10.1500, mean_ecr: 0.0552 mean_entropies: 0.1472, took: 54.0433s
2022-10-11 15:15:02,547 [INFO] 	Process 3 - batch 117299: mean_policy_losses: -42.332, mean_net_lifetime: 5523.8203, mean_mc_travel_dist: 1370.2891, mean_rewards: 274.3941, total_rewards: 4182.4666, mean_steps: 19.2800, mean_ecr: 0.0448 mean_entropies: 0.4247, took: 96.4036s
2022-10-11 15:15:27,583 [INFO] 	Process 6 - batch 156999: mean_policy_losses: -107.395, mean_net_lifetime: 3849.8098, mean_mc_travel_dist: 1015.0115, mean_rewards: 345.2287, total_rewards: 2869.0471, mean_steps: 10.1200, mean_ecr: 0.0549 mean_entropies: 0.1411, took: 53.6454s
2022-10-11 15:15:31,707 [INFO] 	Process 7 - batch 106499: mean_policy_losses: -280.580, mean_net_lifetime: 4618.3076, mean_mc_travel_dist: 1385.6482, mean_rewards: 200.2897, total_rewards: 3265.8290, mean_steps: 22.1300, mean_ecr: 0.0413 mean_entropies: 1.1905, took: 103.1895s
2022-10-11 15:15:34,992 [INFO] 	Process 1 - batch 97199: mean_policy_losses: 63.527, mean_net_lifetime: 6861.2597, mean_mc_travel_dist: 2050.6367, mean_rewards: 254.0466, total_rewards: 4838.0812, mean_steps: 26.1200, mean_ecr: 0.0384 mean_entropies: 0.9520, took: 123.4687s
2022-10-11 15:15:37,001 [INFO] 	Process 4 - batch 103799: mean_policy_losses: 166.399, mean_net_lifetime: 15358.8904, mean_mc_travel_dist: 4879.0661, mean_rewards: 253.5284, total_rewards: 10503.6233, mean_steps: 66.3700, mean_ecr: 0.0358 mean_entropies: 0.5251, took: 296.3573s
2022-10-11 15:16:17,855 [INFO] Process 2 - epoch 69: mean_policy_losses: -2.943, mean_net_lifetime: 5657.5803, mean_mc_travel_dist: 1736.7539, mean_entropies: 0.7599, m_net_lifetime_valid: 4332.1534, took: 2511.6639s, (157.4427 / 100 batches)

2022-10-11 15:16:22,319 [INFO] 	Process 6 - batch 157099: mean_policy_losses: -78.250, mean_net_lifetime: 3928.3494, mean_mc_travel_dist: 1032.2237, mean_rewards: 343.1209, total_rewards: 2919.5255, mean_steps: 10.4000, mean_ecr: 0.0551 mean_entropies: 0.1383, took: 54.7362s
2022-10-11 15:16:37,015 [INFO] 	Process 3 - batch 117399: mean_policy_losses: -60.230, mean_net_lifetime: 5448.8287, mean_mc_travel_dist: 1372.3325, mean_rewards: 270.6664, total_rewards: 4097.3481, mean_steps: 19.2600, mean_ecr: 0.0449 mean_entropies: 0.4497, took: 94.4686s
2022-10-11 15:17:18,278 [INFO] 	Process 6 - batch 157199: mean_policy_losses: -85.897, mean_net_lifetime: 3965.7911, mean_mc_travel_dist: 1042.6577, mean_rewards: 343.2723, total_rewards: 2946.5142, mean_steps: 10.5000, mean_ecr: 0.0550 mean_entropies: 0.1239, took: 55.9593s
2022-10-11 15:17:37,458 [INFO] 	Process 1 - batch 97299: mean_policy_losses: 7.705, mean_net_lifetime: 6745.9110, mean_mc_travel_dist: 2052.9918, mean_rewards: 246.6295, total_rewards: 4720.8203, mean_steps: 26.5100, mean_ecr: 0.0382 mean_entropies: 0.9099, took: 122.4655s
2022-10-11 15:18:08,424 [INFO] 	Process 3 - batch 117499: mean_policy_losses: -50.890, mean_net_lifetime: 5336.1988, mean_mc_travel_dist: 1326.2098, mean_rewards: 277.8756, total_rewards: 4034.4993, mean_steps: 18.2600, mean_ecr: 0.0450 mean_entropies: 0.4440, took: 91.4086s
2022-10-11 15:18:11,655 [INFO] 	Process 6 - batch 157299: mean_policy_losses: -91.986, mean_net_lifetime: 3781.1397, mean_mc_travel_dist: 993.5055, mean_rewards: 344.5063, total_rewards: 2809.7594, mean_steps: 9.9400, mean_ecr: 0.0551 mean_entropies: 0.1493, took: 53.3773s
2022-10-11 15:18:12,206 [INFO] 	Process 2 - batch 103599: mean_policy_losses: -54.154, mean_net_lifetime: 7182.8905, mean_mc_travel_dist: 1870.4748, mean_rewards: 285.5368, total_rewards: 5342.6034, mean_steps: 24.2400, mean_ecr: 0.0387 mean_entropies: 0.3298, took: 786.8921s
2022-10-11 15:19:05,958 [INFO] 	Process 6 - batch 157399: mean_policy_losses: -76.391, mean_net_lifetime: 3947.9195, mean_mc_travel_dist: 1055.4557, mean_rewards: 342.8987, total_rewards: 2918.4221, mean_steps: 10.4900, mean_ecr: 0.0549 mean_entropies: 0.1400, took: 54.3024s
2022-10-11 15:19:25,625 [INFO] 	Process 4 - batch 103899: mean_policy_losses: 66.408, mean_net_lifetime: 12416.9485, mean_mc_travel_dist: 3821.5812, mean_rewards: 263.3453, total_rewards: 8622.1716, mean_steps: 51.6900, mean_ecr: 0.0384 mean_entropies: 0.5329, took: 228.6232s
2022-10-11 15:19:39,769 [INFO] 	Process 1 - batch 97399: mean_policy_losses: 11.597, mean_net_lifetime: 6667.5607, mean_mc_travel_dist: 2005.8970, mean_rewards: 248.6293, total_rewards: 4690.0334, mean_steps: 25.9700, mean_ecr: 0.0385 mean_entropies: 0.9565, took: 122.3102s
2022-10-11 15:19:40,609 [INFO] 	Process 3 - batch 117599: mean_policy_losses: -36.782, mean_net_lifetime: 5518.7993, mean_mc_travel_dist: 1402.2724, mean_rewards: 282.7501, total_rewards: 4142.9971, mean_steps: 18.5900, mean_ecr: 0.0445 mean_entropies: 0.4700, took: 92.1847s
2022-10-11 15:20:00,484 [INFO] 	Process 6 - batch 157499: mean_policy_losses: -103.618, mean_net_lifetime: 3926.1518, mean_mc_travel_dist: 1048.6351, mean_rewards: 344.2967, total_rewards: 2904.3422, mean_steps: 10.3500, mean_ecr: 0.0550 mean_entropies: 0.1378, took: 54.5256s
2022-10-11 15:20:15,753 [INFO] 	Process 2 - batch 103699: mean_policy_losses: -10.336, mean_net_lifetime: 7744.9970, mean_mc_travel_dist: 2005.4654, mean_rewards: 287.1467, total_rewards: 5761.2902, mean_steps: 26.0600, mean_ecr: 0.0382 mean_entropies: 0.3279, took: 123.5473s
2022-10-11 15:21:09,345 [INFO] 	Process 3 - batch 117699: mean_policy_losses: -72.629, mean_net_lifetime: 5379.9901, mean_mc_travel_dist: 1365.1041, mean_rewards: 279.7277, total_rewards: 4045.0111, mean_steps: 18.2900, mean_ecr: 0.0445 mean_entropies: 0.4765, took: 88.7363s
2022-10-11 15:21:43,371 [INFO] 	Process 1 - batch 97499: mean_policy_losses: 9.515, mean_net_lifetime: 6815.4689, mean_mc_travel_dist: 2040.9507, mean_rewards: 245.1959, total_rewards: 4803.3602, mean_steps: 26.9200, mean_ecr: 0.0383 mean_entropies: 0.9306, took: 123.6027s
2022-10-11 15:22:17,713 [INFO] 	Process 2 - batch 103799: mean_policy_losses: -29.688, mean_net_lifetime: 7648.6848, mean_mc_travel_dist: 1981.5427, mean_rewards: 281.6068, total_rewards: 5689.7530, mean_steps: 26.2400, mean_ecr: 0.0382 mean_entropies: 0.3150, took: 121.9582s
2022-10-11 15:22:35,381 [INFO] 	Process 3 - batch 117799: mean_policy_losses: -59.994, mean_net_lifetime: 5371.0273, mean_mc_travel_dist: 1374.9326, mean_rewards: 274.2118, total_rewards: 4023.0206, mean_steps: 18.6600, mean_ecr: 0.0444 mean_entropies: 0.4773, took: 86.0363s
2022-10-11 15:23:41,208 [INFO] 	Process 4 - batch 103999: mean_policy_losses: 83.283, mean_net_lifetime: 14246.3551, mean_mc_travel_dist: 4461.1214, mean_rewards: 259.2709, total_rewards: 9808.2791, mean_steps: 60.3700, mean_ecr: 0.0365 mean_entropies: 0.4913, took: 255.5822s

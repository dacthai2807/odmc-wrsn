2022-10-08 22:39:44,877 [INFO] Running on device: cuda
2022-10-08 22:39:44,878 [INFO] Log dir: logs/test1_08_10_2022_22_39_44
2022-10-08 22:39:44,878 [INFO] Running problem with 20 sensors 10 targets: (checkpoint: None, seed : 123, config: configs/test1.yml)
2022-10-08 22:41:26,579 [INFO] 	Process 1 - batch 99: mean_policy_losses: 230.936, mean_net_lifetime: 2700.7804, mean_mc_travel_dist: 1801.0535, mean_rewards: 165.0925, total_rewards: 975.0357, mean_steps: 15.1100, mean_ecr: 0.0415 mean_entropies: 2.9860, took: 81.5625s
2022-10-08 22:41:28,131 [INFO] 	Process 3 - batch 99: mean_policy_losses: 223.532, mean_net_lifetime: 2702.8386, mean_mc_travel_dist: 1838.6255, mean_rewards: 170.0474, total_rewards: 944.7706, mean_steps: 15.0000, mean_ecr: 0.0416 mean_entropies: 2.9855, took: 82.8871s
2022-10-08 22:41:32,498 [INFO] 	Process 4 - batch 99: mean_policy_losses: 256.117, mean_net_lifetime: 2896.3437, mean_mc_travel_dist: 1927.2215, mean_rewards: 170.9057, total_rewards: 1035.2670, mean_steps: 15.8200, mean_ecr: 0.0414 mean_entropies: 2.9834, took: 87.3342s
2022-10-08 22:41:33,337 [INFO] 	Process 6 - batch 99: mean_policy_losses: 222.430, mean_net_lifetime: 2878.8026, mean_mc_travel_dist: 1960.7915, mean_rewards: 165.9066, total_rewards: 994.8207, mean_steps: 16.2000, mean_ecr: 0.0411 mean_entropies: 2.9829, took: 88.0220s
2022-10-08 22:41:34,063 [INFO] 	Process 0 - batch 99: mean_policy_losses: 232.305, mean_net_lifetime: 2874.8078, mean_mc_travel_dist: 1949.2340, mean_rewards: 164.5427, total_rewards: 1007.0683, mean_steps: 16.3800, mean_ecr: 0.0416 mean_entropies: 2.9834, took: 89.0146s
2022-10-08 22:41:34,221 [INFO] 	Process 2 - batch 99: mean_policy_losses: 258.346, mean_net_lifetime: 2918.4187, mean_mc_travel_dist: 1953.6970, mean_rewards: 171.1499, total_rewards: 1053.2623, mean_steps: 16.2100, mean_ecr: 0.0414 mean_entropies: 2.9841, took: 89.1792s
2022-10-08 22:41:35,182 [INFO] 	Process 5 - batch 99: mean_policy_losses: 250.731, mean_net_lifetime: 2956.7210, mean_mc_travel_dist: 1924.5959, mean_rewards: 172.5820, total_rewards: 1105.8791, mean_steps: 16.1000, mean_ecr: 0.0411 mean_entropies: 2.9820, took: 90.0116s
2022-10-08 22:42:48,905 [INFO] 	Process 3 - batch 199: mean_policy_losses: -26.430, mean_net_lifetime: 2873.3144, mean_mc_travel_dist: 1996.5468, mean_rewards: 166.9718, total_rewards: 966.3370, mean_steps: 15.9800, mean_ecr: 0.0401 mean_entropies: 2.9594, took: 80.7740s
2022-10-08 22:42:56,125 [INFO] 	Process 1 - batch 199: mean_policy_losses: 76.776, mean_net_lifetime: 3151.7334, mean_mc_travel_dist: 2132.8897, mean_rewards: 172.3898, total_rewards: 1094.4705, mean_steps: 17.5900, mean_ecr: 0.0400 mean_entropies: 2.9583, took: 89.5461s
2022-10-08 22:42:58,473 [INFO] 	Process 6 - batch 199: mean_policy_losses: 14.636, mean_net_lifetime: 2895.1857, mean_mc_travel_dist: 2006.7670, mean_rewards: 165.4615, total_rewards: 976.6081, mean_steps: 16.3900, mean_ecr: 0.0401 mean_entropies: 2.9573, took: 85.1363s
2022-10-08 22:42:58,672 [INFO] 	Process 2 - batch 199: mean_policy_losses: 59.950, mean_net_lifetime: 2901.3417, mean_mc_travel_dist: 1942.8593, mean_rewards: 171.5794, total_rewards: 1033.8307, mean_steps: 16.2500, mean_ecr: 0.0402 mean_entropies: 2.9579, took: 84.4522s
2022-10-08 22:42:58,893 [INFO] 	Process 4 - batch 199: mean_policy_losses: 94.180, mean_net_lifetime: 3110.5401, mean_mc_travel_dist: 2063.6007, mean_rewards: 173.0172, total_rewards: 1141.8090, mean_steps: 16.7300, mean_ecr: 0.0399 mean_entropies: 2.9581, took: 86.3952s
2022-10-08 22:42:59,242 [INFO] 	Process 5 - batch 199: mean_policy_losses: 36.327, mean_net_lifetime: 2875.0320, mean_mc_travel_dist: 1914.5902, mean_rewards: 177.5189, total_rewards: 1022.9570, mean_steps: 15.6300, mean_ecr: 0.0399 mean_entropies: 2.9592, took: 84.0606s
2022-10-08 22:43:01,403 [INFO] 	Process 0 - batch 199: mean_policy_losses: 124.148, mean_net_lifetime: 3020.0064, mean_mc_travel_dist: 1991.6820, mean_rewards: 171.5945, total_rewards: 1111.5401, mean_steps: 16.4500, mean_ecr: 0.0399 mean_entropies: 2.9573, took: 87.3390s
2022-10-08 22:44:08,049 [INFO] 	Process 3 - batch 299: mean_policy_losses: 77.745, mean_net_lifetime: 2870.4709, mean_mc_travel_dist: 1977.1254, mean_rewards: 176.4248, total_rewards: 991.5754, mean_steps: 15.3000, mean_ecr: 0.0396 mean_entropies: 2.8560, took: 79.1433s
2022-10-08 22:44:14,264 [INFO] 	Process 1 - batch 299: mean_policy_losses: 56.067, mean_net_lifetime: 2844.0278, mean_mc_travel_dist: 1911.3898, mean_rewards: 179.9350, total_rewards: 1027.9864, mean_steps: 15.1700, mean_ecr: 0.0396 mean_entropies: 2.8164, took: 78.1393s
2022-10-08 22:44:16,526 [INFO] 	Process 0 - batch 299: mean_policy_losses: 49.119, mean_net_lifetime: 2762.4466, mean_mc_travel_dist: 1836.2165, mean_rewards: 186.2536, total_rewards: 1007.6829, mean_steps: 14.2900, mean_ecr: 0.0398 mean_entropies: 2.7988, took: 75.1237s
2022-10-08 22:44:16,870 [INFO] 	Process 4 - batch 299: mean_policy_losses: 53.977, mean_net_lifetime: 2786.8142, mean_mc_travel_dist: 1919.2530, mean_rewards: 178.9321, total_rewards: 949.9531, mean_steps: 14.8500, mean_ecr: 0.0397 mean_entropies: 2.7978, took: 77.9771s
2022-10-08 22:44:18,212 [INFO] 	Process 6 - batch 299: mean_policy_losses: 92.576, mean_net_lifetime: 2949.5272, mean_mc_travel_dist: 1924.0007, mean_rewards: 187.7333, total_rewards: 1101.3958, mean_steps: 14.9600, mean_ecr: 0.0394 mean_entropies: 2.7985, took: 79.7395s
2022-10-08 22:44:19,310 [INFO] 	Process 5 - batch 299: mean_policy_losses: 114.558, mean_net_lifetime: 3118.0385, mean_mc_travel_dist: 1984.0366, mean_rewards: 197.4352, total_rewards: 1212.6781, mean_steps: 15.3900, mean_ecr: 0.0393 mean_entropies: 2.7797, took: 80.0673s
2022-10-08 22:44:20,242 [INFO] 	Process 2 - batch 299: mean_policy_losses: 78.665, mean_net_lifetime: 2952.7480, mean_mc_travel_dist: 1959.9730, mean_rewards: 183.6228, total_rewards: 1092.8392, mean_steps: 15.4500, mean_ecr: 0.0395 mean_entropies: 2.7721, took: 81.5696s
2022-10-08 22:45:03,465 [INFO] 	Process 3 - batch 399: mean_policy_losses: -72.074, mean_net_lifetime: 2516.2804, mean_mc_travel_dist: 1444.8882, mean_rewards: 234.3106, total_rewards: 1192.4242, mean_steps: 10.1100, mean_ecr: 0.0392 mean_entropies: 2.0797, took: 55.4168s
2022-10-08 22:45:08,383 [INFO] 	Process 1 - batch 399: mean_policy_losses: -88.160, mean_net_lifetime: 2514.6040, mean_mc_travel_dist: 1424.3485, mean_rewards: 237.9327, total_rewards: 1199.6766, mean_steps: 10.0800, mean_ecr: 0.0391 mean_entropies: 2.0489, took: 54.1187s
2022-10-08 22:45:12,943 [INFO] 	Process 2 - batch 399: mean_policy_losses: -91.101, mean_net_lifetime: 2472.2683, mean_mc_travel_dist: 1333.8969, mean_rewards: 247.7895, total_rewards: 1246.2922, mean_steps: 9.4500, mean_ecr: 0.0389 mean_entropies: 2.0186, took: 52.7004s
2022-10-08 22:45:13,596 [INFO] 	Process 4 - batch 399: mean_policy_losses: -64.794, mean_net_lifetime: 2547.9378, mean_mc_travel_dist: 1399.4977, mean_rewards: 237.2542, total_rewards: 1261.4299, mean_steps: 10.2100, mean_ecr: 0.0393 mean_entropies: 2.0188, took: 56.7266s
2022-10-08 22:45:14,618 [INFO] 	Process 0 - batch 399: mean_policy_losses: -57.097, mean_net_lifetime: 2621.9386, mean_mc_travel_dist: 1452.6671, mean_rewards: 236.2646, total_rewards: 1287.8865, mean_steps: 10.5000, mean_ecr: 0.0391 mean_entropies: 2.0507, took: 58.0921s
2022-10-08 22:45:15,420 [INFO] 	Process 6 - batch 399: mean_policy_losses: -31.382, mean_net_lifetime: 2681.6970, mean_mc_travel_dist: 1455.2252, mean_rewards: 242.3224, total_rewards: 1339.9787, mean_steps: 10.4800, mean_ecr: 0.0388 mean_entropies: 2.0156, took: 57.2074s
2022-10-08 22:45:16,774 [INFO] 	Process 5 - batch 399: mean_policy_losses: -40.621, mean_net_lifetime: 2622.2486, mean_mc_travel_dist: 1441.1244, mean_rewards: 235.4368, total_rewards: 1301.6444, mean_steps: 10.5200, mean_ecr: 0.0391 mean_entropies: 2.0126, took: 57.4651s
2022-10-08 22:45:55,957 [INFO] 	Process 3 - batch 499: mean_policy_losses: -127.516, mean_net_lifetime: 2403.6206, mean_mc_travel_dist: 1209.2967, mean_rewards: 240.0905, total_rewards: 1279.1021, mean_steps: 9.4700, mean_ecr: 0.0422 mean_entropies: 2.1669, took: 52.4918s
2022-10-08 22:46:00,074 [INFO] 	Process 1 - batch 499: mean_policy_losses: -109.661, mean_net_lifetime: 2436.6715, mean_mc_travel_dist: 1211.5437, mean_rewards: 239.2287, total_rewards: 1338.7427, mean_steps: 9.5900, mean_ecr: 0.0419 mean_entropies: 2.2050, took: 51.6909s
2022-10-08 22:46:04,798 [INFO] 	Process 4 - batch 499: mean_policy_losses: -111.645, mean_net_lifetime: 2411.3577, mean_mc_travel_dist: 1194.6441, mean_rewards: 241.0496, total_rewards: 1320.6565, mean_steps: 9.2700, mean_ecr: 0.0420 mean_entropies: 2.2407, took: 51.2021s
2022-10-08 22:46:07,664 [INFO] 	Process 5 - batch 499: mean_policy_losses: -83.537, mean_net_lifetime: 2385.4119, mean_mc_travel_dist: 1164.6952, mean_rewards: 242.5726, total_rewards: 1325.6664, mean_steps: 9.1800, mean_ecr: 0.0419 mean_entropies: 2.2471, took: 50.8901s
2022-10-08 22:46:08,710 [INFO] 	Process 0 - batch 499: mean_policy_losses: -72.569, mean_net_lifetime: 2442.1252, mean_mc_travel_dist: 1182.0114, mean_rewards: 243.3649, total_rewards: 1366.8279, mean_steps: 9.3100, mean_ecr: 0.0424 mean_entropies: 2.2248, took: 54.0916s
2022-10-08 22:46:09,197 [INFO] 	Process 2 - batch 499: mean_policy_losses: -41.473, mean_net_lifetime: 2610.4144, mean_mc_travel_dist: 1255.0379, mean_rewards: 239.0454, total_rewards: 1435.7194, mean_steps: 10.1500, mean_ecr: 0.0419 mean_entropies: 2.2596, took: 56.2548s
2022-10-08 22:46:10,154 [INFO] 	Process 6 - batch 499: mean_policy_losses: -55.299, mean_net_lifetime: 2525.8073, mean_mc_travel_dist: 1272.2811, mean_rewards: 232.8517, total_rewards: 1357.3396, mean_steps: 10.1000, mean_ecr: 0.0420 mean_entropies: 2.2488, took: 54.7349s
2022-10-08 22:46:57,445 [INFO] 	Process 3 - batch 599: mean_policy_losses: 17.517, mean_net_lifetime: 2802.3908, mean_mc_travel_dist: 1328.9821, mean_rewards: 236.6649, total_rewards: 1563.2308, mean_steps: 11.2600, mean_ecr: 0.0399 mean_entropies: 2.4027, took: 61.4892s
2022-10-08 22:47:00,812 [INFO] 	Process 1 - batch 599: mean_policy_losses: -30.377, mean_net_lifetime: 2818.6034, mean_mc_travel_dist: 1359.1096, mean_rewards: 232.9566, total_rewards: 1536.7984, mean_steps: 11.5000, mean_ecr: 0.0395 mean_entropies: 2.4170, took: 60.7387s
2022-10-08 22:47:04,235 [INFO] 	Process 4 - batch 599: mean_policy_losses: -55.302, mean_net_lifetime: 2755.9287, mean_mc_travel_dist: 1336.8380, mean_rewards: 239.1459, total_rewards: 1520.6229, mean_steps: 11.0700, mean_ecr: 0.0399 mean_entropies: 2.4128, took: 59.4364s
2022-10-08 22:47:07,328 [INFO] 	Process 5 - batch 599: mean_policy_losses: -61.015, mean_net_lifetime: 2715.0070, mean_mc_travel_dist: 1267.6172, mean_rewards: 233.4119, total_rewards: 1530.5242, mean_steps: 11.0700, mean_ecr: 0.0399 mean_entropies: 2.4108, took: 59.6640s
2022-10-08 22:47:10,556 [INFO] 	Process 2 - batch 599: mean_policy_losses: -88.752, mean_net_lifetime: 2736.8577, mean_mc_travel_dist: 1329.6675, mean_rewards: 234.3175, total_rewards: 1495.6631, mean_steps: 11.2400, mean_ecr: 0.0399 mean_entropies: 2.4182, took: 61.3584s
2022-10-08 22:47:12,798 [INFO] 	Process 0 - batch 599: mean_policy_losses: -10.739, mean_net_lifetime: 2870.4436, mean_mc_travel_dist: 1348.5712, mean_rewards: 230.0977, total_rewards: 1613.9691, mean_steps: 11.7300, mean_ecr: 0.0398 mean_entropies: 2.4236, took: 64.0877s
2022-10-08 22:47:15,380 [INFO] 	Process 6 - batch 599: mean_policy_losses: 18.719, mean_net_lifetime: 2908.8839, mean_mc_travel_dist: 1368.9395, mean_rewards: 229.5275, total_rewards: 1617.4957, mean_steps: 12.0700, mean_ecr: 0.0398 mean_entropies: 2.4184, took: 65.2250s
2022-10-08 22:47:57,140 [INFO] 	Process 3 - batch 699: mean_policy_losses: -44.374, mean_net_lifetime: 2703.9410, mean_mc_travel_dist: 1238.8201, mean_rewards: 234.2630, total_rewards: 1553.8611, mean_steps: 11.1300, mean_ecr: 0.0392 mean_entropies: 2.4979, took: 59.6948s
2022-10-08 22:48:01,418 [INFO] 	Process 1 - batch 699: mean_policy_losses: -54.248, mean_net_lifetime: 2740.9396, mean_mc_travel_dist: 1260.6202, mean_rewards: 235.5307, total_rewards: 1549.4753, mean_steps: 11.4900, mean_ecr: 0.0388 mean_entropies: 2.5144, took: 60.6057s
2022-10-08 22:48:04,999 [INFO] 	Process 4 - batch 699: mean_policy_losses: -28.232, mean_net_lifetime: 2722.0124, mean_mc_travel_dist: 1255.4082, mean_rewards: 232.4632, total_rewards: 1554.1425, mean_steps: 11.0700, mean_ecr: 0.0387 mean_entropies: 2.5384, took: 60.7638s
2022-10-08 22:48:09,571 [INFO] 	Process 5 - batch 699: mean_policy_losses: -94.035, mean_net_lifetime: 2719.7435, mean_mc_travel_dist: 1267.4782, mean_rewards: 228.2802, total_rewards: 1533.3200, mean_steps: 11.5300, mean_ecr: 0.0390 mean_entropies: 2.5239, took: 62.2425s
2022-10-08 22:48:12,764 [INFO] 	Process 2 - batch 699: mean_policy_losses: -17.879, mean_net_lifetime: 2705.3304, mean_mc_travel_dist: 1221.9745, mean_rewards: 230.7194, total_rewards: 1572.6999, mean_steps: 11.2300, mean_ecr: 0.0389 mean_entropies: 2.5187, took: 62.2088s
2022-10-08 22:48:14,138 [INFO] 	Process 0 - batch 699: mean_policy_losses: -42.506, mean_net_lifetime: 2677.6287, mean_mc_travel_dist: 1228.4828, mean_rewards: 233.8504, total_rewards: 1531.2228, mean_steps: 11.2100, mean_ecr: 0.0389 mean_entropies: 2.5304, took: 61.3405s
2022-10-08 22:48:17,007 [INFO] 	Process 6 - batch 699: mean_policy_losses: -1.880, mean_net_lifetime: 2756.0547, mean_mc_travel_dist: 1257.4265, mean_rewards: 232.2113, total_rewards: 1566.1690, mean_steps: 11.3700, mean_ecr: 0.0389 mean_entropies: 2.5343, took: 61.6281s
2022-10-08 22:49:03,139 [INFO] 	Process 1 - batch 799: mean_policy_losses: -62.745, mean_net_lifetime: 2824.1994, mean_mc_travel_dist: 1264.4565, mean_rewards: 231.5179, total_rewards: 1626.2701, mean_steps: 11.6700, mean_ecr: 0.0381 mean_entropies: 2.5631, took: 61.7210s
2022-10-08 22:49:07,865 [INFO] 	Process 3 - batch 799: mean_policy_losses: 26.274, mean_net_lifetime: 3104.2439, mean_mc_travel_dist: 1418.1163, mean_rewards: 227.6502, total_rewards: 1775.8697, mean_steps: 13.3900, mean_ecr: 0.0377 mean_entropies: 2.5558, took: 70.7249s
2022-10-08 22:49:08,129 [INFO] 	Process 4 - batch 799: mean_policy_losses: -96.049, mean_net_lifetime: 2767.8920, mean_mc_travel_dist: 1256.0542, mean_rewards: 232.1316, total_rewards: 1592.8299, mean_steps: 11.6600, mean_ecr: 0.0379 mean_entropies: 2.5398, took: 63.1297s
2022-10-08 22:49:16,578 [INFO] 	Process 2 - batch 799: mean_policy_losses: -86.105, mean_net_lifetime: 2818.7072, mean_mc_travel_dist: 1286.9632, mean_rewards: 230.7510, total_rewards: 1613.8262, mean_steps: 11.7800, mean_ecr: 0.0377 mean_entropies: 2.5285, took: 63.8141s
2022-10-08 22:49:16,704 [INFO] 	Process 5 - batch 799: mean_policy_losses: -35.593, mean_net_lifetime: 2915.2231, mean_mc_travel_dist: 1312.1384, mean_rewards: 224.4187, total_rewards: 1687.4997, mean_steps: 12.4700, mean_ecr: 0.0375 mean_entropies: 2.5413, took: 67.1336s
2022-10-08 22:49:18,841 [INFO] 	Process 0 - batch 799: mean_policy_losses: -46.222, mean_net_lifetime: 2831.4544, mean_mc_travel_dist: 1288.7401, mean_rewards: 229.5154, total_rewards: 1622.1608, mean_steps: 11.9100, mean_ecr: 0.0384 mean_entropies: 2.5517, took: 64.7032s
2022-10-08 22:49:20,842 [INFO] 	Process 6 - batch 799: mean_policy_losses: -94.641, mean_net_lifetime: 2742.8395, mean_mc_travel_dist: 1244.5322, mean_rewards: 224.8623, total_rewards: 1589.2508, mean_steps: 11.6300, mean_ecr: 0.0379 mean_entropies: 2.5300, took: 63.8350s
2022-10-08 22:50:00,224 [INFO] 	Process 1 - batch 899: mean_policy_losses: -123.141, mean_net_lifetime: 2533.5218, mean_mc_travel_dist: 1110.6961, mean_rewards: 229.0991, total_rewards: 1488.1557, mean_steps: 10.7100, mean_ecr: 0.0396 mean_entropies: 2.4694, took: 57.0850s
2022-10-08 22:50:08,756 [INFO] 	Process 3 - batch 899: mean_policy_losses: -18.416, mean_net_lifetime: 2656.5503, mean_mc_travel_dist: 1149.2210, mean_rewards: 225.3997, total_rewards: 1582.8123, mean_steps: 11.3000, mean_ecr: 0.0394 mean_entropies: 2.4907, took: 60.8907s
2022-10-08 22:50:10,765 [INFO] 	Process 4 - batch 899: mean_policy_losses: -39.136, mean_net_lifetime: 2693.6738, mean_mc_travel_dist: 1188.4464, mean_rewards: 223.0885, total_rewards: 1572.6338, mean_steps: 11.6000, mean_ecr: 0.0399 mean_entropies: 2.4945, took: 62.6370s
2022-10-08 22:50:16,374 [INFO] 	Process 2 - batch 899: mean_policy_losses: -48.609, mean_net_lifetime: 2642.7829, mean_mc_travel_dist: 1132.4324, mean_rewards: 232.1438, total_rewards: 1583.7289, mean_steps: 10.9000, mean_ecr: 0.0400 mean_entropies: 2.5114, took: 59.7957s
2022-10-08 22:50:16,834 [INFO] 	Process 5 - batch 899: mean_policy_losses: -4.543, mean_net_lifetime: 2678.5378, mean_mc_travel_dist: 1162.8182, mean_rewards: 233.2464, total_rewards: 1588.9544, mean_steps: 10.9500, mean_ecr: 0.0399 mean_entropies: 2.5219, took: 60.1301s
2022-10-08 22:50:18,066 [INFO] 	Process 0 - batch 899: mean_policy_losses: -16.820, mean_net_lifetime: 2616.6975, mean_mc_travel_dist: 1129.3813, mean_rewards: 231.2450, total_rewards: 1567.5428, mean_steps: 10.9700, mean_ecr: 0.0396 mean_entropies: 2.5075, took: 59.2249s
2022-10-08 22:50:22,422 [INFO] 	Process 6 - batch 899: mean_policy_losses: 31.472, mean_net_lifetime: 2737.6880, mean_mc_travel_dist: 1166.2696, mean_rewards: 226.3112, total_rewards: 1648.6423, mean_steps: 11.3500, mean_ecr: 0.0398 mean_entropies: 2.5623, took: 61.5798s
2022-10-08 22:51:03,787 [INFO] 	Process 1 - batch 999: mean_policy_losses: -3.752, mean_net_lifetime: 2753.1890, mean_mc_travel_dist: 1219.4605, mean_rewards: 220.0325, total_rewards: 1606.8728, mean_steps: 12.0100, mean_ecr: 0.0400 mean_entropies: 2.5209, took: 63.5632s
2022-10-08 22:51:13,184 [INFO] 	Process 3 - batch 999: mean_policy_losses: -39.195, mean_net_lifetime: 2804.3720, mean_mc_travel_dist: 1259.9061, mean_rewards: 218.7238, total_rewards: 1617.0523, mean_steps: 12.1000, mean_ecr: 0.0401 mean_entropies: 2.5136, took: 64.4279s
2022-10-08 22:51:14,494 [INFO] 	Process 4 - batch 999: mean_policy_losses: -44.085, mean_net_lifetime: 2740.5907, mean_mc_travel_dist: 1218.9531, mean_rewards: 221.3989, total_rewards: 1588.1388, mean_steps: 11.5700, mean_ecr: 0.0400 mean_entropies: 2.5213, took: 63.7285s
2022-10-08 22:51:20,139 [INFO] 	Process 2 - batch 999: mean_policy_losses: -24.590, mean_net_lifetime: 2782.8991, mean_mc_travel_dist: 1228.3339, mean_rewards: 225.4994, total_rewards: 1637.0201, mean_steps: 11.6600, mean_ecr: 0.0400 mean_entropies: 2.5417, took: 63.7650s
2022-10-08 22:51:25,582 [INFO] 	Process 0 - batch 999: mean_policy_losses: -15.195, mean_net_lifetime: 2853.4112, mean_mc_travel_dist: 1247.4282, mean_rewards: 216.7771, total_rewards: 1676.3248, mean_steps: 12.5900, mean_ecr: 0.0406 mean_entropies: 2.4882, took: 67.5160s
2022-10-08 22:51:26,372 [INFO] 	Process 5 - batch 999: mean_policy_losses: 9.194, mean_net_lifetime: 3003.5868, mean_mc_travel_dist: 1334.0891, mean_rewards: 222.5106, total_rewards: 1731.7113, mean_steps: 13.0300, mean_ecr: 0.0399 mean_entropies: 2.5309, took: 69.5378s
2022-10-08 22:51:29,403 [INFO] 	Process 6 - batch 999: mean_policy_losses: 13.920, mean_net_lifetime: 2949.6745, mean_mc_travel_dist: 1293.0904, mean_rewards: 222.6898, total_rewards: 1730.5729, mean_steps: 12.5700, mean_ecr: 0.0403 mean_entropies: 2.5202, took: 66.9806s
2022-10-08 22:52:05,529 [INFO] 	Process 1 - batch 1099: mean_policy_losses: -116.085, mean_net_lifetime: 2799.2632, mean_mc_travel_dist: 1181.4993, mean_rewards: 232.8137, total_rewards: 1693.6892, mean_steps: 11.6900, mean_ecr: 0.0405 mean_entropies: 2.5299, took: 61.7417s
2022-10-08 22:52:20,364 [INFO] 	Process 3 - batch 1099: mean_policy_losses: -55.703, mean_net_lifetime: 2928.0270, mean_mc_travel_dist: 1216.2243, mean_rewards: 228.9867, total_rewards: 1765.8393, mean_steps: 12.5200, mean_ecr: 0.0401 mean_entropies: 2.5390, took: 67.1800s
2022-10-08 22:52:24,879 [INFO] 	Process 4 - batch 1099: mean_policy_losses: -24.567, mean_net_lifetime: 3025.7246, mean_mc_travel_dist: 1279.6596, mean_rewards: 226.5707, total_rewards: 1815.4068, mean_steps: 13.1500, mean_ecr: 0.0400 mean_entropies: 2.5361, took: 70.3847s
2022-10-08 22:52:32,647 [INFO] 	Process 2 - batch 1099: mean_policy_losses: 5.888, mean_net_lifetime: 3129.3900, mean_mc_travel_dist: 1290.7926, mean_rewards: 234.1483, total_rewards: 1898.4427, mean_steps: 13.4400, mean_ecr: 0.0405 mean_entropies: 2.5398, took: 72.5076s
2022-10-08 22:52:39,461 [INFO] 	Process 0 - batch 1099: mean_policy_losses: -69.912, mean_net_lifetime: 3088.2473, mean_mc_travel_dist: 1334.9100, mean_rewards: 226.8682, total_rewards: 1817.9434, mean_steps: 13.6500, mean_ecr: 0.0401 mean_entropies: 2.5476, took: 73.8791s
2022-10-08 22:52:43,494 [INFO] 	Process 5 - batch 1099: mean_policy_losses: 19.949, mean_net_lifetime: 3324.8728, mean_mc_travel_dist: 1407.5969, mean_rewards: 224.2297, total_rewards: 1982.2508, mean_steps: 14.5400, mean_ecr: 0.0403 mean_entropies: 2.5723, took: 77.1217s
2022-10-08 22:52:44,401 [INFO] 	Process 6 - batch 1099: mean_policy_losses: 0.791, mean_net_lifetime: 3274.9765, mean_mc_travel_dist: 1384.3616, mean_rewards: 226.2683, total_rewards: 1959.0658, mean_steps: 14.2900, mean_ecr: 0.0406 mean_entropies: 2.5680, took: 74.9988s
2022-10-08 22:53:06,345 [INFO] 	Process 1 - batch 1199: mean_policy_losses: -93.696, mean_net_lifetime: 2709.3240, mean_mc_travel_dist: 1125.1422, mean_rewards: 226.0024, total_rewards: 1662.5581, mean_steps: 11.4500, mean_ecr: 0.0409 mean_entropies: 2.5102, took: 60.8160s
2022-10-08 22:53:26,468 [INFO] 	Process 4 - batch 1199: mean_policy_losses: -70.462, mean_net_lifetime: 2789.9572, mean_mc_travel_dist: 1190.8779, mean_rewards: 228.3962, total_rewards: 1663.6711, mean_steps: 11.7400, mean_ecr: 0.0409 mean_entropies: 2.5283, took: 61.5893s
2022-10-08 22:53:31,301 [INFO] 	Process 3 - batch 1199: mean_policy_losses: 61.556, mean_net_lifetime: 3153.3898, mean_mc_travel_dist: 1302.1619, mean_rewards: 229.8953, total_rewards: 1922.0042, mean_steps: 13.4000, mean_ecr: 0.0407 mean_entropies: 2.5376, took: 70.9369s
2022-10-08 22:53:38,930 [INFO] 	Process 2 - batch 1199: mean_policy_losses: -42.164, mean_net_lifetime: 2818.9578, mean_mc_travel_dist: 1189.4012, mean_rewards: 225.3865, total_rewards: 1692.2518, mean_steps: 12.1900, mean_ecr: 0.0408 mean_entropies: 2.5192, took: 66.2822s
2022-10-08 22:53:43,691 [INFO] 	Process 0 - batch 1199: mean_policy_losses: -53.210, mean_net_lifetime: 2717.0435, mean_mc_travel_dist: 1099.2505, mean_rewards: 222.8332, total_rewards: 1688.8797, mean_steps: 11.4700, mean_ecr: 0.0409 mean_entropies: 2.5335, took: 64.2299s
2022-10-08 22:53:48,997 [INFO] 	Process 6 - batch 1199: mean_policy_losses: -55.225, mean_net_lifetime: 2889.3961, mean_mc_travel_dist: 1219.0739, mean_rewards: 225.9358, total_rewards: 1718.5545, mean_steps: 12.2500, mean_ecr: 0.0404 mean_entropies: 2.5318, took: 64.5953s
2022-10-08 22:53:53,754 [INFO] 	Process 5 - batch 1199: mean_policy_losses: 8.224, mean_net_lifetime: 2972.5640, mean_mc_travel_dist: 1224.1720, mean_rewards: 223.3779, total_rewards: 1823.2144, mean_steps: 12.8600, mean_ecr: 0.0406 mean_entropies: 2.5444, took: 70.2588s
2022-10-08 22:54:11,652 [INFO] 	Process 1 - batch 1299: mean_policy_losses: 29.023, mean_net_lifetime: 2976.2888, mean_mc_travel_dist: 1163.9978, mean_rewards: 231.8724, total_rewards: 1868.3997, mean_steps: 12.4500, mean_ecr: 0.0410 mean_entropies: 2.5324, took: 65.3065s
2022-10-08 22:54:29,134 [INFO] 	Process 4 - batch 1299: mean_policy_losses: -45.844, mean_net_lifetime: 2919.5738, mean_mc_travel_dist: 1141.1893, mean_rewards: 236.0437, total_rewards: 1834.7392, mean_steps: 12.0000, mean_ecr: 0.0411 mean_entropies: 2.5178, took: 62.6660s
2022-10-08 22:54:40,312 [INFO] 	Process 3 - batch 1299: mean_policy_losses: -22.587, mean_net_lifetime: 3111.2796, mean_mc_travel_dist: 1216.0712, mean_rewards: 230.5343, total_rewards: 1945.2643, mean_steps: 13.0900, mean_ecr: 0.0409 mean_entropies: 2.5443, took: 69.0113s
2022-10-08 22:54:49,702 [INFO] 	Process 2 - batch 1299: mean_policy_losses: -6.339, mean_net_lifetime: 3126.7239, mean_mc_travel_dist: 1192.1876, mean_rewards: 231.7469, total_rewards: 1991.0742, mean_steps: 13.0500, mean_ecr: 0.0409 mean_entropies: 2.5168, took: 70.7734s
2022-10-08 22:54:52,727 [INFO] 	Process 0 - batch 1299: mean_policy_losses: -65.141, mean_net_lifetime: 3043.9013, mean_mc_travel_dist: 1181.8063, mean_rewards: 232.2263, total_rewards: 1915.4859, mean_steps: 12.7200, mean_ecr: 0.0410 mean_entropies: 2.5008, took: 69.0360s
2022-10-08 22:54:57,469 [INFO] 	Process 6 - batch 1299: mean_policy_losses: -62.857, mean_net_lifetime: 3026.7505, mean_mc_travel_dist: 1170.8772, mean_rewards: 229.4459, total_rewards: 1926.0647, mean_steps: 12.6900, mean_ecr: 0.0411 mean_entropies: 2.5119, took: 68.4722s
2022-10-08 22:55:03,510 [INFO] 	Process 5 - batch 1299: mean_policy_losses: -56.011, mean_net_lifetime: 3082.4281, mean_mc_travel_dist: 1189.3329, mean_rewards: 223.1450, total_rewards: 1948.7013, mean_steps: 13.2200, mean_ecr: 0.0412 mean_entropies: 2.5154, took: 69.7567s
2022-10-08 22:55:31,201 [INFO] 	Process 1 - batch 1399: mean_policy_losses: 65.619, mean_net_lifetime: 3556.9241, mean_mc_travel_dist: 1407.1183, mean_rewards: 226.7531, total_rewards: 2207.6826, mean_steps: 15.6100, mean_ecr: 0.0403 mean_entropies: 2.5445, took: 79.5490s
2022-10-08 22:55:47,329 [INFO] 	Process 4 - batch 1399: mean_policy_losses: 47.564, mean_net_lifetime: 3390.0364, mean_mc_travel_dist: 1322.3669, mean_rewards: 225.0900, total_rewards: 2117.0910, mean_steps: 14.7900, mean_ecr: 0.0399 mean_entropies: 2.5234, took: 78.1949s
2022-10-08 22:55:58,380 [INFO] 	Process 3 - batch 1399: mean_policy_losses: -5.346, mean_net_lifetime: 3430.4051, mean_mc_travel_dist: 1385.2695, mean_rewards: 226.9090, total_rewards: 2104.2342, mean_steps: 15.0800, mean_ecr: 0.0401 mean_entropies: 2.5227, took: 78.0683s
2022-10-08 22:56:06,779 [INFO] 	Process 2 - batch 1399: mean_policy_losses: -76.199, mean_net_lifetime: 3192.7231, mean_mc_travel_dist: 1291.6517, mean_rewards: 218.5481, total_rewards: 1958.9062, mean_steps: 14.4100, mean_ecr: 0.0401 mean_entropies: 2.4963, took: 77.0764s
2022-10-08 22:56:13,939 [INFO] 	Process 6 - batch 1399: mean_policy_losses: -79.010, mean_net_lifetime: 3188.4669, mean_mc_travel_dist: 1258.7409, mean_rewards: 214.3540, total_rewards: 1982.9939, mean_steps: 14.4100, mean_ecr: 0.0402 mean_entropies: 2.4859, took: 76.4705s
2022-10-08 22:56:16,198 [INFO] 	Process 5 - batch 1399: mean_policy_losses: -36.868, mean_net_lifetime: 3135.4017, mean_mc_travel_dist: 1239.0403, mean_rewards: 222.7987, total_rewards: 1954.2774, mean_steps: 13.8600, mean_ecr: 0.0399 mean_entropies: 2.4740, took: 72.6888s
2022-10-08 22:56:19,434 [INFO] 	Process 0 - batch 1399: mean_policy_losses: 81.261, mean_net_lifetime: 3587.4433, mean_mc_travel_dist: 1421.8190, mean_rewards: 220.7375, total_rewards: 2225.9786, mean_steps: 16.4100, mean_ecr: 0.0397 mean_entropies: 2.5176, took: 86.7071s
2022-10-08 22:56:46,389 [INFO] 	Process 1 - batch 1499: mean_policy_losses: -28.528, mean_net_lifetime: 3349.0737, mean_mc_travel_dist: 1337.1421, mean_rewards: 221.9328, total_rewards: 2076.0145, mean_steps: 14.6300, mean_ecr: 0.0403 mean_entropies: 2.4409, took: 75.1886s
2022-10-08 22:57:09,394 [INFO] 	Process 4 - batch 1499: mean_policy_losses: 2.065, mean_net_lifetime: 3508.6364, mean_mc_travel_dist: 1396.2485, mean_rewards: 222.9820, total_rewards: 2167.5822, mean_steps: 15.6300, mean_ecr: 0.0401 mean_entropies: 2.4066, took: 82.0649s
2022-10-08 22:57:14,103 [INFO] 	Process 3 - batch 1499: mean_policy_losses: -28.586, mean_net_lifetime: 3286.2770, mean_mc_travel_dist: 1297.4564, mean_rewards: 219.2501, total_rewards: 2045.0466, mean_steps: 14.5400, mean_ecr: 0.0400 mean_entropies: 2.4105, took: 75.7225s
2022-10-08 22:57:22,713 [INFO] 	Process 2 - batch 1499: mean_policy_losses: -44.758, mean_net_lifetime: 3368.1536, mean_mc_travel_dist: 1345.8573, mean_rewards: 223.2053, total_rewards: 2078.5816, mean_steps: 14.9200, mean_ecr: 0.0399 mean_entropies: 2.4177, took: 75.9336s
2022-10-08 22:57:25,146 [INFO] 	Process 6 - batch 1499: mean_policy_losses: -71.049, mean_net_lifetime: 3165.5406, mean_mc_travel_dist: 1227.1202, mean_rewards: 223.7441, total_rewards: 1983.6407, mean_steps: 13.8500, mean_ecr: 0.0401 mean_entropies: 2.3765, took: 71.2067s
2022-10-08 22:57:29,436 [INFO] 	Process 5 - batch 1499: mean_policy_losses: -144.273, mean_net_lifetime: 3074.2400, mean_mc_travel_dist: 1248.4953, mean_rewards: 216.1634, total_rewards: 1889.4145, mean_steps: 13.8700, mean_ecr: 0.0405 mean_entropies: 2.3808, took: 73.2381s
2022-10-08 22:57:35,106 [INFO] 	Process 0 - batch 1499: mean_policy_losses: -65.974, mean_net_lifetime: 3397.9232, mean_mc_travel_dist: 1352.8852, mean_rewards: 225.2992, total_rewards: 2092.8782, mean_steps: 14.8600, mean_ecr: 0.0405 mean_entropies: 2.4115, took: 75.6718s
2022-10-08 23:06:34,688 [INFO] Process 3 - epoch 1: mean_policy_losses: -2.240, mean_net_lifetime: 2889.8268, mean_mc_travel_dist: 1418.5808, mean_entropies: 2.5375, m_net_lifetime_valid: 2350.8288, took: 1589.4459s, (64.3037 / 100 batches)

2022-10-08 23:07:09,024 [INFO] Process 2 - epoch 1: mean_policy_losses: -11.008, mean_net_lifetime: 2878.5144, mean_mc_travel_dist: 1396.9817, mean_entropies: 2.5334, m_net_lifetime_valid: 2352.5121, took: 1623.9843s, (64.8544 / 100 batches)

2022-10-08 23:07:09,245 [INFO] Process 4 - epoch 1: mean_policy_losses: -8.414, mean_net_lifetime: 2871.1346, mean_mc_travel_dist: 1406.0173, mean_entropies: 2.5345, m_net_lifetime_valid: 2363.4906, took: 1624.0834s, (64.0144 / 100 batches)

2022-10-08 23:07:38,432 [INFO] 	Process 3 - batch 1599: mean_policy_losses: -113.827, mean_net_lifetime: 3187.6834, mean_mc_travel_dist: 1287.4018, mean_rewards: 222.3324, total_rewards: 1948.3843, mean_steps: 14.5000, mean_ecr: 0.0399 mean_entropies: 2.4350, took: 624.3288s
2022-10-08 23:07:47,164 [INFO] Process 1 - epoch 1: mean_policy_losses: -16.798, mean_net_lifetime: 2847.2763, mean_mc_travel_dist: 1394.0312, mean_entropies: 2.5372, m_net_lifetime_valid: 2310.6470, took: 1662.1485s, (62.5858 / 100 batches)

2022-10-08 23:07:49,849 [INFO] Process 6 - epoch 1: mean_policy_losses: -3.787, mean_net_lifetime: 2904.7527, mean_mc_travel_dist: 1413.9665, mean_entropies: 2.5361, m_net_lifetime_valid: 2331.2472, took: 1664.5359s, (64.9895 / 100 batches)

2022-10-08 23:07:52,614 [INFO] Process 0 - epoch 1: mean_policy_losses: -1.903, mean_net_lifetime: 2893.7013, mean_mc_travel_dist: 1403.0057, mean_entropies: 2.5351, m_net_lifetime_valid: 2482.9903, took: 1667.5670s, (65.6286 / 100 batches)

2022-10-08 23:07:54,579 [INFO] Process 5 - epoch 1: mean_policy_losses: -7.834, mean_net_lifetime: 2905.2705, mean_mc_travel_dist: 1405.4547, mean_entropies: 2.5331, m_net_lifetime_valid: 2470.8923, took: 1669.4106s, (65.2667 / 100 batches)

2022-10-08 23:08:15,696 [INFO] 	Process 4 - batch 1599: mean_policy_losses: 28.462, mean_net_lifetime: 3123.9629, mean_mc_travel_dist: 1233.6180, mean_rewards: 226.4238, total_rewards: 1941.1491, mean_steps: 13.5200, mean_ecr: 0.0399 mean_entropies: 2.4115, took: 666.3026s
2022-10-08 23:08:17,185 [INFO] 	Process 2 - batch 1599: mean_policy_losses: -78.085, mean_net_lifetime: 3100.1706, mean_mc_travel_dist: 1276.7091, mean_rewards: 231.3938, total_rewards: 1882.8571, mean_steps: 13.8700, mean_ecr: 0.0397 mean_entropies: 2.4013, took: 654.4725s
2022-10-08 23:08:49,708 [INFO] 	Process 3 - batch 1699: mean_policy_losses: -11.798, mean_net_lifetime: 3063.1823, mean_mc_travel_dist: 1202.7052, mean_rewards: 223.7834, total_rewards: 1917.0548, mean_steps: 13.6200, mean_ecr: 0.0405 mean_entropies: 2.4334, took: 71.2765s
2022-10-08 23:08:57,720 [INFO] 	Process 1 - batch 1599: mean_policy_losses: -56.382, mean_net_lifetime: 3057.9368, mean_mc_travel_dist: 1229.2184, mean_rewards: 221.8962, total_rewards: 1873.9945, mean_steps: 13.6500, mean_ecr: 0.0397 mean_entropies: 2.4213, took: 731.3302s
2022-10-08 23:09:03,783 [INFO] 	Process 5 - batch 1599: mean_policy_losses: -28.833, mean_net_lifetime: 2969.5769, mean_mc_travel_dist: 1155.7887, mean_rewards: 227.9120, total_rewards: 1874.3518, mean_steps: 12.9300, mean_ecr: 0.0401 mean_entropies: 2.4079, took: 694.3462s
2022-10-08 23:09:10,572 [INFO] 	Process 6 - batch 1599: mean_policy_losses: -86.097, mean_net_lifetime: 3232.0199, mean_mc_travel_dist: 1329.7550, mean_rewards: 217.4410, total_rewards: 1955.1453, mean_steps: 15.1900, mean_ecr: 0.0402 mean_entropies: 2.4034, took: 705.4259s
2022-10-08 23:09:10,971 [INFO] 	Process 0 - batch 1599: mean_policy_losses: -31.451, mean_net_lifetime: 3210.9895, mean_mc_travel_dist: 1309.6620, mean_rewards: 216.0298, total_rewards: 1955.9030, mean_steps: 14.9800, mean_ecr: 0.0394 mean_entropies: 2.4060, took: 695.8656s
2022-10-08 23:09:24,886 [INFO] 	Process 2 - batch 1699: mean_policy_losses: -134.508, mean_net_lifetime: 2822.9255, mean_mc_travel_dist: 1094.9060, mean_rewards: 218.1576, total_rewards: 1785.9865, mean_steps: 12.4200, mean_ecr: 0.0408 mean_entropies: 2.4158, took: 67.7014s
2022-10-08 23:09:33,854 [INFO] 	Process 4 - batch 1699: mean_policy_losses: 0.357, mean_net_lifetime: 3203.9358, mean_mc_travel_dist: 1209.5017, mean_rewards: 214.6324, total_rewards: 2053.4274, mean_steps: 14.4200, mean_ecr: 0.0401 mean_entropies: 2.4330, took: 78.1581s
2022-10-08 23:09:59,505 [INFO] 	Process 3 - batch 1799: mean_policy_losses: -130.647, mean_net_lifetime: 2970.0948, mean_mc_travel_dist: 1140.2676, mean_rewards: 226.0243, total_rewards: 1881.0013, mean_steps: 13.1200, mean_ecr: 0.0403 mean_entropies: 2.3263, took: 69.7965s
2022-10-08 23:10:07,279 [INFO] 	Process 1 - batch 1699: mean_policy_losses: -88.728, mean_net_lifetime: 2985.6353, mean_mc_travel_dist: 1183.9841, mean_rewards: 223.5369, total_rewards: 1857.8864, mean_steps: 13.3200, mean_ecr: 0.0406 mean_entropies: 2.3439, took: 69.5597s
2022-10-08 23:10:21,314 [INFO] 	Process 5 - batch 1699: mean_policy_losses: 3.911, mean_net_lifetime: 3204.6547, mean_mc_travel_dist: 1251.6893, mean_rewards: 217.6321, total_rewards: 2009.2240, mean_steps: 14.4300, mean_ecr: 0.0401 mean_entropies: 2.3592, took: 77.5308s
2022-10-08 23:10:24,735 [INFO] 	Process 0 - batch 1699: mean_policy_losses: -63.574, mean_net_lifetime: 3039.3830, mean_mc_travel_dist: 1183.9375, mean_rewards: 215.9573, total_rewards: 1906.8020, mean_steps: 13.9300, mean_ecr: 0.0410 mean_entropies: 2.3316, took: 73.7626s
2022-10-08 23:10:27,619 [INFO] 	Process 6 - batch 1699: mean_policy_losses: -16.356, mean_net_lifetime: 3094.8719, mean_mc_travel_dist: 1198.0976, mean_rewards: 212.9003, total_rewards: 1944.7706, mean_steps: 14.0400, mean_ecr: 0.0397 mean_entropies: 2.3613, took: 77.0470s
2022-10-08 23:10:40,457 [INFO] 	Process 2 - batch 1799: mean_policy_losses: -88.099, mean_net_lifetime: 3100.1839, mean_mc_travel_dist: 1204.0381, mean_rewards: 217.8739, total_rewards: 1945.0669, mean_steps: 14.4200, mean_ecr: 0.0398 mean_entropies: 2.3416, took: 75.5709s
2022-10-08 23:10:44,112 [INFO] 	Process 4 - batch 1799: mean_policy_losses: -190.798, mean_net_lifetime: 2936.0773, mean_mc_travel_dist: 1128.2863, mean_rewards: 220.0657, total_rewards: 1873.5778, mean_steps: 13.4600, mean_ecr: 0.0404 mean_entropies: 2.3168, took: 70.2575s
2022-10-08 23:11:15,199 [INFO] 	Process 3 - batch 1899: mean_policy_losses: -100.890, mean_net_lifetime: 3143.9698, mean_mc_travel_dist: 1181.5428, mean_rewards: 221.3484, total_rewards: 2009.2894, mean_steps: 14.3000, mean_ecr: 0.0400 mean_entropies: 2.3702, took: 75.6944s
2022-10-08 23:11:25,098 [INFO] 	Process 1 - batch 1799: mean_policy_losses: -92.165, mean_net_lifetime: 3299.6605, mean_mc_travel_dist: 1281.2275, mean_rewards: 219.5464, total_rewards: 2076.4931, mean_steps: 15.1800, mean_ecr: 0.0398 mean_entropies: 2.3792, took: 77.8187s
2022-10-08 23:11:33,150 [INFO] 	Process 5 - batch 1799: mean_policy_losses: -112.041, mean_net_lifetime: 3068.9142, mean_mc_travel_dist: 1138.2635, mean_rewards: 237.9506, total_rewards: 1976.1392, mean_steps: 13.2600, mean_ecr: 0.0406 mean_entropies: 2.3785, took: 71.8361s
2022-10-08 23:11:43,762 [INFO] 	Process 6 - batch 1799: mean_policy_losses: -93.247, mean_net_lifetime: 3202.2768, mean_mc_travel_dist: 1194.8358, mean_rewards: 227.8626, total_rewards: 2052.9902, mean_steps: 14.1500, mean_ecr: 0.0404 mean_entropies: 2.3594, took: 76.1427s
2022-10-08 23:11:48,569 [INFO] 	Process 0 - batch 1799: mean_policy_losses: -76.802, mean_net_lifetime: 3355.9216, mean_mc_travel_dist: 1316.7385, mean_rewards: 218.8031, total_rewards: 2095.7130, mean_steps: 16.0000, mean_ecr: 0.0399 mean_entropies: 2.3856, took: 83.8351s
2022-10-08 23:11:56,271 [INFO] 	Process 2 - batch 1899: mean_policy_losses: -99.157, mean_net_lifetime: 3148.4181, mean_mc_travel_dist: 1205.6721, mean_rewards: 221.8759, total_rewards: 2001.0839, mean_steps: 14.1500, mean_ecr: 0.0402 mean_entropies: 2.3693, took: 75.8140s
2022-10-08 23:12:01,829 [INFO] 	Process 4 - batch 1899: mean_policy_losses: -22.930, mean_net_lifetime: 3226.6670, mean_mc_travel_dist: 1217.6051, mean_rewards: 224.7686, total_rewards: 2062.0652, mean_steps: 14.6400, mean_ecr: 0.0397 mean_entropies: 2.3573, took: 77.7169s
2022-10-08 23:12:32,637 [INFO] 	Process 3 - batch 1999: mean_policy_losses: 36.348, mean_net_lifetime: 3250.2495, mean_mc_travel_dist: 1197.1756, mean_rewards: 224.8039, total_rewards: 2099.7781, mean_steps: 14.7500, mean_ecr: 0.0398 mean_entropies: 2.3618, took: 77.4377s
2022-10-08 23:12:41,688 [INFO] 	Process 1 - batch 1899: mean_policy_losses: -30.322, mean_net_lifetime: 3235.0447, mean_mc_travel_dist: 1243.8173, mean_rewards: 223.7974, total_rewards: 2040.0552, mean_steps: 14.9400, mean_ecr: 0.0400 mean_entropies: 2.3465, took: 76.5899s
2022-10-08 23:12:52,698 [INFO] 	Process 5 - batch 1899: mean_policy_losses: 30.665, mean_net_lifetime: 3293.5304, mean_mc_travel_dist: 1209.7716, mean_rewards: 220.6697, total_rewards: 2133.2453, mean_steps: 14.9700, mean_ecr: 0.0396 mean_entropies: 2.3609, took: 79.5483s
2022-10-08 23:12:57,430 [INFO] 	Process 6 - batch 1899: mean_policy_losses: -121.851, mean_net_lifetime: 2979.9999, mean_mc_travel_dist: 1146.9434, mean_rewards: 223.2209, total_rewards: 1887.6046, mean_steps: 13.6800, mean_ecr: 0.0396 mean_entropies: 2.3392, took: 73.6673s
2022-10-08 23:13:05,542 [INFO] 	Process 0 - batch 1899: mean_policy_losses: -149.000, mean_net_lifetime: 3096.0195, mean_mc_travel_dist: 1158.6127, mean_rewards: 217.7295, total_rewards: 1986.2013, mean_steps: 14.2000, mean_ecr: 0.0400 mean_entropies: 2.3439, took: 76.9721s
2022-10-08 23:13:18,336 [INFO] 	Process 2 - batch 1999: mean_policy_losses: -52.666, mean_net_lifetime: 3327.3070, mean_mc_travel_dist: 1247.6710, mean_rewards: 209.1116, total_rewards: 2123.7518, mean_steps: 15.7900, mean_ecr: 0.0398 mean_entropies: 2.3184, took: 82.0643s
2022-10-08 23:13:30,401 [INFO] 	Process 4 - batch 1999: mean_policy_losses: 9.582, mean_net_lifetime: 3528.3333, mean_mc_travel_dist: 1347.1072, mean_rewards: 209.0578, total_rewards: 2220.5085, mean_steps: 17.2000, mean_ecr: 0.0398 mean_entropies: 2.3445, took: 88.5726s
2022-10-08 23:13:58,563 [INFO] 	Process 3 - batch 2099: mean_policy_losses: -111.962, mean_net_lifetime: 3405.3528, mean_mc_travel_dist: 1329.1791, mean_rewards: 213.7611, total_rewards: 2123.1379, mean_steps: 16.3100, mean_ecr: 0.0404 mean_entropies: 2.3249, took: 85.9269s
2022-10-08 23:14:02,013 [INFO] 	Process 1 - batch 1999: mean_policy_losses: -21.690, mean_net_lifetime: 3373.8307, mean_mc_travel_dist: 1227.6543, mean_rewards: 216.1493, total_rewards: 2177.4707, mean_steps: 15.5600, mean_ecr: 0.0395 mean_entropies: 2.3017, took: 80.3248s
2022-10-08 23:14:12,478 [INFO] 	Process 5 - batch 1999: mean_policy_losses: -72.381, mean_net_lifetime: 3212.8929, mean_mc_travel_dist: 1203.9623, mean_rewards: 212.0880, total_rewards: 2064.0562, mean_steps: 15.1500, mean_ecr: 0.0398 mean_entropies: 2.3055, took: 79.7806s
2022-10-08 23:14:14,580 [INFO] 	Process 6 - batch 1999: mean_policy_losses: -62.161, mean_net_lifetime: 3185.7341, mean_mc_travel_dist: 1205.2138, mean_rewards: 213.8110, total_rewards: 2024.1651, mean_steps: 14.7100, mean_ecr: 0.0402 mean_entropies: 2.3174, took: 77.1511s
2022-10-08 23:14:26,960 [INFO] 	Process 0 - batch 1999: mean_policy_losses: 1.771, mean_net_lifetime: 3304.7842, mean_mc_travel_dist: 1217.9581, mean_rewards: 211.8763, total_rewards: 2128.7973, mean_steps: 15.3600, mean_ecr: 0.0397 mean_entropies: 2.3119, took: 81.4190s
2022-10-08 23:14:40,096 [INFO] 	Process 2 - batch 2099: mean_policy_losses: -142.613, mean_net_lifetime: 3245.1735, mean_mc_travel_dist: 1216.4747, mean_rewards: 215.2008, total_rewards: 2075.1435, mean_steps: 15.3400, mean_ecr: 0.0402 mean_entropies: 2.3267, took: 81.7604s
2022-10-08 23:15:00,975 [INFO] 	Process 4 - batch 2099: mean_policy_losses: -92.607, mean_net_lifetime: 3547.3807, mean_mc_travel_dist: 1362.0058, mean_rewards: 221.0762, total_rewards: 2228.0761, mean_steps: 17.3900, mean_ecr: 0.0402 mean_entropies: 2.3182, took: 90.5734s
2022-10-08 23:15:20,268 [INFO] 	Process 3 - batch 2199: mean_policy_losses: -126.754, mean_net_lifetime: 3216.1805, mean_mc_travel_dist: 1225.4913, mean_rewards: 213.0941, total_rewards: 2037.5474, mean_steps: 15.4500, mean_ecr: 0.0403 mean_entropies: 2.2666, took: 81.7032s
2022-10-08 23:15:20,708 [INFO] 	Process 1 - batch 2099: mean_policy_losses: -151.559, mean_net_lifetime: 3185.8814, mean_mc_travel_dist: 1213.6936, mean_rewards: 216.5858, total_rewards: 2016.8175, mean_steps: 15.2400, mean_ecr: 0.0408 mean_entropies: 2.3055, took: 78.6950s
2022-10-08 23:15:35,077 [INFO] 	Process 5 - batch 2099: mean_policy_losses: -92.847, mean_net_lifetime: 3247.7666, mean_mc_travel_dist: 1219.4274, mean_rewards: 217.0045, total_rewards: 2072.7536, mean_steps: 15.6200, mean_ecr: 0.0404 mean_entropies: 2.3147, took: 82.5981s
2022-10-08 23:15:36,701 [INFO] 	Process 6 - batch 2099: mean_policy_losses: -79.614, mean_net_lifetime: 3306.4697, mean_mc_travel_dist: 1263.5145, mean_rewards: 215.5559, total_rewards: 2096.9100, mean_steps: 15.8700, mean_ecr: 0.0401 mean_entropies: 2.3110, took: 82.1206s
2022-10-08 23:15:52,252 [INFO] 	Process 0 - batch 2099: mean_policy_losses: -96.967, mean_net_lifetime: 3345.6005, mean_mc_travel_dist: 1267.5872, mean_rewards: 214.0743, total_rewards: 2127.0913, mean_steps: 16.3300, mean_ecr: 0.0405 mean_entropies: 2.3083, took: 85.2916s
2022-10-08 23:16:06,313 [INFO] 	Process 2 - batch 2199: mean_policy_losses: -64.550, mean_net_lifetime: 3430.2492, mean_mc_travel_dist: 1292.4302, mean_rewards: 214.9908, total_rewards: 2178.5368, mean_steps: 16.5800, mean_ecr: 0.0404 mean_entropies: 2.2768, took: 86.2171s
2022-10-08 23:16:29,904 [INFO] 	Process 4 - batch 2199: mean_policy_losses: -125.947, mean_net_lifetime: 3437.5951, mean_mc_travel_dist: 1311.9715, mean_rewards: 208.9584, total_rewards: 2173.6031, mean_steps: 16.9600, mean_ecr: 0.0405 mean_entropies: 2.2605, took: 88.9289s
2022-10-08 23:16:36,425 [INFO] 	Process 3 - batch 2299: mean_policy_losses: -129.688, mean_net_lifetime: 3151.2233, mean_mc_travel_dist: 1156.9980, mean_rewards: 223.9210, total_rewards: 2033.0730, mean_steps: 14.0800, mean_ecr: 0.0416 mean_entropies: 2.2993, took: 76.1579s
2022-10-08 23:16:49,703 [INFO] 	Process 1 - batch 2199: mean_policy_losses: -169.482, mean_net_lifetime: 3490.6600, mean_mc_travel_dist: 1353.8590, mean_rewards: 209.1909, total_rewards: 2172.3270, mean_steps: 17.6400, mean_ecr: 0.0401 mean_entropies: 2.2523, took: 88.9959s
2022-10-08 23:16:59,372 [INFO] 	Process 6 - batch 2199: mean_policy_losses: -134.942, mean_net_lifetime: 3324.5857, mean_mc_travel_dist: 1268.2182, mean_rewards: 213.3605, total_rewards: 2106.7188, mean_steps: 16.0200, mean_ecr: 0.0405 mean_entropies: 2.2546, took: 82.6700s
2022-10-08 23:17:01,189 [INFO] 	Process 5 - batch 2199: mean_policy_losses: -82.772, mean_net_lifetime: 3347.1905, mean_mc_travel_dist: 1238.8504, mean_rewards: 211.8011, total_rewards: 2155.8822, mean_steps: 16.3800, mean_ecr: 0.0402 mean_entropies: 2.2738, took: 86.1122s
2022-10-08 23:17:25,823 [INFO] 	Process 2 - batch 2299: mean_policy_losses: -114.397, mean_net_lifetime: 3251.8181, mean_mc_travel_dist: 1213.4936, mean_rewards: 221.1777, total_rewards: 2091.9790, mean_steps: 14.8800, mean_ecr: 0.0409 mean_entropies: 2.3221, took: 79.5107s
2022-10-08 23:17:31,487 [INFO] 	Process 0 - batch 2199: mean_policy_losses: -117.062, mean_net_lifetime: 3788.1311, mean_mc_travel_dist: 1446.4824, mean_rewards: 211.2471, total_rewards: 2376.0938, mean_steps: 19.2600, mean_ecr: 0.0398 mean_entropies: 2.2425, took: 99.2349s
2022-10-08 23:17:45,183 [INFO] 	Process 4 - batch 2299: mean_policy_losses: -92.025, mean_net_lifetime: 3167.6766, mean_mc_travel_dist: 1161.2704, mean_rewards: 218.9899, total_rewards: 2051.5464, mean_steps: 14.3800, mean_ecr: 0.0414 mean_entropies: 2.3164, took: 75.2794s
2022-10-08 23:17:52,352 [INFO] 	Process 3 - batch 2399: mean_policy_losses: -91.255, mean_net_lifetime: 3129.4011, mean_mc_travel_dist: 1130.7109, mean_rewards: 217.7962, total_rewards: 2046.1511, mean_steps: 14.1900, mean_ecr: 0.0416 mean_entropies: 2.2728, took: 75.9271s
2022-10-08 23:18:05,813 [INFO] 	Process 1 - batch 2299: mean_policy_losses: -112.789, mean_net_lifetime: 3200.7284, mean_mc_travel_dist: 1180.7713, mean_rewards: 220.2801, total_rewards: 2063.8232, mean_steps: 14.6700, mean_ecr: 0.0412 mean_entropies: 2.2887, took: 76.1092s
2022-10-08 23:18:13,355 [INFO] 	Process 6 - batch 2299: mean_policy_losses: -209.565, mean_net_lifetime: 3104.2457, mean_mc_travel_dist: 1165.5901, mean_rewards: 217.3898, total_rewards: 1988.5812, mean_steps: 14.1600, mean_ecr: 0.0410 mean_entropies: 2.2754, took: 73.9839s
2022-10-08 23:18:19,556 [INFO] 	Process 5 - batch 2299: mean_policy_losses: -85.952, mean_net_lifetime: 3299.2970, mean_mc_travel_dist: 1214.5917, mean_rewards: 218.5601, total_rewards: 2129.3569, mean_steps: 14.9600, mean_ecr: 0.0411 mean_entropies: 2.2838, took: 78.3673s
2022-10-08 23:18:46,995 [INFO] 	Process 2 - batch 2399: mean_policy_losses: -116.938, mean_net_lifetime: 3295.3290, mean_mc_travel_dist: 1223.1245, mean_rewards: 214.0718, total_rewards: 2127.7993, mean_steps: 15.5400, mean_ecr: 0.0413 mean_entropies: 2.1935, took: 81.1710s
2022-10-08 23:18:54,499 [INFO] 	Process 0 - batch 2299: mean_policy_losses: -81.503, mean_net_lifetime: 3336.2957, mean_mc_travel_dist: 1229.3262, mean_rewards: 220.3327, total_rewards: 2152.8285, mean_steps: 15.6100, mean_ecr: 0.0412 mean_entropies: 2.2092, took: 83.0125s
2022-10-08 23:19:03,926 [INFO] 	Process 4 - batch 2399: mean_policy_losses: -110.297, mean_net_lifetime: 3194.6172, mean_mc_travel_dist: 1174.1707, mean_rewards: 217.0021, total_rewards: 2070.6530, mean_steps: 15.0100, mean_ecr: 0.0410 mean_entropies: 2.1844, took: 78.7429s
2022-10-08 23:19:21,460 [INFO] 	Process 1 - batch 2399: mean_policy_losses: -161.979, mean_net_lifetime: 3066.4129, mean_mc_travel_dist: 1156.4590, mean_rewards: 209.6408, total_rewards: 1965.8628, mean_steps: 14.5700, mean_ecr: 0.0411 mean_entropies: 2.1770, took: 75.6472s
2022-10-08 23:19:26,490 [INFO] 	Process 3 - batch 2499: mean_policy_losses: 62.353, mean_net_lifetime: 3741.9587, mean_mc_travel_dist: 1353.2239, mean_rewards: 207.4912, total_rewards: 2429.4966, mean_steps: 18.0400, mean_ecr: 0.0395 mean_entropies: 2.2004, took: 94.1369s
2022-10-08 23:19:30,803 [INFO] 	Process 6 - batch 2399: mean_policy_losses: -147.982, mean_net_lifetime: 3093.0329, mean_mc_travel_dist: 1131.8121, mean_rewards: 211.2500, total_rewards: 2010.6194, mean_steps: 14.8000, mean_ecr: 0.0418 mean_entropies: 2.1874, took: 77.4481s
2022-10-08 23:19:42,429 [INFO] 	Process 5 - batch 2399: mean_policy_losses: -92.110, mean_net_lifetime: 3267.5989, mean_mc_travel_dist: 1182.5990, mean_rewards: 212.8927, total_rewards: 2129.1209, mean_steps: 15.4500, mean_ecr: 0.0414 mean_entropies: 2.1681, took: 82.8725s
2022-10-08 23:20:18,157 [INFO] 	Process 0 - batch 2399: mean_policy_losses: -80.415, mean_net_lifetime: 3306.6583, mean_mc_travel_dist: 1205.3326, mean_rewards: 214.6101, total_rewards: 2142.9376, mean_steps: 15.8700, mean_ecr: 0.0415 mean_entropies: 2.1957, took: 83.6577s
2022-10-08 23:20:18,823 [INFO] 	Process 2 - batch 2499: mean_policy_losses: -123.395, mean_net_lifetime: 3506.6944, mean_mc_travel_dist: 1306.4306, mean_rewards: 207.8256, total_rewards: 2239.4578, mean_steps: 17.4600, mean_ecr: 0.0398 mean_entropies: 2.1926, took: 91.8285s
2022-10-08 23:20:40,641 [INFO] 	Process 4 - batch 2499: mean_policy_losses: -1.665, mean_net_lifetime: 3752.3051, mean_mc_travel_dist: 1399.3798, mean_rewards: 200.3635, total_rewards: 2398.8668, mean_steps: 19.0900, mean_ecr: 0.0396 mean_entropies: 2.2384, took: 96.7159s
2022-10-08 23:20:49,568 [INFO] 	Process 1 - batch 2499: mean_policy_losses: -18.872, mean_net_lifetime: 3516.4200, mean_mc_travel_dist: 1278.9635, mean_rewards: 203.9449, total_rewards: 2280.0874, mean_steps: 17.3900, mean_ecr: 0.0397 mean_entropies: 2.2335, took: 88.1078s
2022-10-08 23:20:56,238 [INFO] 	Process 6 - batch 2499: mean_policy_losses: -150.785, mean_net_lifetime: 3455.9242, mean_mc_travel_dist: 1303.1701, mean_rewards: 208.0054, total_rewards: 2188.3680, mean_steps: 16.7500, mean_ecr: 0.0397 mean_entropies: 2.1994, took: 85.4351s
2022-10-08 23:21:01,452 [INFO] 	Process 3 - batch 2599: mean_policy_losses: -93.285, mean_net_lifetime: 3702.8403, mean_mc_travel_dist: 1377.6856, mean_rewards: 211.1303, total_rewards: 2375.1106, mean_steps: 18.4900, mean_ecr: 0.0386 mean_entropies: 2.1892, took: 94.9628s
2022-10-08 23:21:20,563 [INFO] 	Process 5 - batch 2499: mean_policy_losses: -67.627, mean_net_lifetime: 3726.9379, mean_mc_travel_dist: 1390.1174, mean_rewards: 208.7259, total_rewards: 2376.9608, mean_steps: 18.7600, mean_ecr: 0.0394 mean_entropies: 2.2064, took: 98.1343s
2022-10-08 23:21:45,523 [INFO] 	Process 0 - batch 2499: mean_policy_losses: -98.665, mean_net_lifetime: 3373.3877, mean_mc_travel_dist: 1238.6020, mean_rewards: 210.3263, total_rewards: 2173.1316, mean_steps: 16.5700, mean_ecr: 0.0400 mean_entropies: 2.2288, took: 87.3652s
2022-10-08 23:21:53,493 [INFO] 	Process 2 - batch 2599: mean_policy_losses: -101.761, mean_net_lifetime: 3631.6919, mean_mc_travel_dist: 1362.8678, mean_rewards: 207.5560, total_rewards: 2312.1932, mean_steps: 18.4800, mean_ecr: 0.0388 mean_entropies: 2.1946, took: 94.6699s
2022-10-08 23:22:10,830 [INFO] 	Process 4 - batch 2599: mean_policy_losses: -111.152, mean_net_lifetime: 3439.8041, mean_mc_travel_dist: 1309.9661, mean_rewards: 209.1271, total_rewards: 2172.9046, mean_steps: 17.5300, mean_ecr: 0.0387 mean_entropies: 2.1924, took: 90.1880s
2022-10-08 23:22:14,753 [INFO] 	Process 1 - batch 2599: mean_policy_losses: -87.517, mean_net_lifetime: 3410.4798, mean_mc_travel_dist: 1264.4769, mean_rewards: 212.5091, total_rewards: 2190.3543, mean_steps: 16.5600, mean_ecr: 0.0387 mean_entropies: 2.2034, took: 85.1845s
2022-10-08 23:22:18,682 [INFO] 	Process 3 - batch 2699: mean_policy_losses: -162.267, mean_net_lifetime: 3005.3204, mean_mc_travel_dist: 1111.7219, mean_rewards: 221.9458, total_rewards: 1941.5474, mean_steps: 14.6000, mean_ecr: 0.0395 mean_entropies: 2.2016, took: 77.2308s
2022-10-08 23:22:21,528 [INFO] 	Process 6 - batch 2599: mean_policy_losses: -86.498, mean_net_lifetime: 3385.3764, mean_mc_travel_dist: 1241.8861, mean_rewards: 213.8108, total_rewards: 2189.6250, mean_steps: 16.6100, mean_ecr: 0.0395 mean_entropies: 2.1957, took: 85.2896s
2022-10-08 23:22:51,676 [INFO] 	Process 5 - batch 2599: mean_policy_losses: -39.913, mean_net_lifetime: 3532.6030, mean_mc_travel_dist: 1318.3539, mean_rewards: 210.2135, total_rewards: 2251.2786, mean_steps: 17.4200, mean_ecr: 0.0391 mean_entropies: 2.2303, took: 91.1132s
2022-10-08 23:23:09,263 [INFO] 	Process 0 - batch 2599: mean_policy_losses: -94.523, mean_net_lifetime: 3227.2520, mean_mc_travel_dist: 1175.2982, mean_rewards: 211.8967, total_rewards: 2082.2160, mean_steps: 16.2200, mean_ecr: 0.0389 mean_entropies: 2.2028, took: 83.7404s
2022-10-08 23:23:22,376 [INFO] 	Process 2 - batch 2699: mean_policy_losses: -27.637, mean_net_lifetime: 3358.5189, mean_mc_travel_dist: 1214.9712, mean_rewards: 213.3841, total_rewards: 2184.8340, mean_steps: 16.9500, mean_ecr: 0.0392 mean_entropies: 2.2165, took: 88.8829s
2022-10-08 23:23:33,550 [INFO] 	Process 4 - batch 2699: mean_policy_losses: -146.721, mean_net_lifetime: 3194.1187, mean_mc_travel_dist: 1198.8655, mean_rewards: 216.0432, total_rewards: 2039.9973, mean_steps: 15.7000, mean_ecr: 0.0397 mean_entropies: 2.2024, took: 82.7203s
2022-10-08 23:23:37,706 [INFO] 	Process 1 - batch 2699: mean_policy_losses: -82.803, mean_net_lifetime: 3269.6329, mean_mc_travel_dist: 1207.3866, mean_rewards: 214.6621, total_rewards: 2105.5086, mean_steps: 16.2400, mean_ecr: 0.0395 mean_entropies: 2.2193, took: 82.9536s
2022-10-08 23:23:42,578 [INFO] 	Process 6 - batch 2699: mean_policy_losses: -130.111, mean_net_lifetime: 3200.6564, mean_mc_travel_dist: 1181.5254, mean_rewards: 223.2889, total_rewards: 2056.4108, mean_steps: 15.5800, mean_ecr: 0.0391 mean_entropies: 2.2055, took: 81.0500s
2022-10-08 23:23:44,297 [INFO] 	Process 3 - batch 2799: mean_policy_losses: -111.374, mean_net_lifetime: 3303.5566, mean_mc_travel_dist: 1218.5589, mean_rewards: 209.6835, total_rewards: 2124.6639, mean_steps: 16.2100, mean_ecr: 0.0405 mean_entropies: 2.2003, took: 85.6147s
2022-10-08 23:24:18,327 [INFO] 	Process 5 - batch 2699: mean_policy_losses: -50.352, mean_net_lifetime: 3318.3194, mean_mc_travel_dist: 1232.2728, mean_rewards: 210.1712, total_rewards: 2128.5087, mean_steps: 16.6900, mean_ecr: 0.0394 mean_entropies: 2.1963, took: 86.6513s
2022-10-08 23:24:38,237 [INFO] 	Process 0 - batch 2699: mean_policy_losses: -111.007, mean_net_lifetime: 3299.5156, mean_mc_travel_dist: 1230.0731, mean_rewards: 210.0075, total_rewards: 2118.7876, mean_steps: 16.7300, mean_ecr: 0.0395 mean_entropies: 2.2033, took: 88.9740s
2022-10-08 23:24:47,725 [INFO] 	Process 2 - batch 2799: mean_policy_losses: -124.628, mean_net_lifetime: 3283.3630, mean_mc_travel_dist: 1208.5740, mean_rewards: 212.7096, total_rewards: 2112.2494, mean_steps: 16.4600, mean_ecr: 0.0400 mean_entropies: 2.1718, took: 85.3486s
2022-10-08 23:24:59,269 [INFO] 	Process 1 - batch 2799: mean_policy_losses: -51.073, mean_net_lifetime: 3253.8563, mean_mc_travel_dist: 1181.9026, mean_rewards: 211.9682, total_rewards: 2115.2059, mean_steps: 15.8200, mean_ecr: 0.0402 mean_entropies: 2.1906, took: 81.5629s
2022-10-08 23:24:59,658 [INFO] 	Process 4 - batch 2799: mean_policy_losses: -72.226, mean_net_lifetime: 3274.7264, mean_mc_travel_dist: 1201.6261, mean_rewards: 206.3590, total_rewards: 2111.3631, mean_steps: 16.7300, mean_ecr: 0.0401 mean_entropies: 2.1895, took: 86.1077s
2022-10-08 23:25:11,537 [INFO] 	Process 6 - batch 2799: mean_policy_losses: -56.549, mean_net_lifetime: 3306.7750, mean_mc_travel_dist: 1239.5671, mean_rewards: 204.5070, total_rewards: 2112.5240, mean_steps: 16.8500, mean_ecr: 0.0402 mean_entropies: 2.1862, took: 88.9593s
2022-10-08 23:25:20,110 [INFO] 	Process 3 - batch 2899: mean_policy_losses: 111.181, mean_net_lifetime: 3758.7888, mean_mc_travel_dist: 1385.9058, mean_rewards: 207.7507, total_rewards: 2419.4547, mean_steps: 18.6500, mean_ecr: 0.0387 mean_entropies: 2.2560, took: 95.8127s
2022-10-08 23:25:42,325 [INFO] 	Process 5 - batch 2799: mean_policy_losses: -75.944, mean_net_lifetime: 3197.7135, mean_mc_travel_dist: 1156.0706, mean_rewards: 208.5415, total_rewards: 2091.1492, mean_steps: 16.0600, mean_ecr: 0.0401 mean_entropies: 2.1845, took: 83.9973s
2022-10-08 23:26:11,264 [INFO] 	Process 0 - batch 2799: mean_policy_losses: -71.602, mean_net_lifetime: 3439.8999, mean_mc_travel_dist: 1264.1708, mean_rewards: 204.2751, total_rewards: 2216.1112, mean_steps: 17.6900, mean_ecr: 0.0399 mean_entropies: 2.1729, took: 93.0280s
2022-10-08 23:26:16,756 [INFO] 	Process 2 - batch 2899: mean_policy_losses: -73.416, mean_net_lifetime: 3431.8483, mean_mc_travel_dist: 1237.6231, mean_rewards: 209.8180, total_rewards: 2236.1140, mean_steps: 16.6600, mean_ecr: 0.0388 mean_entropies: 2.2207, took: 89.0314s
2022-10-08 23:26:29,321 [INFO] 	Process 1 - batch 2899: mean_policy_losses: -22.492, mean_net_lifetime: 3635.8435, mean_mc_travel_dist: 1324.2729, mean_rewards: 209.6749, total_rewards: 2353.8844, mean_steps: 17.7300, mean_ecr: 0.0385 mean_entropies: 2.2466, took: 90.0529s
2022-10-08 23:26:30,621 [INFO] 	Process 4 - batch 2899: mean_policy_losses: -28.791, mean_net_lifetime: 3550.7258, mean_mc_travel_dist: 1308.1268, mean_rewards: 210.9438, total_rewards: 2271.1039, mean_steps: 17.6000, mean_ecr: 0.0386 mean_entropies: 2.2415, took: 90.9637s
2022-10-08 23:26:34,179 [INFO] 	Process 6 - batch 2899: mean_policy_losses: -90.370, mean_net_lifetime: 3384.6082, mean_mc_travel_dist: 1238.9311, mean_rewards: 219.4981, total_rewards: 2206.5379, mean_steps: 15.7300, mean_ecr: 0.0386 mean_entropies: 2.2401, took: 82.6417s
2022-10-08 23:26:58,832 [INFO] 	Process 3 - batch 2999: mean_policy_losses: -48.948, mean_net_lifetime: 3825.2891, mean_mc_travel_dist: 1418.9109, mean_rewards: 211.5699, total_rewards: 2447.7793, mean_steps: 19.2900, mean_ecr: 0.0392 mean_entropies: 2.2446, took: 98.7218s
2022-10-08 23:27:11,177 [INFO] 	Process 5 - batch 2899: mean_policy_losses: -95.934, mean_net_lifetime: 3554.4578, mean_mc_travel_dist: 1258.5435, mean_rewards: 210.0890, total_rewards: 2335.0908, mean_steps: 17.2900, mean_ecr: 0.0385 mean_entropies: 2.2463, took: 88.8524s
2022-10-08 23:27:40,889 [INFO] 	Process 0 - batch 2899: mean_policy_losses: -154.568, mean_net_lifetime: 3487.6986, mean_mc_travel_dist: 1285.3389, mean_rewards: 216.0542, total_rewards: 2249.2571, mean_steps: 17.1600, mean_ecr: 0.0386 mean_entropies: 2.2222, took: 89.6242s
2022-10-08 23:27:53,516 [INFO] 	Process 2 - batch 2999: mean_policy_losses: -85.628, mean_net_lifetime: 3804.9936, mean_mc_travel_dist: 1367.8379, mean_rewards: 212.7159, total_rewards: 2482.3380, mean_steps: 18.9900, mean_ecr: 0.0390 mean_entropies: 2.2272, took: 96.7595s
2022-10-08 23:28:00,498 [INFO] 	Process 6 - batch 2999: mean_policy_losses: -134.011, mean_net_lifetime: 3570.2725, mean_mc_travel_dist: 1274.2941, mean_rewards: 222.8689, total_rewards: 2341.5107, mean_steps: 16.6900, mean_ecr: 0.0390 mean_entropies: 2.1989, took: 86.3196s
2022-10-08 23:28:01,771 [INFO] 	Process 1 - batch 2999: mean_policy_losses: -6.891, mean_net_lifetime: 3853.5309, mean_mc_travel_dist: 1413.0048, mean_rewards: 215.4300, total_rewards: 2471.6183, mean_steps: 18.7000, mean_ecr: 0.0386 mean_entropies: 2.2231, took: 92.4496s
2022-10-08 23:28:05,479 [INFO] 	Process 4 - batch 2999: mean_policy_losses: -99.765, mean_net_lifetime: 3793.8451, mean_mc_travel_dist: 1371.4350, mean_rewards: 217.0604, total_rewards: 2461.2961, mean_steps: 18.7400, mean_ecr: 0.0388 mean_entropies: 2.2083, took: 94.8570s
2022-10-08 23:28:35,022 [INFO] 	Process 5 - batch 2999: mean_policy_losses: -57.519, mean_net_lifetime: 3653.9963, mean_mc_travel_dist: 1345.6904, mean_rewards: 207.4501, total_rewards: 2338.5611, mean_steps: 17.9700, mean_ecr: 0.0391 mean_entropies: 2.1872, took: 83.8444s
2022-10-08 23:28:58,263 [INFO] 	Process 0 - batch 2999: mean_policy_losses: -68.753, mean_net_lifetime: 3442.1858, mean_mc_travel_dist: 1260.5711, mean_rewards: 206.2648, total_rewards: 2233.2420, mean_steps: 16.9700, mean_ecr: 0.0393 mean_entropies: 2.1509, took: 77.3743s
2022-10-08 23:39:19,904 [INFO] 	Process 2 - batch 3099: mean_policy_losses: -114.279, mean_net_lifetime: 3676.3002, mean_mc_travel_dist: 1430.8380, mean_rewards: 203.4412, total_rewards: 2286.5751, mean_steps: 20.3200, mean_ecr: 0.0382 mean_entropies: 2.0269, took: 686.3880s
2022-10-08 23:39:20,728 [INFO] 	Process 4 - batch 3099: mean_policy_losses: -202.493, mean_net_lifetime: 3337.6522, mean_mc_travel_dist: 1314.9329, mean_rewards: 203.0654, total_rewards: 2078.0382, mean_steps: 17.9700, mean_ecr: 0.0387 mean_entropies: 1.9884, took: 675.2500s
2022-10-08 23:39:31,056 [INFO] 	Process 6 - batch 3099: mean_policy_losses: -51.110, mean_net_lifetime: 3950.4089, mean_mc_travel_dist: 1545.2618, mean_rewards: 202.0285, total_rewards: 2439.4281, mean_steps: 21.6500, mean_ecr: 0.0386 mean_entropies: 2.0406, took: 690.5574s
2022-10-08 23:39:40,623 [INFO] 	Process 1 - batch 3099: mean_policy_losses: -69.134, mean_net_lifetime: 3605.9433, mean_mc_travel_dist: 1381.4754, mean_rewards: 207.3165, total_rewards: 2260.9837, mean_steps: 19.8200, mean_ecr: 0.0382 mean_entropies: 2.0406, took: 698.8515s
2022-10-08 23:40:08,845 [INFO] 	Process 3 - batch 3099: mean_policy_losses: -77.413, mean_net_lifetime: 3623.1745, mean_mc_travel_dist: 1379.4674, mean_rewards: 211.9464, total_rewards: 2281.1753, mean_steps: 19.0700, mean_ecr: 0.0383 mean_entropies: 2.0609, took: 790.0124s
2022-10-08 23:40:54,834 [INFO] 	Process 2 - batch 3199: mean_policy_losses: -44.370, mean_net_lifetime: 3720.2763, mean_mc_travel_dist: 1384.3584, mean_rewards: 214.7779, total_rewards: 2380.0163, mean_steps: 18.2500, mean_ecr: 0.0387 mean_entropies: 2.1514, took: 94.9301s
2022-10-08 23:40:57,488 [INFO] 	Process 4 - batch 3199: mean_policy_losses: 9.137, mean_net_lifetime: 3801.3220, mean_mc_travel_dist: 1373.9846, mean_rewards: 211.0003, total_rewards: 2477.0180, mean_steps: 18.8900, mean_ecr: 0.0381 mean_entropies: 2.1728, took: 96.7588s
2022-10-08 23:41:04,217 [INFO] 	Process 6 - batch 3199: mean_policy_losses: -78.947, mean_net_lifetime: 3742.0644, mean_mc_travel_dist: 1378.2597, mean_rewards: 210.2405, total_rewards: 2404.0251, mean_steps: 18.6100, mean_ecr: 0.0379 mean_entropies: 2.1584, took: 93.1610s
2022-10-08 23:41:13,241 [INFO] 	Process 1 - batch 3199: mean_policy_losses: -60.465, mean_net_lifetime: 3735.2346, mean_mc_travel_dist: 1378.1343, mean_rewards: 209.1375, total_rewards: 2404.8726, mean_steps: 18.5000, mean_ecr: 0.0387 mean_entropies: 2.1743, took: 92.6186s
2022-10-08 23:41:17,728 [INFO] 	Process 5 - batch 3099: mean_policy_losses: -263.092, mean_net_lifetime: 3429.0911, mean_mc_travel_dist: 1263.2351, mean_rewards: 208.7243, total_rewards: 2209.9720, mean_steps: 18.2200, mean_ecr: 0.0386 mean_entropies: 2.0935, took: 762.7066s
2022-10-08 23:41:48,533 [INFO] 	Process 0 - batch 3099: mean_policy_losses: -179.534, mean_net_lifetime: 3763.1323, mean_mc_travel_dist: 1420.7956, mean_rewards: 209.7547, total_rewards: 2388.0569, mean_steps: 19.9300, mean_ecr: 0.0379 mean_entropies: 2.1146, took: 770.2692s
2022-10-08 23:41:49,472 [INFO] 	Process 3 - batch 3199: mean_policy_losses: -90.478, mean_net_lifetime: 3924.7149, mean_mc_travel_dist: 1452.5412, mean_rewards: 212.2505, total_rewards: 2522.4858, mean_steps: 19.2300, mean_ecr: 0.0383 mean_entropies: 2.1799, took: 100.6273s
2022-10-08 23:42:21,487 [INFO] 	Process 4 - batch 3299: mean_policy_losses: -174.313, mean_net_lifetime: 3213.9632, mean_mc_travel_dist: 1157.7908, mean_rewards: 209.3685, total_rewards: 2098.2421, mean_steps: 16.0900, mean_ecr: 0.0393 mean_entropies: 2.1618, took: 83.9991s
2022-10-08 23:42:26,057 [INFO] 	Process 2 - batch 3299: mean_policy_losses: -205.164, mean_net_lifetime: 3296.1331, mean_mc_travel_dist: 1212.1024, mean_rewards: 208.6367, total_rewards: 2122.6690, mean_steps: 17.0600, mean_ecr: 0.0394 mean_entropies: 2.1508, took: 91.2237s
2022-10-08 23:42:32,885 [INFO] 	Process 6 - batch 3299: mean_policy_losses: -91.526, mean_net_lifetime: 3531.1397, mean_mc_travel_dist: 1276.3684, mean_rewards: 213.7416, total_rewards: 2290.8353, mean_steps: 17.1200, mean_ecr: 0.0392 mean_entropies: 2.1619, took: 88.6682s
2022-10-08 23:42:34,311 [INFO] 	Process 1 - batch 3299: mean_policy_losses: -118.956, mean_net_lifetime: 3276.8266, mean_mc_travel_dist: 1169.1862, mean_rewards: 212.6108, total_rewards: 2148.5889, mean_steps: 15.7400, mean_ecr: 0.0394 mean_entropies: 2.1606, took: 81.0691s
2022-10-08 23:42:47,741 [INFO] 	Process 5 - batch 3199: mean_policy_losses: -80.932, mean_net_lifetime: 3552.3742, mean_mc_travel_dist: 1252.6209, mean_rewards: 209.3290, total_rewards: 2335.4886, mean_steps: 17.3000, mean_ecr: 0.0381 mean_entropies: 2.1473, took: 90.0123s
2022-10-08 23:43:15,371 [INFO] 	Process 3 - batch 3299: mean_policy_losses: -241.503, mean_net_lifetime: 3299.7291, mean_mc_travel_dist: 1228.8668, mean_rewards: 215.4468, total_rewards: 2109.3784, mean_steps: 16.4500, mean_ecr: 0.0393 mean_entropies: 2.0876, took: 85.8995s
2022-10-08 23:43:29,070 [INFO] 	Process 0 - batch 3199: mean_policy_losses: -78.905, mean_net_lifetime: 3765.8287, mean_mc_travel_dist: 1425.7110, mean_rewards: 205.8743, total_rewards: 2387.3953, mean_steps: 19.2000, mean_ecr: 0.0382 mean_entropies: 2.0925, took: 100.5380s
2022-10-08 23:43:44,811 [INFO] 	Process 4 - batch 3399: mean_policy_losses: -69.373, mean_net_lifetime: 3274.8511, mean_mc_travel_dist: 1184.5438, mean_rewards: 202.0849, total_rewards: 2129.6881, mean_steps: 16.1600, mean_ecr: 0.0412 mean_entropies: 2.0472, took: 83.3243s
2022-10-08 23:43:54,599 [INFO] 	Process 1 - batch 3399: mean_policy_losses: -45.787, mean_net_lifetime: 3073.2372, mean_mc_travel_dist: 1095.9159, mean_rewards: 201.1370, total_rewards: 2018.1428, mean_steps: 15.5500, mean_ecr: 0.0416 mean_entropies: 2.0371, took: 80.2885s
2022-10-08 23:44:01,399 [INFO] 	Process 2 - batch 3399: mean_policy_losses: -112.710, mean_net_lifetime: 3449.1801, mean_mc_travel_dist: 1304.6828, mean_rewards: 203.8302, total_rewards: 2185.7517, mean_steps: 17.7300, mean_ecr: 0.0409 mean_entropies: 2.0606, took: 95.3418s
2022-10-08 23:44:09,238 [INFO] 	Process 6 - batch 3399: mean_policy_losses: -14.313, mean_net_lifetime: 3579.6138, mean_mc_travel_dist: 1308.8191, mean_rewards: 199.2604, total_rewards: 2309.7994, mean_steps: 18.4300, mean_ecr: 0.0405 mean_entropies: 2.0687, took: 96.3527s
2022-10-08 23:44:09,568 [INFO] 	Process 5 - batch 3299: mean_policy_losses: -115.510, mean_net_lifetime: 3086.6832, mean_mc_travel_dist: 1133.0292, mean_rewards: 202.6341, total_rewards: 1989.1745, mean_steps: 15.7100, mean_ecr: 0.0397 mean_entropies: 2.0492, took: 81.8274s
2022-10-08 23:44:40,299 [INFO] 	Process 3 - batch 3399: mean_policy_losses: -33.413, mean_net_lifetime: 3244.1512, mean_mc_travel_dist: 1177.5924, mean_rewards: 205.9587, total_rewards: 2101.9148, mean_steps: 16.4600, mean_ecr: 0.0410 mean_entropies: 2.0821, took: 84.9280s
2022-10-08 23:44:53,525 [INFO] 	Process 0 - batch 3299: mean_policy_losses: -95.214, mean_net_lifetime: 3217.6308, mean_mc_travel_dist: 1166.9115, mean_rewards: 211.0874, total_rewards: 2088.8184, mean_steps: 16.2500, mean_ecr: 0.0394 mean_entropies: 2.0999, took: 84.4552s
2022-10-08 23:45:20,122 [INFO] 	Process 4 - batch 3499: mean_policy_losses: -68.678, mean_net_lifetime: 3610.8331, mean_mc_travel_dist: 1344.8125, mean_rewards: 202.2324, total_rewards: 2304.4896, mean_steps: 18.3500, mean_ecr: 0.0384 mean_entropies: 2.0621, took: 95.3116s
2022-10-08 23:45:24,457 [INFO] 	Process 1 - batch 3499: mean_policy_losses: -31.008, mean_net_lifetime: 3579.1359, mean_mc_travel_dist: 1301.9468, mean_rewards: 216.2149, total_rewards: 2318.0869, mean_steps: 17.7700, mean_ecr: 0.0389 mean_entropies: 2.0515, took: 89.8579s
2022-10-08 23:45:33,405 [INFO] 	Process 2 - batch 3499: mean_policy_losses: -60.616, mean_net_lifetime: 3416.5933, mean_mc_travel_dist: 1257.3885, mean_rewards: 209.9943, total_rewards: 2210.0623, mean_steps: 17.2400, mean_ecr: 0.0387 mean_entropies: 2.0344, took: 92.0052s
2022-10-08 23:45:34,507 [INFO] 	Process 6 - batch 3499: mean_policy_losses: -137.771, mean_net_lifetime: 3210.8271, mean_mc_travel_dist: 1188.7790, mean_rewards: 213.3246, total_rewards: 2073.1280, mean_steps: 16.1800, mean_ecr: 0.0387 mean_entropies: 2.0380, took: 85.2691s
2022-10-08 23:45:41,412 [INFO] 	Process 5 - batch 3399: mean_policy_losses: -14.055, mean_net_lifetime: 3357.7309, mean_mc_travel_dist: 1249.3300, mean_rewards: 194.7682, total_rewards: 2150.9293, mean_steps: 17.7100, mean_ecr: 0.0407 mean_entropies: 2.0756, took: 91.8443s
2022-10-08 23:46:08,585 [INFO] 	Process 3 - batch 3499: mean_policy_losses: -66.686, mean_net_lifetime: 3331.6336, mean_mc_travel_dist: 1232.4805, mean_rewards: 203.2169, total_rewards: 2146.7396, mean_steps: 16.8400, mean_ecr: 0.0388 mean_entropies: 1.9341, took: 88.2866s
2022-10-08 23:46:14,660 [INFO] 	Process 0 - batch 3399: mean_policy_losses: -21.161, mean_net_lifetime: 3076.5650, mean_mc_travel_dist: 1141.2422, mean_rewards: 205.9332, total_rewards: 1975.6889, mean_steps: 15.1200, mean_ecr: 0.0412 mean_entropies: 2.0166, took: 81.1350s
2022-10-08 23:46:41,347 [INFO] 	Process 4 - batch 3599: mean_policy_losses: -123.545, mean_net_lifetime: 2940.3018, mean_mc_travel_dist: 1077.1717, mean_rewards: 205.3568, total_rewards: 1909.1332, mean_steps: 15.3400, mean_ecr: 0.0415 mean_entropies: 2.0047, took: 81.2249s
2022-10-08 23:46:47,178 [INFO] 	Process 1 - batch 3599: mean_policy_losses: -72.794, mean_net_lifetime: 3120.3294, mean_mc_travel_dist: 1132.9806, mean_rewards: 208.9493, total_rewards: 2030.7634, mean_steps: 16.0700, mean_ecr: 0.0413 mean_entropies: 2.0479, took: 82.7216s
2022-10-08 23:46:51,063 [INFO] 	Process 2 - batch 3599: mean_policy_losses: -85.319, mean_net_lifetime: 2986.0803, mean_mc_travel_dist: 1086.1878, mean_rewards: 205.3620, total_rewards: 1944.9000, mean_steps: 14.8600, mean_ecr: 0.0415 mean_entropies: 2.0226, took: 77.6587s
2022-10-08 23:46:51,868 [INFO] 	Process 6 - batch 3599: mean_policy_losses: -119.612, mean_net_lifetime: 2837.3982, mean_mc_travel_dist: 1012.5622, mean_rewards: 204.3413, total_rewards: 1878.8387, mean_steps: 14.4700, mean_ecr: 0.0416 mean_entropies: 2.0498, took: 77.3606s
2022-10-08 23:47:11,450 [INFO] 	Process 5 - batch 3499: mean_policy_losses: -31.549, mean_net_lifetime: 3308.6631, mean_mc_travel_dist: 1221.6440, mean_rewards: 208.1160, total_rewards: 2132.9995, mean_steps: 17.2500, mean_ecr: 0.0389 mean_entropies: 2.0096, took: 90.0375s
2022-10-08 23:47:30,447 [INFO] 	Process 3 - batch 3599: mean_policy_losses: -154.756, mean_net_lifetime: 3104.5144, mean_mc_travel_dist: 1096.8640, mean_rewards: 209.5868, total_rewards: 2052.4304, mean_steps: 15.7200, mean_ecr: 0.0414 mean_entropies: 2.1186, took: 81.8622s
2022-10-08 23:47:44,807 [INFO] 	Process 0 - batch 3499: mean_policy_losses: -79.701, mean_net_lifetime: 3401.4027, mean_mc_travel_dist: 1261.3033, mean_rewards: 212.6791, total_rewards: 2180.3286, mean_steps: 17.3200, mean_ecr: 0.0391 mean_entropies: 2.0820, took: 90.1468s
2022-10-08 23:48:11,796 [INFO] 	Process 4 - batch 3699: mean_policy_losses: -110.032, mean_net_lifetime: 3387.2469, mean_mc_travel_dist: 1218.2646, mean_rewards: 209.4585, total_rewards: 2208.5717, mean_steps: 17.2500, mean_ecr: 0.0375 mean_entropies: 2.1215, took: 90.4480s
2022-10-08 23:48:13,020 [INFO] 	Process 1 - batch 3699: mean_policy_losses: -0.145, mean_net_lifetime: 3430.8243, mean_mc_travel_dist: 1233.7115, mean_rewards: 210.9048, total_rewards: 2238.0261, mean_steps: 16.9300, mean_ecr: 0.0378 mean_entropies: 2.1482, took: 85.8410s
2022-10-08 23:48:18,918 [INFO] 	Process 6 - batch 3699: mean_policy_losses: -10.669, mean_net_lifetime: 3356.5130, mean_mc_travel_dist: 1197.8473, mean_rewards: 211.3420, total_rewards: 2207.5311, mean_steps: 16.4900, mean_ecr: 0.0375 mean_entropies: 2.1264, took: 87.0503s
2022-10-08 23:48:22,017 [INFO] 	Process 2 - batch 3699: mean_policy_losses: 42.730, mean_net_lifetime: 3504.3167, mean_mc_travel_dist: 1240.7468, mean_rewards: 209.1502, total_rewards: 2304.1176, mean_steps: 17.5800, mean_ecr: 0.0378 mean_entropies: 2.1290, took: 90.9534s
2022-10-08 23:48:28,650 [INFO] 	Process 5 - batch 3599: mean_policy_losses: -168.726, mean_net_lifetime: 2869.3891, mean_mc_travel_dist: 1026.3634, mean_rewards: 205.3106, total_rewards: 1879.8852, mean_steps: 14.3900, mean_ecr: 0.0416 mean_entropies: 2.0984, took: 77.1994s
2022-10-08 23:49:03,827 [INFO] 	Process 3 - batch 3699: mean_policy_losses: -7.363, mean_net_lifetime: 3598.9911, mean_mc_travel_dist: 1297.9933, mean_rewards: 207.6867, total_rewards: 2332.5549, mean_steps: 18.2000, mean_ecr: 0.0375 mean_entropies: 2.1220, took: 93.3795s
2022-10-08 23:49:16,182 [INFO] 	Process 0 - batch 3599: mean_policy_losses: -209.202, mean_net_lifetime: 3064.4926, mean_mc_travel_dist: 1110.0742, mean_rewards: 201.6321, total_rewards: 1994.6307, mean_steps: 17.1800, mean_ecr: 0.0414 mean_entropies: 2.0448, took: 91.3755s
2022-10-08 23:49:38,142 [INFO] 	Process 4 - batch 3799: mean_policy_losses: -10.171, mean_net_lifetime: 3337.7736, mean_mc_travel_dist: 1231.9648, mean_rewards: 207.0347, total_rewards: 2143.2047, mean_steps: 16.6900, mean_ecr: 0.0401 mean_entropies: 2.1090, took: 86.3465s
2022-10-08 23:49:44,954 [INFO] 	Process 1 - batch 3799: mean_policy_losses: -57.051, mean_net_lifetime: 3475.2028, mean_mc_travel_dist: 1288.0673, mean_rewards: 203.5945, total_rewards: 2223.6256, mean_steps: 18.1500, mean_ecr: 0.0397 mean_entropies: 2.1063, took: 91.9347s
2022-10-08 23:49:46,192 [INFO] 	Process 6 - batch 3799: mean_policy_losses: -59.017, mean_net_lifetime: 3293.7193, mean_mc_travel_dist: 1206.4572, mean_rewards: 208.5936, total_rewards: 2119.5584, mean_steps: 16.4400, mean_ecr: 0.0402 mean_entropies: 2.1068, took: 87.2735s
2022-10-08 23:49:57,259 [INFO] 	Process 2 - batch 3799: mean_policy_losses: -9.860, mean_net_lifetime: 3481.8507, mean_mc_travel_dist: 1288.5002, mean_rewards: 201.6704, total_rewards: 2234.4833, mean_steps: 18.3100, mean_ecr: 0.0399 mean_entropies: 2.0997, took: 95.2423s
2022-10-08 23:49:57,390 [INFO] 	Process 5 - batch 3699: mean_policy_losses: -84.490, mean_net_lifetime: 3362.1373, mean_mc_travel_dist: 1208.7811, mean_rewards: 206.7007, total_rewards: 2205.1418, mean_steps: 17.1700, mean_ecr: 0.0378 mean_entropies: 2.0990, took: 88.7408s
2022-10-08 23:50:36,948 [INFO] 	Process 3 - batch 3799: mean_policy_losses: -20.372, mean_net_lifetime: 3425.9241, mean_mc_travel_dist: 1289.2764, mean_rewards: 198.1163, total_rewards: 2176.8310, mean_steps: 17.9600, mean_ecr: 0.0396 mean_entropies: 2.1151, took: 93.1216s
2022-10-08 23:50:44,918 [INFO] 	Process 0 - batch 3699: mean_policy_losses: -52.482, mean_net_lifetime: 3235.7267, mean_mc_travel_dist: 1166.2711, mean_rewards: 198.6468, total_rewards: 2111.6595, mean_steps: 16.7600, mean_ecr: 0.0379 mean_entropies: 2.0657, took: 88.7361s
2022-10-08 23:51:04,681 [INFO] 	Process 4 - batch 3899: mean_policy_losses: -25.085, mean_net_lifetime: 3305.7809, mean_mc_travel_dist: 1238.3904, mean_rewards: 205.0350, total_rewards: 2105.5988, mean_steps: 16.3500, mean_ecr: 0.0405 mean_entropies: 2.0317, took: 86.5388s
2022-10-08 23:51:07,060 [INFO] 	Process 6 - batch 3899: mean_policy_losses: -95.354, mean_net_lifetime: 3077.9311, mean_mc_travel_dist: 1115.3836, mean_rewards: 205.2480, total_rewards: 2006.3831, mean_steps: 15.3200, mean_ecr: 0.0408 mean_entropies: 1.9991, took: 80.8686s
2022-10-08 23:51:09,802 [INFO] 	Process 1 - batch 3899: mean_policy_losses: -21.314, mean_net_lifetime: 3297.9046, mean_mc_travel_dist: 1217.1946, mean_rewards: 202.6815, total_rewards: 2118.6642, mean_steps: 16.6800, mean_ecr: 0.0404 mean_entropies: 2.0187, took: 84.8480s
2022-10-08 23:51:21,337 [INFO] 	Process 2 - batch 3899: mean_policy_losses: -4.299, mean_net_lifetime: 3264.2776, mean_mc_travel_dist: 1185.5104, mean_rewards: 207.4044, total_rewards: 2112.7102, mean_steps: 15.8900, mean_ecr: 0.0403 mean_entropies: 2.0193, took: 84.0776s
2022-10-08 23:51:26,039 [INFO] 	Process 5 - batch 3799: mean_policy_losses: -65.707, mean_net_lifetime: 3224.8098, mean_mc_travel_dist: 1220.8886, mean_rewards: 195.7970, total_rewards: 2044.5449, mean_steps: 17.1000, mean_ecr: 0.0400 mean_entropies: 2.0612, took: 88.6479s
2022-10-08 23:51:58,193 [INFO] 	Process 3 - batch 3899: mean_policy_losses: -85.773, mean_net_lifetime: 3166.1162, mean_mc_travel_dist: 1158.0620, mean_rewards: 202.2542, total_rewards: 2052.8669, mean_steps: 15.3100, mean_ecr: 0.0409 mean_entropies: 1.9899, took: 81.2444s
2022-10-08 23:52:21,078 [INFO] 	Process 0 - batch 3799: mean_policy_losses: 49.276, mean_net_lifetime: 3555.5466, mean_mc_travel_dist: 1318.4845, mean_rewards: 200.4538, total_rewards: 2283.0207, mean_steps: 18.0200, mean_ecr: 0.0397 mean_entropies: 2.0376, took: 96.1594s
2022-10-08 23:52:24,480 [INFO] 	Process 6 - batch 3999: mean_policy_losses: -122.289, mean_net_lifetime: 3042.3432, mean_mc_travel_dist: 1110.9603, mean_rewards: 206.9241, total_rewards: 1978.6963, mean_steps: 14.6800, mean_ecr: 0.0410 mean_entropies: 2.0209, took: 77.4196s
2022-10-08 23:52:27,189 [INFO] 	Process 4 - batch 3999: mean_policy_losses: -98.614, mean_net_lifetime: 3175.8465, mean_mc_travel_dist: 1153.1784, mean_rewards: 211.1709, total_rewards: 2069.5410, mean_steps: 15.4500, mean_ecr: 0.0409 mean_entropies: 2.0491, took: 82.5078s
2022-10-08 23:52:31,547 [INFO] 	Process 1 - batch 3999: mean_policy_losses: -62.275, mean_net_lifetime: 3246.7073, mean_mc_travel_dist: 1206.5202, mean_rewards: 208.8403, total_rewards: 2079.0476, mean_steps: 16.0700, mean_ecr: 0.0411 mean_entropies: 2.0305, took: 81.7453s
2022-10-08 23:52:36,647 [INFO] 	Process 2 - batch 3999: mean_policy_losses: -148.626, mean_net_lifetime: 3045.3821, mean_mc_travel_dist: 1116.9784, mean_rewards: 210.4481, total_rewards: 1972.1317, mean_steps: 14.6100, mean_ecr: 0.0412 mean_entropies: 2.0022, took: 75.3105s
2022-10-08 23:52:52,164 [INFO] 	Process 5 - batch 3899: mean_policy_losses: -67.637, mean_net_lifetime: 3212.6787, mean_mc_travel_dist: 1204.1690, mean_rewards: 201.7286, total_rewards: 2053.9221, mean_steps: 16.0300, mean_ecr: 0.0405 mean_entropies: 1.9628, took: 86.1258s
2022-10-08 23:53:13,024 [INFO] 	Process 3 - batch 3999: mean_policy_losses: -158.872, mean_net_lifetime: 2861.7519, mean_mc_travel_dist: 1088.4571, mean_rewards: 210.0878, total_rewards: 1820.4701, mean_steps: 14.0700, mean_ecr: 0.0408 mean_entropies: 1.8796, took: 74.8306s
2022-10-08 23:53:34,758 [INFO] 	Process 0 - batch 3899: mean_policy_losses: -82.587, mean_net_lifetime: 2917.7223, mean_mc_travel_dist: 1091.3321, mean_rewards: 208.9326, total_rewards: 1857.7471, mean_steps: 13.9400, mean_ecr: 0.0406 mean_entropies: 1.8698, took: 73.6793s
2022-10-08 23:53:43,918 [INFO] 	Process 6 - batch 4099: mean_policy_losses: -45.118, mean_net_lifetime: 3089.1400, mean_mc_travel_dist: 1169.7384, mean_rewards: 205.4680, total_rewards: 1960.0259, mean_steps: 14.8900, mean_ecr: 0.0409 mean_entropies: 1.8571, took: 79.4384s
2022-10-08 23:53:47,380 [INFO] 	Process 4 - batch 4099: mean_policy_losses: -51.405, mean_net_lifetime: 3072.1093, mean_mc_travel_dist: 1180.1960, mean_rewards: 204.3173, total_rewards: 1944.1221, mean_steps: 15.3100, mean_ecr: 0.0408 mean_entropies: 1.8355, took: 80.1919s
2022-10-08 23:53:51,018 [INFO] 	Process 1 - batch 4099: mean_policy_losses: -58.636, mean_net_lifetime: 3157.2678, mean_mc_travel_dist: 1231.6670, mean_rewards: 202.2486, total_rewards: 1977.6375, mean_steps: 15.5600, mean_ecr: 0.0408 mean_entropies: 1.8314, took: 79.4706s
2022-10-08 23:53:54,532 [INFO] 	Process 2 - batch 4099: mean_policy_losses: -48.751, mean_net_lifetime: 3050.3890, mean_mc_travel_dist: 1197.5164, mean_rewards: 206.7462, total_rewards: 1903.1994, mean_steps: 14.8000, mean_ecr: 0.0405 mean_entropies: 1.8279, took: 77.8852s
2022-10-08 23:54:12,679 [INFO] 	Process 5 - batch 3999: mean_policy_losses: -99.291, mean_net_lifetime: 3012.0163, mean_mc_travel_dist: 1163.0577, mean_rewards: 208.5232, total_rewards: 1895.5370, mean_steps: 14.7900, mean_ecr: 0.0408 mean_entropies: 1.8736, took: 80.5151s
2022-10-08 23:54:38,007 [INFO] 	Process 3 - batch 4099: mean_policy_losses: 26.995, mean_net_lifetime: 3381.4887, mean_mc_travel_dist: 1274.9230, mean_rewards: 198.8013, total_rewards: 2154.0662, mean_steps: 16.7600, mean_ecr: 0.0406 mean_entropies: 1.8517, took: 84.9833s
2022-10-08 23:54:46,026 [INFO] 	Process 0 - batch 3999: mean_policy_losses: -74.675, mean_net_lifetime: 2862.9890, mean_mc_travel_dist: 1077.9386, mean_rewards: 218.5635, total_rewards: 1834.4432, mean_steps: 13.5500, mean_ecr: 0.0411 mean_entropies: 1.8908, took: 71.2680s
2022-10-08 23:55:03,776 [INFO] 	Process 4 - batch 4199: mean_policy_losses: -160.919, mean_net_lifetime: 2905.7160, mean_mc_travel_dist: 1117.7832, mean_rewards: 207.4728, total_rewards: 1827.1159, mean_steps: 14.2900, mean_ecr: 0.0389 mean_entropies: 1.8620, took: 76.3962s
2022-10-08 23:55:07,621 [INFO] 	Process 1 - batch 4199: mean_policy_losses: -64.592, mean_net_lifetime: 3012.8468, mean_mc_travel_dist: 1144.0396, mean_rewards: 205.3944, total_rewards: 1901.8445, mean_steps: 14.9300, mean_ecr: 0.0392 mean_entropies: 1.8837, took: 76.6035s
2022-10-08 23:55:07,727 [INFO] 	Process 6 - batch 4199: mean_policy_losses: -64.294, mean_net_lifetime: 3225.1323, mean_mc_travel_dist: 1236.2460, mean_rewards: 208.4330, total_rewards: 2034.2997, mean_steps: 16.0500, mean_ecr: 0.0388 mean_entropies: 1.8713, took: 83.8088s
2022-10-08 23:55:14,364 [INFO] 	Process 2 - batch 4199: mean_policy_losses: -79.776, mean_net_lifetime: 3031.6370, mean_mc_travel_dist: 1171.5470, mean_rewards: 208.0200, total_rewards: 1915.3123, mean_steps: 14.9700, mean_ecr: 0.0392 mean_entropies: 1.8759, took: 79.8315s
2022-10-08 23:55:33,939 [INFO] 	Process 5 - batch 4099: mean_policy_losses: 23.497, mean_net_lifetime: 3142.1615, mean_mc_travel_dist: 1170.9392, mean_rewards: 202.1581, total_rewards: 2013.3026, mean_steps: 15.4700, mean_ecr: 0.0406 mean_entropies: 1.9580, took: 81.2607s
2022-10-08 23:55:58,208 [INFO] 	Process 3 - batch 4199: mean_policy_losses: -120.221, mean_net_lifetime: 2982.4840, mean_mc_travel_dist: 1122.7866, mean_rewards: 211.2920, total_rewards: 1896.4536, mean_steps: 14.8700, mean_ecr: 0.0390 mean_entropies: 1.9450, took: 80.2008s
2022-10-08 23:56:13,873 [INFO] 	Process 0 - batch 4099: mean_policy_losses: 120.166, mean_net_lifetime: 3440.8503, mean_mc_travel_dist: 1234.4510, mean_rewards: 211.2753, total_rewards: 2249.0177, mean_steps: 16.4000, mean_ecr: 0.0406 mean_entropies: 1.9993, took: 87.8477s
2022-10-08 23:56:19,359 [INFO] 	Process 4 - batch 4299: mean_policy_losses: -107.812, mean_net_lifetime: 2964.3836, mean_mc_travel_dist: 1060.8872, mean_rewards: 208.7219, total_rewards: 1942.2451, mean_steps: 14.3900, mean_ecr: 0.0401 mean_entropies: 1.9940, took: 75.5823s
2022-10-08 23:56:22,989 [INFO] 	Process 6 - batch 4299: mean_policy_losses: -164.776, mean_net_lifetime: 2859.7087, mean_mc_travel_dist: 1032.4305, mean_rewards: 208.4046, total_rewards: 1870.7223, mean_steps: 14.3300, mean_ecr: 0.0402 mean_entropies: 2.0231, took: 75.2627s
2022-10-08 23:56:27,097 [INFO] 	Process 1 - batch 4299: mean_policy_losses: -65.252, mean_net_lifetime: 3121.3535, mean_mc_travel_dist: 1131.2188, mean_rewards: 210.1685, total_rewards: 2025.6190, mean_steps: 15.4800, mean_ecr: 0.0399 mean_entropies: 2.0129, took: 79.4755s
2022-10-08 23:56:37,177 [INFO] 	Process 2 - batch 4299: mean_policy_losses: -80.367, mean_net_lifetime: 3022.9207, mean_mc_travel_dist: 1095.8716, mean_rewards: 202.7714, total_rewards: 1967.2674, mean_steps: 15.6000, mean_ecr: 0.0402 mean_entropies: 1.9788, took: 82.8140s
2022-10-08 23:56:57,287 [INFO] 	Process 5 - batch 4199: mean_policy_losses: -27.769, mean_net_lifetime: 3175.6686, mean_mc_travel_dist: 1187.4669, mean_rewards: 201.0768, total_rewards: 2032.3454, mean_steps: 16.1400, mean_ecr: 0.0389 mean_entropies: 1.9427, took: 83.3474s
2022-10-08 23:57:17,465 [INFO] 	Process 3 - batch 4299: mean_policy_losses: -42.024, mean_net_lifetime: 3045.1639, mean_mc_travel_dist: 1121.2915, mean_rewards: 207.4347, total_rewards: 1974.8762, mean_steps: 14.8300, mean_ecr: 0.0399 mean_entropies: 1.9358, took: 79.2573s
2022-10-08 23:57:44,360 [INFO] 	Process 4 - batch 4399: mean_policy_losses: -6.764, mean_net_lifetime: 3178.5504, mean_mc_travel_dist: 1161.5605, mean_rewards: 207.6986, total_rewards: 2056.9024, mean_steps: 16.2300, mean_ecr: 0.0395 mean_entropies: 1.9571, took: 85.0012s
2022-10-08 23:57:44,993 [INFO] 	Process 0 - batch 4199: mean_policy_losses: -105.102, mean_net_lifetime: 3280.4691, mean_mc_travel_dist: 1244.3851, mean_rewards: 206.8087, total_rewards: 2090.1558, mean_steps: 16.8900, mean_ecr: 0.0390 mean_entropies: 1.8902, took: 91.1202s
2022-10-08 23:57:45,846 [INFO] 	Process 1 - batch 4399: mean_policy_losses: -79.564, mean_net_lifetime: 3035.5251, mean_mc_travel_dist: 1101.7386, mean_rewards: 209.0844, total_rewards: 1967.7344, mean_steps: 15.3700, mean_ecr: 0.0400 mean_entropies: 1.9174, took: 78.7489s
2022-10-08 23:57:49,962 [INFO] 	Process 6 - batch 4399: mean_policy_losses: -30.662, mean_net_lifetime: 3226.8734, mean_mc_travel_dist: 1205.1966, mean_rewards: 205.9277, total_rewards: 2072.3627, mean_steps: 16.3800, mean_ecr: 0.0394 mean_entropies: 1.9383, took: 86.9720s
2022-10-08 23:58:04,406 [INFO] 	Process 2 - batch 4399: mean_policy_losses: -26.298, mean_net_lifetime: 3272.2481, mean_mc_travel_dist: 1207.5577, mean_rewards: 214.3143, total_rewards: 2105.0264, mean_steps: 16.5200, mean_ecr: 0.0394 mean_entropies: 1.9674, took: 87.2283s
2022-10-08 23:58:12,831 [INFO] 	Process 5 - batch 4299: mean_policy_losses: -226.063, mean_net_lifetime: 2892.8896, mean_mc_travel_dist: 1025.9218, mean_rewards: 205.5580, total_rewards: 1905.8603, mean_steps: 14.5800, mean_ecr: 0.0402 mean_entropies: 1.9866, took: 75.5443s
2022-10-08 23:58:45,842 [INFO] 	Process 3 - batch 4399: mean_policy_losses: -136.919, mean_net_lifetime: 3220.3362, mean_mc_travel_dist: 1169.9660, mean_rewards: 208.0552, total_rewards: 2089.9633, mean_steps: 17.1600, mean_ecr: 0.0395 mean_entropies: 2.0194, took: 88.3765s
2022-10-08 23:59:03,522 [INFO] 	Process 0 - batch 4299: mean_policy_losses: -149.315, mean_net_lifetime: 2981.0483, mean_mc_travel_dist: 1044.7473, mean_rewards: 205.2161, total_rewards: 1979.1070, mean_steps: 14.6300, mean_ecr: 0.0401 mean_entropies: 2.0232, took: 78.5288s
2022-10-08 23:59:10,859 [INFO] 	Process 4 - batch 4499: mean_policy_losses: -63.320, mean_net_lifetime: 3437.7850, mean_mc_travel_dist: 1225.7667, mean_rewards: 215.7739, total_rewards: 2254.7173, mean_steps: 16.5200, mean_ecr: 0.0395 mean_entropies: 2.0974, took: 86.4995s
2022-10-08 23:59:14,076 [INFO] 	Process 1 - batch 4499: mean_policy_losses: -81.819, mean_net_lifetime: 3431.4320, mean_mc_travel_dist: 1230.5481, mean_rewards: 210.3503, total_rewards: 2237.8189, mean_steps: 17.3200, mean_ecr: 0.0393 mean_entropies: 2.0757, took: 88.2297s
2022-10-08 23:59:18,275 [INFO] 	Process 6 - batch 4499: mean_policy_losses: -144.377, mean_net_lifetime: 3352.4363, mean_mc_travel_dist: 1216.4430, mean_rewards: 209.5590, total_rewards: 2177.3709, mean_steps: 17.0400, mean_ecr: 0.0396 mean_entropies: 2.0742, took: 88.3141s
2022-10-08 23:59:27,057 [INFO] 	Process 2 - batch 4499: mean_policy_losses: -151.196, mean_net_lifetime: 3233.4440, mean_mc_travel_dist: 1144.9303, mean_rewards: 212.6784, total_rewards: 2128.8502, mean_steps: 15.8000, mean_ecr: 0.0393 mean_entropies: 2.0756, took: 82.6503s
2022-10-08 23:59:41,312 [INFO] 	Process 5 - batch 4399: mean_policy_losses: -19.066, mean_net_lifetime: 3402.4312, mean_mc_travel_dist: 1276.4867, mean_rewards: 210.6791, total_rewards: 2164.9226, mean_steps: 17.8100, mean_ecr: 0.0397 mean_entropies: 2.0233, took: 88.4808s
2022-10-09 00:00:04,831 [INFO] 	Process 3 - batch 4499: mean_policy_losses: -32.984, mean_net_lifetime: 3375.2352, mean_mc_travel_dist: 1224.0547, mean_rewards: 218.1521, total_rewards: 2191.5034, mean_steps: 16.0300, mean_ecr: 0.0396 mean_entropies: 2.0283, took: 78.9893s
2022-10-09 00:00:15,853 [INFO] 	Process 0 - batch 4399: mean_policy_losses: -148.986, mean_net_lifetime: 2976.0670, mean_mc_travel_dist: 1125.1612, mean_rewards: 207.7626, total_rewards: 1888.2899, mean_steps: 15.1100, mean_ecr: 0.0396 mean_entropies: 1.9192, took: 72.3308s
2022-10-09 00:00:56,379 [INFO] 	Process 5 - batch 4499: mean_policy_losses: -99.520, mean_net_lifetime: 3255.0158, mean_mc_travel_dist: 1224.8034, mean_rewards: 204.9831, total_rewards: 2084.4597, mean_steps: 16.8200, mean_ecr: 0.0395 mean_entropies: 1.9694, took: 75.0676s
2022-10-09 00:01:29,744 [INFO] 	Process 0 - batch 4499: mean_policy_losses: -117.660, mean_net_lifetime: 3185.7797, mean_mc_travel_dist: 1166.6323, mean_rewards: 211.5368, total_rewards: 2066.5607, mean_steps: 16.1500, mean_ecr: 0.0396 mean_entropies: 2.0043, took: 73.8913s
2022-10-09 00:09:56,275 [INFO] 	Process 4 - batch 4599: mean_policy_losses: -82.949, mean_net_lifetime: 3261.7303, mean_mc_travel_dist: 1174.0393, mean_rewards: 215.7577, total_rewards: 2133.3434, mean_steps: 16.0700, mean_ecr: 0.0397 mean_entropies: 2.0366, took: 645.4160s
2022-10-09 00:09:59,433 [INFO] 	Process 3 - batch 4599: mean_policy_losses: -56.418, mean_net_lifetime: 3269.1071, mean_mc_travel_dist: 1168.9433, mean_rewards: 212.5548, total_rewards: 2144.5294, mean_steps: 16.5900, mean_ecr: 0.0396 mean_entropies: 2.0443, took: 594.6024s
2022-10-09 00:10:08,712 [INFO] 	Process 2 - batch 4599: mean_policy_losses: -73.727, mean_net_lifetime: 3148.4390, mean_mc_travel_dist: 1109.7651, mean_rewards: 210.9162, total_rewards: 2081.1098, mean_steps: 15.6600, mean_ecr: 0.0399 mean_entropies: 2.0753, took: 641.6550s
2022-10-09 00:10:37,263 [INFO] 	Process 1 - batch 4599: mean_policy_losses: -104.158, mean_net_lifetime: 3257.4092, mean_mc_travel_dist: 1166.5126, mean_rewards: 207.6035, total_rewards: 2133.5113, mean_steps: 16.6900, mean_ecr: 0.0400 mean_entropies: 2.0870, took: 683.1875s
2022-10-09 00:10:40,652 [INFO] 	Process 6 - batch 4599: mean_policy_losses: -130.718, mean_net_lifetime: 3251.9206, mean_mc_travel_dist: 1164.9499, mean_rewards: 214.6462, total_rewards: 2123.5260, mean_steps: 16.1000, mean_ecr: 0.0399 mean_entropies: 2.0808, took: 682.3759s
2022-10-09 00:11:27,670 [INFO] 	Process 4 - batch 4699: mean_policy_losses: -147.481, mean_net_lifetime: 3564.0368, mean_mc_travel_dist: 1266.9497, mean_rewards: 207.7161, total_rewards: 2336.1776, mean_steps: 18.8500, mean_ecr: 0.0398 mean_entropies: 2.1133, took: 91.3938s
2022-10-09 00:11:29,090 [INFO] 	Process 3 - batch 4699: mean_policy_losses: -146.555, mean_net_lifetime: 3563.4437, mean_mc_travel_dist: 1260.9370, mean_rewards: 214.5381, total_rewards: 2338.2183, mean_steps: 18.2400, mean_ecr: 0.0397 mean_entropies: 2.1045, took: 89.6559s
2022-10-09 00:11:34,940 [INFO] 	Process 2 - batch 4699: mean_policy_losses: -166.268, mean_net_lifetime: 3455.7385, mean_mc_travel_dist: 1207.2536, mean_rewards: 209.8890, total_rewards: 2289.0145, mean_steps: 17.5400, mean_ecr: 0.0400 mean_entropies: 2.0949, took: 86.2286s
2022-10-09 00:12:04,481 [INFO] 	Process 1 - batch 4699: mean_policy_losses: -156.281, mean_net_lifetime: 3621.7241, mean_mc_travel_dist: 1269.7294, mean_rewards: 216.3571, total_rewards: 2390.7166, mean_steps: 18.4100, mean_ecr: 0.0397 mean_entropies: 2.0951, took: 87.2185s
2022-10-09 00:12:13,271 [INFO] 	Process 6 - batch 4699: mean_policy_losses: -21.008, mean_net_lifetime: 3766.1133, mean_mc_travel_dist: 1346.2620, mean_rewards: 207.7723, total_rewards: 2451.8555, mean_steps: 19.2800, mean_ecr: 0.0395 mean_entropies: 2.1209, took: 92.6183s
2022-10-09 00:12:41,848 [INFO] 	Process 3 - batch 4799: mean_policy_losses: -238.329, mean_net_lifetime: 3188.0132, mean_mc_travel_dist: 1134.8275, mean_rewards: 220.7535, total_rewards: 2096.1826, mean_steps: 15.1800, mean_ecr: 0.0400 mean_entropies: 2.0775, took: 72.7592s
2022-10-09 00:12:52,730 [INFO] 	Process 2 - batch 4799: mean_policy_losses: -150.122, mean_net_lifetime: 3153.4500, mean_mc_travel_dist: 1117.2456, mean_rewards: 216.6150, total_rewards: 2081.2378, mean_steps: 15.2600, mean_ecr: 0.0403 mean_entropies: 2.0741, took: 77.7897s
2022-10-09 00:12:54,983 [INFO] 	Process 4 - batch 4799: mean_policy_losses: -136.788, mean_net_lifetime: 3528.6894, mean_mc_travel_dist: 1309.8445, mean_rewards: 214.8957, total_rewards: 2258.1545, mean_steps: 17.8100, mean_ecr: 0.0399 mean_entropies: 2.0866, took: 87.3127s
2022-10-09 00:13:25,651 [INFO] 	Process 1 - batch 4799: mean_policy_losses: -167.758, mean_net_lifetime: 3395.1289, mean_mc_travel_dist: 1228.3338, mean_rewards: 216.9445, total_rewards: 2212.0998, mean_steps: 16.5600, mean_ecr: 0.0402 mean_entropies: 2.0154, took: 81.1698s
2022-10-09 00:13:35,107 [INFO] 	Process 6 - batch 4799: mean_policy_losses: -82.965, mean_net_lifetime: 3342.4119, mean_mc_travel_dist: 1196.9017, mean_rewards: 213.3283, total_rewards: 2185.8858, mean_steps: 16.3500, mean_ecr: 0.0402 mean_entropies: 2.0573, took: 81.8370s
2022-10-09 00:13:52,348 [INFO] 	Process 5 - batch 4599: mean_policy_losses: -178.281, mean_net_lifetime: 3094.6312, mean_mc_travel_dist: 1118.4322, mean_rewards: 211.6879, total_rewards: 2024.5232, mean_steps: 15.9000, mean_ecr: 0.0400 mean_entropies: 1.9998, took: 775.9683s
2022-10-09 00:14:14,419 [INFO] 	Process 3 - batch 4899: mean_policy_losses: -14.309, mean_net_lifetime: 3442.8892, mean_mc_travel_dist: 1256.2180, mean_rewards: 197.6885, total_rewards: 2228.5446, mean_steps: 18.1400, mean_ecr: 0.0413 mean_entropies: 2.0174, took: 92.5705s
2022-10-09 00:14:27,881 [INFO] 	Process 2 - batch 4899: mean_policy_losses: -74.119, mean_net_lifetime: 3460.9378, mean_mc_travel_dist: 1259.2417, mean_rewards: 198.4558, total_rewards: 2235.5857, mean_steps: 18.4200, mean_ecr: 0.0414 mean_entropies: 2.0025, took: 95.1521s
2022-10-09 00:14:30,715 [INFO] 	Process 4 - batch 4899: mean_policy_losses: -25.924, mean_net_lifetime: 3619.7531, mean_mc_travel_dist: 1326.8741, mean_rewards: 205.7540, total_rewards: 2329.5515, mean_steps: 18.8100, mean_ecr: 0.0410 mean_entropies: 2.0098, took: 95.7321s
2022-10-09 00:15:04,788 [INFO] 	Process 1 - batch 4899: mean_policy_losses: 30.824, mean_net_lifetime: 3728.2361, mean_mc_travel_dist: 1346.6770, mean_rewards: 198.2102, total_rewards: 2414.8731, mean_steps: 19.7200, mean_ecr: 0.0413 mean_entropies: 2.0196, took: 99.1365s
2022-10-09 00:15:06,134 [INFO] 	Process 0 - batch 4599: mean_policy_losses: -128.809, mean_net_lifetime: 3194.9145, mean_mc_travel_dist: 1154.7530, mean_rewards: 211.3108, total_rewards: 2076.9159, mean_steps: 16.4500, mean_ecr: 0.0397 mean_entropies: 2.0241, took: 816.3901s
2022-10-09 00:15:07,674 [INFO] 	Process 6 - batch 4899: mean_policy_losses: -58.572, mean_net_lifetime: 3469.5170, mean_mc_travel_dist: 1281.4969, mean_rewards: 198.3935, total_rewards: 2226.5336, mean_steps: 17.8900, mean_ecr: 0.0412 mean_entropies: 2.0133, took: 92.5676s
2022-10-09 00:15:22,138 [INFO] 	Process 5 - batch 4699: mean_policy_losses: -1.101, mean_net_lifetime: 3426.3116, mean_mc_travel_dist: 1194.9878, mean_rewards: 203.7882, total_rewards: 2261.4265, mean_steps: 17.3500, mean_ecr: 0.0396 mean_entropies: 2.0069, took: 89.7905s
2022-10-09 00:15:33,848 [INFO] 	Process 3 - batch 4999: mean_policy_losses: -106.242, mean_net_lifetime: 3177.1251, mean_mc_travel_dist: 1153.4921, mean_rewards: 212.6176, total_rewards: 2061.6272, mean_steps: 15.4000, mean_ecr: 0.0397 mean_entropies: 1.9844, took: 79.4295s
2022-10-09 00:15:48,128 [INFO] 	Process 2 - batch 4999: mean_policy_losses: -117.820, mean_net_lifetime: 3057.2998, mean_mc_travel_dist: 1097.0110, mean_rewards: 199.6257, total_rewards: 2003.9983, mean_steps: 15.3700, mean_ecr: 0.0397 mean_entropies: 2.0229, took: 80.2468s
2022-10-09 00:15:59,506 [INFO] 	Process 4 - batch 4999: mean_policy_losses: -122.125, mean_net_lifetime: 3261.2512, mean_mc_travel_dist: 1172.9388, mean_rewards: 204.3692, total_rewards: 2123.9516, mean_steps: 16.6800, mean_ecr: 0.0399 mean_entropies: 1.9759, took: 88.7923s
2022-10-09 00:16:30,317 [INFO] 	Process 6 - batch 4999: mean_policy_losses: -87.946, mean_net_lifetime: 3207.0290, mean_mc_travel_dist: 1133.5123, mean_rewards: 209.2920, total_rewards: 2111.5110, mean_steps: 15.6400, mean_ecr: 0.0401 mean_entropies: 2.0081, took: 82.6428s
2022-10-09 00:16:30,452 [INFO] 	Process 1 - batch 4999: mean_policy_losses: -62.190, mean_net_lifetime: 3334.4100, mean_mc_travel_dist: 1227.7723, mean_rewards: 206.9360, total_rewards: 2142.0797, mean_steps: 16.8800, mean_ecr: 0.0396 mean_entropies: 1.9901, took: 85.6641s
2022-10-09 00:16:40,687 [INFO] 	Process 5 - batch 4799: mean_policy_losses: -235.635, mean_net_lifetime: 2976.2004, mean_mc_travel_dist: 1075.7834, mean_rewards: 212.6669, total_rewards: 1940.4757, mean_steps: 14.8100, mean_ecr: 0.0402 mean_entropies: 1.9936, took: 78.5483s
2022-10-09 00:16:43,046 [INFO] 	Process 0 - batch 4699: mean_policy_losses: 20.175, mean_net_lifetime: 3627.6276, mean_mc_travel_dist: 1307.7209, mean_rewards: 203.6484, total_rewards: 2359.1439, mean_steps: 18.9800, mean_ecr: 0.0394 mean_entropies: 1.9988, took: 96.9119s
2022-10-09 00:17:05,751 [INFO] 	Process 3 - batch 5099: mean_policy_losses: -86.259, mean_net_lifetime: 3483.6605, mean_mc_travel_dist: 1295.9662, mean_rewards: 203.1964, total_rewards: 2224.5274, mean_steps: 18.0900, mean_ecr: 0.0375 mean_entropies: 2.0088, took: 91.9028s
2022-10-09 00:17:19,224 [INFO] 	Process 2 - batch 5099: mean_policy_losses: -101.987, mean_net_lifetime: 3349.5097, mean_mc_travel_dist: 1233.1258, mean_rewards: 212.4471, total_rewards: 2154.9755, mean_steps: 16.9500, mean_ecr: 0.0378 mean_entropies: 1.9855, took: 91.0953s
2022-10-09 00:17:35,381 [INFO] 	Process 4 - batch 5099: mean_policy_losses: -83.496, mean_net_lifetime: 3526.0181, mean_mc_travel_dist: 1321.2612, mean_rewards: 204.5172, total_rewards: 2252.1743, mean_steps: 18.4500, mean_ecr: 0.0377 mean_entropies: 2.0023, took: 95.8743s
2022-10-09 00:18:00,047 [INFO] 	Process 1 - batch 5099: mean_policy_losses: -115.920, mean_net_lifetime: 3342.4704, mean_mc_travel_dist: 1240.6909, mean_rewards: 200.7320, total_rewards: 2139.4814, mean_steps: 17.7200, mean_ecr: 0.0381 mean_entropies: 1.9934, took: 89.5947s
2022-10-09 00:18:00,942 [INFO] 	Process 0 - batch 4799: mean_policy_losses: -139.539, mean_net_lifetime: 3126.4738, mean_mc_travel_dist: 1117.1754, mean_rewards: 226.4599, total_rewards: 2050.4429, mean_steps: 14.8800, mean_ecr: 0.0405 mean_entropies: 2.0223, took: 77.8955s
2022-10-09 00:18:05,189 [INFO] 	Process 6 - batch 5099: mean_policy_losses: -58.491, mean_net_lifetime: 3547.8527, mean_mc_travel_dist: 1319.1090, mean_rewards: 200.7166, total_rewards: 2263.1309, mean_steps: 18.5900, mean_ecr: 0.0378 mean_entropies: 1.9814, took: 94.8710s
2022-10-09 00:18:16,291 [INFO] 	Process 5 - batch 4899: mean_policy_losses: -63.199, mean_net_lifetime: 3456.0705, mean_mc_travel_dist: 1267.2795, mean_rewards: 195.7822, total_rewards: 2223.7755, mean_steps: 18.3200, mean_ecr: 0.0410 mean_entropies: 1.9699, took: 95.6041s
2022-10-09 00:18:40,964 [INFO] 	Process 3 - batch 5199: mean_policy_losses: -49.619, mean_net_lifetime: 3484.5640, mean_mc_travel_dist: 1241.9387, mean_rewards: 193.8579, total_rewards: 2279.1548, mean_steps: 18.3800, mean_ecr: 0.0398 mean_entropies: 1.9890, took: 95.2124s
2022-10-09 00:18:52,595 [INFO] 	Process 2 - batch 5199: mean_policy_losses: -53.139, mean_net_lifetime: 3383.1062, mean_mc_travel_dist: 1222.1645, mean_rewards: 196.9142, total_rewards: 2199.3166, mean_steps: 17.5900, mean_ecr: 0.0398 mean_entropies: 1.9496, took: 93.3718s
2022-10-09 00:19:10,299 [INFO] 	Process 4 - batch 5199: mean_policy_losses: -109.893, mean_net_lifetime: 3355.8497, mean_mc_travel_dist: 1250.8646, mean_rewards: 192.1225, total_rewards: 2150.3105, mean_steps: 18.1700, mean_ecr: 0.0397 mean_entropies: 1.9131, took: 94.9180s
2022-10-09 00:19:31,775 [INFO] 	Process 1 - batch 5199: mean_policy_losses: -43.923, mean_net_lifetime: 3458.5937, mean_mc_travel_dist: 1279.2757, mean_rewards: 202.1530, total_rewards: 2218.0102, mean_steps: 18.2200, mean_ecr: 0.0394 mean_entropies: 1.9317, took: 91.7288s
2022-10-09 00:19:35,031 [INFO] 	Process 0 - batch 4899: mean_policy_losses: -50.282, mean_net_lifetime: 3321.7074, mean_mc_travel_dist: 1235.4173, mean_rewards: 199.5873, total_rewards: 2138.1346, mean_steps: 17.6000, mean_ecr: 0.0413 mean_entropies: 1.9015, took: 94.0899s
2022-10-09 00:19:35,987 [INFO] 	Process 5 - batch 4999: mean_policy_losses: -129.968, mean_net_lifetime: 3015.1033, mean_mc_travel_dist: 1144.7272, mean_rewards: 204.6825, total_rewards: 1908.5359, mean_steps: 14.8500, mean_ecr: 0.0401 mean_entropies: 1.8511, took: 79.6955s
2022-10-09 00:19:37,173 [INFO] 	Process 6 - batch 5199: mean_policy_losses: -69.621, mean_net_lifetime: 3451.9417, mean_mc_travel_dist: 1295.5495, mean_rewards: 201.6455, total_rewards: 2195.1775, mean_steps: 17.9300, mean_ecr: 0.0393 mean_entropies: 1.8843, took: 91.9851s
2022-10-09 00:20:09,303 [INFO] 	Process 3 - batch 5299: mean_policy_losses: -117.950, mean_net_lifetime: 3306.0434, mean_mc_travel_dist: 1291.8014, mean_rewards: 199.9095, total_rewards: 2060.1790, mean_steps: 17.4000, mean_ecr: 0.0394 mean_entropies: 1.8647, took: 88.3392s
2022-10-09 00:20:27,172 [INFO] 	Process 2 - batch 5299: mean_policy_losses: -42.794, mean_net_lifetime: 3428.2833, mean_mc_travel_dist: 1307.4259, mean_rewards: 204.0689, total_rewards: 2172.6728, mean_steps: 18.1900, mean_ecr: 0.0401 mean_entropies: 1.8931, took: 94.5764s
2022-10-09 00:20:41,518 [INFO] 	Process 4 - batch 5299: mean_policy_losses: -108.977, mean_net_lifetime: 3377.9351, mean_mc_travel_dist: 1285.8774, mean_rewards: 210.0246, total_rewards: 2133.3111, mean_steps: 18.0000, mean_ecr: 0.0394 mean_entropies: 1.9231, took: 91.2194s
2022-10-09 00:21:00,317 [INFO] 	Process 1 - batch 5299: mean_policy_losses: -67.188, mean_net_lifetime: 3322.3034, mean_mc_travel_dist: 1226.4710, mean_rewards: 204.6131, total_rewards: 2135.0489, mean_steps: 17.4200, mean_ecr: 0.0396 mean_entropies: 1.9470, took: 88.5423s
2022-10-09 00:21:02,727 [INFO] 	Process 0 - batch 4999: mean_policy_losses: -91.196, mean_net_lifetime: 3261.9139, mean_mc_travel_dist: 1207.3966, mean_rewards: 204.8406, total_rewards: 2101.9647, mean_steps: 16.6000, mean_ecr: 0.0399 mean_entropies: 1.9535, took: 87.6950s
2022-10-09 00:21:07,263 [INFO] 	Process 5 - batch 5099: mean_policy_losses: -101.818, mean_net_lifetime: 3406.9687, mean_mc_travel_dist: 1280.5238, mean_rewards: 201.8761, total_rewards: 2167.2046, mean_steps: 18.0200, mean_ecr: 0.0377 mean_entropies: 1.9518, took: 91.2767s
2022-10-09 00:21:15,579 [INFO] 	Process 6 - batch 5299: mean_policy_losses: -118.942, mean_net_lifetime: 3522.9145, mean_mc_travel_dist: 1339.3577, mean_rewards: 206.0478, total_rewards: 2216.1178, mean_steps: 18.8800, mean_ecr: 0.0398 mean_entropies: 1.9637, took: 98.4062s
2022-10-09 00:21:22,213 [INFO] 	Process 3 - batch 5399: mean_policy_losses: -108.987, mean_net_lifetime: 2939.4586, mean_mc_travel_dist: 1041.9627, mean_rewards: 222.0210, total_rewards: 1934.4016, mean_steps: 13.7900, mean_ecr: 0.0419 mean_entropies: 1.9703, took: 72.9106s
2022-10-09 00:21:43,918 [INFO] 	Process 2 - batch 5399: mean_policy_losses: -68.537, mean_net_lifetime: 3030.8279, mean_mc_travel_dist: 1048.0501, mean_rewards: 220.6621, total_rewards: 2022.9100, mean_steps: 14.2000, mean_ecr: 0.0417 mean_entropies: 1.9851, took: 76.7457s
2022-10-09 00:21:56,315 [INFO] 	Process 4 - batch 5399: mean_policy_losses: -122.814, mean_net_lifetime: 2964.0864, mean_mc_travel_dist: 1041.5313, mean_rewards: 219.6577, total_rewards: 1967.8920, mean_steps: 13.9900, mean_ecr: 0.0417 mean_entropies: 1.9471, took: 74.7973s
2022-10-09 00:22:14,742 [INFO] 	Process 1 - batch 5399: mean_policy_losses: -144.963, mean_net_lifetime: 2928.1418, mean_mc_travel_dist: 1064.1076, mean_rewards: 212.1515, total_rewards: 1904.5819, mean_steps: 14.4100, mean_ecr: 0.0420 mean_entropies: 1.9526, took: 74.4247s
2022-10-09 00:22:34,761 [INFO] 	Process 6 - batch 5399: mean_policy_losses: -62.170, mean_net_lifetime: 2934.0953, mean_mc_travel_dist: 1065.9268, mean_rewards: 206.1289, total_rewards: 1910.9936, mean_steps: 14.9400, mean_ecr: 0.0420 mean_entropies: 1.9295, took: 79.1815s
2022-10-09 00:22:36,370 [INFO] 	Process 0 - batch 5099: mean_policy_losses: -73.131, mean_net_lifetime: 3436.3274, mean_mc_travel_dist: 1287.4945, mean_rewards: 199.5707, total_rewards: 2188.6736, mean_steps: 18.0800, mean_ecr: 0.0379 mean_entropies: 1.9350, took: 93.6431s
2022-10-09 00:22:43,618 [INFO] 	Process 5 - batch 5199: mean_policy_losses: -39.792, mean_net_lifetime: 3442.6055, mean_mc_travel_dist: 1242.2860, mean_rewards: 200.6053, total_rewards: 2244.8926, mean_steps: 18.4300, mean_ecr: 0.0395 mean_entropies: 1.9588, took: 96.3552s
2022-10-09 00:22:47,792 [INFO] 	Process 3 - batch 5499: mean_policy_losses: -73.827, mean_net_lifetime: 3115.4731, mean_mc_travel_dist: 1173.8283, mean_rewards: 202.2015, total_rewards: 1978.3361, mean_steps: 16.2800, mean_ecr: 0.0384 mean_entropies: 1.8959, took: 85.5792s
2022-10-09 00:23:10,419 [INFO] 	Process 2 - batch 5499: mean_policy_losses: -92.391, mean_net_lifetime: 3118.3916, mean_mc_travel_dist: 1163.4571, mean_rewards: 204.4255, total_rewards: 2000.9514, mean_steps: 16.4100, mean_ecr: 0.0384 mean_entropies: 1.8770, took: 86.5021s
2022-10-09 00:23:19,331 [INFO] 	Process 4 - batch 5499: mean_policy_losses: -92.311, mean_net_lifetime: 3065.9816, mean_mc_travel_dist: 1141.3904, mean_rewards: 205.0498, total_rewards: 1963.4684, mean_steps: 15.8600, mean_ecr: 0.0385 mean_entropies: 1.8687, took: 83.0155s
2022-10-09 00:23:40,059 [INFO] 	Process 1 - batch 5499: mean_policy_losses: -85.503, mean_net_lifetime: 3150.4780, mean_mc_travel_dist: 1201.7490, mean_rewards: 204.2027, total_rewards: 1999.6956, mean_steps: 16.7100, mean_ecr: 0.0385 mean_entropies: 1.8745, took: 85.3165s
2022-10-09 00:24:01,330 [INFO] 	Process 6 - batch 5499: mean_policy_losses: -54.333, mean_net_lifetime: 3269.1016, mean_mc_travel_dist: 1204.5040, mean_rewards: 208.8255, total_rewards: 2109.6632, mean_steps: 16.7800, mean_ecr: 0.0382 mean_entropies: 1.8938, took: 86.5668s
2022-10-09 00:24:12,462 [INFO] 	Process 0 - batch 5199: mean_policy_losses: -39.400, mean_net_lifetime: 3459.7403, mean_mc_travel_dist: 1271.0475, mean_rewards: 202.0260, total_rewards: 2230.8855, mean_steps: 18.3400, mean_ecr: 0.0398 mean_entropies: 1.9577, took: 96.0927s
2022-10-09 00:24:16,836 [INFO] 	Process 3 - batch 5599: mean_policy_losses: -30.868, mean_net_lifetime: 3331.6325, mean_mc_travel_dist: 1221.5324, mean_rewards: 211.8610, total_rewards: 2149.9694, mean_steps: 17.0600, mean_ecr: 0.0406 mean_entropies: 1.9182, took: 89.0431s
2022-10-09 00:24:20,490 [INFO] 	Process 5 - batch 5299: mean_policy_losses: -90.262, mean_net_lifetime: 3555.8561, mean_mc_travel_dist: 1352.0710, mean_rewards: 200.0985, total_rewards: 2247.4654, mean_steps: 19.1500, mean_ecr: 0.0397 mean_entropies: 1.9415, took: 96.8720s
2022-10-09 00:24:44,436 [INFO] 	Process 2 - batch 5599: mean_policy_losses: -148.160, mean_net_lifetime: 3243.9898, mean_mc_travel_dist: 1255.2737, mean_rewards: 211.3189, total_rewards: 2032.8165, mean_steps: 17.7800, mean_ecr: 0.0402 mean_entropies: 1.9244, took: 94.0162s
2022-10-09 00:25:08,361 [INFO] 	Process 1 - batch 5599: mean_policy_losses: -100.027, mean_net_lifetime: 3257.3367, mean_mc_travel_dist: 1234.8777, mean_rewards: 212.1289, total_rewards: 2071.1704, mean_steps: 17.3800, mean_ecr: 0.0407 mean_entropies: 1.9430, took: 88.3028s
2022-10-09 00:25:16,001 [INFO] 	Process 4 - batch 5599: mean_policy_losses: -154.116, mean_net_lifetime: 3796.2343, mean_mc_travel_dist: 1583.7180, mean_rewards: 210.2416, total_rewards: 2248.9414, mean_steps: 22.8200, mean_ecr: 0.0408 mean_entropies: 1.9056, took: 116.6702s
2022-10-09 00:25:27,946 [INFO] 	Process 6 - batch 5599: mean_policy_losses: -124.793, mean_net_lifetime: 3160.0727, mean_mc_travel_dist: 1174.2682, mean_rewards: 207.7538, total_rewards: 2031.6417, mean_steps: 16.3800, mean_ecr: 0.0408 mean_entropies: 1.9268, took: 86.6181s
2022-10-09 00:25:48,550 [INFO] 	Process 5 - batch 5399: mean_policy_losses: -56.218, mean_net_lifetime: 3247.8337, mean_mc_travel_dist: 1185.2843, mean_rewards: 208.3496, total_rewards: 2101.4131, mean_steps: 16.6500, mean_ecr: 0.0416 mean_entropies: 1.9804, took: 88.0596s
2022-10-09 00:25:49,027 [INFO] 	Process 0 - batch 5299: mean_policy_losses: -115.208, mean_net_lifetime: 3531.4699, mean_mc_travel_dist: 1317.0267, mean_rewards: 215.0079, total_rewards: 2245.8806, mean_steps: 18.5400, mean_ecr: 0.0397 mean_entropies: 1.9427, took: 96.5648s
2022-10-09 00:25:57,280 [INFO] 	Process 3 - batch 5699: mean_policy_losses: -89.861, mean_net_lifetime: 3703.3971, mean_mc_travel_dist: 1391.6211, mean_rewards: 204.1854, total_rewards: 2346.8491, mean_steps: 19.6400, mean_ecr: 0.0377 mean_entropies: 1.8906, took: 100.4442s
2022-10-09 00:26:17,590 [INFO] 	Process 2 - batch 5699: mean_policy_losses: -163.178, mean_net_lifetime: 3462.3615, mean_mc_travel_dist: 1314.6877, mean_rewards: 206.7800, total_rewards: 2197.5674, mean_steps: 18.5000, mean_ecr: 0.0377 mean_entropies: 1.9128, took: 93.1537s
2022-10-09 00:26:40,740 [INFO] 	Process 1 - batch 5699: mean_policy_losses: -139.373, mean_net_lifetime: 3372.8208, mean_mc_travel_dist: 1277.7025, mean_rewards: 199.1584, total_rewards: 2139.0390, mean_steps: 18.3000, mean_ecr: 0.0376 mean_entropies: 1.8930, took: 92.3786s
2022-10-09 00:26:51,904 [INFO] 	Process 4 - batch 5699: mean_policy_losses: -78.861, mean_net_lifetime: 3523.2914, mean_mc_travel_dist: 1345.7671, mean_rewards: 206.8552, total_rewards: 2214.6119, mean_steps: 18.6700, mean_ecr: 0.0376 mean_entropies: 1.8849, took: 95.9027s
2022-10-09 00:27:07,119 [INFO] 	Process 0 - batch 5399: mean_policy_losses: -103.378, mean_net_lifetime: 2928.3349, mean_mc_travel_dist: 1062.0798, mean_rewards: 212.5395, total_rewards: 1903.8058, mean_steps: 14.2400, mean_ecr: 0.0421 mean_entropies: 1.9588, took: 78.0918s
2022-10-09 00:27:09,208 [INFO] 	Process 6 - batch 5699: mean_policy_losses: -8.457, mean_net_lifetime: 3816.4952, mean_mc_travel_dist: 1446.4987, mean_rewards: 208.2977, total_rewards: 2418.3438, mean_steps: 19.9700, mean_ecr: 0.0377 mean_entropies: 1.9215, took: 101.2619s
2022-10-09 00:27:13,853 [INFO] 	Process 5 - batch 5499: mean_policy_losses: -105.769, mean_net_lifetime: 3098.2309, mean_mc_travel_dist: 1187.0834, mean_rewards: 206.6619, total_rewards: 1959.0803, mean_steps: 16.0700, mean_ecr: 0.0387 mean_entropies: 1.8786, took: 85.3035s
2022-10-09 00:27:23,419 [INFO] 	Process 3 - batch 5799: mean_policy_losses: -67.564, mean_net_lifetime: 3242.7368, mean_mc_travel_dist: 1176.0563, mean_rewards: 215.9812, total_rewards: 2106.7465, mean_steps: 16.4200, mean_ecr: 0.0405 mean_entropies: 1.9833, took: 86.1387s
2022-10-09 00:27:43,954 [INFO] 	Process 2 - batch 5799: mean_policy_losses: -108.105, mean_net_lifetime: 3319.8405, mean_mc_travel_dist: 1188.5779, mean_rewards: 219.7830, total_rewards: 2163.7656, mean_steps: 16.4500, mean_ecr: 0.0407 mean_entropies: 2.0100, took: 86.3641s
2022-10-09 00:28:01,250 [INFO] 	Process 1 - batch 5799: mean_policy_losses: -162.024, mean_net_lifetime: 3161.4565, mean_mc_travel_dist: 1119.8397, mean_rewards: 216.0917, total_rewards: 2077.1428, mean_steps: 15.7100, mean_ecr: 0.0409 mean_entropies: 2.0320, took: 80.5092s
2022-10-09 00:28:11,893 [INFO] 	Process 4 - batch 5799: mean_policy_losses: -105.856, mean_net_lifetime: 3105.5365, mean_mc_travel_dist: 1091.5639, mean_rewards: 212.7699, total_rewards: 2053.6496, mean_steps: 15.4500, mean_ecr: 0.0410 mean_entropies: 2.0414, took: 79.9896s
2022-10-09 00:28:33,194 [INFO] 	Process 0 - batch 5499: mean_policy_losses: -81.182, mean_net_lifetime: 3225.7999, mean_mc_travel_dist: 1174.5998, mean_rewards: 208.4206, total_rewards: 2079.8343, mean_steps: 16.5100, mean_ecr: 0.0379 mean_entropies: 1.9798, took: 86.0749s
2022-10-09 00:28:34,584 [INFO] 	Process 6 - batch 5799: mean_policy_losses: -103.641, mean_net_lifetime: 3264.1328, mean_mc_travel_dist: 1154.2010, mean_rewards: 217.2698, total_rewards: 2142.2685, mean_steps: 16.1100, mean_ecr: 0.0405 mean_entropies: 2.0286, took: 85.3752s
2022-10-09 00:28:49,445 [INFO] 	Process 5 - batch 5599: mean_policy_losses: -120.217, mean_net_lifetime: 3389.9805, mean_mc_travel_dist: 1279.0085, mean_rewards: 206.6124, total_rewards: 2151.0216, mean_steps: 18.4300, mean_ecr: 0.0406 mean_entropies: 1.9860, took: 95.5920s
2022-10-09 00:28:51,549 [INFO] 	Process 3 - batch 5899: mean_policy_losses: -115.013, mean_net_lifetime: 3331.1276, mean_mc_travel_dist: 1204.4409, mean_rewards: 205.9933, total_rewards: 2162.7938, mean_steps: 17.0600, mean_ecr: 0.0403 mean_entropies: 2.0252, took: 88.1308s
2022-10-09 00:29:17,186 [INFO] 	Process 2 - batch 5899: mean_policy_losses: -54.032, mean_net_lifetime: 3424.8234, mean_mc_travel_dist: 1239.3471, mean_rewards: 207.9409, total_rewards: 2224.1389, mean_steps: 17.7100, mean_ecr: 0.0401 mean_entropies: 2.0266, took: 93.2324s
2022-10-09 00:29:25,570 [INFO] 	Process 1 - batch 5899: mean_policy_losses: -103.071, mean_net_lifetime: 3234.2971, mean_mc_travel_dist: 1136.4064, mean_rewards: 202.0619, total_rewards: 2139.4277, mean_steps: 16.5800, mean_ecr: 0.0403 mean_entropies: 1.9874, took: 84.3204s
2022-10-09 00:29:36,974 [INFO] 	Process 4 - batch 5899: mean_policy_losses: -78.335, mean_net_lifetime: 3224.0089, mean_mc_travel_dist: 1150.5807, mean_rewards: 207.2053, total_rewards: 2112.9164, mean_steps: 16.1800, mean_ecr: 0.0404 mean_entropies: 2.0190, took: 85.0808s
2022-10-09 00:29:59,995 [INFO] 	Process 0 - batch 5599: mean_policy_losses: -116.306, mean_net_lifetime: 3263.5546, mean_mc_travel_dist: 1198.1410, mean_rewards: 217.8377, total_rewards: 2094.8611, mean_steps: 16.5400, mean_ecr: 0.0410 mean_entropies: 1.9901, took: 86.8009s
2022-10-09 00:30:03,935 [INFO] 	Process 6 - batch 5899: mean_policy_losses: -87.926, mean_net_lifetime: 3386.7635, mean_mc_travel_dist: 1239.5665, mean_rewards: 204.8210, total_rewards: 2182.8353, mean_steps: 17.1800, mean_ecr: 0.0403 mean_entropies: 2.0232, took: 89.3522s
2022-10-09 00:30:25,399 [INFO] 	Process 5 - batch 5699: mean_policy_losses: -187.782, mean_net_lifetime: 3516.2074, mean_mc_travel_dist: 1273.3248, mean_rewards: 208.2019, total_rewards: 2276.6982, mean_steps: 18.2900, mean_ecr: 0.0380 mean_entropies: 2.0025, took: 95.9534s
2022-10-09 00:30:30,605 [INFO] 	Process 3 - batch 5999: mean_policy_losses: -51.674, mean_net_lifetime: 3630.2303, mean_mc_travel_dist: 1315.1082, mean_rewards: 201.7271, total_rewards: 2346.4889, mean_steps: 18.7800, mean_ecr: 0.0400 mean_entropies: 2.0230, took: 99.0551s
2022-10-09 00:30:48,989 [INFO] 	Process 2 - batch 5999: mean_policy_losses: -144.839, mean_net_lifetime: 3412.1337, mean_mc_travel_dist: 1214.9639, mean_rewards: 210.7995, total_rewards: 2240.4840, mean_steps: 17.4400, mean_ecr: 0.0401 mean_entropies: 2.0270, took: 91.8036s
2022-10-09 00:30:58,498 [INFO] 	Process 1 - batch 5999: mean_policy_losses: -62.055, mean_net_lifetime: 3574.2085, mean_mc_travel_dist: 1257.8120, mean_rewards: 204.7486, total_rewards: 2342.9152, mean_steps: 18.6500, mean_ecr: 0.0401 mean_entropies: 2.0426, took: 92.9283s
2022-10-09 00:31:09,189 [INFO] 	Process 4 - batch 5999: mean_policy_losses: -68.852, mean_net_lifetime: 3483.7545, mean_mc_travel_dist: 1205.4284, mean_rewards: 210.8347, total_rewards: 2320.0513, mean_steps: 17.9100, mean_ecr: 0.0399 mean_entropies: 2.0354, took: 92.2153s
2022-10-09 00:31:29,031 [INFO] 	Process 6 - batch 5999: mean_policy_losses: -113.383, mean_net_lifetime: 3310.2280, mean_mc_travel_dist: 1152.8201, mean_rewards: 206.1637, total_rewards: 2199.8230, mean_steps: 17.3100, mean_ecr: 0.0402 mean_entropies: 2.0457, took: 85.0947s
2022-10-09 00:31:30,628 [INFO] 	Process 0 - batch 5699: mean_policy_losses: -105.214, mean_net_lifetime: 3570.4078, mean_mc_travel_dist: 1299.2761, mean_rewards: 210.2111, total_rewards: 2303.1119, mean_steps: 18.4300, mean_ecr: 0.0376 mean_entropies: 2.0235, took: 90.6328s
2022-10-09 00:31:40,387 [INFO] 	Process 5 - batch 5799: mean_policy_losses: -181.881, mean_net_lifetime: 3129.7806, mean_mc_travel_dist: 1126.9428, mean_rewards: 222.3280, total_rewards: 2047.9329, mean_steps: 15.3600, mean_ecr: 0.0408 mean_entropies: 2.0521, took: 74.9886s
2022-10-09 00:32:42,460 [INFO] 	Process 0 - batch 5799: mean_policy_losses: -118.782, mean_net_lifetime: 3209.8597, mean_mc_travel_dist: 1122.1707, mean_rewards: 213.9426, total_rewards: 2120.7705, mean_steps: 16.0400, mean_ecr: 0.0410 mean_entropies: 2.0812, took: 71.8329s
2022-10-09 00:32:54,179 [INFO] 	Process 5 - batch 5899: mean_policy_losses: -137.692, mean_net_lifetime: 3252.9844, mean_mc_travel_dist: 1172.7906, mean_rewards: 205.4723, total_rewards: 2127.7763, mean_steps: 16.5500, mean_ecr: 0.0400 mean_entropies: 2.0583, took: 73.7921s
2022-10-09 00:34:03,549 [INFO] 	Process 0 - batch 5899: mean_policy_losses: -58.757, mean_net_lifetime: 3509.1266, mean_mc_travel_dist: 1267.4183, mean_rewards: 203.4398, total_rewards: 2282.1495, mean_steps: 18.1200, mean_ecr: 0.0403 mean_entropies: 2.0585, took: 81.0881s
2022-10-09 00:34:11,816 [INFO] 	Process 5 - batch 5999: mean_policy_losses: -159.627, mean_net_lifetime: 3315.3029, mean_mc_travel_dist: 1173.4674, mean_rewards: 210.6274, total_rewards: 2182.8067, mean_steps: 17.1700, mean_ecr: 0.0399 mean_entropies: 2.0445, took: 77.6366s
2022-10-09 00:35:24,426 [INFO] 	Process 0 - batch 5999: mean_policy_losses: -101.612, mean_net_lifetime: 3695.2962, mean_mc_travel_dist: 1302.9401, mean_rewards: 205.2028, total_rewards: 2421.0089, mean_steps: 19.4500, mean_ecr: 0.0397 mean_entropies: 2.0625, took: 80.8777s
2022-10-09 00:43:13,254 [INFO] 	Process 3 - batch 6099: mean_policy_losses: -50.422, mean_net_lifetime: 3484.4361, mean_mc_travel_dist: 1240.6868, mean_rewards: 214.7640, total_rewards: 2282.8878, mean_steps: 16.9500, mean_ecr: 0.0392 mean_entropies: 2.0667, took: 762.6491s
2022-10-09 00:43:29,766 [INFO] 	Process 2 - batch 6099: mean_policy_losses: -169.659, mean_net_lifetime: 3345.5315, mean_mc_travel_dist: 1207.4290, mean_rewards: 207.1981, total_rewards: 2180.1567, mean_steps: 16.8800, mean_ecr: 0.0391 mean_entropies: 2.0555, took: 760.7756s
2022-10-09 00:43:49,114 [INFO] 	Process 1 - batch 6099: mean_policy_losses: -181.851, mean_net_lifetime: 3341.9928, mean_mc_travel_dist: 1228.2316, mean_rewards: 201.8962, total_rewards: 2148.9128, mean_steps: 17.8400, mean_ecr: 0.0393 mean_entropies: 2.0416, took: 770.6160s
2022-10-09 00:44:10,634 [INFO] 	Process 4 - batch 6099: mean_policy_losses: -110.713, mean_net_lifetime: 3236.4406, mean_mc_travel_dist: 1155.9591, mean_rewards: 202.9474, total_rewards: 2116.7010, mean_steps: 16.7200, mean_ecr: 0.0397 mean_entropies: 2.0445, took: 781.4442s
2022-10-09 00:44:17,898 [INFO] 	Process 6 - batch 6099: mean_policy_losses: -151.853, mean_net_lifetime: 3253.0155, mean_mc_travel_dist: 1174.2897, mean_rewards: 209.4154, total_rewards: 2109.2638, mean_steps: 16.5700, mean_ecr: 0.0394 mean_entropies: 2.0516, took: 768.8685s
2022-10-09 00:44:40,957 [INFO] 	Process 3 - batch 6199: mean_policy_losses: -28.106, mean_net_lifetime: 3502.6704, mean_mc_travel_dist: 1293.4987, mean_rewards: 203.5384, total_rewards: 2248.7284, mean_steps: 18.6600, mean_ecr: 0.0397 mean_entropies: 2.0355, took: 87.7032s
2022-10-09 00:44:51,872 [INFO] 	Process 2 - batch 6199: mean_policy_losses: -85.831, mean_net_lifetime: 3355.1051, mean_mc_travel_dist: 1204.1091, mean_rewards: 215.1278, total_rewards: 2194.0770, mean_steps: 16.6800, mean_ecr: 0.0402 mean_entropies: 2.0266, took: 82.1064s
2022-10-09 00:45:14,363 [INFO] 	Process 1 - batch 6199: mean_policy_losses: -105.724, mean_net_lifetime: 3427.4562, mean_mc_travel_dist: 1285.0305, mean_rewards: 210.1772, total_rewards: 2181.9291, mean_steps: 18.0100, mean_ecr: 0.0397 mean_entropies: 2.0367, took: 85.2490s
2022-10-09 00:45:40,837 [INFO] 	Process 4 - batch 6199: mean_policy_losses: -90.307, mean_net_lifetime: 3470.4562, mean_mc_travel_dist: 1246.6047, mean_rewards: 204.6387, total_rewards: 2259.7610, mean_steps: 18.1300, mean_ecr: 0.0398 mean_entropies: 2.0351, took: 90.2025s
2022-10-09 00:45:43,595 [INFO] 	Process 6 - batch 6199: mean_policy_losses: -184.102, mean_net_lifetime: 3356.9187, mean_mc_travel_dist: 1258.6210, mean_rewards: 205.5806, total_rewards: 2139.8351, mean_steps: 17.7800, mean_ecr: 0.0402 mean_entropies: 2.0275, took: 85.6955s
2022-10-09 00:45:56,643 [INFO] 	Process 3 - batch 6299: mean_policy_losses: -277.315, mean_net_lifetime: 3005.0490, mean_mc_travel_dist: 1089.7637, mean_rewards: 202.1029, total_rewards: 1962.2514, mean_steps: 15.3600, mean_ecr: 0.0405 mean_entropies: 2.0068, took: 75.6862s
2022-10-09 00:46:08,595 [INFO] 	Process 2 - batch 6299: mean_policy_losses: -204.477, mean_net_lifetime: 3007.9346, mean_mc_travel_dist: 1089.5206, mean_rewards: 206.2322, total_rewards: 1959.1864, mean_steps: 15.0100, mean_ecr: 0.0407 mean_entropies: 2.0117, took: 76.7236s
2022-10-09 00:46:30,162 [INFO] 	Process 1 - batch 6299: mean_policy_losses: -130.174, mean_net_lifetime: 3155.8048, mean_mc_travel_dist: 1125.5437, mean_rewards: 211.2523, total_rewards: 2064.7392, mean_steps: 15.7200, mean_ecr: 0.0407 mean_entropies: 2.0194, took: 75.7986s
2022-10-09 00:46:58,285 [INFO] 	Process 4 - batch 6299: mean_policy_losses: -87.252, mean_net_lifetime: 3166.5808, mean_mc_travel_dist: 1117.9688, mean_rewards: 208.6114, total_rewards: 2093.2037, mean_steps: 15.8600, mean_ecr: 0.0404 mean_entropies: 2.0245, took: 77.4480s
2022-10-09 00:47:02,694 [INFO] 	Process 6 - batch 6299: mean_policy_losses: -73.007, mean_net_lifetime: 3141.4687, mean_mc_travel_dist: 1115.0037, mean_rewards: 212.5352, total_rewards: 2061.4466, mean_steps: 15.6500, mean_ecr: 0.0404 mean_entropies: 2.0365, took: 79.1006s
2022-10-09 00:47:25,754 [INFO] 	Process 3 - batch 6399: mean_policy_losses: -47.366, mean_net_lifetime: 3428.2986, mean_mc_travel_dist: 1241.4242, mean_rewards: 202.7908, total_rewards: 2227.5433, mean_steps: 18.2300, mean_ecr: 0.0385 mean_entropies: 2.0501, took: 89.1105s
2022-10-09 00:47:41,187 [INFO] 	Process 2 - batch 6399: mean_policy_losses: -108.659, mean_net_lifetime: 3543.0478, mean_mc_travel_dist: 1283.6667, mean_rewards: 210.6347, total_rewards: 2308.6011, mean_steps: 17.9200, mean_ecr: 0.0383 mean_entropies: 2.0546, took: 92.5921s
2022-10-09 00:47:51,309 [INFO] 	Process 1 - batch 6399: mean_policy_losses: -118.815, mean_net_lifetime: 3228.8766, mean_mc_travel_dist: 1159.0919, mean_rewards: 210.2232, total_rewards: 2112.1052, mean_steps: 16.5300, mean_ecr: 0.0379 mean_entropies: 2.0544, took: 81.1475s
2022-10-09 00:48:17,611 [INFO] 	Process 5 - batch 6099: mean_policy_losses: -106.316, mean_net_lifetime: 3348.5148, mean_mc_travel_dist: 1230.7373, mean_rewards: 204.1286, total_rewards: 2169.5894, mean_steps: 16.9400, mean_ecr: 0.0394 mean_entropies: 2.1078, took: 845.7950s
2022-10-09 00:48:31,650 [INFO] 	Process 6 - batch 6399: mean_policy_losses: -107.021, mean_net_lifetime: 3433.6811, mean_mc_travel_dist: 1245.3255, mean_rewards: 207.4575, total_rewards: 2229.8246, mean_steps: 17.6900, mean_ecr: 0.0384 mean_entropies: 2.0742, took: 88.9553s
2022-10-09 00:48:34,736 [INFO] 	Process 4 - batch 6399: mean_policy_losses: -103.933, mean_net_lifetime: 3523.9536, mean_mc_travel_dist: 1300.5310, mean_rewards: 203.0848, total_rewards: 2266.3343, mean_steps: 18.5200, mean_ecr: 0.0383 mean_entropies: 2.0840, took: 96.4519s
2022-10-09 00:48:50,726 [INFO] 	Process 3 - batch 6499: mean_policy_losses: -109.859, mean_net_lifetime: 3249.1006, mean_mc_travel_dist: 1181.4325, mean_rewards: 212.1078, total_rewards: 2110.4090, mean_steps: 16.3600, mean_ecr: 0.0410 mean_entropies: 2.0364, took: 84.9723s
2022-10-09 00:49:07,205 [INFO] 	Process 2 - batch 6499: mean_policy_losses: -144.541, mean_net_lifetime: 3188.4205, mean_mc_travel_dist: 1166.9154, mean_rewards: 209.5405, total_rewards: 2061.5377, mean_steps: 16.3200, mean_ecr: 0.0414 mean_entropies: 2.0448, took: 86.0179s
2022-10-09 00:49:12,136 [INFO] 	Process 0 - batch 6099: mean_policy_losses: -121.696, mean_net_lifetime: 3379.2376, mean_mc_travel_dist: 1213.8944, mean_rewards: 206.1528, total_rewards: 2207.1234, mean_steps: 16.8300, mean_ecr: 0.0391 mean_entropies: 2.0877, took: 827.7100s
2022-10-09 00:49:17,564 [INFO] 	Process 1 - batch 6499: mean_policy_losses: -86.194, mean_net_lifetime: 3357.1954, mean_mc_travel_dist: 1173.5939, mean_rewards: 216.5603, total_rewards: 2224.8091, mean_steps: 16.8200, mean_ecr: 0.0410 mean_entropies: 2.0554, took: 86.2551s
2022-10-09 00:49:45,738 [INFO] 	Process 5 - batch 6199: mean_policy_losses: -100.661, mean_net_lifetime: 3366.8129, mean_mc_travel_dist: 1227.7726, mean_rewards: 206.9495, total_rewards: 2180.9386, mean_steps: 16.7600, mean_ecr: 0.0401 mean_entropies: 2.0555, took: 88.1269s
2022-10-09 00:49:49,589 [INFO] 	Process 4 - batch 6499: mean_policy_losses: -194.044, mean_net_lifetime: 3040.0148, mean_mc_travel_dist: 1084.7083, mean_rewards: 215.3608, total_rewards: 1993.2236, mean_steps: 14.4600, mean_ecr: 0.0413 mean_entropies: 1.9945, took: 74.8538s
2022-10-09 00:49:59,562 [INFO] 	Process 6 - batch 6499: mean_policy_losses: -103.037, mean_net_lifetime: 3291.5654, mean_mc_travel_dist: 1191.1684, mean_rewards: 207.7175, total_rewards: 2141.3970, mean_steps: 16.8500, mean_ecr: 0.0412 mean_entropies: 2.0138, took: 87.9124s
2022-10-09 00:50:25,151 [INFO] 	Process 3 - batch 6599: mean_policy_losses: -41.001, mean_net_lifetime: 3491.4783, mean_mc_travel_dist: 1277.5475, mean_rewards: 202.0778, total_rewards: 2250.0597, mean_steps: 18.1000, mean_ecr: 0.0395 mean_entropies: 2.0577, took: 94.4255s
2022-10-09 00:50:40,529 [INFO] 	Process 2 - batch 6599: mean_policy_losses: -36.316, mean_net_lifetime: 3517.7717, mean_mc_travel_dist: 1283.5134, mean_rewards: 198.1424, total_rewards: 2278.6972, mean_steps: 18.1300, mean_ecr: 0.0392 mean_entropies: 2.0387, took: 93.3236s
2022-10-09 00:50:42,563 [INFO] 	Process 0 - batch 6199: mean_policy_losses: -99.640, mean_net_lifetime: 3324.0625, mean_mc_travel_dist: 1214.8102, mean_rewards: 205.0209, total_rewards: 2157.5903, mean_steps: 17.2100, mean_ecr: 0.0401 mean_entropies: 2.0030, took: 90.4271s
2022-10-09 00:50:56,224 [INFO] 	Process 1 - batch 6599: mean_policy_losses: 40.993, mean_net_lifetime: 3734.6372, mean_mc_travel_dist: 1355.5204, mean_rewards: 198.1500, total_rewards: 2421.3797, mean_steps: 19.5900, mean_ecr: 0.0390 mean_entropies: 2.0639, took: 98.6594s
2022-10-09 00:51:07,075 [INFO] 	Process 5 - batch 6299: mean_policy_losses: -146.916, mean_net_lifetime: 3002.1663, mean_mc_travel_dist: 1091.7499, mean_rewards: 203.5858, total_rewards: 1952.5044, mean_steps: 15.0600, mean_ecr: 0.0405 mean_entropies: 1.9536, took: 81.3371s
2022-10-09 00:51:31,923 [INFO] 	Process 4 - batch 6599: mean_policy_losses: 10.782, mean_net_lifetime: 3718.2906, mean_mc_travel_dist: 1358.7679, mean_rewards: 194.2614, total_rewards: 2392.4880, mean_steps: 19.8000, mean_ecr: 0.0396 mean_entropies: 2.0429, took: 102.3327s
2022-10-09 00:51:43,643 [INFO] 	Process 6 - batch 6599: mean_policy_losses: -0.014, mean_net_lifetime: 3875.0932, mean_mc_travel_dist: 1403.8204, mean_rewards: 194.0857, total_rewards: 2506.2651, mean_steps: 20.5700, mean_ecr: 0.0397 mean_entropies: 2.0509, took: 104.0813s
2022-10-09 00:52:02,790 [INFO] 	Process 3 - batch 6699: mean_policy_losses: -81.097, mean_net_lifetime: 3592.1115, mean_mc_travel_dist: 1359.3412, mean_rewards: 202.7187, total_rewards: 2272.8023, mean_steps: 19.0800, mean_ecr: 0.0397 mean_entropies: 1.9908, took: 97.6384s
2022-10-09 00:52:09,371 [INFO] 	Process 0 - batch 6299: mean_policy_losses: -72.780, mean_net_lifetime: 3193.4536, mean_mc_travel_dist: 1148.3173, mean_rewards: 204.5197, total_rewards: 2082.8613, mean_steps: 16.3200, mean_ecr: 0.0407 mean_entropies: 2.0002, took: 86.8078s
2022-10-09 00:52:36,986 [INFO] 	Process 2 - batch 6699: mean_policy_losses: -107.270, mean_net_lifetime: 3820.3794, mean_mc_travel_dist: 1498.5806, mean_rewards: 201.3476, total_rewards: 2359.5336, mean_steps: 23.0500, mean_ecr: 0.0396 mean_entropies: 1.9821, took: 116.4566s
2022-10-09 00:52:39,743 [INFO] 	Process 5 - batch 6399: mean_policy_losses: -125.638, mean_net_lifetime: 3375.1264, mean_mc_travel_dist: 1235.5149, mean_rewards: 206.1418, total_rewards: 2181.6289, mean_steps: 17.9200, mean_ecr: 0.0383 mean_entropies: 2.0149, took: 92.6677s
2022-10-09 00:53:00,092 [INFO] 	Process 4 - batch 6699: mean_policy_losses: -169.221, mean_net_lifetime: 3246.2704, mean_mc_travel_dist: 1236.3636, mean_rewards: 202.8465, total_rewards: 2066.2517, mean_steps: 17.0000, mean_ecr: 0.0401 mean_entropies: 1.9657, took: 88.1690s
2022-10-09 00:53:06,130 [INFO] 	Process 1 - batch 6699: mean_policy_losses: -124.896, mean_net_lifetime: 4177.4993, mean_mc_travel_dist: 1676.0719, mean_rewards: 209.3186, total_rewards: 2544.7679, mean_steps: 26.0600, mean_ecr: 0.0397 mean_entropies: 1.9663, took: 129.9056s
2022-10-09 00:53:35,033 [INFO] 	Process 3 - batch 6799: mean_policy_losses: -171.260, mean_net_lifetime: 3405.1930, mean_mc_travel_dist: 1277.5968, mean_rewards: 209.9279, total_rewards: 2165.3101, mean_steps: 18.3100, mean_ecr: 0.0391 mean_entropies: 1.9461, took: 92.2436s
2022-10-09 00:53:45,390 [INFO] 	Process 0 - batch 6399: mean_policy_losses: -174.547, mean_net_lifetime: 3386.0026, mean_mc_travel_dist: 1267.4470, mean_rewards: 203.1476, total_rewards: 2153.1594, mean_steps: 18.0400, mean_ecr: 0.0378 mean_entropies: 1.9814, took: 96.0178s
2022-10-09 00:54:02,732 [INFO] 	Process 6 - batch 6699: mean_policy_losses: -70.534, mean_net_lifetime: 4380.3763, mean_mc_travel_dist: 1792.2352, mean_rewards: 201.5475, total_rewards: 2624.0250, mean_steps: 27.9500, mean_ecr: 0.0399 mean_entropies: 1.9476, took: 139.0889s
2022-10-09 00:54:03,102 [INFO] 	Process 5 - batch 6499: mean_policy_losses: -188.056, mean_net_lifetime: 3125.1961, mean_mc_travel_dist: 1139.4674, mean_rewards: 211.9364, total_rewards: 2026.3830, mean_steps: 15.7000, mean_ecr: 0.0412 mean_entropies: 1.8829, took: 83.3587s
2022-10-09 00:54:08,398 [INFO] 	Process 2 - batch 6799: mean_policy_losses: -114.276, mean_net_lifetime: 3318.3851, mean_mc_travel_dist: 1244.5357, mean_rewards: 204.5475, total_rewards: 2108.7857, mean_steps: 17.5300, mean_ecr: 0.0393 mean_entropies: 1.9325, took: 91.4123s
2022-10-09 00:54:27,019 [INFO] 	Process 4 - batch 6799: mean_policy_losses: -165.413, mean_net_lifetime: 3193.8741, mean_mc_travel_dist: 1216.6290, mean_rewards: 203.1485, total_rewards: 2030.8930, mean_steps: 16.3600, mean_ecr: 0.0394 mean_entropies: 1.8966, took: 86.9273s
2022-10-09 00:54:35,980 [INFO] 	Process 1 - batch 6799: mean_policy_losses: -142.554, mean_net_lifetime: 3344.2844, mean_mc_travel_dist: 1253.8826, mean_rewards: 202.3264, total_rewards: 2125.8787, mean_steps: 17.6900, mean_ecr: 0.0395 mean_entropies: 1.9034, took: 89.8498s
2022-10-09 00:55:11,267 [INFO] 	Process 3 - batch 6899: mean_policy_losses: -108.313, mean_net_lifetime: 3580.6465, mean_mc_travel_dist: 1324.6886, mean_rewards: 200.6629, total_rewards: 2307.9436, mean_steps: 18.8500, mean_ecr: 0.0385 mean_entropies: 1.9549, took: 96.2337s
2022-10-09 00:55:14,808 [INFO] 	Process 0 - batch 6499: mean_policy_losses: -95.034, mean_net_lifetime: 3370.8939, mean_mc_travel_dist: 1231.1882, mean_rewards: 211.0361, total_rewards: 2177.4545, mean_steps: 16.7100, mean_ecr: 0.0417 mean_entropies: 1.8994, took: 89.4199s
2022-10-09 00:55:37,817 [INFO] 	Process 5 - batch 6599: mean_policy_losses: -94.028, mean_net_lifetime: 3533.2419, mean_mc_travel_dist: 1293.1516, mean_rewards: 201.6979, total_rewards: 2280.5998, mean_steps: 18.0600, mean_ecr: 0.0397 mean_entropies: 1.9875, took: 94.7157s
2022-10-09 00:55:40,350 [INFO] 	Process 6 - batch 6799: mean_policy_losses: -157.177, mean_net_lifetime: 3484.4044, mean_mc_travel_dist: 1309.7971, mean_rewards: 198.0863, total_rewards: 2213.2311, mean_steps: 18.5000, mean_ecr: 0.0391 mean_entropies: 1.9348, took: 97.6183s
2022-10-09 00:55:47,079 [INFO] 	Process 2 - batch 6899: mean_policy_losses: -153.175, mean_net_lifetime: 3663.4905, mean_mc_travel_dist: 1352.3813, mean_rewards: 205.4913, total_rewards: 2352.2101, mean_steps: 19.3900, mean_ecr: 0.0382 mean_entropies: 1.9687, took: 98.6811s
2022-10-09 00:56:12,491 [INFO] 	Process 4 - batch 6899: mean_policy_losses: -50.766, mean_net_lifetime: 3923.9000, mean_mc_travel_dist: 1421.9049, mean_rewards: 209.8338, total_rewards: 2538.9742, mean_steps: 20.2500, mean_ecr: 0.0385 mean_entropies: 2.0195, took: 105.4719s
2022-10-09 00:56:26,069 [INFO] 	Process 1 - batch 6899: mean_policy_losses: -80.136, mean_net_lifetime: 3985.0903, mean_mc_travel_dist: 1480.9795, mean_rewards: 205.0722, total_rewards: 2548.6078, mean_steps: 22.0700, mean_ecr: 0.0381 mean_entropies: 1.9981, took: 110.0896s
2022-10-09 00:56:43,280 [INFO] 	Process 3 - batch 6999: mean_policy_losses: -149.568, mean_net_lifetime: 3469.5255, mean_mc_travel_dist: 1277.4125, mean_rewards: 207.7715, total_rewards: 2231.5252, mean_steps: 17.6900, mean_ecr: 0.0387 mean_entropies: 2.0290, took: 92.0129s
2022-10-09 00:57:01,013 [INFO] 	Process 0 - batch 6599: mean_policy_losses: -16.071, mean_net_lifetime: 3895.9437, mean_mc_travel_dist: 1460.8185, mean_rewards: 202.0752, total_rewards: 2465.7971, mean_steps: 20.7800, mean_ecr: 0.0388 mean_entropies: 2.0423, took: 106.2038s
2022-10-09 00:57:13,188 [INFO] 	Process 2 - batch 6999: mean_policy_losses: -126.223, mean_net_lifetime: 3356.7484, mean_mc_travel_dist: 1189.5229, mean_rewards: 211.0894, total_rewards: 2202.1541, mean_steps: 16.9400, mean_ecr: 0.0389 mean_entropies: 2.0058, took: 86.1087s
2022-10-09 00:57:18,447 [INFO] 	Process 5 - batch 6699: mean_policy_losses: -77.133, mean_net_lifetime: 3595.0784, mean_mc_travel_dist: 1355.5326, mean_rewards: 207.1244, total_rewards: 2284.5396, mean_steps: 19.6300, mean_ecr: 0.0395 mean_entropies: 1.9608, took: 100.6303s
2022-10-09 00:57:20,004 [INFO] 	Process 6 - batch 6899: mean_policy_losses: -55.703, mean_net_lifetime: 3687.8194, mean_mc_travel_dist: 1376.7115, mean_rewards: 210.4106, total_rewards: 2343.4081, mean_steps: 19.1900, mean_ecr: 0.0381 mean_entropies: 2.0359, took: 99.6523s
2022-10-09 00:57:44,156 [INFO] 	Process 4 - batch 6999: mean_policy_losses: -97.129, mean_net_lifetime: 3366.5057, mean_mc_travel_dist: 1196.6380, mean_rewards: 202.4282, total_rewards: 2207.6036, mean_steps: 17.1700, mean_ecr: 0.0387 mean_entropies: 2.0118, took: 91.6642s
2022-10-09 00:57:58,205 [INFO] 	Process 1 - batch 6999: mean_policy_losses: -89.281, mean_net_lifetime: 3534.0456, mean_mc_travel_dist: 1278.0176, mean_rewards: 201.8413, total_rewards: 2291.7513, mean_steps: 18.2200, mean_ecr: 0.0387 mean_entropies: 1.9762, took: 92.1365s
2022-10-09 00:58:21,417 [INFO] 	Process 3 - batch 7099: mean_policy_losses: -41.676, mean_net_lifetime: 3602.9648, mean_mc_travel_dist: 1302.8154, mean_rewards: 205.3199, total_rewards: 2335.5933, mean_steps: 19.1700, mean_ecr: 0.0391 mean_entropies: 1.9540, took: 98.1372s
2022-10-09 00:58:33,160 [INFO] 	Process 0 - batch 6699: mean_policy_losses: -167.971, mean_net_lifetime: 3460.2141, mean_mc_travel_dist: 1338.1340, mean_rewards: 207.0669, total_rewards: 2169.6393, mean_steps: 18.0500, mean_ecr: 0.0397 mean_entropies: 1.9023, took: 92.1470s
2022-10-09 00:58:47,034 [INFO] 	Process 2 - batch 7099: mean_policy_losses: -80.147, mean_net_lifetime: 3488.5046, mean_mc_travel_dist: 1331.8731, mean_rewards: 207.6997, total_rewards: 2197.7778, mean_steps: 18.0900, mean_ecr: 0.0387 mean_entropies: 1.9130, took: 93.8456s
2022-10-09 00:58:48,495 [INFO] 	Process 6 - batch 6999: mean_policy_losses: -104.514, mean_net_lifetime: 3298.2302, mean_mc_travel_dist: 1179.1115, mean_rewards: 212.6543, total_rewards: 2156.4657, mean_steps: 16.7200, mean_ecr: 0.0390 mean_entropies: 1.8865, took: 88.4914s
2022-10-09 00:58:50,913 [INFO] 	Process 5 - batch 6799: mean_policy_losses: -90.606, mean_net_lifetime: 3359.9604, mean_mc_travel_dist: 1295.7776, mean_rewards: 201.7787, total_rewards: 2105.6513, mean_steps: 17.3800, mean_ecr: 0.0392 mean_entropies: 1.8688, took: 92.4656s
2022-10-09 00:59:16,247 [INFO] 	Process 4 - batch 7099: mean_policy_losses: -81.909, mean_net_lifetime: 3416.9247, mean_mc_travel_dist: 1328.3885, mean_rewards: 204.7196, total_rewards: 2124.6573, mean_steps: 17.8100, mean_ecr: 0.0391 mean_entropies: 1.8586, took: 92.0914s
2022-10-09 00:59:30,208 [INFO] 	Process 1 - batch 7099: mean_policy_losses: -35.212, mean_net_lifetime: 3522.9404, mean_mc_travel_dist: 1392.0010, mean_rewards: 203.3816, total_rewards: 2170.1065, mean_steps: 18.2900, mean_ecr: 0.0392 mean_entropies: 1.8416, took: 92.0025s
2022-10-09 00:59:37,208 [INFO] 	Process 3 - batch 7199: mean_policy_losses: -114.053, mean_net_lifetime: 3044.4535, mean_mc_travel_dist: 1114.2976, mean_rewards: 220.0882, total_rewards: 1974.2615, mean_steps: 14.3500, mean_ecr: 0.0416 mean_entropies: 1.8726, took: 75.7905s
2022-10-09 00:59:57,745 [INFO] 	Process 0 - batch 6799: mean_policy_losses: -155.120, mean_net_lifetime: 3136.8698, mean_mc_travel_dist: 1220.8223, mean_rewards: 204.5864, total_rewards: 1973.0412, mean_steps: 15.9000, mean_ecr: 0.0398 mean_entropies: 1.8196, took: 84.5857s
2022-10-09 01:00:03,380 [INFO] 	Process 2 - batch 7199: mean_policy_losses: -115.678, mean_net_lifetime: 3030.0649, mean_mc_travel_dist: 1124.7392, mean_rewards: 214.8247, total_rewards: 1946.2923, mean_steps: 14.2800, mean_ecr: 0.0418 mean_entropies: 1.8783, took: 76.3464s
2022-10-09 01:00:23,296 [INFO] 	Process 6 - batch 7099: mean_policy_losses: -67.141, mean_net_lifetime: 3382.9242, mean_mc_travel_dist: 1312.4793, mean_rewards: 203.2020, total_rewards: 2111.5861, mean_steps: 17.8400, mean_ecr: 0.0391 mean_entropies: 1.8733, took: 94.8013s
2022-10-09 01:00:25,319 [INFO] 	Process 5 - batch 6899: mean_policy_losses: -93.637, mean_net_lifetime: 3460.4324, mean_mc_travel_dist: 1323.7797, mean_rewards: 207.0364, total_rewards: 2177.7206, mean_steps: 18.0700, mean_ecr: 0.0383 mean_entropies: 1.8634, took: 94.4059s
2022-10-09 01:00:36,724 [INFO] 	Process 4 - batch 7199: mean_policy_losses: -71.520, mean_net_lifetime: 3162.7508, mean_mc_travel_dist: 1147.2558, mean_rewards: 213.3979, total_rewards: 2067.7884, mean_steps: 15.2400, mean_ecr: 0.0416 mean_entropies: 1.9183, took: 80.4770s
2022-10-09 01:00:48,166 [INFO] 	Process 1 - batch 7199: mean_policy_losses: -78.199, mean_net_lifetime: 3155.6273, mean_mc_travel_dist: 1125.8015, mean_rewards: 216.5568, total_rewards: 2069.6916, mean_steps: 15.1200, mean_ecr: 0.0415 mean_entropies: 1.9385, took: 77.9585s
2022-10-09 01:01:03,957 [INFO] 	Process 3 - batch 7299: mean_policy_losses: -122.927, mean_net_lifetime: 3217.9549, mean_mc_travel_dist: 1197.4336, mean_rewards: 205.7972, total_rewards: 2058.7375, mean_steps: 16.6800, mean_ecr: 0.0399 mean_entropies: 1.8720, took: 86.7497s
2022-10-09 01:01:32,619 [INFO] 	Process 2 - batch 7299: mean_policy_losses: -135.857, mean_net_lifetime: 3377.7297, mean_mc_travel_dist: 1222.4979, mean_rewards: 206.6088, total_rewards: 2190.8597, mean_steps: 17.1400, mean_ecr: 0.0396 mean_entropies: 1.8782, took: 89.2386s
2022-10-09 01:01:44,447 [INFO] 	Process 0 - batch 6899: mean_policy_losses: -74.278, mean_net_lifetime: 3849.3343, mean_mc_travel_dist: 1481.5784, mean_rewards: 208.1282, total_rewards: 2408.0459, mean_steps: 20.6300, mean_ecr: 0.0379 mean_entropies: 1.9238, took: 106.7021s
2022-10-09 01:01:45,470 [INFO] 	Process 6 - batch 7199: mean_policy_losses: -88.183, mean_net_lifetime: 3128.7460, mean_mc_travel_dist: 1088.7412, mean_rewards: 211.8721, total_rewards: 2082.7892, mean_steps: 15.2400, mean_ecr: 0.0415 mean_entropies: 2.0063, took: 82.1744s
2022-10-09 01:01:57,415 [INFO] 	Process 5 - batch 6999: mean_policy_losses: -109.999, mean_net_lifetime: 3312.3094, mean_mc_travel_dist: 1211.0568, mean_rewards: 202.8700, total_rewards: 2143.9763, mean_steps: 17.4000, mean_ecr: 0.0391 mean_entropies: 1.9454, took: 92.0961s
2022-10-09 01:02:01,940 [INFO] 	Process 4 - batch 7299: mean_policy_losses: -126.353, mean_net_lifetime: 3238.4860, mean_mc_travel_dist: 1155.3993, mean_rewards: 209.4724, total_rewards: 2116.3289, mean_steps: 16.3600, mean_ecr: 0.0396 mean_entropies: 1.9205, took: 85.2161s
2022-10-09 01:02:17,742 [INFO] 	Process 1 - batch 7299: mean_policy_losses: -95.157, mean_net_lifetime: 3349.0559, mean_mc_travel_dist: 1218.3381, mean_rewards: 200.4133, total_rewards: 2168.4572, mean_steps: 17.6400, mean_ecr: 0.0398 mean_entropies: 1.9085, took: 89.5762s
2022-10-09 01:02:27,014 [INFO] 	Process 3 - batch 7399: mean_policy_losses: -73.051, mean_net_lifetime: 3173.3752, mean_mc_travel_dist: 1146.3278, mean_rewards: 206.9811, total_rewards: 2067.3529, mean_steps: 16.0100, mean_ecr: 0.0410 mean_entropies: 1.9290, took: 83.0561s
2022-10-09 01:03:07,699 [INFO] 	Process 2 - batch 7399: mean_policy_losses: -12.302, mean_net_lifetime: 3591.5070, mean_mc_travel_dist: 1290.5444, mean_rewards: 211.6544, total_rewards: 2341.4561, mean_steps: 17.9200, mean_ecr: 0.0407 mean_entropies: 1.9909, took: 95.0806s
2022-10-09 01:03:12,193 [INFO] 	Process 0 - batch 6999: mean_policy_losses: -162.838, mean_net_lifetime: 3382.5796, mean_mc_travel_dist: 1208.9255, mean_rewards: 215.7554, total_rewards: 2210.9832, mean_steps: 16.7200, mean_ecr: 0.0391 mean_entropies: 2.0043, took: 87.7442s
2022-10-09 01:03:12,945 [INFO] 	Process 6 - batch 7299: mean_policy_losses: -135.703, mean_net_lifetime: 3312.2116, mean_mc_travel_dist: 1172.5313, mean_rewards: 211.7035, total_rewards: 2177.5116, mean_steps: 16.7800, mean_ecr: 0.0398 mean_entropies: 1.9612, took: 87.4755s
2022-10-09 01:03:26,275 [INFO] 	Process 4 - batch 7399: mean_policy_losses: -107.188, mean_net_lifetime: 3308.6494, mean_mc_travel_dist: 1152.4273, mean_rewards: 213.2143, total_rewards: 2195.6886, mean_steps: 16.3100, mean_ecr: 0.0407 mean_entropies: 1.9988, took: 84.3358s
2022-10-09 01:03:33,854 [INFO] 	Process 5 - batch 7099: mean_policy_losses: -124.117, mean_net_lifetime: 3518.0133, mean_mc_travel_dist: 1283.1042, mean_rewards: 206.7778, total_rewards: 2276.0554, mean_steps: 18.6700, mean_ecr: 0.0392 mean_entropies: 1.9963, took: 96.4382s
2022-10-09 01:03:45,489 [INFO] 	Process 1 - batch 7399: mean_policy_losses: -113.790, mean_net_lifetime: 3405.9735, mean_mc_travel_dist: 1233.1317, mean_rewards: 218.4964, total_rewards: 2211.1349, mean_steps: 17.3100, mean_ecr: 0.0407 mean_entropies: 2.0081, took: 87.7464s
2022-10-09 01:04:00,270 [INFO] 	Process 3 - batch 7499: mean_policy_losses: -135.257, mean_net_lifetime: 3459.7158, mean_mc_travel_dist: 1253.4571, mean_rewards: 212.8830, total_rewards: 2241.0519, mean_steps: 17.9000, mean_ecr: 0.0401 mean_entropies: 2.0136, took: 93.2567s
2022-10-09 01:04:36,964 [INFO] 	Process 2 - batch 7499: mean_policy_losses: -179.376, mean_net_lifetime: 3314.3611, mean_mc_travel_dist: 1181.9498, mean_rewards: 208.7193, total_rewards: 2173.3966, mean_steps: 17.0700, mean_ecr: 0.0405 mean_entropies: 2.0219, took: 89.2654s
2022-10-09 01:04:42,289 [INFO] 	Process 6 - batch 7399: mean_policy_losses: -91.833, mean_net_lifetime: 3395.0697, mean_mc_travel_dist: 1178.9265, mean_rewards: 211.1906, total_rewards: 2251.9439, mean_steps: 17.2300, mean_ecr: 0.0405 mean_entropies: 2.0122, took: 89.3430s
2022-10-09 01:04:47,643 [INFO] 	Process 0 - batch 7099: mean_policy_losses: -115.227, mean_net_lifetime: 3486.0229, mean_mc_travel_dist: 1256.2142, mean_rewards: 203.3834, total_rewards: 2264.4837, mean_steps: 18.3300, mean_ecr: 0.0388 mean_entropies: 2.0296, took: 95.4512s
2022-10-09 01:04:55,352 [INFO] 	Process 5 - batch 7199: mean_policy_losses: -94.017, mean_net_lifetime: 3273.7950, mean_mc_travel_dist: 1115.9666, mean_rewards: 219.0354, total_rewards: 2188.8324, mean_steps: 15.9500, mean_ecr: 0.0413 mean_entropies: 2.0571, took: 81.4990s
2022-10-09 01:04:55,474 [INFO] 	Process 4 - batch 7499: mean_policy_losses: -219.783, mean_net_lifetime: 3311.7036, mean_mc_travel_dist: 1216.0047, mean_rewards: 210.7736, total_rewards: 2138.1759, mean_steps: 17.2800, mean_ecr: 0.0403 mean_entropies: 2.0240, took: 89.1980s
2022-10-09 01:05:01,003 [INFO] 	Process 1 - batch 7499: mean_policy_losses: -125.832, mean_net_lifetime: 3147.1519, mean_mc_travel_dist: 1103.9030, mean_rewards: 215.4765, total_rewards: 2087.4549, mean_steps: 15.3000, mean_ecr: 0.0406 mean_entropies: 2.0282, took: 75.5145s
2022-10-09 01:05:56,967 [INFO] 	Process 6 - batch 7499: mean_policy_losses: -134.411, mean_net_lifetime: 3218.3530, mean_mc_travel_dist: 1162.8098, mean_rewards: 214.3838, total_rewards: 2098.3941, mean_steps: 16.0000, mean_ecr: 0.0404 mean_entropies: 2.0349, took: 74.6786s
2022-10-09 01:05:58,220 [INFO] 	Process 0 - batch 7199: mean_policy_losses: -36.148, mean_net_lifetime: 3248.5054, mean_mc_travel_dist: 1076.9117, mean_rewards: 220.2677, total_rewards: 2205.0916, mean_steps: 15.3100, mean_ecr: 0.0410 mean_entropies: 2.0760, took: 70.5764s
2022-10-09 01:06:17,584 [INFO] 	Process 5 - batch 7299: mean_policy_losses: -103.850, mean_net_lifetime: 3446.9891, mean_mc_travel_dist: 1229.9417, mean_rewards: 208.2563, total_rewards: 2253.9768, mean_steps: 17.8900, mean_ecr: 0.0397 mean_entropies: 2.0116, took: 82.2317s
2022-10-09 01:07:11,601 [INFO] 	Process 0 - batch 7299: mean_policy_losses: -162.533, mean_net_lifetime: 3334.5077, mean_mc_travel_dist: 1190.3464, mean_rewards: 209.6608, total_rewards: 2190.3468, mean_steps: 16.9100, mean_ecr: 0.0398 mean_entropies: 2.0066, took: 73.3811s
2022-10-09 01:07:34,986 [INFO] 	Process 5 - batch 7399: mean_policy_losses: -12.664, mean_net_lifetime: 3628.3315, mean_mc_travel_dist: 1258.4527, mean_rewards: 212.5817, total_rewards: 2408.8687, mean_steps: 18.1300, mean_ecr: 0.0407 mean_entropies: 2.0245, took: 77.4026s
2022-10-09 01:08:35,180 [INFO] 	Process 0 - batch 7399: mean_policy_losses: -56.820, mean_net_lifetime: 3681.0086, mean_mc_travel_dist: 1313.6088, mean_rewards: 211.1602, total_rewards: 2404.0061, mean_steps: 18.9800, mean_ecr: 0.0408 mean_entropies: 2.0354, took: 83.5801s
2022-10-09 01:08:44,291 [INFO] 	Process 5 - batch 7499: mean_policy_losses: -263.647, mean_net_lifetime: 3198.2964, mean_mc_travel_dist: 1131.4028, mean_rewards: 213.0197, total_rewards: 2105.3786, mean_steps: 15.6700, mean_ecr: 0.0406 mean_entropies: 2.0477, took: 69.3041s
2022-10-09 01:09:42,867 [INFO] 	Process 0 - batch 7499: mean_policy_losses: -208.844, mean_net_lifetime: 2993.7171, mean_mc_travel_dist: 1069.0319, mean_rewards: 216.3896, total_rewards: 1970.3389, mean_steps: 15.0700, mean_ecr: 0.0405 mean_entropies: 2.0226, took: 67.6862s
2022-10-09 01:17:20,035 [INFO] 	Process 3 - batch 7599: mean_policy_losses: -4.407, mean_net_lifetime: 3402.0011, mean_mc_travel_dist: 1267.9007, mean_rewards: 203.8317, total_rewards: 2169.0347, mean_steps: 18.5300, mean_ecr: 0.0394 mean_entropies: 1.9693, took: 799.7648s
2022-10-09 01:17:21,948 [INFO] 	Process 2 - batch 7599: mean_policy_losses: -5.598, mean_net_lifetime: 3466.1336, mean_mc_travel_dist: 1261.5869, mean_rewards: 201.5669, total_rewards: 2240.3829, mean_steps: 18.8600, mean_ecr: 0.0394 mean_entropies: 1.9631, took: 764.9823s
2022-10-09 01:18:07,052 [INFO] 	Process 1 - batch 7599: mean_policy_losses: -71.187, mean_net_lifetime: 3490.0388, mean_mc_travel_dist: 1290.0663, mean_rewards: 197.8875, total_rewards: 2238.7461, mean_steps: 19.1800, mean_ecr: 0.0390 mean_entropies: 1.9875, took: 786.0493s
2022-10-09 01:18:10,030 [INFO] 	Process 4 - batch 7599: mean_policy_losses: -69.583, mean_net_lifetime: 3511.1641, mean_mc_travel_dist: 1338.7407, mean_rewards: 199.8180, total_rewards: 2223.8441, mean_steps: 19.6600, mean_ecr: 0.0389 mean_entropies: 1.9971, took: 794.5558s
2022-10-09 01:18:45,154 [INFO] 	Process 3 - batch 7699: mean_policy_losses: -69.860, mean_net_lifetime: 3450.1685, mean_mc_travel_dist: 1209.9071, mean_rewards: 209.4595, total_rewards: 2280.1901, mean_steps: 17.4900, mean_ecr: 0.0403 mean_entropies: 2.0468, took: 85.1180s
2022-10-09 01:18:51,290 [INFO] 	Process 2 - batch 7699: mean_policy_losses: -76.759, mean_net_lifetime: 3544.1039, mean_mc_travel_dist: 1257.5363, mean_rewards: 208.9216, total_rewards: 2325.8036, mean_steps: 18.0700, mean_ecr: 0.0404 mean_entropies: 2.0616, took: 89.3439s
2022-10-09 01:19:07,993 [INFO] 	Process 6 - batch 7599: mean_policy_losses: -79.881, mean_net_lifetime: 3561.5556, mean_mc_travel_dist: 1323.2610, mean_rewards: 208.1565, total_rewards: 2283.6729, mean_steps: 19.1600, mean_ecr: 0.0389 mean_entropies: 2.0183, took: 791.0241s
2022-10-09 01:19:27,103 [INFO] 	Process 1 - batch 7699: mean_policy_losses: -178.677, mean_net_lifetime: 3343.8106, mean_mc_travel_dist: 1198.4764, mean_rewards: 213.2304, total_rewards: 2186.1264, mean_steps: 16.7800, mean_ecr: 0.0402 mean_entropies: 2.0509, took: 80.0507s
2022-10-09 01:19:27,345 [INFO] 	Process 4 - batch 7699: mean_policy_losses: -176.928, mean_net_lifetime: 3178.0846, mean_mc_travel_dist: 1108.3129, mean_rewards: 207.7234, total_rewards: 2111.5527, mean_steps: 15.8500, mean_ecr: 0.0403 mean_entropies: 2.0540, took: 77.3152s
2022-10-09 01:20:15,247 [INFO] 	Process 3 - batch 7799: mean_policy_losses: -113.724, mean_net_lifetime: 3573.6706, mean_mc_travel_dist: 1272.0572, mean_rewards: 201.6889, total_rewards: 2328.7472, mean_steps: 18.5500, mean_ecr: 0.0398 mean_entropies: 2.0674, took: 90.0944s
2022-10-09 01:20:20,928 [INFO] 	Process 2 - batch 7799: mean_policy_losses: -68.092, mean_net_lifetime: 3564.1423, mean_mc_travel_dist: 1268.4743, mean_rewards: 200.6614, total_rewards: 2339.0927, mean_steps: 18.4200, mean_ecr: 0.0397 mean_entropies: 2.0674, took: 89.6380s
2022-10-09 01:20:30,094 [INFO] 	Process 6 - batch 7699: mean_policy_losses: -151.265, mean_net_lifetime: 3376.6486, mean_mc_travel_dist: 1179.1833, mean_rewards: 207.8734, total_rewards: 2242.4026, mean_steps: 17.1600, mean_ecr: 0.0404 mean_entropies: 2.0449, took: 82.1026s
2022-10-09 01:20:54,950 [INFO] 	Process 1 - batch 7799: mean_policy_losses: -48.280, mean_net_lifetime: 3609.7518, mean_mc_travel_dist: 1283.2847, mean_rewards: 206.4961, total_rewards: 2359.9251, mean_steps: 18.3800, mean_ecr: 0.0399 mean_entropies: 2.0599, took: 87.8473s
2022-10-09 01:20:55,971 [INFO] 	Process 4 - batch 7799: mean_policy_losses: -96.427, mean_net_lifetime: 3559.2397, mean_mc_travel_dist: 1289.5401, mean_rewards: 203.0769, total_rewards: 2306.7909, mean_steps: 18.5700, mean_ecr: 0.0396 mean_entropies: 2.0760, took: 88.6267s
2022-10-09 01:21:31,598 [INFO] 	Process 3 - batch 7899: mean_policy_losses: -281.522, mean_net_lifetime: 3185.0524, mean_mc_travel_dist: 1111.8801, mean_rewards: 218.7463, total_rewards: 2111.8504, mean_steps: 15.4900, mean_ecr: 0.0378 mean_entropies: 2.0309, took: 76.3499s
2022-10-09 01:21:44,807 [INFO] 	Process 2 - batch 7899: mean_policy_losses: -157.466, mean_net_lifetime: 3446.1370, mean_mc_travel_dist: 1217.9120, mean_rewards: 214.2589, total_rewards: 2268.7611, mean_steps: 16.7900, mean_ecr: 0.0377 mean_entropies: 2.0490, took: 83.8786s
2022-10-09 01:22:03,149 [INFO] 	Process 6 - batch 7799: mean_policy_losses: -11.024, mean_net_lifetime: 3691.5329, mean_mc_travel_dist: 1340.8708, mean_rewards: 208.2295, total_rewards: 2393.5775, mean_steps: 19.1600, mean_ecr: 0.0395 mean_entropies: 2.0663, took: 93.0552s
2022-10-09 01:22:10,811 [INFO] 	Process 1 - batch 7899: mean_policy_losses: -246.304, mean_net_lifetime: 3128.7967, mean_mc_travel_dist: 1109.1029, mean_rewards: 216.1415, total_rewards: 2068.4232, mean_steps: 15.4500, mean_ecr: 0.0380 mean_entropies: 2.0502, took: 75.8605s
2022-10-09 01:22:14,321 [INFO] 	Process 4 - batch 7899: mean_policy_losses: -192.456, mean_net_lifetime: 3251.2024, mean_mc_travel_dist: 1133.5846, mean_rewards: 213.4327, total_rewards: 2154.5796, mean_steps: 15.8900, mean_ecr: 0.0379 mean_entropies: 2.0180, took: 78.3496s
2022-10-09 01:23:06,962 [INFO] 	Process 3 - batch 7999: mean_policy_losses: -41.999, mean_net_lifetime: 3788.4699, mean_mc_travel_dist: 1367.0770, mean_rewards: 207.2756, total_rewards: 2450.5201, mean_steps: 19.6100, mean_ecr: 0.0385 mean_entropies: 2.0752, took: 95.3657s
2022-10-09 01:23:16,412 [INFO] 	Process 2 - batch 7999: mean_policy_losses: -44.901, mean_net_lifetime: 3673.6631, mean_mc_travel_dist: 1313.1648, mean_rewards: 208.5260, total_rewards: 2412.3655, mean_steps: 18.1900, mean_ecr: 0.0385 mean_entropies: 2.0775, took: 91.6046s
2022-10-09 01:23:22,631 [INFO] 	Process 6 - batch 7899: mean_policy_losses: -280.057, mean_net_lifetime: 3129.5662, mean_mc_travel_dist: 1085.7765, mean_rewards: 217.0761, total_rewards: 2079.4428, mean_steps: 15.0300, mean_ecr: 0.0382 mean_entropies: 2.0440, took: 79.4815s
2022-10-09 01:23:31,569 [INFO] 	Process 5 - batch 7599: mean_policy_losses: -157.851, mean_net_lifetime: 3412.3434, mean_mc_travel_dist: 1256.8418, mean_rewards: 207.2984, total_rewards: 2193.7410, mean_steps: 18.0600, mean_ecr: 0.0393 mean_entropies: 2.0271, took: 887.2784s
2022-10-09 01:23:36,469 [INFO] 	Process 1 - batch 7999: mean_policy_losses: -125.497, mean_net_lifetime: 3456.8918, mean_mc_travel_dist: 1234.9105, mean_rewards: 210.7981, total_rewards: 2255.6918, mean_steps: 17.0100, mean_ecr: 0.0386 mean_entropies: 2.0737, took: 85.6580s
2022-10-09 01:23:50,101 [INFO] 	Process 4 - batch 7999: mean_policy_losses: -108.429, mean_net_lifetime: 3603.9709, mean_mc_travel_dist: 1305.8967, mean_rewards: 206.5969, total_rewards: 2342.7031, mean_steps: 18.5100, mean_ecr: 0.0383 mean_entropies: 2.0772, took: 95.7800s
2022-10-09 01:24:15,624 [INFO] 	Process 0 - batch 7599: mean_policy_losses: -190.323, mean_net_lifetime: 3215.2710, mean_mc_travel_dist: 1188.2011, mean_rewards: 210.2716, total_rewards: 2063.1923, mean_steps: 16.8700, mean_ecr: 0.0392 mean_entropies: 2.0133, took: 872.7570s
2022-10-09 01:24:46,375 [INFO] 	Process 3 - batch 8099: mean_policy_losses: -173.902, mean_net_lifetime: 3709.4658, mean_mc_travel_dist: 1340.7577, mean_rewards: 206.8602, total_rewards: 2404.9276, mean_steps: 19.5400, mean_ecr: 0.0370 mean_entropies: 2.0563, took: 99.4112s
2022-10-09 01:25:01,356 [INFO] 	Process 5 - batch 7699: mean_policy_losses: -123.087, mean_net_lifetime: 3348.5729, mean_mc_travel_dist: 1230.1365, mean_rewards: 201.5584, total_rewards: 2166.3280, mean_steps: 17.2200, mean_ecr: 0.0404 mean_entropies: 2.0715, took: 89.7869s
2022-10-09 01:25:03,062 [INFO] 	Process 2 - batch 8099: mean_policy_losses: -149.806, mean_net_lifetime: 3878.9910, mean_mc_travel_dist: 1431.0855, mean_rewards: 200.2102, total_rewards: 2482.3254, mean_steps: 20.6400, mean_ecr: 0.0366 mean_entropies: 2.0674, took: 106.6502s
2022-10-09 01:25:05,457 [INFO] 	Process 6 - batch 7999: mean_policy_losses: 17.361, mean_net_lifetime: 3990.6551, mean_mc_travel_dist: 1439.1236, mean_rewards: 210.0726, total_rewards: 2593.4676, mean_steps: 19.8300, mean_ecr: 0.0383 mean_entropies: 2.0832, took: 102.8257s
2022-10-09 01:25:16,096 [INFO] 	Process 1 - batch 8099: mean_policy_losses: -151.798, mean_net_lifetime: 3758.9884, mean_mc_travel_dist: 1385.9852, mean_rewards: 207.6232, total_rewards: 2410.7706, mean_steps: 19.8800, mean_ecr: 0.0365 mean_entropies: 2.0455, took: 99.6263s
2022-10-09 01:25:33,903 [INFO] 	Process 4 - batch 8099: mean_policy_losses: -129.520, mean_net_lifetime: 3806.1756, mean_mc_travel_dist: 1402.6906, mean_rewards: 204.2161, total_rewards: 2436.6558, mean_steps: 20.0300, mean_ecr: 0.0366 mean_entropies: 2.0517, took: 103.8023s
2022-10-09 01:25:42,222 [INFO] 	Process 0 - batch 7699: mean_policy_losses: -144.553, mean_net_lifetime: 3346.5776, mean_mc_travel_dist: 1179.9890, mean_rewards: 213.3695, total_rewards: 2212.1375, mean_steps: 16.5000, mean_ecr: 0.0403 mean_entropies: 2.0621, took: 86.5982s
2022-10-09 01:26:28,390 [INFO] 	Process 3 - batch 8199: mean_policy_losses: -238.223, mean_net_lifetime: 3677.8937, mean_mc_travel_dist: 1379.6824, mean_rewards: 221.9286, total_rewards: 2343.1807, mean_steps: 19.8200, mean_ecr: 0.0402 mean_entropies: 2.0775, took: 102.0152s
2022-10-09 01:26:29,527 [INFO] 	Process 2 - batch 8199: mean_policy_losses: -213.292, mean_net_lifetime: 3293.4428, mean_mc_travel_dist: 1183.3176, mean_rewards: 221.7179, total_rewards: 2153.4593, mean_steps: 16.3200, mean_ecr: 0.0400 mean_entropies: 2.0821, took: 86.4654s
2022-10-09 01:26:30,458 [INFO] 	Process 5 - batch 7799: mean_policy_losses: -62.160, mean_net_lifetime: 3405.6166, mean_mc_travel_dist: 1228.0003, mean_rewards: 209.7395, total_rewards: 2212.7826, mean_steps: 16.9600, mean_ecr: 0.0394 mean_entropies: 2.1011, took: 89.1016s
2022-10-09 01:26:43,560 [INFO] 	Process 6 - batch 8099: mean_policy_losses: -69.248, mean_net_lifetime: 3734.3975, mean_mc_travel_dist: 1348.0938, mean_rewards: 208.5923, total_rewards: 2421.6775, mean_steps: 19.2100, mean_ecr: 0.0371 mean_entropies: 2.0827, took: 98.1039s
2022-10-09 01:26:45,123 [INFO] 	Process 1 - batch 8199: mean_policy_losses: -190.194, mean_net_lifetime: 3338.7848, mean_mc_travel_dist: 1221.2194, mean_rewards: 214.7315, total_rewards: 2153.2487, mean_steps: 17.6200, mean_ecr: 0.0400 mean_entropies: 2.0829, took: 89.0280s
2022-10-09 01:27:03,062 [INFO] 	Process 4 - batch 8199: mean_policy_losses: -147.847, mean_net_lifetime: 3417.6706, mean_mc_travel_dist: 1274.4941, mean_rewards: 215.1566, total_rewards: 2192.5241, mean_steps: 17.3800, mean_ecr: 0.0398 mean_entropies: 2.0924, took: 89.1590s
2022-10-09 01:27:14,691 [INFO] 	Process 0 - batch 7799: mean_policy_losses: -59.294, mean_net_lifetime: 3451.3968, mean_mc_travel_dist: 1258.7363, mean_rewards: 205.7729, total_rewards: 2237.2717, mean_steps: 17.5400, mean_ecr: 0.0398 mean_entropies: 2.1074, took: 92.4691s
2022-10-09 01:27:50,322 [INFO] 	Process 5 - batch 7899: mean_policy_losses: -277.864, mean_net_lifetime: 3227.4908, mean_mc_travel_dist: 1142.6916, mean_rewards: 227.8890, total_rewards: 2134.7584, mean_steps: 15.0200, mean_ecr: 0.0380 mean_entropies: 2.0360, took: 79.8646s
2022-10-09 01:27:59,024 [INFO] 	Process 2 - batch 8299: mean_policy_losses: -133.317, mean_net_lifetime: 3484.6096, mean_mc_travel_dist: 1271.8721, mean_rewards: 218.2227, total_rewards: 2253.0714, mean_steps: 17.2300, mean_ecr: 0.0402 mean_entropies: 2.0945, took: 89.4953s
2022-10-09 01:28:03,159 [INFO] 	Process 3 - batch 8299: mean_policy_losses: -108.493, mean_net_lifetime: 3701.1649, mean_mc_travel_dist: 1362.1580, mean_rewards: 217.6443, total_rewards: 2374.6490, mean_steps: 18.1700, mean_ecr: 0.0401 mean_entropies: 2.1063, took: 94.7691s
2022-10-09 01:28:10,034 [INFO] 	Process 1 - batch 8299: mean_policy_losses: -113.902, mean_net_lifetime: 3452.8757, mean_mc_travel_dist: 1247.0993, mean_rewards: 217.7572, total_rewards: 2239.9733, mean_steps: 16.6100, mean_ecr: 0.0404 mean_entropies: 2.1099, took: 84.9100s
2022-10-09 01:28:13,932 [INFO] 	Process 6 - batch 8199: mean_policy_losses: -150.677, mean_net_lifetime: 3335.2619, mean_mc_travel_dist: 1211.8014, mean_rewards: 211.6465, total_rewards: 2164.2636, mean_steps: 17.3200, mean_ecr: 0.0401 mean_entropies: 2.0880, took: 90.3719s
2022-10-09 01:28:38,750 [INFO] 	Process 0 - batch 7899: mean_policy_losses: -220.640, mean_net_lifetime: 3314.3078, mean_mc_travel_dist: 1147.4912, mean_rewards: 225.9814, total_rewards: 2209.0424, mean_steps: 15.8300, mean_ecr: 0.0377 mean_entropies: 2.0176, took: 84.0593s
2022-10-09 01:28:39,457 [INFO] 	Process 4 - batch 8299: mean_policy_losses: -31.974, mean_net_lifetime: 3812.7076, mean_mc_travel_dist: 1383.4061, mean_rewards: 222.8016, total_rewards: 2472.5067, mean_steps: 18.3100, mean_ecr: 0.0402 mean_entropies: 2.1089, took: 96.3948s
2022-10-09 01:29:29,197 [INFO] 	Process 2 - batch 8399: mean_policy_losses: -142.441, mean_net_lifetime: 3425.9019, mean_mc_travel_dist: 1222.5752, mean_rewards: 207.8095, total_rewards: 2242.6256, mean_steps: 17.5700, mean_ecr: 0.0391 mean_entropies: 2.0399, took: 90.1741s
2022-10-09 01:29:31,989 [INFO] 	Process 5 - batch 7999: mean_policy_losses: -71.800, mean_net_lifetime: 3943.2022, mean_mc_travel_dist: 1435.5803, mean_rewards: 217.9049, total_rewards: 2542.2288, mean_steps: 20.0700, mean_ecr: 0.0379 mean_entropies: 2.0460, took: 101.6671s
2022-10-09 01:29:37,168 [INFO] 	Process 3 - batch 8399: mean_policy_losses: -107.663, mean_net_lifetime: 3507.8796, mean_mc_travel_dist: 1250.0631, mean_rewards: 203.4783, total_rewards: 2291.8513, mean_steps: 17.8500, mean_ecr: 0.0390 mean_entropies: 2.0612, took: 94.0098s
2022-10-09 01:29:41,969 [INFO] 	Process 1 - batch 8399: mean_policy_losses: -172.288, mean_net_lifetime: 3552.5618, mean_mc_travel_dist: 1272.5711, mean_rewards: 207.0560, total_rewards: 2324.7902, mean_steps: 18.0600, mean_ecr: 0.0387 mean_entropies: 2.0428, took: 91.9353s
2022-10-09 01:29:43,602 [INFO] 	Process 6 - batch 8299: mean_policy_losses: -164.344, mean_net_lifetime: 3503.3167, mean_mc_travel_dist: 1235.2473, mean_rewards: 214.5730, total_rewards: 2305.5996, mean_steps: 17.2000, mean_ecr: 0.0399 mean_entropies: 2.0713, took: 89.6688s
2022-10-09 01:30:12,041 [INFO] 	Process 4 - batch 8399: mean_policy_losses: -155.021, mean_net_lifetime: 3562.4932, mean_mc_travel_dist: 1298.6923, mean_rewards: 203.5951, total_rewards: 2318.3547, mean_steps: 18.0100, mean_ecr: 0.0388 mean_entropies: 2.0319, took: 92.5844s
2022-10-09 01:30:17,828 [INFO] 	Process 0 - batch 7999: mean_policy_losses: -112.658, mean_net_lifetime: 3777.9324, mean_mc_travel_dist: 1378.2324, mean_rewards: 210.1206, total_rewards: 2444.6850, mean_steps: 19.4800, mean_ecr: 0.0387 mean_entropies: 2.0637, took: 99.0781s
2022-10-09 01:30:53,189 [INFO] 	Process 2 - batch 8499: mean_policy_losses: -240.182, mean_net_lifetime: 3272.0660, mean_mc_travel_dist: 1169.2281, mean_rewards: 211.4732, total_rewards: 2148.3756, mean_steps: 16.0000, mean_ecr: 0.0397 mean_entropies: 2.0462, took: 83.9922s
2022-10-09 01:30:56,229 [INFO] 	Process 3 - batch 8499: mean_policy_losses: -238.763, mean_net_lifetime: 3112.9850, mean_mc_travel_dist: 1105.0438, mean_rewards: 222.2311, total_rewards: 2047.4779, mean_steps: 14.7600, mean_ecr: 0.0399 mean_entropies: 2.0218, took: 79.0612s
2022-10-09 01:31:06,044 [INFO] 	Process 1 - batch 8499: mean_policy_losses: -115.279, mean_net_lifetime: 3350.4234, mean_mc_travel_dist: 1206.5153, mean_rewards: 213.8227, total_rewards: 2188.8642, mean_steps: 16.4200, mean_ecr: 0.0396 mean_entropies: 2.0431, took: 84.0750s
2022-10-09 01:31:11,957 [INFO] 	Process 5 - batch 8099: mean_policy_losses: -46.936, mean_net_lifetime: 3752.5058, mean_mc_travel_dist: 1324.4636, mean_rewards: 207.7845, total_rewards: 2465.0344, mean_steps: 19.4500, mean_ecr: 0.0370 mean_entropies: 2.0434, took: 99.9677s
2022-10-09 01:31:13,994 [INFO] 	Process 6 - batch 8399: mean_policy_losses: -104.427, mean_net_lifetime: 3402.2450, mean_mc_travel_dist: 1207.2750, mean_rewards: 201.3479, total_rewards: 2228.7003, mean_steps: 17.4000, mean_ecr: 0.0389 mean_entropies: 2.0398, took: 90.3931s
2022-10-09 01:31:37,906 [INFO] 	Process 4 - batch 8499: mean_policy_losses: -112.770, mean_net_lifetime: 3342.4821, mean_mc_travel_dist: 1176.4342, mean_rewards: 215.1572, total_rewards: 2202.6658, mean_steps: 16.2200, mean_ecr: 0.0398 mean_entropies: 2.0548, took: 85.8659s
2022-10-09 01:32:04,912 [INFO] 	Process 0 - batch 8099: mean_policy_losses: -82.413, mean_net_lifetime: 3834.9028, mean_mc_travel_dist: 1399.6339, mean_rewards: 199.2514, total_rewards: 2466.4576, mean_steps: 20.6600, mean_ecr: 0.0365 mean_entropies: 2.0540, took: 107.0832s
2022-10-09 01:32:14,008 [INFO] 	Process 2 - batch 8599: mean_policy_losses: -91.250, mean_net_lifetime: 3283.7324, mean_mc_travel_dist: 1180.4101, mean_rewards: 221.9367, total_rewards: 2140.5185, mean_steps: 15.5900, mean_ecr: 0.0414 mean_entropies: 2.0174, took: 80.8191s
2022-10-09 01:32:21,200 [INFO] 	Process 3 - batch 8599: mean_policy_losses: -8.048, mean_net_lifetime: 3303.9211, mean_mc_travel_dist: 1175.0925, mean_rewards: 216.2759, total_rewards: 2164.1253, mean_steps: 16.3400, mean_ecr: 0.0414 mean_entropies: 2.0259, took: 84.9707s
2022-10-09 01:32:26,417 [INFO] 	Process 1 - batch 8599: mean_policy_losses: -123.027, mean_net_lifetime: 3184.0613, mean_mc_travel_dist: 1157.8719, mean_rewards: 211.7789, total_rewards: 2070.8960, mean_steps: 15.6300, mean_ecr: 0.0414 mean_entropies: 2.0259, took: 80.3733s
2022-10-09 01:32:32,010 [INFO] 	Process 6 - batch 8499: mean_policy_losses: -187.311, mean_net_lifetime: 3119.8494, mean_mc_travel_dist: 1114.3135, mean_rewards: 218.7699, total_rewards: 2049.6495, mean_steps: 14.8400, mean_ecr: 0.0397 mean_entropies: 2.0523, took: 78.0154s
2022-10-09 01:32:40,211 [INFO] 	Process 5 - batch 8199: mean_policy_losses: -113.206, mean_net_lifetime: 3344.4841, mean_mc_travel_dist: 1200.1600, mean_rewards: 210.5773, total_rewards: 2177.0678, mean_steps: 17.0700, mean_ecr: 0.0400 mean_entropies: 2.0864, took: 88.2543s
2022-10-09 01:33:01,232 [INFO] 	Process 4 - batch 8599: mean_policy_losses: -51.290, mean_net_lifetime: 3292.7550, mean_mc_travel_dist: 1169.3994, mean_rewards: 221.5035, total_rewards: 2171.7474, mean_steps: 15.7900, mean_ecr: 0.0416 mean_entropies: 2.0186, took: 83.3249s
2022-10-09 01:33:38,887 [INFO] 	Process 0 - batch 8199: mean_policy_losses: -122.503, mean_net_lifetime: 3479.9855, mean_mc_travel_dist: 1227.0648, mean_rewards: 214.8809, total_rewards: 2294.1249, mean_steps: 17.5500, mean_ecr: 0.0396 mean_entropies: 2.0725, took: 93.9755s
2022-10-09 01:33:52,813 [INFO] 	Process 6 - batch 8599: mean_policy_losses: -175.793, mean_net_lifetime: 3166.6034, mean_mc_travel_dist: 1122.3454, mean_rewards: 216.5059, total_rewards: 2092.8236, mean_steps: 15.3800, mean_ecr: 0.0416 mean_entropies: 2.0138, took: 80.8033s
2022-10-09 01:33:52,938 [INFO] 	Process 2 - batch 8699: mean_policy_losses: -74.316, mean_net_lifetime: 3584.1992, mean_mc_travel_dist: 1288.3489, mean_rewards: 209.0403, total_rewards: 2330.9224, mean_steps: 19.0000, mean_ecr: 0.0404 mean_entropies: 2.0284, took: 98.9301s
2022-10-09 01:33:56,636 [INFO] 	Process 1 - batch 8699: mean_policy_losses: -226.979, mean_net_lifetime: 3351.2527, mean_mc_travel_dist: 1213.4282, mean_rewards: 208.7224, total_rewards: 2179.6927, mean_steps: 17.8700, mean_ecr: 0.0402 mean_entropies: 2.0089, took: 90.2195s
2022-10-09 01:33:57,551 [INFO] 	Process 3 - batch 8699: mean_policy_losses: -124.149, mean_net_lifetime: 3545.9175, mean_mc_travel_dist: 1305.6069, mean_rewards: 209.7739, total_rewards: 2270.9506, mean_steps: 19.1300, mean_ecr: 0.0406 mean_entropies: 2.0195, took: 96.3514s
2022-10-09 01:34:12,736 [INFO] 	Process 5 - batch 8299: mean_policy_losses: -90.010, mean_net_lifetime: 3648.9129, mean_mc_travel_dist: 1303.7327, mean_rewards: 220.9214, total_rewards: 2387.0759, mean_steps: 17.7000, mean_ecr: 0.0400 mean_entropies: 2.0699, took: 92.5247s
2022-10-09 01:34:39,781 [INFO] 	Process 4 - batch 8699: mean_policy_losses: -73.159, mean_net_lifetime: 3743.7174, mean_mc_travel_dist: 1339.1818, mean_rewards: 216.1313, total_rewards: 2437.5670, mean_steps: 19.3800, mean_ecr: 0.0404 mean_entropies: 2.0162, took: 98.5490s
2022-10-09 01:35:08,652 [INFO] 	Process 0 - batch 8299: mean_policy_losses: -133.655, mean_net_lifetime: 3493.3716, mean_mc_travel_dist: 1239.1338, mean_rewards: 220.7272, total_rewards: 2300.5307, mean_steps: 17.0100, mean_ecr: 0.0406 mean_entropies: 2.0498, took: 89.7648s
2022-10-09 01:35:22,744 [INFO] 	Process 1 - batch 8799: mean_policy_losses: -165.884, mean_net_lifetime: 3409.0417, mean_mc_travel_dist: 1228.1593, mean_rewards: 215.0589, total_rewards: 2214.1671, mean_steps: 17.0000, mean_ecr: 0.0396 mean_entropies: 2.0097, took: 86.1073s
2022-10-09 01:35:24,162 [INFO] 	Process 3 - batch 8799: mean_policy_losses: -146.129, mean_net_lifetime: 3418.7932, mean_mc_travel_dist: 1251.0774, mean_rewards: 210.3662, total_rewards: 2212.0566, mean_steps: 17.0400, mean_ecr: 0.0395 mean_entropies: 2.0308, took: 86.6111s
2022-10-09 01:35:28,166 [INFO] 	Process 2 - batch 8799: mean_policy_losses: -97.680, mean_net_lifetime: 3522.7252, mean_mc_travel_dist: 1241.2852, mean_rewards: 209.8800, total_rewards: 2324.6579, mean_steps: 17.7800, mean_ecr: 0.0394 mean_entropies: 2.0191, took: 95.2273s
2022-10-09 01:35:33,654 [INFO] 	Process 6 - batch 8699: mean_policy_losses: -86.561, mean_net_lifetime: 3589.0371, mean_mc_travel_dist: 1281.5845, mean_rewards: 213.1180, total_rewards: 2339.2331, mean_steps: 19.3400, mean_ecr: 0.0404 mean_entropies: 1.9835, took: 100.8416s
2022-10-09 01:35:47,886 [INFO] 	Process 5 - batch 8399: mean_policy_losses: -108.476, mean_net_lifetime: 3448.3418, mean_mc_travel_dist: 1227.0593, mean_rewards: 201.2123, total_rewards: 2259.1453, mean_steps: 17.9800, mean_ecr: 0.0390 mean_entropies: 2.0023, took: 95.1502s
2022-10-09 01:36:04,675 [INFO] 	Process 4 - batch 8799: mean_policy_losses: -110.893, mean_net_lifetime: 3370.2491, mean_mc_travel_dist: 1197.3552, mean_rewards: 217.6132, total_rewards: 2211.0351, mean_steps: 16.5600, mean_ecr: 0.0394 mean_entropies: 2.0318, took: 84.8943s
2022-10-09 01:36:38,794 [INFO] 	Process 0 - batch 8399: mean_policy_losses: -152.865, mean_net_lifetime: 3408.9096, mean_mc_travel_dist: 1198.7873, mean_rewards: 207.7776, total_rewards: 2247.0447, mean_steps: 17.1700, mean_ecr: 0.0388 mean_entropies: 2.0217, took: 90.1420s
2022-10-09 01:36:41,467 [INFO] 	Process 1 - batch 8899: mean_policy_losses: -184.983, mean_net_lifetime: 3159.5850, mean_mc_travel_dist: 1102.0804, mean_rewards: 217.9436, total_rewards: 2096.4072, mean_steps: 15.1400, mean_ecr: 0.0398 mean_entropies: 2.0559, took: 78.7230s
2022-10-09 01:36:52,408 [INFO] 	Process 3 - batch 8899: mean_policy_losses: -121.677, mean_net_lifetime: 3403.4660, mean_mc_travel_dist: 1186.9954, mean_rewards: 213.2978, total_rewards: 2258.5799, mean_steps: 17.2500, mean_ecr: 0.0396 mean_entropies: 2.0556, took: 88.2447s
2022-10-09 01:36:58,106 [INFO] 	Process 2 - batch 8899: mean_policy_losses: -83.618, mean_net_lifetime: 3297.4393, mean_mc_travel_dist: 1168.9087, mean_rewards: 211.1205, total_rewards: 2170.2143, mean_steps: 16.7300, mean_ecr: 0.0398 mean_entropies: 2.0670, took: 89.9408s
2022-10-09 01:37:06,444 [INFO] 	Process 6 - batch 8799: mean_policy_losses: -153.801, mean_net_lifetime: 3503.3619, mean_mc_travel_dist: 1262.8874, mean_rewards: 213.4433, total_rewards: 2271.7948, mean_steps: 17.7400, mean_ecr: 0.0390 mean_entropies: 2.0328, took: 92.7900s
2022-10-09 01:37:09,493 [INFO] 	Process 5 - batch 8499: mean_policy_losses: -178.554, mean_net_lifetime: 3330.5692, mean_mc_travel_dist: 1176.5186, mean_rewards: 222.1523, total_rewards: 2197.3996, mean_steps: 15.9500, mean_ecr: 0.0400 mean_entropies: 2.0349, took: 81.6066s
2022-10-09 01:37:29,328 [INFO] 	Process 4 - batch 8899: mean_policy_losses: -90.825, mean_net_lifetime: 3329.1255, mean_mc_travel_dist: 1155.5660, mean_rewards: 217.7606, total_rewards: 2210.8076, mean_steps: 16.2000, mean_ecr: 0.0400 mean_entropies: 2.0673, took: 84.6530s
2022-10-09 01:38:04,253 [INFO] 	Process 0 - batch 8499: mean_policy_losses: -195.000, mean_net_lifetime: 3310.1184, mean_mc_travel_dist: 1167.8329, mean_rewards: 217.4939, total_rewards: 2185.0809, mean_steps: 15.8600, mean_ecr: 0.0400 mean_entropies: 2.0295, took: 85.4592s
2022-10-09 01:38:06,693 [INFO] 	Process 1 - batch 8999: mean_policy_losses: -97.167, mean_net_lifetime: 3339.7171, mean_mc_travel_dist: 1208.1597, mean_rewards: 218.6119, total_rewards: 2166.0288, mean_steps: 16.5700, mean_ecr: 0.0413 mean_entropies: 2.0372, took: 85.2261s
2022-10-09 01:38:14,267 [INFO] 	Process 3 - batch 8999: mean_policy_losses: -129.685, mean_net_lifetime: 3155.7597, mean_mc_travel_dist: 1129.4143, mean_rewards: 218.3596, total_rewards: 2062.0837, mean_steps: 15.7100, mean_ecr: 0.0415 mean_entropies: 2.0385, took: 81.8599s
2022-10-09 01:38:27,235 [INFO] 	Process 2 - batch 8999: mean_policy_losses: -69.330, mean_net_lifetime: 3424.6968, mean_mc_travel_dist: 1245.7679, mean_rewards: 204.9590, total_rewards: 2215.7341, mean_steps: 17.3700, mean_ecr: 0.0411 mean_entropies: 2.0623, took: 89.1285s
2022-10-09 01:38:34,835 [INFO] 	Process 5 - batch 8599: mean_policy_losses: -109.769, mean_net_lifetime: 3375.6845, mean_mc_travel_dist: 1209.3101, mean_rewards: 220.8641, total_rewards: 2200.8612, mean_steps: 16.6500, mean_ecr: 0.0411 mean_entropies: 1.9986, took: 85.3414s
2022-10-09 01:38:36,585 [INFO] 	Process 6 - batch 8899: mean_policy_losses: -39.569, mean_net_lifetime: 3502.2562, mean_mc_travel_dist: 1229.9586, mean_rewards: 210.2361, total_rewards: 2315.9252, mean_steps: 17.8100, mean_ecr: 0.0403 mean_entropies: 2.0920, took: 90.1406s
2022-10-09 01:38:51,483 [INFO] 	Process 4 - batch 8999: mean_policy_losses: -106.457, mean_net_lifetime: 3266.6787, mean_mc_travel_dist: 1174.4054, mean_rewards: 216.7072, total_rewards: 2131.0020, mean_steps: 15.9000, mean_ecr: 0.0414 mean_entropies: 2.0526, took: 82.1549s
2022-10-09 01:39:19,424 [INFO] 	Process 0 - batch 8599: mean_policy_losses: -150.458, mean_net_lifetime: 3315.7836, mean_mc_travel_dist: 1185.2274, mean_rewards: 222.1800, total_rewards: 2169.3025, mean_steps: 16.2000, mean_ecr: 0.0414 mean_entropies: 2.0067, took: 75.1714s
2022-10-09 01:39:57,950 [INFO] 	Process 6 - batch 8999: mean_policy_losses: -114.020, mean_net_lifetime: 3335.6913, mean_mc_travel_dist: 1215.3390, mean_rewards: 212.8275, total_rewards: 2158.2522, mean_steps: 16.9300, mean_ecr: 0.0412 mean_entropies: 2.0477, took: 81.3652s
2022-10-09 01:40:01,163 [INFO] 	Process 5 - batch 8699: mean_policy_losses: -107.903, mean_net_lifetime: 3403.7931, mean_mc_travel_dist: 1218.1473, mean_rewards: 214.3325, total_rewards: 2210.7687, mean_steps: 18.3700, mean_ecr: 0.0404 mean_entropies: 2.0060, took: 86.3290s
2022-10-09 01:40:45,809 [INFO] 	Process 0 - batch 8699: mean_policy_losses: -50.682, mean_net_lifetime: 3549.5687, mean_mc_travel_dist: 1274.0872, mean_rewards: 207.3262, total_rewards: 2310.3731, mean_steps: 19.4700, mean_ecr: 0.0402 mean_entropies: 2.0075, took: 86.3841s
2022-10-09 01:41:18,362 [INFO] 	Process 5 - batch 8799: mean_policy_losses: -196.299, mean_net_lifetime: 3418.6766, mean_mc_travel_dist: 1232.7731, mean_rewards: 215.5178, total_rewards: 2222.5663, mean_steps: 17.2600, mean_ecr: 0.0393 mean_entropies: 2.0234, took: 77.1992s
2022-10-09 01:42:04,614 [INFO] 	Process 0 - batch 8799: mean_policy_losses: -132.659, mean_net_lifetime: 3520.8721, mean_mc_travel_dist: 1271.0707, mean_rewards: 215.7154, total_rewards: 2290.5214, mean_steps: 17.7000, mean_ecr: 0.0396 mean_entropies: 2.0250, took: 78.8059s
2022-10-09 01:42:25,793 [INFO] 	Process 5 - batch 8899: mean_policy_losses: -118.556, mean_net_lifetime: 3148.0365, mean_mc_travel_dist: 1086.1024, mean_rewards: 222.3434, total_rewards: 2092.2905, mean_steps: 15.0800, mean_ecr: 0.0406 mean_entropies: 2.0369, took: 67.4303s
2022-10-09 01:43:13,268 [INFO] 	Process 0 - batch 8899: mean_policy_losses: -158.956, mean_net_lifetime: 3149.2458, mean_mc_travel_dist: 1092.7267, mean_rewards: 209.2229, total_rewards: 2089.5424, mean_steps: 15.6400, mean_ecr: 0.0398 mean_entropies: 2.0188, took: 68.6531s
2022-10-09 01:43:40,453 [INFO] 	Process 5 - batch 8999: mean_policy_losses: -111.902, mean_net_lifetime: 3263.5455, mean_mc_travel_dist: 1180.5953, mean_rewards: 212.3426, total_rewards: 2116.4469, mean_steps: 16.5800, mean_ecr: 0.0411 mean_entropies: 2.0095, took: 74.6601s
2022-10-09 01:44:23,214 [INFO] 	Process 0 - batch 8999: mean_policy_losses: -77.599, mean_net_lifetime: 3213.3135, mean_mc_travel_dist: 1172.5539, mean_rewards: 209.4615, total_rewards: 2085.1284, mean_steps: 16.2600, mean_ecr: 0.0415 mean_entropies: 2.0121, took: 69.9471s
2022-10-09 01:51:28,998 [INFO] 	Process 1 - batch 9099: mean_policy_losses: -142.214, mean_net_lifetime: 3515.8860, mean_mc_travel_dist: 1233.5708, mean_rewards: 209.2730, total_rewards: 2325.0704, mean_steps: 17.9600, mean_ecr: 0.0410 mean_entropies: 2.0548, took: 802.3054s
2022-10-09 01:51:30,889 [INFO] 	Process 2 - batch 9099: mean_policy_losses: -171.493, mean_net_lifetime: 3568.8798, mean_mc_travel_dist: 1233.5684, mean_rewards: 205.9030, total_rewards: 2380.5690, mean_steps: 18.1700, mean_ecr: 0.0409 mean_entropies: 2.0587, took: 783.6543s
2022-10-09 01:51:31,835 [INFO] 	Process 4 - batch 9099: mean_policy_losses: -161.140, mean_net_lifetime: 3486.1737, mean_mc_travel_dist: 1196.1439, mean_rewards: 213.6335, total_rewards: 2340.6663, mean_steps: 17.0900, mean_ecr: 0.0408 mean_entropies: 2.0718, took: 760.3520s
2022-10-09 01:51:50,606 [INFO] 	Process 3 - batch 9099: mean_policy_losses: -97.460, mean_net_lifetime: 3731.9436, mean_mc_travel_dist: 1328.6303, mean_rewards: 212.0421, total_rewards: 2441.4000, mean_steps: 19.2500, mean_ecr: 0.0406 mean_entropies: 2.0802, took: 816.3387s
2022-10-09 01:52:47,994 [INFO] 	Process 6 - batch 9099: mean_policy_losses: -207.496, mean_net_lifetime: 3483.5988, mean_mc_travel_dist: 1216.5169, mean_rewards: 206.9443, total_rewards: 2301.8725, mean_steps: 18.0900, mean_ecr: 0.0410 mean_entropies: 2.0687, took: 770.0440s
2022-10-09 01:52:48,753 [INFO] 	Process 1 - batch 9199: mean_policy_losses: -103.741, mean_net_lifetime: 3415.6829, mean_mc_travel_dist: 1215.1895, mean_rewards: 209.3775, total_rewards: 2239.7330, mean_steps: 16.7100, mean_ecr: 0.0406 mean_entropies: 2.0284, took: 79.7543s
2022-10-09 01:52:52,256 [INFO] 	Process 2 - batch 9199: mean_policy_losses: -132.808, mean_net_lifetime: 3348.4637, mean_mc_travel_dist: 1198.0511, mean_rewards: 209.4443, total_rewards: 2185.5659, mean_steps: 16.5500, mean_ecr: 0.0406 mean_entropies: 2.0337, took: 81.3665s
2022-10-09 01:52:58,724 [INFO] 	Process 4 - batch 9199: mean_policy_losses: -34.943, mean_net_lifetime: 3527.0393, mean_mc_travel_dist: 1268.0973, mean_rewards: 207.0607, total_rewards: 2303.3198, mean_steps: 17.3900, mean_ecr: 0.0405 mean_entropies: 2.0228, took: 86.8888s
2022-10-09 01:53:19,215 [INFO] 	Process 3 - batch 9199: mean_policy_losses: -204.795, mean_net_lifetime: 3682.5260, mean_mc_travel_dist: 1379.5806, mean_rewards: 212.8451, total_rewards: 2344.7558, mean_steps: 18.0600, mean_ecr: 0.0402 mean_entropies: 2.0350, took: 88.6091s
2022-10-09 01:54:14,054 [INFO] 	Process 6 - batch 9199: mean_policy_losses: -52.627, mean_net_lifetime: 3521.6759, mean_mc_travel_dist: 1288.2522, mean_rewards: 209.1127, total_rewards: 2286.5544, mean_steps: 17.3800, mean_ecr: 0.0403 mean_entropies: 2.0149, took: 86.0599s
2022-10-09 01:54:16,865 [INFO] 	Process 1 - batch 9299: mean_policy_losses: -75.402, mean_net_lifetime: 3619.1915, mean_mc_travel_dist: 1319.7419, mean_rewards: 205.7469, total_rewards: 2338.5046, mean_steps: 18.5300, mean_ecr: 0.0384 mean_entropies: 2.0593, took: 88.1130s
2022-10-09 01:54:21,201 [INFO] 	Process 2 - batch 9299: mean_policy_losses: -122.952, mean_net_lifetime: 3582.2311, mean_mc_travel_dist: 1306.1223, mean_rewards: 208.5750, total_rewards: 2309.0528, mean_steps: 18.2300, mean_ecr: 0.0387 mean_entropies: 2.0403, took: 88.9449s
2022-10-09 01:54:27,051 [INFO] 	Process 4 - batch 9299: mean_policy_losses: -83.690, mean_net_lifetime: 3630.4337, mean_mc_travel_dist: 1331.4169, mean_rewards: 200.0188, total_rewards: 2335.8643, mean_steps: 18.5700, mean_ecr: 0.0387 mean_entropies: 2.0425, took: 88.3273s
2022-10-09 01:54:50,450 [INFO] 	Process 3 - batch 9299: mean_policy_losses: -67.236, mean_net_lifetime: 3673.9804, mean_mc_travel_dist: 1337.4288, mean_rewards: 202.0951, total_rewards: 2371.1741, mean_steps: 18.9600, mean_ecr: 0.0386 mean_entropies: 2.0365, took: 91.2349s
2022-10-09 01:55:46,870 [INFO] 	Process 6 - batch 9299: mean_policy_losses: -14.128, mean_net_lifetime: 3760.5794, mean_mc_travel_dist: 1374.6396, mean_rewards: 200.4085, total_rewards: 2424.6536, mean_steps: 19.6900, mean_ecr: 0.0388 mean_entropies: 2.0337, took: 92.8153s
2022-10-09 01:56:10,303 [INFO] 	Process 4 - batch 9399: mean_policy_losses: -65.677, mean_net_lifetime: 4040.6169, mean_mc_travel_dist: 1538.7126, mean_rewards: 205.9770, total_rewards: 2543.1791, mean_steps: 21.9500, mean_ecr: 0.0380 mean_entropies: 2.0018, took: 103.2513s
2022-10-09 01:56:35,297 [INFO] 	Process 1 - batch 9399: mean_policy_losses: -25.069, mean_net_lifetime: 5018.0416, mean_mc_travel_dist: 2132.6865, mean_rewards: 203.7820, total_rewards: 2918.0029, mean_steps: 30.0600, mean_ecr: 0.0383 mean_entropies: 2.0078, took: 138.4312s
2022-10-09 01:56:52,789 [INFO] 	Process 2 - batch 9399: mean_policy_losses: -112.291, mean_net_lifetime: 5126.9224, mean_mc_travel_dist: 2250.6567, mean_rewards: 205.9196, total_rewards: 2910.7149, mean_steps: 30.9300, mean_ecr: 0.0380 mean_entropies: 1.9950, took: 151.5884s
2022-10-09 01:57:16,619 [INFO] 	Process 3 - batch 9399: mean_policy_losses: -147.587, mean_net_lifetime: 5152.1838, mean_mc_travel_dist: 2219.7450, mean_rewards: 209.7131, total_rewards: 2972.2233, mean_steps: 30.7600, mean_ecr: 0.0384 mean_entropies: 2.0086, took: 146.1689s
2022-10-09 01:57:39,242 [INFO] 	Process 4 - batch 9499: mean_policy_losses: -123.360, mean_net_lifetime: 3569.0864, mean_mc_travel_dist: 1279.4440, mean_rewards: 213.5854, total_rewards: 2329.7146, mean_steps: 17.5800, mean_ecr: 0.0397 mean_entropies: 2.0640, took: 88.9397s
2022-10-09 01:57:57,668 [INFO] 	Process 1 - batch 9499: mean_policy_losses: -137.703, mean_net_lifetime: 3368.1734, mean_mc_travel_dist: 1208.9472, mean_rewards: 218.2924, total_rewards: 2206.2814, mean_steps: 16.0600, mean_ecr: 0.0396 mean_entropies: 2.0560, took: 82.3711s
2022-10-09 01:58:02,755 [INFO] 	Process 0 - batch 9099: mean_policy_losses: -126.371, mean_net_lifetime: 3402.5215, mean_mc_travel_dist: 1207.7452, mean_rewards: 208.2558, total_rewards: 2241.9917, mean_steps: 17.3000, mean_ecr: 0.0409 mean_entropies: 2.0336, took: 819.5404s
2022-10-09 01:58:05,321 [INFO] 	Process 5 - batch 9099: mean_policy_losses: -79.584, mean_net_lifetime: 3452.3964, mean_mc_travel_dist: 1210.0996, mean_rewards: 209.9281, total_rewards: 2280.7841, mean_steps: 17.2100, mean_ecr: 0.0409 mean_entropies: 2.0459, took: 864.8675s
2022-10-09 01:58:19,172 [INFO] 	Process 2 - batch 9499: mean_policy_losses: -174.973, mean_net_lifetime: 3332.4231, mean_mc_travel_dist: 1166.5529, mean_rewards: 214.8408, total_rewards: 2205.9205, mean_steps: 16.6000, mean_ecr: 0.0396 mean_entropies: 2.0493, took: 86.3837s
2022-10-09 01:58:26,323 [INFO] 	Process 6 - batch 9399: mean_policy_losses: -170.974, mean_net_lifetime: 5272.3594, mean_mc_travel_dist: 2212.4297, mean_rewards: 202.7386, total_rewards: 3111.7644, mean_steps: 33.0200, mean_ecr: 0.0381 mean_entropies: 2.0053, took: 159.4503s
2022-10-09 01:58:49,993 [INFO] 	Process 3 - batch 9499: mean_policy_losses: -140.878, mean_net_lifetime: 3572.6796, mean_mc_travel_dist: 1288.5950, mean_rewards: 221.5849, total_rewards: 2329.6712, mean_steps: 17.9000, mean_ecr: 0.0396 mean_entropies: 2.0030, took: 93.3745s
2022-10-09 01:59:08,134 [INFO] 	Process 4 - batch 9599: mean_policy_losses: -121.061, mean_net_lifetime: 3361.9904, mean_mc_travel_dist: 1161.9769, mean_rewards: 209.8161, total_rewards: 2225.8988, mean_steps: 16.8300, mean_ecr: 0.0403 mean_entropies: 2.0306, took: 88.8915s
2022-10-09 01:59:27,536 [INFO] 	Process 1 - batch 9599: mean_policy_losses: -181.163, mean_net_lifetime: 3448.3474, mean_mc_travel_dist: 1225.5278, mean_rewards: 209.7033, total_rewards: 2264.2250, mean_steps: 17.6000, mean_ecr: 0.0402 mean_entropies: 2.0167, took: 89.8680s
2022-10-09 01:59:33,033 [INFO] 	Process 5 - batch 9199: mean_policy_losses: -87.062, mean_net_lifetime: 3461.0166, mean_mc_travel_dist: 1221.1865, mean_rewards: 211.3832, total_rewards: 2273.3468, mean_steps: 16.6500, mean_ecr: 0.0403 mean_entropies: 1.9877, took: 87.7131s
2022-10-09 01:59:39,212 [INFO] 	Process 0 - batch 9199: mean_policy_losses: 30.034, mean_net_lifetime: 3779.7693, mean_mc_travel_dist: 1334.0182, mean_rewards: 206.5352, total_rewards: 2477.9980, mean_steps: 18.8500, mean_ecr: 0.0406 mean_entropies: 2.0066, took: 96.4573s
2022-10-09 01:59:48,726 [INFO] 	Process 2 - batch 9599: mean_policy_losses: -151.492, mean_net_lifetime: 3447.4641, mean_mc_travel_dist: 1212.2913, mean_rewards: 213.7423, total_rewards: 2269.3209, mean_steps: 17.1200, mean_ecr: 0.0401 mean_entropies: 2.0308, took: 89.5539s
2022-10-09 01:59:54,163 [INFO] 	Process 6 - batch 9499: mean_policy_losses: -251.645, mean_net_lifetime: 3444.4895, mean_mc_travel_dist: 1231.4516, mean_rewards: 215.2892, total_rewards: 2258.2077, mean_steps: 16.9400, mean_ecr: 0.0399 mean_entropies: 2.0149, took: 87.8435s
2022-10-09 02:00:16,628 [INFO] 	Process 3 - batch 9599: mean_policy_losses: -141.410, mean_net_lifetime: 3374.1969, mean_mc_travel_dist: 1203.7240, mean_rewards: 210.9078, total_rewards: 2204.8542, mean_steps: 16.7000, mean_ecr: 0.0406 mean_entropies: 2.0179, took: 86.6354s
2022-10-09 02:00:34,119 [INFO] 	Process 4 - batch 9699: mean_policy_losses: -198.130, mean_net_lifetime: 3284.9316, mean_mc_travel_dist: 1165.6518, mean_rewards: 224.0279, total_rewards: 2151.9680, mean_steps: 16.2200, mean_ecr: 0.0400 mean_entropies: 1.9998, took: 85.9859s
2022-10-09 02:00:54,990 [INFO] 	Process 1 - batch 9699: mean_policy_losses: -73.846, mean_net_lifetime: 3395.6287, mean_mc_travel_dist: 1221.8162, mean_rewards: 215.4941, total_rewards: 2216.0920, mean_steps: 17.1300, mean_ecr: 0.0404 mean_entropies: 2.0039, took: 87.4544s
2022-10-09 02:01:10,521 [INFO] 	Process 2 - batch 9699: mean_policy_losses: -180.810, mean_net_lifetime: 3146.6527, mean_mc_travel_dist: 1132.0086, mean_rewards: 223.9478, total_rewards: 2051.8290, mean_steps: 15.7500, mean_ecr: 0.0407 mean_entropies: 1.9734, took: 81.7940s
2022-10-09 02:01:15,883 [INFO] 	Process 0 - batch 9299: mean_policy_losses: -34.876, mean_net_lifetime: 3699.7093, mean_mc_travel_dist: 1345.3791, mean_rewards: 207.4566, total_rewards: 2402.0529, mean_steps: 18.8700, mean_ecr: 0.0384 mean_entropies: 2.0429, took: 96.6711s
2022-10-09 02:01:17,692 [INFO] 	Process 5 - batch 9299: mean_policy_losses: -58.422, mean_net_lifetime: 3928.3123, mean_mc_travel_dist: 1408.0758, mean_rewards: 207.8463, total_rewards: 2554.5100, mean_steps: 20.1600, mean_ecr: 0.0387 mean_entropies: 2.0429, took: 104.6593s
2022-10-09 02:01:27,948 [INFO] 	Process 6 - batch 9599: mean_policy_losses: 80.948, mean_net_lifetime: 3625.9232, mean_mc_travel_dist: 1281.9555, mean_rewards: 202.8115, total_rewards: 2389.2629, mean_steps: 18.4300, mean_ecr: 0.0402 mean_entropies: 2.0082, took: 93.7850s
2022-10-09 02:01:42,124 [INFO] 	Process 3 - batch 9699: mean_policy_losses: -100.459, mean_net_lifetime: 3288.7805, mean_mc_travel_dist: 1170.5443, mean_rewards: 223.1192, total_rewards: 2158.1003, mean_steps: 16.0000, mean_ecr: 0.0401 mean_entropies: 2.0098, took: 85.4948s
2022-10-09 02:02:03,969 [INFO] 	Process 4 - batch 9799: mean_policy_losses: -127.038, mean_net_lifetime: 3295.1229, mean_mc_travel_dist: 1157.0560, mean_rewards: 206.6330, total_rewards: 2181.6810, mean_steps: 17.1500, mean_ecr: 0.0408 mean_entropies: 1.9537, took: 89.8494s
2022-10-09 02:02:25,207 [INFO] 	Process 1 - batch 9799: mean_policy_losses: -95.523, mean_net_lifetime: 3391.6877, mean_mc_travel_dist: 1212.0842, mean_rewards: 205.7686, total_rewards: 2222.8691, mean_steps: 17.8900, mean_ecr: 0.0408 mean_entropies: 1.9524, took: 90.2156s
2022-10-09 02:02:38,498 [INFO] 	Process 2 - batch 9799: mean_policy_losses: -176.391, mean_net_lifetime: 3250.3766, mean_mc_travel_dist: 1135.7975, mean_rewards: 210.5273, total_rewards: 2145.4943, mean_steps: 16.9700, mean_ecr: 0.0407 mean_entropies: 1.9468, took: 87.9774s
2022-10-09 02:02:53,137 [INFO] 	Process 6 - batch 9699: mean_policy_losses: -140.799, mean_net_lifetime: 3243.9642, mean_mc_travel_dist: 1193.2402, mean_rewards: 221.2083, total_rewards: 2091.7460, mean_steps: 16.2800, mean_ecr: 0.0401 mean_entropies: 2.0044, took: 85.1885s
2022-10-09 02:03:04,813 [INFO] 	Process 3 - batch 9799: mean_policy_losses: -144.396, mean_net_lifetime: 3224.3794, mean_mc_travel_dist: 1149.6668, mean_rewards: 206.0367, total_rewards: 2114.7257, mean_steps: 16.2500, mean_ecr: 0.0411 mean_entropies: 1.9778, took: 82.6887s
2022-10-09 02:03:21,982 [INFO] 	Process 4 - batch 9899: mean_policy_losses: -13.200, mean_net_lifetime: 3177.2976, mean_mc_travel_dist: 1103.4823, mean_rewards: 226.6873, total_rewards: 2104.7175, mean_steps: 14.3700, mean_ecr: 0.0416 mean_entropies: 1.9833, took: 78.0133s
2022-10-09 02:03:37,769 [INFO] 	Process 1 - batch 9899: mean_policy_losses: -131.825, mean_net_lifetime: 3039.0396, mean_mc_travel_dist: 1099.5021, mean_rewards: 229.0668, total_rewards: 1990.9495, mean_steps: 13.8500, mean_ecr: 0.0418 mean_entropies: 1.9776, took: 72.5631s
2022-10-09 02:03:48,772 [INFO] 	Process 0 - batch 9399: mean_policy_losses: -83.584, mean_net_lifetime: 5062.1113, mean_mc_travel_dist: 2206.5789, mean_rewards: 210.9768, total_rewards: 2893.2716, mean_steps: 30.3900, mean_ecr: 0.0384 mean_entropies: 1.9689, took: 152.8879s
2022-10-09 02:03:50,561 [INFO] 	Process 2 - batch 9899: mean_policy_losses: 4.916, mean_net_lifetime: 3157.2382, mean_mc_travel_dist: 1125.9610, mean_rewards: 226.1620, total_rewards: 2074.7836, mean_steps: 13.8300, mean_ecr: 0.0417 mean_entropies: 1.9538, took: 72.0634s
2022-10-09 02:03:51,376 [INFO] 	Process 5 - batch 9399: mean_policy_losses: -52.920, mean_net_lifetime: 5102.6136, mean_mc_travel_dist: 2193.4739, mean_rewards: 206.6952, total_rewards: 2959.6610, mean_steps: 30.4900, mean_ecr: 0.0380 mean_entropies: 1.9777, took: 153.6832s
2022-10-09 02:04:19,079 [INFO] 	Process 6 - batch 9799: mean_policy_losses: -134.436, mean_net_lifetime: 3168.1866, mean_mc_travel_dist: 1115.4450, mean_rewards: 212.0816, total_rewards: 2088.7928, mean_steps: 15.9400, mean_ecr: 0.0412 mean_entropies: 1.9378, took: 85.9431s
2022-10-09 02:04:31,822 [INFO] 	Process 3 - batch 9899: mean_policy_losses: -137.935, mean_net_lifetime: 3333.0553, mean_mc_travel_dist: 1268.6178, mean_rewards: 231.3634, total_rewards: 2108.1709, mean_steps: 16.5800, mean_ecr: 0.0418 mean_entropies: 1.9409, took: 87.0096s
2022-10-09 02:05:00,853 [INFO] 	Process 4 - batch 9999: mean_policy_losses: -19.665, mean_net_lifetime: 3823.3570, mean_mc_travel_dist: 1400.3499, mean_rewards: 217.2425, total_rewards: 2472.2887, mean_steps: 18.8500, mean_ecr: 0.0377 mean_entropies: 2.0379, took: 98.8705s
2022-10-09 02:05:19,133 [INFO] 	Process 1 - batch 9999: mean_policy_losses: 49.394, mean_net_lifetime: 4146.4454, mean_mc_travel_dist: 1536.6483, mean_rewards: 217.2031, total_rewards: 2651.0949, mean_steps: 20.2500, mean_ecr: 0.0375 mean_entropies: 2.0641, took: 101.3639s
2022-10-09 02:05:25,477 [INFO] 	Process 0 - batch 9499: mean_policy_losses: -137.828, mean_net_lifetime: 3706.6232, mean_mc_travel_dist: 1375.1684, mean_rewards: 223.2570, total_rewards: 2384.7042, mean_steps: 18.1800, mean_ecr: 0.0395 mean_entropies: 1.9922, took: 96.7057s
2022-10-09 02:05:34,413 [INFO] 	Process 2 - batch 9999: mean_policy_losses: -71.195, mean_net_lifetime: 4059.4236, mean_mc_travel_dist: 1491.8193, mean_rewards: 213.7152, total_rewards: 2618.7059, mean_steps: 20.3700, mean_ecr: 0.0375 mean_entropies: 2.0582, took: 103.8520s
2022-10-09 02:05:35,567 [INFO] 	Process 5 - batch 9499: mean_policy_losses: -142.091, mean_net_lifetime: 3925.8712, mean_mc_travel_dist: 1441.9018, mean_rewards: 222.1635, total_rewards: 2519.2232, mean_steps: 20.6300, mean_ecr: 0.0395 mean_entropies: 1.9750, took: 104.1908s
2022-10-09 02:05:36,674 [INFO] 	Process 6 - batch 9899: mean_policy_losses: -106.943, mean_net_lifetime: 3126.9600, mean_mc_travel_dist: 1117.3552, mean_rewards: 223.9322, total_rewards: 2048.2810, mean_steps: 14.2300, mean_ecr: 0.0417 mean_entropies: 1.9562, took: 77.5941s
2022-10-09 02:06:22,634 [INFO] 	Process 3 - batch 9999: mean_policy_losses: -42.323, mean_net_lifetime: 4213.9241, mean_mc_travel_dist: 1562.2642, mean_rewards: 211.4004, total_rewards: 2692.2557, mean_steps: 21.8300, mean_ecr: 0.0380 mean_entropies: 2.0814, took: 110.8128s
2022-10-09 02:06:39,198 [INFO] 	Process 4 - batch 10099: mean_policy_losses: -121.630, mean_net_lifetime: 3822.1505, mean_mc_travel_dist: 1407.3976, mean_rewards: 211.7829, total_rewards: 2451.4618, mean_steps: 19.2800, mean_ecr: 0.0381 mean_entropies: 2.0293, took: 98.3453s
2022-10-09 02:06:48,911 [INFO] 	Process 1 - batch 10099: mean_policy_losses: -194.202, mean_net_lifetime: 3577.6311, mean_mc_travel_dist: 1305.4884, mean_rewards: 209.1104, total_rewards: 2316.3697, mean_steps: 17.7000, mean_ecr: 0.0383 mean_entropies: 2.0332, took: 89.7782s
2022-10-09 02:06:56,240 [INFO] 	Process 0 - batch 9599: mean_policy_losses: -79.834, mean_net_lifetime: 3521.3630, mean_mc_travel_dist: 1268.3304, mean_rewards: 213.6470, total_rewards: 2297.5901, mean_steps: 16.9700, mean_ecr: 0.0398 mean_entropies: 2.0239, took: 90.7631s
2022-10-09 02:07:01,617 [INFO] 	Process 5 - batch 9599: mean_policy_losses: -65.414, mean_net_lifetime: 3433.5532, mean_mc_travel_dist: 1236.3813, mean_rewards: 213.6769, total_rewards: 2235.5876, mean_steps: 16.3800, mean_ecr: 0.0404 mean_entropies: 2.0226, took: 86.0503s
2022-10-09 02:07:15,416 [INFO] 	Process 6 - batch 9999: mean_policy_losses: -53.663, mean_net_lifetime: 3872.0434, mean_mc_travel_dist: 1400.6585, mean_rewards: 209.6486, total_rewards: 2514.0887, mean_steps: 19.3200, mean_ecr: 0.0375 mean_entropies: 2.0771, took: 98.7428s
2022-10-09 02:07:15,609 [INFO] 	Process 2 - batch 10099: mean_policy_losses: -82.135, mean_net_lifetime: 3939.7682, mean_mc_travel_dist: 1445.2157, mean_rewards: 214.4136, total_rewards: 2531.4241, mean_steps: 19.3300, mean_ecr: 0.0383 mean_entropies: 2.0166, took: 101.1965s
2022-10-09 02:08:03,367 [INFO] 	Process 3 - batch 10099: mean_policy_losses: 75.648, mean_net_lifetime: 4049.6514, mean_mc_travel_dist: 1458.8295, mean_rewards: 211.0346, total_rewards: 2637.2696, mean_steps: 20.0300, mean_ecr: 0.0381 mean_entropies: 2.0450, took: 100.7323s
2022-10-09 02:08:09,984 [INFO] 	Process 4 - batch 10199: mean_policy_losses: -100.333, mean_net_lifetime: 3639.5557, mean_mc_travel_dist: 1277.2042, mean_rewards: 218.9122, total_rewards: 2405.1109, mean_steps: 17.2100, mean_ecr: 0.0393 mean_entropies: 2.0463, took: 90.7864s
2022-10-09 02:08:14,854 [INFO] 	Process 1 - batch 10199: mean_policy_losses: -112.648, mean_net_lifetime: 3591.8219, mean_mc_travel_dist: 1260.8183, mean_rewards: 221.6676, total_rewards: 2368.7452, mean_steps: 16.8100, mean_ecr: 0.0400 mean_entropies: 2.0363, took: 85.9427s
2022-10-09 02:08:16,920 [INFO] 	Process 5 - batch 9699: mean_policy_losses: -343.702, mean_net_lifetime: 3018.4906, mean_mc_travel_dist: 1106.2937, mean_rewards: 230.0795, total_rewards: 1957.0872, mean_steps: 14.0400, mean_ecr: 0.0400 mean_entropies: 2.0055, took: 75.3032s
2022-10-09 02:08:17,992 [INFO] 	Process 0 - batch 9699: mean_policy_losses: -235.663, mean_net_lifetime: 3202.1591, mean_mc_travel_dist: 1163.4331, mean_rewards: 223.6200, total_rewards: 2080.0295, mean_steps: 15.2600, mean_ecr: 0.0404 mean_entropies: 2.0054, took: 81.7520s
2022-10-09 02:08:44,297 [INFO] 	Process 2 - batch 10199: mean_policy_losses: -187.522, mean_net_lifetime: 3404.4067, mean_mc_travel_dist: 1183.2170, mean_rewards: 216.8897, total_rewards: 2267.6334, mean_steps: 16.4400, mean_ecr: 0.0400 mean_entropies: 2.0294, took: 88.6870s
2022-10-09 02:08:54,451 [INFO] 	Process 6 - batch 10099: mean_policy_losses: -98.999, mean_net_lifetime: 3811.6238, mean_mc_travel_dist: 1403.0380, mean_rewards: 206.7429, total_rewards: 2450.2106, mean_steps: 19.2200, mean_ecr: 0.0386 mean_entropies: 2.0358, took: 99.0339s
2022-10-09 02:09:36,372 [INFO] 	Process 3 - batch 10199: mean_policy_losses: -154.573, mean_net_lifetime: 3685.5860, mean_mc_travel_dist: 1316.9836, mean_rewards: 205.8771, total_rewards: 2423.2416, mean_steps: 18.3700, mean_ecr: 0.0395 mean_entropies: 1.9840, took: 93.0050s
2022-10-09 02:09:40,463 [INFO] 	Process 5 - batch 9799: mean_policy_losses: -125.203, mean_net_lifetime: 3278.0675, mean_mc_travel_dist: 1133.9142, mean_rewards: 217.5236, total_rewards: 2175.5326, mean_steps: 15.9100, mean_ecr: 0.0408 mean_entropies: 1.9499, took: 83.5435s
2022-10-09 02:09:42,911 [INFO] 	Process 4 - batch 10299: mean_policy_losses: -71.381, mean_net_lifetime: 3748.8982, mean_mc_travel_dist: 1342.0491, mean_rewards: 216.8474, total_rewards: 2445.6862, mean_steps: 18.1600, mean_ecr: 0.0392 mean_entropies: 2.0327, took: 92.9265s
2022-10-09 02:09:44,123 [INFO] 	Process 1 - batch 10299: mean_policy_losses: -78.393, mean_net_lifetime: 3647.6955, mean_mc_travel_dist: 1296.7287, mean_rewards: 217.4587, total_rewards: 2386.0262, mean_steps: 17.5100, mean_ecr: 0.0395 mean_entropies: 2.0300, took: 89.2692s
2022-10-09 02:09:45,947 [INFO] 	Process 0 - batch 9799: mean_policy_losses: -148.151, mean_net_lifetime: 3297.4205, mean_mc_travel_dist: 1139.4079, mean_rewards: 212.5540, total_rewards: 2195.4718, mean_steps: 16.4200, mean_ecr: 0.0408 mean_entropies: 1.9242, took: 87.9533s
2022-10-09 02:10:15,826 [INFO] 	Process 2 - batch 10299: mean_policy_losses: -71.836, mean_net_lifetime: 3732.5913, mean_mc_travel_dist: 1327.4581, mean_rewards: 217.9482, total_rewards: 2453.4855, mean_steps: 17.7600, mean_ecr: 0.0391 mean_entropies: 2.0335, took: 91.5292s
2022-10-09 02:10:19,742 [INFO] 	Process 6 - batch 10199: mean_policy_losses: -195.124, mean_net_lifetime: 3404.9300, mean_mc_travel_dist: 1167.0364, mean_rewards: 216.4481, total_rewards: 2277.7613, mean_steps: 16.5700, mean_ecr: 0.0396 mean_entropies: 1.9556, took: 85.2916s
2022-10-09 02:11:05,117 [INFO] 	Process 0 - batch 9899: mean_policy_losses: -171.209, mean_net_lifetime: 3060.5265, mean_mc_travel_dist: 1051.6152, mean_rewards: 224.1882, total_rewards: 2041.8215, mean_steps: 14.2400, mean_ecr: 0.0417 mean_entropies: 1.9197, took: 79.1714s
2022-10-09 02:11:11,804 [INFO] 	Process 5 - batch 9899: mean_policy_losses: -149.562, mean_net_lifetime: 3584.8043, mean_mc_travel_dist: 1287.0970, mean_rewards: 223.6972, total_rewards: 2330.8308, mean_steps: 17.6500, mean_ecr: 0.0415 mean_entropies: 1.9187, took: 91.3404s
2022-10-09 02:11:12,724 [INFO] 	Process 3 - batch 10299: mean_policy_losses: -43.574, mean_net_lifetime: 3790.1238, mean_mc_travel_dist: 1367.8051, mean_rewards: 217.2709, total_rewards: 2470.7266, mean_steps: 18.2800, mean_ecr: 0.0392 mean_entropies: 2.0182, took: 96.3518s
2022-10-09 02:11:19,412 [INFO] 	Process 4 - batch 10399: mean_policy_losses: -128.078, mean_net_lifetime: 3611.5954, mean_mc_travel_dist: 1318.5596, mean_rewards: 211.4944, total_rewards: 2334.2744, mean_steps: 18.6600, mean_ecr: 0.0379 mean_entropies: 1.9099, took: 96.5012s
2022-10-09 02:11:23,555 [INFO] 	Process 1 - batch 10399: mean_policy_losses: -58.001, mean_net_lifetime: 3826.7738, mean_mc_travel_dist: 1374.6179, mean_rewards: 205.0770, total_rewards: 2479.6290, mean_steps: 19.8600, mean_ecr: 0.0377 mean_entropies: 1.9291, took: 99.4311s
2022-10-09 02:11:45,742 [INFO] 	Process 6 - batch 10299: mean_policy_losses: -165.023, mean_net_lifetime: 3470.2589, mean_mc_travel_dist: 1233.9558, mean_rewards: 216.4044, total_rewards: 2284.4898, mean_steps: 16.4000, mean_ecr: 0.0395 mean_entropies: 1.9939, took: 86.0002s
2022-10-09 02:11:54,394 [INFO] 	Process 2 - batch 10399: mean_policy_losses: -91.384, mean_net_lifetime: 3690.0164, mean_mc_travel_dist: 1366.2512, mean_rewards: 212.0659, total_rewards: 2358.0341, mean_steps: 18.8100, mean_ecr: 0.0377 mean_entropies: 1.8995, took: 98.5678s
2022-10-09 02:12:41,017 [INFO] 	Process 0 - batch 9999: mean_policy_losses: -9.266, mean_net_lifetime: 3772.6051, mean_mc_travel_dist: 1315.2047, mean_rewards: 209.2633, total_rewards: 2487.0115, mean_steps: 18.8000, mean_ecr: 0.0380 mean_entropies: 2.0233, took: 95.9002s
2022-10-09 02:12:46,186 [INFO] 	Process 1 - batch 10499: mean_policy_losses: -144.872, mean_net_lifetime: 3294.8563, mean_mc_travel_dist: 1149.4056, mean_rewards: 214.7291, total_rewards: 2192.0035, mean_steps: 16.0400, mean_ecr: 0.0398 mean_entropies: 1.9589, took: 82.6316s
2022-10-09 02:12:47,873 [INFO] 	Process 4 - batch 10499: mean_policy_losses: -66.764, mean_net_lifetime: 3444.3050, mean_mc_travel_dist: 1204.0079, mean_rewards: 209.5188, total_rewards: 2291.3653, mean_steps: 16.8500, mean_ecr: 0.0395 mean_entropies: 1.9516, took: 88.4606s
2022-10-09 02:12:49,609 [INFO] 	Process 5 - batch 9999: mean_policy_losses: -90.874, mean_net_lifetime: 3760.5058, mean_mc_travel_dist: 1336.1330, mean_rewards: 210.7520, total_rewards: 2460.1219, mean_steps: 18.9900, mean_ecr: 0.0377 mean_entropies: 2.0039, took: 97.8057s
2022-10-09 02:12:51,291 [INFO] 	Process 3 - batch 10399: mean_policy_losses: -82.538, mean_net_lifetime: 3684.7451, mean_mc_travel_dist: 1358.6430, mean_rewards: 207.5446, total_rewards: 2361.0071, mean_steps: 19.5800, mean_ecr: 0.0380 mean_entropies: 1.8941, took: 98.5673s
2022-10-09 02:13:17,699 [INFO] 	Process 6 - batch 10399: mean_policy_losses: -91.131, mean_net_lifetime: 3633.3571, mean_mc_travel_dist: 1287.3331, mean_rewards: 212.8175, total_rewards: 2385.9424, mean_steps: 18.2900, mean_ecr: 0.0385 mean_entropies: 1.9151, took: 91.9568s
2022-10-09 02:13:29,251 [INFO] 	Process 2 - batch 10499: mean_policy_losses: -158.547, mean_net_lifetime: 3701.9693, mean_mc_travel_dist: 1330.8304, mean_rewards: 206.3106, total_rewards: 2407.8824, mean_steps: 18.9400, mean_ecr: 0.0392 mean_entropies: 1.9735, took: 94.8563s
2022-10-09 02:14:06,836 [INFO] 	Process 3 - batch 10499: mean_policy_losses: -208.221, mean_net_lifetime: 3201.5439, mean_mc_travel_dist: 1109.2314, mean_rewards: 216.0024, total_rewards: 2133.5234, mean_steps: 15.3300, mean_ecr: 0.0397 mean_entropies: 1.9538, took: 75.5451s
2022-10-09 02:14:15,102 [INFO] 	Process 0 - batch 10099: mean_policy_losses: -110.202, mean_net_lifetime: 3812.2748, mean_mc_travel_dist: 1352.0509, mean_rewards: 205.8750, total_rewards: 2498.5635, mean_steps: 20.0300, mean_ecr: 0.0380 mean_entropies: 1.9714, took: 94.0853s
2022-10-09 02:14:30,951 [INFO] 	Process 5 - batch 10099: mean_policy_losses: -49.679, mean_net_lifetime: 4118.5351, mean_mc_travel_dist: 1512.3596, mean_rewards: 207.3239, total_rewards: 2645.7193, mean_steps: 21.4500, mean_ecr: 0.0383 mean_entropies: 1.9893, took: 101.3412s
2022-10-09 02:14:41,860 [INFO] 	Process 6 - batch 10499: mean_policy_losses: -44.014, mean_net_lifetime: 3620.4358, mean_mc_travel_dist: 1258.3603, mean_rewards: 207.1516, total_rewards: 2401.7237, mean_steps: 18.1200, mean_ecr: 0.0389 mean_entropies: 1.9789, took: 84.1606s
2022-10-09 02:15:32,680 [INFO] 	Process 0 - batch 10199: mean_policy_losses: -140.273, mean_net_lifetime: 3547.4047, mean_mc_travel_dist: 1232.2374, mean_rewards: 206.2066, total_rewards: 2350.3768, mean_steps: 17.6200, mean_ecr: 0.0399 mean_entropies: 2.0052, took: 77.5785s
2022-10-09 02:15:54,017 [INFO] 	Process 5 - batch 10199: mean_policy_losses: -172.860, mean_net_lifetime: 3794.0833, mean_mc_travel_dist: 1306.2033, mean_rewards: 210.6844, total_rewards: 2521.3863, mean_steps: 18.7500, mean_ecr: 0.0394 mean_entropies: 2.0063, took: 83.0656s
2022-10-09 02:16:46,323 [INFO] 	Process 0 - batch 10299: mean_policy_losses: -110.795, mean_net_lifetime: 3624.1624, mean_mc_travel_dist: 1255.6977, mean_rewards: 220.7704, total_rewards: 2412.9941, mean_steps: 16.9900, mean_ecr: 0.0395 mean_entropies: 2.0697, took: 73.6419s
2022-10-09 02:17:09,706 [INFO] 	Process 5 - batch 10299: mean_policy_losses: -220.845, mean_net_lifetime: 3536.2414, mean_mc_travel_dist: 1263.7375, mean_rewards: 224.0355, total_rewards: 2316.7949, mean_steps: 16.3300, mean_ecr: 0.0394 mean_entropies: 2.0556, took: 75.6888s
2022-10-09 02:18:14,682 [INFO] 	Process 0 - batch 10399: mean_policy_losses: -119.669, mean_net_lifetime: 3913.4415, mean_mc_travel_dist: 1434.0987, mean_rewards: 199.0704, total_rewards: 2518.2384, mean_steps: 20.5100, mean_ecr: 0.0379 mean_entropies: 2.0145, took: 88.3590s
2022-10-09 02:18:30,678 [INFO] 	Process 5 - batch 10399: mean_policy_losses: -190.901, mean_net_lifetime: 3593.1171, mean_mc_travel_dist: 1289.0725, mean_rewards: 208.5228, total_rewards: 2341.4935, mean_steps: 18.1400, mean_ecr: 0.0384 mean_entropies: 1.9760, took: 80.9725s
2022-10-09 02:19:31,214 [INFO] 	Process 0 - batch 10499: mean_policy_losses: -122.098, mean_net_lifetime: 3586.0617, mean_mc_travel_dist: 1296.1889, mean_rewards: 218.5805, total_rewards: 2336.0485, mean_steps: 17.3000, mean_ecr: 0.0396 mean_entropies: 2.0241, took: 76.5324s
2022-10-09 02:19:55,876 [INFO] 	Process 5 - batch 10499: mean_policy_losses: -85.615, mean_net_lifetime: 3824.7170, mean_mc_travel_dist: 1400.6679, mean_rewards: 208.4617, total_rewards: 2460.7471, mean_steps: 19.1900, mean_ecr: 0.0389 mean_entropies: 2.0269, took: 85.1979s
2022-10-09 02:25:48,083 [INFO] 	Process 4 - batch 10599: mean_policy_losses: -86.645, mean_net_lifetime: 3827.7101, mean_mc_travel_dist: 1430.2150, mean_rewards: 222.8565, total_rewards: 2445.4032, mean_steps: 19.0100, mean_ecr: 0.0371 mean_entropies: 2.0490, took: 780.2104s
2022-10-09 02:25:53,342 [INFO] 	Process 1 - batch 10599: mean_policy_losses: -52.844, mean_net_lifetime: 3674.7677, mean_mc_travel_dist: 1374.3141, mean_rewards: 221.4610, total_rewards: 2351.0699, mean_steps: 18.2200, mean_ecr: 0.0371 mean_entropies: 2.0236, took: 787.1559s
2022-10-09 02:26:53,385 [INFO] 	Process 2 - batch 10599: mean_policy_losses: -89.280, mean_net_lifetime: 3626.2138, mean_mc_travel_dist: 1364.2232, mean_rewards: 216.3663, total_rewards: 2320.8546, mean_steps: 18.0100, mean_ecr: 0.0372 mean_entropies: 2.0430, took: 804.1338s
2022-10-09 02:27:11,902 [INFO] 	Process 1 - batch 10699: mean_policy_losses: -84.658, mean_net_lifetime: 3462.2575, mean_mc_travel_dist: 1255.1343, mean_rewards: 222.1880, total_rewards: 2242.8606, mean_steps: 16.8900, mean_ecr: 0.0372 mean_entropies: 1.9640, took: 78.5608s
2022-10-09 02:27:13,407 [INFO] 	Process 4 - batch 10699: mean_policy_losses: -24.086, mean_net_lifetime: 3644.9544, mean_mc_travel_dist: 1325.9360, mean_rewards: 223.2457, total_rewards: 2362.7204, mean_steps: 18.0200, mean_ecr: 0.0374 mean_entropies: 1.9547, took: 85.3232s
2022-10-09 02:27:31,283 [INFO] 	Process 3 - batch 10599: mean_policy_losses: -85.986, mean_net_lifetime: 3799.5219, mean_mc_travel_dist: 1384.4828, mean_rewards: 223.5193, total_rewards: 2459.8781, mean_steps: 18.8700, mean_ecr: 0.0373 mean_entropies: 2.0430, took: 804.4466s
2022-10-09 02:28:16,663 [INFO] 	Process 2 - batch 10699: mean_policy_losses: -104.386, mean_net_lifetime: 3546.7527, mean_mc_travel_dist: 1249.0762, mean_rewards: 219.8665, total_rewards: 2356.0549, mean_steps: 17.1100, mean_ecr: 0.0373 mean_entropies: 1.9848, took: 83.2794s
2022-10-09 02:28:22,588 [INFO] 	Process 6 - batch 10599: mean_policy_losses: -146.879, mean_net_lifetime: 3891.1789, mean_mc_travel_dist: 1421.5517, mean_rewards: 219.6818, total_rewards: 2506.9461, mean_steps: 19.1300, mean_ecr: 0.0369 mean_entropies: 2.0365, took: 820.7284s
2022-10-09 02:28:39,490 [INFO] 	Process 1 - batch 10799: mean_policy_losses: 25.472, mean_net_lifetime: 3868.3973, mean_mc_travel_dist: 1355.7208, mean_rewards: 218.1805, total_rewards: 2543.9447, mean_steps: 18.4100, mean_ecr: 0.0400 mean_entropies: 2.0559, took: 87.5879s
2022-10-09 02:28:39,628 [INFO] 	Process 4 - batch 10799: mean_policy_losses: -56.083, mean_net_lifetime: 3681.2115, mean_mc_travel_dist: 1287.1783, mean_rewards: 218.5134, total_rewards: 2438.1513, mean_steps: 17.2900, mean_ecr: 0.0399 mean_entropies: 2.0497, took: 86.2222s
2022-10-09 02:28:53,016 [INFO] 	Process 3 - batch 10699: mean_policy_losses: -142.405, mean_net_lifetime: 3492.9710, mean_mc_travel_dist: 1264.7297, mean_rewards: 216.5942, total_rewards: 2268.6090, mean_steps: 17.0500, mean_ecr: 0.0373 mean_entropies: 1.9544, took: 81.7332s
2022-10-09 02:29:41,210 [INFO] 	Process 2 - batch 10799: mean_policy_losses: 11.109, mean_net_lifetime: 3717.6296, mean_mc_travel_dist: 1310.7907, mean_rewards: 229.7220, total_rewards: 2436.0488, mean_steps: 16.8200, mean_ecr: 0.0397 mean_entropies: 2.0624, took: 84.5466s
2022-10-09 02:29:41,951 [INFO] 	Process 6 - batch 10699: mean_policy_losses: -122.604, mean_net_lifetime: 3491.9028, mean_mc_travel_dist: 1301.2450, mean_rewards: 220.8420, total_rewards: 2234.2951, mean_steps: 16.4000, mean_ecr: 0.0374 mean_entropies: 1.9681, took: 79.3625s
2022-10-09 02:29:53,282 [INFO] 	Process 1 - batch 10899: mean_policy_losses: -152.880, mean_net_lifetime: 3396.7113, mean_mc_travel_dist: 1228.7809, mean_rewards: 224.7574, total_rewards: 2195.6469, mean_steps: 15.3700, mean_ecr: 0.0403 mean_entropies: 2.0165, took: 73.7920s
2022-10-09 02:30:00,172 [INFO] 	Process 4 - batch 10899: mean_policy_losses: -90.658, mean_net_lifetime: 3514.2982, mean_mc_travel_dist: 1273.0371, mean_rewards: 217.6427, total_rewards: 2290.3896, mean_steps: 16.5500, mean_ecr: 0.0404 mean_entropies: 2.0168, took: 80.5437s
2022-10-09 02:30:15,174 [INFO] 	Process 3 - batch 10799: mean_policy_losses: -48.410, mean_net_lifetime: 3625.9924, mean_mc_travel_dist: 1297.7545, mean_rewards: 223.2116, total_rewards: 2364.4323, mean_steps: 16.6700, mean_ecr: 0.0399 mean_entropies: 2.0605, took: 82.1577s
2022-10-09 02:31:05,186 [INFO] 	Process 2 - batch 10899: mean_policy_losses: -200.623, mean_net_lifetime: 3389.5926, mean_mc_travel_dist: 1193.7357, mean_rewards: 213.9827, total_rewards: 2229.6285, mean_steps: 16.4000, mean_ecr: 0.0402 mean_entropies: 1.9844, took: 83.9754s
2022-10-09 02:31:08,471 [INFO] 	Process 6 - batch 10799: mean_policy_losses: 7.090, mean_net_lifetime: 3755.9439, mean_mc_travel_dist: 1302.9447, mean_rewards: 216.8724, total_rewards: 2490.3934, mean_steps: 17.4900, mean_ecr: 0.0399 mean_entropies: 2.0229, took: 86.5207s
2022-10-09 02:31:43,603 [INFO] 	Process 3 - batch 10899: mean_policy_losses: -76.312, mean_net_lifetime: 3708.7370, mean_mc_travel_dist: 1323.8563, mean_rewards: 212.8807, total_rewards: 2430.6632, mean_steps: 18.3800, mean_ecr: 0.0401 mean_entropies: 1.9935, took: 88.4296s
2022-10-09 02:31:44,169 [INFO] 	Process 1 - batch 10999: mean_policy_losses: -178.818, mean_net_lifetime: 4384.5422, mean_mc_travel_dist: 1799.5822, mean_rewards: 213.2545, total_rewards: 2620.5704, mean_steps: 24.1100, mean_ecr: 0.0380 mean_entropies: 1.9563, took: 110.8859s
2022-10-09 02:32:31,633 [INFO] 	Process 6 - batch 10899: mean_policy_losses: -1.624, mean_net_lifetime: 3482.5876, mean_mc_travel_dist: 1236.3721, mean_rewards: 217.1512, total_rewards: 2287.7124, mean_steps: 16.8500, mean_ecr: 0.0408 mean_entropies: 1.9761, took: 83.1627s
2022-10-09 02:32:56,161 [INFO] 	Process 4 - batch 10999: mean_policy_losses: -49.722, mean_net_lifetime: 6608.9484, mean_mc_travel_dist: 3001.8971, mean_rewards: 215.9306, total_rewards: 3643.0712, mean_steps: 38.1500, mean_ecr: 0.0380 mean_entropies: 1.9497, took: 175.9894s
2022-10-09 02:33:17,111 [INFO] 	Process 2 - batch 10999: mean_policy_losses: -70.922, mean_net_lifetime: 4894.3378, mean_mc_travel_dist: 2048.2557, mean_rewards: 213.1093, total_rewards: 2875.3467, mean_steps: 27.9200, mean_ecr: 0.0382 mean_entropies: 1.9472, took: 131.9258s
2022-10-09 02:33:22,419 [INFO] 	Process 1 - batch 11099: mean_policy_losses: -49.905, mean_net_lifetime: 3965.9233, mean_mc_travel_dist: 1451.2468, mean_rewards: 212.3557, total_rewards: 2550.6404, mean_steps: 20.2000, mean_ecr: 0.0391 mean_entropies: 1.9982, took: 98.2514s
2022-10-09 02:34:02,416 [INFO] 	Process 0 - batch 10599: mean_policy_losses: -131.122, mean_net_lifetime: 4041.8218, mean_mc_travel_dist: 1486.8340, mean_rewards: 216.6176, total_rewards: 2600.8042, mean_steps: 21.2300, mean_ecr: 0.0371 mean_entropies: 2.0044, took: 871.2012s
2022-10-09 02:34:09,422 [INFO] 	Process 3 - batch 10999: mean_policy_losses: -132.839, mean_net_lifetime: 5312.8582, mean_mc_travel_dist: 2292.0060, mean_rewards: 216.4740, total_rewards: 3061.1512, mean_steps: 30.1700, mean_ecr: 0.0381 mean_entropies: 1.9606, took: 145.8184s
2022-10-09 02:34:34,242 [INFO] 	Process 4 - batch 11099: mean_policy_losses: -118.635, mean_net_lifetime: 3835.9540, mean_mc_travel_dist: 1360.1102, mean_rewards: 215.6224, total_rewards: 2505.2119, mean_steps: 19.1600, mean_ecr: 0.0390 mean_entropies: 1.9916, took: 98.0799s
2022-10-09 02:34:40,907 [INFO] 	Process 5 - batch 10599: mean_policy_losses: -132.106, mean_net_lifetime: 3631.0623, mean_mc_travel_dist: 1299.5119, mean_rewards: 220.0031, total_rewards: 2374.4105, mean_steps: 18.1000, mean_ecr: 0.0372 mean_entropies: 2.0277, took: 885.0314s
2022-10-09 02:34:51,785 [INFO] 	Process 2 - batch 11099: mean_policy_losses: -89.452, mean_net_lifetime: 3642.0146, mean_mc_travel_dist: 1274.6854, mean_rewards: 214.7321, total_rewards: 2408.6511, mean_steps: 17.9600, mean_ecr: 0.0392 mean_entropies: 1.9902, took: 94.6743s
2022-10-09 02:34:53,860 [INFO] 	Process 1 - batch 11199: mean_policy_losses: -74.245, mean_net_lifetime: 3500.8738, mean_mc_travel_dist: 1215.2793, mean_rewards: 215.9572, total_rewards: 2325.4246, mean_steps: 17.8500, mean_ecr: 0.0397 mean_entropies: 1.9909, took: 91.4400s
2022-10-09 02:34:54,942 [INFO] 	Process 6 - batch 10999: mean_policy_losses: -150.268, mean_net_lifetime: 5165.5808, mean_mc_travel_dist: 2170.2779, mean_rewards: 214.3889, total_rewards: 3033.9106, mean_steps: 29.4300, mean_ecr: 0.0380 mean_entropies: 1.9452, took: 143.3087s
2022-10-09 02:35:40,587 [INFO] 	Process 0 - batch 10699: mean_policy_losses: -94.560, mean_net_lifetime: 3751.6754, mean_mc_travel_dist: 1355.2687, mean_rewards: 218.7150, total_rewards: 2435.8931, mean_steps: 18.8200, mean_ecr: 0.0371 mean_entropies: 1.9298, took: 98.1708s
2022-10-09 02:35:52,725 [INFO] 	Process 3 - batch 11099: mean_policy_losses: -120.800, mean_net_lifetime: 3940.0902, mean_mc_travel_dist: 1441.2138, mean_rewards: 209.2074, total_rewards: 2536.3463, mean_steps: 20.1200, mean_ecr: 0.0392 mean_entropies: 2.0009, took: 103.3036s
2022-10-09 02:36:00,550 [INFO] 	Process 4 - batch 11199: mean_policy_losses: -92.649, mean_net_lifetime: 3499.2276, mean_mc_travel_dist: 1232.3014, mean_rewards: 222.2419, total_rewards: 2297.2898, mean_steps: 16.7500, mean_ecr: 0.0400 mean_entropies: 1.9548, took: 86.3086s
2022-10-09 02:36:16,164 [INFO] 	Process 5 - batch 10699: mean_policy_losses: -78.905, mean_net_lifetime: 3701.2901, mean_mc_travel_dist: 1324.2613, mean_rewards: 220.3295, total_rewards: 2415.0287, mean_steps: 18.1600, mean_ecr: 0.0374 mean_entropies: 1.9020, took: 95.2566s
2022-10-09 02:36:17,835 [INFO] 	Process 1 - batch 11299: mean_policy_losses: -106.203, mean_net_lifetime: 3541.5490, mean_mc_travel_dist: 1203.3479, mean_rewards: 225.6410, total_rewards: 2377.9268, mean_steps: 16.3300, mean_ecr: 0.0396 mean_entropies: 2.0094, took: 83.9762s
2022-10-09 02:36:20,584 [INFO] 	Process 2 - batch 11199: mean_policy_losses: -37.891, mean_net_lifetime: 3535.8060, mean_mc_travel_dist: 1231.9485, mean_rewards: 221.8609, total_rewards: 2340.3399, mean_steps: 16.8200, mean_ecr: 0.0394 mean_entropies: 1.9763, took: 88.7984s
2022-10-09 02:36:30,201 [INFO] 	Process 6 - batch 11099: mean_policy_losses: -197.646, mean_net_lifetime: 3717.3360, mean_mc_travel_dist: 1338.2222, mean_rewards: 213.1100, total_rewards: 2414.1940, mean_steps: 18.7800, mean_ecr: 0.0394 mean_entropies: 1.9681, took: 95.2585s
2022-10-09 02:37:13,107 [INFO] 	Process 0 - batch 10799: mean_policy_losses: -78.854, mean_net_lifetime: 3738.8506, mean_mc_travel_dist: 1265.5213, mean_rewards: 215.1371, total_rewards: 2508.4839, mean_steps: 17.8200, mean_ecr: 0.0399 mean_entropies: 1.9655, took: 92.5204s
2022-10-09 02:37:25,517 [INFO] 	Process 3 - batch 11199: mean_policy_losses: -190.419, mean_net_lifetime: 3615.6962, mean_mc_travel_dist: 1307.9773, mean_rewards: 216.0946, total_rewards: 2340.1580, mean_steps: 18.0300, mean_ecr: 0.0395 mean_entropies: 1.9700, took: 92.7917s
2022-10-09 02:37:31,133 [INFO] 	Process 4 - batch 11299: mean_policy_losses: -125.825, mean_net_lifetime: 3655.3530, mean_mc_travel_dist: 1257.7208, mean_rewards: 216.1910, total_rewards: 2435.1193, mean_steps: 17.3500, mean_ecr: 0.0398 mean_entropies: 1.9676, took: 90.5823s
2022-10-09 02:37:48,947 [INFO] 	Process 1 - batch 11399: mean_policy_losses: -216.874, mean_net_lifetime: 3653.9958, mean_mc_travel_dist: 1269.7152, mean_rewards: 211.3172, total_rewards: 2417.7098, mean_steps: 17.9800, mean_ecr: 0.0393 mean_entropies: 1.9545, took: 91.1108s
2022-10-09 02:37:50,021 [INFO] 	Process 5 - batch 10799: mean_policy_losses: -133.043, mean_net_lifetime: 3704.3635, mean_mc_travel_dist: 1244.6210, mean_rewards: 217.3998, total_rewards: 2499.8295, mean_steps: 17.8300, mean_ecr: 0.0398 mean_entropies: 1.9755, took: 93.8563s
2022-10-09 02:37:56,285 [INFO] 	Process 2 - batch 11299: mean_policy_losses: -154.407, mean_net_lifetime: 3756.9601, mean_mc_travel_dist: 1295.1661, mean_rewards: 208.8109, total_rewards: 2504.1512, mean_steps: 18.5200, mean_ecr: 0.0398 mean_entropies: 1.9625, took: 95.7007s
2022-10-09 02:38:01,975 [INFO] 	Process 6 - batch 11199: mean_policy_losses: -62.430, mean_net_lifetime: 3654.7909, mean_mc_travel_dist: 1288.5671, mean_rewards: 216.4049, total_rewards: 2396.5318, mean_steps: 17.8700, mean_ecr: 0.0397 mean_entropies: 1.9415, took: 91.7740s
2022-10-09 02:38:39,243 [INFO] 	Process 0 - batch 10899: mean_policy_losses: -164.049, mean_net_lifetime: 3405.3831, mean_mc_travel_dist: 1183.8708, mean_rewards: 216.7911, total_rewards: 2264.3622, mean_steps: 16.5500, mean_ecr: 0.0401 mean_entropies: 1.9682, took: 86.1370s
2022-10-09 02:38:57,250 [INFO] 	Process 3 - batch 11299: mean_policy_losses: -98.136, mean_net_lifetime: 3718.7820, mean_mc_travel_dist: 1257.2437, mean_rewards: 220.4464, total_rewards: 2500.5092, mean_steps: 17.6400, mean_ecr: 0.0396 mean_entropies: 2.0106, took: 91.7333s
2022-10-09 02:39:02,544 [INFO] 	Process 4 - batch 11399: mean_policy_losses: -181.903, mean_net_lifetime: 3585.2704, mean_mc_travel_dist: 1247.1714, mean_rewards: 211.1863, total_rewards: 2385.3175, mean_steps: 17.7500, mean_ecr: 0.0391 mean_entropies: 2.0018, took: 91.4121s
2022-10-09 02:39:20,387 [INFO] 	Process 5 - batch 10899: mean_policy_losses: -134.633, mean_net_lifetime: 3494.9663, mean_mc_travel_dist: 1230.5627, mean_rewards: 216.2761, total_rewards: 2295.8508, mean_steps: 17.3200, mean_ecr: 0.0407 mean_entropies: 2.0035, took: 90.3670s
2022-10-09 02:39:25,799 [INFO] 	Process 1 - batch 11499: mean_policy_losses: -152.413, mean_net_lifetime: 3638.1637, mean_mc_travel_dist: 1291.8578, mean_rewards: 203.1850, total_rewards: 2382.5322, mean_steps: 19.2300, mean_ecr: 0.0397 mean_entropies: 1.9441, took: 96.8521s
2022-10-09 02:39:29,610 [INFO] 	Process 6 - batch 11299: mean_policy_losses: -81.775, mean_net_lifetime: 3646.3539, mean_mc_travel_dist: 1226.5785, mean_rewards: 224.5659, total_rewards: 2462.3450, mean_steps: 16.6900, mean_ecr: 0.0397 mean_entropies: 2.0210, took: 87.6347s
2022-10-09 02:39:31,636 [INFO] 	Process 2 - batch 11399: mean_policy_losses: -149.643, mean_net_lifetime: 3713.6121, mean_mc_travel_dist: 1295.1115, mean_rewards: 215.1376, total_rewards: 2467.9292, mean_steps: 18.6300, mean_ecr: 0.0394 mean_entropies: 2.0047, took: 95.3515s
2022-10-09 02:40:26,414 [INFO] 	Process 3 - batch 11399: mean_policy_losses: -166.155, mean_net_lifetime: 3515.2452, mean_mc_travel_dist: 1195.0976, mean_rewards: 208.3720, total_rewards: 2359.2982, mean_steps: 17.3500, mean_ecr: 0.0392 mean_entropies: 2.0033, took: 89.1635s
2022-10-09 02:40:57,949 [INFO] 	Process 4 - batch 11499: mean_policy_losses: -86.690, mean_net_lifetime: 4291.5605, mean_mc_travel_dist: 1665.9905, mean_rewards: 211.2147, total_rewards: 2671.1056, mean_steps: 22.8400, mean_ecr: 0.0396 mean_entropies: 1.9820, took: 115.4046s
2022-10-09 02:41:02,794 [INFO] 	Process 6 - batch 11399: mean_policy_losses: -92.948, mean_net_lifetime: 3701.3960, mean_mc_travel_dist: 1252.4258, mean_rewards: 219.5977, total_rewards: 2482.2133, mean_steps: 17.8000, mean_ecr: 0.0395 mean_entropies: 2.0218, took: 93.1839s
2022-10-09 02:41:04,596 [INFO] 	Process 1 - batch 11599: mean_policy_losses: -92.719, mean_net_lifetime: 3937.9810, mean_mc_travel_dist: 1411.8342, mean_rewards: 222.4663, total_rewards: 2568.6285, mean_steps: 19.4700, mean_ecr: 0.0389 mean_entropies: 2.0237, took: 98.7981s
2022-10-09 02:41:09,489 [INFO] 	Process 2 - batch 11499: mean_policy_losses: -206.277, mean_net_lifetime: 3672.5220, mean_mc_travel_dist: 1346.7800, mean_rewards: 203.9335, total_rewards: 2371.8112, mean_steps: 19.0000, mean_ecr: 0.0400 mean_entropies: 1.9714, took: 97.8535s
2022-10-09 02:41:16,725 [INFO] 	Process 5 - batch 10999: mean_policy_losses: -76.666, mean_net_lifetime: 4369.9568, mean_mc_travel_dist: 1594.6350, mean_rewards: 212.6048, total_rewards: 2804.0904, mean_steps: 22.6700, mean_ecr: 0.0376 mean_entropies: 1.9770, took: 116.3384s
2022-10-09 02:41:22,507 [INFO] 	Process 0 - batch 10999: mean_policy_losses: -116.537, mean_net_lifetime: 5485.1599, mean_mc_travel_dist: 2378.7519, mean_rewards: 206.8161, total_rewards: 3147.4106, mean_steps: 32.9600, mean_ecr: 0.0379 mean_entropies: 1.9763, took: 163.2636s
2022-10-09 02:41:56,750 [INFO] 	Process 3 - batch 11499: mean_policy_losses: -278.938, mean_net_lifetime: 3465.4504, mean_mc_travel_dist: 1291.4564, mean_rewards: 213.3070, total_rewards: 2204.9226, mean_steps: 17.2400, mean_ecr: 0.0397 mean_entropies: 1.9599, took: 90.3362s
2022-10-09 02:42:37,350 [INFO] 	Process 1 - batch 11699: mean_policy_losses: -196.734, mean_net_lifetime: 3760.0467, mean_mc_travel_dist: 1342.5863, mean_rewards: 221.5012, total_rewards: 2454.0052, mean_steps: 18.2400, mean_ecr: 0.0405 mean_entropies: 1.9888, took: 92.7531s
2022-10-09 02:42:39,065 [INFO] 	Process 4 - batch 11599: mean_policy_losses: -172.385, mean_net_lifetime: 3917.2870, mean_mc_travel_dist: 1392.5467, mean_rewards: 216.3717, total_rewards: 2563.2037, mean_steps: 19.7800, mean_ecr: 0.0389 mean_entropies: 2.0165, took: 101.1167s
2022-10-09 02:42:42,102 [INFO] 	Process 6 - batch 11499: mean_policy_losses: -241.411, mean_net_lifetime: 3669.9830, mean_mc_travel_dist: 1304.9904, mean_rewards: 203.9352, total_rewards: 2402.5039, mean_steps: 19.2500, mean_ecr: 0.0398 mean_entropies: 2.0016, took: 99.3085s
2022-10-09 02:42:52,149 [INFO] 	Process 5 - batch 11099: mean_policy_losses: -193.342, mean_net_lifetime: 3733.4638, mean_mc_travel_dist: 1318.1777, mean_rewards: 214.2677, total_rewards: 2457.7472, mean_steps: 18.2800, mean_ecr: 0.0392 mean_entropies: 2.0133, took: 95.4232s
2022-10-09 02:42:52,157 [INFO] 	Process 2 - batch 11599: mean_policy_losses: -132.820, mean_net_lifetime: 3967.9757, mean_mc_travel_dist: 1416.4093, mean_rewards: 219.0623, total_rewards: 2589.9867, mean_steps: 19.6800, mean_ecr: 0.0394 mean_entropies: 1.9945, took: 102.6676s
2022-10-09 02:42:57,845 [INFO] 	Process 0 - batch 11099: mean_policy_losses: -213.154, mean_net_lifetime: 3730.0954, mean_mc_travel_dist: 1292.5707, mean_rewards: 219.7797, total_rewards: 2474.8502, mean_steps: 18.0200, mean_ecr: 0.0390 mean_entropies: 1.9872, took: 95.3382s
2022-10-09 02:43:32,390 [INFO] 	Process 3 - batch 11599: mean_policy_losses: -170.748, mean_net_lifetime: 3893.7285, mean_mc_travel_dist: 1353.2119, mean_rewards: 221.5750, total_rewards: 2578.2586, mean_steps: 18.9700, mean_ecr: 0.0392 mean_entropies: 2.0149, took: 95.6405s
2022-10-09 02:44:10,031 [INFO] 	Process 4 - batch 11699: mean_policy_losses: -204.551, mean_net_lifetime: 3621.5955, mean_mc_travel_dist: 1260.9789, mean_rewards: 219.5499, total_rewards: 2401.0276, mean_steps: 17.5300, mean_ecr: 0.0399 mean_entropies: 1.9930, took: 90.9651s
2022-10-09 02:44:14,739 [INFO] 	Process 1 - batch 11799: mean_policy_losses: -137.005, mean_net_lifetime: 3945.0683, mean_mc_travel_dist: 1386.4922, mean_rewards: 215.6996, total_rewards: 2603.3896, mean_steps: 19.2400, mean_ecr: 0.0382 mean_entropies: 1.9929, took: 97.3898s
2022-10-09 02:44:20,215 [INFO] 	Process 2 - batch 11699: mean_policy_losses: -169.146, mean_net_lifetime: 3477.2498, mean_mc_travel_dist: 1180.2157, mean_rewards: 217.2784, total_rewards: 2335.3993, mean_steps: 16.7500, mean_ecr: 0.0403 mean_entropies: 1.9790, took: 88.0575s
2022-10-09 02:44:28,347 [INFO] 	Process 6 - batch 11599: mean_policy_losses: -154.471, mean_net_lifetime: 3997.2262, mean_mc_travel_dist: 1450.2557, mean_rewards: 212.2681, total_rewards: 2583.4488, mean_steps: 20.7400, mean_ecr: 0.0390 mean_entropies: 2.0228, took: 106.2442s
2022-10-09 02:44:28,899 [INFO] 	Process 5 - batch 11199: mean_policy_losses: -122.265, mean_net_lifetime: 3746.1406, mean_mc_travel_dist: 1309.0972, mean_rewards: 214.6621, total_rewards: 2470.1525, mean_steps: 18.7300, mean_ecr: 0.0397 mean_entropies: 1.9962, took: 96.7497s
2022-10-09 02:44:45,791 [INFO] 	Process 0 - batch 11199: mean_policy_losses: -41.550, mean_net_lifetime: 4145.9982, mean_mc_travel_dist: 1501.6815, mean_rewards: 224.7745, total_rewards: 2679.3738, mean_steps: 20.9600, mean_ecr: 0.0395 mean_entropies: 2.0125, took: 107.9462s
2022-10-09 02:45:03,137 [INFO] 	Process 3 - batch 11699: mean_policy_losses: -207.378, mean_net_lifetime: 3469.4766, mean_mc_travel_dist: 1232.2478, mean_rewards: 217.1395, total_rewards: 2273.8086, mean_steps: 17.4800, mean_ecr: 0.0400 mean_entropies: 1.9938, took: 90.7472s
2022-10-09 02:45:32,466 [INFO] 	Process 1 - batch 11899: mean_policy_losses: -245.049, mean_net_lifetime: 3174.5953, mean_mc_travel_dist: 1059.1263, mean_rewards: 218.8357, total_rewards: 2149.1161, mean_steps: 15.0500, mean_ecr: 0.0390 mean_entropies: 1.9851, took: 77.7267s
2022-10-09 02:45:50,781 [INFO] 	Process 4 - batch 11799: mean_policy_losses: -157.929, mean_net_lifetime: 3838.6086, mean_mc_travel_dist: 1370.3580, mean_rewards: 215.4333, total_rewards: 2502.3274, mean_steps: 19.5000, mean_ecr: 0.0381 mean_entropies: 1.9840, took: 100.7487s
2022-10-09 02:45:51,158 [INFO] 	Process 2 - batch 11799: mean_policy_losses: -101.418, mean_net_lifetime: 3709.9495, mean_mc_travel_dist: 1322.1041, mean_rewards: 219.5482, total_rewards: 2433.9535, mean_steps: 17.6800, mean_ecr: 0.0382 mean_entropies: 1.9831, took: 90.9434s
2022-10-09 02:45:58,915 [INFO] 	Process 6 - batch 11699: mean_policy_losses: -128.239, mean_net_lifetime: 3661.9150, mean_mc_travel_dist: 1289.3885, mean_rewards: 220.3917, total_rewards: 2417.1311, mean_steps: 17.5400, mean_ecr: 0.0403 mean_entropies: 1.9949, took: 90.5687s
2022-10-09 02:45:59,990 [INFO] 	Process 5 - batch 11299: mean_policy_losses: -65.213, mean_net_lifetime: 3731.4663, mean_mc_travel_dist: 1290.2247, mean_rewards: 221.6464, total_rewards: 2478.4785, mean_steps: 17.2600, mean_ecr: 0.0397 mean_entropies: 2.0522, took: 91.0917s
2022-10-09 02:46:18,653 [INFO] 	Process 0 - batch 11299: mean_policy_losses: -152.481, mean_net_lifetime: 3662.8944, mean_mc_travel_dist: 1287.7419, mean_rewards: 217.8241, total_rewards: 2412.9738, mean_steps: 17.6100, mean_ecr: 0.0397 mean_entropies: 2.0184, took: 92.8608s
2022-10-09 02:46:32,687 [INFO] 	Process 3 - batch 11799: mean_policy_losses: -154.785, mean_net_lifetime: 3659.2690, mean_mc_travel_dist: 1314.5829, mean_rewards: 223.0766, total_rewards: 2388.8927, mean_steps: 17.4100, mean_ecr: 0.0382 mean_entropies: 1.9717, took: 89.5497s
2022-10-09 02:46:53,490 [INFO] 	Process 1 - batch 11999: mean_policy_losses: -22.264, mean_net_lifetime: 3493.1616, mean_mc_travel_dist: 1216.6733, mean_rewards: 224.9625, total_rewards: 2316.2626, mean_steps: 15.7100, mean_ecr: 0.0412 mean_entropies: 1.9774, took: 81.0234s
2022-10-09 02:47:05,458 [INFO] 	Process 4 - batch 11899: mean_policy_losses: -194.432, mean_net_lifetime: 3153.6141, mean_mc_travel_dist: 1074.4138, mean_rewards: 223.7649, total_rewards: 2120.4172, mean_steps: 14.3200, mean_ecr: 0.0393 mean_entropies: 1.9899, took: 74.6776s
2022-10-09 02:47:08,023 [INFO] 	Process 2 - batch 11899: mean_policy_losses: -236.033, mean_net_lifetime: 3195.1552, mean_mc_travel_dist: 1112.3931, mean_rewards: 222.4431, total_rewards: 2127.0168, mean_steps: 14.8100, mean_ecr: 0.0390 mean_entropies: 1.9759, took: 76.8652s
2022-10-09 02:47:30,487 [INFO] 	Process 5 - batch 11399: mean_policy_losses: -26.973, mean_net_lifetime: 3682.1660, mean_mc_travel_dist: 1275.3384, mean_rewards: 218.5290, total_rewards: 2446.7096, mean_steps: 17.0800, mean_ecr: 0.0393 mean_entropies: 2.0321, took: 90.4971s
2022-10-09 02:47:33,483 [INFO] 	Process 6 - batch 11799: mean_policy_losses: -69.927, mean_net_lifetime: 3862.8713, mean_mc_travel_dist: 1421.9451, mean_rewards: 218.5083, total_rewards: 2489.7850, mean_steps: 18.6800, mean_ecr: 0.0383 mean_entropies: 1.9834, took: 94.5679s
2022-10-09 02:47:48,107 [INFO] 	Process 0 - batch 11399: mean_policy_losses: -111.778, mean_net_lifetime: 3739.9603, mean_mc_travel_dist: 1340.7070, mean_rewards: 221.6898, total_rewards: 2444.5081, mean_steps: 17.4300, mean_ecr: 0.0389 mean_entropies: 2.0260, took: 89.4548s
2022-10-09 02:47:51,068 [INFO] 	Process 3 - batch 11899: mean_policy_losses: -248.708, mean_net_lifetime: 3346.9868, mean_mc_travel_dist: 1163.4501, mean_rewards: 224.6391, total_rewards: 2230.9401, mean_steps: 15.5200, mean_ecr: 0.0391 mean_entropies: 1.9609, took: 78.3813s
2022-10-09 02:48:28,877 [INFO] 	Process 4 - batch 11999: mean_policy_losses: -7.043, mean_net_lifetime: 3679.5859, mean_mc_travel_dist: 1273.4483, mean_rewards: 225.8668, total_rewards: 2446.9872, mean_steps: 16.3200, mean_ecr: 0.0415 mean_entropies: 2.0002, took: 83.4196s
2022-10-09 02:48:37,278 [INFO] 	Process 2 - batch 11999: mean_policy_losses: 6.775, mean_net_lifetime: 3822.3343, mean_mc_travel_dist: 1360.8197, mean_rewards: 220.1449, total_rewards: 2515.7904, mean_steps: 17.8800, mean_ecr: 0.0411 mean_entropies: 1.9916, took: 89.2552s
2022-10-09 02:48:49,397 [INFO] 	Process 6 - batch 11899: mean_policy_losses: -265.032, mean_net_lifetime: 3296.0558, mean_mc_travel_dist: 1121.5878, mean_rewards: 226.1539, total_rewards: 2214.9765, mean_steps: 14.9500, mean_ecr: 0.0391 mean_entropies: 1.9837, took: 75.9133s
2022-10-09 02:49:04,090 [INFO] 	Process 5 - batch 11499: mean_policy_losses: -143.654, mean_net_lifetime: 3710.3304, mean_mc_travel_dist: 1367.4870, mean_rewards: 202.8714, total_rewards: 2386.0313, mean_steps: 19.0500, mean_ecr: 0.0394 mean_entropies: 1.9534, took: 93.6027s
2022-10-09 02:49:16,288 [INFO] 	Process 3 - batch 11999: mean_policy_losses: -22.742, mean_net_lifetime: 3751.9513, mean_mc_travel_dist: 1315.3380, mean_rewards: 228.9240, total_rewards: 2467.4316, mean_steps: 17.4600, mean_ecr: 0.0412 mean_entropies: 1.9873, took: 85.2191s
2022-10-09 02:49:17,330 [INFO] 	Process 0 - batch 11499: mean_policy_losses: -212.223, mean_net_lifetime: 3631.8263, mean_mc_travel_dist: 1329.8005, mean_rewards: 210.7992, total_rewards: 2340.9139, mean_steps: 18.0600, mean_ecr: 0.0397 mean_entropies: 1.9592, took: 89.2232s
2022-10-09 02:50:03,594 [INFO] 	Process 6 - batch 11999: mean_policy_losses: -137.580, mean_net_lifetime: 3437.0715, mean_mc_travel_dist: 1181.0055, mean_rewards: 224.4381, total_rewards: 2299.5901, mean_steps: 15.9000, mean_ecr: 0.0414 mean_entropies: 1.9806, took: 74.1978s
2022-10-09 02:50:22,450 [INFO] 	Process 5 - batch 11599: mean_policy_losses: -188.965, mean_net_lifetime: 3772.5032, mean_mc_travel_dist: 1323.9190, mean_rewards: 229.2385, total_rewards: 2486.7148, mean_steps: 17.2900, mean_ecr: 0.0390 mean_entropies: 1.9945, took: 78.3600s
2022-10-09 02:50:52,215 [INFO] 	Process 0 - batch 11599: mean_policy_losses: -78.238, mean_net_lifetime: 4113.7104, mean_mc_travel_dist: 1479.4322, mean_rewards: 209.4310, total_rewards: 2660.4865, mean_steps: 21.2200, mean_ecr: 0.0385 mean_entropies: 1.9956, took: 94.8842s
2022-10-09 02:51:50,763 [INFO] 	Process 5 - batch 11699: mean_policy_losses: -142.938, mean_net_lifetime: 4081.9353, mean_mc_travel_dist: 1484.6784, mean_rewards: 221.3751, total_rewards: 2639.0314, mean_steps: 20.2800, mean_ecr: 0.0398 mean_entropies: 1.9661, took: 88.3133s
2022-10-09 02:52:16,693 [INFO] 	Process 0 - batch 11699: mean_policy_losses: -230.555, mean_net_lifetime: 4022.6925, mean_mc_travel_dist: 1435.2307, mean_rewards: 222.7440, total_rewards: 2629.1734, mean_steps: 19.6000, mean_ecr: 0.0403 mean_entropies: 1.9489, took: 84.4789s
2022-10-09 02:53:15,995 [INFO] 	Process 5 - batch 11799: mean_policy_losses: -233.093, mean_net_lifetime: 3805.7666, mean_mc_travel_dist: 1361.7958, mean_rewards: 214.3726, total_rewards: 2492.5573, mean_steps: 19.4500, mean_ecr: 0.0380 mean_entropies: 1.9411, took: 85.2314s
2022-10-09 02:53:40,030 [INFO] 	Process 0 - batch 11799: mean_policy_losses: -185.298, mean_net_lifetime: 3957.3469, mean_mc_travel_dist: 1435.4313, mean_rewards: 218.0176, total_rewards: 2564.2453, mean_steps: 19.1600, mean_ecr: 0.0377 mean_entropies: 1.9599, took: 83.3370s
2022-10-09 02:54:22,710 [INFO] 	Process 5 - batch 11899: mean_policy_losses: -147.923, mean_net_lifetime: 3336.7633, mean_mc_travel_dist: 1141.7343, mean_rewards: 229.5660, total_rewards: 2236.2369, mean_steps: 14.7900, mean_ecr: 0.0390 mean_entropies: 1.9758, took: 66.7155s
2022-10-09 02:54:48,791 [INFO] 	Process 0 - batch 11899: mean_policy_losses: -139.423, mean_net_lifetime: 3269.6872, mean_mc_travel_dist: 1122.2793, mean_rewards: 227.8622, total_rewards: 2181.7612, mean_steps: 15.0300, mean_ecr: 0.0391 mean_entropies: 1.9638, took: 68.7608s
2022-10-09 02:55:35,284 [INFO] 	Process 5 - batch 11999: mean_policy_losses: -22.433, mean_net_lifetime: 3634.4734, mean_mc_travel_dist: 1274.4123, mean_rewards: 224.4847, total_rewards: 2404.2382, mean_steps: 16.3300, mean_ecr: 0.0415 mean_entropies: 2.0069, took: 72.5737s
2022-10-09 02:55:59,570 [INFO] 	Process 0 - batch 11999: mean_policy_losses: -147.043, mean_net_lifetime: 3645.1034, mean_mc_travel_dist: 1241.0917, mean_rewards: 226.3876, total_rewards: 2442.6833, mean_steps: 16.0500, mean_ecr: 0.0411 mean_entropies: 2.0009, took: 70.7793s
2022-10-09 03:00:12,627 [INFO] 	Process 1 - batch 12099: mean_policy_losses: -81.186, mean_net_lifetime: 3926.1666, mean_mc_travel_dist: 1408.2776, mean_rewards: 222.3069, total_rewards: 2553.0680, mean_steps: 18.6900, mean_ecr: 0.0402 mean_entropies: 2.0224, took: 799.1370s
2022-10-09 03:01:32,634 [INFO] 	Process 1 - batch 12199: mean_policy_losses: -82.740, mean_net_lifetime: 3764.3223, mean_mc_travel_dist: 1358.7509, mean_rewards: 221.6750, total_rewards: 2446.4740, mean_steps: 17.7600, mean_ecr: 0.0392 mean_entropies: 2.0239, took: 80.0074s
2022-10-09 03:01:38,845 [INFO] 	Process 2 - batch 12099: mean_policy_losses: -98.189, mean_net_lifetime: 3650.2254, mean_mc_travel_dist: 1271.4825, mean_rewards: 224.1786, total_rewards: 2420.2045, mean_steps: 16.7100, mean_ecr: 0.0400 mean_entropies: 2.0194, took: 781.5658s
2022-10-09 03:01:49,495 [INFO] 	Process 4 - batch 12099: mean_policy_losses: -182.134, mean_net_lifetime: 3679.7670, mean_mc_travel_dist: 1237.7289, mean_rewards: 231.4289, total_rewards: 2479.0007, mean_steps: 17.2400, mean_ecr: 0.0399 mean_entropies: 1.9811, took: 800.6188s
2022-10-09 03:02:10,929 [INFO] 	Process 3 - batch 12099: mean_policy_losses: -122.165, mean_net_lifetime: 3911.1948, mean_mc_travel_dist: 1395.7849, mean_rewards: 224.6251, total_rewards: 2560.6174, mean_steps: 18.6700, mean_ecr: 0.0398 mean_entropies: 1.9996, took: 774.6412s
2022-10-09 03:02:50,550 [INFO] 	Process 6 - batch 12099: mean_policy_losses: -131.500, mean_net_lifetime: 3668.9770, mean_mc_travel_dist: 1285.4832, mean_rewards: 229.6669, total_rewards: 2421.3018, mean_steps: 17.1000, mean_ecr: 0.0397 mean_entropies: 1.9807, took: 766.9551s
2022-10-09 03:03:01,900 [INFO] 	Process 1 - batch 12299: mean_policy_losses: -74.527, mean_net_lifetime: 3835.1475, mean_mc_travel_dist: 1382.4775, mean_rewards: 212.7252, total_rewards: 2487.7107, mean_steps: 18.8500, mean_ecr: 0.0393 mean_entropies: 2.0187, took: 89.2653s
2022-10-09 03:03:05,730 [INFO] 	Process 2 - batch 12199: mean_policy_losses: -77.025, mean_net_lifetime: 3714.8006, mean_mc_travel_dist: 1337.0022, mean_rewards: 216.6440, total_rewards: 2418.8214, mean_steps: 17.8100, mean_ecr: 0.0393 mean_entropies: 2.0013, took: 86.8857s
2022-10-09 03:03:13,375 [INFO] 	Process 4 - batch 12199: mean_policy_losses: -69.155, mean_net_lifetime: 3682.2586, mean_mc_travel_dist: 1333.7871, mean_rewards: 224.3534, total_rewards: 2391.2061, mean_steps: 17.0300, mean_ecr: 0.0392 mean_entropies: 2.0012, took: 83.8798s
2022-10-09 03:03:40,945 [INFO] 	Process 3 - batch 12199: mean_policy_losses: -97.189, mean_net_lifetime: 3884.4491, mean_mc_travel_dist: 1392.7473, mean_rewards: 219.6253, total_rewards: 2531.8763, mean_steps: 18.8600, mean_ecr: 0.0392 mean_entropies: 1.9969, took: 90.0166s
2022-10-09 03:04:19,112 [INFO] 	Process 1 - batch 12399: mean_policy_losses: -175.861, mean_net_lifetime: 3436.5499, mean_mc_travel_dist: 1165.1523, mean_rewards: 223.1306, total_rewards: 2300.5686, mean_steps: 16.1100, mean_ecr: 0.0399 mean_entropies: 1.9531, took: 77.2127s
2022-10-09 03:04:22,138 [INFO] 	Process 6 - batch 12199: mean_policy_losses: -162.141, mean_net_lifetime: 3770.4982, mean_mc_travel_dist: 1347.1602, mean_rewards: 218.7258, total_rewards: 2462.2049, mean_steps: 18.1700, mean_ecr: 0.0393 mean_entropies: 1.9951, took: 91.5890s
2022-10-09 03:04:46,420 [INFO] 	Process 2 - batch 12299: mean_policy_losses: -28.843, mean_net_lifetime: 4177.7903, mean_mc_travel_dist: 1483.6808, mean_rewards: 212.3054, total_rewards: 2732.3436, mean_steps: 20.3100, mean_ecr: 0.0392 mean_entropies: 2.0291, took: 100.6905s
2022-10-09 03:04:51,116 [INFO] 	Process 4 - batch 12299: mean_policy_losses: -41.410, mean_net_lifetime: 4202.6792, mean_mc_travel_dist: 1487.8485, mean_rewards: 212.4649, total_rewards: 2744.5547, mean_steps: 20.5600, mean_ecr: 0.0393 mean_entropies: 2.0255, took: 97.7404s
2022-10-09 03:05:16,920 [INFO] 	Process 3 - batch 12299: mean_policy_losses: -86.613, mean_net_lifetime: 3983.0648, mean_mc_travel_dist: 1393.4267, mean_rewards: 209.9532, total_rewards: 2625.4070, mean_steps: 19.7600, mean_ecr: 0.0395 mean_entropies: 2.0420, took: 95.9745s
2022-10-09 03:05:40,298 [INFO] 	Process 1 - batch 12499: mean_policy_losses: -175.148, mean_net_lifetime: 3484.9043, mean_mc_travel_dist: 1191.5335, mean_rewards: 219.9981, total_rewards: 2326.9407, mean_steps: 17.0400, mean_ecr: 0.0405 mean_entropies: 1.9092, took: 81.1864s
2022-10-09 03:06:04,988 [INFO] 	Process 2 - batch 12399: mean_policy_losses: -206.916, mean_net_lifetime: 3264.1034, mean_mc_travel_dist: 1118.4025, mean_rewards: 219.6344, total_rewards: 2185.0423, mean_steps: 15.6800, mean_ecr: 0.0399 mean_entropies: 1.9408, took: 78.5677s
2022-10-09 03:06:06,180 [INFO] 	Process 6 - batch 12299: mean_policy_losses: -31.745, mean_net_lifetime: 4189.3009, mean_mc_travel_dist: 1515.9789, mean_rewards: 213.8199, total_rewards: 2717.4968, mean_steps: 21.3400, mean_ecr: 0.0391 mean_entropies: 2.0191, took: 104.0424s
2022-10-09 03:06:09,270 [INFO] 	Process 4 - batch 12399: mean_policy_losses: -184.085, mean_net_lifetime: 3352.0822, mean_mc_travel_dist: 1166.5211, mean_rewards: 218.7148, total_rewards: 2226.4754, mean_steps: 16.3200, mean_ecr: 0.0399 mean_entropies: 1.9352, took: 78.1536s
2022-10-09 03:06:38,253 [INFO] 	Process 3 - batch 12399: mean_policy_losses: -60.506, mean_net_lifetime: 3513.6881, mean_mc_travel_dist: 1188.8283, mean_rewards: 221.7216, total_rewards: 2358.8887, mean_steps: 16.4500, mean_ecr: 0.0399 mean_entropies: 1.9274, took: 81.3335s
2022-10-09 03:07:11,553 [INFO] 	Process 1 - batch 12599: mean_policy_losses: -172.924, mean_net_lifetime: 3840.4370, mean_mc_travel_dist: 1383.2376, mean_rewards: 211.9072, total_rewards: 2501.0248, mean_steps: 19.3800, mean_ecr: 0.0390 mean_entropies: 1.9615, took: 91.2548s
2022-10-09 03:07:23,499 [INFO] 	Process 6 - batch 12399: mean_policy_losses: -258.017, mean_net_lifetime: 3329.1833, mean_mc_travel_dist: 1136.5356, mean_rewards: 224.9446, total_rewards: 2228.1777, mean_steps: 15.4300, mean_ecr: 0.0398 mean_entropies: 1.9195, took: 77.3185s
2022-10-09 03:07:32,828 [INFO] 	Process 2 - batch 12499: mean_policy_losses: -131.792, mean_net_lifetime: 3578.1822, mean_mc_travel_dist: 1220.4817, mean_rewards: 218.6255, total_rewards: 2396.7784, mean_steps: 17.3600, mean_ecr: 0.0401 mean_entropies: 1.9246, took: 87.8393s
2022-10-09 03:07:39,500 [INFO] 	Process 4 - batch 12499: mean_policy_losses: -123.371, mean_net_lifetime: 3800.3120, mean_mc_travel_dist: 1327.4999, mean_rewards: 219.8120, total_rewards: 2506.1993, mean_steps: 18.4200, mean_ecr: 0.0401 mean_entropies: 1.9313, took: 90.2299s
2022-10-09 03:08:03,440 [INFO] 	Process 3 - batch 12499: mean_policy_losses: -119.192, mean_net_lifetime: 3630.5042, mean_mc_travel_dist: 1236.4840, mean_rewards: 222.4165, total_rewards: 2439.6881, mean_steps: 16.6500, mean_ecr: 0.0399 mean_entropies: 1.9563, took: 85.1862s
2022-10-09 03:08:43,420 [INFO] 	Process 1 - batch 12699: mean_policy_losses: -239.910, mean_net_lifetime: 3912.4254, mean_mc_travel_dist: 1444.4036, mean_rewards: 217.5281, total_rewards: 2510.6571, mean_steps: 19.3900, mean_ecr: 0.0381 mean_entropies: 1.9835, took: 91.8661s
2022-10-09 03:08:52,382 [INFO] 	Process 6 - batch 12499: mean_policy_losses: -64.476, mean_net_lifetime: 3737.2553, mean_mc_travel_dist: 1298.6739, mean_rewards: 215.8531, total_rewards: 2478.6339, mean_steps: 17.4700, mean_ecr: 0.0405 mean_entropies: 1.9533, took: 88.8811s
2022-10-09 03:09:06,220 [INFO] 	Process 2 - batch 12599: mean_policy_losses: -179.357, mean_net_lifetime: 3811.4384, mean_mc_travel_dist: 1397.9449, mean_rewards: 220.2684, total_rewards: 2452.0645, mean_steps: 18.2200, mean_ecr: 0.0393 mean_entropies: 2.0056, took: 93.3926s
2022-10-09 03:09:15,790 [INFO] 	Process 4 - batch 12599: mean_policy_losses: -184.430, mean_net_lifetime: 3878.8651, mean_mc_travel_dist: 1416.7941, mean_rewards: 221.2423, total_rewards: 2495.7936, mean_steps: 18.9000, mean_ecr: 0.0393 mean_entropies: 1.9990, took: 96.2906s
2022-10-09 03:09:36,051 [INFO] 	Process 3 - batch 12599: mean_policy_losses: -109.263, mean_net_lifetime: 3809.2308, mean_mc_travel_dist: 1384.5925, mean_rewards: 216.6569, total_rewards: 2462.8536, mean_steps: 17.9200, mean_ecr: 0.0391 mean_entropies: 2.0070, took: 92.6097s
2022-10-09 03:09:56,038 [INFO] 	Process 5 - batch 12099: mean_policy_losses: -134.148, mean_net_lifetime: 3931.2815, mean_mc_travel_dist: 1402.9549, mean_rewards: 228.8134, total_rewards: 2566.3457, mean_steps: 18.1100, mean_ecr: 0.0398 mean_entropies: 2.0002, took: 860.7538s
2022-10-09 03:10:18,677 [INFO] 	Process 1 - batch 12799: mean_policy_losses: 29.422, mean_net_lifetime: 3999.6916, mean_mc_travel_dist: 1465.3821, mean_rewards: 216.9742, total_rewards: 2576.3894, mean_steps: 19.0400, mean_ecr: 0.0397 mean_entropies: 1.9947, took: 95.2568s
2022-10-09 03:10:27,691 [INFO] 	Process 0 - batch 12099: mean_policy_losses: -73.114, mean_net_lifetime: 3908.8318, mean_mc_travel_dist: 1371.8368, mean_rewards: 228.9093, total_rewards: 2583.7347, mean_steps: 18.2300, mean_ecr: 0.0403 mean_entropies: 1.9825, took: 868.1213s
2022-10-09 03:10:44,790 [INFO] 	Process 6 - batch 12599: mean_policy_losses: -113.753, mean_net_lifetime: 4281.4158, mean_mc_travel_dist: 1589.1786, mean_rewards: 216.0884, total_rewards: 2733.9007, mean_steps: 21.1700, mean_ecr: 0.0389 mean_entropies: 1.9862, took: 112.4092s
2022-10-09 03:11:02,625 [INFO] 	Process 2 - batch 12699: mean_policy_losses: -24.826, mean_net_lifetime: 4335.0706, mean_mc_travel_dist: 1623.8085, mean_rewards: 204.2801, total_rewards: 2751.8331, mean_steps: 22.0800, mean_ecr: 0.0378 mean_entropies: 2.0031, took: 116.4040s
2022-10-09 03:11:04,336 [INFO] 	Process 4 - batch 12699: mean_policy_losses: -153.248, mean_net_lifetime: 4004.2979, mean_mc_travel_dist: 1450.5118, mean_rewards: 205.2162, total_rewards: 2595.7661, mean_steps: 20.7600, mean_ecr: 0.0376 mean_entropies: 1.9630, took: 108.5465s
2022-10-09 03:11:34,479 [INFO] 	Process 5 - batch 12199: mean_policy_losses: -121.506, mean_net_lifetime: 3929.4826, mean_mc_travel_dist: 1434.6237, mean_rewards: 221.9065, total_rewards: 2538.0305, mean_steps: 18.6900, mean_ecr: 0.0392 mean_entropies: 1.9494, took: 98.4399s
2022-10-09 03:11:35,850 [INFO] 	Process 3 - batch 12699: mean_policy_losses: -105.974, mean_net_lifetime: 4433.0535, mean_mc_travel_dist: 1626.9485, mean_rewards: 204.2683, total_rewards: 2848.1441, mean_steps: 23.0800, mean_ecr: 0.0377 mean_entropies: 1.9635, took: 119.8000s
2022-10-09 03:11:52,659 [INFO] 	Process 1 - batch 12899: mean_policy_losses: -200.349, mean_net_lifetime: 3853.9971, mean_mc_travel_dist: 1376.4026, mean_rewards: 208.1237, total_rewards: 2520.9313, mean_steps: 18.7000, mean_ecr: 0.0379 mean_entropies: 1.9607, took: 93.9831s
2022-10-09 03:12:28,269 [INFO] 	Process 0 - batch 12199: mean_policy_losses: -134.440, mean_net_lifetime: 4509.3330, mean_mc_travel_dist: 1689.6780, mean_rewards: 213.2238, total_rewards: 2854.5832, mean_steps: 23.2100, mean_ecr: 0.0390 mean_entropies: 1.9694, took: 120.5768s
2022-10-09 03:12:37,801 [INFO] 	Process 6 - batch 12699: mean_policy_losses: -121.652, mean_net_lifetime: 4255.5740, mean_mc_travel_dist: 1558.2111, mean_rewards: 209.8496, total_rewards: 2729.1623, mean_steps: 21.6000, mean_ecr: 0.0371 mean_entropies: 1.9675, took: 113.0107s
2022-10-09 03:12:45,486 [INFO] 	Process 4 - batch 12799: mean_policy_losses: -63.568, mean_net_lifetime: 3975.2247, mean_mc_travel_dist: 1423.9254, mean_rewards: 211.6816, total_rewards: 2594.7035, mean_steps: 19.2100, mean_ecr: 0.0400 mean_entropies: 2.0095, took: 101.1489s
2022-10-09 03:12:45,859 [INFO] 	Process 2 - batch 12799: mean_policy_losses: -71.948, mean_net_lifetime: 3987.5788, mean_mc_travel_dist: 1451.6399, mean_rewards: 211.3993, total_rewards: 2577.6260, mean_steps: 19.5000, mean_ecr: 0.0398 mean_entropies: 1.9957, took: 103.2345s
2022-10-09 03:13:11,343 [INFO] 	Process 3 - batch 12799: mean_policy_losses: -32.823, mean_net_lifetime: 3900.4345, mean_mc_travel_dist: 1384.6387, mean_rewards: 219.7178, total_rewards: 2554.6201, mean_steps: 17.8700, mean_ecr: 0.0402 mean_entropies: 2.0184, took: 95.4932s
2022-10-09 03:13:15,723 [INFO] 	Process 5 - batch 12299: mean_policy_losses: -117.787, mean_net_lifetime: 3916.8040, mean_mc_travel_dist: 1387.2313, mean_rewards: 218.5532, total_rewards: 2563.4091, mean_steps: 18.7400, mean_ecr: 0.0392 mean_entropies: 2.0159, took: 101.2448s
2022-10-09 03:13:28,662 [INFO] 	Process 1 - batch 12999: mean_policy_losses: -123.886, mean_net_lifetime: 3984.8538, mean_mc_travel_dist: 1399.1257, mean_rewards: 218.0493, total_rewards: 2621.6781, mean_steps: 19.0700, mean_ecr: 0.0377 mean_entropies: 1.9921, took: 96.0027s
2022-10-09 03:14:14,189 [INFO] 	Process 0 - batch 12299: mean_policy_losses: -69.793, mean_net_lifetime: 4070.0550, mean_mc_travel_dist: 1446.8999, mean_rewards: 214.2680, total_rewards: 2665.6530, mean_steps: 19.7500, mean_ecr: 0.0389 mean_entropies: 2.0128, took: 105.9208s
2022-10-09 03:14:14,791 [INFO] 	Process 6 - batch 12799: mean_policy_losses: -75.716, mean_net_lifetime: 3836.8159, mean_mc_travel_dist: 1360.1982, mean_rewards: 216.1944, total_rewards: 2514.5276, mean_steps: 18.2000, mean_ecr: 0.0403 mean_entropies: 1.9940, took: 96.9906s
2022-10-09 03:14:28,262 [INFO] 	Process 2 - batch 12899: mean_policy_losses: -111.320, mean_net_lifetime: 3979.4670, mean_mc_travel_dist: 1440.5650, mean_rewards: 206.8402, total_rewards: 2574.3414, mean_steps: 19.5200, mean_ecr: 0.0377 mean_entropies: 1.9843, took: 102.4031s
2022-10-09 03:14:30,446 [INFO] 	Process 4 - batch 12899: mean_policy_losses: -51.535, mean_net_lifetime: 4171.2915, mean_mc_travel_dist: 1518.8582, mean_rewards: 213.1570, total_rewards: 2685.4551, mean_steps: 20.0600, mean_ecr: 0.0383 mean_entropies: 1.9570, took: 104.9606s
2022-10-09 03:14:35,933 [INFO] 	Process 5 - batch 12399: mean_policy_losses: -289.695, mean_net_lifetime: 3320.0683, mean_mc_travel_dist: 1134.3801, mean_rewards: 230.1806, total_rewards: 2226.3480, mean_steps: 15.0400, mean_ecr: 0.0399 mean_entropies: 1.8972, took: 80.2104s
2022-10-09 03:14:57,985 [INFO] 	Process 3 - batch 12899: mean_policy_losses: 40.425, mean_net_lifetime: 4214.5956, mean_mc_travel_dist: 1523.7927, mean_rewards: 210.3729, total_rewards: 2735.9310, mean_steps: 20.3000, mean_ecr: 0.0379 mean_entropies: 1.9705, took: 106.6423s
2022-10-09 03:15:18,268 [INFO] 	Process 1 - batch 13099: mean_policy_losses: -53.479, mean_net_lifetime: 4432.7110, mean_mc_travel_dist: 1658.5806, mean_rewards: 215.9382, total_rewards: 2826.4025, mean_steps: 22.1500, mean_ecr: 0.0390 mean_entropies: 1.9598, took: 109.6062s
2022-10-09 03:15:39,904 [INFO] 	Process 0 - batch 12399: mean_policy_losses: -138.163, mean_net_lifetime: 3393.5509, mean_mc_travel_dist: 1175.5140, mean_rewards: 219.1317, total_rewards: 2265.5842, mean_steps: 15.9700, mean_ecr: 0.0396 mean_entropies: 1.8973, took: 85.7140s
2022-10-09 03:15:58,020 [INFO] 	Process 6 - batch 12899: mean_policy_losses: -82.621, mean_net_lifetime: 3983.5332, mean_mc_travel_dist: 1428.5467, mean_rewards: 208.5263, total_rewards: 2596.2095, mean_steps: 19.8500, mean_ecr: 0.0380 mean_entropies: 1.9163, took: 103.2289s
2022-10-09 03:16:12,963 [INFO] 	Process 5 - batch 12499: mean_policy_losses: -8.441, mean_net_lifetime: 3820.3422, mean_mc_travel_dist: 1333.1905, mean_rewards: 217.9096, total_rewards: 2520.2663, mean_steps: 17.9800, mean_ecr: 0.0406 mean_entropies: 1.8751, took: 97.0293s
2022-10-09 03:16:23,418 [INFO] 	Process 2 - batch 12999: mean_policy_losses: -10.600, mean_net_lifetime: 4315.4636, mean_mc_travel_dist: 1566.9063, mean_rewards: 212.4079, total_rewards: 2786.8935, mean_steps: 22.0500, mean_ecr: 0.0383 mean_entropies: 1.9285, took: 115.1562s
2022-10-09 03:16:29,102 [INFO] 	Process 4 - batch 12999: mean_policy_losses: -17.285, mean_net_lifetime: 4414.2229, mean_mc_travel_dist: 1641.9147, mean_rewards: 213.2402, total_rewards: 2819.3631, mean_steps: 22.9500, mean_ecr: 0.0376 mean_entropies: 1.9467, took: 118.6569s
2022-10-09 03:16:40,187 [INFO] 	Process 3 - batch 12999: mean_policy_losses: -188.387, mean_net_lifetime: 3910.4614, mean_mc_travel_dist: 1434.7068, mean_rewards: 212.5892, total_rewards: 2523.4916, mean_steps: 19.2000, mean_ecr: 0.0377 mean_entropies: 1.9425, took: 102.2013s
2022-10-09 03:16:48,451 [INFO] 	Process 1 - batch 13199: mean_policy_losses: -50.542, mean_net_lifetime: 3695.5524, mean_mc_travel_dist: 1267.8798, mean_rewards: 214.9555, total_rewards: 2458.9994, mean_steps: 17.8300, mean_ecr: 0.0404 mean_entropies: 2.0004, took: 90.1821s
2022-10-09 03:17:15,094 [INFO] 	Process 0 - batch 12499: mean_policy_losses: -94.079, mean_net_lifetime: 3717.7086, mean_mc_travel_dist: 1309.0417, mean_rewards: 219.6021, total_rewards: 2442.2697, mean_steps: 17.8900, mean_ecr: 0.0405 mean_entropies: 1.9224, took: 95.1904s
2022-10-09 03:17:42,528 [INFO] 	Process 6 - batch 12999: mean_policy_losses: -30.709, mean_net_lifetime: 4226.0436, mean_mc_travel_dist: 1519.3508, mean_rewards: 215.3456, total_rewards: 2749.6591, mean_steps: 20.1500, mean_ecr: 0.0381 mean_entropies: 2.0006, took: 104.5084s
2022-10-09 03:18:01,783 [INFO] 	Process 5 - batch 12599: mean_policy_losses: -221.529, mean_net_lifetime: 4279.6849, mean_mc_travel_dist: 1593.3630, mean_rewards: 217.6420, total_rewards: 2731.3570, mean_steps: 20.6800, mean_ecr: 0.0389 mean_entropies: 1.9602, took: 108.8199s
2022-10-09 03:18:09,508 [INFO] 	Process 2 - batch 13099: mean_policy_losses: 6.732, mean_net_lifetime: 4245.5294, mean_mc_travel_dist: 1500.8839, mean_rewards: 222.2485, total_rewards: 2780.5415, mean_steps: 19.9000, mean_ecr: 0.0392 mean_entropies: 1.9711, took: 106.0881s
2022-10-09 03:18:15,086 [INFO] 	Process 4 - batch 13099: mean_policy_losses: -50.599, mean_net_lifetime: 4212.6406, mean_mc_travel_dist: 1513.6588, mean_rewards: 217.6637, total_rewards: 2743.0579, mean_steps: 20.4600, mean_ecr: 0.0390 mean_entropies: 1.9609, took: 105.9829s
2022-10-09 03:18:17,059 [INFO] 	Process 3 - batch 13099: mean_policy_losses: -161.432, mean_net_lifetime: 3869.2062, mean_mc_travel_dist: 1372.0945, mean_rewards: 220.2016, total_rewards: 2535.8039, mean_steps: 18.4600, mean_ecr: 0.0392 mean_entropies: 1.9472, took: 96.8733s
2022-10-09 03:18:23,147 [INFO] 	Process 1 - batch 13299: mean_policy_losses: -171.813, mean_net_lifetime: 3921.1612, mean_mc_travel_dist: 1397.8600, mean_rewards: 220.9466, total_rewards: 2560.5972, mean_steps: 18.7500, mean_ecr: 0.0380 mean_entropies: 1.9535, took: 94.6965s
2022-10-09 03:19:04,456 [INFO] 	Process 0 - batch 12599: mean_policy_losses: -179.298, mean_net_lifetime: 4092.6727, mean_mc_travel_dist: 1505.8857, mean_rewards: 213.4947, total_rewards: 2639.9413, mean_steps: 20.8100, mean_ecr: 0.0387 mean_entropies: 1.9767, took: 109.3632s
2022-10-09 03:19:32,715 [INFO] 	Process 6 - batch 13099: mean_policy_losses: -1.124, mean_net_lifetime: 4373.2188, mean_mc_travel_dist: 1575.4237, mean_rewards: 218.0672, total_rewards: 2828.5332, mean_steps: 20.9700, mean_ecr: 0.0388 mean_entropies: 1.9593, took: 110.1865s
2022-10-09 03:19:41,841 [INFO] 	Process 5 - batch 12699: mean_policy_losses: -139.513, mean_net_lifetime: 3809.1451, mean_mc_travel_dist: 1402.1505, mean_rewards: 209.9798, total_rewards: 2439.4824, mean_steps: 19.0600, mean_ecr: 0.0377 mean_entropies: 1.9594, took: 100.0585s
2022-10-09 03:19:46,607 [INFO] 	Process 2 - batch 13199: mean_policy_losses: -39.915, mean_net_lifetime: 3841.3393, mean_mc_travel_dist: 1317.4127, mean_rewards: 217.1961, total_rewards: 2564.4205, mean_steps: 18.1800, mean_ecr: 0.0406 mean_entropies: 1.9953, took: 97.1008s
2022-10-09 03:19:49,739 [INFO] 	Process 3 - batch 13199: mean_policy_losses: -100.295, mean_net_lifetime: 3651.6274, mean_mc_travel_dist: 1247.7262, mean_rewards: 222.4455, total_rewards: 2437.6649, mean_steps: 17.1700, mean_ecr: 0.0401 mean_entropies: 1.9826, took: 92.6797s
2022-10-09 03:19:50,051 [INFO] 	Process 4 - batch 13199: mean_policy_losses: -19.348, mean_net_lifetime: 3751.4283, mean_mc_travel_dist: 1287.5762, mean_rewards: 218.7181, total_rewards: 2499.7400, mean_steps: 17.7600, mean_ecr: 0.0400 mean_entropies: 2.0164, took: 94.9646s
2022-10-09 03:20:02,664 [INFO] 	Process 1 - batch 13399: mean_policy_losses: 15.927, mean_net_lifetime: 4259.9308, mean_mc_travel_dist: 1502.2082, mean_rewards: 220.2361, total_rewards: 2792.4895, mean_steps: 19.8400, mean_ecr: 0.0385 mean_entropies: 2.0449, took: 99.5175s
2022-10-09 03:20:55,727 [INFO] 	Process 0 - batch 12699: mean_policy_losses: -101.801, mean_net_lifetime: 4270.0295, mean_mc_travel_dist: 1585.7415, mean_rewards: 212.6856, total_rewards: 2718.6320, mean_steps: 21.0400, mean_ecr: 0.0380 mean_entropies: 1.9466, took: 111.2697s
2022-10-09 03:21:10,660 [INFO] 	Process 6 - batch 13199: mean_policy_losses: -51.426, mean_net_lifetime: 3796.8873, mean_mc_travel_dist: 1323.4992, mean_rewards: 214.9997, total_rewards: 2506.3906, mean_steps: 18.3500, mean_ecr: 0.0400 mean_entropies: 2.0075, took: 97.9446s
2022-10-09 03:21:16,979 [INFO] 	Process 5 - batch 12799: mean_policy_losses: -13.795, mean_net_lifetime: 3842.7825, mean_mc_travel_dist: 1363.1855, mean_rewards: 222.0629, total_rewards: 2511.4635, mean_steps: 17.8000, mean_ecr: 0.0401 mean_entropies: 1.9638, took: 95.1380s
2022-10-09 03:21:25,866 [INFO] 	Process 2 - batch 13299: mean_policy_losses: -222.708, mean_net_lifetime: 3909.9827, mean_mc_travel_dist: 1409.6092, mean_rewards: 219.7614, total_rewards: 2535.8025, mean_steps: 18.6500, mean_ecr: 0.0381 mean_entropies: 1.9434, took: 99.2589s
2022-10-09 03:21:29,194 [INFO] 	Process 3 - batch 13299: mean_policy_losses: -152.709, mean_net_lifetime: 4098.2703, mean_mc_travel_dist: 1450.5339, mean_rewards: 227.1562, total_rewards: 2689.3294, mean_steps: 19.2000, mean_ecr: 0.0378 mean_entropies: 1.9572, took: 99.4549s
2022-10-09 03:21:32,432 [INFO] 	Process 4 - batch 13299: mean_policy_losses: -206.988, mean_net_lifetime: 4036.7125, mean_mc_travel_dist: 1460.8325, mean_rewards: 217.6043, total_rewards: 2627.1907, mean_steps: 19.6100, mean_ecr: 0.0380 mean_entropies: 1.9465, took: 102.3815s
2022-10-09 03:21:45,953 [INFO] 	Process 1 - batch 13499: mean_policy_losses: -55.654, mean_net_lifetime: 4205.8894, mean_mc_travel_dist: 1480.8099, mean_rewards: 213.3441, total_rewards: 2769.9250, mean_steps: 20.7300, mean_ecr: 0.0380 mean_entropies: 1.9837, took: 103.2882s
2022-10-09 03:22:36,375 [INFO] 	Process 0 - batch 12799: mean_policy_losses: -69.493, mean_net_lifetime: 3976.8482, mean_mc_travel_dist: 1414.0990, mean_rewards: 211.6979, total_rewards: 2598.8132, mean_steps: 19.3700, mean_ecr: 0.0401 mean_entropies: 1.9459, took: 100.6480s
2022-10-09 03:22:53,913 [INFO] 	Process 6 - batch 13299: mean_policy_losses: -156.203, mean_net_lifetime: 4054.5804, mean_mc_travel_dist: 1423.1267, mean_rewards: 219.6542, total_rewards: 2663.4520, mean_steps: 19.5600, mean_ecr: 0.0384 mean_entropies: 1.9422, took: 103.2530s
2022-10-09 03:22:58,702 [INFO] 	Process 5 - batch 12899: mean_policy_losses: -126.029, mean_net_lifetime: 3967.1944, mean_mc_travel_dist: 1407.6081, mean_rewards: 206.4472, total_rewards: 2600.2299, mean_steps: 19.5900, mean_ecr: 0.0382 mean_entropies: 1.9312, took: 101.7231s
2022-10-09 03:23:13,063 [INFO] 	Process 2 - batch 13399: mean_policy_losses: -86.302, mean_net_lifetime: 4452.4894, mean_mc_travel_dist: 1581.5144, mean_rewards: 215.8807, total_rewards: 2908.3622, mean_steps: 21.4000, mean_ecr: 0.0385 mean_entropies: 2.0222, took: 107.1966s
2022-10-09 03:23:16,950 [INFO] 	Process 4 - batch 13399: mean_policy_losses: -67.262, mean_net_lifetime: 4370.1346, mean_mc_travel_dist: 1573.2349, mean_rewards: 215.9234, total_rewards: 2837.1693, mean_steps: 20.9500, mean_ecr: 0.0384 mean_entropies: 2.0366, took: 104.5167s
2022-10-09 03:23:17,292 [INFO] 	Process 3 - batch 13399: mean_policy_losses: -62.229, mean_net_lifetime: 4373.9160, mean_mc_travel_dist: 1543.9990, mean_rewards: 212.6075, total_rewards: 2864.8907, mean_steps: 21.1500, mean_ecr: 0.0388 mean_entropies: 2.0484, took: 108.0972s
2022-10-09 03:24:14,763 [INFO] 	Process 0 - batch 12899: mean_policy_losses: -179.168, mean_net_lifetime: 3971.4032, mean_mc_travel_dist: 1398.5883, mean_rewards: 214.2963, total_rewards: 2621.7420, mean_steps: 18.8400, mean_ecr: 0.0378 mean_entropies: 1.9622, took: 98.3890s
2022-10-09 03:24:38,638 [INFO] 	Process 6 - batch 13399: mean_policy_losses: -149.350, mean_net_lifetime: 4380.5042, mean_mc_travel_dist: 1564.7003, mean_rewards: 218.1511, total_rewards: 2871.7919, mean_steps: 20.9200, mean_ecr: 0.0384 mean_entropies: 2.0382, took: 104.7262s
2022-10-09 03:24:46,701 [INFO] 	Process 5 - batch 12999: mean_policy_losses: -161.948, mean_net_lifetime: 4196.1305, mean_mc_travel_dist: 1532.0479, mean_rewards: 210.2155, total_rewards: 2705.6537, mean_steps: 21.1900, mean_ecr: 0.0379 mean_entropies: 1.9444, took: 107.9989s
2022-10-09 03:24:53,470 [INFO] 	Process 4 - batch 13499: mean_policy_losses: -172.916, mean_net_lifetime: 4020.1344, mean_mc_travel_dist: 1408.3357, mean_rewards: 217.5017, total_rewards: 2646.4264, mean_steps: 18.7700, mean_ecr: 0.0383 mean_entropies: 1.9840, took: 96.5221s
2022-10-09 03:24:54,517 [INFO] 	Process 2 - batch 13499: mean_policy_losses: -147.927, mean_net_lifetime: 4100.9401, mean_mc_travel_dist: 1424.2999, mean_rewards: 212.4445, total_rewards: 2716.2388, mean_steps: 19.7900, mean_ecr: 0.0382 mean_entropies: 1.9889, took: 101.4548s
2022-10-09 03:24:54,809 [INFO] 	Process 3 - batch 13499: mean_policy_losses: -172.282, mean_net_lifetime: 4083.7398, mean_mc_travel_dist: 1424.5451, mean_rewards: 221.3395, total_rewards: 2694.6628, mean_steps: 18.8800, mean_ecr: 0.0380 mean_entropies: 1.9965, took: 97.5174s
2022-10-09 03:25:52,599 [INFO] 	Process 0 - batch 12999: mean_policy_losses: -99.708, mean_net_lifetime: 4276.1693, mean_mc_travel_dist: 1589.2156, mean_rewards: 215.8075, total_rewards: 2729.2915, mean_steps: 20.6500, mean_ecr: 0.0375 mean_entropies: 1.9443, took: 97.8349s
2022-10-09 03:26:08,482 [INFO] 	Process 5 - batch 13099: mean_policy_losses: -173.587, mean_net_lifetime: 3707.7836, mean_mc_travel_dist: 1306.3185, mean_rewards: 217.5701, total_rewards: 2439.0981, mean_steps: 17.3900, mean_ecr: 0.0393 mean_entropies: 1.9221, took: 81.7804s
2022-10-09 03:26:09,961 [INFO] 	Process 6 - batch 13499: mean_policy_losses: -47.479, mean_net_lifetime: 4191.5659, mean_mc_travel_dist: 1487.1961, mean_rewards: 219.0332, total_rewards: 2740.5528, mean_steps: 19.3200, mean_ecr: 0.0384 mean_entropies: 1.9922, took: 91.3224s
2022-10-09 03:27:21,069 [INFO] 	Process 0 - batch 13099: mean_policy_losses: -88.164, mean_net_lifetime: 4083.6923, mean_mc_travel_dist: 1425.9238, mean_rewards: 217.4319, total_rewards: 2698.0052, mean_steps: 19.7700, mean_ecr: 0.0392 mean_entropies: 1.9227, took: 88.4696s
2022-10-09 03:27:32,450 [INFO] 	Process 5 - batch 13199: mean_policy_losses: -124.028, mean_net_lifetime: 3944.3069, mean_mc_travel_dist: 1364.7711, mean_rewards: 216.9774, total_rewards: 2611.4806, mean_steps: 18.8300, mean_ecr: 0.0401 mean_entropies: 1.9633, took: 83.9685s
2022-10-09 03:28:43,694 [INFO] 	Process 0 - batch 13199: mean_policy_losses: -41.558, mean_net_lifetime: 3667.7738, mean_mc_travel_dist: 1277.5881, mean_rewards: 215.4566, total_rewards: 2430.6091, mean_steps: 17.7800, mean_ecr: 0.0405 mean_entropies: 1.9615, took: 82.6252s
2022-10-09 03:28:51,986 [INFO] 	Process 5 - batch 13299: mean_policy_losses: -90.035, mean_net_lifetime: 3707.2223, mean_mc_travel_dist: 1313.5497, mean_rewards: 215.6457, total_rewards: 2442.7783, mean_steps: 17.8400, mean_ecr: 0.0384 mean_entropies: 1.8869, took: 79.5369s
2022-10-09 03:30:08,785 [INFO] 	Process 0 - batch 13299: mean_policy_losses: -165.933, mean_net_lifetime: 3798.4751, mean_mc_travel_dist: 1356.9080, mean_rewards: 209.8270, total_rewards: 2478.4528, mean_steps: 18.9900, mean_ecr: 0.0380 mean_entropies: 1.9030, took: 85.0923s
2022-10-09 03:30:29,151 [INFO] 	Process 5 - batch 13399: mean_policy_losses: -53.021, mean_net_lifetime: 4463.0428, mean_mc_travel_dist: 1616.8397, mean_rewards: 214.8944, total_rewards: 2878.0648, mean_steps: 22.2200, mean_ecr: 0.0383 mean_entropies: 1.9979, took: 97.1639s
2022-10-09 03:31:43,411 [INFO] 	Process 0 - batch 13399: mean_policy_losses: -97.455, mean_net_lifetime: 4294.0082, mean_mc_travel_dist: 1535.1782, mean_rewards: 206.2626, total_rewards: 2805.6990, mean_steps: 21.0900, mean_ecr: 0.0385 mean_entropies: 2.0088, took: 94.6248s
2022-10-09 03:31:50,890 [INFO] 	Process 5 - batch 13499: mean_policy_losses: -186.488, mean_net_lifetime: 3874.2294, mean_mc_travel_dist: 1351.7953, mean_rewards: 215.5012, total_rewards: 2561.2822, mean_steps: 18.2200, mean_ecr: 0.0384 mean_entropies: 1.9422, took: 81.7395s
2022-10-09 03:33:13,416 [INFO] 	Process 0 - batch 13499: mean_policy_losses: -130.252, mean_net_lifetime: 4334.0343, mean_mc_travel_dist: 1585.3866, mean_rewards: 212.2280, total_rewards: 2789.4279, mean_steps: 20.7300, mean_ecr: 0.0377 mean_entropies: 1.9763, took: 90.0057s
2022-10-09 03:35:09,513 [INFO] 	Process 1 - batch 13599: mean_policy_losses: -81.153, mean_net_lifetime: 3699.4988, mean_mc_travel_dist: 1329.5030, mean_rewards: 220.4024, total_rewards: 2417.8367, mean_steps: 17.4600, mean_ecr: 0.0390 mean_entropies: 1.8939, took: 803.5608s
2022-10-09 03:36:54,809 [INFO] 	Process 1 - batch 13699: mean_policy_losses: -52.871, mean_net_lifetime: 4826.5541, mean_mc_travel_dist: 1845.7654, mean_rewards: 218.5790, total_rewards: 3013.1052, mean_steps: 26.1500, mean_ecr: 0.0386 mean_entropies: 1.8575, took: 105.2952s
2022-10-09 03:37:32,608 [INFO] 	Process 2 - batch 13599: mean_policy_losses: -43.038, mean_net_lifetime: 3780.8083, mean_mc_travel_dist: 1339.2447, mean_rewards: 217.1661, total_rewards: 2486.0805, mean_steps: 17.7200, mean_ecr: 0.0389 mean_entropies: 1.9087, took: 758.0898s
2022-10-09 03:37:54,846 [INFO] 	Process 4 - batch 13599: mean_policy_losses: -72.692, mean_net_lifetime: 3735.6972, mean_mc_travel_dist: 1331.8078, mean_rewards: 220.4380, total_rewards: 2444.3122, mean_steps: 17.1400, mean_ecr: 0.0390 mean_entropies: 1.8923, took: 781.3751s
2022-10-09 03:38:18,614 [INFO] 	Process 1 - batch 13799: mean_policy_losses: -139.581, mean_net_lifetime: 3752.0141, mean_mc_travel_dist: 1332.7049, mean_rewards: 221.9223, total_rewards: 2467.0661, mean_steps: 17.9000, mean_ecr: 0.0385 mean_entropies: 1.8938, took: 83.8062s
2022-10-09 03:38:18,797 [INFO] 	Process 3 - batch 13599: mean_policy_losses: -21.185, mean_net_lifetime: 3659.1475, mean_mc_travel_dist: 1278.5222, mean_rewards: 216.7231, total_rewards: 2423.0759, mean_steps: 17.0700, mean_ecr: 0.0392 mean_entropies: 1.9072, took: 803.9871s
2022-10-09 03:38:33,004 [INFO] 	Process 6 - batch 13599: mean_policy_losses: -5.809, mean_net_lifetime: 3706.1166, mean_mc_travel_dist: 1313.1054, mean_rewards: 210.3858, total_rewards: 2426.9795, mean_steps: 18.0500, mean_ecr: 0.0391 mean_entropies: 1.9053, took: 743.0427s
2022-10-09 03:39:24,052 [INFO] 	Process 2 - batch 13699: mean_policy_losses: 10.219, mean_net_lifetime: 4408.9641, mean_mc_travel_dist: 1625.6128, mean_rewards: 213.2876, total_rewards: 2824.4119, mean_steps: 23.0100, mean_ecr: 0.0387 mean_entropies: 1.8721, took: 111.4431s
2022-10-09 03:39:58,038 [INFO] 	Process 4 - batch 13699: mean_policy_losses: -161.894, mean_net_lifetime: 4630.7474, mean_mc_travel_dist: 1736.1515, mean_rewards: 223.3437, total_rewards: 2935.1144, mean_steps: 25.2900, mean_ecr: 0.0384 mean_entropies: 1.8347, took: 123.1929s
2022-10-09 03:40:27,812 [INFO] 	Process 1 - batch 13899: mean_policy_losses: -19.305, mean_net_lifetime: 4796.0576, mean_mc_travel_dist: 1914.2975, mean_rewards: 219.6421, total_rewards: 2925.8713, mean_steps: 28.1700, mean_ecr: 0.0403 mean_entropies: 1.8525, took: 129.1975s
2022-10-09 03:40:41,708 [INFO] 	Process 3 - batch 13699: mean_policy_losses: -15.152, mean_net_lifetime: 5286.4682, mean_mc_travel_dist: 2020.9411, mean_rewards: 212.8140, total_rewards: 3306.7672, mean_steps: 30.2900, mean_ecr: 0.0387 mean_entropies: 1.8671, took: 142.9123s
2022-10-09 03:40:56,675 [INFO] 	Process 2 - batch 13799: mean_policy_losses: -157.971, mean_net_lifetime: 3831.0459, mean_mc_travel_dist: 1349.2812, mean_rewards: 217.1750, total_rewards: 2521.1855, mean_steps: 18.3600, mean_ecr: 0.0389 mean_entropies: 1.8552, took: 92.6249s
2022-10-09 03:41:02,217 [INFO] 	Process 6 - batch 13699: mean_policy_losses: -6.859, mean_net_lifetime: 5364.9144, mean_mc_travel_dist: 2042.8018, mean_rewards: 218.1697, total_rewards: 3362.5156, mean_steps: 30.7400, mean_ecr: 0.0384 mean_entropies: 1.8632, took: 149.2144s
2022-10-09 03:41:38,013 [INFO] 	Process 4 - batch 13799: mean_policy_losses: -104.205, mean_net_lifetime: 4121.9775, mean_mc_travel_dist: 1489.8983, mean_rewards: 216.9301, total_rewards: 2673.2037, mean_steps: 20.3500, mean_ecr: 0.0384 mean_entropies: 1.8758, took: 99.9749s
2022-10-09 03:41:53,149 [INFO] 	Process 1 - batch 13999: mean_policy_losses: -149.856, mean_net_lifetime: 3731.4866, mean_mc_travel_dist: 1299.6416, mean_rewards: 216.5542, total_rewards: 2467.7381, mean_steps: 17.9800, mean_ecr: 0.0398 mean_entropies: 1.8656, took: 85.3361s
2022-10-09 03:42:07,332 [INFO] 	Process 3 - batch 13799: mean_policy_losses: -169.530, mean_net_lifetime: 3746.6344, mean_mc_travel_dist: 1283.2377, mean_rewards: 218.5287, total_rewards: 2500.5858, mean_steps: 17.6600, mean_ecr: 0.0387 mean_entropies: 1.8932, took: 85.6237s
2022-10-09 03:42:32,172 [INFO] 	Process 2 - batch 13899: mean_policy_losses: -81.837, mean_net_lifetime: 3912.5135, mean_mc_travel_dist: 1424.7365, mean_rewards: 220.4183, total_rewards: 2526.0761, mean_steps: 19.5300, mean_ecr: 0.0403 mean_entropies: 1.8445, took: 95.4939s
2022-10-09 03:42:42,693 [INFO] 	Process 6 - batch 13799: mean_policy_losses: -163.818, mean_net_lifetime: 4313.5108, mean_mc_travel_dist: 1583.1746, mean_rewards: 225.2035, total_rewards: 2763.7405, mean_steps: 20.4700, mean_ecr: 0.0385 mean_entropies: 1.8819, took: 100.4754s
2022-10-09 03:43:19,951 [INFO] 	Process 1 - batch 14099: mean_policy_losses: -66.099, mean_net_lifetime: 3892.4751, mean_mc_travel_dist: 1343.2527, mean_rewards: 227.0762, total_rewards: 2586.5143, mean_steps: 18.2400, mean_ecr: 0.0382 mean_entropies: 1.8805, took: 86.8023s
2022-10-09 03:43:34,406 [INFO] 	Process 4 - batch 13899: mean_policy_losses: -101.934, mean_net_lifetime: 4437.4637, mean_mc_travel_dist: 1758.2501, mean_rewards: 224.8507, total_rewards: 2721.0675, mean_steps: 24.4100, mean_ecr: 0.0407 mean_entropies: 1.8485, took: 116.3920s
2022-10-09 03:43:43,975 [INFO] 	Process 3 - batch 13899: mean_policy_losses: -195.930, mean_net_lifetime: 3814.2354, mean_mc_travel_dist: 1411.9660, mean_rewards: 219.0989, total_rewards: 2443.5651, mean_steps: 19.2700, mean_ecr: 0.0404 mean_entropies: 1.8218, took: 96.6438s
2022-10-09 03:44:03,860 [INFO] 	Process 2 - batch 13999: mean_policy_losses: -132.157, mean_net_lifetime: 3800.6499, mean_mc_travel_dist: 1299.0715, mean_rewards: 228.9349, total_rewards: 2531.9679, mean_steps: 17.9800, mean_ecr: 0.0396 mean_entropies: 1.8593, took: 91.6916s
2022-10-09 03:44:38,007 [INFO] 	Process 6 - batch 13899: mean_policy_losses: -87.401, mean_net_lifetime: 4398.6469, mean_mc_travel_dist: 1734.0783, mean_rewards: 230.5951, total_rewards: 2697.1717, mean_steps: 23.9600, mean_ecr: 0.0408 mean_entropies: 1.8370, took: 115.3131s
2022-10-09 03:44:51,923 [INFO] 	Process 1 - batch 14199: mean_policy_losses: -88.464, mean_net_lifetime: 3976.0681, mean_mc_travel_dist: 1445.9500, mean_rewards: 210.2075, total_rewards: 2569.5653, mean_steps: 19.5700, mean_ecr: 0.0388 mean_entropies: 1.8788, took: 91.9720s
2022-10-09 03:45:05,683 [INFO] 	Process 4 - batch 13999: mean_policy_losses: -120.615, mean_net_lifetime: 3805.2324, mean_mc_travel_dist: 1297.8777, mean_rewards: 221.2319, total_rewards: 2541.4145, mean_steps: 18.1700, mean_ecr: 0.0391 mean_entropies: 1.8831, took: 91.2781s
2022-10-09 03:45:21,562 [INFO] 	Process 3 - batch 13999: mean_policy_losses: -71.874, mean_net_lifetime: 4088.5707, mean_mc_travel_dist: 1430.4140, mean_rewards: 224.6639, total_rewards: 2699.4679, mean_steps: 19.2700, mean_ecr: 0.0393 mean_entropies: 1.8882, took: 97.5850s
2022-10-09 03:45:33,411 [INFO] 	Process 2 - batch 14099: mean_policy_losses: -172.402, mean_net_lifetime: 3666.1318, mean_mc_travel_dist: 1297.0804, mean_rewards: 222.9910, total_rewards: 2407.0976, mean_steps: 17.3000, mean_ecr: 0.0381 mean_entropies: 1.8878, took: 89.5499s
2022-10-09 03:46:15,045 [INFO] 	Process 5 - batch 13599: mean_policy_losses: -23.170, mean_net_lifetime: 3921.3754, mean_mc_travel_dist: 1339.0079, mean_rewards: 212.3000, total_rewards: 2626.8132, mean_steps: 18.8700, mean_ecr: 0.0389 mean_entropies: 1.8930, took: 864.1542s
2022-10-09 03:46:15,469 [INFO] 	Process 6 - batch 13999: mean_policy_losses: -158.494, mean_net_lifetime: 3876.3563, mean_mc_travel_dist: 1350.5987, mean_rewards: 226.1447, total_rewards: 2564.5681, mean_steps: 18.6600, mean_ecr: 0.0389 mean_entropies: 1.8764, took: 97.4628s
2022-10-09 03:46:18,800 [INFO] 	Process 1 - batch 14299: mean_policy_losses: -135.236, mean_net_lifetime: 3706.1067, mean_mc_travel_dist: 1265.6646, mean_rewards: 218.0751, total_rewards: 2485.0283, mean_steps: 17.6500, mean_ecr: 0.0381 mean_entropies: 1.9365, took: 86.8774s
2022-10-09 03:46:30,736 [INFO] 	Process 4 - batch 14099: mean_policy_losses: -193.534, mean_net_lifetime: 3514.1374, mean_mc_travel_dist: 1194.3873, mean_rewards: 230.8311, total_rewards: 2349.6481, mean_steps: 16.1200, mean_ecr: 0.0389 mean_entropies: 1.8311, took: 85.0519s
2022-10-09 03:46:54,320 [INFO] 	Process 3 - batch 14099: mean_policy_losses: -82.439, mean_net_lifetime: 3754.4954, mean_mc_travel_dist: 1295.0927, mean_rewards: 220.7088, total_rewards: 2496.2499, mean_steps: 17.6300, mean_ecr: 0.0387 mean_entropies: 1.8588, took: 92.7590s
2022-10-09 03:47:06,903 [INFO] 	Process 2 - batch 14199: mean_policy_losses: -174.199, mean_net_lifetime: 3668.8948, mean_mc_travel_dist: 1290.7149, mean_rewards: 211.3689, total_rewards: 2422.1774, mean_steps: 17.6400, mean_ecr: 0.0389 mean_entropies: 1.8645, took: 93.4928s
2022-10-09 03:47:34,177 [INFO] 	Process 0 - batch 13599: mean_policy_losses: -34.051, mean_net_lifetime: 3910.4327, mean_mc_travel_dist: 1363.3778, mean_rewards: 214.7405, total_rewards: 2583.7542, mean_steps: 18.9400, mean_ecr: 0.0388 mean_entropies: 1.8604, took: 860.7604s
2022-10-09 03:47:51,191 [INFO] 	Process 6 - batch 14099: mean_policy_losses: -139.028, mean_net_lifetime: 3814.4868, mean_mc_travel_dist: 1346.4201, mean_rewards: 219.8177, total_rewards: 2510.3915, mean_steps: 18.0300, mean_ecr: 0.0389 mean_entropies: 1.8429, took: 95.7226s
2022-10-09 03:47:54,062 [INFO] 	Process 1 - batch 14399: mean_policy_losses: 4.745, mean_net_lifetime: 4087.9336, mean_mc_travel_dist: 1453.3799, mean_rewards: 216.3572, total_rewards: 2677.2279, mean_steps: 19.0300, mean_ecr: 0.0392 mean_entropies: 1.8930, took: 95.2615s
2022-10-09 03:47:58,788 [INFO] 	Process 5 - batch 13699: mean_policy_losses: -117.476, mean_net_lifetime: 3953.6061, mean_mc_travel_dist: 1414.3467, mean_rewards: 219.6344, total_rewards: 2581.2528, mean_steps: 20.0800, mean_ecr: 0.0386 mean_entropies: 1.8568, took: 103.7426s
2022-10-09 03:48:11,735 [INFO] 	Process 4 - batch 14199: mean_policy_losses: -103.031, mean_net_lifetime: 4008.7473, mean_mc_travel_dist: 1477.5552, mean_rewards: 214.2125, total_rewards: 2571.3342, mean_steps: 19.2000, mean_ecr: 0.0387 mean_entropies: 1.8512, took: 100.9998s
2022-10-09 03:48:26,043 [INFO] 	Process 3 - batch 14199: mean_policy_losses: -165.076, mean_net_lifetime: 3652.8107, mean_mc_travel_dist: 1254.4220, mean_rewards: 223.1471, total_rewards: 2441.9680, mean_steps: 16.9300, mean_ecr: 0.0388 mean_entropies: 1.8435, took: 91.7228s
2022-10-09 03:48:50,687 [INFO] 	Process 2 - batch 14299: mean_policy_losses: -65.254, mean_net_lifetime: 3977.4250, mean_mc_travel_dist: 1382.1642, mean_rewards: 218.2955, total_rewards: 2630.7578, mean_steps: 19.0500, mean_ecr: 0.0376 mean_entropies: 1.9369, took: 103.7833s
2022-10-09 03:49:30,208 [INFO] 	Process 0 - batch 13699: mean_policy_losses: -113.883, mean_net_lifetime: 3962.1093, mean_mc_travel_dist: 1410.9029, mean_rewards: 215.6063, total_rewards: 2589.8463, mean_steps: 20.2400, mean_ecr: 0.0389 mean_entropies: 1.8369, took: 116.0311s
2022-10-09 03:49:46,733 [INFO] 	Process 6 - batch 14199: mean_policy_losses: -92.824, mean_net_lifetime: 4064.0096, mean_mc_travel_dist: 1458.2336, mean_rewards: 213.0030, total_rewards: 2640.8384, mean_steps: 19.8000, mean_ecr: 0.0386 mean_entropies: 1.8300, took: 115.5415s
2022-10-09 03:49:48,260 [INFO] 	Process 1 - batch 14499: mean_policy_losses: -159.544, mean_net_lifetime: 3971.3781, mean_mc_travel_dist: 1415.9048, mean_rewards: 208.0222, total_rewards: 2588.2909, mean_steps: 20.5900, mean_ecr: 0.0385 mean_entropies: 1.8804, took: 114.1981s
2022-10-09 03:50:04,236 [INFO] 	Process 5 - batch 13799: mean_policy_losses: -189.963, mean_net_lifetime: 4277.3765, mean_mc_travel_dist: 1526.0509, mean_rewards: 219.1883, total_rewards: 2790.8998, mean_steps: 20.9900, mean_ecr: 0.0386 mean_entropies: 1.8482, took: 125.4489s
2022-10-09 03:50:06,682 [INFO] 	Process 4 - batch 14299: mean_policy_losses: -144.575, mean_net_lifetime: 3890.2825, mean_mc_travel_dist: 1350.5248, mean_rewards: 217.0364, total_rewards: 2582.8883, mean_steps: 18.7200, mean_ecr: 0.0376 mean_entropies: 1.9161, took: 114.9457s
2022-10-09 03:50:20,978 [INFO] 	Process 3 - batch 14299: mean_policy_losses: -98.344, mean_net_lifetime: 3872.6551, mean_mc_travel_dist: 1345.4570, mean_rewards: 213.3438, total_rewards: 2569.4498, mean_steps: 18.4200, mean_ecr: 0.0378 mean_entropies: 1.9358, took: 114.9353s
2022-10-09 03:50:50,084 [INFO] 	Process 2 - batch 14399: mean_policy_losses: -43.765, mean_net_lifetime: 4074.8800, mean_mc_travel_dist: 1399.6791, mean_rewards: 220.6913, total_rewards: 2704.3013, mean_steps: 19.2600, mean_ecr: 0.0391 mean_entropies: 1.8742, took: 119.3974s
2022-10-09 03:51:28,458 [INFO] 	Process 1 - batch 14599: mean_policy_losses: -80.721, mean_net_lifetime: 3596.1074, mean_mc_travel_dist: 1222.2284, mean_rewards: 228.2227, total_rewards: 2411.1338, mean_steps: 16.7100, mean_ecr: 0.0402 mean_entropies: 1.8127, took: 100.1983s
2022-10-09 03:51:29,572 [INFO] 	Process 0 - batch 13799: mean_policy_losses: -78.757, mean_net_lifetime: 3933.7453, mean_mc_travel_dist: 1376.5236, mean_rewards: 215.7709, total_rewards: 2596.3475, mean_steps: 19.2400, mean_ecr: 0.0386 mean_entropies: 1.8802, took: 119.3651s
2022-10-09 03:51:41,136 [INFO] 	Process 6 - batch 14299: mean_policy_losses: -117.529, mean_net_lifetime: 3802.9422, mean_mc_travel_dist: 1327.5539, mean_rewards: 212.2375, total_rewards: 2518.3757, mean_steps: 18.5100, mean_ecr: 0.0375 mean_entropies: 1.9253, took: 114.4011s
2022-10-09 03:51:52,385 [INFO] 	Process 5 - batch 13899: mean_policy_losses: -128.334, mean_net_lifetime: 3604.7717, mean_mc_travel_dist: 1296.2785, mean_rewards: 224.2682, total_rewards: 2339.7520, mean_steps: 17.3400, mean_ecr: 0.0410 mean_entropies: 1.8020, took: 108.1491s
2022-10-09 03:51:52,821 [INFO] 	Process 4 - batch 14399: mean_policy_losses: -77.271, mean_net_lifetime: 3732.8071, mean_mc_travel_dist: 1285.2050, mean_rewards: 228.2591, total_rewards: 2483.6429, mean_steps: 16.8900, mean_ecr: 0.0396 mean_entropies: 1.8589, took: 106.1401s
2022-10-09 03:52:04,537 [INFO] 	Process 3 - batch 14399: mean_policy_losses: -106.359, mean_net_lifetime: 3675.3406, mean_mc_travel_dist: 1299.7956, mean_rewards: 224.0672, total_rewards: 2417.2335, mean_steps: 16.4600, mean_ecr: 0.0395 mean_entropies: 1.8636, took: 103.5595s
2022-10-09 03:52:51,629 [INFO] 	Process 2 - batch 14499: mean_policy_losses: -108.435, mean_net_lifetime: 3970.8081, mean_mc_travel_dist: 1446.9348, mean_rewards: 216.7456, total_rewards: 2558.9140, mean_steps: 19.3900, mean_ecr: 0.0386 mean_entropies: 1.8838, took: 121.5451s
2022-10-09 03:53:15,926 [INFO] 	Process 0 - batch 13899: mean_policy_losses: -160.851, mean_net_lifetime: 3565.5045, mean_mc_travel_dist: 1231.7867, mean_rewards: 223.8377, total_rewards: 2362.5978, mean_steps: 16.9300, mean_ecr: 0.0400 mean_entropies: 1.8156, took: 106.3530s
2022-10-09 03:53:25,442 [INFO] 	Process 1 - batch 14699: mean_policy_losses: 52.034, mean_net_lifetime: 4170.8937, mean_mc_travel_dist: 1465.9312, mean_rewards: 217.0329, total_rewards: 2747.1406, mean_steps: 19.8300, mean_ecr: 0.0399 mean_entropies: 1.9422, took: 116.9841s
2022-10-09 03:53:26,960 [INFO] 	Process 6 - batch 14399: mean_policy_losses: -142.968, mean_net_lifetime: 3680.2462, mean_mc_travel_dist: 1291.6767, mean_rewards: 218.8910, total_rewards: 2427.5414, mean_steps: 16.9700, mean_ecr: 0.0399 mean_entropies: 1.8803, took: 105.8250s
2022-10-09 03:53:55,053 [INFO] 	Process 5 - batch 13999: mean_policy_losses: -70.841, mean_net_lifetime: 4152.8842, mean_mc_travel_dist: 1430.7997, mean_rewards: 225.3342, total_rewards: 2757.3293, mean_steps: 19.6600, mean_ecr: 0.0387 mean_entropies: 1.8857, took: 122.6677s
2022-10-09 03:54:00,496 [INFO] 	Process 3 - batch 14499: mean_policy_losses: -88.505, mean_net_lifetime: 3952.8793, mean_mc_travel_dist: 1402.8276, mean_rewards: 220.4662, total_rewards: 2581.6411, mean_steps: 18.7200, mean_ecr: 0.0385 mean_entropies: 1.8967, took: 115.9576s
2022-10-09 03:54:00,998 [INFO] 	Process 4 - batch 14499: mean_policy_losses: -138.003, mean_net_lifetime: 4143.2247, mean_mc_travel_dist: 1535.6467, mean_rewards: 207.2186, total_rewards: 2652.8937, mean_steps: 21.0300, mean_ecr: 0.0387 mean_entropies: 1.8908, took: 128.1757s
2022-10-09 03:54:40,529 [INFO] 	Process 2 - batch 14599: mean_policy_losses: -96.412, mean_net_lifetime: 3745.1162, mean_mc_travel_dist: 1295.5469, mean_rewards: 225.8310, total_rewards: 2494.7080, mean_steps: 17.4500, mean_ecr: 0.0400 mean_entropies: 1.8165, took: 108.8989s
2022-10-09 03:55:05,810 [INFO] 	Process 0 - batch 13999: mean_policy_losses: -176.943, mean_net_lifetime: 3632.5222, mean_mc_travel_dist: 1220.5003, mean_rewards: 221.5695, total_rewards: 2443.2924, mean_steps: 17.2700, mean_ecr: 0.0399 mean_entropies: 1.8363, took: 109.8841s
2022-10-09 03:55:26,923 [INFO] 	Process 1 - batch 14799: mean_policy_losses: -46.517, mean_net_lifetime: 4211.7828, mean_mc_travel_dist: 1509.1653, mean_rewards: 216.5116, total_rewards: 2743.1290, mean_steps: 20.6600, mean_ecr: 0.0386 mean_entropies: 1.8541, took: 121.4810s
2022-10-09 03:55:39,475 [INFO] 	Process 4 - batch 14599: mean_policy_losses: -175.194, mean_net_lifetime: 3442.7327, mean_mc_travel_dist: 1154.0678, mean_rewards: 231.2137, total_rewards: 2327.1651, mean_steps: 15.6400, mean_ecr: 0.0403 mean_entropies: 1.8084, took: 98.4786s
2022-10-09 03:55:40,937 [INFO] 	Process 5 - batch 14099: mean_policy_losses: -170.742, mean_net_lifetime: 3638.9071, mean_mc_travel_dist: 1249.6083, mean_rewards: 221.1163, total_rewards: 2423.9548, mean_steps: 16.8900, mean_ecr: 0.0392 mean_entropies: 1.8322, took: 105.8837s
2022-10-09 03:55:42,015 [INFO] 	Process 6 - batch 14499: mean_policy_losses: -94.819, mean_net_lifetime: 4315.6834, mean_mc_travel_dist: 1582.0220, mean_rewards: 210.7344, total_rewards: 2772.8208, mean_steps: 21.6600, mean_ecr: 0.0388 mean_entropies: 1.8928, took: 135.0556s
2022-10-09 03:55:44,815 [INFO] 	Process 3 - batch 14599: mean_policy_losses: -140.272, mean_net_lifetime: 3536.6174, mean_mc_travel_dist: 1206.9988, mean_rewards: 227.6011, total_rewards: 2359.6381, mean_steps: 16.4200, mean_ecr: 0.0402 mean_entropies: 1.8135, took: 104.3197s
2022-10-09 03:56:47,092 [INFO] 	Process 2 - batch 14699: mean_policy_losses: -10.367, mean_net_lifetime: 4304.9811, mean_mc_travel_dist: 1539.7164, mean_rewards: 216.1014, total_rewards: 2806.4301, mean_steps: 20.6000, mean_ecr: 0.0398 mean_entropies: 1.9106, took: 126.5637s
2022-10-09 03:56:50,874 [INFO] 	Process 0 - batch 14099: mean_policy_losses: -185.125, mean_net_lifetime: 3694.8902, mean_mc_travel_dist: 1288.4459, mean_rewards: 231.7519, total_rewards: 2445.0371, mean_steps: 16.6700, mean_ecr: 0.0382 mean_entropies: 1.8373, took: 105.0645s
2022-10-09 03:57:10,778 [INFO] 	Process 1 - batch 14899: mean_policy_losses: -115.255, mean_net_lifetime: 3744.6111, mean_mc_travel_dist: 1300.5527, mean_rewards: 225.3628, total_rewards: 2484.1171, mean_steps: 17.3000, mean_ecr: 0.0394 mean_entropies: 1.8512, took: 103.8550s
2022-10-09 03:57:31,454 [INFO] 	Process 5 - batch 14199: mean_policy_losses: -201.252, mean_net_lifetime: 3707.4776, mean_mc_travel_dist: 1334.8967, mean_rewards: 216.0017, total_rewards: 2416.3464, mean_steps: 17.5900, mean_ecr: 0.0388 mean_entropies: 1.8223, took: 110.5182s
2022-10-09 03:57:33,216 [INFO] 	Process 6 - batch 14599: mean_policy_losses: -44.861, mean_net_lifetime: 3921.7143, mean_mc_travel_dist: 1344.5321, mean_rewards: 227.8666, total_rewards: 2612.2124, mean_steps: 17.7400, mean_ecr: 0.0400 mean_entropies: 1.8117, took: 111.2004s
2022-10-09 03:57:40,723 [INFO] 	Process 3 - batch 14699: mean_policy_losses: -69.130, mean_net_lifetime: 4007.4048, mean_mc_travel_dist: 1376.0087, mean_rewards: 221.8179, total_rewards: 2667.8761, mean_steps: 18.9300, mean_ecr: 0.0396 mean_entropies: 1.8861, took: 115.9082s
2022-10-09 03:57:58,328 [INFO] 	Process 4 - batch 14699: mean_policy_losses: 15.151, mean_net_lifetime: 4630.2105, mean_mc_travel_dist: 1627.6265, mean_rewards: 221.2193, total_rewards: 3035.2383, mean_steps: 22.5300, mean_ecr: 0.0393 mean_entropies: 1.9036, took: 138.8513s
2022-10-09 03:58:42,798 [INFO] 	Process 0 - batch 14199: mean_policy_losses: -150.957, mean_net_lifetime: 3851.4198, mean_mc_travel_dist: 1396.8139, mean_rewards: 220.9163, total_rewards: 2489.1391, mean_steps: 17.8600, mean_ecr: 0.0387 mean_entropies: 1.8195, took: 111.9223s
2022-10-09 03:58:45,898 [INFO] 	Process 2 - batch 14799: mean_policy_losses: -105.870, mean_net_lifetime: 4072.3304, mean_mc_travel_dist: 1499.9448, mean_rewards: 220.3835, total_rewards: 2611.2470, mean_steps: 19.2200, mean_ecr: 0.0383 mean_entropies: 1.7813, took: 118.8064s
2022-10-09 03:59:07,008 [INFO] 	Process 1 - batch 14999: mean_policy_losses: -83.681, mean_net_lifetime: 4079.9145, mean_mc_travel_dist: 1522.6078, mean_rewards: 215.2999, total_rewards: 2597.4356, mean_steps: 19.6700, mean_ecr: 0.0405 mean_entropies: 1.8447, took: 116.2304s
2022-10-09 03:59:21,878 [INFO] 	Process 5 - batch 14299: mean_policy_losses: -212.418, mean_net_lifetime: 3734.2907, mean_mc_travel_dist: 1338.2064, mean_rewards: 219.3571, total_rewards: 2436.4795, mean_steps: 17.5800, mean_ecr: 0.0375 mean_entropies: 1.8820, took: 110.4233s
2022-10-09 03:59:35,581 [INFO] 	Process 6 - batch 14699: mean_policy_losses: -72.519, mean_net_lifetime: 4087.7985, mean_mc_travel_dist: 1442.6790, mean_rewards: 213.3273, total_rewards: 2678.5255, mean_steps: 19.7600, mean_ecr: 0.0392 mean_entropies: 1.8829, took: 122.3655s
2022-10-09 03:59:40,918 [INFO] 	Process 3 - batch 14799: mean_policy_losses: -14.976, mean_net_lifetime: 4088.9900, mean_mc_travel_dist: 1468.1985, mean_rewards: 214.6620, total_rewards: 2662.8884, mean_steps: 19.5400, mean_ecr: 0.0386 mean_entropies: 1.7783, took: 120.1942s
2022-10-09 03:59:53,188 [INFO] 	Process 4 - batch 14799: mean_policy_losses: -166.005, mean_net_lifetime: 3779.7499, mean_mc_travel_dist: 1382.2410, mean_rewards: 215.4092, total_rewards: 2439.4059, mean_steps: 18.4600, mean_ecr: 0.0387 mean_entropies: 1.7454, took: 114.8607s
2022-10-09 04:00:33,385 [INFO] 	Process 2 - batch 14899: mean_policy_losses: -75.328, mean_net_lifetime: 3842.2917, mean_mc_travel_dist: 1337.0676, mean_rewards: 222.5555, total_rewards: 2527.5524, mean_steps: 17.6700, mean_ecr: 0.0394 mean_entropies: 1.8237, took: 107.4868s
2022-10-09 04:00:35,041 [INFO] 	Process 0 - batch 14299: mean_policy_losses: -180.533, mean_net_lifetime: 3813.9285, mean_mc_travel_dist: 1356.2533, mean_rewards: 220.6865, total_rewards: 2492.1161, mean_steps: 18.2500, mean_ecr: 0.0381 mean_entropies: 1.8896, took: 112.2439s
2022-10-09 04:01:21,231 [INFO] 	Process 5 - batch 14399: mean_policy_losses: -120.113, mean_net_lifetime: 4211.2430, mean_mc_travel_dist: 1528.2516, mean_rewards: 217.5980, total_rewards: 2721.9610, mean_steps: 19.6200, mean_ecr: 0.0391 mean_entropies: 1.8295, took: 119.3527s
2022-10-09 04:01:28,335 [INFO] 	Process 6 - batch 14799: mean_policy_losses: -150.838, mean_net_lifetime: 3850.5218, mean_mc_travel_dist: 1399.7101, mean_rewards: 214.8091, total_rewards: 2492.0055, mean_steps: 18.5900, mean_ecr: 0.0385 mean_entropies: 1.7864, took: 112.7536s
2022-10-09 04:01:34,136 [INFO] 	Process 3 - batch 14899: mean_policy_losses: -71.379, mean_net_lifetime: 4060.3542, mean_mc_travel_dist: 1406.6921, mean_rewards: 218.9792, total_rewards: 2690.6885, mean_steps: 18.7600, mean_ecr: 0.0396 mean_entropies: 1.8332, took: 113.2187s
2022-10-09 04:01:35,843 [INFO] 	Process 4 - batch 14899: mean_policy_losses: -95.303, mean_net_lifetime: 3686.0835, mean_mc_travel_dist: 1276.9031, mean_rewards: 224.5204, total_rewards: 2452.3069, mean_steps: 16.6100, mean_ecr: 0.0396 mean_entropies: 1.8346, took: 102.6554s
2022-10-09 04:02:27,131 [INFO] 	Process 0 - batch 14399: mean_policy_losses: -107.171, mean_net_lifetime: 4000.8954, mean_mc_travel_dist: 1404.1016, mean_rewards: 224.6162, total_rewards: 2638.7363, mean_steps: 18.1800, mean_ecr: 0.0393 mean_entropies: 1.8301, took: 112.0904s
2022-10-09 04:02:27,722 [INFO] 	Process 2 - batch 14999: mean_policy_losses: -126.132, mean_net_lifetime: 3910.1882, mean_mc_travel_dist: 1377.3175, mean_rewards: 214.7447, total_rewards: 2571.3730, mean_steps: 18.4700, mean_ecr: 0.0403 mean_entropies: 1.8595, took: 114.3380s
2022-10-09 04:03:14,202 [INFO] 	Process 5 - batch 14499: mean_policy_losses: -126.185, mean_net_lifetime: 3832.4352, mean_mc_travel_dist: 1369.8906, mean_rewards: 213.7420, total_rewards: 2498.8849, mean_steps: 18.7100, mean_ecr: 0.0389 mean_entropies: 1.8321, took: 112.9712s
2022-10-09 04:03:15,919 [INFO] 	Process 6 - batch 14899: mean_policy_losses: -130.417, mean_net_lifetime: 3861.5226, mean_mc_travel_dist: 1339.5779, mean_rewards: 224.9999, total_rewards: 2556.4718, mean_steps: 17.9300, mean_ecr: 0.0398 mean_entropies: 1.8303, took: 107.5835s
2022-10-09 04:03:30,221 [INFO] 	Process 4 - batch 14999: mean_policy_losses: 16.109, mean_net_lifetime: 4109.3251, mean_mc_travel_dist: 1460.6771, mean_rewards: 211.7648, total_rewards: 2692.2802, mean_steps: 19.4200, mean_ecr: 0.0399 mean_entropies: 1.8530, took: 114.3765s
2022-10-09 04:03:35,399 [INFO] 	Process 3 - batch 14999: mean_policy_losses: -32.553, mean_net_lifetime: 4419.4679, mean_mc_travel_dist: 1685.6991, mean_rewards: 221.1122, total_rewards: 2773.2281, mean_steps: 20.9500, mean_ecr: 0.0399 mean_entropies: 1.8479, took: 121.2636s
2022-10-09 04:04:19,047 [INFO] 	Process 0 - batch 14499: mean_policy_losses: -79.755, mean_net_lifetime: 3979.2770, mean_mc_travel_dist: 1425.0771, mean_rewards: 211.9224, total_rewards: 2592.3274, mean_steps: 19.7400, mean_ecr: 0.0385 mean_entropies: 1.8619, took: 111.9151s
2022-10-09 04:04:48,916 [INFO] 	Process 5 - batch 14599: mean_policy_losses: -126.388, mean_net_lifetime: 3619.1210, mean_mc_travel_dist: 1190.0548, mean_rewards: 227.9510, total_rewards: 2470.2061, mean_steps: 16.7000, mean_ecr: 0.0402 mean_entropies: 1.7768, took: 94.7144s
2022-10-09 04:04:56,394 [INFO] 	Process 6 - batch 14999: mean_policy_losses: -70.966, mean_net_lifetime: 3823.0046, mean_mc_travel_dist: 1317.2713, mean_rewards: 218.2693, total_rewards: 2540.3671, mean_steps: 18.1900, mean_ecr: 0.0404 mean_entropies: 1.8487, took: 100.4762s
2022-10-09 04:05:49,896 [INFO] 	Process 0 - batch 14599: mean_policy_losses: -182.449, mean_net_lifetime: 3645.2627, mean_mc_travel_dist: 1207.1918, mean_rewards: 231.7993, total_rewards: 2468.6737, mean_steps: 16.3000, mean_ecr: 0.0402 mean_entropies: 1.8018, took: 90.8502s
2022-10-09 04:06:36,230 [INFO] 	Process 5 - batch 14699: mean_policy_losses: -116.254, mean_net_lifetime: 4260.6782, mean_mc_travel_dist: 1481.6892, mean_rewards: 218.9591, total_rewards: 2808.9277, mean_steps: 20.0800, mean_ecr: 0.0395 mean_entropies: 1.9095, took: 107.3142s
2022-10-09 04:07:31,335 [INFO] 	Process 0 - batch 14699: mean_policy_losses: -126.867, mean_net_lifetime: 4126.2213, mean_mc_travel_dist: 1452.5135, mean_rewards: 224.0432, total_rewards: 2713.0237, mean_steps: 18.8300, mean_ecr: 0.0394 mean_entropies: 1.9156, took: 101.4393s
2022-10-09 04:08:18,194 [INFO] 	Process 5 - batch 14799: mean_policy_losses: -169.776, mean_net_lifetime: 3874.8999, mean_mc_travel_dist: 1405.5538, mean_rewards: 215.3098, total_rewards: 2510.4215, mean_steps: 18.7500, mean_ecr: 0.0383 mean_entropies: 1.7827, took: 101.9632s
2022-10-09 04:09:09,640 [INFO] 	Process 0 - batch 14799: mean_policy_losses: -33.461, mean_net_lifetime: 3868.4732, mean_mc_travel_dist: 1349.0791, mean_rewards: 214.7824, total_rewards: 2559.1530, mean_steps: 18.3300, mean_ecr: 0.0390 mean_entropies: 1.7867, took: 98.3050s
2022-10-09 04:09:53,419 [INFO] 	Process 5 - batch 14899: mean_policy_losses: -16.483, mean_net_lifetime: 3890.1460, mean_mc_travel_dist: 1381.8736, mean_rewards: 225.1763, total_rewards: 2547.3360, mean_steps: 17.5800, mean_ecr: 0.0396 mean_entropies: 1.8292, took: 95.2258s
2022-10-09 04:10:51,370 [INFO] 	Process 0 - batch 14899: mean_policy_losses: -94.531, mean_net_lifetime: 3989.7707, mean_mc_travel_dist: 1382.1610, mean_rewards: 219.7729, total_rewards: 2636.5799, mean_steps: 18.5300, mean_ecr: 0.0390 mean_entropies: 1.8350, took: 101.7303s
2022-10-09 04:11:55,713 [INFO] 	Process 5 - batch 14999: mean_policy_losses: -156.129, mean_net_lifetime: 4610.2650, mean_mc_travel_dist: 1796.3280, mean_rewards: 212.4453, total_rewards: 2845.3506, mean_steps: 23.3600, mean_ecr: 0.0400 mean_entropies: 1.7987, took: 122.2940s
2022-10-09 04:12:33,061 [INFO] 	Process 0 - batch 14999: mean_policy_losses: -203.860, mean_net_lifetime: 3830.3978, mean_mc_travel_dist: 1370.7748, mean_rewards: 214.0291, total_rewards: 2495.6793, mean_steps: 18.6800, mean_ecr: 0.0401 mean_entropies: 1.8115, took: 101.6907s
2022-10-09 04:14:06,408 [INFO] 	Process 1 - batch 15099: mean_policy_losses: -156.681, mean_net_lifetime: 3771.2532, mean_mc_travel_dist: 1314.2197, mean_rewards: 221.0586, total_rewards: 2499.0859, mean_steps: 17.9600, mean_ecr: 0.0389 mean_entropies: 1.8461, took: 899.3998s
2022-10-09 04:15:29,900 [INFO] 	Process 1 - batch 15199: mean_policy_losses: -88.708, mean_net_lifetime: 3961.4073, mean_mc_travel_dist: 1361.1964, mean_rewards: 214.0382, total_rewards: 2640.7214, mean_steps: 19.2000, mean_ecr: 0.0397 mean_entropies: 1.8509, took: 83.4922s
2022-10-09 04:16:52,343 [INFO] 	Process 1 - batch 15299: mean_policy_losses: -127.813, mean_net_lifetime: 4115.8839, mean_mc_travel_dist: 1459.7707, mean_rewards: 219.7806, total_rewards: 2696.0371, mean_steps: 20.0000, mean_ecr: 0.0392 mean_entropies: 1.8362, took: 82.4427s
2022-10-09 04:17:07,011 [INFO] 	Process 2 - batch 15099: mean_policy_losses: -157.262, mean_net_lifetime: 3774.5930, mean_mc_travel_dist: 1294.3264, mean_rewards: 218.8630, total_rewards: 2521.3745, mean_steps: 17.6700, mean_ecr: 0.0394 mean_entropies: 1.8634, took: 879.2874s
2022-10-09 04:18:19,729 [INFO] 	Process 1 - batch 15399: mean_policy_losses: -34.609, mean_net_lifetime: 4017.2645, mean_mc_travel_dist: 1391.6260, mean_rewards: 212.5975, total_rewards: 2662.6834, mean_steps: 18.9200, mean_ecr: 0.0397 mean_entropies: 1.8315, took: 87.3863s
2022-10-09 04:18:24,664 [INFO] 	Process 4 - batch 15099: mean_policy_losses: -165.386, mean_net_lifetime: 3654.6621, mean_mc_travel_dist: 1275.7794, mean_rewards: 221.5884, total_rewards: 2407.0675, mean_steps: 17.1800, mean_ecr: 0.0395 mean_entropies: 1.8562, took: 894.4439s
2022-10-09 04:18:37,029 [INFO] 	Process 2 - batch 15199: mean_policy_losses: -107.479, mean_net_lifetime: 3663.1527, mean_mc_travel_dist: 1266.3033, mean_rewards: 219.5434, total_rewards: 2438.6900, mean_steps: 17.0700, mean_ecr: 0.0398 mean_entropies: 1.8413, took: 90.0181s
2022-10-09 04:18:44,796 [INFO] 	Process 3 - batch 15099: mean_policy_losses: -134.868, mean_net_lifetime: 3681.5705, mean_mc_travel_dist: 1276.8968, mean_rewards: 215.7042, total_rewards: 2449.1028, mean_steps: 17.5600, mean_ecr: 0.0399 mean_entropies: 1.8651, took: 909.3973s
2022-10-09 04:19:19,246 [INFO] 	Process 6 - batch 15099: mean_policy_losses: -151.155, mean_net_lifetime: 3750.5261, mean_mc_travel_dist: 1285.6271, mean_rewards: 221.6304, total_rewards: 2495.2315, mean_steps: 17.5700, mean_ecr: 0.0395 mean_entropies: 1.8587, took: 862.8505s
2022-10-09 04:19:52,136 [INFO] 	Process 1 - batch 15499: mean_policy_losses: -152.286, mean_net_lifetime: 3663.6014, mean_mc_travel_dist: 1275.6420, mean_rewards: 230.3518, total_rewards: 2429.5578, mean_steps: 16.2100, mean_ecr: 0.0405 mean_entropies: 1.8169, took: 92.4073s
2022-10-09 04:20:19,412 [INFO] 	Process 4 - batch 15199: mean_policy_losses: 28.742, mean_net_lifetime: 4128.6132, mean_mc_travel_dist: 1455.8246, mean_rewards: 212.1195, total_rewards: 2717.8893, mean_steps: 19.7900, mean_ecr: 0.0398 mean_entropies: 1.8667, took: 114.7485s
2022-10-09 04:20:20,712 [INFO] 	Process 2 - batch 15299: mean_policy_losses: -220.166, mean_net_lifetime: 3646.4979, mean_mc_travel_dist: 1297.1010, mean_rewards: 215.7146, total_rewards: 2388.2684, mean_steps: 17.7300, mean_ecr: 0.0391 mean_entropies: 1.8102, took: 103.6824s
2022-10-09 04:20:32,227 [INFO] 	Process 3 - batch 15199: mean_policy_losses: -133.356, mean_net_lifetime: 3899.9908, mean_mc_travel_dist: 1381.9171, mean_rewards: 219.8566, total_rewards: 2548.0695, mean_steps: 18.0500, mean_ecr: 0.0397 mean_entropies: 1.8508, took: 107.4309s
2022-10-09 04:21:22,373 [INFO] 	Process 6 - batch 15199: mean_policy_losses: -52.936, mean_net_lifetime: 4324.4923, mean_mc_travel_dist: 1583.2845, mean_rewards: 210.3230, total_rewards: 2783.8303, mean_steps: 21.0000, mean_ecr: 0.0392 mean_entropies: 1.8735, took: 123.1285s
2022-10-09 04:21:31,061 [INFO] 	Process 1 - batch 15599: mean_policy_losses: -177.978, mean_net_lifetime: 3743.9091, mean_mc_travel_dist: 1293.3577, mean_rewards: 230.6506, total_rewards: 2492.1261, mean_steps: 17.5900, mean_ecr: 0.0386 mean_entropies: 1.8121, took: 98.9242s
2022-10-09 04:22:09,137 [INFO] 	Process 2 - batch 15399: mean_policy_losses: -49.159, mean_net_lifetime: 3955.7515, mean_mc_travel_dist: 1403.5366, mean_rewards: 219.6661, total_rewards: 2590.5167, mean_steps: 18.3700, mean_ecr: 0.0396 mean_entropies: 1.8169, took: 108.4264s
2022-10-09 04:22:12,268 [INFO] 	Process 3 - batch 15299: mean_policy_losses: -156.714, mean_net_lifetime: 3673.9691, mean_mc_travel_dist: 1305.4248, mean_rewards: 219.1037, total_rewards: 2403.6165, mean_steps: 16.9800, mean_ecr: 0.0391 mean_entropies: 1.7825, took: 100.0399s
2022-10-09 04:22:12,276 [INFO] 	Process 4 - batch 15299: mean_policy_losses: -122.216, mean_net_lifetime: 3977.5499, mean_mc_travel_dist: 1410.4427, mean_rewards: 214.6184, total_rewards: 2604.7029, mean_steps: 19.3400, mean_ecr: 0.0393 mean_entropies: 1.8060, took: 112.8642s
2022-10-09 04:23:06,584 [INFO] 	Process 1 - batch 15699: mean_policy_losses: -90.171, mean_net_lifetime: 3596.8793, mean_mc_travel_dist: 1229.6912, mean_rewards: 218.9709, total_rewards: 2401.4960, mean_steps: 16.9600, mean_ecr: 0.0411 mean_entropies: 1.7662, took: 95.5237s
2022-10-09 04:23:16,944 [INFO] 	Process 6 - batch 15299: mean_policy_losses: -47.893, mean_net_lifetime: 4043.7884, mean_mc_travel_dist: 1423.3503, mean_rewards: 216.7943, total_rewards: 2650.8972, mean_steps: 19.3200, mean_ecr: 0.0394 mean_entropies: 1.8190, took: 114.5706s
2022-10-09 04:23:49,069 [INFO] 	Process 2 - batch 15499: mean_policy_losses: -80.177, mean_net_lifetime: 3789.0777, mean_mc_travel_dist: 1324.1486, mean_rewards: 221.1514, total_rewards: 2519.2387, mean_steps: 17.2900, mean_ecr: 0.0404 mean_entropies: 1.8109, took: 99.9320s
2022-10-09 04:23:55,701 [INFO] 	Process 4 - batch 15399: mean_policy_losses: -149.750, mean_net_lifetime: 3703.4440, mean_mc_travel_dist: 1288.1645, mean_rewards: 209.0837, total_rewards: 2449.7649, mean_steps: 17.8700, mean_ecr: 0.0399 mean_entropies: 1.8170, took: 103.4245s
2022-10-09 04:24:14,453 [INFO] 	Process 3 - batch 15399: mean_policy_losses: -84.595, mean_net_lifetime: 4436.8096, mean_mc_travel_dist: 1617.6401, mean_rewards: 214.7525, total_rewards: 2851.4526, mean_steps: 22.5000, mean_ecr: 0.0396 mean_entropies: 1.7967, took: 122.1857s
2022-10-09 04:24:37,710 [INFO] 	Process 1 - batch 15799: mean_policy_losses: -116.423, mean_net_lifetime: 3849.8323, mean_mc_travel_dist: 1294.9396, mean_rewards: 214.8583, total_rewards: 2591.0652, mean_steps: 18.3900, mean_ecr: 0.0406 mean_entropies: 1.7703, took: 91.1254s
2022-10-09 04:24:59,457 [INFO] 	Process 6 - batch 15399: mean_policy_losses: -56.124, mean_net_lifetime: 4158.0354, mean_mc_travel_dist: 1501.8331, mean_rewards: 216.5266, total_rewards: 2688.5623, mean_steps: 20.2200, mean_ecr: 0.0396 mean_entropies: 1.7989, took: 102.5136s
2022-10-09 04:25:20,834 [INFO] 	Process 2 - batch 15599: mean_policy_losses: -248.245, mean_net_lifetime: 3749.8675, mean_mc_travel_dist: 1288.2174, mean_rewards: 221.4517, total_rewards: 2492.0273, mean_steps: 18.2700, mean_ecr: 0.0386 mean_entropies: 1.7882, took: 91.7651s
2022-10-09 04:25:21,236 [INFO] 	Process 4 - batch 15499: mean_policy_losses: -135.927, mean_net_lifetime: 3802.0824, mean_mc_travel_dist: 1323.1095, mean_rewards: 229.2762, total_rewards: 2522.9464, mean_steps: 16.8600, mean_ecr: 0.0406 mean_entropies: 1.7925, took: 85.5348s
2022-10-09 04:25:39,947 [INFO] 	Process 3 - batch 15499: mean_policy_losses: -107.228, mean_net_lifetime: 3738.3422, mean_mc_travel_dist: 1313.5414, mean_rewards: 225.7708, total_rewards: 2475.7466, mean_steps: 16.7800, mean_ecr: 0.0405 mean_entropies: 1.8004, took: 85.4942s
2022-10-09 04:26:21,695 [INFO] 	Process 6 - batch 15499: mean_policy_losses: -195.982, mean_net_lifetime: 3516.1655, mean_mc_travel_dist: 1213.9771, mean_rewards: 229.4499, total_rewards: 2336.8159, mean_steps: 15.7400, mean_ecr: 0.0406 mean_entropies: 1.7866, took: 82.2371s
2022-10-09 04:26:26,357 [INFO] 	Process 1 - batch 15899: mean_policy_losses: 0.791, mean_net_lifetime: 4618.4916, mean_mc_travel_dist: 1690.8906, mean_rewards: 205.9493, total_rewards: 2971.1347, mean_steps: 23.0400, mean_ecr: 0.0382 mean_entropies: 1.8795, took: 108.6471s
2022-10-09 04:26:56,660 [INFO] 	Process 2 - batch 15699: mean_policy_losses: -11.786, mean_net_lifetime: 3870.1323, mean_mc_travel_dist: 1342.0584, mean_rewards: 218.8446, total_rewards: 2564.4191, mean_steps: 18.4700, mean_ecr: 0.0408 mean_entropies: 1.7795, took: 95.8254s
2022-10-09 04:26:57,722 [INFO] 	Process 4 - batch 15599: mean_policy_losses: -176.519, mean_net_lifetime: 3934.4252, mean_mc_travel_dist: 1397.7072, mean_rewards: 229.7721, total_rewards: 2572.2219, mean_steps: 18.5100, mean_ecr: 0.0383 mean_entropies: 1.8176, took: 96.4867s
2022-10-09 04:27:20,247 [INFO] 	Process 3 - batch 15599: mean_policy_losses: -149.658, mean_net_lifetime: 3975.4200, mean_mc_travel_dist: 1379.2674, mean_rewards: 223.4793, total_rewards: 2634.9270, mean_steps: 19.1400, mean_ecr: 0.0382 mean_entropies: 1.8263, took: 100.2990s
2022-10-09 04:27:31,938 [INFO] 	Process 0 - batch 15099: mean_policy_losses: -157.266, mean_net_lifetime: 3762.1983, mean_mc_travel_dist: 1303.7708, mean_rewards: 212.4570, total_rewards: 2497.4231, mean_steps: 18.0100, mean_ecr: 0.0392 mean_entropies: 1.8834, took: 898.8765s
2022-10-09 04:27:42,013 [INFO] 	Process 5 - batch 15099: mean_policy_losses: -174.043, mean_net_lifetime: 3885.0067, mean_mc_travel_dist: 1394.6466, mean_rewards: 212.8898, total_rewards: 2533.1128, mean_steps: 18.9100, mean_ecr: 0.0393 mean_entropies: 1.8653, took: 946.2998s
2022-10-09 04:28:04,207 [INFO] 	Process 6 - batch 15599: mean_policy_losses: -198.219, mean_net_lifetime: 3888.1615, mean_mc_travel_dist: 1370.0183, mean_rewards: 222.5687, total_rewards: 2556.9474, mean_steps: 19.3000, mean_ecr: 0.0380 mean_entropies: 1.8366, took: 102.5120s
2022-10-09 04:28:07,877 [INFO] 	Process 1 - batch 15999: mean_policy_losses: -93.621, mean_net_lifetime: 4234.7093, mean_mc_travel_dist: 1526.4413, mean_rewards: 215.6993, total_rewards: 2745.0558, mean_steps: 20.2800, mean_ecr: 0.0377 mean_entropies: 1.8158, took: 101.5189s
2022-10-09 04:28:26,798 [INFO] 	Process 4 - batch 15699: mean_policy_losses: -87.245, mean_net_lifetime: 3597.4634, mean_mc_travel_dist: 1207.4929, mean_rewards: 220.1902, total_rewards: 2420.5640, mean_steps: 16.9200, mean_ecr: 0.0416 mean_entropies: 1.7790, took: 89.0759s
2022-10-09 04:28:40,269 [INFO] 	Process 2 - batch 15799: mean_policy_losses: -48.649, mean_net_lifetime: 4046.1483, mean_mc_travel_dist: 1377.7525, mean_rewards: 213.5566, total_rewards: 2699.0392, mean_steps: 19.3500, mean_ecr: 0.0406 mean_entropies: 1.8270, took: 103.6094s
2022-10-09 04:28:50,127 [INFO] 	Process 3 - batch 15699: mean_policy_losses: -103.181, mean_net_lifetime: 3598.8498, mean_mc_travel_dist: 1223.7861, mean_rewards: 223.2974, total_rewards: 2410.3185, mean_steps: 16.6500, mean_ecr: 0.0414 mean_entropies: 1.7857, took: 89.8803s
2022-10-09 04:29:05,982 [INFO] 	Process 0 - batch 15199: mean_policy_losses: -222.550, mean_net_lifetime: 3712.9313, mean_mc_travel_dist: 1293.4176, mean_rewards: 220.7704, total_rewards: 2443.7157, mean_steps: 17.6600, mean_ecr: 0.0396 mean_entropies: 1.8119, took: 94.0449s
2022-10-09 04:29:19,654 [INFO] 	Process 5 - batch 15199: mean_policy_losses: -123.268, mean_net_lifetime: 3932.6159, mean_mc_travel_dist: 1378.0148, mean_rewards: 220.9708, total_rewards: 2592.5388, mean_steps: 18.0700, mean_ecr: 0.0396 mean_entropies: 1.8537, took: 97.6406s
2022-10-09 04:29:32,165 [INFO] 	Process 6 - batch 15699: mean_policy_losses: -120.972, mean_net_lifetime: 3532.6536, mean_mc_travel_dist: 1233.8861, mean_rewards: 219.6876, total_rewards: 2344.5434, mean_steps: 16.3900, mean_ecr: 0.0416 mean_entropies: 1.7556, took: 87.9580s
2022-10-09 04:29:39,877 [INFO] 	Process 1 - batch 16099: mean_policy_losses: -65.637, mean_net_lifetime: 3867.5602, mean_mc_travel_dist: 1327.2254, mean_rewards: 219.7590, total_rewards: 2585.7607, mean_steps: 18.3900, mean_ecr: 0.0387 mean_entropies: 1.8405, took: 92.0018s
2022-10-09 04:30:36,947 [INFO] 	Process 3 - batch 15799: mean_policy_losses: -13.241, mean_net_lifetime: 4207.0579, mean_mc_travel_dist: 1441.1672, mean_rewards: 213.8599, total_rewards: 2796.8839, mean_steps: 20.2100, mean_ecr: 0.0400 mean_entropies: 1.8025, took: 106.8199s
2022-10-09 04:30:38,149 [INFO] 	Process 2 - batch 15899: mean_policy_losses: -93.945, mean_net_lifetime: 4409.5093, mean_mc_travel_dist: 1580.2291, mean_rewards: 208.0366, total_rewards: 2859.9784, mean_steps: 22.3600, mean_ecr: 0.0381 mean_entropies: 1.8551, took: 117.8794s
2022-10-09 04:30:47,106 [INFO] 	Process 0 - batch 15299: mean_policy_losses: -204.140, mean_net_lifetime: 3923.3897, mean_mc_travel_dist: 1401.2453, mean_rewards: 209.6120, total_rewards: 2552.5237, mean_steps: 18.9300, mean_ecr: 0.0393 mean_entropies: 1.8135, took: 101.1233s
2022-10-09 04:30:52,036 [INFO] 	Process 4 - batch 15799: mean_policy_losses: -149.432, mean_net_lifetime: 5511.3551, mean_mc_travel_dist: 2017.5577, mean_rewards: 213.8426, total_rewards: 3537.4085, mean_steps: 28.5200, mean_ecr: 0.0403 mean_entropies: 1.8227, took: 145.2342s
2022-10-09 04:30:55,064 [INFO] 	Process 5 - batch 15299: mean_policy_losses: -170.644, mean_net_lifetime: 3826.9305, mean_mc_travel_dist: 1316.7283, mean_rewards: 218.3216, total_rewards: 2534.7889, mean_steps: 18.0300, mean_ecr: 0.0395 mean_entropies: 1.8019, took: 95.4099s
2022-10-09 04:31:17,333 [INFO] 	Process 1 - batch 16199: mean_policy_losses: -122.518, mean_net_lifetime: 4094.1913, mean_mc_travel_dist: 1419.7002, mean_rewards: 213.9519, total_rewards: 2707.3373, mean_steps: 19.5200, mean_ecr: 0.0379 mean_entropies: 1.8192, took: 97.4552s
2022-10-09 04:31:19,200 [INFO] 	Process 6 - batch 15799: mean_policy_losses: -77.209, mean_net_lifetime: 4209.1492, mean_mc_travel_dist: 1439.5074, mean_rewards: 216.7791, total_rewards: 2800.1515, mean_steps: 20.2500, mean_ecr: 0.0394 mean_entropies: 1.8274, took: 107.0357s
2022-10-09 04:32:23,137 [INFO] 	Process 2 - batch 15999: mean_policy_losses: -94.379, mean_net_lifetime: 4211.9056, mean_mc_travel_dist: 1522.7415, mean_rewards: 218.3173, total_rewards: 2731.7082, mean_steps: 20.0700, mean_ecr: 0.0380 mean_entropies: 1.7739, took: 104.9883s
2022-10-09 04:32:24,770 [INFO] 	Process 0 - batch 15399: mean_policy_losses: -134.071, mean_net_lifetime: 3849.3654, mean_mc_travel_dist: 1335.8759, mean_rewards: 213.3453, total_rewards: 2555.4463, mean_steps: 18.0500, mean_ecr: 0.0400 mean_entropies: 1.8110, took: 97.6641s
2022-10-09 04:32:27,814 [INFO] 	Process 3 - batch 15899: mean_policy_losses: -63.818, mean_net_lifetime: 4344.3786, mean_mc_travel_dist: 1561.6374, mean_rewards: 208.9660, total_rewards: 2816.2042, mean_steps: 21.0200, mean_ecr: 0.0383 mean_entropies: 1.8502, took: 110.8668s
2022-10-09 04:32:28,889 [INFO] 	Process 5 - batch 15399: mean_policy_losses: -135.519, mean_net_lifetime: 3770.1372, mean_mc_travel_dist: 1294.9360, mean_rewards: 219.5815, total_rewards: 2514.0579, mean_steps: 17.4500, mean_ecr: 0.0398 mean_entropies: 1.8015, took: 93.8250s
2022-10-09 04:32:44,721 [INFO] 	Process 4 - batch 15899: mean_policy_losses: -125.571, mean_net_lifetime: 4425.3542, mean_mc_travel_dist: 1646.2788, mean_rewards: 208.9799, total_rewards: 2828.4102, mean_steps: 21.6500, mean_ecr: 0.0383 mean_entropies: 1.8623, took: 112.6888s
2022-10-09 04:32:59,598 [INFO] 	Process 1 - batch 16299: mean_policy_losses: -27.237, mean_net_lifetime: 4359.0360, mean_mc_travel_dist: 1636.7076, mean_rewards: 218.7728, total_rewards: 2757.9355, mean_steps: 20.5700, mean_ecr: 0.0402 mean_entropies: 1.7985, took: 102.2652s
2022-10-09 04:33:07,417 [INFO] 	Process 6 - batch 15899: mean_policy_losses: -74.097, mean_net_lifetime: 4355.0254, mean_mc_travel_dist: 1576.8038, mean_rewards: 212.9368, total_rewards: 2820.9379, mean_steps: 20.8700, mean_ecr: 0.0384 mean_entropies: 1.8567, took: 108.2165s
2022-10-09 04:33:53,355 [INFO] 	Process 0 - batch 15499: mean_policy_losses: -221.495, mean_net_lifetime: 3540.4607, mean_mc_travel_dist: 1230.1866, mean_rewards: 226.0541, total_rewards: 2355.5001, mean_steps: 16.2900, mean_ecr: 0.0410 mean_entropies: 1.7788, took: 88.5844s
2022-10-09 04:33:57,615 [INFO] 	Process 5 - batch 15499: mean_policy_losses: -162.503, mean_net_lifetime: 3676.3378, mean_mc_travel_dist: 1264.4402, mean_rewards: 230.4057, total_rewards: 2447.5109, mean_steps: 16.5900, mean_ecr: 0.0406 mean_entropies: 1.7773, took: 88.7254s
2022-10-09 04:34:00,038 [INFO] 	Process 3 - batch 15999: mean_policy_losses: -132.267, mean_net_lifetime: 3798.6257, mean_mc_travel_dist: 1319.5424, mean_rewards: 217.3750, total_rewards: 2519.6081, mean_steps: 17.5400, mean_ecr: 0.0383 mean_entropies: 1.7811, took: 92.2245s
2022-10-09 04:34:12,226 [INFO] 	Process 2 - batch 16099: mean_policy_losses: -75.259, mean_net_lifetime: 4214.6412, mean_mc_travel_dist: 1534.8431, mean_rewards: 218.5845, total_rewards: 2720.9703, mean_steps: 20.5600, mean_ecr: 0.0387 mean_entropies: 1.8431, took: 109.0884s
2022-10-09 04:34:31,091 [INFO] 	Process 4 - batch 15999: mean_policy_losses: -76.184, mean_net_lifetime: 4178.5667, mean_mc_travel_dist: 1523.8162, mean_rewards: 221.7241, total_rewards: 2691.3259, mean_steps: 20.2200, mean_ecr: 0.0377 mean_entropies: 1.7721, took: 106.3703s
2022-10-09 04:34:47,970 [INFO] 	Process 6 - batch 15999: mean_policy_losses: -142.993, mean_net_lifetime: 3979.9088, mean_mc_travel_dist: 1428.2249, mean_rewards: 219.7583, total_rewards: 2582.1685, mean_steps: 19.0000, mean_ecr: 0.0381 mean_entropies: 1.7706, took: 100.5519s
2022-10-09 04:34:50,151 [INFO] 	Process 1 - batch 16399: mean_policy_losses: 15.690, mean_net_lifetime: 4566.6102, mean_mc_travel_dist: 1625.2871, mean_rewards: 219.5144, total_rewards: 2974.8003, mean_steps: 22.2900, mean_ecr: 0.0385 mean_entropies: 1.8418, took: 110.5523s
2022-10-09 04:35:33,639 [INFO] 	Process 3 - batch 16099: mean_policy_losses: -179.518, mean_net_lifetime: 3683.5562, mean_mc_travel_dist: 1288.3440, mean_rewards: 216.6151, total_rewards: 2433.8968, mean_steps: 17.7500, mean_ecr: 0.0389 mean_entropies: 1.8334, took: 93.6001s
2022-10-09 04:35:33,644 [INFO] 	Process 0 - batch 15599: mean_policy_losses: -159.938, mean_net_lifetime: 3927.2292, mean_mc_travel_dist: 1333.0374, mean_rewards: 228.0276, total_rewards: 2623.0097, mean_steps: 18.2200, mean_ecr: 0.0385 mean_entropies: 1.8146, took: 100.2901s
2022-10-09 04:35:36,498 [INFO] 	Process 5 - batch 15599: mean_policy_losses: -155.993, mean_net_lifetime: 3898.4330, mean_mc_travel_dist: 1365.9647, mean_rewards: 223.9250, total_rewards: 2572.7289, mean_steps: 18.4700, mean_ecr: 0.0384 mean_entropies: 1.8214, took: 98.8844s
2022-10-09 04:35:56,481 [INFO] 	Process 2 - batch 16199: mean_policy_losses: -40.670, mean_net_lifetime: 4154.5353, mean_mc_travel_dist: 1455.6966, mean_rewards: 222.4573, total_rewards: 2726.5812, mean_steps: 19.5800, mean_ecr: 0.0381 mean_entropies: 1.8115, took: 104.2559s
2022-10-09 04:36:12,918 [INFO] 	Process 4 - batch 16099: mean_policy_losses: -175.879, mean_net_lifetime: 3964.7693, mean_mc_travel_dist: 1384.1942, mean_rewards: 218.2965, total_rewards: 2625.3422, mean_steps: 19.3100, mean_ecr: 0.0386 mean_entropies: 1.8218, took: 101.8269s
2022-10-09 04:36:33,745 [INFO] 	Process 6 - batch 16099: mean_policy_losses: -34.569, mean_net_lifetime: 4199.0464, mean_mc_travel_dist: 1485.3319, mean_rewards: 221.4078, total_rewards: 2754.2395, mean_steps: 20.0800, mean_ecr: 0.0386 mean_entropies: 1.8227, took: 105.7763s
2022-10-09 04:36:34,611 [INFO] 	Process 1 - batch 16499: mean_policy_losses: -73.591, mean_net_lifetime: 4248.2574, mean_mc_travel_dist: 1596.6912, mean_rewards: 218.5606, total_rewards: 2687.7828, mean_steps: 21.0500, mean_ecr: 0.0390 mean_entropies: 1.7582, took: 104.4611s
2022-10-09 04:37:03,209 [INFO] 	Process 5 - batch 15699: mean_policy_losses: -155.842, mean_net_lifetime: 3500.2617, mean_mc_travel_dist: 1178.5850, mean_rewards: 224.8251, total_rewards: 2356.2023, mean_steps: 16.0900, mean_ecr: 0.0415 mean_entropies: 1.7547, took: 86.7111s
2022-10-09 04:37:03,243 [INFO] 	Process 0 - batch 15699: mean_policy_losses: -119.198, mean_net_lifetime: 3557.9608, mean_mc_travel_dist: 1218.8579, mean_rewards: 219.3699, total_rewards: 2367.7918, mean_steps: 16.7700, mean_ecr: 0.0409 mean_entropies: 1.7652, took: 89.5980s
2022-10-09 04:37:14,362 [INFO] 	Process 3 - batch 16199: mean_policy_losses: -70.508, mean_net_lifetime: 4262.3891, mean_mc_travel_dist: 1500.2960, mean_rewards: 223.2142, total_rewards: 2800.6907, mean_steps: 19.7000, mean_ecr: 0.0382 mean_entropies: 1.8202, took: 100.7242s
2022-10-09 04:37:27,066 [INFO] 	Process 2 - batch 16299: mean_policy_losses: -179.924, mean_net_lifetime: 3680.2502, mean_mc_travel_dist: 1269.1750, mean_rewards: 225.8009, total_rewards: 2452.0608, mean_steps: 17.3400, mean_ecr: 0.0405 mean_entropies: 1.7904, took: 90.5856s
2022-10-09 04:37:49,166 [INFO] 	Process 4 - batch 16199: mean_policy_losses: -92.313, mean_net_lifetime: 3951.7048, mean_mc_travel_dist: 1368.2766, mean_rewards: 223.0804, total_rewards: 2626.5661, mean_steps: 18.3100, mean_ecr: 0.0384 mean_entropies: 1.7879, took: 96.2480s
2022-10-09 04:38:15,343 [INFO] 	Process 6 - batch 16199: mean_policy_losses: -76.530, mean_net_lifetime: 4189.5928, mean_mc_travel_dist: 1485.8527, mean_rewards: 219.1092, total_rewards: 2742.9044, mean_steps: 19.8400, mean_ecr: 0.0384 mean_entropies: 1.7718, took: 101.5977s
2022-10-09 04:38:48,213 [INFO] 	Process 3 - batch 16299: mean_policy_losses: -154.760, mean_net_lifetime: 3741.7783, mean_mc_travel_dist: 1309.7307, mean_rewards: 212.6505, total_rewards: 2463.8724, mean_steps: 18.5000, mean_ecr: 0.0401 mean_entropies: 1.7310, took: 93.8502s
2022-10-09 04:38:49,427 [INFO] 	Process 5 - batch 15799: mean_policy_losses: -111.090, mean_net_lifetime: 4128.8866, mean_mc_travel_dist: 1441.1541, mean_rewards: 206.8839, total_rewards: 2718.4538, mean_steps: 20.8400, mean_ecr: 0.0398 mean_entropies: 1.7819, took: 106.2175s
2022-10-09 04:38:52,869 [INFO] 	Process 0 - batch 15799: mean_policy_losses: -48.350, mean_net_lifetime: 4239.6346, mean_mc_travel_dist: 1479.3774, mean_rewards: 210.7981, total_rewards: 2790.3252, mean_steps: 21.0600, mean_ecr: 0.0400 mean_entropies: 1.7546, took: 109.6271s
2022-10-09 04:39:25,561 [INFO] 	Process 2 - batch 16399: mean_policy_losses: -39.135, mean_net_lifetime: 4613.2637, mean_mc_travel_dist: 1657.6478, mean_rewards: 208.4044, total_rewards: 2992.1593, mean_steps: 23.8200, mean_ecr: 0.0382 mean_entropies: 1.7736, took: 118.4948s
2022-10-09 04:39:27,323 [INFO] 	Process 4 - batch 16299: mean_policy_losses: -107.488, mean_net_lifetime: 3869.6178, mean_mc_travel_dist: 1340.3900, mean_rewards: 206.8253, total_rewards: 2563.4794, mean_steps: 19.5300, mean_ecr: 0.0400 mean_entropies: 1.7854, took: 98.1567s
2022-10-09 04:39:50,731 [INFO] 	Process 6 - batch 16299: mean_policy_losses: -196.469, mean_net_lifetime: 3808.8158, mean_mc_travel_dist: 1320.7179, mean_rewards: 216.0538, total_rewards: 2531.9579, mean_steps: 18.8400, mean_ecr: 0.0393 mean_entropies: 1.7702, took: 95.3883s
2022-10-09 04:40:33,130 [INFO] 	Process 5 - batch 15899: mean_policy_losses: -118.175, mean_net_lifetime: 4072.7991, mean_mc_travel_dist: 1454.5307, mean_rewards: 210.6931, total_rewards: 2651.5329, mean_steps: 19.9000, mean_ecr: 0.0386 mean_entropies: 1.8030, took: 103.7026s
2022-10-09 04:40:34,913 [INFO] 	Process 3 - batch 16399: mean_policy_losses: -35.238, mean_net_lifetime: 4459.4415, mean_mc_travel_dist: 1573.1027, mean_rewards: 218.8712, total_rewards: 2931.6030, mean_steps: 21.1900, mean_ecr: 0.0381 mean_entropies: 1.8119, took: 106.7004s
2022-10-09 04:40:46,095 [INFO] 	Process 0 - batch 15899: mean_policy_losses: -69.359, mean_net_lifetime: 4476.5577, mean_mc_travel_dist: 1617.3713, mean_rewards: 205.9038, total_rewards: 2905.4181, mean_steps: 22.3600, mean_ecr: 0.0382 mean_entropies: 1.8349, took: 113.2253s
2022-10-09 04:41:07,591 [INFO] 	Process 2 - batch 16499: mean_policy_losses: -42.291, mean_net_lifetime: 4093.2363, mean_mc_travel_dist: 1452.2258, mean_rewards: 213.3563, total_rewards: 2678.2818, mean_steps: 20.4000, mean_ecr: 0.0390 mean_entropies: 1.7721, took: 102.0294s
2022-10-09 04:41:12,436 [INFO] 	Process 4 - batch 16399: mean_policy_losses: -52.512, mean_net_lifetime: 4312.8748, mean_mc_travel_dist: 1523.4584, mean_rewards: 213.2224, total_rewards: 2829.0554, mean_steps: 20.5400, mean_ecr: 0.0383 mean_entropies: 1.8169, took: 105.1133s
2022-10-09 04:41:39,612 [INFO] 	Process 6 - batch 16399: mean_policy_losses: -67.516, mean_net_lifetime: 4485.5602, mean_mc_travel_dist: 1594.8510, mean_rewards: 221.5440, total_rewards: 2927.9225, mean_steps: 21.4800, mean_ecr: 0.0381 mean_entropies: 1.8208, took: 108.8808s
2022-10-09 04:42:07,557 [INFO] 	Process 5 - batch 15999: mean_policy_losses: -108.521, mean_net_lifetime: 4043.7659, mean_mc_travel_dist: 1416.0335, mean_rewards: 224.7259, total_rewards: 2664.2712, mean_steps: 18.6700, mean_ecr: 0.0379 mean_entropies: 1.7669, took: 94.4269s
2022-10-09 04:42:19,147 [INFO] 	Process 0 - batch 15999: mean_policy_losses: -148.430, mean_net_lifetime: 3965.4644, mean_mc_travel_dist: 1436.5679, mean_rewards: 222.1775, total_rewards: 2577.3406, mean_steps: 18.7200, mean_ecr: 0.0380 mean_entropies: 1.7263, took: 93.0520s
2022-10-09 04:42:25,669 [INFO] 	Process 3 - batch 16499: mean_policy_losses: -158.449, mean_net_lifetime: 4548.8586, mean_mc_travel_dist: 1723.6930, mean_rewards: 224.5027, total_rewards: 2858.3653, mean_steps: 22.7200, mean_ecr: 0.0388 mean_entropies: 1.7598, took: 110.7566s
2022-10-09 04:42:47,638 [INFO] 	Process 4 - batch 16499: mean_policy_losses: -126.082, mean_net_lifetime: 4052.1108, mean_mc_travel_dist: 1501.4675, mean_rewards: 219.4621, total_rewards: 2589.2534, mean_steps: 19.7000, mean_ecr: 0.0391 mean_entropies: 1.7300, took: 95.2014s
2022-10-09 04:43:19,183 [INFO] 	Process 6 - batch 16499: mean_policy_losses: -126.181, mean_net_lifetime: 4156.1247, mean_mc_travel_dist: 1554.2123, mean_rewards: 217.8586, total_rewards: 2639.8059, mean_steps: 20.5000, mean_ecr: 0.0393 mean_entropies: 1.7209, took: 99.5711s
2022-10-09 04:43:42,698 [INFO] 	Process 5 - batch 16099: mean_policy_losses: -78.013, mean_net_lifetime: 4251.7066, mean_mc_travel_dist: 1488.7157, mean_rewards: 224.2709, total_rewards: 2800.7810, mean_steps: 20.0900, mean_ecr: 0.0387 mean_entropies: 1.8100, took: 95.1416s
2022-10-09 04:43:52,841 [INFO] 	Process 0 - batch 16099: mean_policy_losses: -173.710, mean_net_lifetime: 4178.5335, mean_mc_travel_dist: 1501.2005, mean_rewards: 213.8722, total_rewards: 2722.2030, mean_steps: 20.4300, mean_ecr: 0.0388 mean_entropies: 1.8057, took: 93.6937s
2022-10-09 04:45:05,501 [INFO] 	Process 5 - batch 16199: mean_policy_losses: -111.671, mean_net_lifetime: 3903.2610, mean_mc_travel_dist: 1387.7003, mean_rewards: 220.3977, total_rewards: 2569.0989, mean_steps: 17.9600, mean_ecr: 0.0386 mean_entropies: 1.7876, took: 82.8031s
2022-10-09 04:45:14,664 [INFO] 	Process 0 - batch 16199: mean_policy_losses: -78.085, mean_net_lifetime: 4056.3579, mean_mc_travel_dist: 1445.5788, mean_rewards: 226.2888, total_rewards: 2644.2452, mean_steps: 18.1300, mean_ecr: 0.0378 mean_entropies: 1.7887, took: 81.8219s
2022-10-09 04:46:25,892 [INFO] 	Process 5 - batch 16299: mean_policy_losses: -107.037, mean_net_lifetime: 3723.2334, mean_mc_travel_dist: 1296.0467, mean_rewards: 219.1564, total_rewards: 2465.5437, mean_steps: 17.6200, mean_ecr: 0.0396 mean_entropies: 1.7743, took: 80.3903s
2022-10-09 04:46:36,228 [INFO] 	Process 0 - batch 16299: mean_policy_losses: -28.526, mean_net_lifetime: 3818.6513, mean_mc_travel_dist: 1330.8537, mean_rewards: 216.7862, total_rewards: 2517.2379, mean_steps: 18.2100, mean_ecr: 0.0405 mean_entropies: 1.7533, took: 81.5648s
2022-10-09 04:47:52,003 [INFO] 	Process 5 - batch 16399: mean_policy_losses: -51.880, mean_net_lifetime: 4026.9486, mean_mc_travel_dist: 1433.0895, mean_rewards: 215.4485, total_rewards: 2626.9776, mean_steps: 19.2700, mean_ecr: 0.0386 mean_entropies: 1.7376, took: 86.1122s
2022-10-09 04:48:05,635 [INFO] 	Process 0 - batch 16399: mean_policy_losses: -33.887, mean_net_lifetime: 4230.1609, mean_mc_travel_dist: 1532.2384, mean_rewards: 217.9949, total_rewards: 2745.3893, mean_steps: 19.8200, mean_ecr: 0.0382 mean_entropies: 1.7607, took: 89.4077s
2022-10-09 04:49:22,571 [INFO] 	Process 5 - batch 16499: mean_policy_losses: -105.636, mean_net_lifetime: 4271.4370, mean_mc_travel_dist: 1538.5020, mean_rewards: 222.7614, total_rewards: 2778.0364, mean_steps: 20.7300, mean_ecr: 0.0390 mean_entropies: 1.7231, took: 90.5678s
2022-10-09 04:49:39,808 [INFO] 	Process 0 - batch 16499: mean_policy_losses: -150.913, mean_net_lifetime: 4009.8680, mean_mc_travel_dist: 1452.4775, mean_rewards: 211.9389, total_rewards: 2597.9963, mean_steps: 20.5200, mean_ecr: 0.0390 mean_entropies: 1.7103, took: 94.1719s
2022-10-09 04:50:16,228 [INFO] 	Process 1 - batch 16599: mean_policy_losses: -141.899, mean_net_lifetime: 4334.9280, mean_mc_travel_dist: 1514.0064, mean_rewards: 214.4602, total_rewards: 2864.4825, mean_steps: 20.4600, mean_ecr: 0.0385 mean_entropies: 1.7686, took: 821.6163s
2022-10-09 04:51:49,685 [INFO] 	Process 1 - batch 16699: mean_policy_losses: -59.295, mean_net_lifetime: 4771.6533, mean_mc_travel_dist: 1750.1713, mean_rewards: 228.7641, total_rewards: 3054.6146, mean_steps: 23.5400, mean_ecr: 0.0385 mean_entropies: 1.8213, took: 93.4574s
2022-10-09 04:53:09,486 [INFO] 	Process 1 - batch 16799: mean_policy_losses: -81.601, mean_net_lifetime: 4146.3584, mean_mc_travel_dist: 1441.9605, mean_rewards: 221.9577, total_rewards: 2746.8680, mean_steps: 19.5800, mean_ecr: 0.0396 mean_entropies: 1.8103, took: 79.8006s
2022-10-09 04:53:52,867 [INFO] 	Process 2 - batch 16599: mean_policy_losses: -110.821, mean_net_lifetime: 3978.9173, mean_mc_travel_dist: 1382.2898, mean_rewards: 219.4062, total_rewards: 2635.1208, mean_steps: 19.0900, mean_ecr: 0.0387 mean_entropies: 1.7770, took: 765.2766s
2022-10-09 04:54:37,026 [INFO] 	Process 1 - batch 16899: mean_policy_losses: -94.022, mean_net_lifetime: 4184.0206, mean_mc_travel_dist: 1415.6586, mean_rewards: 212.5406, total_rewards: 2799.7721, mean_steps: 20.7200, mean_ecr: 0.0397 mean_entropies: 1.8101, took: 87.5402s
2022-10-09 04:55:33,418 [INFO] 	Process 3 - batch 16599: mean_policy_losses: -53.004, mean_net_lifetime: 3908.2054, mean_mc_travel_dist: 1360.1350, mean_rewards: 219.8814, total_rewards: 2588.9434, mean_steps: 18.4700, mean_ecr: 0.0391 mean_entropies: 1.7747, took: 787.7479s
2022-10-09 04:55:40,784 [INFO] 	Process 2 - batch 16699: mean_policy_losses: -176.893, mean_net_lifetime: 4580.1161, mean_mc_travel_dist: 1651.8223, mean_rewards: 217.5069, total_rewards: 2969.8925, mean_steps: 22.8700, mean_ecr: 0.0383 mean_entropies: 1.8847, took: 107.9167s
2022-10-09 04:56:03,552 [INFO] 	Process 1 - batch 16999: mean_policy_losses: -181.860, mean_net_lifetime: 3867.3470, mean_mc_travel_dist: 1337.6505, mean_rewards: 223.2045, total_rewards: 2565.3890, mean_steps: 18.3400, mean_ecr: 0.0400 mean_entropies: 1.7673, took: 86.5264s
2022-10-09 04:56:14,288 [INFO] 	Process 4 - batch 16599: mean_policy_losses: -50.032, mean_net_lifetime: 3968.5376, mean_mc_travel_dist: 1367.0112, mean_rewards: 222.4709, total_rewards: 2634.3523, mean_steps: 18.3900, mean_ecr: 0.0390 mean_entropies: 1.7915, took: 806.6504s
2022-10-09 04:56:15,188 [INFO] 	Process 6 - batch 16599: mean_policy_losses: -94.556, mean_net_lifetime: 4311.3366, mean_mc_travel_dist: 1550.9536, mean_rewards: 223.2610, total_rewards: 2799.1130, mean_steps: 20.4500, mean_ecr: 0.0388 mean_entropies: 1.7968, took: 776.0048s
2022-10-09 04:57:18,043 [INFO] 	Process 2 - batch 16799: mean_policy_losses: -62.523, mean_net_lifetime: 4178.9517, mean_mc_travel_dist: 1476.5148, mean_rewards: 221.2994, total_rewards: 2740.9048, mean_steps: 19.6800, mean_ecr: 0.0397 mean_entropies: 1.8369, took: 97.2579s
2022-10-09 04:57:19,165 [INFO] 	Process 3 - batch 16699: mean_policy_losses: -93.178, mean_net_lifetime: 4550.0892, mean_mc_travel_dist: 1599.2465, mean_rewards: 227.3653, total_rewards: 2995.0390, mean_steps: 21.6300, mean_ecr: 0.0384 mean_entropies: 1.8467, took: 105.7472s
2022-10-09 04:57:27,904 [INFO] 	Process 1 - batch 17099: mean_policy_losses: -250.501, mean_net_lifetime: 3779.8505, mean_mc_travel_dist: 1319.2512, mean_rewards: 221.5511, total_rewards: 2504.9712, mean_steps: 17.7900, mean_ecr: 0.0383 mean_entropies: 1.8254, took: 84.3523s
2022-10-09 04:57:41,126 [INFO] 	Process 4 - batch 16699: mean_policy_losses: -118.378, mean_net_lifetime: 3841.7701, mean_mc_travel_dist: 1331.6302, mean_rewards: 220.9805, total_rewards: 2548.3259, mean_steps: 17.6700, mean_ecr: 0.0385 mean_entropies: 1.8700, took: 86.8381s
2022-10-09 04:58:31,596 [INFO] 	Process 6 - batch 16699: mean_policy_losses: -86.188, mean_net_lifetime: 5458.0883, mean_mc_travel_dist: 2042.6917, mean_rewards: 229.0503, total_rewards: 3455.1588, mean_steps: 27.6900, mean_ecr: 0.0383 mean_entropies: 1.8591, took: 136.4054s
2022-10-09 04:59:00,748 [INFO] 	Process 1 - batch 17199: mean_policy_losses: -194.506, mean_net_lifetime: 3973.5524, mean_mc_travel_dist: 1383.2881, mean_rewards: 212.3147, total_rewards: 2626.2195, mean_steps: 19.8600, mean_ecr: 0.0385 mean_entropies: 1.8229, took: 92.8437s
2022-10-09 04:59:02,226 [INFO] 	Process 2 - batch 16899: mean_policy_losses: -78.282, mean_net_lifetime: 4243.4091, mean_mc_travel_dist: 1482.3502, mean_rewards: 216.5684, total_rewards: 2790.9785, mean_steps: 20.9600, mean_ecr: 0.0398 mean_entropies: 1.8426, took: 104.1840s
2022-10-09 04:59:04,125 [INFO] 	Process 3 - batch 16799: mean_policy_losses: 31.865, mean_net_lifetime: 4499.2181, mean_mc_travel_dist: 1564.7175, mean_rewards: 217.2971, total_rewards: 2974.5545, mean_steps: 21.5200, mean_ecr: 0.0394 mean_entropies: 1.8538, took: 104.9602s
2022-10-09 04:59:16,986 [INFO] 	Process 4 - batch 16799: mean_policy_losses: -34.256, mean_net_lifetime: 4158.1680, mean_mc_travel_dist: 1423.4272, mean_rewards: 222.2177, total_rewards: 2767.9286, mean_steps: 19.3600, mean_ecr: 0.0396 mean_entropies: 1.8339, took: 95.8596s
2022-10-09 05:00:07,501 [INFO] 	Process 6 - batch 16799: mean_policy_losses: -129.300, mean_net_lifetime: 3982.7646, mean_mc_travel_dist: 1400.0553, mean_rewards: 217.1239, total_rewards: 2617.9812, mean_steps: 19.4200, mean_ecr: 0.0394 mean_entropies: 1.8014, took: 95.9071s
2022-10-09 05:00:26,597 [INFO] 	Process 1 - batch 17299: mean_policy_losses: -188.819, mean_net_lifetime: 3792.4582, mean_mc_travel_dist: 1324.3686, mean_rewards: 218.9030, total_rewards: 2504.3480, mean_steps: 18.2500, mean_ecr: 0.0384 mean_entropies: 1.7206, took: 85.8490s
2022-10-09 05:00:37,249 [INFO] 	Process 2 - batch 16999: mean_policy_losses: -139.869, mean_net_lifetime: 3882.2535, mean_mc_travel_dist: 1360.5085, mean_rewards: 216.9821, total_rewards: 2556.9823, mean_steps: 18.8500, mean_ecr: 0.0397 mean_entropies: 1.7349, took: 95.0234s
2022-10-09 05:00:50,188 [INFO] 	Process 3 - batch 16899: mean_policy_losses: -53.339, mean_net_lifetime: 4304.5743, mean_mc_travel_dist: 1484.1296, mean_rewards: 209.8908, total_rewards: 2856.2389, mean_steps: 21.7300, mean_ecr: 0.0397 mean_entropies: 1.7932, took: 106.0625s
2022-10-09 05:00:58,310 [INFO] 	Process 4 - batch 16899: mean_policy_losses: -61.440, mean_net_lifetime: 4054.0934, mean_mc_travel_dist: 1384.4106, mean_rewards: 210.0761, total_rewards: 2704.8850, mean_steps: 20.3900, mean_ecr: 0.0395 mean_entropies: 1.7857, took: 101.3241s
2022-10-09 05:01:57,734 [INFO] 	Process 1 - batch 17399: mean_policy_losses: -258.216, mean_net_lifetime: 3916.0752, mean_mc_travel_dist: 1393.7030, mean_rewards: 219.6085, total_rewards: 2559.7382, mean_steps: 19.0600, mean_ecr: 0.0383 mean_entropies: 1.7799, took: 91.1371s
2022-10-09 05:02:02,448 [INFO] 	Process 6 - batch 16899: mean_policy_losses: 24.908, mean_net_lifetime: 4483.2056, mean_mc_travel_dist: 1571.5745, mean_rewards: 215.2675, total_rewards: 2948.1909, mean_steps: 23.1600, mean_ecr: 0.0399 mean_entropies: 1.7894, took: 114.9488s
2022-10-09 05:02:15,870 [INFO] 	Process 3 - batch 16999: mean_policy_losses: -160.497, mean_net_lifetime: 3597.0764, mean_mc_travel_dist: 1226.5459, mean_rewards: 231.7831, total_rewards: 2409.4296, mean_steps: 16.8500, mean_ecr: 0.0402 mean_entropies: 1.6944, took: 85.6834s
2022-10-09 05:02:19,461 [INFO] 	Process 2 - batch 17099: mean_policy_losses: -73.421, mean_net_lifetime: 4179.7840, mean_mc_travel_dist: 1472.7406, mean_rewards: 219.7100, total_rewards: 2738.7079, mean_steps: 20.1800, mean_ecr: 0.0385 mean_entropies: 1.7634, took: 102.2110s
2022-10-09 05:02:30,910 [INFO] 	Process 4 - batch 16999: mean_policy_losses: -226.159, mean_net_lifetime: 3567.4902, mean_mc_travel_dist: 1259.0355, mean_rewards: 219.1905, total_rewards: 2351.8134, mean_steps: 17.5800, mean_ecr: 0.0402 mean_entropies: 1.6937, took: 92.6003s
2022-10-09 05:03:09,464 [INFO] 	Process 5 - batch 16599: mean_policy_losses: -52.812, mean_net_lifetime: 4003.5364, mean_mc_travel_dist: 1420.2479, mean_rewards: 218.6774, total_rewards: 2630.1490, mean_steps: 19.5300, mean_ecr: 0.0387 mean_entropies: 1.7450, took: 826.8917s
2022-10-09 05:03:33,519 [INFO] 	Process 0 - batch 16599: mean_policy_losses: 47.168, mean_net_lifetime: 4068.3108, mean_mc_travel_dist: 1401.1632, mean_rewards: 221.8056, total_rewards: 2709.1017, mean_steps: 19.1400, mean_ecr: 0.0385 mean_entropies: 1.7313, took: 833.7121s
2022-10-09 05:03:36,987 [INFO] 	Process 6 - batch 16999: mean_policy_losses: -186.642, mean_net_lifetime: 3610.5609, mean_mc_travel_dist: 1264.3076, mean_rewards: 220.2469, total_rewards: 2385.5502, mean_steps: 17.7900, mean_ecr: 0.0399 mean_entropies: 1.6823, took: 94.5382s
2022-10-09 05:03:40,185 [INFO] 	Process 1 - batch 17499: mean_policy_losses: -53.146, mean_net_lifetime: 4283.4557, mean_mc_travel_dist: 1533.4992, mean_rewards: 218.8923, total_rewards: 2782.5094, mean_steps: 20.6400, mean_ecr: 0.0384 mean_entropies: 1.7756, took: 102.4493s
2022-10-09 05:03:57,966 [INFO] 	Process 2 - batch 17199: mean_policy_losses: -64.005, mean_net_lifetime: 3816.5931, mean_mc_travel_dist: 1322.5386, mean_rewards: 219.1366, total_rewards: 2537.3378, mean_steps: 18.5100, mean_ecr: 0.0383 mean_entropies: 1.7802, took: 98.5054s
2022-10-09 05:04:10,182 [INFO] 	Process 3 - batch 17099: mean_policy_losses: -192.471, mean_net_lifetime: 4415.4277, mean_mc_travel_dist: 1570.8727, mean_rewards: 220.7602, total_rewards: 2883.8556, mean_steps: 21.8900, mean_ecr: 0.0383 mean_entropies: 1.7608, took: 114.3107s
2022-10-09 05:04:10,361 [INFO] 	Process 4 - batch 17099: mean_policy_losses: -233.409, mean_net_lifetime: 3959.6599, mean_mc_travel_dist: 1411.4164, mean_rewards: 217.2284, total_rewards: 2583.1401, mean_steps: 19.0200, mean_ecr: 0.0383 mean_entropies: 1.7602, took: 99.4517s
2022-10-09 05:05:14,387 [INFO] 	Process 1 - batch 17599: mean_policy_losses: -139.784, mean_net_lifetime: 3985.9024, mean_mc_travel_dist: 1362.1752, mean_rewards: 227.6998, total_rewards: 2653.7363, mean_steps: 18.6100, mean_ecr: 0.0401 mean_entropies: 1.7637, took: 94.2033s
2022-10-09 05:05:29,254 [INFO] 	Process 5 - batch 16699: mean_policy_losses: -86.305, mean_net_lifetime: 5417.7779, mean_mc_travel_dist: 2029.8377, mean_rewards: 222.6354, total_rewards: 3427.8624, mean_steps: 27.3100, mean_ecr: 0.0385 mean_entropies: 1.8463, took: 139.7919s
2022-10-09 05:05:32,320 [INFO] 	Process 6 - batch 17099: mean_policy_losses: -123.951, mean_net_lifetime: 4470.5589, mean_mc_travel_dist: 1580.1641, mean_rewards: 214.1039, total_rewards: 2924.3884, mean_steps: 22.1300, mean_ecr: 0.0380 mean_entropies: 1.7959, took: 115.3328s
2022-10-09 05:05:36,825 [INFO] 	Process 2 - batch 17299: mean_policy_losses: -176.885, mean_net_lifetime: 3810.5295, mean_mc_travel_dist: 1333.2641, mean_rewards: 219.8037, total_rewards: 2517.6127, mean_steps: 18.1200, mean_ecr: 0.0388 mean_entropies: 1.7242, took: 98.8596s
2022-10-09 05:05:56,321 [INFO] 	Process 4 - batch 17199: mean_policy_losses: -77.485, mean_net_lifetime: 4182.8410, mean_mc_travel_dist: 1454.1646, mean_rewards: 218.4512, total_rewards: 2764.3097, mean_steps: 20.2800, mean_ecr: 0.0381 mean_entropies: 1.8157, took: 105.9593s
2022-10-09 05:05:57,746 [INFO] 	Process 3 - batch 17199: mean_policy_losses: -106.112, mean_net_lifetime: 4128.7523, mean_mc_travel_dist: 1450.7682, mean_rewards: 215.3410, total_rewards: 2714.3238, mean_steps: 20.3400, mean_ecr: 0.0381 mean_entropies: 1.8077, took: 107.5643s
2022-10-09 05:05:59,426 [INFO] 	Process 0 - batch 16699: mean_policy_losses: -134.671, mean_net_lifetime: 5313.6504, mean_mc_travel_dist: 2008.8869, mean_rewards: 224.2689, total_rewards: 3338.6019, mean_steps: 28.4800, mean_ecr: 0.0387 mean_entropies: 1.8104, took: 145.9062s
2022-10-09 05:06:44,977 [INFO] 	Process 1 - batch 17699: mean_policy_losses: -183.972, mean_net_lifetime: 3766.2165, mean_mc_travel_dist: 1350.5544, mean_rewards: 214.0750, total_rewards: 2460.6484, mean_steps: 18.0200, mean_ecr: 0.0386 mean_entropies: 1.7223, took: 90.5896s
2022-10-09 05:07:14,777 [INFO] 	Process 5 - batch 16799: mean_policy_losses: -15.422, mean_net_lifetime: 4115.6495, mean_mc_travel_dist: 1445.7115, mean_rewards: 220.5764, total_rewards: 2706.3643, mean_steps: 19.7400, mean_ecr: 0.0393 mean_entropies: 1.7515, took: 105.5215s
2022-10-09 05:07:16,685 [INFO] 	Process 2 - batch 17399: mean_policy_losses: -194.550, mean_net_lifetime: 4005.2918, mean_mc_travel_dist: 1421.8944, mean_rewards: 221.0730, total_rewards: 2622.5405, mean_steps: 18.8900, mean_ecr: 0.0383 mean_entropies: 1.7520, took: 99.8599s
2022-10-09 05:07:19,078 [INFO] 	Process 6 - batch 17199: mean_policy_losses: -7.679, mean_net_lifetime: 4179.9403, mean_mc_travel_dist: 1443.8324, mean_rewards: 211.7194, total_rewards: 2773.1650, mean_steps: 20.5500, mean_ecr: 0.0382 mean_entropies: 1.8013, took: 106.7576s
2022-10-09 05:07:36,009 [INFO] 	Process 4 - batch 17299: mean_policy_losses: -85.806, mean_net_lifetime: 3954.3616, mean_mc_travel_dist: 1402.2370, mean_rewards: 221.9320, total_rewards: 2591.6967, mean_steps: 18.6800, mean_ecr: 0.0384 mean_entropies: 1.7245, took: 99.6880s
2022-10-09 05:07:36,086 [INFO] 	Process 3 - batch 17299: mean_policy_losses: -87.421, mean_net_lifetime: 3892.1537, mean_mc_travel_dist: 1348.6794, mean_rewards: 218.8421, total_rewards: 2583.3695, mean_steps: 18.7400, mean_ecr: 0.0386 mean_entropies: 1.7289, took: 98.3400s
2022-10-09 05:07:48,942 [INFO] 	Process 0 - batch 16799: mean_policy_losses: -59.899, mean_net_lifetime: 4218.6864, mean_mc_travel_dist: 1477.7973, mean_rewards: 221.2282, total_rewards: 2778.5875, mean_steps: 20.6500, mean_ecr: 0.0392 mean_entropies: 1.7778, took: 109.5172s
2022-10-09 05:08:18,146 [INFO] 	Process 1 - batch 17799: mean_policy_losses: -174.146, mean_net_lifetime: 3872.0164, mean_mc_travel_dist: 1363.7285, mean_rewards: 222.7058, total_rewards: 2550.1310, mean_steps: 18.5300, mean_ecr: 0.0387 mean_entropies: 1.7515, took: 93.1693s
2022-10-09 05:08:54,659 [INFO] 	Process 6 - batch 17299: mean_policy_losses: -203.196, mean_net_lifetime: 3811.4308, mean_mc_travel_dist: 1346.1999, mean_rewards: 223.3497, total_rewards: 2504.5536, mean_steps: 18.1100, mean_ecr: 0.0388 mean_entropies: 1.7277, took: 95.5813s
2022-10-09 05:09:03,938 [INFO] 	Process 2 - batch 17499: mean_policy_losses: -111.410, mean_net_lifetime: 4239.9581, mean_mc_travel_dist: 1487.7148, mean_rewards: 227.5036, total_rewards: 2786.4847, mean_steps: 20.1400, mean_ecr: 0.0386 mean_entropies: 1.7923, took: 107.2526s
2022-10-09 05:09:06,278 [INFO] 	Process 3 - batch 17399: mean_policy_losses: -383.136, mean_net_lifetime: 3582.3660, mean_mc_travel_dist: 1250.9444, mean_rewards: 222.5309, total_rewards: 2371.5506, mean_steps: 16.9200, mean_ecr: 0.0385 mean_entropies: 1.7883, took: 90.1928s
2022-10-09 05:09:19,205 [INFO] 	Process 5 - batch 16899: mean_policy_losses: -52.204, mean_net_lifetime: 4534.6441, mean_mc_travel_dist: 1615.7285, mean_rewards: 207.3031, total_rewards: 2953.0486, mean_steps: 24.0900, mean_ecr: 0.0395 mean_entropies: 1.8328, took: 124.4286s
2022-10-09 05:09:23,436 [INFO] 	Process 4 - batch 17399: mean_policy_losses: -207.297, mean_net_lifetime: 4295.5281, mean_mc_travel_dist: 1531.5469, mean_rewards: 224.9609, total_rewards: 2797.7511, mean_steps: 20.5100, mean_ecr: 0.0385 mean_entropies: 1.8190, took: 107.4265s
2022-10-09 05:10:06,057 [INFO] 	Process 0 - batch 16899: mean_policy_losses: 7.975, mean_net_lifetime: 5038.4694, mean_mc_travel_dist: 1798.6598, mean_rewards: 212.7805, total_rewards: 3274.5013, mean_steps: 26.5100, mean_ecr: 0.0397 mean_entropies: 1.8308, took: 137.1140s
2022-10-09 05:10:13,157 [INFO] 	Process 1 - batch 17899: mean_policy_losses: -61.276, mean_net_lifetime: 4759.6114, mean_mc_travel_dist: 1692.1151, mean_rewards: 212.2670, total_rewards: 3101.1664, mean_steps: 23.2000, mean_ecr: 0.0390 mean_entropies: 1.8038, took: 115.0108s
2022-10-09 05:10:36,521 [INFO] 	Process 6 - batch 17399: mean_policy_losses: -86.129, mean_net_lifetime: 4063.3509, mean_mc_travel_dist: 1411.4252, mean_rewards: 217.5030, total_rewards: 2681.1551, mean_steps: 19.2400, mean_ecr: 0.0382 mean_entropies: 1.8455, took: 101.8617s
2022-10-09 05:10:43,592 [INFO] 	Process 2 - batch 17599: mean_policy_losses: -43.137, mean_net_lifetime: 4063.7880, mean_mc_travel_dist: 1400.8004, mean_rewards: 224.4200, total_rewards: 2700.3518, mean_steps: 18.9400, mean_ecr: 0.0406 mean_entropies: 1.7759, took: 99.6547s
2022-10-09 05:10:52,793 [INFO] 	Process 5 - batch 16999: mean_policy_losses: -173.303, mean_net_lifetime: 3686.7999, mean_mc_travel_dist: 1287.1302, mean_rewards: 218.9790, total_rewards: 2432.0996, mean_steps: 17.6800, mean_ecr: 0.0402 mean_entropies: 1.7428, took: 93.5871s
2022-10-09 05:10:55,400 [INFO] 	Process 3 - batch 17499: mean_policy_losses: -55.493, mean_net_lifetime: 4318.3786, mean_mc_travel_dist: 1526.5308, mean_rewards: 215.8895, total_rewards: 2830.4467, mean_steps: 20.8900, mean_ecr: 0.0384 mean_entropies: 1.8063, took: 109.1214s
2022-10-09 05:11:07,420 [INFO] 	Process 4 - batch 17499: mean_policy_losses: -97.031, mean_net_lifetime: 4204.8403, mean_mc_travel_dist: 1492.1008, mean_rewards: 225.5460, total_rewards: 2754.0861, mean_steps: 19.7600, mean_ecr: 0.0386 mean_entropies: 1.8023, took: 103.9840s
2022-10-09 05:11:39,822 [INFO] 	Process 0 - batch 16999: mean_policy_losses: -127.997, mean_net_lifetime: 3730.4217, mean_mc_travel_dist: 1276.2961, mean_rewards: 221.9550, total_rewards: 2492.9640, mean_steps: 17.5500, mean_ecr: 0.0396 mean_entropies: 1.7943, took: 93.7655s
2022-10-09 05:12:02,256 [INFO] 	Process 1 - batch 17999: mean_policy_losses: 32.671, mean_net_lifetime: 4697.8686, mean_mc_travel_dist: 1639.7051, mean_rewards: 221.9829, total_rewards: 3085.5354, mean_steps: 21.9800, mean_ecr: 0.0389 mean_entropies: 1.8116, took: 109.0999s
2022-10-09 05:12:20,140 [INFO] 	Process 2 - batch 17699: mean_policy_losses: -219.165, mean_net_lifetime: 3802.4144, mean_mc_travel_dist: 1323.2217, mean_rewards: 215.3046, total_rewards: 2519.6020, mean_steps: 18.4500, mean_ecr: 0.0384 mean_entropies: 1.8100, took: 96.5469s
2022-10-09 05:12:21,386 [INFO] 	Process 6 - batch 17499: mean_policy_losses: -83.577, mean_net_lifetime: 4240.3668, mean_mc_travel_dist: 1519.8702, mean_rewards: 217.3360, total_rewards: 2762.7084, mean_steps: 20.3100, mean_ecr: 0.0384 mean_entropies: 1.8225, took: 104.8655s
2022-10-09 05:12:36,529 [INFO] 	Process 3 - batch 17599: mean_policy_losses: -100.696, mean_net_lifetime: 4258.7980, mean_mc_travel_dist: 1445.0855, mean_rewards: 226.6549, total_rewards: 2846.5391, mean_steps: 19.4300, mean_ecr: 0.0402 mean_entropies: 1.7847, took: 101.1291s
2022-10-09 05:12:41,427 [INFO] 	Process 4 - batch 17599: mean_policy_losses: -48.415, mean_net_lifetime: 4022.6746, mean_mc_travel_dist: 1354.1946, mean_rewards: 234.6847, total_rewards: 2699.1539, mean_steps: 17.7800, mean_ecr: 0.0403 mean_entropies: 1.7925, took: 94.0069s
2022-10-09 05:12:52,988 [INFO] 	Process 5 - batch 17099: mean_policy_losses: -109.381, mean_net_lifetime: 4752.3866, mean_mc_travel_dist: 1669.5405, mean_rewards: 213.4390, total_rewards: 3111.5704, mean_steps: 23.1300, mean_ecr: 0.0384 mean_entropies: 1.8131, took: 120.1919s
2022-10-09 05:13:22,066 [INFO] 	Process 0 - batch 17099: mean_policy_losses: -159.785, mean_net_lifetime: 3985.6026, mean_mc_travel_dist: 1380.1722, mean_rewards: 218.1442, total_rewards: 2641.5195, mean_steps: 19.3500, mean_ecr: 0.0388 mean_entropies: 1.7947, took: 102.2433s
2022-10-09 05:13:59,028 [INFO] 	Process 2 - batch 17799: mean_policy_losses: -143.852, mean_net_lifetime: 4065.4140, mean_mc_travel_dist: 1420.1707, mean_rewards: 219.3823, total_rewards: 2686.1906, mean_steps: 19.5100, mean_ecr: 0.0389 mean_entropies: 1.7610, took: 98.8885s
2022-10-09 05:14:02,973 [INFO] 	Process 6 - batch 17599: mean_policy_losses: -114.164, mean_net_lifetime: 4170.2470, mean_mc_travel_dist: 1460.0293, mean_rewards: 222.3231, total_rewards: 2747.4665, mean_steps: 19.8200, mean_ecr: 0.0400 mean_entropies: 1.7795, took: 101.5866s
2022-10-09 05:14:19,166 [INFO] 	Process 4 - batch 17699: mean_policy_losses: -215.233, mean_net_lifetime: 3927.4177, mean_mc_travel_dist: 1347.9273, mean_rewards: 215.4763, total_rewards: 2617.3535, mean_steps: 18.9100, mean_ecr: 0.0382 mean_entropies: 1.7439, took: 97.7381s
2022-10-09 05:14:23,251 [INFO] 	Process 3 - batch 17699: mean_policy_losses: -114.673, mean_net_lifetime: 4342.0167, mean_mc_travel_dist: 1516.8791, mean_rewards: 218.2942, total_rewards: 2855.9315, mean_steps: 21.2600, mean_ecr: 0.0382 mean_entropies: 1.7589, took: 106.7220s
2022-10-09 05:14:34,501 [INFO] 	Process 5 - batch 17199: mean_policy_losses: -118.050, mean_net_lifetime: 4057.2695, mean_mc_travel_dist: 1406.4026, mean_rewards: 213.5625, total_rewards: 2685.5225, mean_steps: 20.0700, mean_ecr: 0.0383 mean_entropies: 1.8417, took: 101.5169s
2022-10-09 05:15:08,251 [INFO] 	Process 0 - batch 17199: mean_policy_losses: -74.522, mean_net_lifetime: 4197.7716, mean_mc_travel_dist: 1457.5768, mean_rewards: 216.5208, total_rewards: 2775.9763, mean_steps: 20.7900, mean_ecr: 0.0384 mean_entropies: 1.7995, took: 106.1855s
2022-10-09 05:15:40,922 [INFO] 	Process 6 - batch 17699: mean_policy_losses: -154.319, mean_net_lifetime: 3997.5507, mean_mc_travel_dist: 1424.6016, mean_rewards: 214.9422, total_rewards: 2615.6876, mean_steps: 19.1700, mean_ecr: 0.0387 mean_entropies: 1.7093, took: 97.9495s
2022-10-09 05:15:44,792 [INFO] 	Process 2 - batch 17899: mean_policy_losses: -46.363, mean_net_lifetime: 4292.1743, mean_mc_travel_dist: 1515.0405, mean_rewards: 212.5819, total_rewards: 2812.2422, mean_steps: 20.8800, mean_ecr: 0.0393 mean_entropies: 1.7337, took: 105.7629s
2022-10-09 05:15:59,359 [INFO] 	Process 4 - batch 17799: mean_policy_losses: -130.100, mean_net_lifetime: 4123.4032, mean_mc_travel_dist: 1448.9387, mean_rewards: 219.5567, total_rewards: 2711.3832, mean_steps: 19.8100, mean_ecr: 0.0387 mean_entropies: 1.7361, took: 100.1941s
2022-10-09 05:16:04,129 [INFO] 	Process 3 - batch 17799: mean_policy_losses: -102.167, mean_net_lifetime: 4099.1069, mean_mc_travel_dist: 1457.5154, mean_rewards: 220.9564, total_rewards: 2674.0404, mean_steps: 19.7900, mean_ecr: 0.0386 mean_entropies: 1.7386, took: 100.8776s
2022-10-09 05:16:06,885 [INFO] 	Process 5 - batch 17299: mean_policy_losses: -161.576, mean_net_lifetime: 3854.8409, mean_mc_travel_dist: 1377.9830, mean_rewards: 222.3269, total_rewards: 2517.3391, mean_steps: 18.4500, mean_ecr: 0.0388 mean_entropies: 1.6618, took: 92.3846s
2022-10-09 05:16:46,597 [INFO] 	Process 0 - batch 17299: mean_policy_losses: -160.679, mean_net_lifetime: 3916.8201, mean_mc_travel_dist: 1381.3970, mean_rewards: 220.2264, total_rewards: 2576.8059, mean_steps: 19.0400, mean_ecr: 0.0381 mean_entropies: 1.7265, took: 98.3456s
2022-10-09 05:17:19,507 [INFO] 	Process 6 - batch 17799: mean_policy_losses: -109.995, mean_net_lifetime: 4027.4846, mean_mc_travel_dist: 1426.6484, mean_rewards: 218.0093, total_rewards: 2640.9064, mean_steps: 19.4100, mean_ecr: 0.0386 mean_entropies: 1.7398, took: 98.5852s
2022-10-09 05:17:41,404 [INFO] 	Process 5 - batch 17399: mean_policy_losses: -270.450, mean_net_lifetime: 3863.5018, mean_mc_travel_dist: 1331.0529, mean_rewards: 223.3528, total_rewards: 2572.6120, mean_steps: 18.2000, mean_ecr: 0.0384 mean_entropies: 1.7562, took: 94.5191s
2022-10-09 05:17:46,527 [INFO] 	Process 2 - batch 17999: mean_policy_losses: -62.382, mean_net_lifetime: 4847.8604, mean_mc_travel_dist: 1744.2592, mean_rewards: 217.9756, total_rewards: 3134.8231, mean_steps: 24.0000, mean_ecr: 0.0387 mean_entropies: 1.7854, took: 121.7360s
2022-10-09 05:17:49,624 [INFO] 	Process 3 - batch 17899: mean_policy_losses: -85.110, mean_net_lifetime: 4343.5157, mean_mc_travel_dist: 1552.4374, mean_rewards: 214.3441, total_rewards: 2823.0239, mean_steps: 20.9100, mean_ecr: 0.0395 mean_entropies: 1.7324, took: 105.4953s
2022-10-09 05:17:51,030 [INFO] 	Process 4 - batch 17899: mean_policy_losses: 34.331, mean_net_lifetime: 4527.2820, mean_mc_travel_dist: 1613.5557, mean_rewards: 210.7616, total_rewards: 2945.9489, mean_steps: 22.3100, mean_ecr: 0.0395 mean_entropies: 1.7445, took: 111.6714s
2022-10-09 05:18:24,244 [INFO] 	Process 0 - batch 17399: mean_policy_losses: -161.190, mean_net_lifetime: 4072.8183, mean_mc_travel_dist: 1424.4516, mean_rewards: 224.8868, total_rewards: 2684.3691, mean_steps: 18.8700, mean_ecr: 0.0380 mean_entropies: 1.7830, took: 97.6469s
2022-10-09 05:18:55,282 [INFO] 	Process 6 - batch 17899: mean_policy_losses: -118.937, mean_net_lifetime: 4110.9816, mean_mc_travel_dist: 1445.2614, mean_rewards: 218.4871, total_rewards: 2702.6573, mean_steps: 19.2100, mean_ecr: 0.0394 mean_entropies: 1.7689, took: 95.7745s
2022-10-09 05:19:13,265 [INFO] 	Process 5 - batch 17499: mean_policy_losses: -77.938, mean_net_lifetime: 4079.0324, mean_mc_travel_dist: 1416.0440, mean_rewards: 228.0766, total_rewards: 2697.3540, mean_steps: 18.5900, mean_ecr: 0.0384 mean_entropies: 1.7628, took: 91.8605s
2022-10-09 05:19:24,867 [INFO] 	Process 3 - batch 17999: mean_policy_losses: -91.786, mean_net_lifetime: 4144.3784, mean_mc_travel_dist: 1424.3118, mean_rewards: 227.3197, total_rewards: 2755.7636, mean_steps: 19.1800, mean_ecr: 0.0389 mean_entropies: 1.7928, took: 95.2426s
2022-10-09 05:19:32,043 [INFO] 	Process 4 - batch 17999: mean_policy_losses: -80.850, mean_net_lifetime: 4400.9870, mean_mc_travel_dist: 1563.7373, mean_rewards: 223.6427, total_rewards: 2875.5226, mean_steps: 20.4700, mean_ecr: 0.0379 mean_entropies: 1.8027, took: 101.0124s
2022-10-09 05:20:10,344 [INFO] 	Process 0 - batch 17499: mean_policy_losses: -101.546, mean_net_lifetime: 4646.4362, mean_mc_travel_dist: 1701.9882, mean_rewards: 223.0625, total_rewards: 2979.1254, mean_steps: 22.3800, mean_ecr: 0.0386 mean_entropies: 1.7748, took: 106.1005s
2022-10-09 05:20:33,649 [INFO] 	Process 6 - batch 17999: mean_policy_losses: -27.759, mean_net_lifetime: 4400.4454, mean_mc_travel_dist: 1525.9293, mean_rewards: 216.1280, total_rewards: 2901.7316, mean_steps: 20.7600, mean_ecr: 0.0384 mean_entropies: 1.8278, took: 98.3672s
2022-10-09 05:20:39,436 [INFO] 	Process 5 - batch 17599: mean_policy_losses: -150.031, mean_net_lifetime: 3858.1920, mean_mc_travel_dist: 1348.2246, mean_rewards: 225.4134, total_rewards: 2547.1854, mean_steps: 18.2600, mean_ecr: 0.0401 mean_entropies: 1.7676, took: 86.1705s
2022-10-09 05:21:39,437 [INFO] 	Process 0 - batch 17599: mean_policy_losses: -204.251, mean_net_lifetime: 4028.8319, mean_mc_travel_dist: 1426.2591, mean_rewards: 223.4692, total_rewards: 2640.9239, mean_steps: 19.0900, mean_ecr: 0.0404 mean_entropies: 1.7737, took: 89.0926s
2022-10-09 05:22:09,931 [INFO] 	Process 5 - batch 17699: mean_policy_losses: -139.206, mean_net_lifetime: 4139.8640, mean_mc_travel_dist: 1452.8297, mean_rewards: 219.0465, total_rewards: 2726.8220, mean_steps: 19.8200, mean_ecr: 0.0385 mean_entropies: 1.7328, took: 90.4952s
2022-10-09 05:23:10,887 [INFO] 	Process 0 - batch 17699: mean_policy_losses: -80.393, mean_net_lifetime: 4164.7046, mean_mc_travel_dist: 1443.4756, mean_rewards: 216.2014, total_rewards: 2767.2311, mean_steps: 19.9500, mean_ecr: 0.0387 mean_entropies: 1.7694, took: 91.4506s
2022-10-09 05:23:29,015 [INFO] 	Process 5 - batch 17799: mean_policy_losses: -89.592, mean_net_lifetime: 3849.8465, mean_mc_travel_dist: 1353.9759, mean_rewards: 222.1935, total_rewards: 2535.7111, mean_steps: 17.9900, mean_ecr: 0.0388 mean_entropies: 1.7452, took: 79.0842s
2022-10-09 05:24:38,895 [INFO] 	Process 0 - batch 17799: mean_policy_losses: -103.893, mean_net_lifetime: 4032.2953, mean_mc_travel_dist: 1414.3983, mean_rewards: 217.8169, total_rewards: 2655.9221, mean_steps: 19.4400, mean_ecr: 0.0387 mean_entropies: 1.7488, took: 88.0076s
2022-10-09 05:24:54,702 [INFO] 	Process 5 - batch 17899: mean_policy_losses: -34.275, mean_net_lifetime: 4102.8104, mean_mc_travel_dist: 1426.4478, mean_rewards: 220.5467, total_rewards: 2714.8284, mean_steps: 19.3100, mean_ecr: 0.0390 mean_entropies: 1.7390, took: 85.6870s
2022-10-09 05:26:04,199 [INFO] 	Process 0 - batch 17899: mean_policy_losses: -79.026, mean_net_lifetime: 4015.4186, mean_mc_travel_dist: 1409.6007, mean_rewards: 222.0026, total_rewards: 2641.6928, mean_steps: 18.2800, mean_ecr: 0.0392 mean_entropies: 1.7270, took: 85.3042s
2022-10-09 05:26:07,162 [INFO] 	Process 1 - batch 18099: mean_policy_losses: -116.433, mean_net_lifetime: 3931.0603, mean_mc_travel_dist: 1397.8177, mean_rewards: 219.3027, total_rewards: 2577.0699, mean_steps: 18.3400, mean_ecr: 0.0398 mean_entropies: 1.7151, took: 844.9050s
2022-10-09 05:26:28,809 [INFO] 	Process 5 - batch 17999: mean_policy_losses: -37.143, mean_net_lifetime: 4390.4316, mean_mc_travel_dist: 1641.5015, mean_rewards: 222.0913, total_rewards: 2796.8464, mean_steps: 20.1900, mean_ecr: 0.0382 mean_entropies: 1.7492, took: 94.1065s
2022-10-09 05:27:22,661 [INFO] 	Process 1 - batch 18199: mean_policy_losses: -100.931, mean_net_lifetime: 3834.5981, mean_mc_travel_dist: 1338.5629, mean_rewards: 220.6582, total_rewards: 2533.4075, mean_steps: 17.6800, mean_ecr: 0.0393 mean_entropies: 1.7086, took: 75.4991s
2022-10-09 05:27:31,258 [INFO] 	Process 0 - batch 17999: mean_policy_losses: -52.551, mean_net_lifetime: 4131.9308, mean_mc_travel_dist: 1454.2666, mean_rewards: 223.5571, total_rewards: 2705.7098, mean_steps: 18.9300, mean_ecr: 0.0391 mean_entropies: 1.7488, took: 87.0574s
2022-10-09 05:28:48,483 [INFO] 	Process 1 - batch 18299: mean_policy_losses: -119.614, mean_net_lifetime: 4376.0340, mean_mc_travel_dist: 1556.3059, mean_rewards: 215.0986, total_rewards: 2851.2976, mean_steps: 21.2400, mean_ecr: 0.0393 mean_entropies: 1.7762, took: 85.8224s
2022-10-09 05:30:06,458 [INFO] 	Process 1 - batch 18399: mean_policy_losses: -127.576, mean_net_lifetime: 3899.3554, mean_mc_travel_dist: 1407.0219, mean_rewards: 217.7319, total_rewards: 2537.1057, mean_steps: 19.0200, mean_ecr: 0.0391 mean_entropies: 1.7663, took: 77.9749s
2022-10-09 05:30:41,519 [INFO] 	Process 2 - batch 18099: mean_policy_losses: -39.228, mean_net_lifetime: 3943.4058, mean_mc_travel_dist: 1362.9153, mean_rewards: 224.3413, total_rewards: 2619.1737, mean_steps: 18.2700, mean_ecr: 0.0403 mean_entropies: 1.7414, took: 774.9914s
2022-10-09 05:31:24,173 [INFO] 	Process 1 - batch 18499: mean_policy_losses: -142.485, mean_net_lifetime: 3993.3238, mean_mc_travel_dist: 1403.1070, mean_rewards: 227.2257, total_rewards: 2617.0267, mean_steps: 18.3800, mean_ecr: 0.0389 mean_entropies: 1.7282, took: 77.7147s
2022-10-09 05:32:14,325 [INFO] 	Process 2 - batch 18199: mean_policy_losses: -0.188, mean_net_lifetime: 4230.2335, mean_mc_travel_dist: 1458.6956, mean_rewards: 220.5809, total_rewards: 2814.0164, mean_steps: 19.8800, mean_ecr: 0.0392 mean_entropies: 1.6949, took: 92.8061s
2022-10-09 05:32:34,447 [INFO] 	Process 3 - batch 18099: mean_policy_losses: -5.041, mean_net_lifetime: 4275.3833, mean_mc_travel_dist: 1485.9894, mean_rewards: 221.5416, total_rewards: 2826.2447, mean_steps: 20.3000, mean_ecr: 0.0401 mean_entropies: 1.7097, took: 789.5800s
2022-10-09 05:32:43,080 [INFO] 	Process 1 - batch 18599: mean_policy_losses: -214.401, mean_net_lifetime: 3695.6807, mean_mc_travel_dist: 1324.9524, mean_rewards: 228.6745, total_rewards: 2416.3964, mean_steps: 17.0200, mean_ecr: 0.0388 mean_entropies: 1.7016, took: 78.9075s
2022-10-09 05:33:11,449 [INFO] 	Process 4 - batch 18099: mean_policy_losses: -40.221, mean_net_lifetime: 4095.3506, mean_mc_travel_dist: 1445.0773, mean_rewards: 214.2886, total_rewards: 2687.8428, mean_steps: 19.7600, mean_ecr: 0.0401 mean_entropies: 1.7295, took: 819.4068s
2022-10-09 05:33:56,379 [INFO] 	Process 2 - batch 18299: mean_policy_losses: -103.746, mean_net_lifetime: 4180.5664, mean_mc_travel_dist: 1513.9550, mean_rewards: 216.8793, total_rewards: 2706.5485, mean_steps: 20.2700, mean_ecr: 0.0392 mean_entropies: 1.7129, took: 102.0538s
2022-10-09 05:33:59,311 [INFO] 	Process 6 - batch 18099: mean_policy_losses: 17.292, mean_net_lifetime: 4470.8996, mean_mc_travel_dist: 1548.2013, mean_rewards: 217.2752, total_rewards: 2962.9581, mean_steps: 21.3700, mean_ecr: 0.0401 mean_entropies: 1.7271, took: 805.6621s
2022-10-09 05:34:06,523 [INFO] 	Process 3 - batch 18199: mean_policy_losses: -159.814, mean_net_lifetime: 3894.1789, mean_mc_travel_dist: 1331.1970, mean_rewards: 218.1908, total_rewards: 2602.0187, mean_steps: 18.3300, mean_ecr: 0.0392 mean_entropies: 1.6866, took: 92.0758s
2022-10-09 05:34:21,010 [INFO] 	Process 1 - batch 18699: mean_policy_losses: -32.859, mean_net_lifetime: 4252.3330, mean_mc_travel_dist: 1463.9057, mean_rewards: 204.2057, total_rewards: 2826.8150, mean_steps: 20.8800, mean_ecr: 0.0399 mean_entropies: 1.7518, took: 97.9292s
2022-10-09 05:34:41,722 [INFO] 	Process 4 - batch 18199: mean_policy_losses: -109.843, mean_net_lifetime: 3939.1968, mean_mc_travel_dist: 1329.1527, mean_rewards: 221.2859, total_rewards: 2643.0756, mean_steps: 18.3200, mean_ecr: 0.0395 mean_entropies: 1.6597, took: 90.2722s
2022-10-09 05:35:35,016 [INFO] 	Process 6 - batch 18199: mean_policy_losses: -74.057, mean_net_lifetime: 3962.7506, mean_mc_travel_dist: 1368.9383, mean_rewards: 223.3245, total_rewards: 2632.7228, mean_steps: 19.1100, mean_ecr: 0.0393 mean_entropies: 1.6688, took: 95.7045s
2022-10-09 05:35:42,814 [INFO] 	Process 3 - batch 18299: mean_policy_losses: -55.601, mean_net_lifetime: 3985.0578, mean_mc_travel_dist: 1384.2382, mean_rewards: 212.1750, total_rewards: 2636.7974, mean_steps: 19.7500, mean_ecr: 0.0391 mean_entropies: 1.6860, took: 96.2908s
2022-10-09 05:35:57,940 [INFO] 	Process 2 - batch 18399: mean_policy_losses: -90.478, mean_net_lifetime: 4904.8776, mean_mc_travel_dist: 1852.9062, mean_rewards: 217.4023, total_rewards: 3086.2219, mean_steps: 24.8100, mean_ecr: 0.0387 mean_entropies: 1.7161, took: 121.5623s
2022-10-09 05:36:11,527 [INFO] 	Process 1 - batch 18799: mean_policy_losses: -72.196, mean_net_lifetime: 4616.5222, mean_mc_travel_dist: 1672.8617, mean_rewards: 211.4371, total_rewards: 2976.6310, mean_steps: 23.9300, mean_ecr: 0.0393 mean_entropies: 1.6889, took: 110.5175s
2022-10-09 05:36:25,281 [INFO] 	Process 4 - batch 18299: mean_policy_losses: -93.811, mean_net_lifetime: 4268.6259, mean_mc_travel_dist: 1511.9194, mean_rewards: 217.7144, total_rewards: 2791.8067, mean_steps: 21.1700, mean_ecr: 0.0392 mean_entropies: 1.6786, took: 103.5596s
2022-10-09 05:37:23,042 [INFO] 	Process 6 - batch 18299: mean_policy_losses: -80.024, mean_net_lifetime: 4353.0185, mean_mc_travel_dist: 1579.4951, mean_rewards: 208.6168, total_rewards: 2818.2281, mean_steps: 22.2300, mean_ecr: 0.0390 mean_entropies: 1.6962, took: 108.0258s
2022-10-09 05:37:25,956 [INFO] 	Process 3 - batch 18399: mean_policy_losses: -102.679, mean_net_lifetime: 4257.4495, mean_mc_travel_dist: 1513.9599, mean_rewards: 218.0387, total_rewards: 2779.6478, mean_steps: 21.3400, mean_ecr: 0.0391 mean_entropies: 1.7004, took: 103.1421s
2022-10-09 05:37:42,343 [INFO] 	Process 1 - batch 18899: mean_policy_losses: -66.294, mean_net_lifetime: 4022.6474, mean_mc_travel_dist: 1377.5901, mean_rewards: 222.8591, total_rewards: 2674.9680, mean_steps: 19.1400, mean_ecr: 0.0395 mean_entropies: 1.6902, took: 90.8161s
2022-10-09 05:37:46,342 [INFO] 	Process 2 - batch 18499: mean_policy_losses: -78.509, mean_net_lifetime: 4352.8243, mean_mc_travel_dist: 1542.8731, mean_rewards: 219.7929, total_rewards: 2848.7637, mean_steps: 21.4900, mean_ecr: 0.0389 mean_entropies: 1.6894, took: 108.4019s
2022-10-09 05:38:07,036 [INFO] 	Process 4 - batch 18399: mean_policy_losses: -111.406, mean_net_lifetime: 4072.5898, mean_mc_travel_dist: 1437.3731, mean_rewards: 215.3733, total_rewards: 2671.3234, mean_steps: 20.5800, mean_ecr: 0.0388 mean_entropies: 1.7164, took: 101.7545s
2022-10-09 05:39:04,102 [INFO] 	Process 3 - batch 18499: mean_policy_losses: -54.046, mean_net_lifetime: 4081.4925, mean_mc_travel_dist: 1390.6636, mean_rewards: 220.3553, total_rewards: 2732.6783, mean_steps: 19.5200, mean_ecr: 0.0387 mean_entropies: 1.6941, took: 98.1465s
2022-10-09 05:39:05,388 [INFO] 	Process 6 - batch 18399: mean_policy_losses: -114.117, mean_net_lifetime: 4098.1612, mean_mc_travel_dist: 1387.7014, mean_rewards: 225.1402, total_rewards: 2733.9400, mean_steps: 20.2700, mean_ecr: 0.0389 mean_entropies: 1.7267, took: 102.3442s
2022-10-09 05:39:19,322 [INFO] 	Process 1 - batch 18999: mean_policy_losses: -210.072, mean_net_lifetime: 4017.8216, mean_mc_travel_dist: 1442.4955, mean_rewards: 212.8708, total_rewards: 2609.7136, mean_steps: 20.1500, mean_ecr: 0.0381 mean_entropies: 1.7141, took: 96.9796s
2022-10-09 05:39:30,608 [INFO] 	Process 2 - batch 18599: mean_policy_losses: -142.107, mean_net_lifetime: 4308.3704, mean_mc_travel_dist: 1561.6554, mean_rewards: 224.2610, total_rewards: 2785.8601, mean_steps: 20.8900, mean_ecr: 0.0388 mean_entropies: 1.7178, took: 104.2650s
2022-10-09 05:39:50,119 [INFO] 	Process 4 - batch 18499: mean_policy_losses: -84.082, mean_net_lifetime: 4194.6913, mean_mc_travel_dist: 1466.2109, mean_rewards: 223.4438, total_rewards: 2767.5204, mean_steps: 20.1700, mean_ecr: 0.0386 mean_entropies: 1.6895, took: 103.0834s
2022-10-09 05:39:50,486 [INFO] 	Process 5 - batch 18099: mean_policy_losses: -29.217, mean_net_lifetime: 4284.9580, mean_mc_travel_dist: 1494.5316, mean_rewards: 214.1412, total_rewards: 2826.3477, mean_steps: 21.1400, mean_ecr: 0.0400 mean_entropies: 1.7025, took: 801.6781s
2022-10-09 05:40:38,047 [INFO] 	Process 3 - batch 18599: mean_policy_losses: -244.748, mean_net_lifetime: 3846.5591, mean_mc_travel_dist: 1382.5474, mean_rewards: 218.7201, total_rewards: 2509.8270, mean_steps: 18.2500, mean_ecr: 0.0397 mean_entropies: 1.6901, took: 93.9449s
2022-10-09 05:40:38,412 [INFO] 	Process 6 - batch 18499: mean_policy_losses: -170.272, mean_net_lifetime: 3865.2809, mean_mc_travel_dist: 1347.7657, mean_rewards: 223.4509, total_rewards: 2554.7410, mean_steps: 18.0400, mean_ecr: 0.0387 mean_entropies: 1.6748, took: 93.0269s
2022-10-09 05:41:04,642 [INFO] 	Process 1 - batch 19099: mean_policy_losses: 29.055, mean_net_lifetime: 4459.9343, mean_mc_travel_dist: 1550.0237, mean_rewards: 225.4140, total_rewards: 2943.5517, mean_steps: 21.4200, mean_ecr: 0.0381 mean_entropies: 1.6920, took: 105.3195s
2022-10-09 05:41:16,475 [INFO] 	Process 2 - batch 18699: mean_policy_losses: -101.212, mean_net_lifetime: 4124.7303, mean_mc_travel_dist: 1438.6011, mean_rewards: 213.4458, total_rewards: 2717.2686, mean_steps: 20.0400, mean_ecr: 0.0397 mean_entropies: 1.7331, took: 105.8675s
2022-10-09 05:41:29,672 [INFO] 	Process 5 - batch 18199: mean_policy_losses: -24.573, mean_net_lifetime: 3942.4110, mean_mc_travel_dist: 1348.5445, mean_rewards: 217.0308, total_rewards: 2636.0828, mean_steps: 18.7500, mean_ecr: 0.0394 mean_entropies: 1.6857, took: 99.1852s
2022-10-09 05:41:30,541 [INFO] 	Process 4 - batch 18599: mean_policy_losses: -237.072, mean_net_lifetime: 4044.1938, mean_mc_travel_dist: 1471.4130, mean_rewards: 222.7562, total_rewards: 2613.5338, mean_steps: 19.3400, mean_ecr: 0.0397 mean_entropies: 1.7081, took: 100.4218s
2022-10-09 05:41:46,346 [INFO] 	Process 0 - batch 18099: mean_policy_losses: -18.964, mean_net_lifetime: 4257.7250, mean_mc_travel_dist: 1501.9059, mean_rewards: 228.7796, total_rewards: 2793.4268, mean_steps: 20.6300, mean_ecr: 0.0399 mean_entropies: 1.6893, took: 855.0899s
2022-10-09 05:42:12,579 [INFO] 	Process 6 - batch 18599: mean_policy_losses: -139.931, mean_net_lifetime: 3872.5183, mean_mc_travel_dist: 1400.0170, mean_rewards: 225.7551, total_rewards: 2515.4964, mean_steps: 17.7300, mean_ecr: 0.0400 mean_entropies: 1.6894, took: 94.1664s
2022-10-09 05:42:21,306 [INFO] 	Process 3 - batch 18699: mean_policy_losses: -28.504, mean_net_lifetime: 4030.7031, mean_mc_travel_dist: 1380.2487, mean_rewards: 211.3884, total_rewards: 2679.1179, mean_steps: 19.7400, mean_ecr: 0.0400 mean_entropies: 1.7524, took: 103.2587s
2022-10-09 05:42:38,575 [INFO] 	Process 1 - batch 19199: mean_policy_losses: -79.957, mean_net_lifetime: 3801.4780, mean_mc_travel_dist: 1330.7212, mean_rewards: 212.2623, total_rewards: 2507.1296, mean_steps: 18.5800, mean_ecr: 0.0410 mean_entropies: 1.7030, took: 93.9332s
2022-10-09 05:43:16,251 [INFO] 	Process 4 - batch 18699: mean_policy_losses: -60.739, mean_net_lifetime: 4127.9616, mean_mc_travel_dist: 1461.4867, mean_rewards: 208.7851, total_rewards: 2716.0899, mean_steps: 20.1200, mean_ecr: 0.0396 mean_entropies: 1.7758, took: 105.7100s
2022-10-09 05:43:16,945 [INFO] 	Process 2 - batch 18799: mean_policy_losses: -17.514, mean_net_lifetime: 4749.3116, mean_mc_travel_dist: 1768.1619, mean_rewards: 216.9298, total_rewards: 3016.9171, mean_steps: 23.0200, mean_ecr: 0.0393 mean_entropies: 1.7315, took: 120.4693s
2022-10-09 05:43:24,552 [INFO] 	Process 0 - batch 18199: mean_policy_losses: -56.735, mean_net_lifetime: 3925.5273, mean_mc_travel_dist: 1343.5418, mean_rewards: 223.3367, total_rewards: 2609.6310, mean_steps: 18.2200, mean_ecr: 0.0394 mean_entropies: 1.6716, took: 98.2059s
2022-10-09 05:43:32,291 [INFO] 	Process 5 - batch 18299: mean_policy_losses: -58.076, mean_net_lifetime: 4817.6870, mean_mc_travel_dist: 1810.7095, mean_rewards: 211.8529, total_rewards: 3039.6173, mean_steps: 23.8800, mean_ecr: 0.0393 mean_entropies: 1.7208, took: 122.6200s
2022-10-09 05:43:57,444 [INFO] 	Process 6 - batch 18699: mean_policy_losses: -72.650, mean_net_lifetime: 4151.1563, mean_mc_travel_dist: 1479.0673, mean_rewards: 211.9475, total_rewards: 2712.9171, mean_steps: 19.9500, mean_ecr: 0.0401 mean_entropies: 1.7311, took: 104.8653s
2022-10-09 05:43:58,322 [INFO] 	Process 3 - batch 18799: mean_policy_losses: -148.773, mean_net_lifetime: 3900.4288, mean_mc_travel_dist: 1373.8344, mean_rewards: 221.9494, total_rewards: 2560.5539, mean_steps: 18.3300, mean_ecr: 0.0395 mean_entropies: 1.6990, took: 97.0154s
2022-10-09 05:44:09,337 [INFO] 	Process 1 - batch 19299: mean_policy_losses: -169.493, mean_net_lifetime: 3754.0438, mean_mc_travel_dist: 1301.4378, mean_rewards: 215.5182, total_rewards: 2487.5184, mean_steps: 17.8600, mean_ecr: 0.0391 mean_entropies: 1.7373, took: 90.7612s
2022-10-09 05:44:53,548 [INFO] 	Process 2 - batch 18899: mean_policy_losses: -98.342, mean_net_lifetime: 3889.6955, mean_mc_travel_dist: 1376.2747, mean_rewards: 217.4339, total_rewards: 2551.4402, mean_steps: 18.3900, mean_ecr: 0.0402 mean_entropies: 1.7163, took: 96.6041s
2022-10-09 05:44:55,813 [INFO] 	Process 4 - batch 18799: mean_policy_losses: -103.551, mean_net_lifetime: 3960.8624, mean_mc_travel_dist: 1373.1095, mean_rewards: 215.7798, total_rewards: 2615.6967, mean_steps: 18.8400, mean_ecr: 0.0394 mean_entropies: 1.7046, took: 99.5619s
2022-10-09 05:45:09,463 [INFO] 	Process 0 - batch 18299: mean_policy_losses: -45.596, mean_net_lifetime: 4079.7620, mean_mc_travel_dist: 1443.9812, mean_rewards: 219.4865, total_rewards: 2668.8302, mean_steps: 19.4100, mean_ecr: 0.0390 mean_entropies: 1.6878, took: 104.9109s
2022-10-09 05:45:12,963 [INFO] 	Process 5 - batch 18399: mean_policy_losses: -149.371, mean_net_lifetime: 3889.2435, mean_mc_travel_dist: 1371.0294, mean_rewards: 223.1133, total_rewards: 2568.2251, mean_steps: 18.8400, mean_ecr: 0.0392 mean_entropies: 1.7067, took: 100.6668s
2022-10-09 05:45:37,317 [INFO] 	Process 3 - batch 18899: mean_policy_losses: -99.433, mean_net_lifetime: 3954.1311, mean_mc_travel_dist: 1397.1983, mean_rewards: 218.1996, total_rewards: 2594.2666, mean_steps: 18.7300, mean_ecr: 0.0398 mean_entropies: 1.7037, took: 98.9953s
2022-10-09 05:45:37,406 [INFO] 	Process 1 - batch 19399: mean_policy_losses: -179.547, mean_net_lifetime: 3723.0622, mean_mc_travel_dist: 1310.5465, mean_rewards: 220.8954, total_rewards: 2458.1009, mean_steps: 17.4200, mean_ecr: 0.0407 mean_entropies: 1.6196, took: 88.0696s
2022-10-09 05:45:39,318 [INFO] 	Process 6 - batch 18799: mean_policy_losses: -87.651, mean_net_lifetime: 4055.9822, mean_mc_travel_dist: 1462.9976, mean_rewards: 214.3818, total_rewards: 2633.1397, mean_steps: 19.6300, mean_ecr: 0.0397 mean_entropies: 1.6886, took: 101.8743s
2022-10-09 05:46:42,925 [INFO] 	Process 4 - batch 18899: mean_policy_losses: -42.032, mean_net_lifetime: 4148.7820, mean_mc_travel_dist: 1479.6867, mean_rewards: 216.5598, total_rewards: 2715.6847, mean_steps: 20.1500, mean_ecr: 0.0396 mean_entropies: 1.7104, took: 107.1112s
2022-10-09 05:46:49,018 [INFO] 	Process 2 - batch 18999: mean_policy_losses: -162.286, mean_net_lifetime: 4415.3337, mean_mc_travel_dist: 1648.0669, mean_rewards: 215.4318, total_rewards: 2802.0906, mean_steps: 22.2800, mean_ecr: 0.0382 mean_entropies: 1.6940, took: 115.4696s
2022-10-09 05:46:55,890 [INFO] 	Process 0 - batch 18399: mean_policy_losses: -138.879, mean_net_lifetime: 4086.0198, mean_mc_travel_dist: 1452.8831, mean_rewards: 215.6702, total_rewards: 2667.8551, mean_steps: 19.8200, mean_ecr: 0.0390 mean_entropies: 1.6978, took: 106.4269s
2022-10-09 05:46:56,182 [INFO] 	Process 5 - batch 18499: mean_policy_losses: -100.161, mean_net_lifetime: 4180.6291, mean_mc_travel_dist: 1510.3060, mean_rewards: 224.2716, total_rewards: 2713.3100, mean_steps: 19.8100, mean_ecr: 0.0391 mean_entropies: 1.6479, took: 103.2234s
2022-10-09 05:47:12,956 [INFO] 	Process 1 - batch 19499: mean_policy_losses: -149.969, mean_net_lifetime: 4017.2403, mean_mc_travel_dist: 1408.9495, mean_rewards: 218.2845, total_rewards: 2647.4431, mean_steps: 19.2000, mean_ecr: 0.0393 mean_entropies: 1.6606, took: 95.5498s
2022-10-09 05:47:22,636 [INFO] 	Process 3 - batch 18999: mean_policy_losses: -39.088, mean_net_lifetime: 4283.0759, mean_mc_travel_dist: 1501.0566, mean_rewards: 223.8168, total_rewards: 2824.0471, mean_steps: 20.2600, mean_ecr: 0.0379 mean_entropies: 1.6868, took: 105.3203s
2022-10-09 05:47:23,204 [INFO] 	Process 6 - batch 18899: mean_policy_losses: -84.782, mean_net_lifetime: 4125.3320, mean_mc_travel_dist: 1454.3776, mean_rewards: 216.7669, total_rewards: 2705.8354, mean_steps: 19.6600, mean_ecr: 0.0391 mean_entropies: 1.7192, took: 103.8843s
2022-10-09 05:48:27,563 [INFO] 	Process 4 - batch 18999: mean_policy_losses: -205.542, mean_net_lifetime: 4079.7973, mean_mc_travel_dist: 1455.3629, mean_rewards: 220.0499, total_rewards: 2652.6689, mean_steps: 20.0500, mean_ecr: 0.0383 mean_entropies: 1.6923, took: 104.6392s
2022-10-09 05:48:29,409 [INFO] 	Process 5 - batch 18599: mean_policy_losses: -186.746, mean_net_lifetime: 3954.2460, mean_mc_travel_dist: 1401.6775, mean_rewards: 232.0199, total_rewards: 2595.2989, mean_steps: 18.2600, mean_ecr: 0.0388 mean_entropies: 1.6771, took: 93.2276s
2022-10-09 05:48:31,766 [INFO] 	Process 2 - batch 19099: mean_policy_losses: -80.813, mean_net_lifetime: 4289.2953, mean_mc_travel_dist: 1525.1498, mean_rewards: 225.1199, total_rewards: 2816.2733, mean_steps: 20.3800, mean_ecr: 0.0382 mean_entropies: 1.6591, took: 102.7487s
2022-10-09 05:48:38,441 [INFO] 	Process 0 - batch 18499: mean_policy_losses: -80.977, mean_net_lifetime: 4149.0054, mean_mc_travel_dist: 1472.6586, mean_rewards: 222.3211, total_rewards: 2712.4143, mean_steps: 19.6500, mean_ecr: 0.0391 mean_entropies: 1.6767, took: 102.5503s
2022-10-09 05:49:07,068 [INFO] 	Process 3 - batch 19099: mean_policy_losses: -85.380, mean_net_lifetime: 4161.3024, mean_mc_travel_dist: 1487.2567, mean_rewards: 213.3062, total_rewards: 2717.9307, mean_steps: 20.8100, mean_ecr: 0.0380 mean_entropies: 1.6883, took: 104.4310s
2022-10-09 05:49:11,624 [INFO] 	Process 6 - batch 18999: mean_policy_losses: -58.335, mean_net_lifetime: 4344.5948, mean_mc_travel_dist: 1531.6036, mean_rewards: 217.6320, total_rewards: 2851.1399, mean_steps: 21.1200, mean_ecr: 0.0383 mean_entropies: 1.6876, took: 108.4206s
2022-10-09 05:50:06,411 [INFO] 	Process 2 - batch 19199: mean_policy_losses: -91.131, mean_net_lifetime: 3850.4431, mean_mc_travel_dist: 1325.1478, mean_rewards: 214.1408, total_rewards: 2567.9932, mean_steps: 18.3100, mean_ecr: 0.0407 mean_entropies: 1.6965, took: 94.6445s
2022-10-09 05:50:11,105 [INFO] 	Process 5 - batch 18699: mean_policy_losses: -75.299, mean_net_lifetime: 4002.9952, mean_mc_travel_dist: 1377.3177, mean_rewards: 210.6794, total_rewards: 2664.7449, mean_steps: 19.9900, mean_ecr: 0.0398 mean_entropies: 1.7418, took: 101.6947s
2022-10-09 05:50:14,557 [INFO] 	Process 0 - batch 18599: mean_policy_losses: -190.686, mean_net_lifetime: 3968.1104, mean_mc_travel_dist: 1424.1546, mean_rewards: 225.1596, total_rewards: 2580.4477, mean_steps: 18.5300, mean_ecr: 0.0394 mean_entropies: 1.6961, took: 96.1164s
2022-10-09 05:50:14,767 [INFO] 	Process 4 - batch 19099: mean_policy_losses: -55.065, mean_net_lifetime: 4332.2126, mean_mc_travel_dist: 1517.3724, mean_rewards: 223.3949, total_rewards: 2858.6991, mean_steps: 20.8800, mean_ecr: 0.0377 mean_entropies: 1.6879, took: 107.2036s
2022-10-09 05:50:40,278 [INFO] 	Process 3 - batch 19199: mean_policy_losses: -130.614, mean_net_lifetime: 3844.5270, mean_mc_travel_dist: 1351.1249, mean_rewards: 211.5459, total_rewards: 2530.0433, mean_steps: 18.6200, mean_ecr: 0.0407 mean_entropies: 1.6861, took: 93.2101s
2022-10-09 05:51:14,794 [INFO] 	Process 6 - batch 19099: mean_policy_losses: -94.563, mean_net_lifetime: 4753.0501, mean_mc_travel_dist: 1703.0254, mean_rewards: 217.6014, total_rewards: 3086.7778, mean_steps: 24.4600, mean_ecr: 0.0379 mean_entropies: 1.6782, took: 123.1697s
2022-10-09 05:51:32,914 [INFO] 	Process 2 - batch 19299: mean_policy_losses: -76.222, mean_net_lifetime: 3659.2412, mean_mc_travel_dist: 1255.3273, mean_rewards: 220.5096, total_rewards: 2436.6105, mean_steps: 16.7800, mean_ecr: 0.0394 mean_entropies: 1.6852, took: 86.5024s
2022-10-09 05:51:46,289 [INFO] 	Process 4 - batch 19199: mean_policy_losses: -53.531, mean_net_lifetime: 3742.8526, mean_mc_travel_dist: 1324.8479, mean_rewards: 209.9946, total_rewards: 2452.7287, mean_steps: 17.9400, mean_ecr: 0.0407 mean_entropies: 1.6781, took: 91.5218s
2022-10-09 05:51:50,826 [INFO] 	Process 5 - batch 18799: mean_policy_losses: -64.343, mean_net_lifetime: 4071.4628, mean_mc_travel_dist: 1467.0203, mean_rewards: 217.1583, total_rewards: 2644.5967, mean_steps: 19.4500, mean_ecr: 0.0396 mean_entropies: 1.6704, took: 99.7209s
2022-10-09 05:51:53,274 [INFO] 	Process 0 - batch 18699: mean_policy_losses: -47.638, mean_net_lifetime: 3885.0899, mean_mc_travel_dist: 1371.9513, mean_rewards: 209.8855, total_rewards: 2551.1974, mean_steps: 18.8300, mean_ecr: 0.0399 mean_entropies: 1.7103, took: 98.7175s
2022-10-09 05:52:07,321 [INFO] 	Process 3 - batch 19299: mean_policy_losses: -123.597, mean_net_lifetime: 3730.3272, mean_mc_travel_dist: 1317.0605, mean_rewards: 215.6502, total_rewards: 2456.3385, mean_steps: 17.2900, mean_ecr: 0.0395 mean_entropies: 1.6875, took: 87.0434s
2022-10-09 05:52:51,582 [INFO] 	Process 6 - batch 19199: mean_policy_losses: -89.118, mean_net_lifetime: 3979.9306, mean_mc_travel_dist: 1375.7098, mean_rewards: 214.1721, total_rewards: 2632.3351, mean_steps: 18.8900, mean_ecr: 0.0408 mean_entropies: 1.6819, took: 96.7890s
2022-10-09 05:53:13,437 [INFO] 	Process 2 - batch 19399: mean_policy_losses: -93.908, mean_net_lifetime: 3914.7414, mean_mc_travel_dist: 1359.1352, mean_rewards: 215.1342, total_rewards: 2586.3405, mean_steps: 19.3400, mean_ecr: 0.0407 mean_entropies: 1.6199, took: 100.5237s
2022-10-09 05:53:28,055 [INFO] 	Process 5 - batch 18899: mean_policy_losses: -130.049, mean_net_lifetime: 3857.9316, mean_mc_travel_dist: 1330.6657, mean_rewards: 211.4450, total_rewards: 2566.2617, mean_steps: 18.6600, mean_ecr: 0.0396 mean_entropies: 1.6914, took: 97.2295s
2022-10-09 05:53:30,307 [INFO] 	Process 4 - batch 19299: mean_policy_losses: -120.196, mean_net_lifetime: 4118.2591, mean_mc_travel_dist: 1471.6212, mean_rewards: 213.7093, total_rewards: 2678.7387, mean_steps: 20.3300, mean_ecr: 0.0392 mean_entropies: 1.6813, took: 104.0190s
2022-10-09 05:53:43,795 [INFO] 	Process 3 - batch 19399: mean_policy_losses: -45.566, mean_net_lifetime: 3844.0522, mean_mc_travel_dist: 1310.4313, mean_rewards: 215.6903, total_rewards: 2569.0477, mean_steps: 19.0000, mean_ecr: 0.0411 mean_entropies: 1.6187, took: 96.4736s
2022-10-09 05:53:49,876 [INFO] 	Process 0 - batch 18799: mean_policy_losses: -131.435, mean_net_lifetime: 4482.8705, mean_mc_travel_dist: 1665.4995, mean_rewards: 213.6489, total_rewards: 2847.5458, mean_steps: 23.4700, mean_ecr: 0.0394 mean_entropies: 1.6717, took: 116.6013s
2022-10-09 05:54:52,151 [INFO] 	Process 2 - batch 19499: mean_policy_losses: -123.078, mean_net_lifetime: 3996.6868, mean_mc_travel_dist: 1383.8253, mean_rewards: 214.5681, total_rewards: 2659.2187, mean_steps: 19.1800, mean_ecr: 0.0396 mean_entropies: 1.6499, took: 98.7142s
2022-10-09 05:55:06,853 [INFO] 	Process 4 - batch 19399: mean_policy_losses: -119.671, mean_net_lifetime: 3878.0770, mean_mc_travel_dist: 1318.3291, mean_rewards: 218.1429, total_rewards: 2595.3594, mean_steps: 18.9900, mean_ecr: 0.0406 mean_entropies: 1.6145, took: 96.5451s
2022-10-09 05:55:11,127 [INFO] 	Process 6 - batch 19299: mean_policy_losses: -93.736, mean_net_lifetime: 5510.8828, mean_mc_travel_dist: 2171.2700, mean_rewards: 220.2724, total_rewards: 3370.9058, mean_steps: 28.2700, mean_ecr: 0.0393 mean_entropies: 1.6732, took: 139.5440s
2022-10-09 05:55:19,565 [INFO] 	Process 3 - batch 19499: mean_policy_losses: -103.103, mean_net_lifetime: 3987.2544, mean_mc_travel_dist: 1391.6714, mean_rewards: 217.8158, total_rewards: 2630.3786, mean_steps: 19.1200, mean_ecr: 0.0394 mean_entropies: 1.6569, took: 95.7699s
2022-10-09 05:55:20,798 [INFO] 	Process 5 - batch 18999: mean_policy_losses: -160.878, mean_net_lifetime: 4488.5504, mean_mc_travel_dist: 1628.0377, mean_rewards: 217.2901, total_rewards: 2907.8612, mean_steps: 22.4100, mean_ecr: 0.0386 mean_entropies: 1.6872, took: 112.7434s
2022-10-09 05:55:28,792 [INFO] 	Process 0 - batch 18899: mean_policy_losses: -24.080, mean_net_lifetime: 4102.4680, mean_mc_travel_dist: 1396.8251, mean_rewards: 213.9717, total_rewards: 2744.0273, mean_steps: 19.8700, mean_ecr: 0.0397 mean_entropies: 1.6762, took: 98.9161s
2022-10-09 05:56:31,033 [INFO] 	Process 4 - batch 19499: mean_policy_losses: -189.861, mean_net_lifetime: 3700.3957, mean_mc_travel_dist: 1257.4482, mean_rewards: 220.3345, total_rewards: 2483.3901, mean_steps: 17.4700, mean_ecr: 0.0394 mean_entropies: 1.6571, took: 84.1800s
2022-10-09 05:56:40,469 [INFO] 	Process 6 - batch 19399: mean_policy_losses: -76.433, mean_net_lifetime: 3931.6407, mean_mc_travel_dist: 1342.4655, mean_rewards: 216.9431, total_rewards: 2624.1195, mean_steps: 18.8100, mean_ecr: 0.0405 mean_entropies: 1.6363, took: 89.3420s
2022-10-09 05:56:56,623 [INFO] 	Process 5 - batch 19099: mean_policy_losses: -179.112, mean_net_lifetime: 4049.9701, mean_mc_travel_dist: 1418.2470, mean_rewards: 220.5389, total_rewards: 2674.3603, mean_steps: 19.5900, mean_ecr: 0.0378 mean_entropies: 1.6537, took: 95.8253s
2022-10-09 05:57:13,995 [INFO] 	Process 0 - batch 18999: mean_policy_losses: -185.578, mean_net_lifetime: 4296.9939, mean_mc_travel_dist: 1535.0567, mean_rewards: 213.7546, total_rewards: 2799.4991, mean_steps: 21.5200, mean_ecr: 0.0380 mean_entropies: 1.6821, took: 105.2000s
2022-10-09 05:58:06,355 [INFO] 	Process 6 - batch 19499: mean_policy_losses: -132.668, mean_net_lifetime: 3938.3877, mean_mc_travel_dist: 1347.3114, mean_rewards: 219.2600, total_rewards: 2621.2054, mean_steps: 18.9700, mean_ecr: 0.0394 mean_entropies: 1.6317, took: 85.8869s
2022-10-09 05:58:26,325 [INFO] 	Process 5 - batch 19199: mean_policy_losses: -112.015, mean_net_lifetime: 3900.0028, mean_mc_travel_dist: 1362.5875, mean_rewards: 208.2285, total_rewards: 2574.8037, mean_steps: 19.3500, mean_ecr: 0.0409 mean_entropies: 1.6402, took: 89.7021s
2022-10-09 05:58:49,935 [INFO] 	Process 0 - batch 19099: mean_policy_losses: -82.542, mean_net_lifetime: 4213.4449, mean_mc_travel_dist: 1505.3005, mean_rewards: 216.0902, total_rewards: 2751.0733, mean_steps: 20.7300, mean_ecr: 0.0381 mean_entropies: 1.6576, took: 95.9433s
2022-10-09 05:59:53,483 [INFO] 	Process 5 - batch 19299: mean_policy_losses: -88.026, mean_net_lifetime: 3991.6507, mean_mc_travel_dist: 1396.7548, mean_rewards: 213.9353, total_rewards: 2623.7381, mean_steps: 19.5300, mean_ecr: 0.0393 mean_entropies: 1.6957, took: 87.1581s
2022-10-09 06:00:10,218 [INFO] 	Process 0 - batch 19199: mean_policy_losses: -80.369, mean_net_lifetime: 3748.3456, mean_mc_travel_dist: 1293.9526, mean_rewards: 218.1843, total_rewards: 2489.8164, mean_steps: 17.3300, mean_ecr: 0.0410 mean_entropies: 1.6811, took: 80.2825s
2022-10-09 06:01:16,714 [INFO] 	Process 5 - batch 19399: mean_policy_losses: -39.955, mean_net_lifetime: 3804.7520, mean_mc_travel_dist: 1290.0785, mean_rewards: 220.3380, total_rewards: 2556.7999, mean_steps: 17.7400, mean_ecr: 0.0405 mean_entropies: 1.6434, took: 83.2304s
2022-10-09 06:01:24,453 [INFO] 	Process 1 - batch 19599: mean_policy_losses: -154.550, mean_net_lifetime: 3896.4708, mean_mc_travel_dist: 1455.9287, mean_rewards: 229.4750, total_rewards: 2478.5907, mean_steps: 18.1800, mean_ecr: 0.0386 mean_entropies: 1.6723, took: 851.4972s
2022-10-09 06:01:36,820 [INFO] 	Process 0 - batch 19299: mean_policy_losses: -52.719, mean_net_lifetime: 3946.0075, mean_mc_travel_dist: 1354.1832, mean_rewards: 222.6269, total_rewards: 2623.5497, mean_steps: 18.0700, mean_ecr: 0.0391 mean_entropies: 1.7028, took: 86.6019s
2022-10-09 06:02:42,502 [INFO] 	Process 1 - batch 19699: mean_policy_losses: -159.592, mean_net_lifetime: 3814.7165, mean_mc_travel_dist: 1313.5453, mean_rewards: 223.8806, total_rewards: 2533.7162, mean_steps: 17.8500, mean_ecr: 0.0407 mean_entropies: 1.6748, took: 78.0493s
2022-10-09 06:02:47,704 [INFO] 	Process 5 - batch 19499: mean_policy_losses: -133.254, mean_net_lifetime: 4040.4247, mean_mc_travel_dist: 1417.4949, mean_rewards: 215.9841, total_rewards: 2664.8738, mean_steps: 19.3300, mean_ecr: 0.0391 mean_entropies: 1.6812, took: 90.9899s
2022-10-09 06:03:04,650 [INFO] 	Process 0 - batch 19399: mean_policy_losses: -63.206, mean_net_lifetime: 3977.5371, mean_mc_travel_dist: 1372.0602, mean_rewards: 223.6499, total_rewards: 2641.0521, mean_steps: 18.7500, mean_ecr: 0.0408 mean_entropies: 1.6670, took: 87.8301s
2022-10-09 06:04:08,131 [INFO] 	Process 1 - batch 19799: mean_policy_losses: -39.745, mean_net_lifetime: 4267.7701, mean_mc_travel_dist: 1497.0756, mean_rewards: 215.5812, total_rewards: 2807.0309, mean_steps: 20.5300, mean_ecr: 0.0392 mean_entropies: 1.7816, took: 85.6285s
2022-10-09 06:04:32,749 [INFO] 	Process 0 - batch 19499: mean_policy_losses: -45.957, mean_net_lifetime: 4113.2578, mean_mc_travel_dist: 1440.3889, mean_rewards: 214.4460, total_rewards: 2721.3585, mean_steps: 19.4200, mean_ecr: 0.0389 mean_entropies: 1.7303, took: 88.0999s
2022-10-09 06:05:23,284 [INFO] 	Process 1 - batch 19899: mean_policy_losses: -38.990, mean_net_lifetime: 3858.3901, mean_mc_travel_dist: 1290.3347, mean_rewards: 219.1516, total_rewards: 2596.9414, mean_steps: 17.9800, mean_ecr: 0.0427 mean_entropies: 1.6832, took: 75.1533s
2022-10-09 06:06:43,705 [INFO] 	Process 1 - batch 19999: mean_policy_losses: -104.961, mean_net_lifetime: 4138.9127, mean_mc_travel_dist: 1487.4020, mean_rewards: 213.5359, total_rewards: 2697.0790, mean_steps: 19.8700, mean_ecr: 0.0393 mean_entropies: 1.7472, took: 80.4210s
2022-10-09 06:08:02,218 [INFO] 	Process 1 - batch 20099: mean_policy_losses: 39.345, mean_net_lifetime: 4021.2497, mean_mc_travel_dist: 1375.2345, mean_rewards: 223.9238, total_rewards: 2687.1167, mean_steps: 18.3900, mean_ecr: 0.0400 mean_entropies: 1.7394, took: 78.5132s
2022-10-09 06:08:11,905 [INFO] 	Process 2 - batch 19599: mean_policy_losses: -108.872, mean_net_lifetime: 4067.4259, mean_mc_travel_dist: 1537.6521, mean_rewards: 223.9172, total_rewards: 2580.2014, mean_steps: 19.0900, mean_ecr: 0.0381 mean_entropies: 1.7318, took: 799.7543s
2022-10-09 06:09:05,653 [INFO] 	Process 3 - batch 19599: mean_policy_losses: -110.756, mean_net_lifetime: 3813.0531, mean_mc_travel_dist: 1383.8291, mean_rewards: 220.9964, total_rewards: 2478.2272, mean_steps: 17.8400, mean_ecr: 0.0383 mean_entropies: 1.6982, took: 826.0888s
2022-10-09 06:09:34,135 [INFO] 	Process 1 - batch 20199: mean_policy_losses: 37.340, mean_net_lifetime: 4406.2387, mean_mc_travel_dist: 1574.4447, mean_rewards: 219.0008, total_rewards: 2867.9313, mean_steps: 20.7600, mean_ecr: 0.0382 mean_entropies: 1.6697, took: 91.9169s
2022-10-09 06:09:41,700 [INFO] 	Process 2 - batch 19699: mean_policy_losses: -53.772, mean_net_lifetime: 4029.7266, mean_mc_travel_dist: 1415.1522, mean_rewards: 230.3250, total_rewards: 2646.7932, mean_steps: 18.4900, mean_ecr: 0.0404 mean_entropies: 1.6749, took: 89.7933s
2022-10-09 06:10:19,730 [INFO] 	Process 4 - batch 19599: mean_policy_losses: -78.755, mean_net_lifetime: 4248.4674, mean_mc_travel_dist: 1591.1707, mean_rewards: 222.3334, total_rewards: 2696.6801, mean_steps: 20.6200, mean_ecr: 0.0388 mean_entropies: 1.7152, took: 828.6979s
2022-10-09 06:10:41,281 [INFO] 	Process 3 - batch 19699: mean_policy_losses: -91.463, mean_net_lifetime: 4189.7503, mean_mc_travel_dist: 1446.5308, mean_rewards: 230.7415, total_rewards: 2773.6297, mean_steps: 19.7600, mean_ecr: 0.0406 mean_entropies: 1.6617, took: 95.6283s
2022-10-09 06:10:59,131 [INFO] 	Process 6 - batch 19599: mean_policy_losses: -145.826, mean_net_lifetime: 4223.0565, mean_mc_travel_dist: 1541.8877, mean_rewards: 226.5722, total_rewards: 2724.4843, mean_steps: 19.9600, mean_ecr: 0.0385 mean_entropies: 1.7155, took: 772.7763s
2022-10-09 06:11:01,100 [INFO] 	Process 1 - batch 20299: mean_policy_losses: -85.404, mean_net_lifetime: 4062.6536, mean_mc_travel_dist: 1377.6026, mean_rewards: 230.9716, total_rewards: 2723.7337, mean_steps: 18.3500, mean_ecr: 0.0407 mean_entropies: 1.7232, took: 86.9644s
2022-10-09 06:11:18,621 [INFO] 	Process 2 - batch 19799: mean_policy_losses: -116.675, mean_net_lifetime: 4112.6861, mean_mc_travel_dist: 1372.1050, mean_rewards: 225.3830, total_rewards: 2776.9477, mean_steps: 19.5100, mean_ecr: 0.0391 mean_entropies: 1.7172, took: 96.9214s
2022-10-09 06:11:52,677 [INFO] 	Process 4 - batch 19699: mean_policy_losses: -161.162, mean_net_lifetime: 4068.1092, mean_mc_travel_dist: 1384.1571, mean_rewards: 233.3430, total_rewards: 2719.0833, mean_steps: 18.7100, mean_ecr: 0.0405 mean_entropies: 1.6784, took: 92.9451s
2022-10-09 06:12:17,686 [INFO] 	Process 3 - batch 19799: mean_policy_losses: -26.231, mean_net_lifetime: 4063.8281, mean_mc_travel_dist: 1361.3778, mean_rewards: 217.6486, total_rewards: 2743.3189, mean_steps: 19.5200, mean_ecr: 0.0391 mean_entropies: 1.7410, took: 96.4036s
2022-10-09 06:12:29,899 [INFO] 	Process 6 - batch 19699: mean_policy_losses: -170.787, mean_net_lifetime: 3898.9928, mean_mc_travel_dist: 1343.4761, mean_rewards: 228.9207, total_rewards: 2585.8066, mean_steps: 18.2200, mean_ecr: 0.0407 mean_entropies: 1.6648, took: 90.7663s
2022-10-09 06:12:32,888 [INFO] 	Process 1 - batch 20399: mean_policy_losses: -236.661, mean_net_lifetime: 4020.4944, mean_mc_travel_dist: 1428.5839, mean_rewards: 218.3270, total_rewards: 2627.3905, mean_steps: 19.5700, mean_ecr: 0.0398 mean_entropies: 1.6510, took: 91.7885s
2022-10-09 06:12:41,527 [INFO] 	Process 2 - batch 19899: mean_policy_losses: -181.063, mean_net_lifetime: 3534.6171, mean_mc_travel_dist: 1186.8144, mean_rewards: 224.9612, total_rewards: 2386.6516, mean_steps: 16.5000, mean_ecr: 0.0431 mean_entropies: 1.6135, took: 82.9062s
2022-10-09 06:13:30,203 [INFO] 	Process 4 - batch 19799: mean_policy_losses: -91.135, mean_net_lifetime: 4030.4631, mean_mc_travel_dist: 1386.7866, mean_rewards: 219.7166, total_rewards: 2682.4311, mean_steps: 19.4300, mean_ecr: 0.0389 mean_entropies: 1.6951, took: 97.5262s
2022-10-09 06:13:40,024 [INFO] 	Process 3 - batch 19899: mean_policy_losses: -67.344, mean_net_lifetime: 3656.1093, mean_mc_travel_dist: 1226.5836, mean_rewards: 227.9915, total_rewards: 2452.9586, mean_steps: 16.8000, mean_ecr: 0.0430 mean_entropies: 1.6356, took: 82.3383s
2022-10-09 06:14:11,094 [INFO] 	Process 6 - batch 19799: mean_policy_losses: -35.834, mean_net_lifetime: 4148.3700, mean_mc_travel_dist: 1401.9641, mean_rewards: 214.5482, total_rewards: 2777.9861, mean_steps: 19.9900, mean_ecr: 0.0393 mean_entropies: 1.7236, took: 101.1957s
2022-10-09 06:14:17,546 [INFO] 	Process 2 - batch 19999: mean_policy_losses: -55.703, mean_net_lifetime: 3977.3423, mean_mc_travel_dist: 1384.4238, mean_rewards: 219.7877, total_rewards: 2631.2572, mean_steps: 18.9300, mean_ecr: 0.0391 mean_entropies: 1.7070, took: 96.0192s
2022-10-09 06:14:17,571 [INFO] 	Process 1 - batch 20499: mean_policy_losses: -62.116, mean_net_lifetime: 4565.7015, mean_mc_travel_dist: 1636.1377, mean_rewards: 220.9931, total_rewards: 2968.5959, mean_steps: 22.5300, mean_ecr: 0.0402 mean_entropies: 1.7236, took: 104.6831s
2022-10-09 06:14:55,838 [INFO] 	Process 4 - batch 19899: mean_policy_losses: -3.282, mean_net_lifetime: 3740.3836, mean_mc_travel_dist: 1225.4105, mean_rewards: 226.4044, total_rewards: 2550.0290, mean_steps: 17.2300, mean_ecr: 0.0430 mean_entropies: 1.6660, took: 85.6359s
2022-10-09 06:15:20,348 [INFO] 	Process 3 - batch 19999: mean_policy_losses: -53.252, mean_net_lifetime: 4108.1874, mean_mc_travel_dist: 1480.6120, mean_rewards: 216.4603, total_rewards: 2671.2528, mean_steps: 20.0300, mean_ecr: 0.0390 mean_entropies: 1.7092, took: 100.3250s
2022-10-09 06:15:36,644 [INFO] 	Process 6 - batch 19899: mean_policy_losses: -22.332, mean_net_lifetime: 3623.2859, mean_mc_travel_dist: 1197.6323, mean_rewards: 228.1354, total_rewards: 2472.7457, mean_steps: 17.0100, mean_ecr: 0.0430 mean_entropies: 1.6424, took: 85.5497s
2022-10-09 06:15:52,438 [INFO] 	Process 1 - batch 20599: mean_policy_losses: -66.026, mean_net_lifetime: 4146.4649, mean_mc_travel_dist: 1468.0145, mean_rewards: 217.5192, total_rewards: 2707.4957, mean_steps: 19.7200, mean_ecr: 0.0385 mean_entropies: 1.6958, took: 94.8663s
2022-10-09 06:15:53,740 [INFO] 	Process 2 - batch 20099: mean_policy_losses: -126.761, mean_net_lifetime: 3884.8175, mean_mc_travel_dist: 1332.4102, mean_rewards: 220.3217, total_rewards: 2586.6131, mean_steps: 18.3900, mean_ecr: 0.0401 mean_entropies: 1.7193, took: 96.1941s
2022-10-09 06:16:19,830 [INFO] 	Process 5 - batch 19599: mean_policy_losses: -140.736, mean_net_lifetime: 4040.8172, mean_mc_travel_dist: 1501.6955, mean_rewards: 226.0596, total_rewards: 2581.0109, mean_steps: 19.1400, mean_ecr: 0.0389 mean_entropies: 1.6855, took: 812.1262s
2022-10-09 06:16:35,755 [INFO] 	Process 4 - batch 19999: mean_policy_losses: -181.947, mean_net_lifetime: 4053.9238, mean_mc_travel_dist: 1460.3054, mean_rewards: 216.3543, total_rewards: 2632.6071, mean_steps: 19.7300, mean_ecr: 0.0389 mean_entropies: 1.6970, took: 99.9172s
2022-10-09 06:16:55,448 [INFO] 	Process 3 - batch 20099: mean_policy_losses: -149.805, mean_net_lifetime: 3907.8747, mean_mc_travel_dist: 1373.1524, mean_rewards: 222.3004, total_rewards: 2581.6070, mean_steps: 18.5700, mean_ecr: 0.0397 mean_entropies: 1.7043, took: 95.0990s
2022-10-09 06:17:16,481 [INFO] 	Process 6 - batch 19999: mean_policy_losses: -51.919, mean_net_lifetime: 4052.1724, mean_mc_travel_dist: 1463.4259, mean_rewards: 217.8928, total_rewards: 2623.3011, mean_steps: 19.2000, mean_ecr: 0.0395 mean_entropies: 1.6920, took: 99.8382s
2022-10-09 06:17:32,849 [INFO] 	Process 2 - batch 20199: mean_policy_losses: -42.988, mean_net_lifetime: 4179.3162, mean_mc_travel_dist: 1474.8490, mean_rewards: 223.0502, total_rewards: 2743.4367, mean_steps: 19.2600, mean_ecr: 0.0387 mean_entropies: 1.6677, took: 99.1093s
2022-10-09 06:17:33,894 [INFO] 	Process 1 - batch 20699: mean_policy_losses: -68.033, mean_net_lifetime: 4261.3805, mean_mc_travel_dist: 1518.5180, mean_rewards: 217.5462, total_rewards: 2788.2870, mean_steps: 20.8300, mean_ecr: 0.0387 mean_entropies: 1.7760, took: 101.4568s
2022-10-09 06:17:58,966 [INFO] 	Process 5 - batch 19699: mean_policy_losses: -97.304, mean_net_lifetime: 4063.1218, mean_mc_travel_dist: 1390.0481, mean_rewards: 220.8508, total_rewards: 2724.6934, mean_steps: 18.8600, mean_ecr: 0.0404 mean_entropies: 1.7101, took: 99.1353s
2022-10-09 06:18:21,460 [INFO] 	Process 4 - batch 20099: mean_policy_losses: -59.477, mean_net_lifetime: 4179.1466, mean_mc_travel_dist: 1462.2434, mean_rewards: 212.8944, total_rewards: 2763.3887, mean_steps: 20.4800, mean_ecr: 0.0399 mean_entropies: 1.7429, took: 105.7062s
2022-10-09 06:18:37,823 [INFO] 	Process 3 - batch 20199: mean_policy_losses: -114.244, mean_net_lifetime: 4090.0250, mean_mc_travel_dist: 1457.2654, mean_rewards: 221.0029, total_rewards: 2675.9310, mean_steps: 19.6100, mean_ecr: 0.0384 mean_entropies: 1.6622, took: 102.3762s
2022-10-09 06:18:55,180 [INFO] 	Process 0 - batch 19599: mean_policy_losses: -54.420, mean_net_lifetime: 4318.8250, mean_mc_travel_dist: 1585.7762, mean_rewards: 221.4940, total_rewards: 2779.3474, mean_steps: 20.6300, mean_ecr: 0.0385 mean_entropies: 1.7024, took: 862.4298s
2022-10-09 06:19:03,086 [INFO] 	Process 6 - batch 20099: mean_policy_losses: -28.593, mean_net_lifetime: 4281.1738, mean_mc_travel_dist: 1518.5690, mean_rewards: 216.3289, total_rewards: 2804.1198, mean_steps: 20.5200, mean_ecr: 0.0398 mean_entropies: 1.7056, took: 106.6047s
2022-10-09 06:19:09,481 [INFO] 	Process 2 - batch 20299: mean_policy_losses: -154.267, mean_net_lifetime: 3934.1292, mean_mc_travel_dist: 1383.7839, mean_rewards: 221.6801, total_rewards: 2587.5454, mean_steps: 18.1300, mean_ecr: 0.0410 mean_entropies: 1.7107, took: 96.6314s
2022-10-09 06:19:17,195 [INFO] 	Process 1 - batch 20799: mean_policy_losses: -121.699, mean_net_lifetime: 4293.1849, mean_mc_travel_dist: 1626.2191, mean_rewards: 222.5310, total_rewards: 2713.6555, mean_steps: 20.7500, mean_ecr: 0.0391 mean_entropies: 1.6811, took: 103.3009s
2022-10-09 06:19:43,274 [INFO] 	Process 5 - batch 19799: mean_policy_losses: 28.214, mean_net_lifetime: 4160.4780, mean_mc_travel_dist: 1440.1780, mean_rewards: 216.5148, total_rewards: 2754.0537, mean_steps: 19.8200, mean_ecr: 0.0392 mean_entropies: 1.6890, took: 104.3082s
2022-10-09 06:20:01,733 [INFO] 	Process 4 - batch 20199: mean_policy_losses: -73.297, mean_net_lifetime: 4047.2647, mean_mc_travel_dist: 1434.4746, mean_rewards: 226.3179, total_rewards: 2655.0363, mean_steps: 18.9700, mean_ecr: 0.0384 mean_entropies: 1.5961, took: 100.2721s
2022-10-09 06:20:11,438 [INFO] 	Process 3 - batch 20299: mean_policy_losses: -68.129, mean_net_lifetime: 3828.6375, mean_mc_travel_dist: 1355.0182, mean_rewards: 224.9025, total_rewards: 2510.4522, mean_steps: 17.7100, mean_ecr: 0.0408 mean_entropies: 1.6694, took: 93.6141s
2022-10-09 06:20:28,200 [INFO] 	Process 0 - batch 19699: mean_policy_losses: -58.023, mean_net_lifetime: 3873.6871, mean_mc_travel_dist: 1333.9572, mean_rewards: 228.3938, total_rewards: 2579.1810, mean_steps: 17.5100, mean_ecr: 0.0406 mean_entropies: 1.6395, took: 93.0198s
2022-10-09 06:20:46,501 [INFO] 	Process 6 - batch 20199: mean_policy_losses: -23.334, mean_net_lifetime: 4167.3700, mean_mc_travel_dist: 1473.6148, mean_rewards: 227.0680, total_rewards: 2726.0165, mean_steps: 19.4200, mean_ecr: 0.0385 mean_entropies: 1.6016, took: 103.4151s
2022-10-09 06:20:51,471 [INFO] 	Process 1 - batch 20899: mean_policy_losses: -182.816, mean_net_lifetime: 3897.1809, mean_mc_travel_dist: 1357.9856, mean_rewards: 221.6665, total_rewards: 2579.1539, mean_steps: 18.7800, mean_ecr: 0.0385 mean_entropies: 1.7114, took: 94.2766s
2022-10-09 06:20:53,067 [INFO] 	Process 2 - batch 20399: mean_policy_losses: -104.363, mean_net_lifetime: 4086.4367, mean_mc_travel_dist: 1445.4137, mean_rewards: 225.8739, total_rewards: 2682.3141, mean_steps: 19.5700, mean_ecr: 0.0400 mean_entropies: 1.6243, took: 103.5868s
2022-10-09 06:21:14,292 [INFO] 	Process 5 - batch 19899: mean_policy_losses: -114.098, mean_net_lifetime: 3554.2248, mean_mc_travel_dist: 1193.2530, mean_rewards: 225.3855, total_rewards: 2407.0008, mean_steps: 16.9400, mean_ecr: 0.0429 mean_entropies: 1.5871, took: 91.0184s
2022-10-09 06:21:37,309 [INFO] 	Process 4 - batch 20299: mean_policy_losses: -114.567, mean_net_lifetime: 3835.0614, mean_mc_travel_dist: 1308.7509, mean_rewards: 217.1321, total_rewards: 2564.5950, mean_steps: 18.1600, mean_ecr: 0.0406 mean_entropies: 1.6666, took: 95.5764s
2022-10-09 06:22:19,733 [INFO] 	Process 3 - batch 20399: mean_policy_losses: -90.058, mean_net_lifetime: 4839.4678, mean_mc_travel_dist: 1794.8043, mean_rewards: 218.6724, total_rewards: 3075.3025, mean_steps: 24.6800, mean_ecr: 0.0398 mean_entropies: 1.6496, took: 128.2947s
2022-10-09 06:22:24,230 [INFO] 	Process 0 - batch 19799: mean_policy_losses: -71.901, mean_net_lifetime: 4576.3776, mean_mc_travel_dist: 1570.9526, mean_rewards: 216.5562, total_rewards: 3038.1396, mean_steps: 22.2500, mean_ecr: 0.0388 mean_entropies: 1.7065, took: 116.0308s
2022-10-09 06:22:29,239 [INFO] 	Process 6 - batch 20299: mean_policy_losses: -306.507, mean_net_lifetime: 4106.4305, mean_mc_travel_dist: 1465.6294, mean_rewards: 226.2594, total_rewards: 2679.3386, mean_steps: 19.5400, mean_ecr: 0.0405 mean_entropies: 1.6465, took: 102.7372s
2022-10-09 06:22:46,537 [INFO] 	Process 1 - batch 20999: mean_policy_losses: -20.374, mean_net_lifetime: 4822.7466, mean_mc_travel_dist: 1789.8849, mean_rewards: 232.7231, total_rewards: 3071.2860, mean_steps: 23.4200, mean_ecr: 0.0403 mean_entropies: 1.6326, took: 115.0654s
2022-10-09 06:23:04,111 [INFO] 	Process 2 - batch 20499: mean_policy_losses: -99.482, mean_net_lifetime: 4894.2923, mean_mc_travel_dist: 1829.4224, mean_rewards: 214.5031, total_rewards: 3108.9199, mean_steps: 25.1800, mean_ecr: 0.0401 mean_entropies: 1.7017, took: 131.0438s
2022-10-09 06:23:08,216 [INFO] 	Process 5 - batch 19999: mean_policy_losses: -93.906, mean_net_lifetime: 4442.8299, mean_mc_travel_dist: 1658.7784, mean_rewards: 215.1347, total_rewards: 2826.6154, mean_steps: 22.0600, mean_ecr: 0.0389 mean_entropies: 1.6637, took: 113.9243s
2022-10-09 06:23:21,851 [INFO] 	Process 4 - batch 20399: mean_policy_losses: -120.013, mean_net_lifetime: 4050.5323, mean_mc_travel_dist: 1398.7000, mean_rewards: 220.2593, total_rewards: 2688.0185, mean_steps: 19.6200, mean_ecr: 0.0400 mean_entropies: 1.6450, took: 104.5420s
2022-10-09 06:23:55,599 [INFO] 	Process 0 - batch 19899: mean_policy_losses: -70.551, mean_net_lifetime: 3670.5765, mean_mc_travel_dist: 1240.2264, mean_rewards: 224.5588, total_rewards: 2474.1070, mean_steps: 17.1500, mean_ecr: 0.0430 mean_entropies: 1.5883, took: 91.3700s
2022-10-09 06:24:08,566 [INFO] 	Process 3 - batch 20499: mean_policy_losses: -28.279, mean_net_lifetime: 4477.9380, mean_mc_travel_dist: 1619.7789, mean_rewards: 219.7890, total_rewards: 2901.2222, mean_steps: 21.3200, mean_ecr: 0.0398 mean_entropies: 1.6981, took: 108.8338s
2022-10-09 06:24:09,493 [INFO] 	Process 6 - batch 20399: mean_policy_losses: -36.872, mean_net_lifetime: 4215.5611, mean_mc_travel_dist: 1473.7555, mean_rewards: 223.8400, total_rewards: 2776.1195, mean_steps: 19.5900, mean_ecr: 0.0404 mean_entropies: 1.6613, took: 100.2545s
2022-10-09 06:24:43,994 [INFO] 	Process 5 - batch 20099: mean_policy_losses: -45.503, mean_net_lifetime: 3962.1747, mean_mc_travel_dist: 1378.2441, mean_rewards: 224.6662, total_rewards: 2620.1122, mean_steps: 18.4400, mean_ecr: 0.0400 mean_entropies: 1.6894, took: 95.7775s
2022-10-09 06:24:45,230 [INFO] 	Process 2 - batch 20599: mean_policy_losses: -82.669, mean_net_lifetime: 4227.4652, mean_mc_travel_dist: 1514.8575, mean_rewards: 221.1015, total_rewards: 2755.1990, mean_steps: 19.8800, mean_ecr: 0.0386 mean_entropies: 1.6692, took: 101.1194s
2022-10-09 06:25:14,309 [INFO] 	Process 4 - batch 20499: mean_policy_losses: -38.085, mean_net_lifetime: 4721.0636, mean_mc_travel_dist: 1804.0650, mean_rewards: 224.9018, total_rewards: 2966.1078, mean_steps: 22.3300, mean_ecr: 0.0401 mean_entropies: 1.6918, took: 112.4570s
2022-10-09 06:25:39,029 [INFO] 	Process 0 - batch 19999: mean_policy_losses: -182.343, mean_net_lifetime: 4197.7281, mean_mc_travel_dist: 1572.7477, mean_rewards: 216.9383, total_rewards: 2669.7952, mean_steps: 20.3600, mean_ecr: 0.0395 mean_entropies: 1.6828, took: 103.4286s
2022-10-09 06:25:51,667 [INFO] 	Process 3 - batch 20599: mean_policy_losses: -58.349, mean_net_lifetime: 4266.7125, mean_mc_travel_dist: 1527.5937, mean_rewards: 215.9520, total_rewards: 2782.6731, mean_steps: 20.5200, mean_ecr: 0.0386 mean_entropies: 1.6606, took: 103.1006s
2022-10-09 06:26:05,915 [INFO] 	Process 6 - batch 20499: mean_policy_losses: -158.760, mean_net_lifetime: 4587.6875, mean_mc_travel_dist: 1693.5073, mean_rewards: 214.5362, total_rewards: 2939.5218, mean_steps: 23.0900, mean_ecr: 0.0396 mean_entropies: 1.6828, took: 116.4220s
2022-10-09 06:26:28,348 [INFO] 	Process 5 - batch 20199: mean_policy_losses: -48.954, mean_net_lifetime: 4346.9755, mean_mc_travel_dist: 1553.5875, mean_rewards: 226.8432, total_rewards: 2824.8612, mean_steps: 20.2800, mean_ecr: 0.0384 mean_entropies: 1.5963, took: 104.3531s
2022-10-09 06:26:35,514 [INFO] 	Process 2 - batch 20699: mean_policy_losses: -107.131, mean_net_lifetime: 4408.7943, mean_mc_travel_dist: 1598.3784, mean_rewards: 216.3250, total_rewards: 2855.9070, mean_steps: 21.8800, mean_ecr: 0.0386 mean_entropies: 1.7154, took: 110.2829s
2022-10-09 06:27:01,906 [INFO] 	Process 4 - batch 20599: mean_policy_losses: -96.889, mean_net_lifetime: 4306.3776, mean_mc_travel_dist: 1528.2584, mean_rewards: 216.2339, total_rewards: 2819.2623, mean_steps: 20.9000, mean_ecr: 0.0383 mean_entropies: 1.6635, took: 107.5975s
2022-10-09 06:27:22,724 [INFO] 	Process 0 - batch 20099: mean_policy_losses: -96.245, mean_net_lifetime: 4216.9422, mean_mc_travel_dist: 1462.7750, mean_rewards: 217.1026, total_rewards: 2796.2733, mean_steps: 20.5100, mean_ecr: 0.0397 mean_entropies: 1.6566, took: 103.6958s
2022-10-09 06:27:38,672 [INFO] 	Process 3 - batch 20699: mean_policy_losses: -101.958, mean_net_lifetime: 4168.2803, mean_mc_travel_dist: 1454.5916, mean_rewards: 213.6124, total_rewards: 2758.1475, mean_steps: 21.0300, mean_ecr: 0.0387 mean_entropies: 1.7387, took: 107.0059s
2022-10-09 06:27:47,658 [INFO] 	Process 6 - batch 20599: mean_policy_losses: -87.145, mean_net_lifetime: 4260.6907, mean_mc_travel_dist: 1456.6029, mean_rewards: 218.9958, total_rewards: 2836.5049, mean_steps: 20.0900, mean_ecr: 0.0384 mean_entropies: 1.6896, took: 101.7422s
2022-10-09 06:27:57,162 [INFO] 	Process 5 - batch 20299: mean_policy_losses: -214.824, mean_net_lifetime: 3794.0012, mean_mc_travel_dist: 1257.0544, mean_rewards: 233.8484, total_rewards: 2568.9936, mean_steps: 16.9400, mean_ecr: 0.0409 mean_entropies: 1.6651, took: 88.8141s
2022-10-09 06:28:20,841 [INFO] 	Process 2 - batch 20799: mean_policy_losses: -132.505, mean_net_lifetime: 4301.1956, mean_mc_travel_dist: 1513.0083, mean_rewards: 217.7127, total_rewards: 2822.1230, mean_steps: 20.8400, mean_ecr: 0.0387 mean_entropies: 1.6708, took: 105.3267s
2022-10-09 06:28:53,009 [INFO] 	Process 4 - batch 20699: mean_policy_losses: -134.891, mean_net_lifetime: 4379.0116, mean_mc_travel_dist: 1547.7363, mean_rewards: 212.1485, total_rewards: 2868.6898, mean_steps: 21.6300, mean_ecr: 0.0387 mean_entropies: 1.7333, took: 111.1031s
2022-10-09 06:29:14,642 [INFO] 	Process 0 - batch 20199: mean_policy_losses: -12.943, mean_net_lifetime: 4578.5987, mean_mc_travel_dist: 1646.0938, mean_rewards: 216.6560, total_rewards: 2965.9442, mean_steps: 22.1400, mean_ecr: 0.0379 mean_entropies: 1.6225, took: 111.9166s
2022-10-09 06:29:20,280 [INFO] 	Process 3 - batch 20799: mean_policy_losses: -180.399, mean_net_lifetime: 4088.5916, mean_mc_travel_dist: 1440.5591, mean_rewards: 218.0123, total_rewards: 2687.0026, mean_steps: 19.9800, mean_ecr: 0.0387 mean_entropies: 1.6743, took: 101.6077s
2022-10-09 06:29:36,180 [INFO] 	Process 6 - batch 20699: mean_policy_losses: -174.040, mean_net_lifetime: 4328.0451, mean_mc_travel_dist: 1513.9661, mean_rewards: 210.9004, total_rewards: 2858.1599, mean_steps: 21.4400, mean_ecr: 0.0390 mean_entropies: 1.7432, took: 108.5225s
2022-10-09 06:29:40,608 [INFO] 	Process 5 - batch 20399: mean_policy_losses: -149.971, mean_net_lifetime: 4325.4051, mean_mc_travel_dist: 1527.7710, mean_rewards: 221.0820, total_rewards: 2830.4365, mean_steps: 20.4900, mean_ecr: 0.0400 mean_entropies: 1.6668, took: 103.4471s
2022-10-09 06:29:54,444 [INFO] 	Process 2 - batch 20899: mean_policy_losses: -161.659, mean_net_lifetime: 4003.8376, mean_mc_travel_dist: 1341.1303, mean_rewards: 231.7919, total_rewards: 2697.2449, mean_steps: 18.2100, mean_ecr: 0.0385 mean_entropies: 1.7324, took: 93.6033s
2022-10-09 06:30:29,719 [INFO] 	Process 4 - batch 20799: mean_policy_losses: -94.646, mean_net_lifetime: 4102.3731, mean_mc_travel_dist: 1511.5763, mean_rewards: 222.2252, total_rewards: 2635.5791, mean_steps: 19.2700, mean_ecr: 0.0388 mean_entropies: 1.6705, took: 96.7095s
2022-10-09 06:30:39,626 [INFO] 	Process 0 - batch 20299: mean_policy_losses: -199.104, mean_net_lifetime: 3654.5469, mean_mc_travel_dist: 1254.7706, mean_rewards: 228.5508, total_rewards: 2439.1596, mean_steps: 16.4100, mean_ecr: 0.0405 mean_entropies: 1.6694, took: 84.9855s
2022-10-09 06:30:53,690 [INFO] 	Process 3 - batch 20899: mean_policy_losses: -154.357, mean_net_lifetime: 4033.9404, mean_mc_travel_dist: 1390.8598, mean_rewards: 222.9101, total_rewards: 2667.6363, mean_steps: 18.4400, mean_ecr: 0.0386 mean_entropies: 1.7191, took: 93.4091s
2022-10-09 06:31:19,227 [INFO] 	Process 6 - batch 20799: mean_policy_losses: -81.386, mean_net_lifetime: 4237.7341, mean_mc_travel_dist: 1529.2004, mean_rewards: 221.1024, total_rewards: 2757.0070, mean_steps: 20.0600, mean_ecr: 0.0388 mean_entropies: 1.6783, took: 103.0475s
2022-10-09 06:31:34,811 [INFO] 	Process 2 - batch 20999: mean_policy_losses: -41.508, mean_net_lifetime: 4206.3538, mean_mc_travel_dist: 1469.8387, mean_rewards: 226.3379, total_rewards: 2772.6875, mean_steps: 19.4600, mean_ecr: 0.0404 mean_entropies: 1.6047, took: 100.3679s
2022-10-09 06:31:40,177 [INFO] 	Process 5 - batch 20499: mean_policy_losses: 3.460, mean_net_lifetime: 4829.4718, mean_mc_travel_dist: 1768.6384, mean_rewards: 218.2628, total_rewards: 3097.5625, mean_steps: 23.9700, mean_ecr: 0.0396 mean_entropies: 1.6986, took: 119.5694s
2022-10-09 06:32:12,825 [INFO] 	Process 4 - batch 20899: mean_policy_losses: -136.134, mean_net_lifetime: 4276.4795, mean_mc_travel_dist: 1480.1368, mean_rewards: 216.0349, total_rewards: 2826.0936, mean_steps: 20.7700, mean_ecr: 0.0383 mean_entropies: 1.7348, took: 103.1072s
2022-10-09 06:32:26,023 [INFO] 	Process 0 - batch 20399: mean_policy_losses: -116.121, mean_net_lifetime: 4411.0365, mean_mc_travel_dist: 1586.8370, mean_rewards: 219.6743, total_rewards: 2861.4367, mean_steps: 21.5200, mean_ecr: 0.0399 mean_entropies: 1.6587, took: 106.3968s
2022-10-09 06:32:39,208 [INFO] 	Process 3 - batch 20999: mean_policy_losses: -1.640, mean_net_lifetime: 4400.7236, mean_mc_travel_dist: 1538.2853, mean_rewards: 220.2038, total_rewards: 2890.6050, mean_steps: 21.1600, mean_ecr: 0.0403 mean_entropies: 1.6305, took: 105.5183s
2022-10-09 06:32:49,968 [INFO] 	Process 6 - batch 20899: mean_policy_losses: -217.934, mean_net_lifetime: 3869.4602, mean_mc_travel_dist: 1294.5394, mean_rewards: 221.1852, total_rewards: 2604.5225, mean_steps: 18.2500, mean_ecr: 0.0388 mean_entropies: 1.7312, took: 90.7405s
2022-10-09 06:33:38,810 [INFO] 	Process 5 - batch 20599: mean_policy_losses: -129.206, mean_net_lifetime: 4833.7931, mean_mc_travel_dist: 1755.4873, mean_rewards: 217.0156, total_rewards: 3116.7498, mean_steps: 25.3000, mean_ecr: 0.0386 mean_entropies: 1.6881, took: 118.6322s
2022-10-09 06:33:48,532 [INFO] 	Process 4 - batch 20999: mean_policy_losses: -18.686, mean_net_lifetime: 4334.7312, mean_mc_travel_dist: 1527.0263, mean_rewards: 225.3509, total_rewards: 2849.6545, mean_steps: 19.9800, mean_ecr: 0.0402 mean_entropies: 1.6744, took: 95.7066s
2022-10-09 06:34:00,102 [INFO] 	Process 0 - batch 20499: mean_policy_losses: -129.850, mean_net_lifetime: 4152.7134, mean_mc_travel_dist: 1505.8947, mean_rewards: 223.2732, total_rewards: 2686.9818, mean_steps: 19.5600, mean_ecr: 0.0403 mean_entropies: 1.7122, took: 94.0788s
2022-10-09 06:34:20,697 [INFO] 	Process 6 - batch 20999: mean_policy_losses: -73.707, mean_net_lifetime: 4126.9277, mean_mc_travel_dist: 1468.8788, mean_rewards: 226.1417, total_rewards: 2701.4464, mean_steps: 18.9400, mean_ecr: 0.0401 mean_entropies: 1.6876, took: 90.7299s
2022-10-09 06:35:08,845 [INFO] 	Process 5 - batch 20699: mean_policy_losses: -117.654, mean_net_lifetime: 4067.3914, mean_mc_travel_dist: 1407.3884, mean_rewards: 219.6972, total_rewards: 2690.7230, mean_steps: 19.7600, mean_ecr: 0.0389 mean_entropies: 1.7450, took: 90.0349s
2022-10-09 06:35:29,340 [INFO] 	Process 0 - batch 20599: mean_policy_losses: -155.243, mean_net_lifetime: 4152.7967, mean_mc_travel_dist: 1475.9223, mean_rewards: 213.2462, total_rewards: 2709.3640, mean_steps: 20.0900, mean_ecr: 0.0386 mean_entropies: 1.6923, took: 89.2380s
2022-10-09 06:36:32,596 [INFO] 	Process 5 - batch 20799: mean_policy_losses: -149.272, mean_net_lifetime: 3809.1758, mean_mc_travel_dist: 1321.8746, mean_rewards: 221.2603, total_rewards: 2522.4565, mean_steps: 18.1500, mean_ecr: 0.0390 mean_entropies: 1.6654, took: 83.7514s
2022-10-09 06:37:10,637 [INFO] 	Process 0 - batch 20699: mean_policy_losses: -64.551, mean_net_lifetime: 4495.6499, mean_mc_travel_dist: 1599.8174, mean_rewards: 216.2087, total_rewards: 2940.0609, mean_steps: 22.1400, mean_ecr: 0.0384 mean_entropies: 1.7467, took: 101.2967s
2022-10-09 06:37:16,492 [INFO] 	Process 1 - batch 21099: mean_policy_losses: -40.808, mean_net_lifetime: 4076.9189, mean_mc_travel_dist: 1440.4807, mean_rewards: 216.4517, total_rewards: 2678.2110, mean_steps: 19.7600, mean_ecr: 0.0405 mean_entropies: 1.6336, took: 869.9547s
2022-10-09 06:37:59,768 [INFO] 	Process 5 - batch 20899: mean_policy_losses: -194.217, mean_net_lifetime: 3934.5865, mean_mc_travel_dist: 1324.0102, mean_rewards: 224.1720, total_rewards: 2648.8083, mean_steps: 18.4800, mean_ecr: 0.0386 mean_entropies: 1.7405, took: 87.1721s
2022-10-09 06:38:41,562 [INFO] 	Process 0 - batch 20799: mean_policy_losses: -157.715, mean_net_lifetime: 4099.2080, mean_mc_travel_dist: 1439.3070, mean_rewards: 220.8627, total_rewards: 2696.1354, mean_steps: 19.6800, mean_ecr: 0.0389 mean_entropies: 1.6791, took: 90.9246s
2022-10-09 06:39:07,218 [INFO] 	Process 1 - batch 21199: mean_policy_losses: 26.492, mean_net_lifetime: 5005.2094, mean_mc_travel_dist: 1839.3723, mean_rewards: 214.0121, total_rewards: 3196.3525, mean_steps: 25.9500, mean_ecr: 0.0401 mean_entropies: 1.6801, took: 110.7268s
2022-10-09 06:39:32,077 [INFO] 	Process 5 - batch 20999: mean_policy_losses: -80.574, mean_net_lifetime: 4322.4603, mean_mc_travel_dist: 1537.1893, mean_rewards: 222.9303, total_rewards: 2828.7771, mean_steps: 20.4000, mean_ecr: 0.0407 mean_entropies: 1.6688, took: 92.3090s
2022-10-09 06:40:13,339 [INFO] 	Process 0 - batch 20899: mean_policy_losses: -192.121, mean_net_lifetime: 4259.6757, mean_mc_travel_dist: 1455.1268, mean_rewards: 226.4133, total_rewards: 2834.5095, mean_steps: 19.5000, mean_ecr: 0.0386 mean_entropies: 1.7593, took: 91.7754s
2022-10-09 06:40:31,075 [INFO] 	Process 1 - batch 21299: mean_policy_losses: -83.929, mean_net_lifetime: 4174.6408, mean_mc_travel_dist: 1487.4210, mean_rewards: 212.8282, total_rewards: 2726.3290, mean_steps: 19.9700, mean_ecr: 0.0393 mean_entropies: 1.6624, took: 83.8565s
2022-10-09 06:41:45,347 [INFO] 	Process 0 - batch 20999: mean_policy_losses: -78.236, mean_net_lifetime: 4483.5991, mean_mc_travel_dist: 1605.7662, mean_rewards: 227.2150, total_rewards: 2909.4714, mean_steps: 21.1000, mean_ecr: 0.0400 mean_entropies: 1.6802, took: 92.0107s
2022-10-09 06:41:59,469 [INFO] 	Process 1 - batch 21399: mean_policy_losses: -51.652, mean_net_lifetime: 4457.7982, mean_mc_travel_dist: 1574.4259, mean_rewards: 212.7133, total_rewards: 2915.7457, mean_steps: 21.3400, mean_ecr: 0.0388 mean_entropies: 1.6788, took: 88.3935s
2022-10-09 06:43:16,500 [INFO] 	Process 1 - batch 21499: mean_policy_losses: -206.554, mean_net_lifetime: 4154.7663, mean_mc_travel_dist: 1403.5891, mean_rewards: 223.2856, total_rewards: 2787.0149, mean_steps: 18.7600, mean_ecr: 0.0391 mean_entropies: 1.7316, took: 77.0311s
2022-10-09 06:44:32,884 [INFO] 	Process 2 - batch 21099: mean_policy_losses: -140.821, mean_net_lifetime: 3795.3855, mean_mc_travel_dist: 1348.9739, mean_rewards: 216.7414, total_rewards: 2488.7125, mean_steps: 17.6700, mean_ecr: 0.0406 mean_entropies: 1.6376, took: 778.0726s
2022-10-09 06:44:35,251 [INFO] 	Process 1 - batch 21599: mean_policy_losses: -35.660, mean_net_lifetime: 3986.4022, mean_mc_travel_dist: 1360.7820, mean_rewards: 224.1244, total_rewards: 2669.3752, mean_steps: 18.5400, mean_ecr: 0.0405 mean_entropies: 1.6471, took: 78.7506s
2022-10-09 06:45:53,586 [INFO] 	Process 3 - batch 21099: mean_policy_losses: -83.273, mean_net_lifetime: 4168.8250, mean_mc_travel_dist: 1455.1397, mean_rewards: 218.2297, total_rewards: 2756.4681, mean_steps: 19.9100, mean_ecr: 0.0402 mean_entropies: 1.6550, took: 794.3768s
2022-10-09 06:46:08,776 [INFO] 	Process 1 - batch 21699: mean_policy_losses: -189.721, mean_net_lifetime: 4479.1845, mean_mc_travel_dist: 1611.5161, mean_rewards: 228.0557, total_rewards: 2908.6261, mean_steps: 21.2700, mean_ecr: 0.0387 mean_entropies: 1.6463, took: 93.5266s
2022-10-09 06:46:23,358 [INFO] 	Process 2 - batch 21199: mean_policy_losses: -118.481, mean_net_lifetime: 4433.7833, mean_mc_travel_dist: 1566.5473, mean_rewards: 213.1733, total_rewards: 2907.4683, mean_steps: 22.9500, mean_ecr: 0.0401 mean_entropies: 1.6734, took: 110.4747s
2022-10-09 06:46:50,347 [INFO] 	Process 4 - batch 21099: mean_policy_losses: -119.845, mean_net_lifetime: 3897.2145, mean_mc_travel_dist: 1344.1510, mean_rewards: 218.7863, total_rewards: 2589.4876, mean_steps: 18.7100, mean_ecr: 0.0403 mean_entropies: 1.6254, took: 781.8142s
2022-10-09 06:47:43,419 [INFO] 	Process 6 - batch 21099: mean_policy_losses: -145.819, mean_net_lifetime: 4184.2296, mean_mc_travel_dist: 1503.4221, mean_rewards: 217.5873, total_rewards: 2720.1373, mean_steps: 20.3000, mean_ecr: 0.0405 mean_entropies: 1.6186, took: 802.7212s
2022-10-09 06:47:43,591 [INFO] 	Process 3 - batch 21199: mean_policy_losses: -42.822, mean_net_lifetime: 4473.2904, mean_mc_travel_dist: 1610.0949, mean_rewards: 218.0731, total_rewards: 2898.6295, mean_steps: 22.6800, mean_ecr: 0.0398 mean_entropies: 1.6511, took: 110.0054s
2022-10-09 06:47:48,263 [INFO] 	Process 1 - batch 21799: mean_policy_losses: -133.278, mean_net_lifetime: 4389.0989, mean_mc_travel_dist: 1547.8450, mean_rewards: 213.3782, total_rewards: 2879.2102, mean_steps: 21.3600, mean_ecr: 0.0389 mean_entropies: 1.6696, took: 99.4862s
2022-10-09 06:48:18,676 [INFO] 	Process 2 - batch 21299: mean_policy_losses: -67.374, mean_net_lifetime: 4780.7241, mean_mc_travel_dist: 1827.1567, mean_rewards: 218.0333, total_rewards: 2988.0488, mean_steps: 23.1500, mean_ecr: 0.0392 mean_entropies: 1.6112, took: 115.3170s
2022-10-09 06:48:46,760 [INFO] 	Process 4 - batch 21199: mean_policy_losses: -99.029, mean_net_lifetime: 4642.8557, mean_mc_travel_dist: 1721.0658, mean_rewards: 210.8880, total_rewards: 2964.2554, mean_steps: 24.1600, mean_ecr: 0.0401 mean_entropies: 1.6571, took: 116.4129s
2022-10-09 06:49:17,057 [INFO] 	Process 1 - batch 21899: mean_policy_losses: -88.524, mean_net_lifetime: 3954.8576, mean_mc_travel_dist: 1393.6266, mean_rewards: 224.5024, total_rewards: 2596.8876, mean_steps: 18.7800, mean_ecr: 0.0399 mean_entropies: 1.6160, took: 88.7933s
2022-10-09 06:49:22,534 [INFO] 	Process 3 - batch 21299: mean_policy_losses: -78.350, mean_net_lifetime: 4296.2582, mean_mc_travel_dist: 1552.1492, mean_rewards: 229.0247, total_rewards: 2789.9524, mean_steps: 20.0000, mean_ecr: 0.0391 mean_entropies: 1.5833, took: 98.9437s
2022-10-09 06:49:44,142 [INFO] 	Process 6 - batch 21199: mean_policy_losses: -26.073, mean_net_lifetime: 4902.1836, mean_mc_travel_dist: 1783.2554, mean_rewards: 217.3572, total_rewards: 3154.6742, mean_steps: 25.2100, mean_ecr: 0.0398 mean_entropies: 1.6213, took: 120.7231s
2022-10-09 06:50:03,517 [INFO] 	Process 2 - batch 21399: mean_policy_losses: -7.148, mean_net_lifetime: 4333.6311, mean_mc_travel_dist: 1533.1704, mean_rewards: 215.9277, total_rewards: 2840.0949, mean_steps: 20.8400, mean_ecr: 0.0386 mean_entropies: 1.6583, took: 104.8420s
2022-10-09 06:50:30,485 [INFO] 	Process 4 - batch 21299: mean_policy_losses: -55.070, mean_net_lifetime: 4400.3629, mean_mc_travel_dist: 1622.1354, mean_rewards: 223.0939, total_rewards: 2819.9745, mean_steps: 20.7200, mean_ecr: 0.0391 mean_entropies: 1.5650, took: 103.7249s
2022-10-09 06:50:44,116 [INFO] 	Process 1 - batch 21999: mean_policy_losses: -119.839, mean_net_lifetime: 3914.8061, mean_mc_travel_dist: 1350.1098, mean_rewards: 222.5996, total_rewards: 2606.7321, mean_steps: 18.3700, mean_ecr: 0.0401 mean_entropies: 1.6011, took: 87.0600s
2022-10-09 06:51:00,686 [INFO] 	Process 3 - batch 21399: mean_policy_losses: -43.184, mean_net_lifetime: 4300.8573, mean_mc_travel_dist: 1494.3024, mean_rewards: 219.5697, total_rewards: 2838.2750, mean_steps: 20.3600, mean_ecr: 0.0386 mean_entropies: 1.6522, took: 98.1519s
2022-10-09 06:51:26,742 [INFO] 	Process 6 - batch 21299: mean_policy_losses: -40.846, mean_net_lifetime: 4334.4073, mean_mc_travel_dist: 1515.0496, mean_rewards: 219.9422, total_rewards: 2855.0412, mean_steps: 20.5700, mean_ecr: 0.0389 mean_entropies: 1.6035, took: 102.5991s
2022-10-09 06:51:56,976 [INFO] 	Process 2 - batch 21499: mean_policy_losses: -27.879, mean_net_lifetime: 4741.4044, mean_mc_travel_dist: 1661.7760, mean_rewards: 222.9115, total_rewards: 3114.7668, mean_steps: 22.6400, mean_ecr: 0.0389 mean_entropies: 1.6946, took: 113.4586s
2022-10-09 06:52:06,734 [INFO] 	Process 4 - batch 21399: mean_policy_losses: -89.649, mean_net_lifetime: 4145.5747, mean_mc_travel_dist: 1440.7483, mean_rewards: 219.9603, total_rewards: 2747.5639, mean_steps: 19.1000, mean_ecr: 0.0389 mean_entropies: 1.6710, took: 96.2494s
2022-10-09 06:52:20,126 [INFO] 	Process 1 - batch 22099: mean_policy_losses: -107.946, mean_net_lifetime: 4162.5904, mean_mc_travel_dist: 1451.9140, mean_rewards: 218.8540, total_rewards: 2755.9626, mean_steps: 19.9700, mean_ecr: 0.0381 mean_entropies: 1.6366, took: 96.0097s
2022-10-09 06:52:36,696 [INFO] 	Process 3 - batch 21499: mean_policy_losses: -195.216, mean_net_lifetime: 4021.9392, mean_mc_travel_dist: 1384.5305, mean_rewards: 221.8766, total_rewards: 2671.1399, mean_steps: 18.9300, mean_ecr: 0.0392 mean_entropies: 1.7029, took: 96.0103s
2022-10-09 06:52:45,763 [INFO] 	Process 5 - batch 21099: mean_policy_losses: -125.963, mean_net_lifetime: 3735.5612, mean_mc_travel_dist: 1291.2317, mean_rewards: 225.5796, total_rewards: 2481.3893, mean_steps: 16.9600, mean_ecr: 0.0403 mean_entropies: 1.6567, took: 793.6862s
2022-10-09 06:53:10,094 [INFO] 	Process 6 - batch 21399: mean_policy_losses: -6.885, mean_net_lifetime: 4276.6605, mean_mc_travel_dist: 1511.1328, mean_rewards: 216.1375, total_rewards: 2813.2052, mean_steps: 20.3700, mean_ecr: 0.0393 mean_entropies: 1.6645, took: 103.3529s
2022-10-09 06:53:41,642 [INFO] 	Process 2 - batch 21599: mean_policy_losses: -86.642, mean_net_lifetime: 4387.0421, mean_mc_travel_dist: 1562.5952, mean_rewards: 226.8115, total_rewards: 2859.6254, mean_steps: 20.9400, mean_ecr: 0.0407 mean_entropies: 1.6389, took: 104.6664s
2022-10-09 06:53:53,140 [INFO] 	Process 4 - batch 21499: mean_policy_losses: -110.383, mean_net_lifetime: 4414.5352, mean_mc_travel_dist: 1507.2389, mean_rewards: 222.4342, total_rewards: 2945.5409, mean_steps: 20.7900, mean_ecr: 0.0394 mean_entropies: 1.7030, took: 106.4064s
2022-10-09 06:53:57,409 [INFO] 	Process 1 - batch 22199: mean_policy_losses: -111.169, mean_net_lifetime: 4282.3451, mean_mc_travel_dist: 1476.6097, mean_rewards: 215.3976, total_rewards: 2848.3641, mean_steps: 20.0000, mean_ecr: 0.0402 mean_entropies: 1.6843, took: 97.2826s
2022-10-09 06:54:33,371 [INFO] 	Process 3 - batch 21599: mean_policy_losses: -108.026, mean_net_lifetime: 4685.5456, mean_mc_travel_dist: 1705.2384, mean_rewards: 219.9746, total_rewards: 3009.7873, mean_steps: 23.2100, mean_ecr: 0.0405 mean_entropies: 1.6288, took: 116.6748s
2022-10-09 06:54:39,086 [INFO] 	Process 5 - batch 21199: mean_policy_losses: -109.021, mean_net_lifetime: 4416.1467, mean_mc_travel_dist: 1572.9130, mean_rewards: 218.6142, total_rewards: 2875.0406, mean_steps: 22.5100, mean_ecr: 0.0400 mean_entropies: 1.6460, took: 113.3225s
2022-10-09 06:54:58,368 [INFO] 	Process 6 - batch 21499: mean_policy_losses: -141.884, mean_net_lifetime: 4323.6897, mean_mc_travel_dist: 1507.3403, mean_rewards: 215.8030, total_rewards: 2852.7229, mean_steps: 20.9300, mean_ecr: 0.0391 mean_entropies: 1.6999, took: 108.2736s
2022-10-09 06:55:27,431 [INFO] 	Process 2 - batch 21699: mean_policy_losses: -108.939, mean_net_lifetime: 4284.0188, mean_mc_travel_dist: 1514.6749, mean_rewards: 221.6616, total_rewards: 2805.8931, mean_steps: 20.6000, mean_ecr: 0.0388 mean_entropies: 1.6582, took: 105.7892s
2022-10-09 06:55:41,596 [INFO] 	Process 4 - batch 21599: mean_policy_losses: -148.065, mean_net_lifetime: 4283.6880, mean_mc_travel_dist: 1468.9079, mean_rewards: 215.0870, total_rewards: 2848.0689, mean_steps: 20.5400, mean_ecr: 0.0404 mean_entropies: 1.6349, took: 108.4556s
2022-10-09 06:55:43,383 [INFO] 	Process 1 - batch 22299: mean_policy_losses: -193.341, mean_net_lifetime: 4376.1878, mean_mc_travel_dist: 1552.0141, mean_rewards: 210.8439, total_rewards: 2866.6706, mean_steps: 21.4900, mean_ecr: 0.0388 mean_entropies: 1.6967, took: 105.9750s
2022-10-09 06:55:56,174 [INFO] 	Process 0 - batch 21099: mean_policy_losses: -174.620, mean_net_lifetime: 3881.0272, mean_mc_travel_dist: 1371.3881, mean_rewards: 219.1021, total_rewards: 2545.2976, mean_steps: 18.6500, mean_ecr: 0.0406 mean_entropies: 1.6330, took: 850.8265s
2022-10-09 06:56:17,059 [INFO] 	Process 3 - batch 21699: mean_policy_losses: -70.953, mean_net_lifetime: 4078.3174, mean_mc_travel_dist: 1417.8804, mean_rewards: 219.4911, total_rewards: 2696.0368, mean_steps: 19.6600, mean_ecr: 0.0389 mean_entropies: 1.6484, took: 103.6879s
2022-10-09 06:56:28,265 [INFO] 	Process 5 - batch 21299: mean_policy_losses: -0.295, mean_net_lifetime: 4332.2607, mean_mc_travel_dist: 1516.1743, mean_rewards: 215.0058, total_rewards: 2852.0806, mean_steps: 21.1300, mean_ecr: 0.0389 mean_entropies: 1.6162, took: 109.1782s
2022-10-09 06:56:55,003 [INFO] 	Process 6 - batch 21599: mean_policy_losses: -49.973, mean_net_lifetime: 4446.9833, mean_mc_travel_dist: 1562.0157, mean_rewards: 218.6482, total_rewards: 2913.6973, mean_steps: 22.1500, mean_ecr: 0.0402 mean_entropies: 1.6234, took: 116.6352s
2022-10-09 06:57:10,941 [INFO] 	Process 2 - batch 21799: mean_policy_losses: -130.386, mean_net_lifetime: 4082.9763, mean_mc_travel_dist: 1413.4282, mean_rewards: 216.3923, total_rewards: 2706.8021, mean_steps: 19.6400, mean_ecr: 0.0394 mean_entropies: 1.6742, took: 103.5092s
2022-10-09 06:57:18,614 [INFO] 	Process 1 - batch 22399: mean_policy_losses: -119.795, mean_net_lifetime: 4077.5465, mean_mc_travel_dist: 1392.4122, mean_rewards: 226.2661, total_rewards: 2718.7381, mean_steps: 18.9700, mean_ecr: 0.0391 mean_entropies: 1.6656, took: 95.2311s
2022-10-09 06:57:21,832 [INFO] 	Process 4 - batch 21699: mean_policy_losses: -153.722, mean_net_lifetime: 4042.2692, mean_mc_travel_dist: 1420.2770, mean_rewards: 224.6922, total_rewards: 2668.7341, mean_steps: 18.9900, mean_ecr: 0.0386 mean_entropies: 1.6433, took: 100.2365s
2022-10-09 06:57:58,629 [INFO] 	Process 0 - batch 21199: mean_policy_losses: 8.755, mean_net_lifetime: 4598.7558, mean_mc_travel_dist: 1602.2074, mean_rewards: 211.3224, total_rewards: 3027.8657, mean_steps: 23.5100, mean_ecr: 0.0398 mean_entropies: 1.6636, took: 122.4561s
2022-10-09 06:58:03,235 [INFO] 	Process 3 - batch 21799: mean_policy_losses: -122.041, mean_net_lifetime: 4253.9337, mean_mc_travel_dist: 1469.4296, mean_rewards: 221.4473, total_rewards: 2823.1489, mean_steps: 19.8900, mean_ecr: 0.0392 mean_entropies: 1.6614, took: 106.1760s
2022-10-09 06:58:21,247 [INFO] 	Process 5 - batch 21399: mean_policy_losses: -69.390, mean_net_lifetime: 4371.7692, mean_mc_travel_dist: 1537.9643, mean_rewards: 212.0325, total_rewards: 2869.1749, mean_steps: 21.7100, mean_ecr: 0.0389 mean_entropies: 1.6368, took: 112.9828s
2022-10-09 06:58:43,597 [INFO] 	Process 6 - batch 21699: mean_policy_losses: -121.330, mean_net_lifetime: 4436.6715, mean_mc_travel_dist: 1545.4931, mean_rewards: 226.1586, total_rewards: 2922.9099, mean_steps: 20.9900, mean_ecr: 0.0387 mean_entropies: 1.6515, took: 108.5931s
2022-10-09 06:58:50,358 [INFO] 	Process 1 - batch 22499: mean_policy_losses: -128.207, mean_net_lifetime: 3840.4864, mean_mc_travel_dist: 1328.6433, mean_rewards: 222.6938, total_rewards: 2541.0564, mean_steps: 18.1900, mean_ecr: 0.0400 mean_entropies: 1.5704, took: 91.7432s
2022-10-09 06:58:57,282 [INFO] 	Process 2 - batch 21899: mean_policy_losses: -99.910, mean_net_lifetime: 4097.1156, mean_mc_travel_dist: 1414.6122, mean_rewards: 217.3947, total_rewards: 2726.7947, mean_steps: 19.7800, mean_ecr: 0.0399 mean_entropies: 1.6452, took: 106.3408s
2022-10-09 06:59:03,318 [INFO] 	Process 4 - batch 21799: mean_policy_losses: -169.231, mean_net_lifetime: 3967.2868, mean_mc_travel_dist: 1370.8265, mean_rewards: 216.3695, total_rewards: 2633.7110, mean_steps: 19.1000, mean_ecr: 0.0394 mean_entropies: 1.6821, took: 101.4855s
2022-10-09 06:59:43,346 [INFO] 	Process 3 - batch 21899: mean_policy_losses: -84.426, mean_net_lifetime: 4133.4723, mean_mc_travel_dist: 1412.7951, mean_rewards: 224.3755, total_rewards: 2753.1114, mean_steps: 19.4600, mean_ecr: 0.0400 mean_entropies: 1.6585, took: 100.1115s
2022-10-09 07:00:04,102 [INFO] 	Process 5 - batch 21499: mean_policy_losses: -181.835, mean_net_lifetime: 4139.6140, mean_mc_travel_dist: 1407.9561, mean_rewards: 226.7219, total_rewards: 2769.4960, mean_steps: 19.6700, mean_ecr: 0.0395 mean_entropies: 1.7116, took: 102.8556s
2022-10-09 07:00:08,454 [INFO] 	Process 0 - batch 21299: mean_policy_losses: -46.609, mean_net_lifetime: 5183.2045, mean_mc_travel_dist: 2092.7818, mean_rewards: 212.5212, total_rewards: 3128.6240, mean_steps: 25.9800, mean_ecr: 0.0392 mean_entropies: 1.6337, took: 129.8236s
2022-10-09 07:00:23,059 [INFO] 	Process 6 - batch 21799: mean_policy_losses: -126.411, mean_net_lifetime: 4168.1588, mean_mc_travel_dist: 1420.0868, mean_rewards: 219.7738, total_rewards: 2795.4501, mean_steps: 19.4300, mean_ecr: 0.0396 mean_entropies: 1.6723, took: 99.4629s
2022-10-09 07:00:34,116 [INFO] 	Process 2 - batch 21999: mean_policy_losses: -142.402, mean_net_lifetime: 4077.8378, mean_mc_travel_dist: 1404.5192, mean_rewards: 226.1324, total_rewards: 2706.9623, mean_steps: 19.0500, mean_ecr: 0.0402 mean_entropies: 1.6501, took: 96.8338s
2022-10-09 07:00:44,271 [INFO] 	Process 4 - batch 21899: mean_policy_losses: -76.962, mean_net_lifetime: 4182.7611, mean_mc_travel_dist: 1445.1427, mean_rewards: 223.3452, total_rewards: 2772.8823, mean_steps: 19.6000, mean_ecr: 0.0401 mean_entropies: 1.6248, took: 100.9534s
2022-10-09 07:01:10,468 [INFO] 	Process 3 - batch 21999: mean_policy_losses: -133.899, mean_net_lifetime: 3703.8078, mean_mc_travel_dist: 1268.9309, mean_rewards: 223.3226, total_rewards: 2472.3454, mean_steps: 16.9500, mean_ecr: 0.0402 mean_entropies: 1.6279, took: 87.1221s
2022-10-09 07:01:51,082 [INFO] 	Process 5 - batch 21599: mean_policy_losses: -9.644, mean_net_lifetime: 4414.8112, mean_mc_travel_dist: 1562.4129, mean_rewards: 219.9399, total_rewards: 2888.3202, mean_steps: 20.8100, mean_ecr: 0.0396 mean_entropies: 1.6347, took: 106.9793s
2022-10-09 07:01:52,116 [INFO] 	Process 0 - batch 21399: mean_policy_losses: -40.154, mean_net_lifetime: 4353.5752, mean_mc_travel_dist: 1506.2674, mean_rewards: 217.2980, total_rewards: 2878.6843, mean_steps: 20.1700, mean_ecr: 0.0388 mean_entropies: 1.6495, took: 103.6622s
2022-10-09 07:02:00,208 [INFO] 	Process 6 - batch 21899: mean_policy_losses: -62.694, mean_net_lifetime: 4111.2155, mean_mc_travel_dist: 1421.1106, mean_rewards: 220.1294, total_rewards: 2727.5319, mean_steps: 18.8600, mean_ecr: 0.0402 mean_entropies: 1.6442, took: 97.1489s
2022-10-09 07:02:12,609 [INFO] 	Process 4 - batch 21999: mean_policy_losses: -214.832, mean_net_lifetime: 3737.0911, mean_mc_travel_dist: 1310.2083, mean_rewards: 225.9849, total_rewards: 2467.4245, mean_steps: 16.9200, mean_ecr: 0.0402 mean_entropies: 1.6225, took: 88.3382s
2022-10-09 07:02:31,359 [INFO] 	Process 2 - batch 22099: mean_policy_losses: -41.985, mean_net_lifetime: 4743.0772, mean_mc_travel_dist: 1710.1194, mean_rewards: 214.5772, total_rewards: 3064.8061, mean_steps: 23.3500, mean_ecr: 0.0380 mean_entropies: 1.6409, took: 117.2433s
2022-10-09 07:03:24,025 [INFO] 	Process 3 - batch 22099: mean_policy_losses: -54.835, mean_net_lifetime: 5482.9780, mean_mc_travel_dist: 1989.7629, mean_rewards: 213.6488, total_rewards: 3527.6041, mean_steps: 26.9700, mean_ecr: 0.0385 mean_entropies: 1.6571, took: 133.5565s
2022-10-09 07:03:40,048 [INFO] 	Process 5 - batch 21699: mean_policy_losses: -159.643, mean_net_lifetime: 4455.2221, mean_mc_travel_dist: 1601.6202, mean_rewards: 230.6628, total_rewards: 2883.4866, mean_steps: 21.2800, mean_ecr: 0.0387 mean_entropies: 1.6139, took: 108.9661s
2022-10-09 07:03:41,495 [INFO] 	Process 6 - batch 21999: mean_policy_losses: -102.460, mean_net_lifetime: 4161.0581, mean_mc_travel_dist: 1434.6123, mean_rewards: 218.6228, total_rewards: 2760.6581, mean_steps: 19.6600, mean_ecr: 0.0398 mean_entropies: 1.6570, took: 101.2872s
2022-10-09 07:03:51,406 [INFO] 	Process 0 - batch 21499: mean_policy_losses: -43.826, mean_net_lifetime: 4852.8999, mean_mc_travel_dist: 1673.9067, mean_rewards: 217.7141, total_rewards: 3202.6504, mean_steps: 23.2200, mean_ecr: 0.0385 mean_entropies: 1.7147, took: 119.2898s
2022-10-09 07:03:57,725 [INFO] 	Process 4 - batch 22099: mean_policy_losses: -151.220, mean_net_lifetime: 4304.4925, mean_mc_travel_dist: 1499.6749, mean_rewards: 216.9963, total_rewards: 2836.2049, mean_steps: 20.7900, mean_ecr: 0.0382 mean_entropies: 1.6621, took: 105.1144s
2022-10-09 07:04:15,769 [INFO] 	Process 2 - batch 22199: mean_policy_losses: -92.809, mean_net_lifetime: 4271.9607, mean_mc_travel_dist: 1458.7042, mean_rewards: 213.6017, total_rewards: 2850.7163, mean_steps: 20.2600, mean_ecr: 0.0400 mean_entropies: 1.6612, took: 104.4098s
2022-10-09 07:05:00,780 [INFO] 	Process 3 - batch 22199: mean_policy_losses: -89.287, mean_net_lifetime: 4065.7296, mean_mc_travel_dist: 1392.4156, mean_rewards: 218.5036, total_rewards: 2712.1969, mean_steps: 18.8400, mean_ecr: 0.0398 mean_entropies: 1.6650, took: 96.7554s
2022-10-09 07:05:17,187 [INFO] 	Process 5 - batch 21799: mean_policy_losses: -194.776, mean_net_lifetime: 3981.7378, mean_mc_travel_dist: 1381.9719, mean_rewards: 213.6680, total_rewards: 2632.6555, mean_steps: 18.8200, mean_ecr: 0.0396 mean_entropies: 1.6815, took: 97.1391s
2022-10-09 07:05:28,816 [INFO] 	Process 6 - batch 22099: mean_policy_losses: -102.036, mean_net_lifetime: 4425.0868, mean_mc_travel_dist: 1575.1188, mean_rewards: 217.2943, total_rewards: 2886.7189, mean_steps: 21.1500, mean_ecr: 0.0382 mean_entropies: 1.6362, took: 107.3203s
2022-10-09 07:05:33,729 [INFO] 	Process 0 - batch 21599: mean_policy_losses: -78.503, mean_net_lifetime: 4264.2666, mean_mc_travel_dist: 1456.0084, mean_rewards: 220.8248, total_rewards: 2834.9711, mean_steps: 20.0600, mean_ecr: 0.0409 mean_entropies: 1.6118, took: 102.3239s
2022-10-09 07:05:36,934 [INFO] 	Process 4 - batch 22199: mean_policy_losses: -48.962, mean_net_lifetime: 4184.4693, mean_mc_travel_dist: 1435.9617, mean_rewards: 217.7321, total_rewards: 2783.8503, mean_steps: 19.2900, mean_ecr: 0.0401 mean_entropies: 1.6323, took: 99.2105s
2022-10-09 07:05:57,294 [INFO] 	Process 2 - batch 22299: mean_policy_losses: -117.503, mean_net_lifetime: 4219.0002, mean_mc_travel_dist: 1472.6065, mean_rewards: 224.3243, total_rewards: 2785.5694, mean_steps: 19.6400, mean_ecr: 0.0391 mean_entropies: 1.6750, took: 101.5256s
2022-10-09 07:06:57,876 [INFO] 	Process 5 - batch 21899: mean_policy_losses: -62.907, mean_net_lifetime: 4030.0927, mean_mc_travel_dist: 1389.6979, mean_rewards: 216.8054, total_rewards: 2679.4993, mean_steps: 19.9900, mean_ecr: 0.0399 mean_entropies: 1.5908, took: 100.6891s
2022-10-09 07:07:07,586 [INFO] 	Process 6 - batch 22199: mean_policy_losses: -34.523, mean_net_lifetime: 4135.7024, mean_mc_travel_dist: 1399.7553, mean_rewards: 214.2761, total_rewards: 2767.7461, mean_steps: 19.3900, mean_ecr: 0.0403 mean_entropies: 1.6255, took: 98.7710s
2022-10-09 07:07:14,838 [INFO] 	Process 0 - batch 21699: mean_policy_losses: -142.932, mean_net_lifetime: 3990.1993, mean_mc_travel_dist: 1379.1433, mean_rewards: 223.1367, total_rewards: 2643.8328, mean_steps: 19.5100, mean_ecr: 0.0382 mean_entropies: 1.6257, took: 101.1092s
2022-10-09 07:07:15,163 [INFO] 	Process 4 - batch 22299: mean_policy_losses: -115.853, mean_net_lifetime: 4040.4485, mean_mc_travel_dist: 1392.6393, mean_rewards: 219.9419, total_rewards: 2683.7131, mean_steps: 18.9900, mean_ecr: 0.0389 mean_entropies: 1.6895, took: 98.2278s
2022-10-09 07:07:16,947 [INFO] 	Process 3 - batch 22299: mean_policy_losses: -92.622, mean_net_lifetime: 5671.8692, mean_mc_travel_dist: 2022.0265, mean_rewards: 222.5875, total_rewards: 3691.7949, mean_steps: 27.8800, mean_ecr: 0.0392 mean_entropies: 1.6724, took: 136.1672s
2022-10-09 07:07:34,086 [INFO] 	Process 2 - batch 22399: mean_policy_losses: -197.573, mean_net_lifetime: 3927.6892, mean_mc_travel_dist: 1369.8952, mean_rewards: 224.6068, total_rewards: 2610.8322, mean_steps: 18.3300, mean_ecr: 0.0390 mean_entropies: 1.6317, took: 96.7917s
2022-10-09 07:08:30,985 [INFO] 	Process 5 - batch 21999: mean_policy_losses: -130.462, mean_net_lifetime: 3862.7402, mean_mc_travel_dist: 1347.3232, mean_rewards: 217.9829, total_rewards: 2558.8040, mean_steps: 18.0600, mean_ecr: 0.0399 mean_entropies: 1.6052, took: 93.1080s
2022-10-09 07:08:46,188 [INFO] 	Process 4 - batch 22399: mean_policy_losses: -125.841, mean_net_lifetime: 3765.6442, mean_mc_travel_dist: 1290.5357, mean_rewards: 221.8484, total_rewards: 2507.6119, mean_steps: 17.5300, mean_ecr: 0.0395 mean_entropies: 1.5995, took: 91.0262s
2022-10-09 07:08:46,727 [INFO] 	Process 6 - batch 22299: mean_policy_losses: -98.955, mean_net_lifetime: 4130.6117, mean_mc_travel_dist: 1417.3023, mean_rewards: 217.4975, total_rewards: 2755.5557, mean_steps: 19.4500, mean_ecr: 0.0390 mean_entropies: 1.6575, took: 99.1404s
2022-10-09 07:08:48,029 [INFO] 	Process 3 - batch 22399: mean_policy_losses: -145.313, mean_net_lifetime: 3897.7231, mean_mc_travel_dist: 1392.5046, mean_rewards: 222.5907, total_rewards: 2552.5532, mean_steps: 17.9600, mean_ecr: 0.0393 mean_entropies: 1.6393, took: 91.0820s
2022-10-09 07:08:56,952 [INFO] 	Process 0 - batch 21799: mean_policy_losses: -33.563, mean_net_lifetime: 4235.4008, mean_mc_travel_dist: 1464.1702, mean_rewards: 217.9031, total_rewards: 2817.7102, mean_steps: 19.9700, mean_ecr: 0.0395 mean_entropies: 1.6489, took: 102.1134s
2022-10-09 07:09:11,283 [INFO] 	Process 2 - batch 22499: mean_policy_losses: -27.338, mean_net_lifetime: 4048.5050, mean_mc_travel_dist: 1420.2555, mean_rewards: 219.4577, total_rewards: 2667.5421, mean_steps: 18.9100, mean_ecr: 0.0399 mean_entropies: 1.5311, took: 97.1972s
2022-10-09 07:10:07,167 [INFO] 	Process 5 - batch 22099: mean_policy_losses: -56.764, mean_net_lifetime: 4081.1197, mean_mc_travel_dist: 1413.0893, mean_rewards: 218.4387, total_rewards: 2703.7586, mean_steps: 19.1500, mean_ecr: 0.0385 mean_entropies: 1.6379, took: 96.1814s
2022-10-09 07:10:15,990 [INFO] 	Process 6 - batch 22399: mean_policy_losses: -160.970, mean_net_lifetime: 3789.0595, mean_mc_travel_dist: 1304.1456, mean_rewards: 227.5492, total_rewards: 2526.3752, mean_steps: 17.2200, mean_ecr: 0.0395 mean_entropies: 1.6463, took: 89.2624s
2022-10-09 07:10:18,041 [INFO] 	Process 4 - batch 22499: mean_policy_losses: -55.161, mean_net_lifetime: 3957.7749, mean_mc_travel_dist: 1366.8088, mean_rewards: 222.9175, total_rewards: 2626.2378, mean_steps: 18.3200, mean_ecr: 0.0400 mean_entropies: 1.5615, took: 91.8525s
2022-10-09 07:10:24,436 [INFO] 	Process 3 - batch 22499: mean_policy_losses: -15.282, mean_net_lifetime: 4139.9349, mean_mc_travel_dist: 1428.1817, mean_rewards: 221.4417, total_rewards: 2743.6866, mean_steps: 19.2300, mean_ecr: 0.0401 mean_entropies: 1.5247, took: 96.4068s
2022-10-09 07:10:34,989 [INFO] 	Process 0 - batch 21899: mean_policy_losses: -100.915, mean_net_lifetime: 4043.2362, mean_mc_travel_dist: 1412.7561, mean_rewards: 216.9933, total_rewards: 2668.8078, mean_steps: 19.8400, mean_ecr: 0.0399 mean_entropies: 1.6336, took: 98.0368s
2022-10-09 07:11:36,689 [INFO] 	Process 5 - batch 22199: mean_policy_losses: -61.628, mean_net_lifetime: 4040.2303, mean_mc_travel_dist: 1386.2190, mean_rewards: 214.7410, total_rewards: 2693.2639, mean_steps: 19.2300, mean_ecr: 0.0406 mean_entropies: 1.6517, took: 89.5242s
2022-10-09 07:11:49,706 [INFO] 	Process 6 - batch 22499: mean_policy_losses: -12.414, mean_net_lifetime: 4149.1993, mean_mc_travel_dist: 1433.5919, mean_rewards: 211.3139, total_rewards: 2750.1490, mean_steps: 19.7700, mean_ecr: 0.0399 mean_entropies: 1.5742, took: 93.7168s
2022-10-09 07:11:57,897 [INFO] 	Process 0 - batch 21999: mean_policy_losses: -118.282, mean_net_lifetime: 3848.4744, mean_mc_travel_dist: 1298.8725, mean_rewards: 226.3554, total_rewards: 2584.3448, mean_steps: 17.8900, mean_ecr: 0.0400 mean_entropies: 1.6455, took: 82.9076s
2022-10-09 07:13:08,742 [INFO] 	Process 5 - batch 22299: mean_policy_losses: -84.800, mean_net_lifetime: 4236.3405, mean_mc_travel_dist: 1452.5158, mean_rewards: 220.6189, total_rewards: 2811.1517, mean_steps: 19.8000, mean_ecr: 0.0391 mean_entropies: 1.6972, took: 92.0520s
2022-10-09 07:13:34,372 [INFO] 	Process 1 - batch 22599: mean_policy_losses: -134.710, mean_net_lifetime: 4770.3067, mean_mc_travel_dist: 1686.7125, mean_rewards: 224.2355, total_rewards: 3117.7237, mean_steps: 23.6400, mean_ecr: 0.0398 mean_entropies: 1.5822, took: 884.0144s
2022-10-09 07:13:35,781 [INFO] 	Process 0 - batch 22099: mean_policy_losses: -10.605, mean_net_lifetime: 4417.4296, mean_mc_travel_dist: 1508.0412, mean_rewards: 215.3315, total_rewards: 2941.7258, mean_steps: 21.3000, mean_ecr: 0.0381 mean_entropies: 1.6279, took: 97.8843s
2022-10-09 07:14:31,046 [INFO] 	Process 5 - batch 22399: mean_policy_losses: -137.293, mean_net_lifetime: 3893.2435, mean_mc_travel_dist: 1325.8660, mean_rewards: 224.3638, total_rewards: 2605.8761, mean_steps: 17.6900, mean_ecr: 0.0397 mean_entropies: 1.6346, took: 82.3043s
2022-10-09 07:14:55,144 [INFO] 	Process 1 - batch 22699: mean_policy_losses: -161.074, mean_net_lifetime: 3998.7730, mean_mc_travel_dist: 1356.7410, mean_rewards: 226.3975, total_rewards: 2678.7574, mean_steps: 18.3300, mean_ecr: 0.0381 mean_entropies: 1.6882, took: 80.7717s
2022-10-09 07:15:06,722 [INFO] 	Process 0 - batch 22199: mean_policy_losses: -182.184, mean_net_lifetime: 4054.7931, mean_mc_travel_dist: 1415.3537, mean_rewards: 214.4947, total_rewards: 2673.4398, mean_steps: 19.3600, mean_ecr: 0.0403 mean_entropies: 1.6474, took: 90.9412s
2022-10-09 07:15:59,880 [INFO] 	Process 5 - batch 22499: mean_policy_losses: -34.128, mean_net_lifetime: 4178.6449, mean_mc_travel_dist: 1432.4794, mean_rewards: 221.5302, total_rewards: 2782.2421, mean_steps: 19.3700, mean_ecr: 0.0399 mean_entropies: 1.5508, took: 88.8340s
2022-10-09 07:16:21,633 [INFO] 	Process 1 - batch 22799: mean_policy_losses: -85.518, mean_net_lifetime: 4188.9396, mean_mc_travel_dist: 1422.3894, mean_rewards: 222.6670, total_rewards: 2800.9259, mean_steps: 20.2400, mean_ecr: 0.0394 mean_entropies: 1.6241, took: 86.4900s
2022-10-09 07:16:37,466 [INFO] 	Process 0 - batch 22299: mean_policy_losses: -79.419, mean_net_lifetime: 4152.8554, mean_mc_travel_dist: 1389.1955, mean_rewards: 213.5360, total_rewards: 2801.5450, mean_steps: 19.6200, mean_ecr: 0.0394 mean_entropies: 1.6956, took: 90.7441s
2022-10-09 07:17:40,173 [INFO] 	Process 1 - batch 22899: mean_policy_losses: -32.084, mean_net_lifetime: 3996.3635, mean_mc_travel_dist: 1390.4212, mean_rewards: 222.5084, total_rewards: 2633.1059, mean_steps: 18.8800, mean_ecr: 0.0394 mean_entropies: 1.6207, took: 78.5395s
2022-10-09 07:17:50,399 [INFO] 	Process 0 - batch 22399: mean_policy_losses: -236.753, mean_net_lifetime: 3579.0300, mean_mc_travel_dist: 1229.2750, mean_rewards: 230.2957, total_rewards: 2394.3153, mean_steps: 16.2100, mean_ecr: 0.0391 mean_entropies: 1.6058, took: 72.9334s
2022-10-09 07:18:59,126 [INFO] 	Process 1 - batch 22999: mean_policy_losses: -50.746, mean_net_lifetime: 4008.5927, mean_mc_travel_dist: 1389.4287, mean_rewards: 219.6623, total_rewards: 2656.5450, mean_steps: 18.5600, mean_ecr: 0.0399 mean_entropies: 1.6230, took: 78.9525s
2022-10-09 07:19:14,308 [INFO] 	Process 0 - batch 22499: mean_policy_losses: -127.117, mean_net_lifetime: 3931.4246, mean_mc_travel_dist: 1377.9390, mean_rewards: 221.2533, total_rewards: 2590.7638, mean_steps: 18.4200, mean_ecr: 0.0399 mean_entropies: 1.5287, took: 83.9092s
2022-10-09 07:20:22,752 [INFO] 	Process 1 - batch 23099: mean_policy_losses: -140.888, mean_net_lifetime: 4448.2068, mean_mc_travel_dist: 1552.4002, mean_rewards: 227.0394, total_rewards: 2924.4595, mean_steps: 20.4300, mean_ecr: 0.0402 mean_entropies: 1.6007, took: 83.6263s
2022-10-09 07:21:47,610 [INFO] 	Process 1 - batch 23199: mean_policy_losses: -30.239, mean_net_lifetime: 4242.8668, mean_mc_travel_dist: 1481.4292, mean_rewards: 221.3557, total_rewards: 2801.8098, mean_steps: 20.6200, mean_ecr: 0.0387 mean_entropies: 1.6536, took: 84.8581s
2022-10-09 07:22:23,824 [INFO] 	Process 2 - batch 22599: mean_policy_losses: -48.795, mean_net_lifetime: 4317.6513, mean_mc_travel_dist: 1522.8480, mean_rewards: 218.4482, total_rewards: 2829.6309, mean_steps: 21.3500, mean_ecr: 0.0396 mean_entropies: 1.5723, took: 792.5405s
2022-10-09 07:23:14,011 [INFO] 	Process 1 - batch 23299: mean_policy_losses: -75.039, mean_net_lifetime: 4248.9005, mean_mc_travel_dist: 1543.7046, mean_rewards: 215.8099, total_rewards: 2737.2801, mean_steps: 20.2000, mean_ecr: 0.0393 mean_entropies: 1.6036, took: 86.4000s
2022-10-09 07:23:45,902 [INFO] 	Process 2 - batch 22699: mean_policy_losses: -142.646, mean_net_lifetime: 3840.3899, mean_mc_travel_dist: 1322.0655, mean_rewards: 232.3346, total_rewards: 2553.4946, mean_steps: 16.9200, mean_ecr: 0.0388 mean_entropies: 1.6410, took: 82.0789s
2022-10-09 07:23:57,649 [INFO] 	Process 4 - batch 22599: mean_policy_losses: -47.916, mean_net_lifetime: 4183.4786, mean_mc_travel_dist: 1467.4048, mean_rewards: 227.6793, total_rewards: 2744.0430, mean_steps: 19.1600, mean_ecr: 0.0394 mean_entropies: 1.5694, took: 819.6076s
2022-10-09 07:24:25,391 [INFO] 	Process 3 - batch 22599: mean_policy_losses: -71.658, mean_net_lifetime: 4124.5034, mean_mc_travel_dist: 1420.3625, mean_rewards: 220.6618, total_rewards: 2735.4818, mean_steps: 19.2700, mean_ecr: 0.0397 mean_entropies: 1.5691, took: 840.9546s
2022-10-09 07:24:47,488 [INFO] 	Process 1 - batch 23399: mean_policy_losses: -94.440, mean_net_lifetime: 4274.6455, mean_mc_travel_dist: 1555.4003, mean_rewards: 223.5272, total_rewards: 2759.9286, mean_steps: 19.9000, mean_ecr: 0.0392 mean_entropies: 1.5984, took: 93.4778s
2022-10-09 07:24:53,651 [INFO] 	Process 6 - batch 22599: mean_policy_losses: -58.225, mean_net_lifetime: 4106.7572, mean_mc_travel_dist: 1422.0551, mean_rewards: 222.5714, total_rewards: 2719.5727, mean_steps: 19.1100, mean_ecr: 0.0393 mean_entropies: 1.5564, took: 783.9448s
2022-10-09 07:25:29,430 [INFO] 	Process 2 - batch 22799: mean_policy_losses: -54.759, mean_net_lifetime: 4245.7170, mean_mc_travel_dist: 1493.3632, mean_rewards: 221.4484, total_rewards: 2784.8263, mean_steps: 20.7600, mean_ecr: 0.0390 mean_entropies: 1.5825, took: 103.5277s
2022-10-09 07:25:30,895 [INFO] 	Process 4 - batch 22699: mean_policy_losses: -131.675, mean_net_lifetime: 3923.9696, mean_mc_travel_dist: 1363.2699, mean_rewards: 224.9208, total_rewards: 2600.9221, mean_steps: 18.5700, mean_ecr: 0.0384 mean_entropies: 1.6205, took: 93.2464s
2022-10-09 07:25:52,781 [INFO] 	Process 3 - batch 22699: mean_policy_losses: -161.740, mean_net_lifetime: 3790.6640, mean_mc_travel_dist: 1304.7651, mean_rewards: 229.0409, total_rewards: 2520.1476, mean_steps: 17.1600, mean_ecr: 0.0387 mean_entropies: 1.6380, took: 87.3906s
2022-10-09 07:26:12,475 [INFO] 	Process 1 - batch 23499: mean_policy_losses: -72.794, mean_net_lifetime: 3889.0343, mean_mc_travel_dist: 1339.9452, mean_rewards: 226.4610, total_rewards: 2583.1104, mean_steps: 17.9400, mean_ecr: 0.0410 mean_entropies: 1.5397, took: 84.9868s
2022-10-09 07:26:24,218 [INFO] 	Process 6 - batch 22699: mean_policy_losses: -94.255, mean_net_lifetime: 4007.4875, mean_mc_travel_dist: 1379.1431, mean_rewards: 230.2332, total_rewards: 2665.2980, mean_steps: 18.0500, mean_ecr: 0.0382 mean_entropies: 1.6621, took: 90.5666s
2022-10-09 07:27:05,794 [INFO] 	Process 2 - batch 22899: mean_policy_losses: -61.903, mean_net_lifetime: 4069.0238, mean_mc_travel_dist: 1431.7037, mean_rewards: 224.8140, total_rewards: 2665.4849, mean_steps: 19.1700, mean_ecr: 0.0403 mean_entropies: 1.5625, took: 96.3645s
2022-10-09 07:27:29,147 [INFO] 	Process 3 - batch 22799: mean_policy_losses: -72.469, mean_net_lifetime: 4219.2298, mean_mc_travel_dist: 1515.5606, mean_rewards: 222.1321, total_rewards: 2749.2352, mean_steps: 19.7100, mean_ecr: 0.0395 mean_entropies: 1.5523, took: 96.3659s
2022-10-09 07:27:29,753 [INFO] 	Process 4 - batch 22799: mean_policy_losses: -37.897, mean_net_lifetime: 5056.4246, mean_mc_travel_dist: 1863.3024, mean_rewards: 225.5144, total_rewards: 3244.2502, mean_steps: 24.6300, mean_ecr: 0.0393 mean_entropies: 1.5809, took: 118.8585s
2022-10-09 07:27:47,576 [INFO] 	Process 1 - batch 23599: mean_policy_losses: -46.787, mean_net_lifetime: 4234.0178, mean_mc_travel_dist: 1486.9547, mean_rewards: 216.7722, total_rewards: 2771.5547, mean_steps: 20.1500, mean_ecr: 0.0384 mean_entropies: 1.5735, took: 95.1006s
2022-10-09 07:27:58,394 [INFO] 	Process 6 - batch 22799: mean_policy_losses: -123.529, mean_net_lifetime: 3987.1020, mean_mc_travel_dist: 1392.8386, mean_rewards: 223.8992, total_rewards: 2638.7125, mean_steps: 18.7100, mean_ecr: 0.0397 mean_entropies: 1.5475, took: 94.1759s
2022-10-09 07:28:48,785 [INFO] 	Process 2 - batch 22999: mean_policy_losses: -78.715, mean_net_lifetime: 4223.3295, mean_mc_travel_dist: 1491.9601, mean_rewards: 211.2856, total_rewards: 2765.7125, mean_steps: 20.4600, mean_ecr: 0.0395 mean_entropies: 1.5788, took: 102.9906s
2022-10-09 07:29:14,028 [INFO] 	Process 3 - batch 22899: mean_policy_losses: -62.858, mean_net_lifetime: 4212.1030, mean_mc_travel_dist: 1479.8562, mean_rewards: 217.0335, total_rewards: 2766.6339, mean_steps: 20.8400, mean_ecr: 0.0398 mean_entropies: 1.5669, took: 104.8811s
2022-10-09 07:29:16,075 [INFO] 	Process 4 - batch 22899: mean_policy_losses: -92.368, mean_net_lifetime: 4350.2460, mean_mc_travel_dist: 1524.6684, mean_rewards: 226.2860, total_rewards: 2852.5816, mean_steps: 20.9500, mean_ecr: 0.0396 mean_entropies: 1.5638, took: 106.3213s
2022-10-09 07:29:23,976 [INFO] 	Process 5 - batch 22599: mean_policy_losses: -148.691, mean_net_lifetime: 4111.0838, mean_mc_travel_dist: 1451.4606, mean_rewards: 224.5443, total_rewards: 2700.9470, mean_steps: 19.7900, mean_ecr: 0.0394 mean_entropies: 1.5560, took: 804.0963s
2022-10-09 07:29:27,494 [INFO] 	Process 1 - batch 23699: mean_policy_losses: -157.138, mean_net_lifetime: 4015.1303, mean_mc_travel_dist: 1396.7192, mean_rewards: 207.9135, total_rewards: 2654.5605, mean_steps: 20.6200, mean_ecr: 0.0388 mean_entropies: 1.5284, took: 99.9191s
2022-10-09 07:29:49,026 [INFO] 	Process 6 - batch 22899: mean_policy_losses: -73.651, mean_net_lifetime: 4403.2365, mean_mc_travel_dist: 1551.8932, mean_rewards: 211.7346, total_rewards: 2894.9326, mean_steps: 21.9400, mean_ecr: 0.0387 mean_entropies: 1.5864, took: 110.6320s
2022-10-09 07:30:29,302 [INFO] 	Process 2 - batch 23099: mean_policy_losses: -71.698, mean_net_lifetime: 4256.8974, mean_mc_travel_dist: 1475.5729, mean_rewards: 226.4194, total_rewards: 2814.2559, mean_steps: 19.8000, mean_ecr: 0.0401 mean_entropies: 1.6177, took: 100.5170s
2022-10-09 07:30:45,460 [INFO] 	Process 3 - batch 22999: mean_policy_losses: -132.474, mean_net_lifetime: 3867.4674, mean_mc_travel_dist: 1323.2163, mean_rewards: 219.7240, total_rewards: 2586.3340, mean_steps: 17.8100, mean_ecr: 0.0396 mean_entropies: 1.6284, took: 91.4318s
2022-10-09 07:30:51,645 [INFO] 	Process 4 - batch 22999: mean_policy_losses: -83.653, mean_net_lifetime: 4098.0636, mean_mc_travel_dist: 1410.4145, mean_rewards: 222.6638, total_rewards: 2732.9003, mean_steps: 18.5900, mean_ecr: 0.0393 mean_entropies: 1.6336, took: 95.5700s
2022-10-09 07:30:57,441 [INFO] 	Process 5 - batch 22699: mean_policy_losses: -210.793, mean_net_lifetime: 3876.4529, mean_mc_travel_dist: 1337.6733, mean_rewards: 226.1977, total_rewards: 2577.0567, mean_steps: 17.8900, mean_ecr: 0.0385 mean_entropies: 1.6429, took: 93.4638s
2022-10-09 07:31:19,431 [INFO] 	Process 1 - batch 23799: mean_policy_losses: -38.487, mean_net_lifetime: 4966.8517, mean_mc_travel_dist: 1959.6232, mean_rewards: 223.4194, total_rewards: 3038.4342, mean_steps: 23.5400, mean_ecr: 0.0390 mean_entropies: 1.5685, took: 111.9367s
2022-10-09 07:31:28,455 [INFO] 	Process 6 - batch 22999: mean_policy_losses: -81.298, mean_net_lifetime: 4260.3888, mean_mc_travel_dist: 1480.8552, mean_rewards: 224.1481, total_rewards: 2811.0830, mean_steps: 19.5300, mean_ecr: 0.0395 mean_entropies: 1.6077, took: 99.4291s
2022-10-09 07:32:09,219 [INFO] 	Process 2 - batch 23199: mean_policy_losses: -111.710, mean_net_lifetime: 4062.1899, mean_mc_travel_dist: 1419.4686, mean_rewards: 222.0808, total_rewards: 2685.3350, mean_steps: 19.1400, mean_ecr: 0.0385 mean_entropies: 1.6375, took: 99.9159s
2022-10-09 07:32:33,095 [INFO] 	Process 3 - batch 23099: mean_policy_losses: -102.175, mean_net_lifetime: 4438.5796, mean_mc_travel_dist: 1602.1010, mean_rewards: 224.9545, total_rewards: 2877.8438, mean_steps: 21.0800, mean_ecr: 0.0403 mean_entropies: 1.6188, took: 107.6352s
2022-10-09 07:32:36,461 [INFO] 	Process 4 - batch 23099: mean_policy_losses: -43.817, mean_net_lifetime: 4323.2758, mean_mc_travel_dist: 1514.8642, mean_rewards: 225.6104, total_rewards: 2845.2142, mean_steps: 19.8500, mean_ecr: 0.0401 mean_entropies: 1.6245, took: 104.8166s
2022-10-09 07:32:48,060 [INFO] 	Process 1 - batch 23899: mean_policy_losses: -111.557, mean_net_lifetime: 3802.4013, mean_mc_travel_dist: 1309.5224, mean_rewards: 226.0213, total_rewards: 2529.4621, mean_steps: 17.4600, mean_ecr: 0.0399 mean_entropies: 1.5752, took: 88.6285s
2022-10-09 07:32:55,921 [INFO] 	Process 5 - batch 22799: mean_policy_losses: -3.036, mean_net_lifetime: 4714.2854, mean_mc_travel_dist: 1696.9924, mean_rewards: 217.7936, total_rewards: 3061.7156, mean_steps: 23.0800, mean_ecr: 0.0396 mean_entropies: 1.5881, took: 118.4796s
2022-10-09 07:33:07,488 [INFO] 	Process 0 - batch 22599: mean_policy_losses: 9.790, mean_net_lifetime: 4289.4985, mean_mc_travel_dist: 1507.2294, mean_rewards: 220.3341, total_rewards: 2822.6280, mean_steps: 20.2300, mean_ecr: 0.0395 mean_entropies: 1.5995, took: 833.1794s
2022-10-09 07:33:16,638 [INFO] 	Process 6 - batch 23099: mean_policy_losses: -69.469, mean_net_lifetime: 4428.9559, mean_mc_travel_dist: 1647.4681, mean_rewards: 232.1836, total_rewards: 2829.6692, mean_steps: 20.4600, mean_ecr: 0.0409 mean_entropies: 1.5815, took: 108.1838s
2022-10-09 07:33:49,986 [INFO] 	Process 2 - batch 23299: mean_policy_losses: -143.649, mean_net_lifetime: 3887.7379, mean_mc_travel_dist: 1388.4980, mean_rewards: 217.0079, total_rewards: 2547.2989, mean_steps: 18.9000, mean_ecr: 0.0396 mean_entropies: 1.5841, took: 100.7677s
2022-10-09 07:34:14,739 [INFO] 	Process 3 - batch 23199: mean_policy_losses: -32.117, mean_net_lifetime: 4065.0049, mean_mc_travel_dist: 1406.2788, mean_rewards: 223.2728, total_rewards: 2691.3337, mean_steps: 19.1100, mean_ecr: 0.0388 mean_entropies: 1.6524, took: 101.6437s
2022-10-09 07:34:21,763 [INFO] 	Process 4 - batch 23199: mean_policy_losses: -33.456, mean_net_lifetime: 4288.9782, mean_mc_travel_dist: 1469.6162, mean_rewards: 224.4350, total_rewards: 2849.8012, mean_steps: 20.1000, mean_ecr: 0.0386 mean_entropies: 1.6548, took: 105.3013s
2022-10-09 07:34:38,266 [INFO] 	Process 1 - batch 23999: mean_policy_losses: -67.456, mean_net_lifetime: 4448.3536, mean_mc_travel_dist: 1599.5226, mean_rewards: 207.4216, total_rewards: 2890.8814, mean_steps: 22.2600, mean_ecr: 0.0397 mean_entropies: 1.5928, took: 110.2058s
2022-10-09 07:34:45,806 [INFO] 	Process 0 - batch 22699: mean_policy_losses: -235.172, mean_net_lifetime: 3992.5646, mean_mc_travel_dist: 1357.4829, mean_rewards: 232.5199, total_rewards: 2672.3294, mean_steps: 18.4000, mean_ecr: 0.0380 mean_entropies: 1.6206, took: 98.3180s
2022-10-09 07:34:54,481 [INFO] 	Process 5 - batch 22899: mean_policy_losses: -9.285, mean_net_lifetime: 4644.3707, mean_mc_travel_dist: 1641.8284, mean_rewards: 218.6755, total_rewards: 3037.8989, mean_steps: 23.0800, mean_ecr: 0.0390 mean_entropies: 1.5647, took: 118.5610s
2022-10-09 07:34:56,462 [INFO] 	Process 6 - batch 23199: mean_policy_losses: -169.162, mean_net_lifetime: 4024.4345, mean_mc_travel_dist: 1387.9934, mean_rewards: 220.8588, total_rewards: 2674.7531, mean_steps: 18.9400, mean_ecr: 0.0385 mean_entropies: 1.6221, took: 99.8242s
2022-10-09 07:35:37,468 [INFO] 	Process 2 - batch 23399: mean_policy_losses: -82.434, mean_net_lifetime: 4349.5152, mean_mc_travel_dist: 1547.0492, mean_rewards: 220.0607, total_rewards: 2843.0557, mean_steps: 20.7300, mean_ecr: 0.0391 mean_entropies: 1.5874, took: 107.4810s
2022-10-09 07:36:04,590 [INFO] 	Process 4 - batch 23299: mean_policy_losses: -125.632, mean_net_lifetime: 4185.3462, mean_mc_travel_dist: 1502.4093, mean_rewards: 215.1404, total_rewards: 2716.7192, mean_steps: 20.2300, mean_ecr: 0.0395 mean_entropies: 1.5544, took: 102.8281s
2022-10-09 07:36:06,391 [INFO] 	Process 3 - batch 23299: mean_policy_losses: -155.040, mean_net_lifetime: 4395.8482, mean_mc_travel_dist: 1605.3104, mean_rewards: 212.4839, total_rewards: 2832.4832, mean_steps: 22.2300, mean_ecr: 0.0394 mean_entropies: 1.5638, took: 111.6505s
2022-10-09 07:36:34,567 [INFO] 	Process 0 - batch 22799: mean_policy_losses: -36.695, mean_net_lifetime: 4392.1780, mean_mc_travel_dist: 1572.2543, mean_rewards: 217.7550, total_rewards: 2853.8689, mean_steps: 21.2400, mean_ecr: 0.0392 mean_entropies: 1.5703, took: 108.7599s
2022-10-09 07:36:39,613 [INFO] 	Process 5 - batch 22999: mean_policy_losses: -24.702, mean_net_lifetime: 4328.6742, mean_mc_travel_dist: 1529.2953, mean_rewards: 224.2612, total_rewards: 2835.8861, mean_steps: 20.4600, mean_ecr: 0.0392 mean_entropies: 1.6109, took: 105.1325s
2022-10-09 07:37:00,645 [INFO] 	Process 6 - batch 23299: mean_policy_losses: -100.780, mean_net_lifetime: 5010.3582, mean_mc_travel_dist: 1900.3992, mean_rewards: 208.8165, total_rewards: 3144.2068, mean_steps: 24.9200, mean_ecr: 0.0393 mean_entropies: 1.5659, took: 124.1825s
2022-10-09 07:37:08,396 [INFO] 	Process 2 - batch 23499: mean_policy_losses: -140.474, mean_net_lifetime: 3832.9779, mean_mc_travel_dist: 1302.7431, mean_rewards: 230.0841, total_rewards: 2572.3343, mean_steps: 17.3700, mean_ecr: 0.0408 mean_entropies: 1.4998, took: 90.9282s
2022-10-09 07:37:57,782 [INFO] 	Process 3 - batch 23399: mean_policy_losses: -127.198, mean_net_lifetime: 4453.8042, mean_mc_travel_dist: 1634.7861, mean_rewards: 216.9452, total_rewards: 2855.7721, mean_steps: 21.7200, mean_ecr: 0.0389 mean_entropies: 1.5944, took: 111.3928s
2022-10-09 07:37:59,069 [INFO] 	Process 4 - batch 23399: mean_policy_losses: -100.817, mean_net_lifetime: 4732.4670, mean_mc_travel_dist: 1744.4096, mean_rewards: 214.1692, total_rewards: 3027.6059, mean_steps: 22.8900, mean_ecr: 0.0392 mean_entropies: 1.6017, took: 114.4785s
2022-10-09 07:38:17,687 [INFO] 	Process 5 - batch 23099: mean_policy_losses: -60.488, mean_net_lifetime: 4109.7405, mean_mc_travel_dist: 1440.7352, mean_rewards: 226.7550, total_rewards: 2705.8462, mean_steps: 18.8100, mean_ecr: 0.0405 mean_entropies: 1.5766, took: 98.0742s
2022-10-09 07:38:25,281 [INFO] 	Process 0 - batch 22899: mean_policy_losses: -37.898, mean_net_lifetime: 4265.6975, mean_mc_travel_dist: 1515.9608, mean_rewards: 217.1937, total_rewards: 2793.7124, mean_steps: 21.3800, mean_ecr: 0.0393 mean_entropies: 1.5458, took: 110.7142s
2022-10-09 07:38:53,816 [INFO] 	Process 2 - batch 23599: mean_policy_losses: 1.946, mean_net_lifetime: 4203.4384, mean_mc_travel_dist: 1471.1307, mean_rewards: 211.6918, total_rewards: 2761.4329, mean_steps: 20.5000, mean_ecr: 0.0384 mean_entropies: 1.5660, took: 105.4200s
2022-10-09 07:39:04,483 [INFO] 	Process 6 - batch 23399: mean_policy_losses: -73.128, mean_net_lifetime: 5092.3176, mean_mc_travel_dist: 1896.6864, mean_rewards: 216.9771, total_rewards: 3229.6872, mean_steps: 24.9400, mean_ecr: 0.0395 mean_entropies: 1.6072, took: 123.8380s
2022-10-09 07:39:44,227 [INFO] 	Process 3 - batch 23499: mean_policy_losses: -128.488, mean_net_lifetime: 4359.8457, mean_mc_travel_dist: 1523.6896, mean_rewards: 223.2923, total_rewards: 2865.7095, mean_steps: 21.1500, mean_ecr: 0.0409 mean_entropies: 1.4834, took: 106.4445s
2022-10-09 07:39:45,532 [INFO] 	Process 4 - batch 23499: mean_policy_losses: -119.602, mean_net_lifetime: 4475.4620, mean_mc_travel_dist: 1567.7178, mean_rewards: 223.7100, total_rewards: 2942.5134, mean_steps: 21.0500, mean_ecr: 0.0409 mean_entropies: 1.4975, took: 106.4628s
2022-10-09 07:40:01,529 [INFO] 	Process 5 - batch 23199: mean_policy_losses: -98.544, mean_net_lifetime: 4228.3055, mean_mc_travel_dist: 1478.2258, mean_rewards: 220.6601, total_rewards: 2787.0246, mean_steps: 20.4300, mean_ecr: 0.0385 mean_entropies: 1.6100, took: 103.8412s
2022-10-09 07:40:07,902 [INFO] 	Process 0 - batch 22999: mean_policy_losses: -61.667, mean_net_lifetime: 4277.1749, mean_mc_travel_dist: 1481.3229, mean_rewards: 216.2901, total_rewards: 2829.9857, mean_steps: 20.1600, mean_ecr: 0.0395 mean_entropies: 1.5499, took: 102.6222s
2022-10-09 07:40:32,779 [INFO] 	Process 6 - batch 23499: mean_policy_losses: -191.133, mean_net_lifetime: 3727.4254, mean_mc_travel_dist: 1249.6822, mean_rewards: 231.0878, total_rewards: 2517.6724, mean_steps: 16.8700, mean_ecr: 0.0407 mean_entropies: 1.4812, took: 88.2969s
2022-10-09 07:40:55,224 [INFO] 	Process 2 - batch 23699: mean_policy_losses: -29.070, mean_net_lifetime: 4612.6139, mean_mc_travel_dist: 1647.4259, mean_rewards: 208.0144, total_rewards: 3003.7253, mean_steps: 23.8500, mean_ecr: 0.0391 mean_entropies: 1.5020, took: 121.4081s
2022-10-09 07:41:21,036 [INFO] 	Process 3 - batch 23599: mean_policy_losses: -69.361, mean_net_lifetime: 4117.5969, mean_mc_travel_dist: 1442.8271, mean_rewards: 219.4808, total_rewards: 2712.0184, mean_steps: 19.0700, mean_ecr: 0.0385 mean_entropies: 1.5839, took: 96.8092s
2022-10-09 07:41:31,433 [INFO] 	Process 4 - batch 23599: mean_policy_losses: -71.753, mean_net_lifetime: 4306.0297, mean_mc_travel_dist: 1546.5850, mean_rewards: 216.7554, total_rewards: 2797.7446, mean_steps: 20.7600, mean_ecr: 0.0388 mean_entropies: 1.5551, took: 105.9008s
2022-10-09 07:41:39,967 [INFO] 	Process 0 - batch 23099: mean_policy_losses: -108.552, mean_net_lifetime: 3891.6043, mean_mc_travel_dist: 1340.7421, mean_rewards: 228.6376, total_rewards: 2589.9001, mean_steps: 17.4700, mean_ecr: 0.0405 mean_entropies: 1.6053, took: 92.0646s
2022-10-09 07:41:49,085 [INFO] 	Process 5 - batch 23299: mean_policy_losses: -52.351, mean_net_lifetime: 4321.0831, mean_mc_travel_dist: 1544.6162, mean_rewards: 210.7530, total_rewards: 2817.8940, mean_steps: 21.0600, mean_ecr: 0.0392 mean_entropies: 1.5667, took: 107.5564s
2022-10-09 07:42:21,453 [INFO] 	Process 6 - batch 23599: mean_policy_losses: 11.211, mean_net_lifetime: 4346.8531, mean_mc_travel_dist: 1552.0301, mean_rewards: 210.3740, total_rewards: 2827.8439, mean_steps: 21.4300, mean_ecr: 0.0383 mean_entropies: 1.5453, took: 108.6731s
2022-10-09 07:42:42,885 [INFO] 	Process 2 - batch 23799: mean_policy_losses: -107.627, mean_net_lifetime: 4432.3505, mean_mc_travel_dist: 1665.2007, mean_rewards: 224.3286, total_rewards: 2798.5339, mean_steps: 21.0100, mean_ecr: 0.0393 mean_entropies: 1.5185, took: 107.6613s
2022-10-09 07:43:09,254 [INFO] 	Process 3 - batch 23699: mean_policy_losses: -38.169, mean_net_lifetime: 4226.5061, mean_mc_travel_dist: 1514.7439, mean_rewards: 211.5282, total_rewards: 2744.4239, mean_steps: 21.2300, mean_ecr: 0.0394 mean_entropies: 1.5041, took: 108.2176s
2022-10-09 07:43:17,493 [INFO] 	Process 0 - batch 23199: mean_policy_losses: -94.842, mean_net_lifetime: 4024.8931, mean_mc_travel_dist: 1377.8205, mean_rewards: 226.2542, total_rewards: 2680.6458, mean_steps: 18.7700, mean_ecr: 0.0383 mean_entropies: 1.6058, took: 97.5260s
2022-10-09 07:43:21,805 [INFO] 	Process 4 - batch 23699: mean_policy_losses: -90.840, mean_net_lifetime: 4346.5792, mean_mc_travel_dist: 1544.5149, mean_rewards: 213.0512, total_rewards: 2838.4381, mean_steps: 21.8700, mean_ecr: 0.0395 mean_entropies: 1.4938, took: 110.3731s
2022-10-09 07:43:35,673 [INFO] 	Process 5 - batch 23399: mean_policy_losses: -188.275, mean_net_lifetime: 4377.4111, mean_mc_travel_dist: 1587.7427, mean_rewards: 223.5210, total_rewards: 2819.2792, mean_steps: 21.0100, mean_ecr: 0.0396 mean_entropies: 1.5642, took: 106.5880s
2022-10-09 07:44:07,474 [INFO] 	Process 6 - batch 23699: mean_policy_losses: -72.028, mean_net_lifetime: 4386.8927, mean_mc_travel_dist: 1561.8879, mean_rewards: 215.3816, total_rewards: 2856.6096, mean_steps: 21.3300, mean_ecr: 0.0389 mean_entropies: 1.5295, took: 106.0220s
2022-10-09 07:44:20,666 [INFO] 	Process 2 - batch 23899: mean_policy_losses: -94.525, mean_net_lifetime: 4008.4632, mean_mc_travel_dist: 1410.8020, mean_rewards: 222.5820, total_rewards: 2628.9604, mean_steps: 19.0100, mean_ecr: 0.0396 mean_entropies: 1.5584, took: 97.7816s
2022-10-09 07:44:57,574 [INFO] 	Process 0 - batch 23299: mean_policy_losses: -162.827, mean_net_lifetime: 4041.9481, mean_mc_travel_dist: 1453.5608, mean_rewards: 214.8196, total_rewards: 2621.9612, mean_steps: 19.2700, mean_ecr: 0.0396 mean_entropies: 1.5684, took: 100.0805s
2022-10-09 07:45:01,107 [INFO] 	Process 5 - batch 23499: mean_policy_losses: -176.026, mean_net_lifetime: 3699.0632, mean_mc_travel_dist: 1255.1892, mean_rewards: 236.4534, total_rewards: 2482.9116, mean_steps: 16.1800, mean_ecr: 0.0407 mean_entropies: 1.5096, took: 85.4345s
2022-10-09 07:45:35,028 [INFO] 	Process 3 - batch 23799: mean_policy_losses: -32.242, mean_net_lifetime: 5954.0418, mean_mc_travel_dist: 2619.0293, mean_rewards: 229.5521, total_rewards: 3367.5170, mean_steps: 29.6600, mean_ecr: 0.0389 mean_entropies: 1.6082, took: 145.7729s
2022-10-09 07:45:46,677 [INFO] 	Process 6 - batch 23799: mean_policy_losses: -175.562, mean_net_lifetime: 4183.4291, mean_mc_travel_dist: 1580.5949, mean_rewards: 224.0988, total_rewards: 2644.1198, mean_steps: 19.3900, mean_ecr: 0.0393 mean_entropies: 1.5975, took: 99.2023s
2022-10-09 07:45:50,715 [INFO] 	Process 4 - batch 23799: mean_policy_losses: -18.709, mean_net_lifetime: 6230.0836, mean_mc_travel_dist: 2717.2939, mean_rewards: 228.5302, total_rewards: 3547.0219, mean_steps: 30.1000, mean_ecr: 0.0389 mean_entropies: 1.5998, took: 148.9101s
2022-10-09 07:45:57,921 [INFO] 	Process 2 - batch 23999: mean_policy_losses: -53.743, mean_net_lifetime: 4043.2079, mean_mc_travel_dist: 1439.9623, mean_rewards: 212.1830, total_rewards: 2641.2197, mean_steps: 18.9000, mean_ecr: 0.0399 mean_entropies: 1.6241, took: 97.2547s
2022-10-09 07:46:36,895 [INFO] 	Process 0 - batch 23399: mean_policy_losses: -104.449, mean_net_lifetime: 4172.9283, mean_mc_travel_dist: 1498.6390, mean_rewards: 221.3766, total_rewards: 2718.3218, mean_steps: 19.6700, mean_ecr: 0.0391 mean_entropies: 1.5940, took: 99.3213s
2022-10-09 07:46:49,246 [INFO] 	Process 5 - batch 23599: mean_policy_losses: -3.756, mean_net_lifetime: 4565.2304, mean_mc_travel_dist: 1626.4700, mean_rewards: 219.5676, total_rewards: 2974.5331, mean_steps: 21.5200, mean_ecr: 0.0385 mean_entropies: 1.5779, took: 108.1380s
2022-10-09 07:47:09,928 [INFO] 	Process 3 - batch 23899: mean_policy_losses: -124.163, mean_net_lifetime: 3984.2774, mean_mc_travel_dist: 1427.7187, mean_rewards: 214.2734, total_rewards: 2589.1354, mean_steps: 19.3400, mean_ecr: 0.0399 mean_entropies: 1.5640, took: 94.9013s
2022-10-09 07:47:18,845 [INFO] 	Process 6 - batch 23899: mean_policy_losses: -84.436, mean_net_lifetime: 3966.8705, mean_mc_travel_dist: 1384.8620, mean_rewards: 216.1760, total_rewards: 2609.4472, mean_steps: 18.9700, mean_ecr: 0.0401 mean_entropies: 1.5507, took: 92.1683s
2022-10-09 07:47:25,037 [INFO] 	Process 4 - batch 23899: mean_policy_losses: -31.468, mean_net_lifetime: 4057.2856, mean_mc_travel_dist: 1419.7613, mean_rewards: 214.5083, total_rewards: 2669.6765, mean_steps: 19.4500, mean_ecr: 0.0395 mean_entropies: 1.5550, took: 94.3200s
2022-10-09 07:48:16,268 [INFO] 	Process 0 - batch 23499: mean_policy_losses: -80.127, mean_net_lifetime: 4274.2278, mean_mc_travel_dist: 1451.5984, mean_rewards: 233.7715, total_rewards: 2860.5739, mean_steps: 19.7100, mean_ecr: 0.0410 mean_entropies: 1.5058, took: 99.3736s
2022-10-09 07:48:29,846 [INFO] 	Process 1 - batch 24099: mean_policy_losses: -203.456, mean_net_lifetime: 3883.0870, mean_mc_travel_dist: 1345.8167, mean_rewards: 223.9724, total_rewards: 2580.4979, mean_steps: 18.4100, mean_ecr: 0.0377 mean_entropies: 1.5784, took: 831.5809s
2022-10-09 07:48:35,801 [INFO] 	Process 5 - batch 23699: mean_policy_losses: -114.979, mean_net_lifetime: 4509.5798, mean_mc_travel_dist: 1603.9103, mean_rewards: 214.8643, total_rewards: 2944.9643, mean_steps: 22.2300, mean_ecr: 0.0393 mean_entropies: 1.5374, took: 106.5553s
2022-10-09 07:48:49,760 [INFO] 	Process 3 - batch 23999: mean_policy_losses: -72.547, mean_net_lifetime: 4195.8507, mean_mc_travel_dist: 1496.9098, mean_rewards: 210.5326, total_rewards: 2732.7632, mean_steps: 20.1000, mean_ecr: 0.0397 mean_entropies: 1.5858, took: 99.8321s
2022-10-09 07:49:09,143 [INFO] 	Process 4 - batch 23999: mean_policy_losses: 22.490, mean_net_lifetime: 4426.2341, mean_mc_travel_dist: 1561.9342, mean_rewards: 210.0144, total_rewards: 2898.3320, mean_steps: 21.1900, mean_ecr: 0.0395 mean_entropies: 1.6210, took: 104.1071s
2022-10-09 07:49:10,284 [INFO] 	Process 6 - batch 23999: mean_policy_losses: -19.130, mean_net_lifetime: 4525.9266, mean_mc_travel_dist: 1636.6974, mean_rewards: 209.0049, total_rewards: 2923.5278, mean_steps: 22.1600, mean_ecr: 0.0391 mean_entropies: 1.6216, took: 111.4385s
2022-10-09 07:49:49,629 [INFO] 	Process 0 - batch 23599: mean_policy_losses: -51.947, mean_net_lifetime: 4255.9938, mean_mc_travel_dist: 1473.4709, mean_rewards: 219.2034, total_rewards: 2816.8000, mean_steps: 19.9900, mean_ecr: 0.0387 mean_entropies: 1.6125, took: 93.3615s
2022-10-09 07:49:52,502 [INFO] 	Process 1 - batch 24199: mean_policy_losses: -201.332, mean_net_lifetime: 3716.7189, mean_mc_travel_dist: 1268.0701, mean_rewards: 216.7085, total_rewards: 2486.0006, mean_steps: 17.8100, mean_ecr: 0.0409 mean_entropies: 1.5699, took: 82.6552s
2022-10-09 07:50:51,086 [INFO] 	Process 5 - batch 23799: mean_policy_losses: -105.970, mean_net_lifetime: 5882.3427, mean_mc_travel_dist: 2509.7848, mean_rewards: 222.5661, total_rewards: 3403.6320, mean_steps: 30.5500, mean_ecr: 0.0389 mean_entropies: 1.5676, took: 135.2857s
2022-10-09 07:51:19,001 [INFO] 	Process 1 - batch 24299: mean_policy_losses: -62.595, mean_net_lifetime: 4032.2604, mean_mc_travel_dist: 1385.3525, mean_rewards: 230.1953, total_rewards: 2678.4514, mean_steps: 19.4200, mean_ecr: 0.0401 mean_entropies: 1.5712, took: 86.4993s
2022-10-09 07:51:28,109 [INFO] 	Process 0 - batch 23699: mean_policy_losses: -94.038, mean_net_lifetime: 4252.1557, mean_mc_travel_dist: 1498.9587, mean_rewards: 222.7934, total_rewards: 2783.0864, mean_steps: 21.1600, mean_ecr: 0.0391 mean_entropies: 1.5008, took: 98.4788s
2022-10-09 07:52:18,050 [INFO] 	Process 5 - batch 23899: mean_policy_losses: -46.610, mean_net_lifetime: 4019.3180, mean_mc_travel_dist: 1388.0245, mean_rewards: 219.0305, total_rewards: 2663.6655, mean_steps: 18.7700, mean_ecr: 0.0398 mean_entropies: 1.6191, took: 86.9639s
2022-10-09 07:52:44,213 [INFO] 	Process 1 - batch 24399: mean_policy_losses: -91.924, mean_net_lifetime: 4241.3296, mean_mc_travel_dist: 1490.9728, mean_rewards: 227.1895, total_rewards: 2788.9111, mean_steps: 19.3600, mean_ecr: 0.0384 mean_entropies: 1.6288, took: 85.2114s
2022-10-09 07:53:19,703 [INFO] 	Process 0 - batch 23799: mean_policy_losses: -140.443, mean_net_lifetime: 5061.2196, mean_mc_travel_dist: 2076.2613, mean_rewards: 226.5032, total_rewards: 3016.5553, mean_steps: 24.1100, mean_ecr: 0.0393 mean_entropies: 1.6084, took: 111.5944s
2022-10-09 07:54:02,452 [INFO] 	Process 5 - batch 23999: mean_policy_losses: -45.927, mean_net_lifetime: 4601.5553, mean_mc_travel_dist: 1633.8652, mean_rewards: 216.1418, total_rewards: 3011.5935, mean_steps: 22.0600, mean_ecr: 0.0398 mean_entropies: 1.6167, took: 104.4019s
2022-10-09 07:54:24,557 [INFO] 	Process 1 - batch 24499: mean_policy_losses: -94.617, mean_net_lifetime: 4786.5170, mean_mc_travel_dist: 1650.1326, mean_rewards: 223.0909, total_rewards: 3169.3146, mean_steps: 23.3800, mean_ecr: 0.0375 mean_entropies: 1.6599, took: 100.3447s
2022-10-09 07:54:48,324 [INFO] 	Process 0 - batch 23899: mean_policy_losses: -153.109, mean_net_lifetime: 3896.9164, mean_mc_travel_dist: 1335.4126, mean_rewards: 223.0463, total_rewards: 2593.8548, mean_steps: 18.5900, mean_ecr: 0.0397 mean_entropies: 1.5843, took: 88.6212s
2022-10-09 07:56:18,616 [INFO] 	Process 0 - batch 23999: mean_policy_losses: -3.925, mean_net_lifetime: 4270.3566, mean_mc_travel_dist: 1463.2950, mean_rewards: 220.0987, total_rewards: 2837.6601, mean_steps: 19.7200, mean_ecr: 0.0399 mean_entropies: 1.6040, took: 90.2915s
2022-10-09 07:56:21,346 [INFO] 	Process 1 - batch 24599: mean_policy_losses: -78.293, mean_net_lifetime: 5380.6346, mean_mc_travel_dist: 2087.3969, mean_rewards: 222.5468, total_rewards: 3322.3499, mean_steps: 29.1400, mean_ecr: 0.0392 mean_entropies: 1.5763, took: 116.7893s
2022-10-09 07:57:50,299 [INFO] 	Process 1 - batch 24699: mean_policy_losses: -136.916, mean_net_lifetime: 4507.8321, mean_mc_travel_dist: 1635.9559, mean_rewards: 222.1846, total_rewards: 2916.4173, mean_steps: 22.2500, mean_ecr: 0.0381 mean_entropies: 1.6714, took: 88.9532s
2022-10-09 07:59:09,902 [INFO] 	Process 2 - batch 24099: mean_policy_losses: -79.561, mean_net_lifetime: 4177.4946, mean_mc_travel_dist: 1478.1474, mean_rewards: 232.5217, total_rewards: 2754.2964, mean_steps: 19.0100, mean_ecr: 0.0378 mean_entropies: 1.6166, took: 791.9816s
2022-10-09 07:59:11,005 [INFO] 	Process 1 - batch 24799: mean_policy_losses: 32.420, mean_net_lifetime: 4250.7197, mean_mc_travel_dist: 1518.0788, mean_rewards: 218.9173, total_rewards: 2772.9626, mean_steps: 19.1200, mean_ecr: 0.0406 mean_entropies: 1.5787, took: 80.7056s
2022-10-09 08:00:27,074 [INFO] 	Process 1 - batch 24899: mean_policy_losses: -41.925, mean_net_lifetime: 4166.8886, mean_mc_travel_dist: 1428.0630, mean_rewards: 241.0951, total_rewards: 2767.7463, mean_steps: 18.0600, mean_ecr: 0.0401 mean_entropies: 1.5856, took: 76.0688s
2022-10-09 08:00:36,547 [INFO] 	Process 2 - batch 24199: mean_policy_losses: -116.321, mean_net_lifetime: 4187.1597, mean_mc_travel_dist: 1431.8848, mean_rewards: 227.8768, total_rewards: 2789.6718, mean_steps: 19.0100, mean_ecr: 0.0403 mean_entropies: 1.5780, took: 86.6443s
2022-10-09 08:02:03,465 [INFO] 	Process 2 - batch 24299: mean_policy_losses: -167.152, mean_net_lifetime: 3813.8431, mean_mc_travel_dist: 1317.1920, mean_rewards: 225.3037, total_rewards: 2533.9480, mean_steps: 17.5600, mean_ecr: 0.0408 mean_entropies: 1.5708, took: 86.9177s
2022-10-09 08:02:05,820 [INFO] 	Process 6 - batch 24099: mean_policy_losses: -157.040, mean_net_lifetime: 4085.3409, mean_mc_travel_dist: 1443.7146, mean_rewards: 230.1349, total_rewards: 2673.5948, mean_steps: 18.9400, mean_ecr: 0.0380 mean_entropies: 1.5784, took: 775.5356s
2022-10-09 08:02:15,371 [INFO] 	Process 1 - batch 24999: mean_policy_losses: -8.111, mean_net_lifetime: 5259.8010, mean_mc_travel_dist: 1855.9757, mean_rewards: 223.2807, total_rewards: 3441.0807, mean_steps: 24.3100, mean_ecr: 0.0391 mean_entropies: 1.6149, took: 108.2966s
2022-10-09 08:02:37,115 [INFO] 	Process 3 - batch 24099: mean_policy_losses: -112.997, mean_net_lifetime: 3889.3324, mean_mc_travel_dist: 1392.4514, mean_rewards: 220.5960, total_rewards: 2541.8698, mean_steps: 18.1100, mean_ecr: 0.0377 mean_entropies: 1.5999, took: 827.3546s
2022-10-09 08:02:55,692 [INFO] 	Process 4 - batch 24099: mean_policy_losses: -198.262, mean_net_lifetime: 3790.5626, mean_mc_travel_dist: 1356.1074, mean_rewards: 226.9147, total_rewards: 2480.4592, mean_steps: 17.9100, mean_ecr: 0.0379 mean_entropies: 1.5780, took: 826.5494s
2022-10-09 08:03:39,188 [INFO] 	Process 2 - batch 24399: mean_policy_losses: -46.230, mean_net_lifetime: 3987.8171, mean_mc_travel_dist: 1392.9467, mean_rewards: 219.1579, total_rewards: 2636.0749, mean_steps: 18.9800, mean_ecr: 0.0385 mean_entropies: 1.6040, took: 95.7237s
2022-10-09 08:03:41,720 [INFO] 	Process 6 - batch 24199: mean_policy_losses: -55.596, mean_net_lifetime: 4051.9243, mean_mc_travel_dist: 1404.3151, mean_rewards: 224.8764, total_rewards: 2688.2762, mean_steps: 19.2600, mean_ecr: 0.0408 mean_entropies: 1.5724, took: 95.9010s
2022-10-09 08:03:52,665 [INFO] 	Process 1 - batch 25099: mean_policy_losses: 19.376, mean_net_lifetime: 4294.3621, mean_mc_travel_dist: 1498.7768, mean_rewards: 211.6877, total_rewards: 2837.8758, mean_steps: 20.8400, mean_ecr: 0.0386 mean_entropies: 1.6297, took: 97.2951s
2022-10-09 08:04:09,644 [INFO] 	Process 3 - batch 24199: mean_policy_losses: -44.747, mean_net_lifetime: 3974.9235, mean_mc_travel_dist: 1350.6611, mean_rewards: 218.6147, total_rewards: 2660.7128, mean_steps: 18.7000, mean_ecr: 0.0410 mean_entropies: 1.5736, took: 92.5304s
2022-10-09 08:04:23,508 [INFO] 	Process 4 - batch 24199: mean_policy_losses: -80.004, mean_net_lifetime: 3730.0816, mean_mc_travel_dist: 1254.3247, mean_rewards: 217.3253, total_rewards: 2515.5912, mean_steps: 17.7600, mean_ecr: 0.0410 mean_entropies: 1.5819, took: 87.8166s
2022-10-09 08:05:24,836 [INFO] 	Process 2 - batch 24499: mean_policy_losses: -51.264, mean_net_lifetime: 4455.8858, mean_mc_travel_dist: 1551.3718, mean_rewards: 218.1169, total_rewards: 2946.0250, mean_steps: 21.1300, mean_ecr: 0.0377 mean_entropies: 1.6573, took: 105.6454s
2022-10-09 08:05:25,047 [INFO] 	Process 1 - batch 25199: mean_policy_losses: -74.687, mean_net_lifetime: 4207.9062, mean_mc_travel_dist: 1450.7226, mean_rewards: 222.8165, total_rewards: 2799.8361, mean_steps: 19.6000, mean_ecr: 0.0400 mean_entropies: 1.6100, took: 92.3806s
2022-10-09 08:06:04,156 [INFO] 	Process 6 - batch 24299: mean_policy_losses: -102.084, mean_net_lifetime: 5321.5079, mean_mc_travel_dist: 2010.0066, mean_rewards: 222.6564, total_rewards: 3353.2164, mean_steps: 29.3900, mean_ecr: 0.0406 mean_entropies: 1.5886, took: 142.4366s
2022-10-09 08:06:26,011 [INFO] 	Process 3 - batch 24299: mean_policy_losses: -216.127, mean_net_lifetime: 5197.2047, mean_mc_travel_dist: 1979.1424, mean_rewards: 224.1505, total_rewards: 3255.2525, mean_steps: 28.3100, mean_ecr: 0.0409 mean_entropies: 1.5665, took: 136.3668s
2022-10-09 08:06:58,462 [INFO] 	Process 4 - batch 24299: mean_policy_losses: -114.678, mean_net_lifetime: 5819.4415, mean_mc_travel_dist: 2248.3562, mean_rewards: 222.1135, total_rewards: 3602.7850, mean_steps: 32.0100, mean_ecr: 0.0407 mean_entropies: 1.5726, took: 154.9534s
2022-10-09 08:06:59,147 [INFO] 	Process 1 - batch 25299: mean_policy_losses: -36.006, mean_net_lifetime: 4303.9008, mean_mc_travel_dist: 1466.1516, mean_rewards: 227.4077, total_rewards: 2875.2496, mean_steps: 19.4000, mean_ecr: 0.0398 mean_entropies: 1.6070, took: 94.1007s
2022-10-09 08:07:13,468 [INFO] 	Process 5 - batch 24099: mean_policy_losses: -180.681, mean_net_lifetime: 3849.8319, mean_mc_travel_dist: 1369.7424, mean_rewards: 229.1692, total_rewards: 2523.9714, mean_steps: 17.8200, mean_ecr: 0.0378 mean_entropies: 1.5695, took: 791.0166s
2022-10-09 08:07:42,755 [INFO] 	Process 6 - batch 24399: mean_policy_losses: -54.681, mean_net_lifetime: 4158.0723, mean_mc_travel_dist: 1440.9415, mean_rewards: 223.4237, total_rewards: 2755.1872, mean_steps: 19.1300, mean_ecr: 0.0386 mean_entropies: 1.6076, took: 98.5978s
2022-10-09 08:07:55,829 [INFO] 	Process 2 - batch 24599: mean_policy_losses: -60.737, mean_net_lifetime: 5716.2494, mean_mc_travel_dist: 2332.5271, mean_rewards: 218.9643, total_rewards: 3414.2091, mean_steps: 30.7400, mean_ecr: 0.0395 mean_entropies: 1.5692, took: 150.9964s
2022-10-09 08:08:03,506 [INFO] 	Process 3 - batch 24399: mean_policy_losses: -100.911, mean_net_lifetime: 4049.6529, mean_mc_travel_dist: 1391.6541, mean_rewards: 225.8257, total_rewards: 2689.7763, mean_steps: 18.7300, mean_ecr: 0.0383 mean_entropies: 1.5957, took: 97.4937s
2022-10-09 08:08:38,700 [INFO] 	Process 1 - batch 25399: mean_policy_losses: -91.767, mean_net_lifetime: 4225.8046, mean_mc_travel_dist: 1460.4561, mean_rewards: 218.0240, total_rewards: 2799.2572, mean_steps: 20.3100, mean_ecr: 0.0398 mean_entropies: 1.5670, took: 99.5535s
2022-10-09 08:08:44,770 [INFO] 	Process 4 - batch 24399: mean_policy_losses: -99.079, mean_net_lifetime: 4372.0512, mean_mc_travel_dist: 1557.4298, mean_rewards: 224.7320, total_rewards: 2852.8506, mean_steps: 20.3600, mean_ecr: 0.0382 mean_entropies: 1.5853, took: 106.3075s
2022-10-09 08:08:49,394 [INFO] 	Process 5 - batch 24199: mean_policy_losses: -189.854, mean_net_lifetime: 3773.7480, mean_mc_travel_dist: 1296.9836, mean_rewards: 217.2777, total_rewards: 2514.9932, mean_steps: 17.9500, mean_ecr: 0.0409 mean_entropies: 1.6039, took: 95.9245s
2022-10-09 08:09:39,985 [INFO] 	Process 2 - batch 24699: mean_policy_losses: -80.584, mean_net_lifetime: 4177.3490, mean_mc_travel_dist: 1420.0058, mean_rewards: 231.1837, total_rewards: 2795.2272, mean_steps: 19.7100, mean_ecr: 0.0379 mean_entropies: 1.6480, took: 104.1542s
2022-10-09 08:09:42,630 [INFO] 	Process 6 - batch 24499: mean_policy_losses: -190.811, mean_net_lifetime: 4599.4722, mean_mc_travel_dist: 1622.0159, mean_rewards: 218.9310, total_rewards: 3016.6830, mean_steps: 22.7100, mean_ecr: 0.0376 mean_entropies: 1.6304, took: 119.8752s
2022-10-09 08:09:55,425 [INFO] 	Process 0 - batch 24099: mean_policy_losses: -116.302, mean_net_lifetime: 4427.2479, mean_mc_travel_dist: 1590.1130, mean_rewards: 220.7808, total_rewards: 2891.6869, mean_steps: 21.1000, mean_ecr: 0.0373 mean_entropies: 1.6092, took: 816.8084s
2022-10-09 08:09:59,445 [INFO] 	Process 3 - batch 24499: mean_policy_losses: -20.285, mean_net_lifetime: 4521.3671, mean_mc_travel_dist: 1568.7055, mean_rewards: 215.9821, total_rewards: 2987.1106, mean_steps: 22.0000, mean_ecr: 0.0378 mean_entropies: 1.6530, took: 115.9400s
2022-10-09 08:10:20,363 [INFO] 	Process 1 - batch 25499: mean_policy_losses: -34.448, mean_net_lifetime: 4401.7682, mean_mc_travel_dist: 1519.2424, mean_rewards: 225.7106, total_rewards: 2922.6577, mean_steps: 20.4700, mean_ecr: 0.0378 mean_entropies: 1.6706, took: 101.6627s
2022-10-09 08:10:26,209 [INFO] 	Process 5 - batch 24299: mean_policy_losses: -164.537, mean_net_lifetime: 3925.0778, mean_mc_travel_dist: 1362.0946, mean_rewards: 226.3088, total_rewards: 2597.9701, mean_steps: 18.1700, mean_ecr: 0.0405 mean_entropies: 1.5708, took: 96.8159s
2022-10-09 08:10:34,766 [INFO] 	Process 4 - batch 24499: mean_policy_losses: -73.283, mean_net_lifetime: 4438.8901, mean_mc_travel_dist: 1545.6231, mean_rewards: 216.2044, total_rewards: 2930.6490, mean_steps: 21.1000, mean_ecr: 0.0377 mean_entropies: 1.6476, took: 109.9961s
2022-10-09 08:11:11,207 [INFO] 	Process 2 - batch 24799: mean_policy_losses: -109.886, mean_net_lifetime: 3805.5412, mean_mc_travel_dist: 1335.7801, mean_rewards: 225.0221, total_rewards: 2503.5236, mean_steps: 17.2200, mean_ecr: 0.0404 mean_entropies: 1.5187, took: 91.2235s
2022-10-09 08:11:23,659 [INFO] 	Process 0 - batch 24199: mean_policy_losses: -145.317, mean_net_lifetime: 3677.1832, mean_mc_travel_dist: 1237.3295, mean_rewards: 228.4705, total_rewards: 2469.8941, mean_steps: 16.7200, mean_ecr: 0.0411 mean_entropies: 1.5315, took: 88.2352s
2022-10-09 08:11:33,428 [INFO] 	Process 6 - batch 24599: mean_policy_losses: -33.976, mean_net_lifetime: 4526.8973, mean_mc_travel_dist: 1676.6101, mean_rewards: 221.4007, total_rewards: 2884.6558, mean_steps: 21.3500, mean_ecr: 0.0394 mean_entropies: 1.5771, took: 110.7966s
2022-10-09 08:11:54,956 [INFO] 	Process 3 - batch 24599: mean_policy_losses: -39.289, mean_net_lifetime: 4582.5686, mean_mc_travel_dist: 1719.1947, mean_rewards: 218.0664, total_rewards: 2899.1772, mean_steps: 22.7400, mean_ecr: 0.0394 mean_entropies: 1.5419, took: 115.5104s
2022-10-09 08:12:04,096 [INFO] 	Process 5 - batch 24399: mean_policy_losses: -108.060, mean_net_lifetime: 3948.5564, mean_mc_travel_dist: 1368.5985, mean_rewards: 222.8773, total_rewards: 2622.7775, mean_steps: 19.0900, mean_ecr: 0.0382 mean_entropies: 1.5781, took: 97.8872s
2022-10-09 08:12:50,270 [INFO] 	Process 2 - batch 24899: mean_policy_losses: -17.568, mean_net_lifetime: 4149.0861, mean_mc_travel_dist: 1391.6486, mean_rewards: 230.3802, total_rewards: 2796.0946, mean_steps: 18.6600, mean_ecr: 0.0399 mean_entropies: 1.5530, took: 99.0627s
2022-10-09 08:13:04,085 [INFO] 	Process 0 - batch 24299: mean_policy_losses: -187.727, mean_net_lifetime: 4169.9283, mean_mc_travel_dist: 1441.9096, mean_rewards: 223.9683, total_rewards: 2759.2627, mean_steps: 19.5600, mean_ecr: 0.0406 mean_entropies: 1.5733, took: 100.4259s
2022-10-09 08:13:06,987 [INFO] 	Process 4 - batch 24599: mean_policy_losses: -9.544, mean_net_lifetime: 5978.5916, mean_mc_travel_dist: 2424.6570, mean_rewards: 218.7891, total_rewards: 3583.3002, mean_steps: 30.7800, mean_ecr: 0.0396 mean_entropies: 1.5609, took: 152.2220s
2022-10-09 08:13:18,964 [INFO] 	Process 6 - batch 24699: mean_policy_losses: -101.531, mean_net_lifetime: 4339.8708, mean_mc_travel_dist: 1481.1287, mean_rewards: 217.9983, total_rewards: 2889.2580, mean_steps: 20.6000, mean_ecr: 0.0379 mean_entropies: 1.6490, took: 105.5365s
2022-10-09 08:13:40,238 [INFO] 	Process 3 - batch 24699: mean_policy_losses: -109.629, mean_net_lifetime: 4218.0656, mean_mc_travel_dist: 1480.4376, mean_rewards: 218.1274, total_rewards: 2777.8059, mean_steps: 20.5200, mean_ecr: 0.0381 mean_entropies: 1.6525, took: 105.2818s
2022-10-09 08:13:50,724 [INFO] 	Process 5 - batch 24499: mean_policy_losses: -33.121, mean_net_lifetime: 4386.5431, mean_mc_travel_dist: 1492.0446, mean_rewards: 220.8577, total_rewards: 2935.3299, mean_steps: 20.6700, mean_ecr: 0.0375 mean_entropies: 1.6378, took: 106.6273s
2022-10-09 08:14:50,254 [INFO] 	Process 4 - batch 24699: mean_policy_losses: -122.265, mean_net_lifetime: 4255.4007, mean_mc_travel_dist: 1450.9854, mean_rewards: 224.1782, total_rewards: 2838.7703, mean_steps: 19.9700, mean_ecr: 0.0379 mean_entropies: 1.6638, took: 103.2660s
2022-10-09 08:14:53,893 [INFO] 	Process 2 - batch 24999: mean_policy_losses: -40.142, mean_net_lifetime: 5128.7907, mean_mc_travel_dist: 1850.5621, mean_rewards: 217.0996, total_rewards: 3322.5131, mean_steps: 23.9900, mean_ecr: 0.0390 mean_entropies: 1.6346, took: 123.6217s
2022-10-09 08:14:55,181 [INFO] 	Process 0 - batch 24399: mean_policy_losses: -43.618, mean_net_lifetime: 4522.0962, mean_mc_travel_dist: 1671.0217, mean_rewards: 217.7492, total_rewards: 2885.3299, mean_steps: 21.4300, mean_ecr: 0.0381 mean_entropies: 1.6054, took: 111.0963s
2022-10-09 08:15:03,679 [INFO] 	Process 6 - batch 24799: mean_policy_losses: -18.979, mean_net_lifetime: 4472.5507, mean_mc_travel_dist: 1602.2953, mean_rewards: 219.9908, total_rewards: 2909.7105, mean_steps: 20.7300, mean_ecr: 0.0404 mean_entropies: 1.5409, took: 104.7158s
2022-10-09 08:15:15,122 [INFO] 	Process 3 - batch 24799: mean_policy_losses: -160.862, mean_net_lifetime: 3985.4091, mean_mc_travel_dist: 1393.7022, mean_rewards: 218.6397, total_rewards: 2630.5163, mean_steps: 18.4900, mean_ecr: 0.0402 mean_entropies: 1.5285, took: 94.8839s
2022-10-09 08:15:40,475 [INFO] 	Process 5 - batch 24599: mean_policy_losses: -152.583, mean_net_lifetime: 4423.7951, mean_mc_travel_dist: 1659.2262, mean_rewards: 221.2834, total_rewards: 2790.5957, mean_steps: 21.8300, mean_ecr: 0.0396 mean_entropies: 1.5696, took: 109.7517s
2022-10-09 08:16:22,166 [INFO] 	Process 4 - batch 24799: mean_policy_losses: -146.301, mean_net_lifetime: 3975.8958, mean_mc_travel_dist: 1404.8620, mean_rewards: 229.0587, total_rewards: 2617.1153, mean_steps: 17.7900, mean_ecr: 0.0405 mean_entropies: 1.5308, took: 91.9120s
2022-10-09 08:16:34,580 [INFO] 	Process 2 - batch 25099: mean_policy_losses: -49.213, mean_net_lifetime: 4063.2654, mean_mc_travel_dist: 1376.4359, mean_rewards: 218.1017, total_rewards: 2722.6014, mean_steps: 19.4000, mean_ecr: 0.0388 mean_entropies: 1.6276, took: 100.6879s
2022-10-09 08:16:37,070 [INFO] 	Process 0 - batch 24499: mean_policy_losses: -92.933, mean_net_lifetime: 4278.2958, mean_mc_travel_dist: 1477.5435, mean_rewards: 220.6829, total_rewards: 2849.9213, mean_steps: 19.7900, mean_ecr: 0.0378 mean_entropies: 1.6451, took: 101.8887s
2022-10-09 08:16:41,343 [INFO] 	Process 6 - batch 24899: mean_policy_losses: -54.040, mean_net_lifetime: 4256.4498, mean_mc_travel_dist: 1447.2894, mean_rewards: 229.1579, total_rewards: 2843.8458, mean_steps: 19.0000, mean_ecr: 0.0395 mean_entropies: 1.5588, took: 97.6632s
2022-10-09 08:16:49,291 [INFO] 	Process 3 - batch 24899: mean_policy_losses: -37.367, mean_net_lifetime: 4157.8039, mean_mc_travel_dist: 1453.0247, mean_rewards: 227.2798, total_rewards: 2745.0438, mean_steps: 18.6900, mean_ecr: 0.0399 mean_entropies: 1.5480, took: 94.1696s
2022-10-09 08:17:30,443 [INFO] 	Process 5 - batch 24699: mean_policy_losses: -101.252, mean_net_lifetime: 4379.4765, mean_mc_travel_dist: 1539.9206, mean_rewards: 224.9087, total_rewards: 2882.7002, mean_steps: 21.2300, mean_ecr: 0.0379 mean_entropies: 1.6145, took: 109.9679s
2022-10-09 08:17:55,663 [INFO] 	Process 4 - batch 24899: mean_policy_losses: -0.973, mean_net_lifetime: 4113.8319, mean_mc_travel_dist: 1361.4869, mean_rewards: 233.4115, total_rewards: 2787.3009, mean_steps: 18.3200, mean_ecr: 0.0396 mean_entropies: 1.5284, took: 93.4965s
2022-10-09 08:18:15,415 [INFO] 	Process 2 - batch 25199: mean_policy_losses: -151.330, mean_net_lifetime: 4146.7043, mean_mc_travel_dist: 1435.0035, mean_rewards: 218.6876, total_rewards: 2745.6348, mean_steps: 19.5700, mean_ecr: 0.0397 mean_entropies: 1.5753, took: 100.8343s
2022-10-09 08:18:15,667 [INFO] 	Process 0 - batch 24599: mean_policy_losses: -87.185, mean_net_lifetime: 4108.0977, mean_mc_travel_dist: 1435.5921, mean_rewards: 226.0282, total_rewards: 2707.4626, mean_steps: 19.0800, mean_ecr: 0.0395 mean_entropies: 1.5405, took: 98.5969s
2022-10-09 08:18:31,615 [INFO] 	Process 6 - batch 24999: mean_policy_losses: -103.723, mean_net_lifetime: 4636.5860, mean_mc_travel_dist: 1648.0613, mean_rewards: 218.1219, total_rewards: 3027.5613, mean_steps: 21.7300, mean_ecr: 0.0396 mean_entropies: 1.5953, took: 110.2729s
2022-10-09 08:18:48,565 [INFO] 	Process 3 - batch 24999: mean_policy_losses: -106.127, mean_net_lifetime: 4770.5024, mean_mc_travel_dist: 1734.7660, mean_rewards: 214.3139, total_rewards: 3072.3063, mean_steps: 22.9200, mean_ecr: 0.0396 mean_entropies: 1.5772, took: 119.2739s
2022-10-09 08:19:11,891 [INFO] 	Process 5 - batch 24799: mean_policy_losses: -82.540, mean_net_lifetime: 4132.9407, mean_mc_travel_dist: 1436.0729, mean_rewards: 217.4031, total_rewards: 2729.0558, mean_steps: 19.3100, mean_ecr: 0.0406 mean_entropies: 1.5050, took: 101.4479s
2022-10-09 08:20:03,460 [INFO] 	Process 0 - batch 24699: mean_policy_losses: -92.622, mean_net_lifetime: 4514.2466, mean_mc_travel_dist: 1577.5566, mean_rewards: 224.8687, total_rewards: 2969.7485, mean_steps: 21.3700, mean_ecr: 0.0378 mean_entropies: 1.6472, took: 107.7925s
2022-10-09 08:20:06,695 [INFO] 	Process 2 - batch 25299: mean_policy_losses: -42.401, mean_net_lifetime: 4772.1107, mean_mc_travel_dist: 1694.0266, mean_rewards: 230.4412, total_rewards: 3109.5444, mean_steps: 21.9100, mean_ecr: 0.0398 mean_entropies: 1.5986, took: 111.2806s
2022-10-09 08:20:11,443 [INFO] 	Process 6 - batch 25099: mean_policy_losses: -165.541, mean_net_lifetime: 4004.7819, mean_mc_travel_dist: 1390.3123, mean_rewards: 216.6945, total_rewards: 2660.8587, mean_steps: 19.3400, mean_ecr: 0.0386 mean_entropies: 1.6175, took: 99.8277s
2022-10-09 08:20:15,404 [INFO] 	Process 4 - batch 24999: mean_policy_losses: -137.492, mean_net_lifetime: 5816.0766, mean_mc_travel_dist: 2118.2903, mean_rewards: 223.5666, total_rewards: 3723.8620, mean_steps: 28.3900, mean_ecr: 0.0394 mean_entropies: 1.5822, took: 139.7420s
2022-10-09 08:20:31,811 [INFO] 	Process 3 - batch 25099: mean_policy_losses: -37.556, mean_net_lifetime: 4200.6913, mean_mc_travel_dist: 1419.9950, mean_rewards: 217.4002, total_rewards: 2817.4900, mean_steps: 20.1700, mean_ecr: 0.0387 mean_entropies: 1.6135, took: 103.2448s
2022-10-09 08:20:44,572 [INFO] 	Process 5 - batch 24899: mean_policy_losses: -96.373, mean_net_lifetime: 4098.4077, mean_mc_travel_dist: 1409.9562, mean_rewards: 236.2920, total_rewards: 2726.9034, mean_steps: 17.8100, mean_ecr: 0.0396 mean_entropies: 1.5275, took: 92.6802s
2022-10-09 08:21:41,044 [INFO] 	Process 0 - batch 24799: mean_policy_losses: -136.655, mean_net_lifetime: 4006.1319, mean_mc_travel_dist: 1409.5882, mean_rewards: 222.4239, total_rewards: 2629.6244, mean_steps: 18.5300, mean_ecr: 0.0405 mean_entropies: 1.5090, took: 97.5840s
2022-10-09 08:21:44,781 [INFO] 	Process 2 - batch 25399: mean_policy_losses: -83.727, mean_net_lifetime: 4221.4523, mean_mc_travel_dist: 1431.8624, mean_rewards: 224.9996, total_rewards: 2822.8372, mean_steps: 19.3200, mean_ecr: 0.0396 mean_entropies: 1.5167, took: 98.0865s
2022-10-09 08:21:57,166 [INFO] 	Process 4 - batch 25099: mean_policy_losses: -106.165, mean_net_lifetime: 4098.3356, mean_mc_travel_dist: 1406.4545, mean_rewards: 211.2280, total_rewards: 2729.9886, mean_steps: 19.9400, mean_ecr: 0.0387 mean_entropies: 1.6159, took: 101.7607s
2022-10-09 08:21:59,438 [INFO] 	Process 6 - batch 25199: mean_policy_losses: -85.869, mean_net_lifetime: 4417.5457, mean_mc_travel_dist: 1561.6941, mean_rewards: 216.7312, total_rewards: 2893.9747, mean_steps: 21.0700, mean_ecr: 0.0394 mean_entropies: 1.6060, took: 107.9950s
2022-10-09 08:22:11,510 [INFO] 	Process 3 - batch 25199: mean_policy_losses: -16.648, mean_net_lifetime: 4284.2387, mean_mc_travel_dist: 1466.2266, mean_rewards: 222.8494, total_rewards: 2846.3821, mean_steps: 19.7900, mean_ecr: 0.0396 mean_entropies: 1.5730, took: 99.7004s
2022-10-09 08:22:40,821 [INFO] 	Process 5 - batch 24999: mean_policy_losses: -81.473, mean_net_lifetime: 4903.7665, mean_mc_travel_dist: 1721.4982, mean_rewards: 218.0527, total_rewards: 3227.3645, mean_steps: 23.0100, mean_ecr: 0.0396 mean_entropies: 1.5986, took: 116.2503s
2022-10-09 08:23:15,530 [INFO] 	Process 0 - batch 24899: mean_policy_losses: -159.782, mean_net_lifetime: 3935.2210, mean_mc_travel_dist: 1337.5977, mean_rewards: 228.1607, total_rewards: 2634.2491, mean_steps: 17.9700, mean_ecr: 0.0403 mean_entropies: 1.5217, took: 94.4859s
2022-10-09 08:23:27,083 [INFO] 	Process 2 - batch 25499: mean_policy_losses: -123.863, mean_net_lifetime: 4252.2829, mean_mc_travel_dist: 1451.8349, mean_rewards: 222.7155, total_rewards: 2843.4318, mean_steps: 19.9800, mean_ecr: 0.0377 mean_entropies: 1.6219, took: 102.3010s
2022-10-09 08:23:34,635 [INFO] 	Process 6 - batch 25299: mean_policy_losses: -144.867, mean_net_lifetime: 4159.1183, mean_mc_travel_dist: 1429.8634, mean_rewards: 238.3735, total_rewards: 2764.7564, mean_steps: 17.9500, mean_ecr: 0.0402 mean_entropies: 1.5950, took: 95.1968s
2022-10-09 08:23:41,530 [INFO] 	Process 4 - batch 25199: mean_policy_losses: -113.278, mean_net_lifetime: 4295.2996, mean_mc_travel_dist: 1505.2360, mean_rewards: 223.1464, total_rewards: 2833.4646, mean_steps: 20.0700, mean_ecr: 0.0393 mean_entropies: 1.6102, took: 104.3654s
2022-10-09 08:23:51,949 [INFO] 	Process 3 - batch 25299: mean_policy_losses: -74.284, mean_net_lifetime: 4468.4522, mean_mc_travel_dist: 1516.7737, mean_rewards: 230.1248, total_rewards: 2986.1208, mean_steps: 19.6900, mean_ecr: 0.0399 mean_entropies: 1.5636, took: 100.4371s
2022-10-09 08:24:27,201 [INFO] 	Process 5 - batch 25099: mean_policy_losses: -180.713, mean_net_lifetime: 4124.7149, mean_mc_travel_dist: 1424.1523, mean_rewards: 215.0720, total_rewards: 2733.4288, mean_steps: 20.5000, mean_ecr: 0.0386 mean_entropies: 1.6048, took: 106.3797s
2022-10-09 08:25:02,747 [INFO] 	Process 1 - batch 25599: mean_policy_losses: -146.902, mean_net_lifetime: 4727.7041, mean_mc_travel_dist: 1723.8818, mean_rewards: 213.6277, total_rewards: 3037.6837, mean_steps: 23.7100, mean_ecr: 0.0393 mean_entropies: 1.5439, took: 882.3834s
2022-10-09 08:25:23,875 [INFO] 	Process 4 - batch 25299: mean_policy_losses: -63.127, mean_net_lifetime: 4520.6204, mean_mc_travel_dist: 1544.8886, mean_rewards: 233.4493, total_rewards: 3009.8156, mean_steps: 20.0500, mean_ecr: 0.0399 mean_entropies: 1.5876, took: 102.3449s
2022-10-09 08:25:25,330 [INFO] 	Process 6 - batch 25399: mean_policy_losses: -112.640, mean_net_lifetime: 4449.1120, mean_mc_travel_dist: 1545.4627, mean_rewards: 222.1163, total_rewards: 2932.3911, mean_steps: 21.7000, mean_ecr: 0.0394 mean_entropies: 1.5154, took: 110.6957s
2022-10-09 08:25:35,492 [INFO] 	Process 0 - batch 24999: mean_policy_losses: -112.158, mean_net_lifetime: 5788.2140, mean_mc_travel_dist: 2240.7888, mean_rewards: 217.3784, total_rewards: 3592.6877, mean_steps: 27.9600, mean_ecr: 0.0391 mean_entropies: 1.6004, took: 139.9598s
2022-10-09 08:25:38,171 [INFO] 	Process 3 - batch 25399: mean_policy_losses: -131.640, mean_net_lifetime: 4325.5877, mean_mc_travel_dist: 1506.5281, mean_rewards: 221.5371, total_rewards: 2847.7776, mean_steps: 21.0500, mean_ecr: 0.0396 mean_entropies: 1.5129, took: 106.2238s
2022-10-09 08:26:09,922 [INFO] 	Process 5 - batch 25199: mean_policy_losses: -21.956, mean_net_lifetime: 4301.8159, mean_mc_travel_dist: 1485.1668, mean_rewards: 224.8794, total_rewards: 2857.4468, mean_steps: 20.0500, mean_ecr: 0.0396 mean_entropies: 1.5654, took: 102.7205s
2022-10-09 08:26:36,352 [INFO] 	Process 1 - batch 25699: mean_policy_losses: -79.837, mean_net_lifetime: 4188.0542, mean_mc_travel_dist: 1453.8278, mean_rewards: 223.7335, total_rewards: 2768.4047, mean_steps: 19.1500, mean_ecr: 0.0376 mean_entropies: 1.6245, took: 93.6048s
2022-10-09 08:27:09,764 [INFO] 	Process 6 - batch 25499: mean_policy_losses: -73.199, mean_net_lifetime: 4221.4874, mean_mc_travel_dist: 1480.9821, mean_rewards: 219.8677, total_rewards: 2784.3666, mean_steps: 20.1700, mean_ecr: 0.0378 mean_entropies: 1.6067, took: 104.4323s
2022-10-09 08:27:11,718 [INFO] 	Process 4 - batch 25399: mean_policy_losses: -89.874, mean_net_lifetime: 4391.4962, mean_mc_travel_dist: 1524.7923, mean_rewards: 223.6740, total_rewards: 2906.1190, mean_steps: 21.3700, mean_ecr: 0.0393 mean_entropies: 1.5031, took: 107.8432s
2022-10-09 08:27:16,656 [INFO] 	Process 3 - batch 25499: mean_policy_losses: -138.851, mean_net_lifetime: 4189.1441, mean_mc_travel_dist: 1460.9848, mean_rewards: 221.8423, total_rewards: 2756.6847, mean_steps: 19.3400, mean_ecr: 0.0380 mean_entropies: 1.6139, took: 98.4858s
2022-10-09 08:27:24,982 [INFO] 	Process 0 - batch 25099: mean_policy_losses: -43.177, mean_net_lifetime: 4326.3577, mean_mc_travel_dist: 1471.1494, mean_rewards: 210.0682, total_rewards: 2896.1471, mean_steps: 21.5200, mean_ecr: 0.0386 mean_entropies: 1.6220, took: 109.4925s
2022-10-09 08:27:52,517 [INFO] 	Process 5 - batch 25299: mean_policy_losses: -71.417, mean_net_lifetime: 4477.3630, mean_mc_travel_dist: 1552.1501, mean_rewards: 229.8758, total_rewards: 2961.7335, mean_steps: 20.3300, mean_ecr: 0.0397 mean_entropies: 1.5462, took: 102.5944s
2022-10-09 08:28:06,824 [INFO] 	Process 1 - batch 25799: mean_policy_losses: -154.507, mean_net_lifetime: 4111.6237, mean_mc_travel_dist: 1388.2347, mean_rewards: 227.7338, total_rewards: 2757.0362, mean_steps: 19.2400, mean_ecr: 0.0403 mean_entropies: 1.5558, took: 90.4728s
2022-10-09 08:28:55,065 [INFO] 	Process 4 - batch 25499: mean_policy_losses: -70.306, mean_net_lifetime: 4530.7609, mean_mc_travel_dist: 1584.4862, mean_rewards: 217.9915, total_rewards: 2977.8860, mean_steps: 21.3500, mean_ecr: 0.0379 mean_entropies: 1.6207, took: 103.3469s
2022-10-09 08:29:00,353 [INFO] 	Process 0 - batch 25199: mean_policy_losses: -76.485, mean_net_lifetime: 4076.3896, mean_mc_travel_dist: 1399.4184, mean_rewards: 219.4766, total_rewards: 2705.2319, mean_steps: 19.4100, mean_ecr: 0.0400 mean_entropies: 1.5353, took: 95.3719s
2022-10-09 08:29:25,267 [INFO] 	Process 5 - batch 25399: mean_policy_losses: -85.555, mean_net_lifetime: 4122.5055, mean_mc_travel_dist: 1390.9459, mean_rewards: 226.7119, total_rewards: 2760.4927, mean_steps: 19.2600, mean_ecr: 0.0396 mean_entropies: 1.4899, took: 92.7500s
2022-10-09 08:29:28,711 [INFO] 	Process 1 - batch 25899: mean_policy_losses: -150.983, mean_net_lifetime: 3968.3927, mean_mc_travel_dist: 1304.7027, mean_rewards: 229.8199, total_rewards: 2694.8142, mean_steps: 18.0900, mean_ecr: 0.0388 mean_entropies: 1.5495, took: 81.8865s
2022-10-09 08:30:33,028 [INFO] 	Process 0 - batch 25299: mean_policy_losses: -66.769, mean_net_lifetime: 4329.8239, mean_mc_travel_dist: 1516.1267, mean_rewards: 225.7207, total_rewards: 2850.4733, mean_steps: 19.8900, mean_ecr: 0.0396 mean_entropies: 1.5620, took: 92.6743s
2022-10-09 08:30:53,612 [INFO] 	Process 1 - batch 25999: mean_policy_losses: -89.971, mean_net_lifetime: 4222.0315, mean_mc_travel_dist: 1424.4253, mean_rewards: 224.9615, total_rewards: 2833.9096, mean_steps: 19.3800, mean_ecr: 0.0409 mean_entropies: 1.5328, took: 84.9014s
2022-10-09 08:31:04,157 [INFO] 	Process 5 - batch 25499: mean_policy_losses: -145.059, mean_net_lifetime: 4381.0337, mean_mc_travel_dist: 1529.9368, mean_rewards: 225.1932, total_rewards: 2897.9129, mean_steps: 20.7700, mean_ecr: 0.0377 mean_entropies: 1.6157, took: 98.8905s
2022-10-09 08:32:03,954 [INFO] 	Process 0 - batch 25399: mean_policy_losses: -184.593, mean_net_lifetime: 4243.6878, mean_mc_travel_dist: 1450.1727, mean_rewards: 226.4271, total_rewards: 2833.9269, mean_steps: 20.2100, mean_ecr: 0.0396 mean_entropies: 1.4624, took: 90.9249s
2022-10-09 08:32:29,579 [INFO] 	Process 1 - batch 26099: mean_policy_losses: -111.875, mean_net_lifetime: 4545.1399, mean_mc_travel_dist: 1618.7826, mean_rewards: 205.0645, total_rewards: 2965.3423, mean_steps: 23.4300, mean_ecr: 0.0388 mean_entropies: 1.5307, took: 95.9668s
2022-10-09 08:33:34,595 [INFO] 	Process 0 - batch 25499: mean_policy_losses: -154.273, mean_net_lifetime: 4167.3003, mean_mc_travel_dist: 1476.5571, mean_rewards: 221.8695, total_rewards: 2731.0872, mean_steps: 19.6800, mean_ecr: 0.0379 mean_entropies: 1.5826, took: 90.6420s
2022-10-09 08:33:52,048 [INFO] 	Process 1 - batch 26199: mean_policy_losses: -99.877, mean_net_lifetime: 4349.4982, mean_mc_travel_dist: 1500.4126, mean_rewards: 228.4445, total_rewards: 2880.2020, mean_steps: 19.8100, mean_ecr: 0.0386 mean_entropies: 1.5462, took: 82.4694s
2022-10-09 08:35:16,281 [INFO] 	Process 1 - batch 26299: mean_policy_losses: -60.606, mean_net_lifetime: 4434.3684, mean_mc_travel_dist: 1577.5726, mean_rewards: 219.7678, total_rewards: 2899.1962, mean_steps: 21.1900, mean_ecr: 0.0382 mean_entropies: 1.6497, took: 84.2332s
2022-10-09 08:36:47,363 [INFO] 	Process 1 - batch 26399: mean_policy_losses: -126.676, mean_net_lifetime: 4742.3972, mean_mc_travel_dist: 1623.8451, mean_rewards: 224.2147, total_rewards: 3154.9014, mean_steps: 22.1500, mean_ecr: 0.0400 mean_entropies: 1.5616, took: 91.0810s
2022-10-09 08:37:14,652 [INFO] 	Process 2 - batch 25599: mean_policy_losses: -112.915, mean_net_lifetime: 4377.5411, mean_mc_travel_dist: 1551.6384, mean_rewards: 217.9575, total_rewards: 2866.2461, mean_steps: 21.5000, mean_ecr: 0.0391 mean_entropies: 1.5954, took: 827.5693s
2022-10-09 08:38:21,351 [INFO] 	Process 1 - batch 26499: mean_policy_losses: -123.309, mean_net_lifetime: 4875.2617, mean_mc_travel_dist: 1733.7333, mean_rewards: 219.9802, total_rewards: 3186.2296, mean_steps: 22.7400, mean_ecr: 0.0394 mean_entropies: 1.6192, took: 93.9883s
2022-10-09 08:39:09,208 [INFO] 	Process 2 - batch 25699: mean_policy_losses: -102.624, mean_net_lifetime: 5385.5415, mean_mc_travel_dist: 1994.5482, mean_rewards: 228.1702, total_rewards: 3425.7455, mean_steps: 26.4900, mean_ecr: 0.0375 mean_entropies: 1.6924, took: 114.5557s
2022-10-09 08:39:57,714 [INFO] 	Process 1 - batch 26599: mean_policy_losses: -133.484, mean_net_lifetime: 4742.2861, mean_mc_travel_dist: 1703.5060, mean_rewards: 216.6629, total_rewards: 3063.6474, mean_steps: 22.3200, mean_ecr: 0.0387 mean_entropies: 1.6317, took: 96.3634s
2022-10-09 08:40:33,676 [INFO] 	Process 6 - batch 25599: mean_policy_losses: -161.164, mean_net_lifetime: 4310.0763, mean_mc_travel_dist: 1490.1797, mean_rewards: 223.5242, total_rewards: 2846.3617, mean_steps: 20.3200, mean_ecr: 0.0395 mean_entropies: 1.5890, took: 803.9131s
2022-10-09 08:41:00,382 [INFO] 	Process 2 - batch 25799: mean_policy_losses: -81.264, mean_net_lifetime: 4802.8089, mean_mc_travel_dist: 1750.4020, mean_rewards: 226.3246, total_rewards: 3080.0811, mean_steps: 22.9400, mean_ecr: 0.0405 mean_entropies: 1.6305, took: 111.1737s
2022-10-09 08:41:21,099 [INFO] 	Process 3 - batch 25599: mean_policy_losses: -51.674, mean_net_lifetime: 4618.8313, mean_mc_travel_dist: 1608.6655, mean_rewards: 225.0810, total_rewards: 3041.3079, mean_steps: 21.6900, mean_ecr: 0.0391 mean_entropies: 1.5960, took: 844.4416s
2022-10-09 08:41:38,235 [INFO] 	Process 1 - batch 26699: mean_policy_losses: -17.544, mean_net_lifetime: 4522.9095, mean_mc_travel_dist: 1602.2713, mean_rewards: 208.6646, total_rewards: 2962.3195, mean_steps: 21.9300, mean_ecr: 0.0391 mean_entropies: 1.6056, took: 100.5209s
2022-10-09 08:42:16,878 [INFO] 	Process 6 - batch 25699: mean_policy_losses: -33.698, mean_net_lifetime: 4616.7438, mean_mc_travel_dist: 1661.7152, mean_rewards: 222.6750, total_rewards: 2995.7610, mean_steps: 21.1800, mean_ecr: 0.0370 mean_entropies: 1.6629, took: 103.2022s
2022-10-09 08:42:33,261 [INFO] 	Process 4 - batch 25599: mean_policy_losses: -58.450, mean_net_lifetime: 4358.8943, mean_mc_travel_dist: 1528.5188, mean_rewards: 218.4592, total_rewards: 2870.9133, mean_steps: 20.7300, mean_ecr: 0.0392 mean_entropies: 1.5899, took: 818.1961s
2022-10-09 08:42:35,886 [INFO] 	Process 2 - batch 25899: mean_policy_losses: -80.963, mean_net_lifetime: 4184.3893, mean_mc_travel_dist: 1414.5702, mean_rewards: 232.0522, total_rewards: 2810.4488, mean_steps: 18.8100, mean_ecr: 0.0388 mean_entropies: 1.5824, took: 95.5049s
2022-10-09 08:43:11,394 [INFO] 	Process 3 - batch 25699: mean_policy_losses: -47.177, mean_net_lifetime: 4757.5417, mean_mc_travel_dist: 1722.8903, mean_rewards: 217.0504, total_rewards: 3075.8412, mean_steps: 22.6400, mean_ecr: 0.0373 mean_entropies: 1.6601, took: 110.2953s
2022-10-09 08:43:21,077 [INFO] 	Process 1 - batch 26799: mean_policy_losses: -51.512, mean_net_lifetime: 4476.1031, mean_mc_travel_dist: 1591.5195, mean_rewards: 216.4843, total_rewards: 2922.7309, mean_steps: 21.6300, mean_ecr: 0.0394 mean_entropies: 1.5390, took: 102.8416s
2022-10-09 08:43:56,387 [INFO] 	Process 6 - batch 25799: mean_policy_losses: -184.715, mean_net_lifetime: 4181.9787, mean_mc_travel_dist: 1425.4813, mean_rewards: 224.7472, total_rewards: 2782.9145, mean_steps: 19.6800, mean_ecr: 0.0403 mean_entropies: 1.5570, took: 99.5084s
2022-10-09 08:44:11,603 [INFO] 	Process 2 - batch 25999: mean_policy_losses: -87.783, mean_net_lifetime: 4066.7973, mean_mc_travel_dist: 1336.6984, mean_rewards: 229.4044, total_rewards: 2760.8586, mean_steps: 18.4000, mean_ecr: 0.0409 mean_entropies: 1.5537, took: 95.7172s
2022-10-09 08:44:30,253 [INFO] 	Process 4 - batch 25699: mean_policy_losses: -91.499, mean_net_lifetime: 4972.9573, mean_mc_travel_dist: 1819.4592, mean_rewards: 224.1951, total_rewards: 3191.5917, mean_steps: 23.4300, mean_ecr: 0.0369 mean_entropies: 1.6437, took: 116.9920s
2022-10-09 08:44:39,640 [INFO] 	Process 5 - batch 25599: mean_policy_losses: -137.310, mean_net_lifetime: 4612.8461, mean_mc_travel_dist: 1626.0382, mean_rewards: 222.6733, total_rewards: 3020.8187, mean_steps: 22.3100, mean_ecr: 0.0393 mean_entropies: 1.5888, took: 815.4833s
2022-10-09 08:44:47,996 [INFO] 	Process 3 - batch 25799: mean_policy_losses: -160.272, mean_net_lifetime: 4099.8597, mean_mc_travel_dist: 1377.3305, mean_rewards: 221.4999, total_rewards: 2760.5397, mean_steps: 18.9600, mean_ecr: 0.0404 mean_entropies: 1.5854, took: 96.6020s
2022-10-09 08:44:57,979 [INFO] 	Process 1 - batch 26899: mean_policy_losses: -97.885, mean_net_lifetime: 4296.8098, mean_mc_travel_dist: 1476.7990, mean_rewards: 221.7629, total_rewards: 2855.3094, mean_steps: 20.0200, mean_ecr: 0.0396 mean_entropies: 1.6085, took: 96.9028s
2022-10-09 08:45:34,089 [INFO] 	Process 6 - batch 25899: mean_policy_losses: -97.927, mean_net_lifetime: 4124.9800, mean_mc_travel_dist: 1409.3980, mean_rewards: 221.6255, total_rewards: 2755.6835, mean_steps: 18.9400, mean_ecr: 0.0391 mean_entropies: 1.6068, took: 97.7027s
2022-10-09 08:46:02,337 [INFO] 	Process 2 - batch 26099: mean_policy_losses: -45.569, mean_net_lifetime: 4513.3382, mean_mc_travel_dist: 1586.2662, mean_rewards: 218.5498, total_rewards: 2962.5618, mean_steps: 21.7100, mean_ecr: 0.0390 mean_entropies: 1.5749, took: 110.7337s
2022-10-09 08:46:13,306 [INFO] 	Process 4 - batch 25799: mean_policy_losses: -137.452, mean_net_lifetime: 4203.2849, mean_mc_travel_dist: 1404.5556, mean_rewards: 221.7827, total_rewards: 2842.8124, mean_steps: 19.7400, mean_ecr: 0.0405 mean_entropies: 1.5674, took: 103.0531s
2022-10-09 08:46:27,103 [INFO] 	Process 3 - batch 25899: mean_policy_losses: -106.860, mean_net_lifetime: 4204.7101, mean_mc_travel_dist: 1410.9797, mean_rewards: 229.0593, total_rewards: 2831.1582, mean_steps: 19.1400, mean_ecr: 0.0386 mean_entropies: 1.5735, took: 99.1077s
2022-10-09 08:46:40,195 [INFO] 	Process 1 - batch 26999: mean_policy_losses: -102.138, mean_net_lifetime: 4357.0491, mean_mc_travel_dist: 1508.5929, mean_rewards: 222.6186, total_rewards: 2879.0505, mean_steps: 20.6000, mean_ecr: 0.0379 mean_entropies: 1.6055, took: 102.2156s
2022-10-09 08:46:49,805 [INFO] 	Process 5 - batch 25699: mean_policy_losses: -28.445, mean_net_lifetime: 5172.8554, mean_mc_travel_dist: 1956.1666, mean_rewards: 222.6986, total_rewards: 3255.5779, mean_steps: 25.3300, mean_ecr: 0.0372 mean_entropies: 1.6391, took: 130.1654s
2022-10-09 08:47:11,102 [INFO] 	Process 0 - batch 25599: mean_policy_losses: -120.370, mean_net_lifetime: 4647.3771, mean_mc_travel_dist: 1656.6744, mean_rewards: 215.3500, total_rewards: 3023.3042, mean_steps: 23.4900, mean_ecr: 0.0389 mean_entropies: 1.5584, took: 816.5077s
2022-10-09 08:47:12,938 [INFO] 	Process 6 - batch 25999: mean_policy_losses: -38.325, mean_net_lifetime: 4131.3588, mean_mc_travel_dist: 1366.5307, mean_rewards: 224.8662, total_rewards: 2803.1745, mean_steps: 18.9300, mean_ecr: 0.0404 mean_entropies: 1.5480, took: 98.8487s
2022-10-09 08:47:47,581 [INFO] 	Process 2 - batch 26199: mean_policy_losses: -135.766, mean_net_lifetime: 4453.3534, mean_mc_travel_dist: 1531.5569, mean_rewards: 230.7720, total_rewards: 2955.0149, mean_steps: 20.5600, mean_ecr: 0.0387 mean_entropies: 1.5589, took: 105.2444s
2022-10-09 08:47:54,173 [INFO] 	Process 4 - batch 25899: mean_policy_losses: -155.327, mean_net_lifetime: 4068.5060, mean_mc_travel_dist: 1373.4544, mean_rewards: 221.5711, total_rewards: 2735.1899, mean_steps: 19.3600, mean_ecr: 0.0385 mean_entropies: 1.5726, took: 100.8658s
2022-10-09 08:48:01,248 [INFO] 	Process 3 - batch 25999: mean_policy_losses: -24.584, mean_net_lifetime: 4019.4884, mean_mc_travel_dist: 1356.4455, mean_rewards: 228.1817, total_rewards: 2704.6217, mean_steps: 18.4200, mean_ecr: 0.0408 mean_entropies: 1.5780, took: 94.1446s
2022-10-09 08:48:22,435 [INFO] 	Process 5 - batch 25799: mean_policy_losses: -176.252, mean_net_lifetime: 3827.8504, mean_mc_travel_dist: 1276.0607, mean_rewards: 229.5837, total_rewards: 2585.1252, mean_steps: 17.7200, mean_ecr: 0.0410 mean_entropies: 1.5684, took: 92.6291s
2022-10-09 08:48:56,265 [INFO] 	Process 0 - batch 25699: mean_policy_losses: 5.210, mean_net_lifetime: 4533.5970, mean_mc_travel_dist: 1589.5903, mean_rewards: 226.4363, total_rewards: 2968.1288, mean_steps: 20.7100, mean_ecr: 0.0375 mean_entropies: 1.6268, took: 105.1613s
2022-10-09 08:49:01,736 [INFO] 	Process 6 - batch 26099: mean_policy_losses: -13.109, mean_net_lifetime: 4563.3623, mean_mc_travel_dist: 1651.5666, mean_rewards: 220.5313, total_rewards: 2952.0684, mean_steps: 21.6500, mean_ecr: 0.0392 mean_entropies: 1.5599, took: 108.7990s
2022-10-09 08:49:32,840 [INFO] 	Process 4 - batch 25999: mean_policy_losses: -22.506, mean_net_lifetime: 4271.3701, mean_mc_travel_dist: 1438.1915, mean_rewards: 230.6338, total_rewards: 2863.7672, mean_steps: 19.2300, mean_ecr: 0.0405 mean_entropies: 1.5458, took: 98.6671s
2022-10-09 08:49:47,507 [INFO] 	Process 2 - batch 26299: mean_policy_losses: -118.203, mean_net_lifetime: 4772.8846, mean_mc_travel_dist: 1748.2848, mean_rewards: 219.3809, total_rewards: 3068.6458, mean_steps: 23.5300, mean_ecr: 0.0381 mean_entropies: 1.6191, took: 119.9248s
2022-10-09 08:49:47,719 [INFO] 	Process 3 - batch 26099: mean_policy_losses: -81.912, mean_net_lifetime: 4342.1409, mean_mc_travel_dist: 1542.0597, mean_rewards: 216.3655, total_rewards: 2839.4107, mean_steps: 21.4800, mean_ecr: 0.0388 mean_entropies: 1.5832, took: 106.4708s
2022-10-09 08:50:04,054 [INFO] 	Process 5 - batch 25899: mean_policy_losses: -89.559, mean_net_lifetime: 4329.0397, mean_mc_travel_dist: 1452.5323, mean_rewards: 229.4651, total_rewards: 2906.0494, mean_steps: 19.4100, mean_ecr: 0.0387 mean_entropies: 1.5773, took: 101.6194s
2022-10-09 08:50:38,337 [INFO] 	Process 0 - batch 25799: mean_policy_losses: -95.077, mean_net_lifetime: 4213.8120, mean_mc_travel_dist: 1433.7764, mean_rewards: 220.6828, total_rewards: 2811.7849, mean_steps: 19.6700, mean_ecr: 0.0401 mean_entropies: 1.5822, took: 102.0720s
2022-10-09 08:50:48,540 [INFO] 	Process 6 - batch 26199: mean_policy_losses: -90.206, mean_net_lifetime: 4469.5794, mean_mc_travel_dist: 1580.1211, mean_rewards: 223.3693, total_rewards: 2924.7657, mean_steps: 20.9800, mean_ecr: 0.0388 mean_entropies: 1.4996, took: 106.8029s
2022-10-09 08:51:21,451 [INFO] 	Process 4 - batch 26099: mean_policy_losses: -99.786, mean_net_lifetime: 4217.2502, mean_mc_travel_dist: 1508.6609, mean_rewards: 210.5073, total_rewards: 2750.7346, mean_steps: 21.1900, mean_ecr: 0.0392 mean_entropies: 1.5160, took: 108.6112s
2022-10-09 08:51:26,421 [INFO] 	Process 3 - batch 26199: mean_policy_losses: -104.694, mean_net_lifetime: 4241.8081, mean_mc_travel_dist: 1457.5906, mean_rewards: 229.8666, total_rewards: 2819.6842, mean_steps: 19.2800, mean_ecr: 0.0390 mean_entropies: 1.5171, took: 98.7027s
2022-10-09 08:51:52,391 [INFO] 	Process 2 - batch 26399: mean_policy_losses: 49.777, mean_net_lifetime: 5260.5977, mean_mc_travel_dist: 1792.3700, mean_rewards: 220.9648, total_rewards: 3505.6572, mean_steps: 24.6000, mean_ecr: 0.0395 mean_entropies: 1.5576, took: 124.8856s
2022-10-09 08:52:05,713 [INFO] 	Process 5 - batch 25999: mean_policy_losses: -30.261, mean_net_lifetime: 5181.3191, mean_mc_travel_dist: 1758.7231, mean_rewards: 218.5626, total_rewards: 3464.6229, mean_steps: 24.1500, mean_ecr: 0.0406 mean_entropies: 1.5425, took: 121.6591s
2022-10-09 08:52:20,119 [INFO] 	Process 0 - batch 25899: mean_policy_losses: -129.480, mean_net_lifetime: 4129.5068, mean_mc_travel_dist: 1424.9591, mean_rewards: 225.1468, total_rewards: 2738.5449, mean_steps: 19.6000, mean_ecr: 0.0390 mean_entropies: 1.5536, took: 101.7837s
2022-10-09 08:52:43,420 [INFO] 	Process 6 - batch 26299: mean_policy_losses: -79.681, mean_net_lifetime: 4654.1151, mean_mc_travel_dist: 1695.2370, mean_rewards: 220.0652, total_rewards: 3015.2395, mean_steps: 22.6600, mean_ecr: 0.0381 mean_entropies: 1.5799, took: 114.8798s
2022-10-09 08:52:56,353 [INFO] 	Process 4 - batch 26199: mean_policy_losses: -153.501, mean_net_lifetime: 4071.6813, mean_mc_travel_dist: 1401.6809, mean_rewards: 228.8884, total_rewards: 2702.8013, mean_steps: 18.4700, mean_ecr: 0.0387 mean_entropies: 1.5099, took: 94.9022s
2022-10-09 08:53:21,586 [INFO] 	Process 3 - batch 26299: mean_policy_losses: -129.540, mean_net_lifetime: 4731.8480, mean_mc_travel_dist: 1693.4906, mean_rewards: 228.1149, total_rewards: 3078.4901, mean_steps: 22.6600, mean_ecr: 0.0382 mean_entropies: 1.5645, took: 115.1645s
2022-10-09 08:53:33,464 [INFO] 	Process 2 - batch 26499: mean_policy_losses: -31.213, mean_net_lifetime: 4326.4476, mean_mc_travel_dist: 1493.4336, mean_rewards: 228.1255, total_rewards: 2875.2995, mean_steps: 19.5000, mean_ecr: 0.0397 mean_entropies: 1.5548, took: 101.0721s
2022-10-09 08:54:02,658 [INFO] 	Process 0 - batch 25999: mean_policy_losses: -69.144, mean_net_lifetime: 4314.3700, mean_mc_travel_dist: 1473.6855, mean_rewards: 228.3655, total_rewards: 2880.1867, mean_steps: 19.7700, mean_ecr: 0.0404 mean_entropies: 1.5612, took: 102.5386s
2022-10-09 08:54:38,588 [INFO] 	Process 5 - batch 26099: mean_policy_losses: -160.477, mean_net_lifetime: 5943.1717, mean_mc_travel_dist: 2305.1221, mean_rewards: 210.2258, total_rewards: 3682.0288, mean_steps: 30.4500, mean_ecr: 0.0390 mean_entropies: 1.5642, took: 152.8737s
2022-10-09 08:54:46,793 [INFO] 	Process 6 - batch 26399: mean_policy_losses: -31.773, mean_net_lifetime: 5218.4307, mean_mc_travel_dist: 1824.1717, mean_rewards: 225.4996, total_rewards: 3435.7691, mean_steps: 24.2400, mean_ecr: 0.0397 mean_entropies: 1.5470, took: 123.3723s
2022-10-09 08:54:47,097 [INFO] 	Process 4 - batch 26299: mean_policy_losses: -102.764, mean_net_lifetime: 4691.7280, mean_mc_travel_dist: 1667.0805, mean_rewards: 223.0004, total_rewards: 3069.4393, mean_steps: 22.4200, mean_ecr: 0.0380 mean_entropies: 1.6162, took: 110.7444s
2022-10-09 08:55:02,508 [INFO] 	Process 3 - batch 26399: mean_policy_losses: -28.695, mean_net_lifetime: 4370.8953, mean_mc_travel_dist: 1493.9807, mean_rewards: 225.2831, total_rewards: 2911.9755, mean_steps: 19.5600, mean_ecr: 0.0395 mean_entropies: 1.5693, took: 100.9219s
2022-10-09 08:55:24,398 [INFO] 	Process 2 - batch 26599: mean_policy_losses: -66.855, mean_net_lifetime: 4713.2282, mean_mc_travel_dist: 1674.4970, mean_rewards: 225.0553, total_rewards: 3078.9076, mean_steps: 21.6200, mean_ecr: 0.0391 mean_entropies: 1.5989, took: 110.9344s
2022-10-09 08:55:50,914 [INFO] 	Process 0 - batch 26099: mean_policy_losses: -49.394, mean_net_lifetime: 4377.1976, mean_mc_travel_dist: 1555.6985, mean_rewards: 212.4274, total_rewards: 2855.8229, mean_steps: 21.1700, mean_ecr: 0.0392 mean_entropies: 1.5737, took: 108.2554s
2022-10-09 08:56:17,290 [INFO] 	Process 5 - batch 26199: mean_policy_losses: -192.715, mean_net_lifetime: 4207.7847, mean_mc_travel_dist: 1481.5374, mean_rewards: 224.9797, total_rewards: 2766.2685, mean_steps: 19.3200, mean_ecr: 0.0392 mean_entropies: 1.5350, took: 98.6999s
2022-10-09 08:56:23,622 [INFO] 	Process 4 - batch 26399: mean_policy_losses: 7.819, mean_net_lifetime: 4224.3196, mean_mc_travel_dist: 1423.4324, mean_rewards: 228.8722, total_rewards: 2839.3089, mean_steps: 18.7400, mean_ecr: 0.0397 mean_entropies: 1.5279, took: 96.5239s
2022-10-09 08:56:25,317 [INFO] 	Process 6 - batch 26499: mean_policy_losses: -73.966, mean_net_lifetime: 4203.7410, mean_mc_travel_dist: 1450.7841, mean_rewards: 225.1553, total_rewards: 2789.9801, mean_steps: 18.9800, mean_ecr: 0.0394 mean_entropies: 1.5818, took: 98.5254s
2022-10-09 08:56:49,974 [INFO] 	Process 3 - batch 26499: mean_policy_losses: -67.642, mean_net_lifetime: 4574.7260, mean_mc_travel_dist: 1636.9287, mean_rewards: 220.3943, total_rewards: 2972.9500, mean_steps: 21.5100, mean_ecr: 0.0394 mean_entropies: 1.5666, took: 107.4670s
2022-10-09 08:57:16,629 [INFO] 	Process 2 - batch 26699: mean_policy_losses: 32.359, mean_net_lifetime: 4662.1291, mean_mc_travel_dist: 1648.4598, mean_rewards: 215.9367, total_rewards: 3041.4888, mean_steps: 22.2300, mean_ecr: 0.0390 mean_entropies: 1.5325, took: 112.2305s
2022-10-09 08:57:24,415 [INFO] 	Process 0 - batch 26199: mean_policy_losses: -189.358, mean_net_lifetime: 4088.8960, mean_mc_travel_dist: 1414.0107, mean_rewards: 229.7118, total_rewards: 2714.5710, mean_steps: 18.1200, mean_ecr: 0.0387 mean_entropies: 1.5549, took: 93.5020s
2022-10-09 08:58:03,554 [INFO] 	Process 6 - batch 26599: mean_policy_losses: -65.039, mean_net_lifetime: 4185.0904, mean_mc_travel_dist: 1474.3560, mean_rewards: 223.0367, total_rewards: 2752.6547, mean_steps: 19.2300, mean_ecr: 0.0390 mean_entropies: 1.5666, took: 98.2358s
2022-10-09 08:58:10,742 [INFO] 	Process 4 - batch 26499: mean_policy_losses: -75.858, mean_net_lifetime: 4659.5979, mean_mc_travel_dist: 1641.8408, mean_rewards: 227.0603, total_rewards: 3060.0050, mean_steps: 21.3700, mean_ecr: 0.0392 mean_entropies: 1.5995, took: 107.1207s
2022-10-09 08:58:22,786 [INFO] 	Process 5 - batch 26299: mean_policy_losses: -26.747, mean_net_lifetime: 5085.0335, mean_mc_travel_dist: 1856.7045, mean_rewards: 216.6250, total_rewards: 3272.1501, mean_steps: 25.0200, mean_ecr: 0.0379 mean_entropies: 1.6341, took: 125.4989s
2022-10-09 08:58:37,435 [INFO] 	Process 3 - batch 26599: mean_policy_losses: -51.018, mean_net_lifetime: 4543.8894, mean_mc_travel_dist: 1638.2647, mean_rewards: 224.5702, total_rewards: 2937.1593, mean_steps: 21.0300, mean_ecr: 0.0391 mean_entropies: 1.6086, took: 107.4604s
2022-10-09 08:58:58,760 [INFO] 	Process 2 - batch 26799: mean_policy_losses: -84.746, mean_net_lifetime: 4266.3657, mean_mc_travel_dist: 1489.1108, mean_rewards: 225.5346, total_rewards: 2811.4410, mean_steps: 19.6200, mean_ecr: 0.0399 mean_entropies: 1.5419, took: 102.1315s
2022-10-09 08:59:18,810 [INFO] 	Process 0 - batch 26299: mean_policy_losses: -161.584, mean_net_lifetime: 4662.1048, mean_mc_travel_dist: 1675.9376, mean_rewards: 223.4846, total_rewards: 3017.6577, mean_steps: 22.3700, mean_ecr: 0.0381 mean_entropies: 1.6012, took: 114.3949s
2022-10-09 08:59:45,990 [INFO] 	Process 4 - batch 26599: mean_policy_losses: -123.488, mean_net_lifetime: 4098.9194, mean_mc_travel_dist: 1411.5136, mean_rewards: 224.6863, total_rewards: 2729.9904, mean_steps: 18.4700, mean_ecr: 0.0392 mean_entropies: 1.5966, took: 95.2481s
2022-10-09 08:59:54,668 [INFO] 	Process 6 - batch 26699: mean_policy_losses: -55.579, mean_net_lifetime: 4604.6135, mean_mc_travel_dist: 1616.7160, mean_rewards: 217.2048, total_rewards: 3026.7880, mean_steps: 22.1100, mean_ecr: 0.0393 mean_entropies: 1.5915, took: 111.1145s
2022-10-09 09:00:13,763 [INFO] 	Process 5 - batch 26399: mean_policy_losses: 31.190, mean_net_lifetime: 4708.0398, mean_mc_travel_dist: 1614.0365, mean_rewards: 220.7988, total_rewards: 3131.6983, mean_steps: 21.6900, mean_ecr: 0.0397 mean_entropies: 1.5702, took: 110.9776s
2022-10-09 09:00:38,785 [INFO] 	Process 3 - batch 26699: mean_policy_losses: 17.006, mean_net_lifetime: 4738.7805, mean_mc_travel_dist: 1663.9794, mean_rewards: 210.5906, total_rewards: 3106.5255, mean_steps: 23.5100, mean_ecr: 0.0390 mean_entropies: 1.5772, took: 121.3494s
2022-10-09 09:00:39,302 [INFO] 	Process 2 - batch 26899: mean_policy_losses: -108.195, mean_net_lifetime: 4122.4139, mean_mc_travel_dist: 1399.4903, mean_rewards: 223.3232, total_rewards: 2761.1660, mean_steps: 19.0300, mean_ecr: 0.0396 mean_entropies: 1.5879, took: 100.5423s
2022-10-09 09:01:03,765 [INFO] 	Process 0 - batch 26399: mean_policy_losses: -58.248, mean_net_lifetime: 4391.9971, mean_mc_travel_dist: 1513.5381, mean_rewards: 228.0017, total_rewards: 2915.1641, mean_steps: 19.8200, mean_ecr: 0.0399 mean_entropies: 1.5363, took: 104.9537s
2022-10-09 09:01:10,489 [INFO] 	Process 1 - batch 27099: mean_policy_losses: -189.618, mean_net_lifetime: 4548.6460, mean_mc_travel_dist: 1579.6117, mean_rewards: 231.1009, total_rewards: 3008.2160, mean_steps: 21.1700, mean_ecr: 0.0377 mean_entropies: 1.6482, took: 870.2935s
2022-10-09 09:01:41,737 [INFO] 	Process 4 - batch 26699: mean_policy_losses: 26.625, mean_net_lifetime: 4707.2839, mean_mc_travel_dist: 1629.9949, mean_rewards: 213.9338, total_rewards: 3104.2134, mean_steps: 22.6400, mean_ecr: 0.0391 mean_entropies: 1.5772, took: 115.7476s
2022-10-09 09:01:42,698 [INFO] 	Process 6 - batch 26799: mean_policy_losses: -56.629, mean_net_lifetime: 4313.2137, mean_mc_travel_dist: 1511.5407, mean_rewards: 213.3616, total_rewards: 2834.7370, mean_steps: 20.5700, mean_ecr: 0.0398 mean_entropies: 1.5537, took: 108.0295s
2022-10-09 09:02:00,919 [INFO] 	Process 5 - batch 26499: mean_policy_losses: -112.466, mean_net_lifetime: 4396.9957, mean_mc_travel_dist: 1515.2915, mean_rewards: 221.6677, total_rewards: 2922.4803, mean_steps: 20.4500, mean_ecr: 0.0392 mean_entropies: 1.6066, took: 107.1553s
2022-10-09 09:02:24,707 [INFO] 	Process 3 - batch 26799: mean_policy_losses: -55.722, mean_net_lifetime: 4383.4177, mean_mc_travel_dist: 1541.2201, mean_rewards: 222.9164, total_rewards: 2883.7200, mean_steps: 20.3800, mean_ecr: 0.0393 mean_entropies: 1.5852, took: 105.9224s
2022-10-09 09:02:27,016 [INFO] 	Process 2 - batch 26999: mean_policy_losses: -48.255, mean_net_lifetime: 4454.7299, mean_mc_travel_dist: 1558.5770, mean_rewards: 221.3563, total_rewards: 2935.3426, mean_steps: 20.1600, mean_ecr: 0.0381 mean_entropies: 1.6386, took: 107.7133s
2022-10-09 09:02:51,332 [INFO] 	Process 0 - batch 26499: mean_policy_losses: -75.954, mean_net_lifetime: 4519.8901, mean_mc_travel_dist: 1588.3013, mean_rewards: 228.9776, total_rewards: 2971.6212, mean_steps: 20.3400, mean_ecr: 0.0398 mean_entropies: 1.5702, took: 107.5670s
2022-10-09 09:02:56,057 [INFO] 	Process 1 - batch 27199: mean_policy_losses: -151.528, mean_net_lifetime: 4400.4975, mean_mc_travel_dist: 1549.6439, mean_rewards: 228.4257, total_rewards: 2893.4771, mean_steps: 21.4600, mean_ecr: 0.0383 mean_entropies: 1.5774, took: 105.5681s
2022-10-09 09:03:28,085 [INFO] 	Process 6 - batch 26899: mean_policy_losses: -51.411, mean_net_lifetime: 4343.9139, mean_mc_travel_dist: 1470.1153, mean_rewards: 220.6015, total_rewards: 2906.8937, mean_steps: 20.0100, mean_ecr: 0.0391 mean_entropies: 1.6118, took: 105.3879s
2022-10-09 09:03:30,657 [INFO] 	Process 4 - batch 26799: mean_policy_losses: -32.612, mean_net_lifetime: 4568.2008, mean_mc_travel_dist: 1595.2706, mean_rewards: 221.2731, total_rewards: 3010.8391, mean_steps: 21.0900, mean_ecr: 0.0396 mean_entropies: 1.5404, took: 108.9195s
2022-10-09 09:03:40,828 [INFO] 	Process 5 - batch 26599: mean_policy_losses: -134.343, mean_net_lifetime: 4217.3440, mean_mc_travel_dist: 1482.3292, mean_rewards: 222.1144, total_rewards: 2776.8650, mean_steps: 19.1300, mean_ecr: 0.0392 mean_entropies: 1.5525, took: 99.9098s
2022-10-09 09:04:05,651 [INFO] 	Process 3 - batch 26899: mean_policy_losses: -42.011, mean_net_lifetime: 4319.6343, mean_mc_travel_dist: 1455.0739, mean_rewards: 220.9085, total_rewards: 2907.8659, mean_steps: 19.6700, mean_ecr: 0.0393 mean_entropies: 1.6025, took: 100.9446s
2022-10-09 09:04:28,775 [INFO] 	Process 0 - batch 26599: mean_policy_losses: -150.075, mean_net_lifetime: 4173.0706, mean_mc_travel_dist: 1454.3576, mean_rewards: 228.5495, total_rewards: 2756.4840, mean_steps: 18.6300, mean_ecr: 0.0391 mean_entropies: 1.5742, took: 97.4439s
2022-10-09 09:04:39,977 [INFO] 	Process 1 - batch 27299: mean_policy_losses: -141.109, mean_net_lifetime: 4686.9663, mean_mc_travel_dist: 1718.5019, mean_rewards: 225.1177, total_rewards: 3007.5889, mean_steps: 21.6400, mean_ecr: 0.0409 mean_entropies: 1.5036, took: 103.9190s
2022-10-09 09:05:12,763 [INFO] 	Process 4 - batch 26899: mean_policy_losses: -105.004, mean_net_lifetime: 4330.1619, mean_mc_travel_dist: 1459.1098, mean_rewards: 221.2698, total_rewards: 2916.0553, mean_steps: 19.9400, mean_ecr: 0.0391 mean_entropies: 1.6113, took: 102.1059s
2022-10-09 09:05:18,324 [INFO] 	Process 6 - batch 26999: mean_policy_losses: -164.552, mean_net_lifetime: 4794.5726, mean_mc_travel_dist: 1705.7325, mean_rewards: 221.2247, total_rewards: 3126.7641, mean_steps: 21.8100, mean_ecr: 0.0378 mean_entropies: 1.6496, took: 110.2376s
2022-10-09 09:05:36,333 [INFO] 	Process 5 - batch 26699: mean_policy_losses: -41.536, mean_net_lifetime: 4780.1614, mean_mc_travel_dist: 1687.1183, mean_rewards: 216.7144, total_rewards: 3130.2856, mean_steps: 22.8000, mean_ecr: 0.0390 mean_entropies: 1.5714, took: 115.5046s
2022-10-09 09:05:52,479 [INFO] 	Process 3 - batch 26999: mean_policy_losses: -78.500, mean_net_lifetime: 4645.4574, mean_mc_travel_dist: 1624.4125, mean_rewards: 222.7432, total_rewards: 3064.5452, mean_steps: 21.3300, mean_ecr: 0.0378 mean_entropies: 1.6329, took: 106.8275s
2022-10-09 09:06:13,942 [INFO] 	Process 0 - batch 26699: mean_policy_losses: -107.074, mean_net_lifetime: 4416.3406, mean_mc_travel_dist: 1549.6541, mean_rewards: 220.9100, total_rewards: 2898.1747, mean_steps: 21.2600, mean_ecr: 0.0392 mean_entropies: 1.5313, took: 105.1676s
2022-10-09 09:06:20,827 [INFO] 	Process 1 - batch 27399: mean_policy_losses: -128.377, mean_net_lifetime: 4662.6070, mean_mc_travel_dist: 1635.1191, mean_rewards: 223.4726, total_rewards: 3055.5265, mean_steps: 21.7200, mean_ecr: 0.0387 mean_entropies: 1.5979, took: 100.8511s
2022-10-09 09:06:52,578 [INFO] 	Process 4 - batch 26999: mean_policy_losses: -71.088, mean_net_lifetime: 4477.4238, mean_mc_travel_dist: 1557.4498, mean_rewards: 220.9261, total_rewards: 2956.6321, mean_steps: 20.7900, mean_ecr: 0.0380 mean_entropies: 1.6044, took: 99.8146s
2022-10-09 09:07:11,355 [INFO] 	Process 5 - batch 26799: mean_policy_losses: -54.494, mean_net_lifetime: 4200.4738, mean_mc_travel_dist: 1454.6578, mean_rewards: 223.6372, total_rewards: 2783.2043, mean_steps: 19.7200, mean_ecr: 0.0396 mean_entropies: 1.4826, took: 95.0225s
2022-10-09 09:07:47,798 [INFO] 	Process 1 - batch 27499: mean_policy_losses: -121.744, mean_net_lifetime: 4265.5356, mean_mc_travel_dist: 1471.3885, mean_rewards: 232.9683, total_rewards: 2832.6128, mean_steps: 19.5600, mean_ecr: 0.0401 mean_entropies: 1.4249, took: 86.9717s
2022-10-09 09:07:50,701 [INFO] 	Process 0 - batch 26799: mean_policy_losses: -70.087, mean_net_lifetime: 4302.3728, mean_mc_travel_dist: 1490.9743, mean_rewards: 219.4034, total_rewards: 2844.7030, mean_steps: 20.3400, mean_ecr: 0.0392 mean_entropies: 1.5212, took: 96.7574s
2022-10-09 09:08:49,210 [INFO] 	Process 5 - batch 26899: mean_policy_losses: -40.697, mean_net_lifetime: 4511.2615, mean_mc_travel_dist: 1523.2608, mean_rewards: 218.8816, total_rewards: 3032.5017, mean_steps: 21.1600, mean_ecr: 0.0389 mean_entropies: 1.6056, took: 97.8544s
2022-10-09 09:09:21,534 [INFO] 	Process 1 - batch 27599: mean_policy_losses: -114.403, mean_net_lifetime: 4568.9636, mean_mc_travel_dist: 1642.7260, mean_rewards: 222.2883, total_rewards: 2966.7807, mean_steps: 21.9500, mean_ecr: 0.0383 mean_entropies: 1.5344, took: 93.7356s
2022-10-09 09:09:21,933 [INFO] 	Process 0 - batch 26899: mean_policy_losses: -136.295, mean_net_lifetime: 4204.0604, mean_mc_travel_dist: 1433.7147, mean_rewards: 223.3010, total_rewards: 2805.1893, mean_steps: 19.3700, mean_ecr: 0.0397 mean_entropies: 1.6065, took: 91.2334s
2022-10-09 09:10:23,507 [INFO] 	Process 5 - batch 26999: mean_policy_losses: -89.006, mean_net_lifetime: 4363.2991, mean_mc_travel_dist: 1512.4801, mean_rewards: 221.5001, total_rewards: 2884.3815, mean_steps: 19.9300, mean_ecr: 0.0382 mean_entropies: 1.6529, took: 94.2972s
2022-10-09 09:10:37,260 [INFO] 	Process 1 - batch 27699: mean_policy_losses: -164.191, mean_net_lifetime: 3770.9596, mean_mc_travel_dist: 1294.8827, mean_rewards: 221.4710, total_rewards: 2517.8744, mean_steps: 17.2900, mean_ecr: 0.0400 mean_entropies: 1.5386, took: 75.7258s
2022-10-09 09:10:51,900 [INFO] 	Process 0 - batch 26999: mean_policy_losses: -19.437, mean_net_lifetime: 4440.9299, mean_mc_travel_dist: 1525.7881, mean_rewards: 229.5659, total_rewards: 2959.0539, mean_steps: 19.8800, mean_ecr: 0.0379 mean_entropies: 1.6102, took: 89.9664s
2022-10-09 09:12:03,050 [INFO] 	Process 1 - batch 27799: mean_policy_losses: -98.435, mean_net_lifetime: 4744.9436, mean_mc_travel_dist: 1716.1529, mean_rewards: 235.5702, total_rewards: 3067.3441, mean_steps: 21.4900, mean_ecr: 0.0394 mean_entropies: 1.5774, took: 85.7900s
2022-10-09 09:13:32,927 [INFO] 	Process 1 - batch 27899: mean_policy_losses: -129.369, mean_net_lifetime: 4708.3890, mean_mc_travel_dist: 1650.0108, mean_rewards: 213.2621, total_rewards: 3100.1508, mean_steps: 22.6400, mean_ecr: 0.0380 mean_entropies: 1.6354, took: 89.8774s
2022-10-09 09:14:48,022 [INFO] 	Process 1 - batch 27999: mean_policy_losses: -83.917, mean_net_lifetime: 4076.2887, mean_mc_travel_dist: 1376.3143, mean_rewards: 231.1686, total_rewards: 2734.1126, mean_steps: 18.2400, mean_ecr: 0.0397 mean_entropies: 1.6131, took: 75.0943s
2022-10-09 09:15:33,045 [INFO] 	Process 2 - batch 27099: mean_policy_losses: -93.515, mean_net_lifetime: 4356.5792, mean_mc_travel_dist: 1485.3363, mean_rewards: 225.9855, total_rewards: 2901.1791, mean_steps: 20.2200, mean_ecr: 0.0378 mean_entropies: 1.6608, took: 786.0290s
2022-10-09 09:16:14,839 [INFO] 	Process 1 - batch 28099: mean_policy_losses: -74.573, mean_net_lifetime: 4454.1378, mean_mc_travel_dist: 1540.3842, mean_rewards: 227.9851, total_rewards: 2943.1237, mean_steps: 20.6100, mean_ecr: 0.0401 mean_entropies: 1.5349, took: 86.8176s
2022-10-09 09:17:40,550 [INFO] 	Process 2 - batch 27199: mean_policy_losses: -33.793, mean_net_lifetime: 5551.3932, mean_mc_travel_dist: 1994.1742, mean_rewards: 229.6454, total_rewards: 3590.2386, mean_steps: 28.5900, mean_ecr: 0.0384 mean_entropies: 1.6010, took: 127.5058s
2022-10-09 09:17:57,133 [INFO] 	Process 6 - batch 27099: mean_policy_losses: -113.607, mean_net_lifetime: 3973.2571, mean_mc_travel_dist: 1317.8426, mean_rewards: 233.8410, total_rewards: 2686.1301, mean_steps: 17.7700, mean_ecr: 0.0380 mean_entropies: 1.6481, took: 758.8109s
2022-10-09 09:17:59,584 [INFO] 	Process 1 - batch 28199: mean_policy_losses: -27.316, mean_net_lifetime: 5055.5823, mean_mc_travel_dist: 1864.2660, mean_rewards: 212.2461, total_rewards: 3220.4080, mean_steps: 24.4600, mean_ecr: 0.0376 mean_entropies: 1.6037, took: 104.7449s
2022-10-09 09:19:13,881 [INFO] 	Process 2 - batch 27299: mean_policy_losses: 31.269, mean_net_lifetime: 4257.0839, mean_mc_travel_dist: 1472.8874, mean_rewards: 223.8448, total_rewards: 2812.0173, mean_steps: 19.4000, mean_ecr: 0.0406 mean_entropies: 1.5287, took: 93.3310s
2022-10-09 09:19:24,527 [INFO] 	Process 1 - batch 28299: mean_policy_losses: -29.803, mean_net_lifetime: 4277.2381, mean_mc_travel_dist: 1483.1503, mean_rewards: 237.3168, total_rewards: 2837.0380, mean_steps: 18.3700, mean_ecr: 0.0392 mean_entropies: 1.5269, took: 84.9436s
2022-10-09 09:19:44,233 [INFO] 	Process 6 - batch 27199: mean_policy_losses: -82.284, mean_net_lifetime: 4814.3259, mean_mc_travel_dist: 1739.4874, mean_rewards: 229.8791, total_rewards: 3117.8380, mean_steps: 22.8300, mean_ecr: 0.0379 mean_entropies: 1.5966, took: 107.0996s
2022-10-09 09:19:55,607 [INFO] 	Process 3 - batch 27099: mean_policy_losses: -43.589, mean_net_lifetime: 4429.3841, mean_mc_travel_dist: 1532.4816, mean_rewards: 224.8564, total_rewards: 2922.6427, mean_steps: 20.6300, mean_ecr: 0.0376 mean_entropies: 1.6391, took: 843.1286s
2022-10-09 09:20:17,313 [INFO] 	Process 4 - batch 27099: mean_policy_losses: -171.854, mean_net_lifetime: 4120.1863, mean_mc_travel_dist: 1407.7601, mean_rewards: 230.3014, total_rewards: 2753.0328, mean_steps: 19.2300, mean_ecr: 0.0374 mean_entropies: 1.6406, took: 804.7357s
2022-10-09 09:21:00,912 [INFO] 	Process 2 - batch 27399: mean_policy_losses: -50.532, mean_net_lifetime: 4576.5373, mean_mc_travel_dist: 1634.5675, mean_rewards: 226.0169, total_rewards: 2974.8759, mean_steps: 21.2700, mean_ecr: 0.0387 mean_entropies: 1.5914, took: 107.0305s
2022-10-09 09:21:10,056 [INFO] 	Process 1 - batch 28399: mean_policy_losses: 0.287, mean_net_lifetime: 4745.9367, mean_mc_travel_dist: 1672.3063, mean_rewards: 223.3190, total_rewards: 3108.1345, mean_steps: 22.7500, mean_ecr: 0.0399 mean_entropies: 1.4804, took: 105.5289s
2022-10-09 09:21:18,887 [INFO] 	Process 6 - batch 27299: mean_policy_losses: -78.112, mean_net_lifetime: 4127.5212, mean_mc_travel_dist: 1436.9269, mean_rewards: 223.5294, total_rewards: 2723.9589, mean_steps: 19.0800, mean_ecr: 0.0411 mean_entropies: 1.5001, took: 94.6538s
2022-10-09 09:21:41,178 [INFO] 	Process 3 - batch 27199: mean_policy_losses: -36.829, mean_net_lifetime: 4584.2521, mean_mc_travel_dist: 1616.5226, mean_rewards: 222.1013, total_rewards: 3007.5475, mean_steps: 22.0000, mean_ecr: 0.0383 mean_entropies: 1.5763, took: 105.5707s
2022-10-09 09:21:56,210 [INFO] 	Process 4 - batch 27199: mean_policy_losses: -46.921, mean_net_lifetime: 4295.2048, mean_mc_travel_dist: 1495.4566, mean_rewards: 224.9857, total_rewards: 2843.1945, mean_steps: 19.9600, mean_ecr: 0.0382 mean_entropies: 1.5659, took: 98.8965s
2022-10-09 09:22:29,138 [INFO] 	Process 2 - batch 27499: mean_policy_losses: -200.531, mean_net_lifetime: 3804.4798, mean_mc_travel_dist: 1317.0252, mean_rewards: 232.1759, total_rewards: 2527.1261, mean_steps: 17.3300, mean_ecr: 0.0400 mean_entropies: 1.4691, took: 88.2260s
2022-10-09 09:22:36,932 [INFO] 	Process 1 - batch 28499: mean_policy_losses: -91.986, mean_net_lifetime: 4077.6570, mean_mc_travel_dist: 1417.1207, mean_rewards: 230.2375, total_rewards: 2696.5733, mean_steps: 18.1100, mean_ecr: 0.0394 mean_entropies: 1.5522, took: 86.8753s
2022-10-09 09:22:52,144 [INFO] 	Process 6 - batch 27399: mean_policy_losses: -76.963, mean_net_lifetime: 4282.7585, mean_mc_travel_dist: 1565.4537, mean_rewards: 237.0121, total_rewards: 2759.4743, mean_steps: 18.6600, mean_ecr: 0.0389 mean_entropies: 1.5714, took: 93.2579s
2022-10-09 09:23:11,115 [INFO] 	Process 3 - batch 27299: mean_policy_losses: -54.469, mean_net_lifetime: 4059.9028, mean_mc_travel_dist: 1463.8145, mean_rewards: 230.3063, total_rewards: 2641.5753, mean_steps: 18.0200, mean_ecr: 0.0410 mean_entropies: 1.5079, took: 89.9359s
2022-10-09 09:23:32,533 [INFO] 	Process 4 - batch 27299: mean_policy_losses: 16.463, mean_net_lifetime: 4299.6279, mean_mc_travel_dist: 1532.4514, mean_rewards: 230.2670, total_rewards: 2808.1085, mean_steps: 18.9100, mean_ecr: 0.0407 mean_entropies: 1.5083, took: 96.3232s
2022-10-09 09:23:37,550 [INFO] 	Process 5 - batch 27099: mean_policy_losses: -168.914, mean_net_lifetime: 3831.5174, mean_mc_travel_dist: 1344.4125, mean_rewards: 235.9896, total_rewards: 2531.2620, mean_steps: 17.0800, mean_ecr: 0.0374 mean_entropies: 1.6301, took: 794.0434s
2022-10-09 09:24:08,246 [INFO] 	Process 2 - batch 27599: mean_policy_losses: -31.431, mean_net_lifetime: 4261.4748, mean_mc_travel_dist: 1520.2355, mean_rewards: 232.0993, total_rewards: 2784.6417, mean_steps: 19.3300, mean_ecr: 0.0384 mean_entropies: 1.5487, took: 99.1077s
2022-10-09 09:24:16,495 [INFO] 	Process 0 - batch 27099: mean_policy_losses: -120.534, mean_net_lifetime: 3947.9211, mean_mc_travel_dist: 1357.6291, mean_rewards: 228.5906, total_rewards: 2628.4268, mean_steps: 17.8200, mean_ecr: 0.0376 mean_entropies: 1.6287, took: 804.5957s
2022-10-09 09:24:25,940 [INFO] 	Process 6 - batch 27499: mean_policy_losses: -112.168, mean_net_lifetime: 4034.2542, mean_mc_travel_dist: 1382.2676, mean_rewards: 225.9882, total_rewards: 2687.8532, mean_steps: 18.2700, mean_ecr: 0.0402 mean_entropies: 1.4629, took: 93.7954s
2022-10-09 09:25:01,761 [INFO] 	Process 3 - batch 27399: mean_policy_losses: 20.901, mean_net_lifetime: 4853.2636, mean_mc_travel_dist: 1784.3025, mean_rewards: 222.4952, total_rewards: 3105.4529, mean_steps: 22.4400, mean_ecr: 0.0385 mean_entropies: 1.6208, took: 110.6471s
2022-10-09 09:25:25,245 [INFO] 	Process 4 - batch 27399: mean_policy_losses: -12.744, mean_net_lifetime: 4715.7677, mean_mc_travel_dist: 1735.6170, mean_rewards: 220.9251, total_rewards: 3029.2449, mean_steps: 22.5000, mean_ecr: 0.0385 mean_entropies: 1.6041, took: 112.7113s
2022-10-09 09:25:33,789 [INFO] 	Process 5 - batch 27199: mean_policy_losses: -45.718, mean_net_lifetime: 4755.9517, mean_mc_travel_dist: 1699.7575, mean_rewards: 230.5748, total_rewards: 3094.3103, mean_steps: 23.1000, mean_ecr: 0.0383 mean_entropies: 1.5891, took: 116.2383s
2022-10-09 09:25:56,094 [INFO] 	Process 2 - batch 27699: mean_policy_losses: -105.146, mean_net_lifetime: 4497.3233, mean_mc_travel_dist: 1599.4869, mean_rewards: 227.7004, total_rewards: 2935.0456, mean_steps: 21.1300, mean_ecr: 0.0398 mean_entropies: 1.5859, took: 107.8489s
2022-10-09 09:26:08,159 [INFO] 	Process 0 - batch 27199: mean_policy_losses: -79.818, mean_net_lifetime: 4660.4109, mean_mc_travel_dist: 1636.7984, mean_rewards: 233.3516, total_rewards: 3063.9556, mean_steps: 22.0300, mean_ecr: 0.0382 mean_entropies: 1.5814, took: 111.6640s
2022-10-09 09:26:16,626 [INFO] 	Process 6 - batch 27599: mean_policy_losses: -54.491, mean_net_lifetime: 4676.1531, mean_mc_travel_dist: 1643.1349, mean_rewards: 229.7931, total_rewards: 3067.8485, mean_steps: 21.7200, mean_ecr: 0.0383 mean_entropies: 1.5777, took: 110.6851s
2022-10-09 09:26:36,662 [INFO] 	Process 3 - batch 27499: mean_policy_losses: -119.670, mean_net_lifetime: 4121.8715, mean_mc_travel_dist: 1397.4249, mean_rewards: 231.0382, total_rewards: 2756.8051, mean_steps: 18.5600, mean_ecr: 0.0402 mean_entropies: 1.5010, took: 94.9003s
2022-10-09 09:27:02,284 [INFO] 	Process 4 - batch 27499: mean_policy_losses: -137.699, mean_net_lifetime: 3941.9179, mean_mc_travel_dist: 1330.1183, mean_rewards: 226.2118, total_rewards: 2649.6195, mean_steps: 18.1800, mean_ecr: 0.0402 mean_entropies: 1.4747, took: 97.0396s
2022-10-09 09:27:27,946 [INFO] 	Process 5 - batch 27299: mean_policy_losses: -54.285, mean_net_lifetime: 4440.6434, mean_mc_travel_dist: 1559.2047, mean_rewards: 219.6125, total_rewards: 2915.7808, mean_steps: 20.8200, mean_ecr: 0.0406 mean_entropies: 1.5129, took: 114.1574s
2022-10-09 09:27:53,708 [INFO] 	Process 6 - batch 27699: mean_policy_losses: -232.983, mean_net_lifetime: 3805.0538, mean_mc_travel_dist: 1298.0679, mean_rewards: 222.0167, total_rewards: 2548.7575, mean_steps: 17.2000, mean_ecr: 0.0401 mean_entropies: 1.5464, took: 97.0833s
2022-10-09 09:27:58,179 [INFO] 	Process 0 - batch 27299: mean_policy_losses: -3.137, mean_net_lifetime: 4367.8327, mean_mc_travel_dist: 1489.6943, mean_rewards: 217.9605, total_rewards: 2907.6685, mean_steps: 20.2400, mean_ecr: 0.0406 mean_entropies: 1.5308, took: 110.0191s
2022-10-09 09:28:39,957 [INFO] 	Process 3 - batch 27599: mean_policy_losses: -120.263, mean_net_lifetime: 4578.0615, mean_mc_travel_dist: 1660.2633, mean_rewards: 228.5584, total_rewards: 2956.1133, mean_steps: 21.5200, mean_ecr: 0.0387 mean_entropies: 1.5675, took: 123.2955s
2022-10-09 09:28:40,922 [INFO] 	Process 2 - batch 27799: mean_policy_losses: -139.291, mean_net_lifetime: 6050.4175, mean_mc_travel_dist: 2496.7249, mean_rewards: 237.7291, total_rewards: 3586.4396, mean_steps: 30.9300, mean_ecr: 0.0392 mean_entropies: 1.5499, took: 164.8270s
2022-10-09 09:28:58,472 [INFO] 	Process 4 - batch 27599: mean_policy_losses: -163.772, mean_net_lifetime: 4433.1924, mean_mc_travel_dist: 1576.0395, mean_rewards: 232.0962, total_rewards: 2895.5089, mean_steps: 20.5400, mean_ecr: 0.0387 mean_entropies: 1.5501, took: 116.1878s
2022-10-09 09:29:18,717 [INFO] 	Process 5 - batch 27399: mean_policy_losses: -91.684, mean_net_lifetime: 4542.4777, mean_mc_travel_dist: 1584.7893, mean_rewards: 228.2568, total_rewards: 2995.6192, mean_steps: 20.2400, mean_ecr: 0.0387 mean_entropies: 1.5912, took: 110.7708s
2022-10-09 09:30:03,121 [INFO] 	Process 0 - batch 27399: mean_policy_losses: -33.739, mean_net_lifetime: 4939.6087, mean_mc_travel_dist: 1830.4223, mean_rewards: 216.2164, total_rewards: 3148.9774, mean_steps: 23.5000, mean_ecr: 0.0383 mean_entropies: 1.5777, took: 124.9417s
2022-10-09 09:30:15,773 [INFO] 	Process 3 - batch 27699: mean_policy_losses: -94.032, mean_net_lifetime: 4011.7086, mean_mc_travel_dist: 1368.0005, mean_rewards: 216.5245, total_rewards: 2692.8800, mean_steps: 18.8500, mean_ecr: 0.0395 mean_entropies: 1.5173, took: 95.8148s
2022-10-09 09:30:22,452 [INFO] 	Process 6 - batch 27799: mean_policy_losses: -126.008, mean_net_lifetime: 5733.4165, mean_mc_travel_dist: 2167.3739, mean_rewards: 231.0209, total_rewards: 3595.1511, mean_steps: 28.7800, mean_ecr: 0.0390 mean_entropies: 1.5146, took: 148.7430s
2022-10-09 09:30:30,853 [INFO] 	Process 2 - batch 27899: mean_policy_losses: -49.037, mean_net_lifetime: 4500.7287, mean_mc_travel_dist: 1554.5622, mean_rewards: 214.1958, total_rewards: 2986.3758, mean_steps: 21.6700, mean_ecr: 0.0383 mean_entropies: 1.5810, took: 109.9292s
2022-10-09 09:30:31,746 [INFO] 	Process 4 - batch 27699: mean_policy_losses: -200.508, mean_net_lifetime: 3799.9382, mean_mc_travel_dist: 1318.5163, mean_rewards: 221.3559, total_rewards: 2523.3628, mean_steps: 17.9000, mean_ecr: 0.0398 mean_entropies: 1.5111, took: 93.2750s
2022-10-09 09:30:48,045 [INFO] 	Process 5 - batch 27499: mean_policy_losses: -82.313, mean_net_lifetime: 3859.9023, mean_mc_travel_dist: 1288.8272, mean_rewards: 229.6686, total_rewards: 2600.3135, mean_steps: 17.2500, mean_ecr: 0.0403 mean_entropies: 1.4317, took: 89.3281s
2022-10-09 09:31:39,967 [INFO] 	Process 0 - batch 27499: mean_policy_losses: -178.792, mean_net_lifetime: 4040.0909, mean_mc_travel_dist: 1370.1401, mean_rewards: 234.5831, total_rewards: 2704.7756, mean_steps: 18.7500, mean_ecr: 0.0398 mean_entropies: 1.4341, took: 96.8456s
2022-10-09 09:32:06,381 [INFO] 	Process 6 - batch 27899: mean_policy_losses: -97.136, mean_net_lifetime: 4396.0596, mean_mc_travel_dist: 1505.8339, mean_rewards: 220.4991, total_rewards: 2923.3625, mean_steps: 20.2500, mean_ecr: 0.0380 mean_entropies: 1.6058, took: 103.9293s
2022-10-09 09:32:08,858 [INFO] 	Process 4 - batch 27799: mean_policy_losses: -53.082, mean_net_lifetime: 4235.5216, mean_mc_travel_dist: 1417.6528, mean_rewards: 240.3167, total_rewards: 2847.6020, mean_steps: 18.7800, mean_ecr: 0.0389 mean_entropies: 1.5562, took: 97.1117s
2022-10-09 09:32:09,724 [INFO] 	Process 2 - batch 27999: mean_policy_losses: -69.257, mean_net_lifetime: 4276.1299, mean_mc_travel_dist: 1463.7380, mean_rewards: 227.4428, total_rewards: 2850.9959, mean_steps: 19.2200, mean_ecr: 0.0399 mean_entropies: 1.5903, took: 98.8727s
2022-10-09 09:32:12,570 [INFO] 	Process 3 - batch 27799: mean_policy_losses: -195.805, mean_net_lifetime: 4830.0880, mean_mc_travel_dist: 1831.3184, mean_rewards: 230.4123, total_rewards: 3035.6733, mean_steps: 23.3000, mean_ecr: 0.0390 mean_entropies: 1.5461, took: 116.7981s
2022-10-09 09:32:36,648 [INFO] 	Process 5 - batch 27599: mean_policy_losses: -141.418, mean_net_lifetime: 4498.1429, mean_mc_travel_dist: 1594.7133, mean_rewards: 227.8467, total_rewards: 2941.3877, mean_steps: 21.2000, mean_ecr: 0.0384 mean_entropies: 1.5659, took: 108.6019s
2022-10-09 09:33:28,643 [INFO] 	Process 0 - batch 27599: mean_policy_losses: -151.066, mean_net_lifetime: 4488.9274, mean_mc_travel_dist: 1588.1824, mean_rewards: 225.3464, total_rewards: 2934.8904, mean_steps: 21.0300, mean_ecr: 0.0385 mean_entropies: 1.5582, took: 108.6773s
2022-10-09 09:33:44,796 [INFO] 	Process 6 - batch 27999: mean_policy_losses: -59.957, mean_net_lifetime: 4199.0485, mean_mc_travel_dist: 1424.1574, mean_rewards: 227.3354, total_rewards: 2803.1669, mean_steps: 19.0200, mean_ecr: 0.0400 mean_entropies: 1.6199, took: 98.4151s
2022-10-09 09:33:55,706 [INFO] 	Process 4 - batch 27899: mean_policy_losses: -42.951, mean_net_lifetime: 4524.0963, mean_mc_travel_dist: 1566.2712, mean_rewards: 222.6457, total_rewards: 2992.3623, mean_steps: 20.6600, mean_ecr: 0.0381 mean_entropies: 1.6088, took: 106.8479s
2022-10-09 09:33:57,559 [INFO] 	Process 3 - batch 27899: mean_policy_losses: -53.151, mean_net_lifetime: 4380.4164, mean_mc_travel_dist: 1522.5911, mean_rewards: 221.5294, total_rewards: 2895.7619, mean_steps: 20.1700, mean_ecr: 0.0381 mean_entropies: 1.6198, took: 104.9885s
2022-10-09 09:34:05,866 [INFO] 	Process 2 - batch 28099: mean_policy_losses: -110.929, mean_net_lifetime: 4767.6605, mean_mc_travel_dist: 1689.3310, mean_rewards: 229.1307, total_rewards: 3111.5633, mean_steps: 23.1100, mean_ecr: 0.0401 mean_entropies: 1.5213, took: 116.1426s
2022-10-09 09:34:19,148 [INFO] 	Process 5 - batch 27699: mean_policy_losses: -91.943, mean_net_lifetime: 4285.5708, mean_mc_travel_dist: 1487.7216, mean_rewards: 229.7145, total_rewards: 2834.5926, mean_steps: 19.2500, mean_ecr: 0.0395 mean_entropies: 1.5836, took: 102.5010s
2022-10-09 09:34:39,617 [INFO] 	Process 1 - batch 28599: mean_policy_losses: -61.354, mean_net_lifetime: 4257.3095, mean_mc_travel_dist: 1511.8468, mean_rewards: 214.8324, total_rewards: 2781.0762, mean_steps: 20.1900, mean_ecr: 0.0389 mean_entropies: 1.5712, took: 722.6855s
2022-10-09 09:35:08,240 [INFO] 	Process 0 - batch 27699: mean_policy_losses: -145.402, mean_net_lifetime: 4030.4045, mean_mc_travel_dist: 1401.7190, mean_rewards: 218.3914, total_rewards: 2670.6526, mean_steps: 18.9800, mean_ecr: 0.0395 mean_entropies: 1.5884, took: 99.5972s
2022-10-09 09:35:34,202 [INFO] 	Process 4 - batch 27999: mean_policy_losses: -51.770, mean_net_lifetime: 4225.1087, mean_mc_travel_dist: 1424.7253, mean_rewards: 234.0115, total_rewards: 2838.8965, mean_steps: 18.5000, mean_ecr: 0.0401 mean_entropies: 1.6032, took: 98.4962s
2022-10-09 09:35:43,149 [INFO] 	Process 3 - batch 27999: mean_policy_losses: -89.269, mean_net_lifetime: 4295.3119, mean_mc_travel_dist: 1484.7888, mean_rewards: 218.3198, total_rewards: 2849.1502, mean_steps: 19.8200, mean_ecr: 0.0397 mean_entropies: 1.6044, took: 105.5906s
2022-10-09 09:36:06,434 [INFO] 	Process 2 - batch 28199: mean_policy_losses: -86.092, mean_net_lifetime: 4742.3272, mean_mc_travel_dist: 1746.1719, mean_rewards: 208.9728, total_rewards: 3028.6066, mean_steps: 23.2000, mean_ecr: 0.0374 mean_entropies: 1.6135, took: 120.5670s
2022-10-09 09:36:12,301 [INFO] 	Process 6 - batch 28099: mean_policy_losses: -85.257, mean_net_lifetime: 6019.7948, mean_mc_travel_dist: 2078.6912, mean_rewards: 235.6106, total_rewards: 3980.3531, mean_steps: 29.1400, mean_ecr: 0.0401 mean_entropies: 1.5190, took: 147.5043s
2022-10-09 09:36:27,764 [INFO] 	Process 1 - batch 28699: mean_policy_losses: -22.469, mean_net_lifetime: 4608.2372, mean_mc_travel_dist: 1601.9167, mean_rewards: 221.5497, total_rewards: 3047.7480, mean_steps: 21.7000, mean_ecr: 0.0407 mean_entropies: 1.5105, took: 108.1469s
2022-10-09 09:37:11,196 [INFO] 	Process 0 - batch 27799: mean_policy_losses: -112.550, mean_net_lifetime: 5099.9740, mean_mc_travel_dist: 1835.6292, mean_rewards: 236.1832, total_rewards: 3292.1916, mean_steps: 23.4100, mean_ecr: 0.0392 mean_entropies: 1.5586, took: 122.9559s
2022-10-09 09:37:13,912 [INFO] 	Process 4 - batch 28099: mean_policy_losses: -116.339, mean_net_lifetime: 4280.3073, mean_mc_travel_dist: 1451.8342, mean_rewards: 231.9529, total_rewards: 2867.1018, mean_steps: 19.2200, mean_ecr: 0.0401 mean_entropies: 1.5000, took: 99.7095s
2022-10-09 09:37:18,919 [INFO] 	Process 5 - batch 27799: mean_policy_losses: -24.004, mean_net_lifetime: 7210.9540, mean_mc_travel_dist: 2916.2473, mean_rewards: 234.2395, total_rewards: 4328.1486, mean_steps: 35.9000, mean_ecr: 0.0389 mean_entropies: 1.5516, took: 179.7693s
2022-10-09 09:37:29,630 [INFO] 	Process 3 - batch 28099: mean_policy_losses: -105.219, mean_net_lifetime: 4473.5447, mean_mc_travel_dist: 1560.3183, mean_rewards: 238.5674, total_rewards: 2944.7148, mean_steps: 20.4800, mean_ecr: 0.0402 mean_entropies: 1.4939, took: 106.4808s
2022-10-09 09:37:50,205 [INFO] 	Process 2 - batch 28299: mean_policy_losses: -112.720, mean_net_lifetime: 4382.9974, mean_mc_travel_dist: 1529.9870, mean_rewards: 232.8511, total_rewards: 2891.6658, mean_steps: 19.1700, mean_ecr: 0.0392 mean_entropies: 1.5141, took: 103.7714s
2022-10-09 09:37:59,907 [INFO] 	Process 1 - batch 28799: mean_policy_losses: -140.891, mean_net_lifetime: 3969.1419, mean_mc_travel_dist: 1319.9492, mean_rewards: 229.6069, total_rewards: 2680.5920, mean_steps: 18.0700, mean_ecr: 0.0397 mean_entropies: 1.5310, took: 92.1424s
2022-10-09 09:38:17,042 [INFO] 	Process 6 - batch 28199: mean_policy_losses: -114.139, mean_net_lifetime: 4981.1653, mean_mc_travel_dist: 1831.3102, mean_rewards: 220.5993, total_rewards: 3193.9452, mean_steps: 23.9300, mean_ecr: 0.0372 mean_entropies: 1.5620, took: 124.7421s
2022-10-09 09:38:58,885 [INFO] 	Process 0 - batch 27899: mean_policy_losses: -103.357, mean_net_lifetime: 4429.8523, mean_mc_travel_dist: 1539.4030, mean_rewards: 218.0858, total_rewards: 2930.7526, mean_steps: 20.4000, mean_ecr: 0.0384 mean_entropies: 1.5690, took: 107.6888s
2022-10-09 09:39:05,670 [INFO] 	Process 5 - batch 27899: mean_policy_losses: -100.093, mean_net_lifetime: 4413.6304, mean_mc_travel_dist: 1532.6298, mean_rewards: 220.6244, total_rewards: 2918.1301, mean_steps: 20.4000, mean_ecr: 0.0383 mean_entropies: 1.5808, took: 106.7525s
2022-10-09 09:39:19,017 [INFO] 	Process 3 - batch 28199: mean_policy_losses: -39.681, mean_net_lifetime: 4467.3015, mean_mc_travel_dist: 1602.2967, mean_rewards: 220.3466, total_rewards: 2912.2681, mean_steps: 21.3200, mean_ecr: 0.0374 mean_entropies: 1.5498, took: 109.3876s
2022-10-09 09:39:20,650 [INFO] 	Process 4 - batch 28199: mean_policy_losses: -22.029, mean_net_lifetime: 5141.1269, mean_mc_travel_dist: 1906.1421, mean_rewards: 220.7218, total_rewards: 3278.3456, mean_steps: 24.4600, mean_ecr: 0.0375 mean_entropies: 1.5550, took: 126.7368s
2022-10-09 09:39:37,273 [INFO] 	Process 2 - batch 28399: mean_policy_losses: -63.186, mean_net_lifetime: 4426.7549, mean_mc_travel_dist: 1543.4697, mean_rewards: 228.0732, total_rewards: 2920.1506, mean_steps: 20.2100, mean_ecr: 0.0400 mean_entropies: 1.5091, took: 107.0677s
2022-10-09 09:39:41,810 [INFO] 	Process 1 - batch 28899: mean_policy_losses: -59.228, mean_net_lifetime: 4360.3029, mean_mc_travel_dist: 1510.2931, mean_rewards: 223.5311, total_rewards: 2883.6366, mean_steps: 20.2500, mean_ecr: 0.0408 mean_entropies: 1.5605, took: 101.9039s
2022-10-09 09:39:58,011 [INFO] 	Process 6 - batch 28299: mean_policy_losses: -37.736, mean_net_lifetime: 4469.7594, mean_mc_travel_dist: 1588.8164, mean_rewards: 233.8499, total_rewards: 2922.5919, mean_steps: 19.6300, mean_ecr: 0.0387 mean_entropies: 1.4872, took: 100.9677s
2022-10-09 09:40:35,419 [INFO] 	Process 0 - batch 27999: mean_policy_losses: -95.889, mean_net_lifetime: 4169.4067, mean_mc_travel_dist: 1442.2446, mean_rewards: 237.3258, total_rewards: 2757.0080, mean_steps: 18.1000, mean_ecr: 0.0397 mean_entropies: 1.5677, took: 96.5343s
2022-10-09 09:40:39,235 [INFO] 	Process 5 - batch 27999: mean_policy_losses: -111.518, mean_net_lifetime: 4065.9910, mean_mc_travel_dist: 1379.9227, mean_rewards: 239.6643, total_rewards: 2733.1880, mean_steps: 17.7000, mean_ecr: 0.0401 mean_entropies: 1.5607, took: 93.5650s
2022-10-09 09:41:02,020 [INFO] 	Process 3 - batch 28299: mean_policy_losses: -39.803, mean_net_lifetime: 4548.3890, mean_mc_travel_dist: 1620.8016, mean_rewards: 235.1095, total_rewards: 2960.7852, mean_steps: 19.9100, mean_ecr: 0.0388 mean_entropies: 1.5098, took: 103.0015s
2022-10-09 09:41:12,119 [INFO] 	Process 1 - batch 28999: mean_policy_losses: -160.520, mean_net_lifetime: 3934.5788, mean_mc_travel_dist: 1345.0515, mean_rewards: 236.0223, total_rewards: 2635.2425, mean_steps: 17.9100, mean_ecr: 0.0398 mean_entropies: 1.5144, took: 90.3084s
2022-10-09 09:41:13,955 [INFO] 	Process 4 - batch 28299: mean_policy_losses: -87.104, mean_net_lifetime: 4874.2796, mean_mc_travel_dist: 1771.7456, mean_rewards: 231.9722, total_rewards: 3141.8535, mean_steps: 22.0800, mean_ecr: 0.0389 mean_entropies: 1.5227, took: 113.3062s
2022-10-09 09:41:15,662 [INFO] 	Process 2 - batch 28499: mean_policy_losses: -66.994, mean_net_lifetime: 4179.2103, mean_mc_travel_dist: 1421.7420, mean_rewards: 232.6023, total_rewards: 2797.6235, mean_steps: 18.2600, mean_ecr: 0.0395 mean_entropies: 1.5565, took: 98.3894s
2022-10-09 09:41:42,540 [INFO] 	Process 6 - batch 28399: mean_policy_losses: -59.143, mean_net_lifetime: 4416.7463, mean_mc_travel_dist: 1537.0503, mean_rewards: 225.5603, total_rewards: 2920.2903, mean_steps: 20.0900, mean_ecr: 0.0402 mean_entropies: 1.5090, took: 104.5303s
2022-10-09 09:42:25,178 [INFO] 	Process 0 - batch 28099: mean_policy_losses: -82.999, mean_net_lifetime: 4584.6296, mean_mc_travel_dist: 1593.1710, mean_rewards: 230.8472, total_rewards: 3027.6890, mean_steps: 21.5600, mean_ecr: 0.0403 mean_entropies: 1.5040, took: 109.7577s
2022-10-09 09:42:41,369 [INFO] 	Process 1 - batch 29099: mean_policy_losses: -197.172, mean_net_lifetime: 3789.4689, mean_mc_travel_dist: 1281.3550, mean_rewards: 225.4382, total_rewards: 2543.2688, mean_steps: 18.1700, mean_ecr: 0.0403 mean_entropies: 1.4462, took: 89.2500s
2022-10-09 09:42:51,006 [INFO] 	Process 3 - batch 28399: mean_policy_losses: -5.291, mean_net_lifetime: 4536.2439, mean_mc_travel_dist: 1577.9783, mean_rewards: 222.9871, total_rewards: 2995.9691, mean_steps: 21.5900, mean_ecr: 0.0399 mean_entropies: 1.4885, took: 108.9864s
2022-10-09 09:43:02,290 [INFO] 	Process 4 - batch 28399: mean_policy_losses: -21.643, mean_net_lifetime: 4565.6319, mean_mc_travel_dist: 1594.1078, mean_rewards: 223.5533, total_rewards: 3010.3770, mean_steps: 21.5100, mean_ecr: 0.0401 mean_entropies: 1.4963, took: 108.3351s
2022-10-09 09:43:05,241 [INFO] 	Process 5 - batch 28099: mean_policy_losses: -96.901, mean_net_lifetime: 6105.0312, mean_mc_travel_dist: 2181.6528, mean_rewards: 225.8896, total_rewards: 3960.7966, mean_steps: 29.4800, mean_ecr: 0.0404 mean_entropies: 1.4895, took: 146.0068s
2022-10-09 09:43:30,895 [INFO] 	Process 6 - batch 28499: mean_policy_losses: -125.447, mean_net_lifetime: 4463.6241, mean_mc_travel_dist: 1534.5415, mean_rewards: 223.0901, total_rewards: 2962.1173, mean_steps: 21.2600, mean_ecr: 0.0394 mean_entropies: 1.5438, took: 108.3539s
2022-10-09 09:44:19,039 [INFO] 	Process 1 - batch 29199: mean_policy_losses: -135.002, mean_net_lifetime: 4298.1289, mean_mc_travel_dist: 1503.8081, mean_rewards: 218.3940, total_rewards: 2830.8959, mean_steps: 20.4300, mean_ecr: 0.0385 mean_entropies: 1.6082, took: 97.6702s
2022-10-09 09:44:19,235 [INFO] 	Process 0 - batch 28199: mean_policy_losses: -42.512, mean_net_lifetime: 4670.0967, mean_mc_travel_dist: 1704.7783, mean_rewards: 210.3113, total_rewards: 3006.2266, mean_steps: 23.0100, mean_ecr: 0.0376 mean_entropies: 1.5821, took: 114.0580s
2022-10-09 09:44:32,818 [INFO] 	Process 3 - batch 28499: mean_policy_losses: -44.009, mean_net_lifetime: 4493.2410, mean_mc_travel_dist: 1531.8588, mean_rewards: 228.1372, total_rewards: 2989.2305, mean_steps: 20.6700, mean_ecr: 0.0393 mean_entropies: 1.5561, took: 101.8128s
2022-10-09 09:44:35,739 [INFO] 	Process 4 - batch 28499: mean_policy_losses: -165.784, mean_net_lifetime: 4272.4139, mean_mc_travel_dist: 1488.5262, mean_rewards: 234.8497, total_rewards: 2820.0334, mean_steps: 19.1000, mean_ecr: 0.0391 mean_entropies: 1.5546, took: 93.4489s
2022-10-09 09:45:06,632 [INFO] 	Process 5 - batch 28199: mean_policy_losses: -67.469, mean_net_lifetime: 5288.8304, mean_mc_travel_dist: 1947.7411, mean_rewards: 220.5841, total_rewards: 3374.5191, mean_steps: 25.5600, mean_ecr: 0.0370 mean_entropies: 1.5861, took: 121.3891s
2022-10-09 09:45:51,887 [INFO] 	Process 1 - batch 29299: mean_policy_losses: -144.807, mean_net_lifetime: 4611.6835, mean_mc_travel_dist: 1615.3768, mean_rewards: 226.9323, total_rewards: 3031.9330, mean_steps: 20.8900, mean_ecr: 0.0390 mean_entropies: 1.5639, took: 92.8483s
2022-10-09 09:45:58,893 [INFO] 	Process 0 - batch 28299: mean_policy_losses: -71.849, mean_net_lifetime: 4834.5876, mean_mc_travel_dist: 1703.9973, mean_rewards: 236.8825, total_rewards: 3175.2162, mean_steps: 21.2200, mean_ecr: 0.0388 mean_entropies: 1.4792, took: 99.6584s
2022-10-09 09:46:36,618 [INFO] 	Process 5 - batch 28299: mean_policy_losses: -123.065, mean_net_lifetime: 4285.2736, mean_mc_travel_dist: 1512.3985, mean_rewards: 229.8306, total_rewards: 2808.5363, mean_steps: 19.1200, mean_ecr: 0.0391 mean_entropies: 1.4958, took: 89.9877s
2022-10-09 09:47:09,975 [INFO] 	Process 1 - batch 29399: mean_policy_losses: -161.955, mean_net_lifetime: 3913.4232, mean_mc_travel_dist: 1313.6199, mean_rewards: 230.9170, total_rewards: 2636.4576, mean_steps: 17.6600, mean_ecr: 0.0401 mean_entropies: 1.4855, took: 78.0875s
2022-10-09 09:47:37,385 [INFO] 	Process 0 - batch 28399: mean_policy_losses: -86.181, mean_net_lifetime: 4611.6193, mean_mc_travel_dist: 1627.4297, mean_rewards: 227.1804, total_rewards: 3015.6801, mean_steps: 21.4800, mean_ecr: 0.0404 mean_entropies: 1.4932, took: 98.4921s
2022-10-09 09:48:16,227 [INFO] 	Process 5 - batch 28399: mean_policy_losses: -55.433, mean_net_lifetime: 4609.8537, mean_mc_travel_dist: 1595.3588, mean_rewards: 229.1790, total_rewards: 3050.9933, mean_steps: 21.4300, mean_ecr: 0.0400 mean_entropies: 1.5161, took: 99.6085s
2022-10-09 09:48:36,450 [INFO] 	Process 1 - batch 29499: mean_policy_losses: -103.513, mean_net_lifetime: 4345.0731, mean_mc_travel_dist: 1531.0522, mean_rewards: 221.6225, total_rewards: 2857.6044, mean_steps: 19.9400, mean_ecr: 0.0394 mean_entropies: 1.5143, took: 86.4751s
2022-10-09 09:49:09,839 [INFO] 	Process 0 - batch 28499: mean_policy_losses: -30.855, mean_net_lifetime: 4407.1306, mean_mc_travel_dist: 1520.9551, mean_rewards: 228.5542, total_rewards: 2927.1224, mean_steps: 20.1000, mean_ecr: 0.0392 mean_entropies: 1.5213, took: 92.4528s
2022-10-09 09:49:41,348 [INFO] 	Process 5 - batch 28499: mean_policy_losses: -124.342, mean_net_lifetime: 4131.3068, mean_mc_travel_dist: 1396.9791, mean_rewards: 233.6048, total_rewards: 2777.7116, mean_steps: 18.7500, mean_ecr: 0.0395 mean_entropies: 1.5144, took: 85.1210s
2022-10-09 09:50:07,129 [INFO] 	Process 1 - batch 29599: mean_policy_losses: -50.756, mean_net_lifetime: 4533.1159, mean_mc_travel_dist: 1543.4133, mean_rewards: 221.4611, total_rewards: 3036.1099, mean_steps: 21.6600, mean_ecr: 0.0399 mean_entropies: 1.4890, took: 90.6793s
2022-10-09 09:51:19,585 [INFO] 	Process 1 - batch 29699: mean_policy_losses: -204.408, mean_net_lifetime: 3854.0014, mean_mc_travel_dist: 1272.5998, mean_rewards: 230.3485, total_rewards: 2605.6803, mean_steps: 17.8200, mean_ecr: 0.0400 mean_entropies: 1.5107, took: 72.4555s
2022-10-09 09:52:38,983 [INFO] 	Process 1 - batch 29799: mean_policy_losses: -41.820, mean_net_lifetime: 4358.2044, mean_mc_travel_dist: 1541.3087, mean_rewards: 221.2658, total_rewards: 2853.3732, mean_steps: 19.8000, mean_ecr: 0.0376 mean_entropies: 1.6013, took: 79.3982s
2022-10-09 09:54:07,417 [INFO] 	Process 1 - batch 29899: mean_policy_losses: -77.998, mean_net_lifetime: 4631.8431, mean_mc_travel_dist: 1648.0429, mean_rewards: 229.4855, total_rewards: 3023.9622, mean_steps: 21.6100, mean_ecr: 0.0389 mean_entropies: 1.5571, took: 88.4344s
2022-10-09 09:54:48,738 [INFO] 	Process 2 - batch 28599: mean_policy_losses: -79.516, mean_net_lifetime: 4520.0377, mean_mc_travel_dist: 1549.5347, mean_rewards: 216.8054, total_rewards: 3003.5270, mean_steps: 20.9100, mean_ecr: 0.0390 mean_entropies: 1.5562, took: 813.0760s
2022-10-09 09:55:28,522 [INFO] 	Process 1 - batch 29999: mean_policy_losses: -141.323, mean_net_lifetime: 4062.2179, mean_mc_travel_dist: 1415.1205, mean_rewards: 230.0141, total_rewards: 2694.4487, mean_steps: 18.4500, mean_ecr: 0.0393 mean_entropies: 1.5367, took: 81.1049s
2022-10-09 09:55:57,876 [INFO] 	Process 6 - batch 28599: mean_policy_losses: -55.470, mean_net_lifetime: 4265.1395, mean_mc_travel_dist: 1495.3289, mean_rewards: 221.4620, total_rewards: 2810.8870, mean_steps: 19.6300, mean_ecr: 0.0390 mean_entropies: 1.5491, took: 746.9817s
2022-10-09 09:56:16,995 [INFO] 	Process 2 - batch 28699: mean_policy_losses: 30.993, mean_net_lifetime: 4213.5168, mean_mc_travel_dist: 1432.4728, mean_rewards: 226.2469, total_rewards: 2823.8081, mean_steps: 19.2100, mean_ecr: 0.0408 mean_entropies: 1.5187, took: 88.2567s
2022-10-09 09:57:29,527 [INFO] 	Process 6 - batch 28699: mean_policy_losses: -27.805, mean_net_lifetime: 4377.4091, mean_mc_travel_dist: 1489.1299, mean_rewards: 221.7868, total_rewards: 2924.8573, mean_steps: 20.0500, mean_ecr: 0.0404 mean_entropies: 1.5245, took: 91.6516s
2022-10-09 09:57:46,660 [INFO] 	Process 2 - batch 28799: mean_policy_losses: -129.182, mean_net_lifetime: 4094.0660, mean_mc_travel_dist: 1370.9660, mean_rewards: 229.1685, total_rewards: 2757.1060, mean_steps: 18.6700, mean_ecr: 0.0397 mean_entropies: 1.5350, took: 89.6650s
2022-10-09 09:57:53,395 [INFO] 	Process 4 - batch 28599: mean_policy_losses: -106.623, mean_net_lifetime: 4171.3233, mean_mc_travel_dist: 1444.2645, mean_rewards: 221.9980, total_rewards: 2761.9288, mean_steps: 19.3700, mean_ecr: 0.0393 mean_entropies: 1.5453, took: 797.6559s
2022-10-09 09:58:19,905 [INFO] 	Process 3 - batch 28599: mean_policy_losses: -57.866, mean_net_lifetime: 4571.5247, mean_mc_travel_dist: 1591.0098, mean_rewards: 221.2176, total_rewards: 3013.0579, mean_steps: 21.4100, mean_ecr: 0.0387 mean_entropies: 1.5653, took: 827.0864s
2022-10-09 09:59:08,614 [INFO] 	Process 6 - batch 28799: mean_policy_losses: -66.736, mean_net_lifetime: 4293.5408, mean_mc_travel_dist: 1486.0564, mean_rewards: 220.0708, total_rewards: 2844.2308, mean_steps: 20.8000, mean_ecr: 0.0400 mean_entropies: 1.5232, took: 99.0869s
2022-10-09 09:59:20,097 [INFO] 	Process 2 - batch 28899: mean_policy_losses: -72.244, mean_net_lifetime: 4255.3867, mean_mc_travel_dist: 1446.4271, mean_rewards: 222.7343, total_rewards: 2845.9260, mean_steps: 19.5000, mean_ecr: 0.0410 mean_entropies: 1.5540, took: 93.4373s
2022-10-09 09:59:33,046 [INFO] 	Process 4 - batch 28699: mean_policy_losses: -43.222, mean_net_lifetime: 4353.4919, mean_mc_travel_dist: 1495.1895, mean_rewards: 215.1026, total_rewards: 2901.0532, mean_steps: 20.8200, mean_ecr: 0.0406 mean_entropies: 1.5070, took: 99.6509s
2022-10-09 10:00:04,697 [INFO] 	Process 3 - batch 28699: mean_policy_losses: 2.991, mean_net_lifetime: 4587.7088, mean_mc_travel_dist: 1588.0025, mean_rewards: 219.5920, total_rewards: 3035.5594, mean_steps: 21.9900, mean_ecr: 0.0410 mean_entropies: 1.5152, took: 104.7914s
2022-10-09 10:00:44,808 [INFO] 	Process 6 - batch 28899: mean_policy_losses: -72.052, mean_net_lifetime: 4284.8843, mean_mc_travel_dist: 1460.4657, mean_rewards: 225.2946, total_rewards: 2867.4068, mean_steps: 18.9500, mean_ecr: 0.0410 mean_entropies: 1.5410, took: 96.1931s
2022-10-09 10:00:50,338 [INFO] 	Process 2 - batch 28999: mean_policy_losses: -197.597, mean_net_lifetime: 4013.3679, mean_mc_travel_dist: 1380.6988, mean_rewards: 234.4847, total_rewards: 2670.0704, mean_steps: 17.9200, mean_ecr: 0.0397 mean_entropies: 1.5135, took: 90.2409s
2022-10-09 10:01:05,627 [INFO] 	Process 4 - batch 28799: mean_policy_losses: -89.144, mean_net_lifetime: 4065.2983, mean_mc_travel_dist: 1380.0200, mean_rewards: 231.7254, total_rewards: 2718.7534, mean_steps: 18.4200, mean_ecr: 0.0401 mean_entropies: 1.5389, took: 92.5801s
2022-10-09 10:01:42,472 [INFO] 	Process 3 - batch 28799: mean_policy_losses: -59.773, mean_net_lifetime: 4314.2166, mean_mc_travel_dist: 1497.5707, mean_rewards: 225.9039, total_rewards: 2855.1512, mean_steps: 19.5500, mean_ecr: 0.0396 mean_entropies: 1.5529, took: 97.7758s
2022-10-09 10:02:09,540 [INFO] 	Process 0 - batch 28599: mean_policy_losses: -94.063, mean_net_lifetime: 3949.5079, mean_mc_travel_dist: 1357.5925, mean_rewards: 229.6194, total_rewards: 2629.5356, mean_steps: 17.7700, mean_ecr: 0.0391 mean_entropies: 1.5386, took: 779.7018s
2022-10-09 10:02:20,325 [INFO] 	Process 6 - batch 28999: mean_policy_losses: -149.141, mean_net_lifetime: 3992.5480, mean_mc_travel_dist: 1396.3882, mean_rewards: 236.6828, total_rewards: 2639.5150, mean_steps: 18.1900, mean_ecr: 0.0397 mean_entropies: 1.5073, took: 95.5171s
2022-10-09 10:02:20,538 [INFO] 	Process 2 - batch 29099: mean_policy_losses: -128.485, mean_net_lifetime: 3809.9279, mean_mc_travel_dist: 1303.8649, mean_rewards: 228.7225, total_rewards: 2534.0734, mean_steps: 17.3700, mean_ecr: 0.0402 mean_entropies: 1.4599, took: 90.1987s
2022-10-09 10:02:41,728 [INFO] 	Process 4 - batch 28899: mean_policy_losses: -27.863, mean_net_lifetime: 4184.9262, mean_mc_travel_dist: 1422.1099, mean_rewards: 224.8016, total_rewards: 2806.7591, mean_steps: 18.6800, mean_ecr: 0.0414 mean_entropies: 1.5486, took: 96.1029s
2022-10-09 10:03:01,362 [INFO] 	Process 5 - batch 28599: mean_policy_losses: -147.960, mean_net_lifetime: 4053.0435, mean_mc_travel_dist: 1402.7175, mean_rewards: 218.1962, total_rewards: 2690.1866, mean_steps: 19.4100, mean_ecr: 0.0394 mean_entropies: 1.4972, took: 800.0140s
2022-10-09 10:03:18,648 [INFO] 	Process 3 - batch 28899: mean_policy_losses: -122.014, mean_net_lifetime: 4019.2394, mean_mc_travel_dist: 1399.8117, mean_rewards: 224.8252, total_rewards: 2656.3152, mean_steps: 18.5900, mean_ecr: 0.0408 mean_entropies: 1.5565, took: 96.1765s
2022-10-09 10:03:47,814 [INFO] 	Process 0 - batch 28699: mean_policy_losses: -41.063, mean_net_lifetime: 4063.9389, mean_mc_travel_dist: 1415.0216, mean_rewards: 224.0592, total_rewards: 2682.0013, mean_steps: 18.8000, mean_ecr: 0.0407 mean_entropies: 1.4691, took: 98.2720s
2022-10-09 10:03:55,201 [INFO] 	Process 6 - batch 29099: mean_policy_losses: -80.287, mean_net_lifetime: 3983.2125, mean_mc_travel_dist: 1373.4215, mean_rewards: 222.3271, total_rewards: 2639.2362, mean_steps: 18.5100, mean_ecr: 0.0400 mean_entropies: 1.4791, took: 94.8762s
2022-10-09 10:04:00,052 [INFO] 	Process 2 - batch 29199: mean_policy_losses: -131.501, mean_net_lifetime: 4294.5130, mean_mc_travel_dist: 1515.5721, mean_rewards: 227.0364, total_rewards: 2817.9290, mean_steps: 19.4000, mean_ecr: 0.0384 mean_entropies: 1.5778, took: 99.5144s
2022-10-09 10:04:09,986 [INFO] 	Process 4 - batch 28999: mean_policy_losses: -88.416, mean_net_lifetime: 3869.8895, mean_mc_travel_dist: 1349.5031, mean_rewards: 239.5525, total_rewards: 2565.4072, mean_steps: 17.0400, mean_ecr: 0.0399 mean_entropies: 1.4888, took: 88.2572s
2022-10-09 10:04:43,905 [INFO] 	Process 5 - batch 28699: mean_policy_losses: 34.061, mean_net_lifetime: 4286.8883, mean_mc_travel_dist: 1507.2110, mean_rewards: 225.6603, total_rewards: 2812.2765, mean_steps: 19.7400, mean_ecr: 0.0402 mean_entropies: 1.5296, took: 102.5424s
2022-10-09 10:04:50,840 [INFO] 	Process 3 - batch 28999: mean_policy_losses: -19.092, mean_net_lifetime: 3972.4616, mean_mc_travel_dist: 1400.2755, mean_rewards: 237.6547, total_rewards: 2624.5075, mean_steps: 17.4200, mean_ecr: 0.0397 mean_entropies: 1.4889, took: 92.1906s
2022-10-09 10:05:18,337 [INFO] 	Process 0 - batch 28799: mean_policy_losses: -161.960, mean_net_lifetime: 3708.0669, mean_mc_travel_dist: 1299.3264, mean_rewards: 224.2336, total_rewards: 2450.1806, mean_steps: 16.8700, mean_ecr: 0.0400 mean_entropies: 1.5239, took: 90.5252s
2022-10-09 10:05:36,687 [INFO] 	Process 6 - batch 29199: mean_policy_losses: -123.277, mean_net_lifetime: 4221.2849, mean_mc_travel_dist: 1506.8054, mean_rewards: 220.5486, total_rewards: 2752.4522, mean_steps: 19.5200, mean_ecr: 0.0383 mean_entropies: 1.5775, took: 101.4865s
2022-10-09 10:05:41,386 [INFO] 	Process 2 - batch 29299: mean_policy_losses: -68.494, mean_net_lifetime: 4325.4421, mean_mc_travel_dist: 1522.1334, mean_rewards: 235.0018, total_rewards: 2834.1400, mean_steps: 18.9500, mean_ecr: 0.0390 mean_entropies: 1.5537, took: 101.3352s
2022-10-09 10:05:48,467 [INFO] 	Process 4 - batch 29099: mean_policy_losses: -130.907, mean_net_lifetime: 3960.3497, mean_mc_travel_dist: 1394.5814, mean_rewards: 222.4358, total_rewards: 2613.6781, mean_steps: 18.5000, mean_ecr: 0.0403 mean_entropies: 1.4816, took: 98.4804s
2022-10-09 10:06:23,350 [INFO] 	Process 5 - batch 28799: mean_policy_losses: -80.428, mean_net_lifetime: 3955.0865, mean_mc_travel_dist: 1344.3324, mean_rewards: 218.4560, total_rewards: 2646.0144, mean_steps: 18.8900, mean_ecr: 0.0401 mean_entropies: 1.5296, took: 99.4459s
2022-10-09 10:06:32,581 [INFO] 	Process 3 - batch 29099: mean_policy_losses: -93.941, mean_net_lifetime: 4087.6275, mean_mc_travel_dist: 1407.4113, mean_rewards: 217.0866, total_rewards: 2717.7784, mean_steps: 19.7800, mean_ecr: 0.0400 mean_entropies: 1.4472, took: 101.7410s
2022-10-09 10:06:58,240 [INFO] 	Process 0 - batch 28899: mean_policy_losses: -85.934, mean_net_lifetime: 4078.4182, mean_mc_travel_dist: 1394.5051, mean_rewards: 223.9419, total_rewards: 2724.6957, mean_steps: 18.5200, mean_ecr: 0.0406 mean_entropies: 1.5236, took: 99.9020s
2022-10-09 10:07:18,517 [INFO] 	Process 2 - batch 29399: mean_policy_losses: -103.908, mean_net_lifetime: 4004.3383, mean_mc_travel_dist: 1383.6302, mean_rewards: 227.5529, total_rewards: 2660.8510, mean_steps: 18.2300, mean_ecr: 0.0402 mean_entropies: 1.4603, took: 97.1313s
2022-10-09 10:07:21,983 [INFO] 	Process 6 - batch 29299: mean_policy_losses: -56.713, mean_net_lifetime: 4410.5970, mean_mc_travel_dist: 1523.2554, mean_rewards: 230.1241, total_rewards: 2918.9876, mean_steps: 19.8800, mean_ecr: 0.0390 mean_entropies: 1.5544, took: 105.2953s
2022-10-09 10:07:37,761 [INFO] 	Process 4 - batch 29199: mean_policy_losses: -86.267, mean_net_lifetime: 4364.2624, mean_mc_travel_dist: 1531.0768, mean_rewards: 219.6693, total_rewards: 2871.3602, mean_steps: 20.9600, mean_ecr: 0.0384 mean_entropies: 1.5834, took: 109.2940s
2022-10-09 10:08:02,775 [INFO] 	Process 5 - batch 28899: mean_policy_losses: -122.103, mean_net_lifetime: 4065.6407, mean_mc_travel_dist: 1394.1595, mean_rewards: 222.3662, total_rewards: 2706.0275, mean_steps: 18.4700, mean_ecr: 0.0411 mean_entropies: 1.5285, took: 99.4245s
2022-10-09 10:08:25,093 [INFO] 	Process 1 - batch 30099: mean_policy_losses: -177.329, mean_net_lifetime: 4348.9774, mean_mc_travel_dist: 1594.7892, mean_rewards: 219.1596, total_rewards: 2799.6465, mean_steps: 21.0100, mean_ecr: 0.0379 mean_entropies: 1.4828, took: 776.5702s
2022-10-09 10:08:28,657 [INFO] 	Process 3 - batch 29199: mean_policy_losses: -148.196, mean_net_lifetime: 4602.0036, mean_mc_travel_dist: 1668.8864, mean_rewards: 222.0706, total_rewards: 2974.2120, mean_steps: 22.2600, mean_ecr: 0.0384 mean_entropies: 1.5674, took: 116.0759s
2022-10-09 10:08:39,020 [INFO] 	Process 0 - batch 28999: mean_policy_losses: -158.717, mean_net_lifetime: 3950.7867, mean_mc_travel_dist: 1378.0542, mean_rewards: 229.4362, total_rewards: 2614.8515, mean_steps: 18.7000, mean_ecr: 0.0397 mean_entropies: 1.4681, took: 100.7808s
2022-10-09 10:09:01,427 [INFO] 	Process 6 - batch 29399: mean_policy_losses: -109.658, mean_net_lifetime: 4202.1673, mean_mc_travel_dist: 1445.9136, mean_rewards: 238.1766, total_rewards: 2795.2046, mean_steps: 18.5700, mean_ecr: 0.0407 mean_entropies: 1.4798, took: 99.4450s
2022-10-09 10:09:03,320 [INFO] 	Process 2 - batch 29499: mean_policy_losses: -14.969, mean_net_lifetime: 4284.7881, mean_mc_travel_dist: 1488.9273, mean_rewards: 220.0258, total_rewards: 2837.2831, mean_steps: 19.7800, mean_ecr: 0.0393 mean_entropies: 1.4957, took: 104.8022s
2022-10-09 10:09:31,831 [INFO] 	Process 4 - batch 29299: mean_policy_losses: -56.214, mean_net_lifetime: 4719.4731, mean_mc_travel_dist: 1684.2251, mean_rewards: 223.0189, total_rewards: 3068.3356, mean_steps: 21.9900, mean_ecr: 0.0388 mean_entropies: 1.5669, took: 114.0695s
2022-10-09 10:09:39,759 [INFO] 	Process 5 - batch 28999: mean_policy_losses: -118.553, mean_net_lifetime: 4010.3261, mean_mc_travel_dist: 1397.7359, mean_rewards: 233.5203, total_rewards: 2647.0325, mean_steps: 18.3600, mean_ecr: 0.0397 mean_entropies: 1.5098, took: 96.9845s
2022-10-09 10:09:57,003 [INFO] 	Process 1 - batch 30199: mean_policy_losses: -187.562, mean_net_lifetime: 4065.3406, mean_mc_travel_dist: 1405.4199, mean_rewards: 231.2093, total_rewards: 2712.0893, mean_steps: 18.3000, mean_ecr: 0.0382 mean_entropies: 1.5607, took: 91.9112s
2022-10-09 10:10:12,566 [INFO] 	Process 0 - batch 29099: mean_policy_losses: -42.806, mean_net_lifetime: 3896.0485, mean_mc_travel_dist: 1322.0889, mean_rewards: 231.6012, total_rewards: 2611.7078, mean_steps: 17.4100, mean_ecr: 0.0397 mean_entropies: 1.4630, took: 93.5450s
2022-10-09 10:10:18,790 [INFO] 	Process 3 - batch 29299: mean_policy_losses: -46.637, mean_net_lifetime: 4691.4180, mean_mc_travel_dist: 1678.5916, mean_rewards: 229.1411, total_rewards: 3052.1058, mean_steps: 21.1900, mean_ecr: 0.0388 mean_entropies: 1.5660, took: 110.1333s
2022-10-09 10:10:51,064 [INFO] 	Process 6 - batch 29499: mean_policy_losses: 6.121, mean_net_lifetime: 4462.8669, mean_mc_travel_dist: 1549.6645, mean_rewards: 219.3533, total_rewards: 2953.8982, mean_steps: 20.8800, mean_ecr: 0.0385 mean_entropies: 1.5325, took: 109.6357s
2022-10-09 10:10:55,696 [INFO] 	Process 2 - batch 29599: mean_policy_losses: -40.698, mean_net_lifetime: 4504.7309, mean_mc_travel_dist: 1533.9857, mean_rewards: 224.6512, total_rewards: 3004.7233, mean_steps: 21.3700, mean_ecr: 0.0401 mean_entropies: 1.5315, took: 112.3760s
2022-10-09 10:11:05,457 [INFO] 	Process 4 - batch 29399: mean_policy_losses: -129.977, mean_net_lifetime: 3839.4452, mean_mc_travel_dist: 1295.0922, mean_rewards: 233.1628, total_rewards: 2579.3169, mean_steps: 17.3000, mean_ecr: 0.0407 mean_entropies: 1.4764, took: 93.6270s
2022-10-09 10:11:20,648 [INFO] 	Process 5 - batch 29099: mean_policy_losses: -68.878, mean_net_lifetime: 4112.6219, mean_mc_travel_dist: 1389.1714, mean_rewards: 230.4072, total_rewards: 2761.9619, mean_steps: 19.2200, mean_ecr: 0.0402 mean_entropies: 1.4687, took: 100.8881s
2022-10-09 10:11:26,890 [INFO] 	Process 1 - batch 30299: mean_policy_losses: -141.299, mean_net_lifetime: 3895.5568, mean_mc_travel_dist: 1322.7812, mean_rewards: 224.7012, total_rewards: 2621.9387, mean_steps: 17.9000, mean_ecr: 0.0400 mean_entropies: 1.4961, took: 89.8867s
2022-10-09 10:11:47,995 [INFO] 	Process 3 - batch 29399: mean_policy_losses: -120.643, mean_net_lifetime: 3873.6044, mean_mc_travel_dist: 1293.5554, mean_rewards: 242.7736, total_rewards: 2616.8612, mean_steps: 16.9300, mean_ecr: 0.0403 mean_entropies: 1.4642, took: 89.2056s
2022-10-09 10:12:12,408 [INFO] 	Process 0 - batch 29199: mean_policy_losses: -108.423, mean_net_lifetime: 4669.5374, mean_mc_travel_dist: 1646.0751, mean_rewards: 221.0917, total_rewards: 3054.0798, mean_steps: 22.5700, mean_ecr: 0.0385 mean_entropies: 1.5735, took: 119.8426s
2022-10-09 10:12:27,499 [INFO] 	Process 6 - batch 29599: mean_policy_losses: -138.621, mean_net_lifetime: 3925.6326, mean_mc_travel_dist: 1294.9384, mean_rewards: 223.4243, total_rewards: 2657.2655, mean_steps: 18.3600, mean_ecr: 0.0408 mean_entropies: 1.4758, took: 96.4361s
2022-10-09 10:12:35,828 [INFO] 	Process 2 - batch 29699: mean_policy_losses: -77.875, mean_net_lifetime: 4158.1894, mean_mc_travel_dist: 1382.0985, mean_rewards: 225.6611, total_rewards: 2805.6176, mean_steps: 19.0900, mean_ecr: 0.0397 mean_entropies: 1.4967, took: 100.1328s
2022-10-09 10:12:51,125 [INFO] 	Process 4 - batch 29499: mean_policy_losses: -99.948, mean_net_lifetime: 4189.0285, mean_mc_travel_dist: 1458.3226, mean_rewards: 213.2527, total_rewards: 2772.1148, mean_steps: 20.3400, mean_ecr: 0.0390 mean_entropies: 1.5007, took: 105.6682s
2022-10-09 10:13:05,890 [INFO] 	Process 1 - batch 30399: mean_policy_losses: -61.972, mean_net_lifetime: 4219.1094, mean_mc_travel_dist: 1438.5612, mean_rewards: 219.7052, total_rewards: 2817.7934, mean_steps: 19.8400, mean_ecr: 0.0383 mean_entropies: 1.5683, took: 98.9997s
2022-10-09 10:13:10,952 [INFO] 	Process 5 - batch 29199: mean_policy_losses: -3.657, mean_net_lifetime: 4459.1275, mean_mc_travel_dist: 1528.2307, mean_rewards: 218.4853, total_rewards: 2965.0638, mean_steps: 20.9000, mean_ecr: 0.0383 mean_entropies: 1.5681, took: 110.3050s
2022-10-09 10:13:37,183 [INFO] 	Process 3 - batch 29499: mean_policy_losses: -0.589, mean_net_lifetime: 4380.3683, mean_mc_travel_dist: 1534.8299, mean_rewards: 217.8894, total_rewards: 2890.8622, mean_steps: 20.8900, mean_ecr: 0.0391 mean_entropies: 1.4789, took: 109.1870s
2022-10-09 10:14:00,576 [INFO] 	Process 0 - batch 29299: mean_policy_losses: -91.675, mean_net_lifetime: 4503.5160, mean_mc_travel_dist: 1544.9722, mean_rewards: 230.9510, total_rewards: 2994.2460, mean_steps: 20.2400, mean_ecr: 0.0391 mean_entropies: 1.5280, took: 108.1671s
2022-10-09 10:14:10,534 [INFO] 	Process 6 - batch 29699: mean_policy_losses: -110.206, mean_net_lifetime: 4239.1429, mean_mc_travel_dist: 1424.6933, mean_rewards: 226.5253, total_rewards: 2850.8083, mean_steps: 19.6400, mean_ecr: 0.0398 mean_entropies: 1.4792, took: 103.0345s
2022-10-09 10:14:28,489 [INFO] 	Process 4 - batch 29599: mean_policy_losses: -134.493, mean_net_lifetime: 4005.2022, mean_mc_travel_dist: 1334.1025, mean_rewards: 229.8650, total_rewards: 2708.9303, mean_steps: 18.4000, mean_ecr: 0.0404 mean_entropies: 1.4616, took: 97.3637s
2022-10-09 10:14:40,432 [INFO] 	Process 2 - batch 29799: mean_policy_losses: -157.573, mean_net_lifetime: 5076.2066, mean_mc_travel_dist: 1826.5289, mean_rewards: 224.7801, total_rewards: 3291.4272, mean_steps: 24.0900, mean_ecr: 0.0377 mean_entropies: 1.5334, took: 124.6040s
2022-10-09 10:14:54,905 [INFO] 	Process 5 - batch 29299: mean_policy_losses: -134.181, mean_net_lifetime: 4334.6079, mean_mc_travel_dist: 1491.1369, mean_rewards: 234.0260, total_rewards: 2889.3502, mean_steps: 19.5100, mean_ecr: 0.0389 mean_entropies: 1.5440, took: 103.9527s
2022-10-09 10:15:03,562 [INFO] 	Process 1 - batch 30499: mean_policy_losses: 10.544, mean_net_lifetime: 5031.0415, mean_mc_travel_dist: 1796.4584, mean_rewards: 224.6462, total_rewards: 3274.1049, mean_steps: 23.8900, mean_ecr: 0.0394 mean_entropies: 1.5058, took: 117.6723s
2022-10-09 10:15:32,545 [INFO] 	Process 3 - batch 29599: mean_policy_losses: -98.440, mean_net_lifetime: 4516.4716, mean_mc_travel_dist: 1552.1565, mean_rewards: 219.6859, total_rewards: 3002.8552, mean_steps: 22.3400, mean_ecr: 0.0406 mean_entropies: 1.4971, took: 115.3625s
2022-10-09 10:15:37,285 [INFO] 	Process 0 - batch 29399: mean_policy_losses: -90.385, mean_net_lifetime: 4212.8569, mean_mc_travel_dist: 1459.0242, mean_rewards: 242.1334, total_rewards: 2782.2589, mean_steps: 18.2200, mean_ecr: 0.0401 mean_entropies: 1.4693, took: 96.7103s
2022-10-09 10:16:08,289 [INFO] 	Process 4 - batch 29699: mean_policy_losses: -74.085, mean_net_lifetime: 4250.8301, mean_mc_travel_dist: 1446.0738, mean_rewards: 228.0984, total_rewards: 2843.9611, mean_steps: 19.0100, mean_ecr: 0.0398 mean_entropies: 1.5355, took: 99.8006s
2022-10-09 10:16:09,277 [INFO] 	Process 6 - batch 29799: mean_policy_losses: -155.011, mean_net_lifetime: 4913.6372, mean_mc_travel_dist: 1766.3439, mean_rewards: 221.7495, total_rewards: 3186.2802, mean_steps: 22.9700, mean_ecr: 0.0374 mean_entropies: 1.5698, took: 118.7397s
2022-10-09 10:16:28,703 [INFO] 	Process 2 - batch 29899: mean_policy_losses: -46.675, mean_net_lifetime: 4484.0257, mean_mc_travel_dist: 1560.5879, mean_rewards: 226.3387, total_rewards: 2955.8825, mean_steps: 20.8200, mean_ecr: 0.0388 mean_entropies: 1.5300, took: 108.2705s
2022-10-09 10:16:33,442 [INFO] 	Process 5 - batch 29399: mean_policy_losses: -154.327, mean_net_lifetime: 4007.0407, mean_mc_travel_dist: 1353.5186, mean_rewards: 231.6501, total_rewards: 2688.2900, mean_steps: 18.3400, mean_ecr: 0.0405 mean_entropies: 1.4852, took: 98.5371s
2022-10-09 10:16:47,976 [INFO] 	Process 1 - batch 30599: mean_policy_losses: -88.408, mean_net_lifetime: 4706.2990, mean_mc_travel_dist: 1719.5815, mean_rewards: 229.7023, total_rewards: 3033.0779, mean_steps: 21.1000, mean_ecr: 0.0384 mean_entropies: 1.5320, took: 104.4141s
2022-10-09 10:17:11,537 [INFO] 	Process 3 - batch 29699: mean_policy_losses: -175.054, mean_net_lifetime: 4173.0891, mean_mc_travel_dist: 1400.1267, mean_rewards: 236.9103, total_rewards: 2797.2927, mean_steps: 18.7200, mean_ecr: 0.0399 mean_entropies: 1.4558, took: 98.9928s
2022-10-09 10:17:23,546 [INFO] 	Process 0 - batch 29499: mean_policy_losses: -25.870, mean_net_lifetime: 4313.3951, mean_mc_travel_dist: 1480.7286, mean_rewards: 218.8386, total_rewards: 2871.1302, mean_steps: 20.2700, mean_ecr: 0.0395 mean_entropies: 1.4784, took: 106.2603s
2022-10-09 10:17:58,933 [INFO] 	Process 4 - batch 29799: mean_policy_losses: -168.710, mean_net_lifetime: 4623.5374, mean_mc_travel_dist: 1633.1503, mean_rewards: 224.5623, total_rewards: 3022.2297, mean_steps: 20.8400, mean_ecr: 0.0376 mean_entropies: 1.5516, took: 110.6442s
2022-10-09 10:17:59,462 [INFO] 	Process 6 - batch 29899: mean_policy_losses: -84.334, mean_net_lifetime: 4555.2671, mean_mc_travel_dist: 1593.0310, mean_rewards: 229.3582, total_rewards: 3002.7976, mean_steps: 21.3400, mean_ecr: 0.0389 mean_entropies: 1.5249, took: 110.1881s
2022-10-09 10:18:20,197 [INFO] 	Process 5 - batch 29499: mean_policy_losses: -60.330, mean_net_lifetime: 4300.8162, mean_mc_travel_dist: 1478.0213, mean_rewards: 214.4591, total_rewards: 2857.4691, mean_steps: 20.3000, mean_ecr: 0.0387 mean_entropies: 1.5202, took: 106.7550s
2022-10-09 10:18:23,541 [INFO] 	Process 2 - batch 29999: mean_policy_losses: -85.382, mean_net_lifetime: 4549.6787, mean_mc_travel_dist: 1617.8215, mean_rewards: 225.6182, total_rewards: 2973.1076, mean_steps: 21.9300, mean_ecr: 0.0394 mean_entropies: 1.5304, took: 114.8376s
2022-10-09 10:18:34,514 [INFO] 	Process 1 - batch 30699: mean_policy_losses: -149.967, mean_net_lifetime: 4704.2351, mean_mc_travel_dist: 1682.0063, mean_rewards: 237.3018, total_rewards: 3062.6833, mean_steps: 21.6400, mean_ecr: 0.0391 mean_entropies: 1.5115, took: 106.5382s
2022-10-09 10:18:55,670 [INFO] 	Process 0 - batch 29599: mean_policy_losses: -106.261, mean_net_lifetime: 3859.9503, mean_mc_travel_dist: 1272.7989, mean_rewards: 231.3248, total_rewards: 2619.1205, mean_steps: 17.3600, mean_ecr: 0.0403 mean_entropies: 1.4883, took: 92.1245s
2022-10-09 10:18:59,389 [INFO] 	Process 3 - batch 29799: mean_policy_losses: -144.737, mean_net_lifetime: 4646.4777, mean_mc_travel_dist: 1680.6142, mean_rewards: 231.0676, total_rewards: 3002.5698, mean_steps: 20.7400, mean_ecr: 0.0377 mean_entropies: 1.5861, took: 107.8517s
2022-10-09 10:19:33,644 [INFO] 	Process 6 - batch 29999: mean_policy_losses: -27.782, mean_net_lifetime: 4183.0263, mean_mc_travel_dist: 1433.9330, mean_rewards: 237.2307, total_rewards: 2783.9424, mean_steps: 18.1900, mean_ecr: 0.0396 mean_entropies: 1.5446, took: 94.1824s
2022-10-09 10:19:43,697 [INFO] 	Process 4 - batch 29899: mean_policy_losses: -8.872, mean_net_lifetime: 4582.7052, mean_mc_travel_dist: 1591.4438, mean_rewards: 234.9607, total_rewards: 3031.5792, mean_steps: 20.6400, mean_ecr: 0.0391 mean_entropies: 1.5494, took: 104.7633s
2022-10-09 10:19:49,437 [INFO] 	Process 5 - batch 29599: mean_policy_losses: -127.790, mean_net_lifetime: 3876.8129, mean_mc_travel_dist: 1279.2343, mean_rewards: 226.9140, total_rewards: 2636.9233, mean_steps: 17.3200, mean_ecr: 0.0407 mean_entropies: 1.5034, took: 89.2407s
2022-10-09 10:20:19,524 [INFO] 	Process 1 - batch 30799: mean_policy_losses: -29.480, mean_net_lifetime: 4694.0477, mean_mc_travel_dist: 1683.3947, mean_rewards: 219.2378, total_rewards: 3057.1787, mean_steps: 22.1900, mean_ecr: 0.0385 mean_entropies: 1.5965, took: 105.0096s
2022-10-09 10:20:33,203 [INFO] 	Process 0 - batch 29699: mean_policy_losses: -137.725, mean_net_lifetime: 4272.6594, mean_mc_travel_dist: 1423.3489, mean_rewards: 232.5686, total_rewards: 2884.2175, mean_steps: 19.2200, mean_ecr: 0.0403 mean_entropies: 1.5363, took: 97.5335s
2022-10-09 10:20:36,269 [INFO] 	Process 3 - batch 29899: mean_policy_losses: -103.179, mean_net_lifetime: 4320.1030, mean_mc_travel_dist: 1516.7641, mean_rewards: 231.1899, total_rewards: 2843.5115, mean_steps: 19.3300, mean_ecr: 0.0388 mean_entropies: 1.5492, took: 96.8789s
2022-10-09 10:21:22,281 [INFO] 	Process 4 - batch 29999: mean_policy_losses: -55.620, mean_net_lifetime: 4274.9875, mean_mc_travel_dist: 1484.6890, mean_rewards: 225.3811, total_rewards: 2840.3923, mean_steps: 20.0300, mean_ecr: 0.0394 mean_entropies: 1.5251, took: 98.5839s
2022-10-09 10:21:23,677 [INFO] 	Process 5 - batch 29699: mean_policy_losses: -134.266, mean_net_lifetime: 4167.7769, mean_mc_travel_dist: 1415.9338, mean_rewards: 227.8726, total_rewards: 2781.0862, mean_steps: 19.1100, mean_ecr: 0.0399 mean_entropies: 1.5145, took: 94.2367s
2022-10-09 10:22:10,609 [INFO] 	Process 0 - batch 29799: mean_policy_losses: -126.907, mean_net_lifetime: 4422.5437, mean_mc_travel_dist: 1554.9137, mean_rewards: 230.4241, total_rewards: 2902.3834, mean_steps: 19.8000, mean_ecr: 0.0375 mean_entropies: 1.5527, took: 97.4051s
2022-10-09 10:22:11,843 [INFO] 	Process 3 - batch 29999: mean_policy_losses: -147.978, mean_net_lifetime: 4193.4646, mean_mc_travel_dist: 1488.8364, mean_rewards: 229.3789, total_rewards: 2736.1984, mean_steps: 19.7600, mean_ecr: 0.0396 mean_entropies: 1.5248, took: 95.5754s
2022-10-09 10:22:27,666 [INFO] 	Process 1 - batch 30899: mean_policy_losses: -96.846, mean_net_lifetime: 5558.8374, mean_mc_travel_dist: 2259.3712, mean_rewards: 223.9114, total_rewards: 3338.6748, mean_steps: 29.0000, mean_ecr: 0.0398 mean_entropies: 1.5751, took: 128.1410s
2022-10-09 10:22:58,037 [INFO] 	Process 5 - batch 29799: mean_policy_losses: -98.483, mean_net_lifetime: 4599.2970, mean_mc_travel_dist: 1642.5400, mean_rewards: 233.3874, total_rewards: 2990.4221, mean_steps: 20.1000, mean_ecr: 0.0376 mean_entropies: 1.5540, took: 94.3624s
2022-10-09 10:23:45,394 [INFO] 	Process 0 - batch 29899: mean_policy_losses: -113.911, mean_net_lifetime: 4603.9141, mean_mc_travel_dist: 1646.8510, mean_rewards: 233.9818, total_rewards: 2991.9639, mean_steps: 20.8000, mean_ecr: 0.0390 mean_entropies: 1.4914, took: 94.7848s
2022-10-09 10:23:49,110 [INFO] 	Process 1 - batch 30999: mean_policy_losses: -116.211, mean_net_lifetime: 4173.5307, mean_mc_travel_dist: 1386.7504, mean_rewards: 231.3185, total_rewards: 2819.0974, mean_steps: 18.5400, mean_ecr: 0.0405 mean_entropies: 1.5171, took: 81.4439s
2022-10-09 10:24:30,107 [INFO] 	Process 5 - batch 29899: mean_policy_losses: -89.914, mean_net_lifetime: 4286.7286, mean_mc_travel_dist: 1514.7790, mean_rewards: 230.8501, total_rewards: 2802.1702, mean_steps: 19.6400, mean_ecr: 0.0391 mean_entropies: 1.4861, took: 92.0700s
2022-10-09 10:25:22,819 [INFO] 	Process 0 - batch 29999: mean_policy_losses: -114.188, mean_net_lifetime: 4417.0139, mean_mc_travel_dist: 1575.6714, mean_rewards: 222.4868, total_rewards: 2877.0134, mean_steps: 21.1600, mean_ecr: 0.0393 mean_entropies: 1.5147, took: 97.4251s
2022-10-09 10:25:28,584 [INFO] 	Process 1 - batch 31099: mean_policy_losses: -112.013, mean_net_lifetime: 4773.5132, mean_mc_travel_dist: 1727.4821, mean_rewards: 215.5110, total_rewards: 3086.2011, mean_steps: 23.1900, mean_ecr: 0.0387 mean_entropies: 1.5289, took: 99.4745s
2022-10-09 10:26:04,719 [INFO] 	Process 5 - batch 29999: mean_policy_losses: -84.738, mean_net_lifetime: 4330.1196, mean_mc_travel_dist: 1495.5965, mean_rewards: 223.1447, total_rewards: 2885.1218, mean_steps: 20.7800, mean_ecr: 0.0394 mean_entropies: 1.5006, took: 94.6121s
2022-10-09 10:27:33,068 [INFO] 	Process 1 - batch 31199: mean_policy_losses: -68.501, mean_net_lifetime: 6271.7179, mean_mc_travel_dist: 2563.2388, mean_rewards: 223.6558, total_rewards: 3745.3156, mean_steps: 32.1300, mean_ecr: 0.0379 mean_entropies: 1.5441, took: 124.4845s
2022-10-09 10:29:02,790 [INFO] 	Process 1 - batch 31299: mean_policy_losses: -103.558, mean_net_lifetime: 4646.8426, mean_mc_travel_dist: 1679.4917, mean_rewards: 221.6905, total_rewards: 2999.9706, mean_steps: 22.8400, mean_ecr: 0.0395 mean_entropies: 1.5336, took: 89.7223s
2022-10-09 10:30:35,856 [INFO] 	Process 1 - batch 31399: mean_policy_losses: -59.666, mean_net_lifetime: 4814.9867, mean_mc_travel_dist: 1814.0521, mean_rewards: 220.1322, total_rewards: 3039.5032, mean_steps: 22.9300, mean_ecr: 0.0370 mean_entropies: 1.5836, took: 93.0658s
2022-10-09 10:31:16,766 [INFO] 	Process 2 - batch 30099: mean_policy_losses: -118.785, mean_net_lifetime: 4075.1150, mean_mc_travel_dist: 1422.3310, mean_rewards: 234.9970, total_rewards: 2695.1065, mean_steps: 17.9300, mean_ecr: 0.0380 mean_entropies: 1.4789, took: 773.2248s
2022-10-09 10:31:31,056 [INFO] 	Process 6 - batch 30099: mean_policy_losses: -108.577, mean_net_lifetime: 4079.0022, mean_mc_travel_dist: 1409.4560, mean_rewards: 230.4500, total_rewards: 2705.4252, mean_steps: 18.0500, mean_ecr: 0.0378 mean_entropies: 1.4779, took: 717.4119s
2022-10-09 10:31:57,729 [INFO] 	Process 1 - batch 31499: mean_policy_losses: -72.635, mean_net_lifetime: 4113.1793, mean_mc_travel_dist: 1431.1005, mean_rewards: 233.0915, total_rewards: 2713.0271, mean_steps: 18.5900, mean_ecr: 0.0398 mean_entropies: 1.5005, took: 81.8732s
2022-10-09 10:32:58,459 [INFO] 	Process 2 - batch 30199: mean_policy_losses: -91.144, mean_net_lifetime: 4790.8259, mean_mc_travel_dist: 1678.8498, mean_rewards: 218.6251, total_rewards: 3161.5358, mean_steps: 22.5300, mean_ecr: 0.0380 mean_entropies: 1.5645, took: 101.6937s
2022-10-09 10:33:06,540 [INFO] 	Process 6 - batch 30199: mean_policy_losses: -181.809, mean_net_lifetime: 4470.7534, mean_mc_travel_dist: 1553.7402, mean_rewards: 225.7289, total_rewards: 2953.2156, mean_steps: 21.2800, mean_ecr: 0.0383 mean_entropies: 1.5451, took: 95.4845s
2022-10-09 10:34:19,984 [INFO] 	Process 3 - batch 30099: mean_policy_losses: -77.559, mean_net_lifetime: 4243.7155, mean_mc_travel_dist: 1452.8175, mean_rewards: 233.9965, total_rewards: 2825.3087, mean_steps: 18.4700, mean_ecr: 0.0379 mean_entropies: 1.4893, took: 728.1406s
2022-10-09 10:34:25,378 [INFO] 	Process 2 - batch 30299: mean_policy_losses: -38.755, mean_net_lifetime: 4003.5552, mean_mc_travel_dist: 1372.6567, mean_rewards: 227.3754, total_rewards: 2665.2859, mean_steps: 17.8800, mean_ecr: 0.0401 mean_entropies: 1.5033, took: 86.9194s
2022-10-09 10:34:36,489 [INFO] 	Process 6 - batch 30299: mean_policy_losses: -87.539, mean_net_lifetime: 4061.5978, mean_mc_travel_dist: 1399.4534, mean_rewards: 223.0044, total_rewards: 2706.5295, mean_steps: 18.7800, mean_ecr: 0.0401 mean_entropies: 1.5079, took: 89.9484s
2022-10-09 10:34:53,075 [INFO] 	Process 4 - batch 30099: mean_policy_losses: -58.738, mean_net_lifetime: 4610.9060, mean_mc_travel_dist: 1660.6979, mean_rewards: 231.0613, total_rewards: 2986.0788, mean_steps: 20.8200, mean_ecr: 0.0378 mean_entropies: 1.4674, took: 810.7945s
2022-10-09 10:35:55,870 [INFO] 	Process 3 - batch 30199: mean_policy_losses: -145.499, mean_net_lifetime: 4460.2803, mean_mc_travel_dist: 1529.4820, mean_rewards: 220.2731, total_rewards: 2971.8145, mean_steps: 20.8000, mean_ecr: 0.0381 mean_entropies: 1.5851, took: 95.8851s
2022-10-09 10:36:07,367 [INFO] 	Process 2 - batch 30399: mean_policy_losses: -29.487, mean_net_lifetime: 4704.9603, mean_mc_travel_dist: 1630.7108, mean_rewards: 223.0253, total_rewards: 3113.6377, mean_steps: 21.7000, mean_ecr: 0.0379 mean_entropies: 1.5910, took: 101.9879s
2022-10-09 10:36:10,766 [INFO] 	Process 6 - batch 30399: mean_policy_losses: -76.610, mean_net_lifetime: 4492.2803, mean_mc_travel_dist: 1524.7333, mean_rewards: 228.5294, total_rewards: 3003.6721, mean_steps: 20.2400, mean_ecr: 0.0379 mean_entropies: 1.5600, took: 94.2775s
2022-10-09 10:36:29,502 [INFO] 	Process 4 - batch 30199: mean_policy_losses: -151.372, mean_net_lifetime: 4408.9830, mean_mc_travel_dist: 1511.0695, mean_rewards: 230.6140, total_rewards: 2935.8370, mean_steps: 19.9400, mean_ecr: 0.0380 mean_entropies: 1.6118, took: 96.4258s
2022-10-09 10:37:34,264 [INFO] 	Process 3 - batch 30299: mean_policy_losses: -144.915, mean_net_lifetime: 4323.7283, mean_mc_travel_dist: 1481.9249, mean_rewards: 225.8418, total_rewards: 2878.3911, mean_steps: 19.9900, mean_ecr: 0.0400 mean_entropies: 1.5238, took: 98.3951s
2022-10-09 10:37:57,982 [INFO] 	Process 6 - batch 30499: mean_policy_losses: -26.900, mean_net_lifetime: 4788.8486, mean_mc_travel_dist: 1666.6608, mean_rewards: 220.8396, total_rewards: 3156.6885, mean_steps: 22.4300, mean_ecr: 0.0391 mean_entropies: 1.5398, took: 107.2168s
2022-10-09 10:38:06,852 [INFO] 	Process 4 - batch 30299: mean_policy_losses: -222.013, mean_net_lifetime: 4056.2333, mean_mc_travel_dist: 1413.3161, mean_rewards: 216.7686, total_rewards: 2680.7627, mean_steps: 19.5600, mean_ecr: 0.0402 mean_entropies: 1.4987, took: 97.3514s
2022-10-09 10:38:24,049 [INFO] 	Process 2 - batch 30499: mean_policy_losses: -53.979, mean_net_lifetime: 5895.4988, mean_mc_travel_dist: 2214.1298, mean_rewards: 217.3190, total_rewards: 3725.6886, mean_steps: 28.9700, mean_ecr: 0.0395 mean_entropies: 1.5098, took: 136.6825s
2022-10-09 10:38:36,993 [INFO] 	Process 0 - batch 30099: mean_policy_losses: -170.597, mean_net_lifetime: 4298.6774, mean_mc_travel_dist: 1519.8054, mean_rewards: 221.0616, total_rewards: 2825.1491, mean_steps: 20.3900, mean_ecr: 0.0377 mean_entropies: 1.5287, took: 794.1741s
2022-10-09 10:39:17,544 [INFO] 	Process 3 - batch 30399: mean_policy_losses: -161.708, mean_net_lifetime: 4314.9866, mean_mc_travel_dist: 1505.6586, mean_rewards: 224.7242, total_rewards: 2835.1409, mean_steps: 20.3400, mean_ecr: 0.0381 mean_entropies: 1.5669, took: 103.2787s
2022-10-09 10:39:21,825 [INFO] 	Process 5 - batch 30099: mean_policy_losses: -83.676, mean_net_lifetime: 4468.4764, mean_mc_travel_dist: 1563.8802, mean_rewards: 225.3238, total_rewards: 2940.2278, mean_steps: 20.8000, mean_ecr: 0.0379 mean_entropies: 1.5104, took: 797.1062s
2022-10-09 10:39:43,461 [INFO] 	Process 6 - batch 30599: mean_policy_losses: -36.065, mean_net_lifetime: 4586.9530, mean_mc_travel_dist: 1594.5138, mean_rewards: 229.9837, total_rewards: 3030.9852, mean_steps: 20.7600, mean_ecr: 0.0398 mean_entropies: 1.5108, took: 105.4772s
2022-10-09 10:39:46,783 [INFO] 	Process 4 - batch 30399: mean_policy_losses: -141.818, mean_net_lifetime: 4190.5703, mean_mc_travel_dist: 1450.3726, mean_rewards: 225.5647, total_rewards: 2779.9185, mean_steps: 19.3800, mean_ecr: 0.0380 mean_entropies: 1.5562, took: 99.9310s
2022-10-09 10:40:26,434 [INFO] 	Process 0 - batch 30199: mean_policy_losses: -101.148, mean_net_lifetime: 4547.7375, mean_mc_travel_dist: 1584.5092, mean_rewards: 225.7916, total_rewards: 3005.9648, mean_steps: 21.3100, mean_ecr: 0.0384 mean_entropies: 1.5659, took: 109.4412s
2022-10-09 10:40:35,430 [INFO] 	Process 2 - batch 30599: mean_policy_losses: -26.223, mean_net_lifetime: 5686.6665, mean_mc_travel_dist: 2078.7711, mean_rewards: 233.4261, total_rewards: 3644.0046, mean_steps: 26.7500, mean_ecr: 0.0389 mean_entropies: 1.5476, took: 131.3816s
2022-10-09 10:41:13,808 [INFO] 	Process 5 - batch 30199: mean_policy_losses: -109.459, mean_net_lifetime: 4693.0202, mean_mc_travel_dist: 1617.8979, mean_rewards: 222.9494, total_rewards: 3114.8762, mean_steps: 22.0300, mean_ecr: 0.0381 mean_entropies: 1.5869, took: 111.9832s
2022-10-09 10:41:13,950 [INFO] 	Process 3 - batch 30499: mean_policy_losses: -41.855, mean_net_lifetime: 4873.5636, mean_mc_travel_dist: 1742.2612, mean_rewards: 225.9286, total_rewards: 3161.1454, mean_steps: 23.0700, mean_ecr: 0.0397 mean_entropies: 1.5180, took: 116.4081s
2022-10-09 10:41:24,550 [INFO] 	Process 6 - batch 30699: mean_policy_losses: -140.273, mean_net_lifetime: 4341.5934, mean_mc_travel_dist: 1535.6268, mean_rewards: 229.2799, total_rewards: 2851.7882, mean_steps: 19.7200, mean_ecr: 0.0388 mean_entropies: 1.5375, took: 101.0895s
2022-10-09 10:41:34,776 [INFO] 	Process 4 - batch 30499: mean_policy_losses: -29.420, mean_net_lifetime: 4610.3801, mean_mc_travel_dist: 1612.3677, mean_rewards: 224.9556, total_rewards: 3033.5832, mean_steps: 21.5200, mean_ecr: 0.0393 mean_entropies: 1.5192, took: 107.9922s
2022-10-09 10:42:06,018 [INFO] 	Process 0 - batch 30299: mean_policy_losses: -124.321, mean_net_lifetime: 4141.0260, mean_mc_travel_dist: 1438.4156, mean_rewards: 219.8425, total_rewards: 2739.3384, mean_steps: 19.3500, mean_ecr: 0.0401 mean_entropies: 1.5211, took: 99.5830s
2022-10-09 10:42:27,230 [INFO] 	Process 2 - batch 30699: mean_policy_losses: -180.750, mean_net_lifetime: 4780.7901, mean_mc_travel_dist: 1773.5206, mean_rewards: 227.4066, total_rewards: 3047.2569, mean_steps: 22.2000, mean_ecr: 0.0391 mean_entropies: 1.5192, took: 111.7999s
2022-10-09 10:42:51,086 [INFO] 	Process 5 - batch 30299: mean_policy_losses: -121.136, mean_net_lifetime: 4185.4691, mean_mc_travel_dist: 1440.3182, mean_rewards: 225.8810, total_rewards: 2784.7525, mean_steps: 19.0000, mean_ecr: 0.0398 mean_entropies: 1.5312, took: 97.2781s
2022-10-09 10:43:01,309 [INFO] 	Process 3 - batch 30599: mean_policy_losses: -10.223, mean_net_lifetime: 4657.7138, mean_mc_travel_dist: 1665.7721, mean_rewards: 232.0446, total_rewards: 3041.5100, mean_steps: 20.9900, mean_ecr: 0.0393 mean_entropies: 1.5133, took: 107.3584s
2022-10-09 10:43:23,957 [INFO] 	Process 4 - batch 30599: mean_policy_losses: -53.791, mean_net_lifetime: 4709.0787, mean_mc_travel_dist: 1690.1511, mean_rewards: 228.6719, total_rewards: 3045.7435, mean_steps: 21.4700, mean_ecr: 0.0393 mean_entropies: 1.5203, took: 109.1817s
2022-10-09 10:43:52,598 [INFO] 	Process 0 - batch 30399: mean_policy_losses: -109.934, mean_net_lifetime: 4403.0705, mean_mc_travel_dist: 1593.0494, mean_rewards: 226.1398, total_rewards: 2857.9813, mean_steps: 20.4700, mean_ecr: 0.0380 mean_entropies: 1.5916, took: 106.5803s
2022-10-09 10:44:04,373 [INFO] 	Process 6 - batch 30799: mean_policy_losses: -113.696, mean_net_lifetime: 6373.3099, mean_mc_travel_dist: 2517.5888, mean_rewards: 212.9426, total_rewards: 3897.1847, mean_steps: 33.0100, mean_ecr: 0.0382 mean_entropies: 1.5919, took: 159.8233s
2022-10-09 10:44:20,796 [INFO] 	Process 2 - batch 30799: mean_policy_losses: -44.301, mean_net_lifetime: 4759.1602, mean_mc_travel_dist: 1699.1037, mean_rewards: 222.9830, total_rewards: 3094.4128, mean_steps: 22.3100, mean_ecr: 0.0381 mean_entropies: 1.6064, took: 113.5661s
2022-10-09 10:44:31,423 [INFO] 	Process 5 - batch 30399: mean_policy_losses: -154.815, mean_net_lifetime: 4179.1472, mean_mc_travel_dist: 1429.6514, mean_rewards: 224.8422, total_rewards: 2787.6583, mean_steps: 19.1200, mean_ecr: 0.0381 mean_entropies: 1.5890, took: 100.3357s
2022-10-09 10:45:00,195 [INFO] 	Process 3 - batch 30699: mean_policy_losses: -142.005, mean_net_lifetime: 5082.5133, mean_mc_travel_dist: 1876.0301, mean_rewards: 230.9589, total_rewards: 3242.1029, mean_steps: 23.3000, mean_ecr: 0.0387 mean_entropies: 1.5202, took: 118.8863s
2022-10-09 10:45:20,642 [INFO] 	Process 4 - batch 30699: mean_policy_losses: -117.484, mean_net_lifetime: 4984.3701, mean_mc_travel_dist: 1796.6755, mean_rewards: 233.7039, total_rewards: 3222.4352, mean_steps: 22.5100, mean_ecr: 0.0388 mean_entropies: 1.5308, took: 116.6854s
2022-10-09 10:45:21,551 [INFO] 	Process 1 - batch 31599: mean_policy_losses: -120.332, mean_net_lifetime: 4330.8214, mean_mc_travel_dist: 1543.7283, mean_rewards: 218.0729, total_rewards: 2828.1415, mean_steps: 19.7900, mean_ecr: 0.0379 mean_entropies: 1.5832, took: 803.8209s
2022-10-09 10:46:13,201 [INFO] 	Process 0 - batch 30499: mean_policy_losses: 10.255, mean_net_lifetime: 5721.6054, mean_mc_travel_dist: 2040.5250, mean_rewards: 218.4691, total_rewards: 3715.6193, mean_steps: 27.3700, mean_ecr: 0.0395 mean_entropies: 1.5309, took: 140.6043s
2022-10-09 10:46:54,416 [INFO] 	Process 1 - batch 31699: mean_policy_losses: -155.358, mean_net_lifetime: 3944.3713, mean_mc_travel_dist: 1338.5882, mean_rewards: 229.0234, total_rewards: 2636.4624, mean_steps: 18.0200, mean_ecr: 0.0397 mean_entropies: 1.4412, took: 92.8662s
2022-10-09 10:47:07,069 [INFO] 	Process 6 - batch 30899: mean_policy_losses: -98.078, mean_net_lifetime: 6611.4500, mean_mc_travel_dist: 2719.0948, mean_rewards: 227.6213, total_rewards: 3919.5663, mean_steps: 36.7000, mean_ecr: 0.0397 mean_entropies: 1.5370, took: 182.6959s
2022-10-09 10:47:14,528 [INFO] 	Process 5 - batch 30499: mean_policy_losses: -23.522, mean_net_lifetime: 6614.5787, mean_mc_travel_dist: 2370.8628, mean_rewards: 224.3218, total_rewards: 4278.6617, mean_steps: 32.1100, mean_ecr: 0.0393 mean_entropies: 1.5188, took: 163.1057s
2022-10-09 10:47:45,612 [INFO] 	Process 3 - batch 30799: mean_policy_losses: -160.167, mean_net_lifetime: 6195.4009, mean_mc_travel_dist: 2434.4045, mean_rewards: 207.8527, total_rewards: 3794.5673, mean_steps: 32.7600, mean_ecr: 0.0384 mean_entropies: 1.5491, took: 165.4164s
2022-10-09 10:48:00,066 [INFO] 	Process 2 - batch 30899: mean_policy_losses: -84.675, mean_net_lifetime: 7763.5352, mean_mc_travel_dist: 3277.8672, mean_rewards: 223.9740, total_rewards: 4522.8549, mean_steps: 43.6800, mean_ecr: 0.0396 mean_entropies: 1.5505, took: 219.2699s
2022-10-09 10:48:09,356 [INFO] 	Process 4 - batch 30799: mean_policy_losses: -66.440, mean_net_lifetime: 6272.2887, mean_mc_travel_dist: 2474.0424, mean_rewards: 213.1429, total_rewards: 3839.2215, mean_steps: 33.4100, mean_ecr: 0.0382 mean_entropies: 1.5344, took: 168.7120s
2022-10-09 10:48:10,405 [INFO] 	Process 0 - batch 30599: mean_policy_losses: -50.985, mean_net_lifetime: 4831.8231, mean_mc_travel_dist: 1671.3884, mean_rewards: 232.0838, total_rewards: 3192.4218, mean_steps: 22.0300, mean_ecr: 0.0387 mean_entropies: 1.4984, took: 117.2043s
2022-10-09 10:48:33,271 [INFO] 	Process 1 - batch 31799: mean_policy_losses: -101.925, mean_net_lifetime: 4216.5967, mean_mc_travel_dist: 1474.3079, mean_rewards: 221.2070, total_rewards: 2782.0892, mean_steps: 19.6500, mean_ecr: 0.0378 mean_entropies: 1.5033, took: 98.8540s
2022-10-09 10:48:47,585 [INFO] 	Process 6 - batch 30999: mean_policy_losses: -101.931, mean_net_lifetime: 4203.7204, mean_mc_travel_dist: 1416.6114, mean_rewards: 232.2736, total_rewards: 2812.7752, mean_steps: 18.7900, mean_ecr: 0.0406 mean_entropies: 1.4681, took: 100.5163s
2022-10-09 10:49:34,968 [INFO] 	Process 5 - batch 30599: mean_policy_losses: 43.082, mean_net_lifetime: 5576.7865, mean_mc_travel_dist: 2098.9669, mean_rewards: 225.1235, total_rewards: 3512.9126, mean_steps: 27.0200, mean_ecr: 0.0391 mean_entropies: 1.4744, took: 140.4405s
2022-10-09 10:49:41,596 [INFO] 	Process 2 - batch 30999: mean_policy_losses: -137.475, mean_net_lifetime: 4143.0474, mean_mc_travel_dist: 1403.6463, mean_rewards: 224.8630, total_rewards: 2774.9717, mean_steps: 19.1300, mean_ecr: 0.0406 mean_entropies: 1.4432, took: 101.5293s
2022-10-09 10:50:00,455 [INFO] 	Process 0 - batch 30699: mean_policy_losses: -145.139, mean_net_lifetime: 4503.7502, mean_mc_travel_dist: 1631.6419, mean_rewards: 231.5128, total_rewards: 2917.2966, mean_steps: 20.6500, mean_ecr: 0.0390 mean_entropies: 1.4475, took: 110.0491s
2022-10-09 10:50:05,247 [INFO] 	Process 1 - batch 31899: mean_policy_losses: -135.940, mean_net_lifetime: 3948.1040, mean_mc_travel_dist: 1331.2145, mean_rewards: 228.3423, total_rewards: 2660.1397, mean_steps: 18.1600, mean_ecr: 0.0391 mean_entropies: 1.5285, took: 91.9764s
2022-10-09 10:50:37,187 [INFO] 	Process 3 - batch 30899: mean_policy_losses: 1.860, mean_net_lifetime: 6331.1222, mean_mc_travel_dist: 2637.4605, mean_rewards: 222.8774, total_rewards: 3737.7538, mean_steps: 34.0200, mean_ecr: 0.0395 mean_entropies: 1.4923, took: 171.5756s
2022-10-09 10:50:39,622 [INFO] 	Process 6 - batch 31099: mean_policy_losses: -39.383, mean_net_lifetime: 4496.8974, mean_mc_travel_dist: 1592.1096, mean_rewards: 223.1950, total_rewards: 2938.4167, mean_steps: 21.2400, mean_ecr: 0.0385 mean_entropies: 1.5030, took: 112.0365s
2022-10-09 10:51:21,875 [INFO] 	Process 4 - batch 30899: mean_policy_losses: -142.349, mean_net_lifetime: 7173.0398, mean_mc_travel_dist: 3067.9369, mean_rewards: 233.2382, total_rewards: 4138.6594, mean_steps: 39.4000, mean_ecr: 0.0394 mean_entropies: 1.5079, took: 192.5209s
2022-10-09 10:51:26,389 [INFO] 	Process 5 - batch 30699: mean_policy_losses: -155.358, mean_net_lifetime: 4684.4886, mean_mc_travel_dist: 1646.8279, mean_rewards: 228.2793, total_rewards: 3077.7093, mean_steps: 21.5700, mean_ecr: 0.0392 mean_entropies: 1.4891, took: 111.4217s
2022-10-09 10:51:41,676 [INFO] 	Process 2 - batch 31099: mean_policy_losses: -119.097, mean_net_lifetime: 4807.2803, mean_mc_travel_dist: 1753.3279, mean_rewards: 223.3370, total_rewards: 3087.7144, mean_steps: 22.9300, mean_ecr: 0.0385 mean_entropies: 1.5344, took: 120.0805s
2022-10-09 10:52:14,185 [INFO] 	Process 3 - batch 30999: mean_policy_losses: -87.617, mean_net_lifetime: 4144.9685, mean_mc_travel_dist: 1353.2647, mean_rewards: 228.9686, total_rewards: 2825.7018, mean_steps: 18.4600, mean_ecr: 0.0409 mean_entropies: 1.4819, took: 96.9981s
2022-10-09 10:52:16,406 [INFO] 	Process 0 - batch 30799: mean_policy_losses: -157.083, mean_net_lifetime: 5164.9427, mean_mc_travel_dist: 1933.7025, mean_rewards: 219.7823, total_rewards: 3264.1949, mean_steps: 25.7500, mean_ecr: 0.0385 mean_entropies: 1.5437, took: 135.9509s
2022-10-09 10:52:31,010 [INFO] 	Process 1 - batch 31999: mean_policy_losses: -51.345, mean_net_lifetime: 5941.4531, mean_mc_travel_dist: 2269.8030, mean_rewards: 227.4689, total_rewards: 3715.7970, mean_steps: 29.9400, mean_ecr: 0.0397 mean_entropies: 1.4833, took: 145.7630s
2022-10-09 10:53:05,985 [INFO] 	Process 4 - batch 30999: mean_policy_losses: -72.973, mean_net_lifetime: 4238.7443, mean_mc_travel_dist: 1420.4120, mean_rewards: 226.4409, total_rewards: 2848.9390, mean_steps: 19.3700, mean_ecr: 0.0408 mean_entropies: 1.4643, took: 104.1087s
2022-10-09 10:53:25,477 [INFO] 	Process 5 - batch 30799: mean_policy_losses: -109.185, mean_net_lifetime: 4670.4096, mean_mc_travel_dist: 1655.8298, mean_rewards: 211.9621, total_rewards: 3060.3699, mean_steps: 22.7600, mean_ecr: 0.0381 mean_entropies: 1.5318, took: 119.0877s
2022-10-09 10:53:58,583 [INFO] 	Process 6 - batch 31199: mean_policy_losses: -77.346, mean_net_lifetime: 7372.3262, mean_mc_travel_dist: 3145.5703, mean_rewards: 219.8961, total_rewards: 4261.5588, mean_steps: 39.6600, mean_ecr: 0.0384 mean_entropies: 1.5223, took: 198.9617s
2022-10-09 10:54:14,479 [INFO] 	Process 2 - batch 31199: mean_policy_losses: -117.229, mean_net_lifetime: 5860.3596, mean_mc_travel_dist: 2221.8446, mean_rewards: 223.4672, total_rewards: 3670.8759, mean_steps: 30.0600, mean_ecr: 0.0384 mean_entropies: 1.5297, took: 152.8035s
2022-10-09 10:54:15,155 [INFO] 	Process 1 - batch 32099: mean_policy_losses: -51.949, mean_net_lifetime: 4564.1390, mean_mc_travel_dist: 1561.4468, mean_rewards: 229.9500, total_rewards: 3036.6727, mean_steps: 20.7900, mean_ecr: 0.0404 mean_entropies: 1.4677, took: 104.1450s
2022-10-09 10:54:31,623 [INFO] 	Process 3 - batch 31099: mean_policy_losses: -54.545, mean_net_lifetime: 5404.0801, mean_mc_travel_dist: 2027.1707, mean_rewards: 208.7100, total_rewards: 3407.2940, mean_steps: 27.2600, mean_ecr: 0.0384 mean_entropies: 1.5527, took: 137.4384s
2022-10-09 10:55:17,273 [INFO] 	Process 0 - batch 30899: mean_policy_losses: -86.642, mean_net_lifetime: 6426.7749, mean_mc_travel_dist: 2607.6297, mean_rewards: 220.9498, total_rewards: 3858.5147, mean_steps: 35.5800, mean_ecr: 0.0398 mean_entropies: 1.5330, took: 180.8660s
2022-10-09 10:55:17,994 [INFO] 	Process 4 - batch 31099: mean_policy_losses: -28.738, mean_net_lifetime: 5268.4986, mean_mc_travel_dist: 1911.8076, mean_rewards: 212.5163, total_rewards: 3392.2759, mean_steps: 25.4000, mean_ecr: 0.0385 mean_entropies: 1.5148, took: 132.0102s
2022-10-09 10:55:48,844 [INFO] 	Process 6 - batch 31299: mean_policy_losses: -209.733, mean_net_lifetime: 4348.4498, mean_mc_travel_dist: 1524.2093, mean_rewards: 228.4721, total_rewards: 2859.6881, mean_steps: 20.7700, mean_ecr: 0.0386 mean_entropies: 1.5366, took: 110.2605s
2022-10-09 10:55:51,835 [INFO] 	Process 5 - batch 30899: mean_policy_losses: -151.669, mean_net_lifetime: 5401.8764, mean_mc_travel_dist: 2143.4287, mean_rewards: 227.6587, total_rewards: 3301.1385, mean_steps: 28.7700, mean_ecr: 0.0398 mean_entropies: 1.4939, took: 146.3577s
2022-10-09 10:55:56,294 [INFO] 	Process 1 - batch 32199: mean_policy_losses: -123.156, mean_net_lifetime: 4460.3231, mean_mc_travel_dist: 1547.9565, mean_rewards: 236.4326, total_rewards: 2955.4849, mean_steps: 20.1400, mean_ecr: 0.0402 mean_entropies: 1.4789, took: 101.1387s
2022-10-09 10:56:01,045 [INFO] 	Process 2 - batch 31299: mean_policy_losses: -111.927, mean_net_lifetime: 4383.6803, mean_mc_travel_dist: 1514.2824, mean_rewards: 233.1168, total_rewards: 2904.9579, mean_steps: 20.0100, mean_ecr: 0.0390 mean_entropies: 1.5328, took: 106.5624s
2022-10-09 10:56:30,001 [INFO] 	Process 3 - batch 31199: mean_policy_losses: -49.057, mean_net_lifetime: 4924.7418, mean_mc_travel_dist: 1826.4795, mean_rewards: 224.0386, total_rewards: 3134.6097, mean_steps: 23.1000, mean_ecr: 0.0382 mean_entropies: 1.5382, took: 118.3771s
2022-10-09 10:56:55,876 [INFO] 	Process 0 - batch 30999: mean_policy_losses: -123.973, mean_net_lifetime: 4038.6661, mean_mc_travel_dist: 1330.8100, mean_rewards: 233.7393, total_rewards: 2746.2408, mean_steps: 17.8500, mean_ecr: 0.0406 mean_entropies: 1.4863, took: 98.6045s
2022-10-09 10:57:26,640 [INFO] 	Process 5 - batch 30999: mean_policy_losses: -84.221, mean_net_lifetime: 3954.0359, mean_mc_travel_dist: 1308.9975, mean_rewards: 229.8262, total_rewards: 2686.3983, mean_steps: 17.7800, mean_ecr: 0.0409 mean_entropies: 1.4791, took: 94.8053s
2022-10-09 10:57:35,395 [INFO] 	Process 1 - batch 32299: mean_policy_losses: 7.988, mean_net_lifetime: 4293.0456, mean_mc_travel_dist: 1487.1321, mean_rewards: 225.1995, total_rewards: 2838.5763, mean_steps: 19.7000, mean_ecr: 0.0397 mean_entropies: 1.5059, took: 99.1015s
2022-10-09 10:57:37,059 [INFO] 	Process 4 - batch 31199: mean_policy_losses: -87.823, mean_net_lifetime: 5880.4269, mean_mc_travel_dist: 2396.5073, mean_rewards: 227.0171, total_rewards: 3523.4477, mean_steps: 27.7500, mean_ecr: 0.0384 mean_entropies: 1.5411, took: 139.0651s
2022-10-09 10:58:14,047 [INFO] 	Process 3 - batch 31299: mean_policy_losses: -154.596, mean_net_lifetime: 4169.2397, mean_mc_travel_dist: 1473.1322, mean_rewards: 224.3834, total_rewards: 2734.8411, mean_steps: 19.6600, mean_ecr: 0.0392 mean_entropies: 1.5338, took: 104.0458s
2022-10-09 10:58:18,323 [INFO] 	Process 6 - batch 31399: mean_policy_losses: -65.914, mean_net_lifetime: 6097.0416, mean_mc_travel_dist: 2463.1300, mean_rewards: 224.5417, total_rewards: 3684.2803, mean_steps: 29.5800, mean_ecr: 0.0378 mean_entropies: 1.5212, took: 149.4795s
2022-10-09 10:58:54,887 [INFO] 	Process 0 - batch 31099: mean_policy_losses: -35.571, mean_net_lifetime: 4764.1135, mean_mc_travel_dist: 1722.1347, mean_rewards: 216.8788, total_rewards: 3079.7885, mean_steps: 22.7200, mean_ecr: 0.0388 mean_entropies: 1.5255, took: 119.0104s
2022-10-09 10:59:00,286 [INFO] 	Process 2 - batch 31399: mean_policy_losses: -71.153, mean_net_lifetime: 6939.1994, mean_mc_travel_dist: 2910.0063, mean_rewards: 219.3701, total_rewards: 4065.6903, mean_steps: 36.0500, mean_ecr: 0.0374 mean_entropies: 1.5452, took: 179.2440s
2022-10-09 10:59:23,473 [INFO] 	Process 5 - batch 31099: mean_policy_losses: -48.844, mean_net_lifetime: 4745.6804, mean_mc_travel_dist: 1664.0815, mean_rewards: 223.5761, total_rewards: 3107.6993, mean_steps: 22.3800, mean_ecr: 0.0384 mean_entropies: 1.5415, took: 116.8325s
2022-10-09 10:59:27,753 [INFO] 	Process 4 - batch 31299: mean_policy_losses: -162.416, mean_net_lifetime: 4364.0018, mean_mc_travel_dist: 1538.1935, mean_rewards: 220.0055, total_rewards: 2859.9039, mean_steps: 20.9600, mean_ecr: 0.0389 mean_entropies: 1.5666, took: 110.6939s
2022-10-09 10:59:43,854 [INFO] 	Process 1 - batch 32399: mean_policy_losses: 25.029, mean_net_lifetime: 5300.4318, mean_mc_travel_dist: 1900.2600, mean_rewards: 217.9488, total_rewards: 3441.2663, mean_steps: 26.0900, mean_ecr: 0.0386 mean_entropies: 1.5253, took: 128.4595s
2022-10-09 11:00:01,033 [INFO] 	Process 6 - batch 31499: mean_policy_losses: -63.127, mean_net_lifetime: 4293.0275, mean_mc_travel_dist: 1462.3055, mean_rewards: 230.4248, total_rewards: 2871.4189, mean_steps: 19.2600, mean_ecr: 0.0394 mean_entropies: 1.5130, took: 102.7096s
2022-10-09 11:00:15,712 [INFO] 	Process 3 - batch 31399: mean_policy_losses: -90.890, mean_net_lifetime: 4884.3624, mean_mc_travel_dist: 1868.5500, mean_rewards: 216.6555, total_rewards: 3060.3252, mean_steps: 24.0300, mean_ecr: 0.0373 mean_entropies: 1.5472, took: 121.6651s
2022-10-09 11:00:51,725 [INFO] 	Process 0 - batch 31199: mean_policy_losses: -11.515, mean_net_lifetime: 4825.6636, mean_mc_travel_dist: 1827.0166, mean_rewards: 222.8938, total_rewards: 3045.9507, mean_steps: 22.5500, mean_ecr: 0.0380 mean_entropies: 1.5749, took: 116.8383s
2022-10-09 11:01:06,200 [INFO] 	Process 2 - batch 31499: mean_policy_losses: -51.762, mean_net_lifetime: 5245.7173, mean_mc_travel_dist: 1913.7475, mean_rewards: 226.6466, total_rewards: 3370.9762, mean_steps: 24.3300, mean_ecr: 0.0399 mean_entropies: 1.5162, took: 125.9143s
2022-10-09 11:01:18,505 [INFO] 	Process 4 - batch 31399: mean_policy_losses: -112.007, mean_net_lifetime: 4485.7580, mean_mc_travel_dist: 1650.5777, mean_rewards: 217.6613, total_rewards: 2874.2146, mean_steps: 21.1900, mean_ecr: 0.0375 mean_entropies: 1.5236, took: 110.7517s
2022-10-09 11:01:18,511 [INFO] 	Process 1 - batch 32499: mean_policy_losses: -60.616, mean_net_lifetime: 4301.3782, mean_mc_travel_dist: 1506.3762, mean_rewards: 232.9054, total_rewards: 2838.4429, mean_steps: 19.3500, mean_ecr: 0.0388 mean_entropies: 1.5457, took: 94.6563s
2022-10-09 11:01:53,657 [INFO] 	Process 3 - batch 31499: mean_policy_losses: -39.719, mean_net_lifetime: 4289.1100, mean_mc_travel_dist: 1484.7147, mean_rewards: 230.5282, total_rewards: 2838.2965, mean_steps: 19.4500, mean_ecr: 0.0397 mean_entropies: 1.4901, took: 97.9443s
2022-10-09 11:01:57,468 [INFO] 	Process 5 - batch 31199: mean_policy_losses: 15.819, mean_net_lifetime: 6648.8635, mean_mc_travel_dist: 2763.3651, mean_rewards: 229.1210, total_rewards: 3922.1521, mean_steps: 31.8200, mean_ecr: 0.0384 mean_entropies: 1.5429, took: 153.9949s
2022-10-09 11:02:24,015 [INFO] 	Process 0 - batch 31299: mean_policy_losses: -173.563, mean_net_lifetime: 4018.5222, mean_mc_travel_dist: 1396.4181, mean_rewards: 230.6648, total_rewards: 2674.6938, mean_steps: 18.4100, mean_ecr: 0.0395 mean_entropies: 1.5313, took: 92.2909s
2022-10-09 11:02:53,562 [INFO] 	Process 4 - batch 31499: mean_policy_losses: -56.144, mean_net_lifetime: 4326.4204, mean_mc_travel_dist: 1516.0144, mean_rewards: 227.3093, total_rewards: 2846.2753, mean_steps: 19.7800, mean_ecr: 0.0397 mean_entropies: 1.4842, took: 95.0565s
2022-10-09 11:02:58,402 [INFO] 	Process 1 - batch 32599: mean_policy_losses: -126.783, mean_net_lifetime: 4753.4757, mean_mc_travel_dist: 1728.9529, mean_rewards: 228.9509, total_rewards: 3061.3817, mean_steps: 22.0700, mean_ecr: 0.0397 mean_entropies: 1.4570, took: 99.8907s
2022-10-09 11:03:40,037 [INFO] 	Process 5 - batch 31299: mean_policy_losses: -93.801, mean_net_lifetime: 4622.4073, mean_mc_travel_dist: 1608.2837, mean_rewards: 226.9942, total_rewards: 3055.3119, mean_steps: 21.6300, mean_ecr: 0.0386 mean_entropies: 1.5453, took: 102.5699s
2022-10-09 11:04:08,244 [INFO] 	Process 0 - batch 31399: mean_policy_losses: -106.100, mean_net_lifetime: 4615.8087, mean_mc_travel_dist: 1693.0726, mean_rewards: 224.1972, total_rewards: 2961.5708, mean_steps: 21.7100, mean_ecr: 0.0376 mean_entropies: 1.5305, took: 104.2279s
2022-10-09 11:04:33,413 [INFO] 	Process 1 - batch 32699: mean_policy_losses: -64.009, mean_net_lifetime: 4592.5198, mean_mc_travel_dist: 1637.2494, mean_rewards: 223.4278, total_rewards: 2998.9021, mean_steps: 21.7400, mean_ecr: 0.0382 mean_entropies: 1.5044, took: 95.0115s
2022-10-09 11:05:36,758 [INFO] 	Process 5 - batch 31399: mean_policy_losses: -72.089, mean_net_lifetime: 5490.6661, mean_mc_travel_dist: 2133.8718, mean_rewards: 221.9272, total_rewards: 3399.5506, mean_steps: 25.9800, mean_ecr: 0.0377 mean_entropies: 1.5472, took: 116.7212s
2022-10-09 11:05:37,481 [INFO] 	Process 0 - batch 31499: mean_policy_losses: -144.532, mean_net_lifetime: 4190.5298, mean_mc_travel_dist: 1415.3361, mean_rewards: 235.2169, total_rewards: 2805.3317, mean_steps: 18.4700, mean_ecr: 0.0392 mean_entropies: 1.4652, took: 89.2364s
2022-10-09 11:05:58,140 [INFO] 	Process 1 - batch 32799: mean_policy_losses: -125.525, mean_net_lifetime: 4464.5625, mean_mc_travel_dist: 1550.9962, mean_rewards: 234.2168, total_rewards: 2955.7353, mean_steps: 19.5500, mean_ecr: 0.0395 mean_entropies: 1.5487, took: 84.7270s
2022-10-09 11:07:02,984 [INFO] 	Process 5 - batch 31499: mean_policy_losses: -77.688, mean_net_lifetime: 4435.6866, mean_mc_travel_dist: 1563.9377, mean_rewards: 231.8542, total_rewards: 2906.0999, mean_steps: 19.6300, mean_ecr: 0.0392 mean_entropies: 1.4890, took: 86.2249s
2022-10-09 11:07:43,003 [INFO] 	Process 1 - batch 32899: mean_policy_losses: -55.430, mean_net_lifetime: 5351.1301, mean_mc_travel_dist: 2024.9135, mean_rewards: 224.0861, total_rewards: 3369.5127, mean_steps: 26.1400, mean_ecr: 0.0369 mean_entropies: 1.4683, took: 104.8630s
2022-10-09 11:08:51,829 [INFO] 	Process 1 - batch 32999: mean_policy_losses: -38.201, mean_net_lifetime: 3978.0772, mean_mc_travel_dist: 1386.1266, mean_rewards: 234.4348, total_rewards: 2632.9019, mean_steps: 17.1000, mean_ecr: 0.0398 mean_entropies: 1.4696, took: 68.8263s
2022-10-09 11:12:16,948 [INFO] 	Process 6 - batch 31599: mean_policy_losses: 9.786, mean_net_lifetime: 3807.5101, mean_mc_travel_dist: 1328.5298, mean_rewards: 241.0556, total_rewards: 2512.8502, mean_steps: 15.9800, mean_ecr: 0.0385 mean_entropies: 1.4261, took: 735.9148s
2022-10-09 11:13:40,818 [INFO] 	Process 6 - batch 31699: mean_policy_losses: -24.785, mean_net_lifetime: 4200.5060, mean_mc_travel_dist: 1456.7395, mean_rewards: 226.6657, total_rewards: 2787.5772, mean_steps: 19.0400, mean_ecr: 0.0390 mean_entropies: 1.4371, took: 83.8705s
2022-10-09 11:14:03,003 [INFO] 	Process 2 - batch 31599: mean_policy_losses: -95.757, mean_net_lifetime: 4156.0320, mean_mc_travel_dist: 1477.6387, mean_rewards: 226.5618, total_rewards: 2721.4761, mean_steps: 18.7900, mean_ecr: 0.0383 mean_entropies: 1.4396, took: 776.8025s
2022-10-09 11:15:13,198 [INFO] 	Process 3 - batch 31599: mean_policy_losses: -30.482, mean_net_lifetime: 4284.0232, mean_mc_travel_dist: 1496.6044, mean_rewards: 226.4506, total_rewards: 2820.0772, mean_steps: 19.3000, mean_ecr: 0.0383 mean_entropies: 1.4294, took: 799.5424s
2022-10-09 11:15:23,587 [INFO] 	Process 6 - batch 31799: mean_policy_losses: -48.537, mean_net_lifetime: 4592.0481, mean_mc_travel_dist: 1617.4552, mean_rewards: 218.7207, total_rewards: 3010.2952, mean_steps: 22.2000, mean_ecr: 0.0377 mean_entropies: 1.4298, took: 102.7682s
2022-10-09 11:15:32,662 [INFO] 	Process 2 - batch 31699: mean_policy_losses: -125.279, mean_net_lifetime: 4091.5636, mean_mc_travel_dist: 1426.5774, mean_rewards: 228.2645, total_rewards: 2698.7689, mean_steps: 18.6800, mean_ecr: 0.0393 mean_entropies: 1.4189, took: 89.6598s
2022-10-09 11:15:59,375 [INFO] 	Process 4 - batch 31599: mean_policy_losses: -21.077, mean_net_lifetime: 4531.5029, mean_mc_travel_dist: 1596.6916, mean_rewards: 219.3820, total_rewards: 2974.6918, mean_steps: 21.2600, mean_ecr: 0.0381 mean_entropies: 1.4643, took: 785.8126s
2022-10-09 11:16:47,867 [INFO] 	Process 3 - batch 31699: mean_policy_losses: -84.616, mean_net_lifetime: 4273.7013, mean_mc_travel_dist: 1493.0863, mean_rewards: 222.7198, total_rewards: 2824.2202, mean_steps: 20.1100, mean_ecr: 0.0390 mean_entropies: 1.4446, took: 94.6682s
2022-10-09 11:16:54,333 [INFO] 	Process 6 - batch 31899: mean_policy_losses: -19.587, mean_net_lifetime: 4186.0430, mean_mc_travel_dist: 1424.2649, mean_rewards: 230.3683, total_rewards: 2793.6172, mean_steps: 19.0400, mean_ecr: 0.0391 mean_entropies: 1.5021, took: 90.7462s
2022-10-09 11:17:11,240 [INFO] 	Process 2 - batch 31799: mean_policy_losses: -44.941, mean_net_lifetime: 4432.8387, mean_mc_travel_dist: 1535.7167, mean_rewards: 219.5681, total_rewards: 2935.1908, mean_steps: 20.4300, mean_ecr: 0.0379 mean_entropies: 1.5041, took: 98.5778s
2022-10-09 11:17:28,519 [INFO] 	Process 4 - batch 31699: mean_policy_losses: -145.188, mean_net_lifetime: 3908.7488, mean_mc_travel_dist: 1322.0952, mean_rewards: 231.2131, total_rewards: 2618.4303, mean_steps: 17.7400, mean_ecr: 0.0390 mean_entropies: 1.4872, took: 89.1447s
2022-10-09 11:18:27,123 [INFO] 	Process 0 - batch 31599: mean_policy_losses: -136.458, mean_net_lifetime: 4415.0697, mean_mc_travel_dist: 1552.3598, mean_rewards: 232.0113, total_rewards: 2907.7625, mean_steps: 19.7800, mean_ecr: 0.0384 mean_entropies: 1.5151, took: 769.6428s
2022-10-09 11:18:30,712 [INFO] 	Process 3 - batch 31799: mean_policy_losses: -90.632, mean_net_lifetime: 4429.5893, mean_mc_travel_dist: 1547.0813, mean_rewards: 221.8622, total_rewards: 2917.7679, mean_steps: 20.8900, mean_ecr: 0.0378 mean_entropies: 1.5106, took: 102.8453s
2022-10-09 11:18:52,168 [INFO] 	Process 2 - batch 31899: mean_policy_losses: -94.289, mean_net_lifetime: 4206.5148, mean_mc_travel_dist: 1414.3055, mean_rewards: 228.8532, total_rewards: 2817.6829, mean_steps: 19.3300, mean_ecr: 0.0389 mean_entropies: 1.5296, took: 100.9274s
2022-10-09 11:19:05,599 [INFO] 	Process 5 - batch 31599: mean_policy_losses: -250.895, mean_net_lifetime: 4147.4375, mean_mc_travel_dist: 1437.0328, mean_rewards: 232.8089, total_rewards: 2750.7621, mean_steps: 18.6100, mean_ecr: 0.0388 mean_entropies: 1.4519, took: 722.6154s
2022-10-09 11:19:18,988 [INFO] 	Process 6 - batch 31999: mean_policy_losses: -53.129, mean_net_lifetime: 5793.5898, mean_mc_travel_dist: 2191.9593, mean_rewards: 231.5472, total_rewards: 3637.6353, mean_steps: 30.0100, mean_ecr: 0.0402 mean_entropies: 1.4541, took: 144.6548s
2022-10-09 11:19:19,100 [INFO] 	Process 4 - batch 31799: mean_policy_losses: 3.665, mean_net_lifetime: 4586.7142, mean_mc_travel_dist: 1559.5277, mean_rewards: 219.1332, total_rewards: 3064.5457, mean_steps: 21.4900, mean_ecr: 0.0377 mean_entropies: 1.5307, took: 110.5808s
2022-10-09 11:20:07,918 [INFO] 	Process 3 - batch 31899: mean_policy_losses: -77.041, mean_net_lifetime: 4142.7976, mean_mc_travel_dist: 1385.3790, mean_rewards: 232.2567, total_rewards: 2789.6747, mean_steps: 18.9300, mean_ecr: 0.0391 mean_entropies: 1.5036, took: 97.2063s
2022-10-09 11:20:11,717 [INFO] 	Process 0 - batch 31699: mean_policy_losses: -86.405, mean_net_lifetime: 4394.1162, mean_mc_travel_dist: 1527.2525, mean_rewards: 219.7277, total_rewards: 2907.2526, mean_steps: 20.3100, mean_ecr: 0.0391 mean_entropies: 1.4883, took: 104.5931s
2022-10-09 11:20:57,568 [INFO] 	Process 4 - batch 31899: mean_policy_losses: -171.918, mean_net_lifetime: 4067.4123, mean_mc_travel_dist: 1372.1976, mean_rewards: 229.1198, total_rewards: 2735.5047, mean_steps: 18.4200, mean_ecr: 0.0391 mean_entropies: 1.5275, took: 98.4684s
2022-10-09 11:20:58,833 [INFO] 	Process 5 - batch 31699: mean_policy_losses: -156.545, mean_net_lifetime: 4595.4008, mean_mc_travel_dist: 1676.1718, mean_rewards: 222.8152, total_rewards: 2959.9169, mean_steps: 21.7000, mean_ecr: 0.0389 mean_entropies: 1.4657, took: 113.2304s
2022-10-09 11:21:01,266 [INFO] 	Process 6 - batch 32099: mean_policy_losses: -59.305, mean_net_lifetime: 4305.6028, mean_mc_travel_dist: 1473.6660, mean_rewards: 232.9798, total_rewards: 2874.0335, mean_steps: 19.5300, mean_ecr: 0.0406 mean_entropies: 1.4634, took: 102.2784s
2022-10-09 11:21:16,176 [INFO] 	Process 2 - batch 31999: mean_policy_losses: -134.478, mean_net_lifetime: 5618.3240, mean_mc_travel_dist: 2165.7320, mean_rewards: 224.4922, total_rewards: 3484.7503, mean_steps: 28.6700, mean_ecr: 0.0401 mean_entropies: 1.4182, took: 144.0086s
2022-10-09 11:21:28,408 [INFO] 	Process 1 - batch 33099: mean_policy_losses: -111.681, mean_net_lifetime: 4515.1771, mean_mc_travel_dist: 1544.4920, mean_rewards: 219.9113, total_rewards: 3002.3235, mean_steps: 22.0600, mean_ecr: 0.0394 mean_entropies: 1.3978, took: 756.5783s
2022-10-09 11:22:00,980 [INFO] 	Process 0 - batch 31799: mean_policy_losses: -140.974, mean_net_lifetime: 4350.2390, mean_mc_travel_dist: 1479.5618, mean_rewards: 225.4071, total_rewards: 2902.5662, mean_steps: 20.2400, mean_ecr: 0.0378 mean_entropies: 1.4991, took: 109.2623s
2022-10-09 11:22:39,064 [INFO] 	Process 3 - batch 31999: mean_policy_losses: -50.932, mean_net_lifetime: 5877.1418, mean_mc_travel_dist: 2249.2916, mean_rewards: 225.5461, total_rewards: 3653.4772, mean_steps: 29.9300, mean_ecr: 0.0396 mean_entropies: 1.4706, took: 151.1447s
2022-10-09 11:22:48,832 [INFO] 	Process 6 - batch 32199: mean_policy_losses: -116.764, mean_net_lifetime: 4517.0232, mean_mc_travel_dist: 1525.2291, mean_rewards: 234.4754, total_rewards: 3032.3242, mean_steps: 20.7000, mean_ecr: 0.0401 mean_entropies: 1.4736, took: 107.5663s
2022-10-09 11:22:55,890 [INFO] 	Process 5 - batch 31799: mean_policy_losses: -20.122, mean_net_lifetime: 4734.5171, mean_mc_travel_dist: 1642.2714, mean_rewards: 224.2149, total_rewards: 3130.6569, mean_steps: 22.1000, mean_ecr: 0.0377 mean_entropies: 1.5285, took: 117.0597s
2022-10-09 11:23:02,424 [INFO] 	Process 2 - batch 32099: mean_policy_losses: -2.074, mean_net_lifetime: 4571.4142, mean_mc_travel_dist: 1537.7673, mean_rewards: 234.3225, total_rewards: 3071.2607, mean_steps: 20.4300, mean_ecr: 0.0406 mean_entropies: 1.4946, took: 106.2481s
2022-10-09 11:23:09,707 [INFO] 	Process 4 - batch 31999: mean_policy_losses: -120.273, mean_net_lifetime: 5175.9852, mean_mc_travel_dist: 1930.0712, mean_rewards: 227.3449, total_rewards: 3279.2816, mean_steps: 26.0100, mean_ecr: 0.0401 mean_entropies: 1.4467, took: 132.1390s
2022-10-09 11:23:27,495 [INFO] 	Process 1 - batch 33199: mean_policy_losses: -80.904, mean_net_lifetime: 5015.5415, mean_mc_travel_dist: 1796.4483, mean_rewards: 221.8798, total_rewards: 3262.0727, mean_steps: 24.1400, mean_ecr: 0.0376 mean_entropies: 1.4920, took: 119.0876s
2022-10-09 11:23:53,319 [INFO] 	Process 0 - batch 31899: mean_policy_losses: -67.760, mean_net_lifetime: 4611.8989, mean_mc_travel_dist: 1561.3944, mean_rewards: 232.1284, total_rewards: 3090.6837, mean_steps: 21.1000, mean_ecr: 0.0389 mean_entropies: 1.5406, took: 112.3410s
2022-10-09 11:24:17,901 [INFO] 	Process 3 - batch 32099: mean_policy_losses: -53.377, mean_net_lifetime: 4232.3329, mean_mc_travel_dist: 1401.5302, mean_rewards: 234.0670, total_rewards: 2865.4060, mean_steps: 18.7800, mean_ecr: 0.0407 mean_entropies: 1.4746, took: 98.8386s
2022-10-09 11:24:26,624 [INFO] 	Process 6 - batch 32299: mean_policy_losses: -167.188, mean_net_lifetime: 3928.2401, mean_mc_travel_dist: 1343.4006, mean_rewards: 224.2815, total_rewards: 2621.3309, mean_steps: 18.3100, mean_ecr: 0.0399 mean_entropies: 1.4954, took: 97.7922s
2022-10-09 11:24:29,229 [INFO] 	Process 5 - batch 31899: mean_policy_losses: -196.070, mean_net_lifetime: 3935.4720, mean_mc_travel_dist: 1312.7267, mean_rewards: 229.2388, total_rewards: 2658.7326, mean_steps: 17.6100, mean_ecr: 0.0392 mean_entropies: 1.5048, took: 93.3399s
2022-10-09 11:24:49,973 [INFO] 	Process 2 - batch 32199: mean_policy_losses: -57.880, mean_net_lifetime: 4484.3876, mean_mc_travel_dist: 1519.0452, mean_rewards: 229.5546, total_rewards: 2997.7556, mean_steps: 20.4900, mean_ecr: 0.0400 mean_entropies: 1.4920, took: 107.5481s
2022-10-09 11:24:54,204 [INFO] 	Process 4 - batch 32099: mean_policy_losses: -82.500, mean_net_lifetime: 4540.8439, mean_mc_travel_dist: 1528.4147, mean_rewards: 238.4273, total_rewards: 3047.3889, mean_steps: 20.2300, mean_ecr: 0.0406 mean_entropies: 1.4906, took: 104.4962s
2022-10-09 11:25:18,652 [INFO] 	Process 1 - batch 33299: mean_policy_losses: -150.543, mean_net_lifetime: 4685.0191, mean_mc_travel_dist: 1621.2054, mean_rewards: 222.7328, total_rewards: 3106.4661, mean_steps: 22.4800, mean_ecr: 0.0392 mean_entropies: 1.5355, took: 111.1568s
2022-10-09 11:25:43,429 [INFO] 	Process 0 - batch 31999: mean_policy_losses: -86.340, mean_net_lifetime: 4539.4894, mean_mc_travel_dist: 1564.0099, mean_rewards: 230.9649, total_rewards: 3015.5397, mean_steps: 20.5400, mean_ecr: 0.0400 mean_entropies: 1.4724, took: 110.1094s
2022-10-09 11:25:55,454 [INFO] 	Process 3 - batch 32199: mean_policy_losses: -144.700, mean_net_lifetime: 4141.8299, mean_mc_travel_dist: 1375.7648, mean_rewards: 233.2420, total_rewards: 2809.4111, mean_steps: 18.5300, mean_ecr: 0.0403 mean_entropies: 1.4958, took: 97.5522s
2022-10-09 11:26:24,145 [INFO] 	Process 5 - batch 31999: mean_policy_losses: -122.840, mean_net_lifetime: 4793.8505, mean_mc_travel_dist: 1712.7541, mean_rewards: 230.9723, total_rewards: 3109.8776, mean_steps: 21.8200, mean_ecr: 0.0400 mean_entropies: 1.4961, took: 114.9150s
2022-10-09 11:26:30,634 [INFO] 	Process 6 - batch 32399: mean_policy_losses: -37.309, mean_net_lifetime: 5143.3600, mean_mc_travel_dist: 1816.1358, mean_rewards: 220.8629, total_rewards: 3366.1885, mean_steps: 23.7000, mean_ecr: 0.0387 mean_entropies: 1.5099, took: 124.0090s
2022-10-09 11:26:31,459 [INFO] 	Process 4 - batch 32199: mean_policy_losses: -151.790, mean_net_lifetime: 4016.0179, mean_mc_travel_dist: 1362.5601, mean_rewards: 230.2170, total_rewards: 2697.0365, mean_steps: 18.1500, mean_ecr: 0.0401 mean_entropies: 1.4745, took: 97.2560s
2022-10-09 11:26:40,449 [INFO] 	Process 2 - batch 32299: mean_policy_losses: -135.665, mean_net_lifetime: 4530.2496, mean_mc_travel_dist: 1580.9673, mean_rewards: 231.1504, total_rewards: 2988.4487, mean_steps: 20.9200, mean_ecr: 0.0398 mean_entropies: 1.4943, took: 110.4764s
2022-10-09 11:27:16,250 [INFO] 	Process 1 - batch 33399: mean_policy_losses: -35.652, mean_net_lifetime: 5183.1744, mean_mc_travel_dist: 1862.2423, mean_rewards: 232.8428, total_rewards: 3360.7678, mean_steps: 23.9600, mean_ecr: 0.0381 mean_entropies: 1.5587, took: 117.5985s
2022-10-09 11:27:26,478 [INFO] 	Process 0 - batch 32099: mean_policy_losses: -134.453, mean_net_lifetime: 4401.5399, mean_mc_travel_dist: 1504.1322, mean_rewards: 243.8715, total_rewards: 2943.7904, mean_steps: 19.3300, mean_ecr: 0.0410 mean_entropies: 1.4614, took: 103.0498s
2022-10-09 11:27:36,833 [INFO] 	Process 3 - batch 32299: mean_policy_losses: -70.749, mean_net_lifetime: 4162.5167, mean_mc_travel_dist: 1416.7915, mean_rewards: 225.0630, total_rewards: 2782.6610, mean_steps: 18.9500, mean_ecr: 0.0396 mean_entropies: 1.4852, took: 101.3786s
2022-10-09 11:28:03,296 [INFO] 	Process 5 - batch 32099: mean_policy_losses: -97.288, mean_net_lifetime: 4308.8885, mean_mc_travel_dist: 1448.1649, mean_rewards: 240.2884, total_rewards: 2896.2345, mean_steps: 18.5900, mean_ecr: 0.0410 mean_entropies: 1.4931, took: 99.1520s
2022-10-09 11:28:08,339 [INFO] 	Process 6 - batch 32499: mean_policy_losses: -228.018, mean_net_lifetime: 3910.9280, mean_mc_travel_dist: 1337.1123, mean_rewards: 229.2901, total_rewards: 2613.6270, mean_steps: 18.2300, mean_ecr: 0.0392 mean_entropies: 1.5311, took: 97.7055s
2022-10-09 11:28:19,495 [INFO] 	Process 4 - batch 32299: mean_policy_losses: -161.926, mean_net_lifetime: 4313.3567, mean_mc_travel_dist: 1501.3609, mean_rewards: 221.0045, total_rewards: 2848.0607, mean_steps: 20.5700, mean_ecr: 0.0397 mean_entropies: 1.4768, took: 108.0354s
2022-10-09 11:28:41,285 [INFO] 	Process 2 - batch 32399: mean_policy_losses: -53.778, mean_net_lifetime: 4886.6423, mean_mc_travel_dist: 1711.9960, mean_rewards: 219.7005, total_rewards: 3214.9454, mean_steps: 23.1700, mean_ecr: 0.0385 mean_entropies: 1.5358, took: 120.8356s
2022-10-09 11:29:05,617 [INFO] 	Process 1 - batch 33499: mean_policy_losses: -51.333, mean_net_lifetime: 4782.1699, mean_mc_travel_dist: 1666.3554, mean_rewards: 224.5712, total_rewards: 3148.7692, mean_steps: 22.0100, mean_ecr: 0.0393 mean_entropies: 1.5552, took: 109.3670s
2022-10-09 11:29:13,772 [INFO] 	Process 0 - batch 32199: mean_policy_losses: -36.764, mean_net_lifetime: 4400.3869, mean_mc_travel_dist: 1468.7784, mean_rewards: 230.4394, total_rewards: 2962.5767, mean_steps: 20.3000, mean_ecr: 0.0402 mean_entropies: 1.5030, took: 107.2936s
2022-10-09 11:29:34,240 [INFO] 	Process 3 - batch 32399: mean_policy_losses: -69.230, mean_net_lifetime: 4617.5637, mean_mc_travel_dist: 1602.8923, mean_rewards: 215.5558, total_rewards: 3052.0413, mean_steps: 22.0500, mean_ecr: 0.0388 mean_entropies: 1.5154, took: 117.4072s
2022-10-09 11:29:51,514 [INFO] 	Process 5 - batch 32199: mean_policy_losses: -102.792, mean_net_lifetime: 4479.9353, mean_mc_travel_dist: 1544.4251, mean_rewards: 233.3465, total_rewards: 2979.5140, mean_steps: 20.5200, mean_ecr: 0.0399 mean_entropies: 1.5029, took: 108.2178s
2022-10-09 11:30:11,372 [INFO] 	Process 4 - batch 32399: mean_policy_losses: -126.914, mean_net_lifetime: 4536.8214, mean_mc_travel_dist: 1570.8157, mean_rewards: 219.2547, total_rewards: 3004.2705, mean_steps: 21.3000, mean_ecr: 0.0385 mean_entropies: 1.5385, took: 111.8768s
2022-10-09 11:30:27,182 [INFO] 	Process 2 - batch 32499: mean_policy_losses: -114.193, mean_net_lifetime: 4239.2728, mean_mc_travel_dist: 1441.7120, mean_rewards: 224.5068, total_rewards: 2832.6413, mean_steps: 19.8800, mean_ecr: 0.0392 mean_entropies: 1.5572, took: 105.8985s
2022-10-09 11:30:30,988 [INFO] 	Process 6 - batch 32599: mean_policy_losses: -132.569, mean_net_lifetime: 5524.0628, mean_mc_travel_dist: 2181.4242, mean_rewards: 227.5407, total_rewards: 3384.8412, mean_steps: 27.5500, mean_ecr: 0.0394 mean_entropies: 1.4815, took: 142.6481s
2022-10-09 11:31:00,787 [INFO] 	Process 1 - batch 33599: mean_policy_losses: 7.434, mean_net_lifetime: 5076.6385, mean_mc_travel_dist: 1803.5052, mean_rewards: 231.7478, total_rewards: 3313.5713, mean_steps: 23.2200, mean_ecr: 0.0396 mean_entropies: 1.4968, took: 115.1697s
2022-10-09 11:31:01,433 [INFO] 	Process 0 - batch 32299: mean_policy_losses: -57.383, mean_net_lifetime: 4478.8602, mean_mc_travel_dist: 1513.3240, mean_rewards: 231.1799, total_rewards: 3004.4415, mean_steps: 20.0600, mean_ecr: 0.0395 mean_entropies: 1.5273, took: 107.6616s
2022-10-09 11:31:15,273 [INFO] 	Process 3 - batch 32499: mean_policy_losses: -151.107, mean_net_lifetime: 4218.9420, mean_mc_travel_dist: 1467.7535, mean_rewards: 228.6734, total_rewards: 2800.6049, mean_steps: 19.3900, mean_ecr: 0.0388 mean_entropies: 1.5331, took: 101.0327s
2022-10-09 11:31:36,086 [INFO] 	Process 5 - batch 32299: mean_policy_losses: -96.598, mean_net_lifetime: 4212.0316, mean_mc_travel_dist: 1437.7708, mean_rewards: 223.0473, total_rewards: 2814.1048, mean_steps: 19.7000, mean_ecr: 0.0399 mean_entropies: 1.5061, took: 104.5723s
2022-10-09 11:31:54,819 [INFO] 	Process 4 - batch 32499: mean_policy_losses: -135.777, mean_net_lifetime: 4166.7926, mean_mc_travel_dist: 1429.7960, mean_rewards: 228.7146, total_rewards: 2778.3086, mean_steps: 19.3200, mean_ecr: 0.0393 mean_entropies: 1.5363, took: 103.4475s
2022-10-09 11:32:16,585 [INFO] 	Process 6 - batch 32699: mean_policy_losses: -66.956, mean_net_lifetime: 4318.9434, mean_mc_travel_dist: 1460.7466, mean_rewards: 223.0679, total_rewards: 2893.1598, mean_steps: 19.7800, mean_ecr: 0.0387 mean_entropies: 1.5122, took: 105.5975s
2022-10-09 11:32:28,075 [INFO] 	Process 2 - batch 32599: mean_policy_losses: -118.547, mean_net_lifetime: 4754.0538, mean_mc_travel_dist: 1746.0827, mean_rewards: 227.6987, total_rewards: 3050.5813, mean_steps: 22.5900, mean_ecr: 0.0393 mean_entropies: 1.4593, took: 120.8909s
2022-10-09 11:32:52,150 [INFO] 	Process 1 - batch 33699: mean_policy_losses: 5.382, mean_net_lifetime: 4700.6489, mean_mc_travel_dist: 1613.6660, mean_rewards: 215.3164, total_rewards: 3119.8881, mean_steps: 22.4800, mean_ecr: 0.0380 mean_entropies: 1.5368, took: 111.3627s
2022-10-09 11:32:54,826 [INFO] 	Process 0 - batch 32399: mean_policy_losses: -146.364, mean_net_lifetime: 4344.0889, mean_mc_travel_dist: 1498.3622, mean_rewards: 219.2418, total_rewards: 2883.3304, mean_steps: 21.0000, mean_ecr: 0.0387 mean_entropies: 1.4794, took: 113.3925s
2022-10-09 11:33:31,204 [INFO] 	Process 5 - batch 32399: mean_policy_losses: -59.817, mean_net_lifetime: 4596.3576, mean_mc_travel_dist: 1586.1253, mean_rewards: 219.2329, total_rewards: 3048.1953, mean_steps: 21.8100, mean_ecr: 0.0387 mean_entropies: 1.4918, took: 115.1178s
2022-10-09 11:33:33,096 [INFO] 	Process 3 - batch 32599: mean_policy_losses: -189.108, mean_net_lifetime: 5418.3157, mean_mc_travel_dist: 2106.6497, mean_rewards: 227.4697, total_rewards: 3343.4427, mean_steps: 27.0100, mean_ecr: 0.0397 mean_entropies: 1.4411, took: 137.8241s
2022-10-09 11:34:03,692 [INFO] 	Process 6 - batch 32799: mean_policy_losses: -60.799, mean_net_lifetime: 4493.9428, mean_mc_travel_dist: 1548.6856, mean_rewards: 233.7185, total_rewards: 2985.1039, mean_steps: 19.9500, mean_ecr: 0.0399 mean_entropies: 1.5201, took: 107.1077s
2022-10-09 11:34:15,937 [INFO] 	Process 2 - batch 32699: mean_policy_losses: -114.745, mean_net_lifetime: 4404.4411, mean_mc_travel_dist: 1509.5697, mean_rewards: 229.0231, total_rewards: 2928.7052, mean_steps: 20.0500, mean_ecr: 0.0381 mean_entropies: 1.4959, took: 107.8623s
2022-10-09 11:34:24,441 [INFO] 	Process 4 - batch 32599: mean_policy_losses: -158.570, mean_net_lifetime: 5830.9718, mean_mc_travel_dist: 2220.3210, mean_rewards: 222.6393, total_rewards: 3650.1958, mean_steps: 29.6600, mean_ecr: 0.0393 mean_entropies: 1.4403, took: 149.6213s
2022-10-09 11:34:40,802 [INFO] 	Process 1 - batch 33799: mean_policy_losses: -45.785, mean_net_lifetime: 4714.6375, mean_mc_travel_dist: 1581.8095, mean_rewards: 224.1886, total_rewards: 3171.1516, mean_steps: 21.7300, mean_ecr: 0.0405 mean_entropies: 1.4629, took: 108.6520s
2022-10-09 11:34:49,732 [INFO] 	Process 0 - batch 32499: mean_policy_losses: -119.007, mean_net_lifetime: 4604.0226, mean_mc_travel_dist: 1604.3181, mean_rewards: 222.1407, total_rewards: 3035.4161, mean_steps: 21.4500, mean_ecr: 0.0387 mean_entropies: 1.5356, took: 114.9061s
2022-10-09 11:35:18,699 [INFO] 	Process 5 - batch 32499: mean_policy_losses: -81.649, mean_net_lifetime: 4246.0607, mean_mc_travel_dist: 1476.9088, mean_rewards: 221.3685, total_rewards: 2813.8397, mean_steps: 19.9300, mean_ecr: 0.0390 mean_entropies: 1.5446, took: 107.4953s
2022-10-09 11:36:00,433 [INFO] 	Process 2 - batch 32799: mean_policy_losses: -15.877, mean_net_lifetime: 4556.0078, mean_mc_travel_dist: 1541.1330, mean_rewards: 236.8732, total_rewards: 3051.3289, mean_steps: 19.4900, mean_ecr: 0.0394 mean_entropies: 1.5810, took: 104.4961s
2022-10-09 11:36:05,014 [INFO] 	Process 3 - batch 32699: mean_policy_losses: -39.826, mean_net_lifetime: 5858.6363, mean_mc_travel_dist: 2255.4452, mean_rewards: 227.8487, total_rewards: 3651.9613, mean_steps: 29.4100, mean_ecr: 0.0383 mean_entropies: 1.5019, took: 151.9170s
2022-10-09 11:36:20,729 [INFO] 	Process 4 - batch 32699: mean_policy_losses: -96.273, mean_net_lifetime: 4722.6677, mean_mc_travel_dist: 1723.1953, mean_rewards: 231.0122, total_rewards: 3038.8268, mean_steps: 21.9600, mean_ecr: 0.0383 mean_entropies: 1.5038, took: 116.2885s
2022-10-09 11:36:27,534 [INFO] 	Process 1 - batch 33899: mean_policy_losses: -11.308, mean_net_lifetime: 4628.9246, mean_mc_travel_dist: 1590.0722, mean_rewards: 224.9348, total_rewards: 3080.9427, mean_steps: 21.3500, mean_ecr: 0.0400 mean_entropies: 1.4547, took: 106.7312s
2022-10-09 11:36:50,307 [INFO] 	Process 0 - batch 32599: mean_policy_losses: -121.743, mean_net_lifetime: 4953.3806, mean_mc_travel_dist: 1823.4344, mean_rewards: 231.2867, total_rewards: 3175.2920, mean_steps: 22.8500, mean_ecr: 0.0391 mean_entropies: 1.4694, took: 120.5732s
2022-10-09 11:37:18,056 [INFO] 	Process 6 - batch 32899: mean_policy_losses: -31.213, mean_net_lifetime: 7442.1653, mean_mc_travel_dist: 2989.8792, mean_rewards: 221.0390, total_rewards: 4493.7043, mean_steps: 38.5100, mean_ecr: 0.0371 mean_entropies: 1.5198, took: 194.3642s
2022-10-09 11:37:26,600 [INFO] 	Process 5 - batch 32599: mean_policy_losses: -117.151, mean_net_lifetime: 5041.4304, mean_mc_travel_dist: 1891.8874, mean_rewards: 227.7176, total_rewards: 3189.6321, mean_steps: 24.2500, mean_ecr: 0.0396 mean_entropies: 1.4623, took: 127.9013s
2022-10-09 11:37:44,661 [INFO] 	Process 3 - batch 32799: mean_policy_losses: -148.024, mean_net_lifetime: 4242.1587, mean_mc_travel_dist: 1466.0280, mean_rewards: 238.3041, total_rewards: 2819.0859, mean_steps: 18.4800, mean_ecr: 0.0394 mean_entropies: 1.5339, took: 99.6472s
2022-10-09 11:37:58,505 [INFO] 	Process 4 - batch 32799: mean_policy_losses: -99.467, mean_net_lifetime: 4206.9367, mean_mc_travel_dist: 1403.8232, mean_rewards: 237.3583, total_rewards: 2848.2634, mean_steps: 17.9600, mean_ecr: 0.0395 mean_entropies: 1.5398, took: 97.7764s
2022-10-09 11:38:05,699 [INFO] 	Process 1 - batch 33999: mean_policy_losses: -79.854, mean_net_lifetime: 4401.3607, mean_mc_travel_dist: 1536.6073, mean_rewards: 236.3073, total_rewards: 2895.6765, mean_steps: 19.4800, mean_ecr: 0.0423 mean_entropies: 1.4612, took: 98.1663s
2022-10-09 11:38:27,104 [INFO] 	Process 2 - batch 32899: mean_policy_losses: -64.996, mean_net_lifetime: 5796.6359, mean_mc_travel_dist: 2210.7196, mean_rewards: 220.6890, total_rewards: 3614.4458, mean_steps: 28.5300, mean_ecr: 0.0367 mean_entropies: 1.4912, took: 146.6718s
2022-10-09 11:38:34,955 [INFO] 	Process 0 - batch 32699: mean_policy_losses: -102.857, mean_net_lifetime: 4248.6450, mean_mc_travel_dist: 1486.0432, mean_rewards: 227.5182, total_rewards: 2797.3593, mean_steps: 19.4200, mean_ecr: 0.0382 mean_entropies: 1.5044, took: 104.6489s
2022-10-09 11:39:11,021 [INFO] 	Process 6 - batch 32999: mean_policy_losses: -71.808, mean_net_lifetime: 4568.6562, mean_mc_travel_dist: 1623.0904, mean_rewards: 229.3767, total_rewards: 2981.0641, mean_steps: 21.0200, mean_ecr: 0.0394 mean_entropies: 1.4774, took: 112.9644s
2022-10-09 11:39:13,388 [INFO] 	Process 5 - batch 32699: mean_policy_losses: -67.826, mean_net_lifetime: 4305.0434, mean_mc_travel_dist: 1478.7635, mean_rewards: 224.5292, total_rewards: 2866.1824, mean_steps: 19.7000, mean_ecr: 0.0383 mean_entropies: 1.4754, took: 106.7870s
2022-10-09 11:39:38,456 [INFO] 	Process 1 - batch 34099: mean_policy_losses: -139.349, mean_net_lifetime: 4093.3820, mean_mc_travel_dist: 1381.3343, mean_rewards: 227.4199, total_rewards: 2744.7620, mean_steps: 18.6200, mean_ecr: 0.0412 mean_entropies: 1.4442, took: 92.7565s
2022-10-09 11:40:08,617 [INFO] 	Process 2 - batch 32999: mean_policy_losses: -116.260, mean_net_lifetime: 4240.6039, mean_mc_travel_dist: 1447.0169, mean_rewards: 227.9185, total_rewards: 2836.4981, mean_steps: 19.1600, mean_ecr: 0.0397 mean_entropies: 1.4642, took: 101.5125s
2022-10-09 11:40:21,865 [INFO] 	Process 0 - batch 32799: mean_policy_losses: -98.687, mean_net_lifetime: 4621.8548, mean_mc_travel_dist: 1606.1691, mean_rewards: 231.0163, total_rewards: 3049.5916, mean_steps: 20.5200, mean_ecr: 0.0392 mean_entropies: 1.4962, took: 106.9104s
2022-10-09 11:40:30,758 [INFO] 	Process 3 - batch 32899: mean_policy_losses: -54.636, mean_net_lifetime: 6231.8191, mean_mc_travel_dist: 2441.3872, mean_rewards: 217.2246, total_rewards: 3825.2506, mean_steps: 33.4800, mean_ecr: 0.0371 mean_entropies: 1.4349, took: 166.0983s
2022-10-09 11:40:58,352 [INFO] 	Process 4 - batch 32899: mean_policy_losses: -44.256, mean_net_lifetime: 6882.4731, mean_mc_travel_dist: 2696.1797, mean_rewards: 224.4370, total_rewards: 4220.5325, mean_steps: 36.8000, mean_ecr: 0.0371 mean_entropies: 1.4346, took: 179.8470s
2022-10-09 11:41:04,331 [INFO] 	Process 5 - batch 32799: mean_policy_losses: -59.580, mean_net_lifetime: 4935.8991, mean_mc_travel_dist: 1781.9933, mean_rewards: 233.1337, total_rewards: 3187.4973, mean_steps: 22.2600, mean_ecr: 0.0395 mean_entropies: 1.4955, took: 110.9424s
2022-10-09 11:41:18,712 [INFO] 	Process 1 - batch 34199: mean_policy_losses: -84.148, mean_net_lifetime: 4669.1945, mean_mc_travel_dist: 1651.8954, mean_rewards: 227.9361, total_rewards: 3049.6635, mean_steps: 21.3500, mean_ecr: 0.0398 mean_entropies: 1.4324, took: 100.2558s
2022-10-09 11:42:10,362 [INFO] 	Process 3 - batch 32999: mean_policy_losses: -44.268, mean_net_lifetime: 4470.8104, mean_mc_travel_dist: 1514.5959, mean_rewards: 228.1540, total_rewards: 2991.1222, mean_steps: 20.1800, mean_ecr: 0.0392 mean_entropies: 1.4494, took: 99.6025s
2022-10-09 11:42:26,429 [INFO] 	Process 0 - batch 32899: mean_policy_losses: -13.286, mean_net_lifetime: 5119.6395, mean_mc_travel_dist: 1875.5609, mean_rewards: 221.6566, total_rewards: 3282.0823, mean_steps: 25.4700, mean_ecr: 0.0371 mean_entropies: 1.4417, took: 124.5644s
2022-10-09 11:42:35,357 [INFO] 	Process 4 - batch 32999: mean_policy_losses: -20.794, mean_net_lifetime: 4313.7928, mean_mc_travel_dist: 1440.1164, mean_rewards: 230.0379, total_rewards: 2913.2675, mean_steps: 19.4800, mean_ecr: 0.0392 mean_entropies: 1.5001, took: 97.0036s
2022-10-09 11:42:57,063 [INFO] 	Process 1 - batch 34299: mean_policy_losses: -31.036, mean_net_lifetime: 4571.1038, mean_mc_travel_dist: 1577.3606, mean_rewards: 215.8919, total_rewards: 3031.0916, mean_steps: 21.5300, mean_ecr: 0.0379 mean_entropies: 1.5190, took: 98.3510s
2022-10-09 11:43:54,585 [INFO] 	Process 5 - batch 32899: mean_policy_losses: -69.371, mean_net_lifetime: 6814.5029, mean_mc_travel_dist: 2718.7313, mean_rewards: 218.2462, total_rewards: 4128.7239, mean_steps: 37.1700, mean_ecr: 0.0376 mean_entropies: 1.4681, took: 170.2554s
2022-10-09 11:44:15,826 [INFO] 	Process 0 - batch 32999: mean_policy_losses: -108.890, mean_net_lifetime: 5162.4668, mean_mc_travel_dist: 1844.5363, mean_rewards: 229.4213, total_rewards: 3357.8719, mean_steps: 23.4000, mean_ecr: 0.0395 mean_entropies: 1.5343, took: 109.3965s
2022-10-09 11:44:31,060 [INFO] 	Process 1 - batch 34399: mean_policy_losses: -182.578, mean_net_lifetime: 4658.8632, mean_mc_travel_dist: 1635.0330, mean_rewards: 229.5509, total_rewards: 3056.6104, mean_steps: 21.6000, mean_ecr: 0.0394 mean_entropies: 1.4866, took: 93.9968s
2022-10-09 11:45:32,736 [INFO] 	Process 5 - batch 32999: mean_policy_losses: -77.838, mean_net_lifetime: 4818.6264, mean_mc_travel_dist: 1687.2231, mean_rewards: 230.8707, total_rewards: 3166.1046, mean_steps: 21.5100, mean_ecr: 0.0391 mean_entropies: 1.4970, took: 98.1503s
2022-10-09 11:45:57,223 [INFO] 	Process 1 - batch 34499: mean_policy_losses: -145.737, mean_net_lifetime: 4615.3514, mean_mc_travel_dist: 1608.3473, mean_rewards: 228.3586, total_rewards: 3049.5397, mean_steps: 20.8000, mean_ecr: 0.0395 mean_entropies: 1.5186, took: 86.1635s
2022-10-09 11:51:44,174 [INFO] 	Process 6 - batch 33099: mean_policy_losses: -57.784, mean_net_lifetime: 4331.9873, mean_mc_travel_dist: 1505.5038, mean_rewards: 226.1939, total_rewards: 2869.0571, mean_steps: 19.7800, mean_ecr: 0.0392 mean_entropies: 1.4663, took: 753.1533s
2022-10-09 11:52:31,056 [INFO] 	Process 2 - batch 33099: mean_policy_losses: -68.102, mean_net_lifetime: 4228.0956, mean_mc_travel_dist: 1459.6373, mean_rewards: 232.3082, total_rewards: 2806.4442, mean_steps: 19.8300, mean_ecr: 0.0392 mean_entropies: 1.4217, took: 742.4396s
2022-10-09 11:53:23,475 [INFO] 	Process 6 - batch 33199: mean_policy_losses: -46.139, mean_net_lifetime: 4886.8993, mean_mc_travel_dist: 1751.9179, mean_rewards: 227.0122, total_rewards: 3175.6149, mean_steps: 22.4600, mean_ecr: 0.0376 mean_entropies: 1.5011, took: 99.3005s
2022-10-09 11:54:08,726 [INFO] 	Process 2 - batch 33199: mean_policy_losses: -14.794, mean_net_lifetime: 4734.7139, mean_mc_travel_dist: 1671.6527, mean_rewards: 235.1839, total_rewards: 3108.3334, mean_steps: 21.5400, mean_ecr: 0.0377 mean_entropies: 1.5057, took: 97.6697s
2022-10-09 11:54:57,039 [INFO] 	Process 3 - batch 33099: mean_policy_losses: -99.633, mean_net_lifetime: 4495.1509, mean_mc_travel_dist: 1560.3855, mean_rewards: 229.8936, total_rewards: 2964.1332, mean_steps: 21.4000, mean_ecr: 0.0394 mean_entropies: 1.4204, took: 766.6774s
2022-10-09 11:55:04,526 [INFO] 	Process 6 - batch 33299: mean_policy_losses: -97.363, mean_net_lifetime: 4507.0934, mean_mc_travel_dist: 1568.7612, mean_rewards: 219.7300, total_rewards: 2969.0127, mean_steps: 21.6600, mean_ecr: 0.0392 mean_entropies: 1.5238, took: 101.0511s
2022-10-09 11:55:44,355 [INFO] 	Process 4 - batch 33099: mean_policy_losses: -13.938, mean_net_lifetime: 4574.5919, mean_mc_travel_dist: 1566.1746, mean_rewards: 227.2746, total_rewards: 3047.0799, mean_steps: 21.3800, mean_ecr: 0.0391 mean_entropies: 1.4234, took: 788.9989s
2022-10-09 11:55:49,474 [INFO] 	Process 2 - batch 33299: mean_policy_losses: -175.209, mean_net_lifetime: 4292.6838, mean_mc_travel_dist: 1488.6809, mean_rewards: 226.8256, total_rewards: 2844.2089, mean_steps: 20.3900, mean_ecr: 0.0391 mean_entropies: 1.4990, took: 100.7483s
2022-10-09 11:56:53,351 [INFO] 	Process 3 - batch 33199: mean_policy_losses: -102.685, mean_net_lifetime: 4797.2123, mean_mc_travel_dist: 1691.0287, mean_rewards: 227.6774, total_rewards: 3146.2592, mean_steps: 22.6800, mean_ecr: 0.0377 mean_entropies: 1.5011, took: 116.3130s
2022-10-09 11:57:04,902 [INFO] 	Process 5 - batch 33099: mean_policy_losses: -110.567, mean_net_lifetime: 4470.5904, mean_mc_travel_dist: 1537.8030, mean_rewards: 222.9690, total_rewards: 2974.2289, mean_steps: 21.3100, mean_ecr: 0.0392 mean_entropies: 1.4243, took: 692.1664s
2022-10-09 11:57:09,275 [INFO] 	Process 1 - batch 34599: mean_policy_losses: -80.897, mean_net_lifetime: 4399.4400, mean_mc_travel_dist: 1550.3852, mean_rewards: 223.6364, total_rewards: 2888.6955, mean_steps: 20.2300, mean_ecr: 0.0386 mean_entropies: 1.4694, took: 672.0513s
2022-10-09 11:57:11,151 [INFO] 	Process 0 - batch 33099: mean_policy_losses: -36.698, mean_net_lifetime: 5004.6535, mean_mc_travel_dist: 1711.8746, mean_rewards: 231.0074, total_rewards: 3321.7008, mean_steps: 23.8100, mean_ecr: 0.0393 mean_entropies: 1.4117, took: 775.3250s
2022-10-09 11:57:42,863 [INFO] 	Process 6 - batch 33399: mean_policy_losses: -20.893, mean_net_lifetime: 6735.6527, mean_mc_travel_dist: 2567.3329, mean_rewards: 226.7135, total_rewards: 4202.0430, mean_steps: 31.6100, mean_ecr: 0.0387 mean_entropies: 1.5069, took: 158.3365s
2022-10-09 11:57:52,955 [INFO] 	Process 4 - batch 33199: mean_policy_losses: -138.238, mean_net_lifetime: 4934.4601, mean_mc_travel_dist: 1807.2994, mean_rewards: 220.2181, total_rewards: 3162.9845, mean_steps: 24.6800, mean_ecr: 0.0380 mean_entropies: 1.4767, took: 128.5999s
2022-10-09 11:57:53,701 [INFO] 	Process 2 - batch 33399: mean_policy_losses: -10.127, mean_net_lifetime: 4982.4641, mean_mc_travel_dist: 1729.3704, mean_rewards: 222.2540, total_rewards: 3285.6643, mean_steps: 23.5200, mean_ecr: 0.0384 mean_entropies: 1.5111, took: 124.2271s
2022-10-09 11:58:44,121 [INFO] 	Process 3 - batch 33299: mean_policy_losses: -100.086, mean_net_lifetime: 4402.9836, mean_mc_travel_dist: 1521.3561, mean_rewards: 221.3437, total_rewards: 2917.2554, mean_steps: 21.0400, mean_ecr: 0.0391 mean_entropies: 1.4787, took: 110.7697s
2022-10-09 11:58:56,115 [INFO] 	Process 5 - batch 33199: mean_policy_losses: -126.575, mean_net_lifetime: 4553.0207, mean_mc_travel_dist: 1596.9222, mean_rewards: 235.5072, total_rewards: 2990.0101, mean_steps: 21.1600, mean_ecr: 0.0380 mean_entropies: 1.4696, took: 111.2135s
2022-10-09 11:58:57,123 [INFO] 	Process 1 - batch 34699: mean_policy_losses: -128.609, mean_net_lifetime: 4652.3324, mean_mc_travel_dist: 1688.8216, mean_rewards: 233.5315, total_rewards: 2998.9296, mean_steps: 21.4900, mean_ecr: 0.0404 mean_entropies: 1.4563, took: 107.8487s
2022-10-09 11:59:13,149 [INFO] 	Process 0 - batch 33199: mean_policy_losses: -95.421, mean_net_lifetime: 4839.3790, mean_mc_travel_dist: 1716.1406, mean_rewards: 220.7708, total_rewards: 3161.2642, mean_steps: 23.2300, mean_ecr: 0.0376 mean_entropies: 1.5007, took: 121.9988s
2022-10-09 11:59:41,040 [INFO] 	Process 6 - batch 33499: mean_policy_losses: -109.648, mean_net_lifetime: 4843.3443, mean_mc_travel_dist: 1696.9643, mean_rewards: 223.7170, total_rewards: 3182.2569, mean_steps: 22.5900, mean_ecr: 0.0388 mean_entropies: 1.5431, took: 118.1782s
2022-10-09 11:59:46,000 [INFO] 	Process 4 - batch 33299: mean_policy_losses: -115.409, mean_net_lifetime: 4482.6750, mean_mc_travel_dist: 1551.3071, mean_rewards: 226.0465, total_rewards: 2966.7138, mean_steps: 21.3800, mean_ecr: 0.0392 mean_entropies: 1.4842, took: 113.0453s
2022-10-09 12:00:22,442 [INFO] 	Process 2 - batch 33499: mean_policy_losses: -73.975, mean_net_lifetime: 6031.4638, mean_mc_travel_dist: 2181.8738, mean_rewards: 222.4224, total_rewards: 3885.1437, mean_steps: 28.9700, mean_ecr: 0.0389 mean_entropies: 1.5312, took: 148.7410s
2022-10-09 12:00:44,604 [INFO] 	Process 5 - batch 33299: mean_policy_losses: -146.452, mean_net_lifetime: 4260.6053, mean_mc_travel_dist: 1466.0376, mean_rewards: 227.1078, total_rewards: 2840.3199, mean_steps: 20.1800, mean_ecr: 0.0390 mean_entropies: 1.5005, took: 108.4885s
2022-10-09 12:01:03,153 [INFO] 	Process 1 - batch 34799: mean_policy_losses: -90.772, mean_net_lifetime: 5219.6623, mean_mc_travel_dist: 1859.6906, mean_rewards: 220.0125, total_rewards: 3397.8974, mean_steps: 25.4500, mean_ecr: 0.0378 mean_entropies: 1.5559, took: 126.0291s
2022-10-09 12:01:14,769 [INFO] 	Process 3 - batch 33399: mean_policy_losses: -50.670, mean_net_lifetime: 6153.3197, mean_mc_travel_dist: 2280.7401, mean_rewards: 224.1436, total_rewards: 3910.3482, mean_steps: 29.7500, mean_ecr: 0.0385 mean_entropies: 1.5625, took: 150.6480s
2022-10-09 12:01:18,979 [INFO] 	Process 0 - batch 33299: mean_policy_losses: -111.212, mean_net_lifetime: 4827.2747, mean_mc_travel_dist: 1707.0114, mean_rewards: 222.9040, total_rewards: 3156.4169, mean_steps: 23.7700, mean_ecr: 0.0392 mean_entropies: 1.5212, took: 125.8290s
2022-10-09 12:01:29,145 [INFO] 	Process 6 - batch 33599: mean_policy_losses: -68.159, mean_net_lifetime: 4489.1750, mean_mc_travel_dist: 1536.1963, mean_rewards: 234.5120, total_rewards: 2996.7202, mean_steps: 19.9600, mean_ecr: 0.0397 mean_entropies: 1.4334, took: 108.1041s
2022-10-09 12:02:13,808 [INFO] 	Process 2 - batch 33599: mean_policy_losses: -111.625, mean_net_lifetime: 4653.1802, mean_mc_travel_dist: 1593.6155, mean_rewards: 236.2043, total_rewards: 3101.2195, mean_steps: 20.9300, mean_ecr: 0.0395 mean_entropies: 1.4673, took: 111.3659s
2022-10-09 12:02:19,240 [INFO] 	Process 4 - batch 33399: mean_policy_losses: -23.019, mean_net_lifetime: 6222.3715, mean_mc_travel_dist: 2270.1047, mean_rewards: 225.6099, total_rewards: 3992.2564, mean_steps: 30.1400, mean_ecr: 0.0385 mean_entropies: 1.5597, took: 153.2400s
2022-10-09 12:02:47,642 [INFO] 	Process 1 - batch 34899: mean_policy_losses: -76.702, mean_net_lifetime: 4726.0635, mean_mc_travel_dist: 1590.8780, mean_rewards: 239.1160, total_rewards: 3179.3506, mean_steps: 20.7300, mean_ecr: 0.0412 mean_entropies: 1.5134, took: 104.4902s
2022-10-09 12:03:05,013 [INFO] 	Process 3 - batch 33499: mean_policy_losses: -242.544, mean_net_lifetime: 4585.9888, mean_mc_travel_dist: 1570.4113, mean_rewards: 225.3543, total_rewards: 3047.5874, mean_steps: 20.9500, mean_ecr: 0.0390 mean_entropies: 1.5627, took: 110.2439s
2022-10-09 12:03:18,935 [INFO] 	Process 6 - batch 33699: mean_policy_losses: -231.285, mean_net_lifetime: 4470.8510, mean_mc_travel_dist: 1554.2439, mean_rewards: 227.2871, total_rewards: 2955.1675, mean_steps: 20.7400, mean_ecr: 0.0383 mean_entropies: 1.5785, took: 109.7902s
2022-10-09 12:03:20,873 [INFO] 	Process 5 - batch 33399: mean_policy_losses: -97.166, mean_net_lifetime: 6395.6692, mean_mc_travel_dist: 2357.6970, mean_rewards: 229.3902, total_rewards: 4077.9647, mean_steps: 30.3400, mean_ecr: 0.0385 mean_entropies: 1.5440, took: 156.2692s
2022-10-09 12:03:53,666 [INFO] 	Process 0 - batch 33399: mean_policy_losses: -32.066, mean_net_lifetime: 6571.0426, mean_mc_travel_dist: 2424.7645, mean_rewards: 236.6936, total_rewards: 4181.6187, mean_steps: 30.2400, mean_ecr: 0.0381 mean_entropies: 1.5330, took: 154.6870s
2022-10-09 12:04:09,245 [INFO] 	Process 2 - batch 33699: mean_policy_losses: -242.750, mean_net_lifetime: 4722.5743, mean_mc_travel_dist: 1640.6962, mean_rewards: 226.4136, total_rewards: 3114.3900, mean_steps: 21.5600, mean_ecr: 0.0381 mean_entropies: 1.5338, took: 115.4366s
2022-10-09 12:04:26,951 [INFO] 	Process 4 - batch 33499: mean_policy_losses: -176.117, mean_net_lifetime: 5075.3633, mean_mc_travel_dist: 1760.6546, mean_rewards: 225.1833, total_rewards: 3348.0191, mean_steps: 24.1300, mean_ecr: 0.0390 mean_entropies: 1.5608, took: 127.7116s
2022-10-09 12:04:40,107 [INFO] 	Process 3 - batch 33599: mean_policy_losses: -151.975, mean_net_lifetime: 4073.9690, mean_mc_travel_dist: 1360.6570, mean_rewards: 240.3521, total_rewards: 2745.9108, mean_steps: 17.9700, mean_ecr: 0.0400 mean_entropies: 1.4372, took: 95.0932s
2022-10-09 12:04:49,520 [INFO] 	Process 1 - batch 34999: mean_policy_losses: -38.122, mean_net_lifetime: 5387.7977, mean_mc_travel_dist: 1948.0645, mean_rewards: 225.4483, total_rewards: 3476.2477, mean_steps: 24.8200, mean_ecr: 0.0396 mean_entropies: 1.4897, took: 121.8771s
2022-10-09 12:05:06,635 [INFO] 	Process 5 - batch 33499: mean_policy_losses: -151.602, mean_net_lifetime: 4409.9653, mean_mc_travel_dist: 1502.7195, mean_rewards: 226.8688, total_rewards: 2951.1986, mean_steps: 19.8300, mean_ecr: 0.0392 mean_entropies: 1.5039, took: 105.7622s
2022-10-09 12:05:15,496 [INFO] 	Process 6 - batch 33799: mean_policy_losses: -118.414, mean_net_lifetime: 4754.6745, mean_mc_travel_dist: 1588.9611, mean_rewards: 231.5943, total_rewards: 3192.6641, mean_steps: 21.6500, mean_ecr: 0.0407 mean_entropies: 1.4475, took: 116.5611s
2022-10-09 12:05:58,199 [INFO] 	Process 0 - batch 33499: mean_policy_losses: -137.916, mean_net_lifetime: 5275.3103, mean_mc_travel_dist: 1835.4138, mean_rewards: 229.6491, total_rewards: 3482.5066, mean_steps: 24.1900, mean_ecr: 0.0393 mean_entropies: 1.5062, took: 124.5339s
2022-10-09 12:06:11,444 [INFO] 	Process 4 - batch 33599: mean_policy_losses: -91.767, mean_net_lifetime: 4440.1680, mean_mc_travel_dist: 1540.5568, mean_rewards: 231.7596, total_rewards: 2935.1041, mean_steps: 19.7900, mean_ecr: 0.0397 mean_entropies: 1.4603, took: 104.4930s
2022-10-09 12:06:29,380 [INFO] 	Process 3 - batch 33699: mean_policy_losses: -181.022, mean_net_lifetime: 4678.5786, mean_mc_travel_dist: 1613.3339, mean_rewards: 233.9524, total_rewards: 3101.7906, mean_steps: 20.5400, mean_ecr: 0.0382 mean_entropies: 1.5473, took: 109.2738s
2022-10-09 12:06:33,295 [INFO] 	Process 1 - batch 35099: mean_policy_losses: -131.831, mean_net_lifetime: 4583.4204, mean_mc_travel_dist: 1536.5052, mean_rewards: 228.7508, total_rewards: 3084.1684, mean_steps: 20.7500, mean_ecr: 0.0389 mean_entropies: 1.5516, took: 103.7747s
2022-10-09 12:06:36,532 [INFO] 	Process 2 - batch 33799: mean_policy_losses: -126.993, mean_net_lifetime: 5902.5820, mean_mc_travel_dist: 2047.0706, mean_rewards: 230.3852, total_rewards: 3882.8619, mean_steps: 28.0000, mean_ecr: 0.0406 mean_entropies: 1.4353, took: 147.2876s
2022-10-09 12:06:47,750 [INFO] 	Process 5 - batch 33599: mean_policy_losses: -50.523, mean_net_lifetime: 4429.0765, mean_mc_travel_dist: 1490.1425, mean_rewards: 237.7052, total_rewards: 2981.7870, mean_steps: 18.9700, mean_ecr: 0.0395 mean_entropies: 1.4996, took: 101.1139s
2022-10-09 12:07:10,898 [INFO] 	Process 6 - batch 33899: mean_policy_losses: -135.785, mean_net_lifetime: 4751.1072, mean_mc_travel_dist: 1621.5813, mean_rewards: 230.2396, total_rewards: 3167.7007, mean_steps: 22.1200, mean_ecr: 0.0399 mean_entropies: 1.4706, took: 115.4021s
2022-10-09 12:07:39,584 [INFO] 	Process 0 - batch 33599: mean_policy_losses: -103.502, mean_net_lifetime: 4279.1897, mean_mc_travel_dist: 1460.3446, mean_rewards: 239.2326, total_rewards: 2858.3465, mean_steps: 18.7800, mean_ecr: 0.0395 mean_entropies: 1.4707, took: 101.3840s
2022-10-09 12:08:06,323 [INFO] 	Process 3 - batch 33799: mean_policy_losses: -118.725, mean_net_lifetime: 4095.9325, mean_mc_travel_dist: 1335.0636, mean_rewards: 226.6217, total_rewards: 2799.9554, mean_steps: 17.9700, mean_ecr: 0.0407 mean_entropies: 1.4689, took: 96.9425s
2022-10-09 12:08:06,984 [INFO] 	Process 4 - batch 33699: mean_policy_losses: -168.678, mean_net_lifetime: 4798.7979, mean_mc_travel_dist: 1673.0563, mean_rewards: 226.2932, total_rewards: 3170.3553, mean_steps: 21.9300, mean_ecr: 0.0380 mean_entropies: 1.5628, took: 115.5391s
2022-10-09 12:08:13,730 [INFO] 	Process 1 - batch 35199: mean_policy_losses: -163.229, mean_net_lifetime: 4343.1525, mean_mc_travel_dist: 1485.3917, mean_rewards: 224.4131, total_rewards: 2887.9793, mean_steps: 20.1400, mean_ecr: 0.0385 mean_entropies: 1.4811, took: 100.4351s
2022-10-09 12:08:36,151 [INFO] 	Process 2 - batch 33899: mean_policy_losses: -38.591, mean_net_lifetime: 4833.7081, mean_mc_travel_dist: 1659.8254, mean_rewards: 221.8335, total_rewards: 3209.7759, mean_steps: 22.6700, mean_ecr: 0.0398 mean_entropies: 1.4489, took: 119.6194s
2022-10-09 12:08:45,985 [INFO] 	Process 5 - batch 33699: mean_policy_losses: -110.506, mean_net_lifetime: 4879.6020, mean_mc_travel_dist: 1672.2229, mean_rewards: 229.2773, total_rewards: 3251.7622, mean_steps: 22.2700, mean_ecr: 0.0383 mean_entropies: 1.5477, took: 118.2359s
2022-10-09 12:08:52,953 [INFO] 	Process 6 - batch 33999: mean_policy_losses: -137.662, mean_net_lifetime: 4197.2318, mean_mc_travel_dist: 1429.3387, mean_rewards: 226.2651, total_rewards: 2810.4386, mean_steps: 19.1300, mean_ecr: 0.0428 mean_entropies: 1.4477, took: 102.0552s
2022-10-09 12:09:33,463 [INFO] 	Process 0 - batch 33699: mean_policy_losses: -84.495, mean_net_lifetime: 4755.4696, mean_mc_travel_dist: 1616.2300, mean_rewards: 227.8760, total_rewards: 3173.2346, mean_steps: 21.5800, mean_ecr: 0.0383 mean_entropies: 1.5298, took: 113.8793s
2022-10-09 12:09:46,657 [INFO] 	Process 4 - batch 33799: mean_policy_losses: -69.814, mean_net_lifetime: 4238.8872, mean_mc_travel_dist: 1406.9172, mean_rewards: 227.2259, total_rewards: 2877.1876, mean_steps: 18.7800, mean_ecr: 0.0409 mean_entropies: 1.4575, took: 99.6732s
2022-10-09 12:09:49,430 [INFO] 	Process 3 - batch 33899: mean_policy_losses: -90.245, mean_net_lifetime: 4272.7610, mean_mc_travel_dist: 1445.2446, mean_rewards: 225.7235, total_rewards: 2870.8088, mean_steps: 19.5800, mean_ecr: 0.0397 mean_entropies: 1.4310, took: 103.1068s
2022-10-09 12:09:53,218 [INFO] 	Process 1 - batch 35299: mean_policy_losses: -122.124, mean_net_lifetime: 4316.8390, mean_mc_travel_dist: 1492.3324, mean_rewards: 228.5518, total_rewards: 2858.4642, mean_steps: 19.8800, mean_ecr: 0.0395 mean_entropies: 1.4544, took: 99.4881s
2022-10-09 12:10:25,628 [INFO] 	Process 6 - batch 34099: mean_policy_losses: -182.248, mean_net_lifetime: 3853.4802, mean_mc_travel_dist: 1260.4179, mean_rewards: 236.3318, total_rewards: 2623.3711, mean_steps: 17.1300, mean_ecr: 0.0411 mean_entropies: 1.4845, took: 92.6748s
2022-10-09 12:10:26,435 [INFO] 	Process 2 - batch 33999: mean_policy_losses: -30.511, mean_net_lifetime: 4588.2620, mean_mc_travel_dist: 1564.9086, mean_rewards: 233.0150, total_rewards: 3052.5098, mean_steps: 20.6400, mean_ecr: 0.0429 mean_entropies: 1.4692, took: 110.2838s
2022-10-09 12:10:33,255 [INFO] 	Process 5 - batch 33799: mean_policy_losses: -50.580, mean_net_lifetime: 4501.7874, mean_mc_travel_dist: 1470.1100, mean_rewards: 227.9985, total_rewards: 3060.9098, mean_steps: 20.1000, mean_ecr: 0.0407 mean_entropies: 1.4727, took: 107.2699s
2022-10-09 12:11:30,680 [INFO] 	Process 3 - batch 33999: mean_policy_losses: -120.442, mean_net_lifetime: 4095.7822, mean_mc_travel_dist: 1403.4185, mean_rewards: 232.1064, total_rewards: 2728.8312, mean_steps: 18.9700, mean_ecr: 0.0428 mean_entropies: 1.4468, took: 101.2497s
2022-10-09 12:11:36,164 [INFO] 	Process 0 - batch 33799: mean_policy_losses: -55.540, mean_net_lifetime: 5053.2001, mean_mc_travel_dist: 1719.0892, mean_rewards: 229.1274, total_rewards: 3361.5528, mean_steps: 23.2400, mean_ecr: 0.0406 mean_entropies: 1.4812, took: 122.7020s
2022-10-09 12:11:42,562 [INFO] 	Process 4 - batch 33899: mean_policy_losses: -80.843, mean_net_lifetime: 4665.8824, mean_mc_travel_dist: 1598.5846, mean_rewards: 221.3494, total_rewards: 3097.9994, mean_steps: 22.0700, mean_ecr: 0.0399 mean_entropies: 1.4438, took: 115.9046s
2022-10-09 12:12:08,528 [INFO] 	Process 2 - batch 34099: mean_policy_losses: -90.451, mean_net_lifetime: 4221.3002, mean_mc_travel_dist: 1441.8060, mean_rewards: 240.2000, total_rewards: 2814.9192, mean_steps: 18.8200, mean_ecr: 0.0411 mean_entropies: 1.4793, took: 102.0923s
2022-10-09 12:12:14,975 [INFO] 	Process 6 - batch 34199: mean_policy_losses: -108.613, mean_net_lifetime: 4447.3394, mean_mc_travel_dist: 1561.1532, mean_rewards: 223.7860, total_rewards: 2921.7726, mean_steps: 20.6700, mean_ecr: 0.0405 mean_entropies: 1.4649, took: 109.3470s
2022-10-09 12:12:15,716 [INFO] 	Process 5 - batch 33899: mean_policy_losses: -44.975, mean_net_lifetime: 4246.8949, mean_mc_travel_dist: 1389.2520, mean_rewards: 229.7673, total_rewards: 2895.8148, mean_steps: 19.0100, mean_ecr: 0.0395 mean_entropies: 1.4093, took: 102.4609s
2022-10-09 12:12:18,102 [INFO] 	Process 1 - batch 35399: mean_policy_losses: -143.164, mean_net_lifetime: 5940.4822, mean_mc_travel_dist: 2199.1052, mean_rewards: 225.2210, total_rewards: 3775.5364, mean_steps: 29.8100, mean_ecr: 0.0385 mean_entropies: 1.4354, took: 144.8850s
2022-10-09 12:13:08,284 [INFO] 	Process 3 - batch 34099: mean_policy_losses: -95.601, mean_net_lifetime: 4165.8614, mean_mc_travel_dist: 1392.0718, mean_rewards: 243.0269, total_rewards: 2794.3408, mean_steps: 18.4100, mean_ecr: 0.0410 mean_entropies: 1.4558, took: 97.6046s
2022-10-09 12:13:27,976 [INFO] 	Process 4 - batch 33999: mean_policy_losses: -97.849, mean_net_lifetime: 4281.6395, mean_mc_travel_dist: 1459.5291, mean_rewards: 225.6626, total_rewards: 2861.2178, mean_steps: 19.6300, mean_ecr: 0.0428 mean_entropies: 1.4197, took: 105.4148s
2022-10-09 12:13:38,233 [INFO] 	Process 0 - batch 33899: mean_policy_losses: -22.024, mean_net_lifetime: 4968.2863, mean_mc_travel_dist: 1686.1722, mean_rewards: 222.0499, total_rewards: 3319.2583, mean_steps: 23.3600, mean_ecr: 0.0400 mean_entropies: 1.4321, took: 122.0691s
2022-10-09 12:13:51,587 [INFO] 	Process 2 - batch 34199: mean_policy_losses: -73.593, mean_net_lifetime: 4329.9364, mean_mc_travel_dist: 1471.9393, mean_rewards: 228.0006, total_rewards: 2899.8766, mean_steps: 19.2500, mean_ecr: 0.0404 mean_entropies: 1.4518, took: 103.0587s
2022-10-09 12:13:58,006 [INFO] 	Process 5 - batch 33999: mean_policy_losses: -96.762, mean_net_lifetime: 4145.6604, mean_mc_travel_dist: 1377.4270, mean_rewards: 231.8243, total_rewards: 2797.1493, mean_steps: 18.8000, mean_ecr: 0.0428 mean_entropies: 1.4320, took: 102.2891s
2022-10-09 12:14:14,808 [INFO] 	Process 6 - batch 34299: mean_policy_losses: 4.433, mean_net_lifetime: 5058.6927, mean_mc_travel_dist: 1751.4860, mean_rewards: 225.8600, total_rewards: 3340.2916, mean_steps: 23.2800, mean_ecr: 0.0377 mean_entropies: 1.5165, took: 119.8328s
2022-10-09 12:14:16,689 [INFO] 	Process 1 - batch 35499: mean_policy_losses: -165.145, mean_net_lifetime: 5138.4930, mean_mc_travel_dist: 1937.5044, mean_rewards: 235.4902, total_rewards: 3244.9055, mean_steps: 24.0000, mean_ecr: 0.0387 mean_entropies: 1.4923, took: 118.5865s
2022-10-09 12:14:49,452 [INFO] 	Process 3 - batch 34199: mean_policy_losses: -74.219, mean_net_lifetime: 4310.7184, mean_mc_travel_dist: 1447.6361, mean_rewards: 233.1788, total_rewards: 2895.3250, mean_steps: 19.1900, mean_ecr: 0.0403 mean_entropies: 1.4576, took: 101.1687s
2022-10-09 12:15:01,913 [INFO] 	Process 4 - batch 34099: mean_policy_losses: -122.965, mean_net_lifetime: 3996.7502, mean_mc_travel_dist: 1322.2126, mean_rewards: 240.0492, total_rewards: 2710.9184, mean_steps: 17.6400, mean_ecr: 0.0413 mean_entropies: 1.4675, took: 93.9366s
2022-10-09 12:15:33,013 [INFO] 	Process 0 - batch 33999: mean_policy_losses: -86.337, mean_net_lifetime: 4537.4145, mean_mc_travel_dist: 1593.8061, mean_rewards: 218.0630, total_rewards: 2976.5476, mean_steps: 21.3600, mean_ecr: 0.0422 mean_entropies: 1.4675, took: 114.7785s
2022-10-09 12:15:44,002 [INFO] 	Process 5 - batch 34099: mean_policy_losses: -109.044, mean_net_lifetime: 4254.4308, mean_mc_travel_dist: 1439.0843, mean_rewards: 223.7271, total_rewards: 2841.0756, mean_steps: 19.7800, mean_ecr: 0.0411 mean_entropies: 1.4931, took: 105.9961s
2022-10-09 12:15:52,493 [INFO] 	Process 2 - batch 34299: mean_policy_losses: -80.662, mean_net_lifetime: 4840.4921, mean_mc_travel_dist: 1709.6132, mean_rewards: 216.6491, total_rewards: 3168.8635, mean_steps: 23.0300, mean_ecr: 0.0381 mean_entropies: 1.5127, took: 120.9070s
2022-10-09 12:16:12,004 [INFO] 	Process 1 - batch 35599: mean_policy_losses: -101.939, mean_net_lifetime: 4978.7248, mean_mc_travel_dist: 1747.4294, mean_rewards: 222.2185, total_rewards: 3262.0908, mean_steps: 23.2900, mean_ecr: 0.0389 mean_entropies: 1.4959, took: 115.3149s
2022-10-09 12:16:16,892 [INFO] 	Process 6 - batch 34399: mean_policy_losses: -160.718, mean_net_lifetime: 4838.4611, mean_mc_travel_dist: 1707.8811, mean_rewards: 217.4837, total_rewards: 3176.6469, mean_steps: 23.2900, mean_ecr: 0.0395 mean_entropies: 1.4966, took: 122.0842s
2022-10-09 12:16:45,901 [INFO] 	Process 3 - batch 34299: mean_policy_losses: -59.300, mean_net_lifetime: 4631.8558, mean_mc_travel_dist: 1584.0943, mean_rewards: 214.8053, total_rewards: 3085.1954, mean_steps: 22.0900, mean_ecr: 0.0379 mean_entropies: 1.5037, took: 116.4485s
2022-10-09 12:16:51,360 [INFO] 	Process 4 - batch 34199: mean_policy_losses: -135.567, mean_net_lifetime: 4474.0261, mean_mc_travel_dist: 1535.7093, mean_rewards: 223.8709, total_rewards: 2971.6864, mean_steps: 20.8100, mean_ecr: 0.0402 mean_entropies: 1.4657, took: 109.4469s
2022-10-09 12:17:13,526 [INFO] 	Process 0 - batch 34099: mean_policy_losses: -199.840, mean_net_lifetime: 4105.6605, mean_mc_travel_dist: 1395.3246, mean_rewards: 232.3891, total_rewards: 2742.2838, mean_steps: 18.8600, mean_ecr: 0.0414 mean_entropies: 1.4703, took: 100.5145s
2022-10-09 12:17:41,360 [INFO] 	Process 2 - batch 34399: mean_policy_losses: -104.507, mean_net_lifetime: 4371.9949, mean_mc_travel_dist: 1525.4484, mean_rewards: 226.6620, total_rewards: 2884.0348, mean_steps: 20.3700, mean_ecr: 0.0395 mean_entropies: 1.4762, took: 108.8670s
2022-10-09 12:17:44,784 [INFO] 	Process 5 - batch 34199: mean_policy_losses: -58.762, mean_net_lifetime: 4878.1433, mean_mc_travel_dist: 1737.7232, mean_rewards: 227.5291, total_rewards: 3174.6248, mean_steps: 23.2900, mean_ecr: 0.0400 mean_entropies: 1.4708, took: 120.7825s
2022-10-09 12:18:08,137 [INFO] 	Process 1 - batch 35699: mean_policy_losses: -205.271, mean_net_lifetime: 4963.7661, mean_mc_travel_dist: 1818.5618, mean_rewards: 231.6501, total_rewards: 3179.1718, mean_steps: 23.4100, mean_ecr: 0.0385 mean_entropies: 1.4969, took: 116.1330s
2022-10-09 12:18:33,526 [INFO] 	Process 3 - batch 34399: mean_policy_losses: -82.615, mean_net_lifetime: 4428.1049, mean_mc_travel_dist: 1549.7909, mean_rewards: 225.6088, total_rewards: 2911.9308, mean_steps: 20.3500, mean_ecr: 0.0392 mean_entropies: 1.4748, took: 107.6229s
2022-10-09 12:18:43,741 [INFO] 	Process 6 - batch 34499: mean_policy_losses: -125.688, mean_net_lifetime: 5975.5381, mean_mc_travel_dist: 2222.9275, mean_rewards: 233.1083, total_rewards: 3782.2460, mean_steps: 28.5500, mean_ecr: 0.0396 mean_entropies: 1.5295, took: 146.8482s
2022-10-09 12:18:52,595 [INFO] 	Process 4 - batch 34299: mean_policy_losses: 6.656, mean_net_lifetime: 4990.4079, mean_mc_travel_dist: 1718.2686, mean_rewards: 216.3623, total_rewards: 3298.7374, mean_steps: 23.2900, mean_ecr: 0.0377 mean_entropies: 1.5092, took: 121.2329s
2022-10-09 12:18:58,425 [INFO] 	Process 0 - batch 34199: mean_policy_losses: -93.905, mean_net_lifetime: 4258.2319, mean_mc_travel_dist: 1455.0514, mean_rewards: 227.4437, total_rewards: 2834.5062, mean_steps: 19.4100, mean_ecr: 0.0406 mean_entropies: 1.4467, took: 104.8978s
2022-10-09 12:19:27,139 [INFO] 	Process 2 - batch 34499: mean_policy_losses: -137.934, mean_net_lifetime: 4507.0384, mean_mc_travel_dist: 1529.5565, mean_rewards: 226.6454, total_rewards: 3014.3463, mean_steps: 20.1400, mean_ecr: 0.0393 mean_entropies: 1.5311, took: 105.7784s
2022-10-09 12:19:42,072 [INFO] 	Process 5 - batch 34299: mean_policy_losses: -126.049, mean_net_lifetime: 4888.0199, mean_mc_travel_dist: 1683.9547, mean_rewards: 221.0670, total_rewards: 3232.0536, mean_steps: 22.5900, mean_ecr: 0.0378 mean_entropies: 1.5144, took: 117.2881s
2022-10-09 12:19:52,288 [INFO] 	Process 1 - batch 35799: mean_policy_losses: -80.244, mean_net_lifetime: 4645.3379, mean_mc_travel_dist: 1620.6126, mean_rewards: 226.1766, total_rewards: 3064.1944, mean_steps: 21.4500, mean_ecr: 0.0381 mean_entropies: 1.5103, took: 104.1506s
2022-10-09 12:20:27,431 [INFO] 	Process 3 - batch 34499: mean_policy_losses: -124.959, mean_net_lifetime: 5108.2489, mean_mc_travel_dist: 1803.5449, mean_rewards: 233.9589, total_rewards: 3340.3052, mean_steps: 23.1200, mean_ecr: 0.0394 mean_entropies: 1.5368, took: 113.9059s
2022-10-09 12:20:40,021 [INFO] 	Process 4 - batch 34399: mean_policy_losses: -209.877, mean_net_lifetime: 4620.0645, mean_mc_travel_dist: 1662.0537, mean_rewards: 229.5353, total_rewards: 2988.9435, mean_steps: 21.4300, mean_ecr: 0.0393 mean_entropies: 1.4765, took: 107.4280s
2022-10-09 12:20:52,230 [INFO] 	Process 0 - batch 34299: mean_policy_losses: -2.998, mean_net_lifetime: 5048.1010, mean_mc_travel_dist: 1754.6227, mean_rewards: 225.7742, total_rewards: 3331.0035, mean_steps: 23.2000, mean_ecr: 0.0380 mean_entropies: 1.5079, took: 113.8056s
2022-10-09 12:21:19,277 [INFO] 	Process 1 - batch 35899: mean_policy_losses: -97.338, mean_net_lifetime: 4194.6436, mean_mc_travel_dist: 1420.8125, mean_rewards: 226.7581, total_rewards: 2817.3182, mean_steps: 18.7100, mean_ecr: 0.0398 mean_entropies: 1.4589, took: 86.9895s
2022-10-09 12:21:36,558 [INFO] 	Process 5 - batch 34399: mean_policy_losses: -54.316, mean_net_lifetime: 5180.9044, mean_mc_travel_dist: 1832.8845, mean_rewards: 224.4113, total_rewards: 3399.5008, mean_steps: 23.9200, mean_ecr: 0.0397 mean_entropies: 1.4749, took: 114.4864s
2022-10-09 12:22:22,089 [INFO] 	Process 4 - batch 34499: mean_policy_losses: -109.471, mean_net_lifetime: 4767.4796, mean_mc_travel_dist: 1736.6113, mean_rewards: 230.8732, total_rewards: 3077.8479, mean_steps: 21.3200, mean_ecr: 0.0393 mean_entropies: 1.4890, took: 102.0675s
2022-10-09 12:22:25,646 [INFO] 	Process 0 - batch 34399: mean_policy_losses: -83.423, mean_net_lifetime: 4299.3273, mean_mc_travel_dist: 1534.6934, mean_rewards: 236.4146, total_rewards: 2811.5549, mean_steps: 19.0700, mean_ecr: 0.0391 mean_entropies: 1.4218, took: 93.4151s
2022-10-09 12:22:37,867 [INFO] 	Process 1 - batch 35999: mean_policy_losses: -83.252, mean_net_lifetime: 3879.5586, mean_mc_travel_dist: 1323.9653, mean_rewards: 228.1373, total_rewards: 2587.0605, mean_steps: 16.9500, mean_ecr: 0.0398 mean_entropies: 1.4576, took: 78.5901s
2022-10-09 12:23:08,815 [INFO] 	Process 5 - batch 34499: mean_policy_losses: -110.757, mean_net_lifetime: 4408.2971, mean_mc_travel_dist: 1581.7193, mean_rewards: 233.6972, total_rewards: 2863.5552, mean_steps: 19.4700, mean_ecr: 0.0394 mean_entropies: 1.4797, took: 92.2563s
2022-10-09 12:24:09,771 [INFO] 	Process 0 - batch 34499: mean_policy_losses: -142.318, mean_net_lifetime: 5268.6970, mean_mc_travel_dist: 1957.4455, mean_rewards: 233.2341, total_rewards: 3351.5585, mean_steps: 24.0200, mean_ecr: 0.0392 mean_entropies: 1.5272, took: 104.1258s
2022-10-09 12:30:51,884 [INFO] 	Process 6 - batch 34599: mean_policy_losses: -76.498, mean_net_lifetime: 4119.4537, mean_mc_travel_dist: 1460.6836, mean_rewards: 235.1667, total_rewards: 2701.0071, mean_steps: 18.2200, mean_ecr: 0.0385 mean_entropies: 1.4189, took: 728.1439s
2022-10-09 12:32:16,286 [INFO] 	Process 2 - batch 34599: mean_policy_losses: -76.537, mean_net_lifetime: 4304.7362, mean_mc_travel_dist: 1535.5098, mean_rewards: 225.1368, total_rewards: 2799.8055, mean_steps: 19.6400, mean_ecr: 0.0386 mean_entropies: 1.4069, took: 769.1477s
2022-10-09 12:32:21,559 [INFO] 	Process 6 - batch 34699: mean_policy_losses: -89.380, mean_net_lifetime: 4373.7464, mean_mc_travel_dist: 1575.8041, mean_rewards: 225.6357, total_rewards: 2836.3825, mean_steps: 19.9400, mean_ecr: 0.0406 mean_entropies: 1.4438, took: 89.6744s
2022-10-09 12:33:45,202 [INFO] 	Process 1 - batch 36099: mean_policy_losses: -46.493, mean_net_lifetime: 4370.7656, mean_mc_travel_dist: 1523.8084, mean_rewards: 224.5699, total_rewards: 2890.1595, mean_steps: 20.0100, mean_ecr: 0.0397 mean_entropies: 1.4960, took: 667.3352s
2022-10-09 12:33:45,577 [INFO] 	Process 3 - batch 34599: mean_policy_losses: -13.899, mean_net_lifetime: 4515.2790, mean_mc_travel_dist: 1615.4907, mean_rewards: 227.5361, total_rewards: 2937.1381, mean_steps: 20.4500, mean_ecr: 0.0384 mean_entropies: 1.4167, took: 798.1472s
2022-10-09 12:33:50,131 [INFO] 	Process 5 - batch 34599: mean_policy_losses: -61.940, mean_net_lifetime: 4637.6170, mean_mc_travel_dist: 1665.0609, mean_rewards: 224.0229, total_rewards: 3008.1838, mean_steps: 21.4600, mean_ecr: 0.0387 mean_entropies: 1.4305, took: 641.3164s
2022-10-09 12:34:04,279 [INFO] 	Process 4 - batch 34599: mean_policy_losses: -108.578, mean_net_lifetime: 4125.8884, mean_mc_travel_dist: 1465.0198, mean_rewards: 228.0288, total_rewards: 2698.1378, mean_steps: 19.2000, mean_ecr: 0.0389 mean_entropies: 1.3887, took: 702.1914s
2022-10-09 12:34:13,514 [INFO] 	Process 2 - batch 34699: mean_policy_losses: -7.088, mean_net_lifetime: 4833.1610, mean_mc_travel_dist: 1817.7150, mean_rewards: 224.9656, total_rewards: 3053.1730, mean_steps: 22.8300, mean_ecr: 0.0401 mean_entropies: 1.4243, took: 117.2275s
2022-10-09 12:34:18,153 [INFO] 	Process 6 - batch 34799: mean_policy_losses: -42.649, mean_net_lifetime: 4653.0091, mean_mc_travel_dist: 1631.7749, mean_rewards: 217.4744, total_rewards: 3053.2526, mean_steps: 22.6700, mean_ecr: 0.0380 mean_entropies: 1.4662, took: 116.5942s
2022-10-09 12:35:28,414 [INFO] 	Process 3 - batch 34699: mean_policy_losses: -104.708, mean_net_lifetime: 4210.7180, mean_mc_travel_dist: 1472.0173, mean_rewards: 228.7538, total_rewards: 2776.3801, mean_steps: 19.0700, mean_ecr: 0.0406 mean_entropies: 1.4433, took: 102.8370s
2022-10-09 12:35:32,681 [INFO] 	Process 1 - batch 36199: mean_policy_losses: -66.199, mean_net_lifetime: 4511.4779, mean_mc_travel_dist: 1599.0492, mean_rewards: 218.2452, total_rewards: 2948.9295, mean_steps: 21.4600, mean_ecr: 0.0380 mean_entropies: 1.4707, took: 107.4781s
2022-10-09 12:35:54,276 [INFO] 	Process 0 - batch 34599: mean_policy_losses: -98.751, mean_net_lifetime: 4733.7179, mean_mc_travel_dist: 1715.8977, mean_rewards: 227.9065, total_rewards: 3051.9967, mean_steps: 22.6200, mean_ecr: 0.0386 mean_entropies: 1.4154, took: 704.5043s
2022-10-09 12:36:05,054 [INFO] 	Process 6 - batch 34899: mean_policy_losses: -62.695, mean_net_lifetime: 4385.8069, mean_mc_travel_dist: 1520.8260, mean_rewards: 231.9267, total_rewards: 2899.0760, mean_steps: 19.9100, mean_ecr: 0.0413 mean_entropies: 1.4366, took: 106.9010s
2022-10-09 12:36:15,278 [INFO] 	Process 5 - batch 34699: mean_policy_losses: -100.355, mean_net_lifetime: 5671.1570, mean_mc_travel_dist: 2262.1527, mean_rewards: 217.3489, total_rewards: 3446.0249, mean_steps: 28.0200, mean_ecr: 0.0404 mean_entropies: 1.4278, took: 145.1467s
2022-10-09 12:36:23,836 [INFO] 	Process 2 - batch 34799: mean_policy_losses: -40.901, mean_net_lifetime: 4866.0677, mean_mc_travel_dist: 1682.6131, mean_rewards: 211.2202, total_rewards: 3221.7916, mean_steps: 24.5800, mean_ecr: 0.0379 mean_entropies: 1.4738, took: 130.3222s
2022-10-09 12:36:34,608 [INFO] 	Process 4 - batch 34699: mean_policy_losses: -142.371, mean_net_lifetime: 6077.6116, mean_mc_travel_dist: 2493.6859, mean_rewards: 222.8584, total_rewards: 3620.5655, mean_steps: 29.4200, mean_ecr: 0.0402 mean_entropies: 1.4453, took: 150.3289s
2022-10-09 12:37:20,223 [INFO] 	Process 1 - batch 36299: mean_policy_losses: -26.185, mean_net_lifetime: 4820.9600, mean_mc_travel_dist: 1706.4186, mean_rewards: 229.9025, total_rewards: 3147.7948, mean_steps: 21.4900, mean_ecr: 0.0388 mean_entropies: 1.4404, took: 107.5423s
2022-10-09 12:37:40,515 [INFO] 	Process 3 - batch 34799: mean_policy_losses: -141.724, mean_net_lifetime: 5114.9939, mean_mc_travel_dist: 1822.2153, mean_rewards: 216.9708, total_rewards: 3325.1770, mean_steps: 25.6800, mean_ecr: 0.0381 mean_entropies: 1.4872, took: 132.1006s
2022-10-09 12:37:50,963 [INFO] 	Process 0 - batch 34699: mean_policy_losses: -80.413, mean_net_lifetime: 4735.9582, mean_mc_travel_dist: 1718.8180, mean_rewards: 232.7074, total_rewards: 3051.6044, mean_steps: 21.8600, mean_ecr: 0.0406 mean_entropies: 1.4457, took: 116.6874s
2022-10-09 12:37:59,231 [INFO] 	Process 2 - batch 34899: mean_policy_losses: -86.464, mean_net_lifetime: 4137.1316, mean_mc_travel_dist: 1365.0521, mean_rewards: 243.3985, total_rewards: 2806.6311, mean_steps: 17.5300, mean_ecr: 0.0415 mean_entropies: 1.4467, took: 95.3947s
2022-10-09 12:38:04,431 [INFO] 	Process 6 - batch 34999: mean_policy_losses: -73.172, mean_net_lifetime: 4878.1154, mean_mc_travel_dist: 1725.4660, mean_rewards: 222.6348, total_rewards: 3184.9184, mean_steps: 22.7100, mean_ecr: 0.0398 mean_entropies: 1.4686, took: 119.3774s
2022-10-09 12:38:16,688 [INFO] 	Process 5 - batch 34799: mean_policy_losses: -103.991, mean_net_lifetime: 4588.5439, mean_mc_travel_dist: 1591.0137, mean_rewards: 213.9494, total_rewards: 3040.2895, mean_steps: 22.7900, mean_ecr: 0.0382 mean_entropies: 1.4881, took: 121.4097s
2022-10-09 12:38:51,406 [INFO] 	Process 1 - batch 36399: mean_policy_losses: -120.742, mean_net_lifetime: 3971.6685, mean_mc_travel_dist: 1331.6145, mean_rewards: 231.7490, total_rewards: 2679.6627, mean_steps: 18.0400, mean_ecr: 0.0402 mean_entropies: 1.3366, took: 91.1833s
2022-10-09 12:38:53,591 [INFO] 	Process 4 - batch 34799: mean_policy_losses: -23.718, mean_net_lifetime: 5256.9773, mean_mc_travel_dist: 1960.4303, mean_rewards: 214.5684, total_rewards: 3338.8156, mean_steps: 26.7800, mean_ecr: 0.0381 mean_entropies: 1.5221, took: 138.9830s
2022-10-09 12:39:13,807 [INFO] 	Process 3 - batch 34899: mean_policy_losses: -53.118, mean_net_lifetime: 4033.9362, mean_mc_travel_dist: 1315.3229, mean_rewards: 243.0630, total_rewards: 2743.2596, mean_steps: 17.0500, mean_ecr: 0.0415 mean_entropies: 1.4391, took: 93.2923s
2022-10-09 12:39:47,193 [INFO] 	Process 0 - batch 34799: mean_policy_losses: -97.214, mean_net_lifetime: 4535.3750, mean_mc_travel_dist: 1573.7651, mean_rewards: 215.4226, total_rewards: 2995.9040, mean_steps: 21.8200, mean_ecr: 0.0375 mean_entropies: 1.4874, took: 116.2291s
2022-10-09 12:39:51,874 [INFO] 	Process 2 - batch 34999: mean_policy_losses: -78.469, mean_net_lifetime: 4711.2496, mean_mc_travel_dist: 1656.5682, mean_rewards: 224.8076, total_rewards: 3096.5266, mean_steps: 21.4000, mean_ecr: 0.0398 mean_entropies: 1.3993, took: 112.6423s
2022-10-09 12:39:55,849 [INFO] 	Process 6 - batch 35099: mean_policy_losses: -127.486, mean_net_lifetime: 4462.8120, mean_mc_travel_dist: 1520.4565, mean_rewards: 229.3079, total_rewards: 2978.6139, mean_steps: 21.1300, mean_ecr: 0.0382 mean_entropies: 1.4582, took: 111.4180s
2022-10-09 12:40:02,129 [INFO] 	Process 5 - batch 34899: mean_policy_losses: -7.964, mean_net_lifetime: 4549.8281, mean_mc_travel_dist: 1528.7422, mean_rewards: 234.1110, total_rewards: 3055.3418, mean_steps: 19.6200, mean_ecr: 0.0415 mean_entropies: 1.4664, took: 105.4419s
2022-10-09 12:40:27,210 [INFO] 	Process 1 - batch 36499: mean_policy_losses: -240.419, mean_net_lifetime: 4064.5910, mean_mc_travel_dist: 1345.0904, mean_rewards: 224.6566, total_rewards: 2753.5518, mean_steps: 19.0200, mean_ecr: 0.0401 mean_entropies: 1.4394, took: 95.8040s
2022-10-09 12:40:38,620 [INFO] 	Process 4 - batch 34899: mean_policy_losses: -101.592, mean_net_lifetime: 4311.6195, mean_mc_travel_dist: 1457.6786, mean_rewards: 229.3914, total_rewards: 2886.8951, mean_steps: 19.7700, mean_ecr: 0.0411 mean_entropies: 1.4234, took: 105.0294s
2022-10-09 12:41:35,392 [INFO] 	Process 3 - batch 34999: mean_policy_losses: -70.885, mean_net_lifetime: 5805.3425, mean_mc_travel_dist: 2100.6367, mean_rewards: 223.8393, total_rewards: 3745.9314, mean_steps: 27.9700, mean_ecr: 0.0400 mean_entropies: 1.4249, took: 141.5852s
2022-10-09 12:41:36,439 [INFO] 	Process 0 - batch 34899: mean_policy_losses: -39.736, mean_net_lifetime: 4593.3583, mean_mc_travel_dist: 1525.1166, mean_rewards: 234.4611, total_rewards: 3114.2797, mean_steps: 20.2200, mean_ecr: 0.0413 mean_entropies: 1.4334, took: 109.2468s
2022-10-09 12:41:44,162 [INFO] 	Process 6 - batch 35199: mean_policy_losses: -135.004, mean_net_lifetime: 4323.5603, mean_mc_travel_dist: 1468.8954, mean_rewards: 222.9569, total_rewards: 2890.9623, mean_steps: 20.3200, mean_ecr: 0.0383 mean_entropies: 1.4301, took: 108.3122s
2022-10-09 12:41:47,930 [INFO] 	Process 2 - batch 35099: mean_policy_losses: -99.654, mean_net_lifetime: 4723.2339, mean_mc_travel_dist: 1603.6744, mean_rewards: 230.8556, total_rewards: 3154.0342, mean_steps: 21.8400, mean_ecr: 0.0386 mean_entropies: 1.4826, took: 116.0568s
2022-10-09 12:41:48,882 [INFO] 	Process 5 - batch 34999: mean_policy_losses: -146.620, mean_net_lifetime: 4498.8284, mean_mc_travel_dist: 1525.1478, mean_rewards: 230.6713, total_rewards: 3011.7166, mean_steps: 20.1300, mean_ecr: 0.0399 mean_entropies: 1.4366, took: 106.7520s
2022-10-09 12:42:12,365 [INFO] 	Process 1 - batch 36599: mean_policy_losses: -76.856, mean_net_lifetime: 4571.2680, mean_mc_travel_dist: 1570.9278, mean_rewards: 225.5267, total_rewards: 3038.6943, mean_steps: 20.9600, mean_ecr: 0.0402 mean_entropies: 1.4346, took: 105.1547s
2022-10-09 12:42:33,226 [INFO] 	Process 4 - batch 34999: mean_policy_losses: -52.599, mean_net_lifetime: 4765.8986, mean_mc_travel_dist: 1670.6814, mean_rewards: 229.3162, total_rewards: 3134.7119, mean_steps: 21.6800, mean_ecr: 0.0399 mean_entropies: 1.4177, took: 114.6057s
2022-10-09 12:43:21,453 [INFO] 	Process 3 - batch 35099: mean_policy_losses: -123.146, mean_net_lifetime: 4396.6255, mean_mc_travel_dist: 1468.3009, mean_rewards: 230.8617, total_rewards: 2970.4684, mean_steps: 20.1600, mean_ecr: 0.0385 mean_entropies: 1.5106, took: 106.0604s
2022-10-09 12:43:34,282 [INFO] 	Process 2 - batch 35199: mean_policy_losses: -136.321, mean_net_lifetime: 4282.4455, mean_mc_travel_dist: 1481.2577, mean_rewards: 234.3395, total_rewards: 2837.9170, mean_steps: 19.5000, mean_ecr: 0.0387 mean_entropies: 1.4162, took: 106.3515s
2022-10-09 12:43:38,607 [INFO] 	Process 5 - batch 35099: mean_policy_losses: -134.621, mean_net_lifetime: 4434.4961, mean_mc_travel_dist: 1515.5717, mean_rewards: 228.9271, total_rewards: 2954.7417, mean_steps: 20.4200, mean_ecr: 0.0381 mean_entropies: 1.4873, took: 109.7250s
2022-10-09 12:43:39,175 [INFO] 	Process 1 - batch 36699: mean_policy_losses: -110.843, mean_net_lifetime: 3970.7048, mean_mc_travel_dist: 1343.0703, mean_rewards: 234.6777, total_rewards: 2674.0901, mean_steps: 17.1000, mean_ecr: 0.0392 mean_entropies: 1.3990, took: 86.8103s
2022-10-09 12:43:42,590 [INFO] 	Process 6 - batch 35299: mean_policy_losses: -55.524, mean_net_lifetime: 4865.6645, mean_mc_travel_dist: 1788.9671, mean_rewards: 231.5199, total_rewards: 3111.5108, mean_steps: 22.5900, mean_ecr: 0.0397 mean_entropies: 1.4045, took: 118.4281s
2022-10-09 12:44:03,420 [INFO] 	Process 0 - batch 34999: mean_policy_losses: -47.431, mean_net_lifetime: 6026.3467, mean_mc_travel_dist: 2265.8231, mean_rewards: 225.6449, total_rewards: 3799.8591, mean_steps: 28.2800, mean_ecr: 0.0400 mean_entropies: 1.4153, took: 146.9807s
2022-10-09 12:44:29,209 [INFO] 	Process 4 - batch 35099: mean_policy_losses: -107.314, mean_net_lifetime: 4835.7482, mean_mc_travel_dist: 1699.2655, mean_rewards: 228.3660, total_rewards: 3170.9453, mean_steps: 21.9500, mean_ecr: 0.0385 mean_entropies: 1.4923, took: 115.9818s
2022-10-09 12:45:00,529 [INFO] 	Process 3 - batch 35199: mean_policy_losses: -137.179, mean_net_lifetime: 4195.0197, mean_mc_travel_dist: 1458.9031, mean_rewards: 227.5591, total_rewards: 2779.6061, mean_steps: 18.8000, mean_ecr: 0.0386 mean_entropies: 1.4790, took: 99.0754s
2022-10-09 12:45:16,692 [INFO] 	Process 5 - batch 35199: mean_policy_losses: -174.782, mean_net_lifetime: 3973.0428, mean_mc_travel_dist: 1371.1586, mean_rewards: 230.6532, total_rewards: 2641.1455, mean_steps: 18.0400, mean_ecr: 0.0389 mean_entropies: 1.4403, took: 98.0848s
2022-10-09 12:45:18,136 [INFO] 	Process 2 - batch 35299: mean_policy_losses: -59.416, mean_net_lifetime: 4254.0929, mean_mc_travel_dist: 1474.3891, mean_rewards: 222.5668, total_rewards: 2819.3082, mean_steps: 19.3100, mean_ecr: 0.0394 mean_entropies: 1.4399, took: 103.8545s
2022-10-09 12:45:18,446 [INFO] 	Process 1 - batch 36799: mean_policy_losses: -100.409, mean_net_lifetime: 4468.1573, mean_mc_travel_dist: 1558.4894, mean_rewards: 230.4816, total_rewards: 2943.8072, mean_steps: 19.6800, mean_ecr: 0.0376 mean_entropies: 1.5495, took: 99.2709s
2022-10-09 12:45:25,034 [INFO] 	Process 6 - batch 35399: mean_policy_losses: -107.234, mean_net_lifetime: 4404.7502, mean_mc_travel_dist: 1560.1332, mean_rewards: 235.7270, total_rewards: 2878.4992, mean_steps: 19.2000, mean_ecr: 0.0387 mean_entropies: 1.4543, took: 102.4449s
2022-10-09 12:45:49,607 [INFO] 	Process 0 - batch 35099: mean_policy_losses: -134.811, mean_net_lifetime: 4338.2591, mean_mc_travel_dist: 1464.3437, mean_rewards: 230.9649, total_rewards: 2912.9866, mean_steps: 19.7100, mean_ecr: 0.0388 mean_entropies: 1.5012, took: 106.1868s
2022-10-09 12:46:11,513 [INFO] 	Process 4 - batch 35199: mean_policy_losses: -218.426, mean_net_lifetime: 4091.1128, mean_mc_travel_dist: 1427.6762, mean_rewards: 226.0815, total_rewards: 2702.0254, mean_steps: 19.1200, mean_ecr: 0.0386 mean_entropies: 1.4128, took: 102.3043s
2022-10-09 12:46:55,518 [INFO] 	Process 3 - batch 35299: mean_policy_losses: -37.279, mean_net_lifetime: 4509.4176, mean_mc_travel_dist: 1635.9310, mean_rewards: 217.0462, total_rewards: 2910.4646, mean_steps: 21.9100, mean_ecr: 0.0397 mean_entropies: 1.4113, took: 114.9895s
2022-10-09 12:47:02,922 [INFO] 	Process 5 - batch 35299: mean_policy_losses: -117.043, mean_net_lifetime: 4237.6529, mean_mc_travel_dist: 1480.7979, mean_rewards: 220.6419, total_rewards: 2795.0618, mean_steps: 20.0500, mean_ecr: 0.0397 mean_entropies: 1.4169, took: 106.2302s
2022-10-09 12:47:04,388 [INFO] 	Process 1 - batch 36899: mean_policy_losses: -114.172, mean_net_lifetime: 4594.3403, mean_mc_travel_dist: 1607.3952, mean_rewards: 230.6795, total_rewards: 3020.9260, mean_steps: 21.0600, mean_ecr: 0.0399 mean_entropies: 1.4656, took: 105.9419s
2022-10-09 12:47:15,286 [INFO] 	Process 2 - batch 35399: mean_policy_losses: -17.388, mean_net_lifetime: 4827.2703, mean_mc_travel_dist: 1687.9077, mean_rewards: 224.1438, total_rewards: 3175.9389, mean_steps: 22.2700, mean_ecr: 0.0385 mean_entropies: 1.4713, took: 117.1498s
2022-10-09 12:47:37,586 [INFO] 	Process 0 - batch 35199: mean_policy_losses: -201.561, mean_net_lifetime: 4365.2615, mean_mc_travel_dist: 1570.1197, mean_rewards: 228.2383, total_rewards: 2841.0158, mean_steps: 20.1400, mean_ecr: 0.0385 mean_entropies: 1.4478, took: 107.9799s
2022-10-09 12:47:46,570 [INFO] 	Process 6 - batch 35499: mean_policy_losses: -59.918, mean_net_lifetime: 5565.3711, mean_mc_travel_dist: 2082.5688, mean_rewards: 221.0342, total_rewards: 3520.5374, mean_steps: 27.2800, mean_ecr: 0.0388 mean_entropies: 1.5040, took: 141.5339s
2022-10-09 12:48:06,318 [INFO] 	Process 4 - batch 35299: mean_policy_losses: -58.730, mean_net_lifetime: 4684.9391, mean_mc_travel_dist: 1659.6816, mean_rewards: 226.3370, total_rewards: 3064.1330, mean_steps: 21.8400, mean_ecr: 0.0397 mean_entropies: 1.4193, took: 114.8056s
2022-10-09 12:48:28,784 [INFO] 	Process 1 - batch 36999: mean_policy_losses: -187.767, mean_net_lifetime: 3900.2307, mean_mc_travel_dist: 1297.3928, mean_rewards: 243.2262, total_rewards: 2638.8947, mean_steps: 16.4300, mean_ecr: 0.0406 mean_entropies: 1.4772, took: 84.3962s
2022-10-09 12:48:45,621 [INFO] 	Process 5 - batch 35399: mean_policy_losses: -120.961, mean_net_lifetime: 4357.4231, mean_mc_travel_dist: 1523.7917, mean_rewards: 233.2471, total_rewards: 2872.8400, mean_steps: 19.1400, mean_ecr: 0.0388 mean_entropies: 1.4712, took: 102.6988s
2022-10-09 12:48:46,224 [INFO] 	Process 3 - batch 35399: mean_policy_losses: -39.308, mean_net_lifetime: 4686.9009, mean_mc_travel_dist: 1639.8075, mean_rewards: 228.9403, total_rewards: 3071.3324, mean_steps: 21.1700, mean_ecr: 0.0384 mean_entropies: 1.4586, took: 110.7063s
2022-10-09 12:49:16,604 [INFO] 	Process 2 - batch 35499: mean_policy_losses: -112.852, mean_net_lifetime: 4958.6740, mean_mc_travel_dist: 1840.6277, mean_rewards: 231.3728, total_rewards: 3157.3473, mean_steps: 23.1100, mean_ecr: 0.0386 mean_entropies: 1.4719, took: 121.3177s
2022-10-09 12:49:19,891 [INFO] 	Process 0 - batch 35299: mean_policy_losses: -129.954, mean_net_lifetime: 4147.0763, mean_mc_travel_dist: 1425.3230, mean_rewards: 227.9328, total_rewards: 2763.0460, mean_steps: 18.9600, mean_ecr: 0.0394 mean_entropies: 1.4428, took: 102.3041s
2022-10-09 12:49:27,542 [INFO] 	Process 6 - batch 35599: mean_policy_losses: -176.140, mean_net_lifetime: 4179.3918, mean_mc_travel_dist: 1398.4157, mean_rewards: 221.0719, total_rewards: 2817.1720, mean_steps: 18.9900, mean_ecr: 0.0395 mean_entropies: 1.4449, took: 100.9726s
2022-10-09 12:50:06,066 [INFO] 	Process 4 - batch 35399: mean_policy_losses: -49.332, mean_net_lifetime: 4923.4661, mean_mc_travel_dist: 1711.8606, mean_rewards: 223.8895, total_rewards: 3254.5259, mean_steps: 22.6900, mean_ecr: 0.0383 mean_entropies: 1.4592, took: 119.7482s
2022-10-09 12:50:14,783 [INFO] 	Process 1 - batch 37099: mean_policy_losses: -119.697, mean_net_lifetime: 4567.6890, mean_mc_travel_dist: 1583.9847, mean_rewards: 221.7128, total_rewards: 3019.9797, mean_steps: 21.2700, mean_ecr: 0.0383 mean_entropies: 1.3975, took: 105.9994s
2022-10-09 12:50:53,868 [INFO] 	Process 5 - batch 35499: mean_policy_losses: -220.753, mean_net_lifetime: 5280.8654, mean_mc_travel_dist: 1988.6280, mean_rewards: 233.7471, total_rewards: 3333.1450, mean_steps: 24.7700, mean_ecr: 0.0387 mean_entropies: 1.4394, took: 128.2467s
2022-10-09 12:51:06,063 [INFO] 	Process 3 - batch 35499: mean_policy_losses: -225.692, mean_net_lifetime: 5727.2786, mean_mc_travel_dist: 2141.9168, mean_rewards: 225.2158, total_rewards: 3623.9890, mean_steps: 27.1000, mean_ecr: 0.0387 mean_entropies: 1.4642, took: 139.8386s
2022-10-09 12:51:08,904 [INFO] 	Process 2 - batch 35599: mean_policy_losses: -70.441, mean_net_lifetime: 4652.8306, mean_mc_travel_dist: 1573.1367, mean_rewards: 226.7662, total_rewards: 3115.0841, mean_steps: 20.9000, mean_ecr: 0.0392 mean_entropies: 1.4729, took: 112.3009s
2022-10-09 12:51:09,754 [INFO] 	Process 0 - batch 35399: mean_policy_losses: -36.847, mean_net_lifetime: 4566.6107, mean_mc_travel_dist: 1607.3475, mean_rewards: 229.1636, total_rewards: 2998.2074, mean_steps: 20.7200, mean_ecr: 0.0384 mean_entropies: 1.4407, took: 109.8641s
2022-10-09 12:51:23,521 [INFO] 	Process 6 - batch 35699: mean_policy_losses: -91.577, mean_net_lifetime: 4769.8833, mean_mc_travel_dist: 1673.4192, mean_rewards: 226.7559, total_rewards: 3138.8446, mean_steps: 22.0800, mean_ecr: 0.0381 mean_entropies: 1.4688, took: 115.9803s
2022-10-09 12:51:56,252 [INFO] 	Process 1 - batch 37199: mean_policy_losses: -91.413, mean_net_lifetime: 4357.7242, mean_mc_travel_dist: 1499.8396, mean_rewards: 222.9400, total_rewards: 2894.4536, mean_steps: 20.1400, mean_ecr: 0.0386 mean_entropies: 1.4895, took: 101.4680s
2022-10-09 12:52:02,574 [INFO] 	Process 4 - batch 35499: mean_policy_losses: -183.258, mean_net_lifetime: 4853.4435, mean_mc_travel_dist: 1776.2293, mean_rewards: 231.5988, total_rewards: 3113.5349, mean_steps: 22.0000, mean_ecr: 0.0389 mean_entropies: 1.4579, took: 116.5066s
2022-10-09 12:52:39,256 [INFO] 	Process 5 - batch 35599: mean_policy_losses: -81.620, mean_net_lifetime: 4331.8810, mean_mc_travel_dist: 1454.7811, mean_rewards: 224.2778, total_rewards: 2912.9435, mean_steps: 19.4400, mean_ecr: 0.0391 mean_entropies: 1.5164, took: 105.3893s
2022-10-09 12:52:51,688 [INFO] 	Process 3 - batch 35599: mean_policy_losses: -140.132, mean_net_lifetime: 4511.8694, mean_mc_travel_dist: 1523.0232, mean_rewards: 228.8750, total_rewards: 3019.3091, mean_steps: 19.9700, mean_ecr: 0.0393 mean_entropies: 1.4975, took: 105.6260s
2022-10-09 12:53:05,508 [INFO] 	Process 0 - batch 35499: mean_policy_losses: -202.178, mean_net_lifetime: 4851.6946, mean_mc_travel_dist: 1728.8009, mean_rewards: 232.7191, total_rewards: 3165.1460, mean_steps: 21.7400, mean_ecr: 0.0386 mean_entropies: 1.4963, took: 115.7538s
2022-10-09 12:53:06,236 [INFO] 	Process 2 - batch 35699: mean_policy_losses: -124.966, mean_net_lifetime: 4922.3327, mean_mc_travel_dist: 1744.2754, mean_rewards: 230.4109, total_rewards: 3216.4042, mean_steps: 22.2000, mean_ecr: 0.0382 mean_entropies: 1.4755, took: 117.3317s
2022-10-09 12:53:21,906 [INFO] 	Process 6 - batch 35799: mean_policy_losses: -150.081, mean_net_lifetime: 4878.7350, mean_mc_travel_dist: 1749.5275, mean_rewards: 223.0822, total_rewards: 3175.3412, mean_steps: 22.5800, mean_ecr: 0.0381 mean_entropies: 1.4974, took: 118.3849s
2022-10-09 12:53:51,530 [INFO] 	Process 4 - batch 35599: mean_policy_losses: -26.226, mean_net_lifetime: 4555.9406, mean_mc_travel_dist: 1551.4973, mean_rewards: 225.7741, total_rewards: 3034.2620, mean_steps: 20.4100, mean_ecr: 0.0394 mean_entropies: 1.5037, took: 108.9574s
2022-10-09 12:54:12,565 [INFO] 	Process 1 - batch 37299: mean_policy_losses: -51.410, mean_net_lifetime: 6041.8494, mean_mc_travel_dist: 2467.9118, mean_rewards: 243.6472, total_rewards: 3610.3043, mean_steps: 28.0800, mean_ecr: 0.0389 mean_entropies: 1.4761, took: 136.3131s
2022-10-09 12:54:25,498 [INFO] 	Process 5 - batch 35699: mean_policy_losses: -135.755, mean_net_lifetime: 4431.2728, mean_mc_travel_dist: 1579.6670, mean_rewards: 234.7178, total_rewards: 2898.4322, mean_steps: 19.7400, mean_ecr: 0.0381 mean_entropies: 1.5012, took: 106.2417s
2022-10-09 12:54:32,391 [INFO] 	Process 3 - batch 35699: mean_policy_losses: -195.611, mean_net_lifetime: 4347.7859, mean_mc_travel_dist: 1532.9593, mean_rewards: 234.3483, total_rewards: 2851.6985, mean_steps: 18.9900, mean_ecr: 0.0381 mean_entropies: 1.4897, took: 100.7027s
2022-10-09 12:54:44,278 [INFO] 	Process 0 - batch 35599: mean_policy_losses: -109.734, mean_net_lifetime: 4118.1066, mean_mc_travel_dist: 1376.6360, mean_rewards: 227.7769, total_rewards: 2780.6332, mean_steps: 18.3600, mean_ecr: 0.0391 mean_entropies: 1.5062, took: 98.7699s
2022-10-09 12:54:55,371 [INFO] 	Process 2 - batch 35799: mean_policy_losses: -67.469, mean_net_lifetime: 4604.3698, mean_mc_travel_dist: 1622.7232, mean_rewards: 230.1614, total_rewards: 3018.4208, mean_steps: 20.7800, mean_ecr: 0.0377 mean_entropies: 1.4830, took: 109.1344s
2022-10-09 12:55:03,398 [INFO] 	Process 6 - batch 35899: mean_policy_losses: -62.995, mean_net_lifetime: 4285.3896, mean_mc_travel_dist: 1449.7639, mean_rewards: 227.2358, total_rewards: 2868.8846, mean_steps: 18.9700, mean_ecr: 0.0391 mean_entropies: 1.4712, took: 101.4907s
2022-10-09 12:55:40,943 [INFO] 	Process 4 - batch 35699: mean_policy_losses: -131.997, mean_net_lifetime: 4717.6174, mean_mc_travel_dist: 1718.1527, mean_rewards: 230.1169, total_rewards: 3040.3027, mean_steps: 21.0800, mean_ecr: 0.0386 mean_entropies: 1.5518, took: 109.4120s
2022-10-09 12:55:53,821 [INFO] 	Process 1 - batch 37399: mean_policy_losses: -99.178, mean_net_lifetime: 4686.1137, mean_mc_travel_dist: 1627.5745, mean_rewards: 232.4622, total_rewards: 3090.7063, mean_steps: 20.1900, mean_ecr: 0.0392 mean_entropies: 1.5229, took: 101.2572s
2022-10-09 12:56:18,253 [INFO] 	Process 5 - batch 35799: mean_policy_losses: -80.529, mean_net_lifetime: 4694.0486, mean_mc_travel_dist: 1671.2716, mean_rewards: 227.3249, total_rewards: 3061.4737, mean_steps: 21.1900, mean_ecr: 0.0381 mean_entropies: 1.5230, took: 112.7543s
2022-10-09 12:56:23,560 [INFO] 	Process 3 - batch 35799: mean_policy_losses: -28.804, mean_net_lifetime: 4694.3295, mean_mc_travel_dist: 1638.1439, mean_rewards: 233.1491, total_rewards: 3090.4638, mean_steps: 21.0900, mean_ecr: 0.0379 mean_entropies: 1.5007, took: 111.1683s
2022-10-09 12:56:36,935 [INFO] 	Process 2 - batch 35899: mean_policy_losses: -148.608, mean_net_lifetime: 4212.4120, mean_mc_travel_dist: 1428.4853, mean_rewards: 229.2147, total_rewards: 2814.3489, mean_steps: 18.8000, mean_ecr: 0.0395 mean_entropies: 1.5132, took: 101.5644s
2022-10-09 12:56:38,007 [INFO] 	Process 0 - batch 35699: mean_policy_losses: -216.670, mean_net_lifetime: 4742.0405, mean_mc_travel_dist: 1700.8732, mean_rewards: 232.2579, total_rewards: 3078.1997, mean_steps: 21.3200, mean_ecr: 0.0380 mean_entropies: 1.5175, took: 113.7289s
2022-10-09 12:56:40,177 [INFO] 	Process 6 - batch 35999: mean_policy_losses: -95.282, mean_net_lifetime: 4167.7421, mean_mc_travel_dist: 1419.2078, mean_rewards: 225.9950, total_rewards: 2789.5137, mean_steps: 18.1900, mean_ecr: 0.0401 mean_entropies: 1.5215, took: 96.7803s
2022-10-09 12:57:34,681 [INFO] 	Process 4 - batch 35799: mean_policy_losses: -152.344, mean_net_lifetime: 4956.5210, mean_mc_travel_dist: 1798.1317, mean_rewards: 232.6780, total_rewards: 3192.1805, mean_steps: 22.4900, mean_ecr: 0.0380 mean_entropies: 1.5191, took: 113.7390s
2022-10-09 12:57:36,188 [INFO] 	Process 1 - batch 37499: mean_policy_losses: -66.775, mean_net_lifetime: 4732.4572, mean_mc_travel_dist: 1597.7604, mean_rewards: 235.4495, total_rewards: 3174.5770, mean_steps: 20.6600, mean_ecr: 0.0389 mean_entropies: 1.5271, took: 102.3664s
2022-10-09 12:58:00,899 [INFO] 	Process 5 - batch 35899: mean_policy_losses: -165.663, mean_net_lifetime: 4413.6346, mean_mc_travel_dist: 1568.9092, mean_rewards: 222.0737, total_rewards: 2888.6312, mean_steps: 19.9900, mean_ecr: 0.0394 mean_entropies: 1.4945, took: 102.6466s
2022-10-09 12:58:02,149 [INFO] 	Process 3 - batch 35899: mean_policy_losses: -108.834, mean_net_lifetime: 4391.1100, mean_mc_travel_dist: 1514.5192, mean_rewards: 229.7893, total_rewards: 2914.9508, mean_steps: 19.3700, mean_ecr: 0.0392 mean_entropies: 1.5175, took: 98.5880s
2022-10-09 12:58:12,503 [INFO] 	Process 2 - batch 35999: mean_policy_losses: -44.220, mean_net_lifetime: 4377.7920, mean_mc_travel_dist: 1477.9040, mean_rewards: 236.1497, total_rewards: 2937.4241, mean_steps: 18.7100, mean_ecr: 0.0401 mean_entropies: 1.5158, took: 95.5682s
2022-10-09 12:58:16,316 [INFO] 	Process 0 - batch 35799: mean_policy_losses: -88.727, mean_net_lifetime: 4353.1058, mean_mc_travel_dist: 1517.9059, mean_rewards: 228.2654, total_rewards: 2878.0632, mean_steps: 19.3200, mean_ecr: 0.0379 mean_entropies: 1.4993, took: 98.3090s
2022-10-09 12:59:02,868 [INFO] 	Process 4 - batch 35899: mean_policy_losses: -166.420, mean_net_lifetime: 4034.4871, mean_mc_travel_dist: 1401.9692, mean_rewards: 225.0749, total_rewards: 2682.6325, mean_steps: 18.1600, mean_ecr: 0.0395 mean_entropies: 1.4832, took: 88.1867s
2022-10-09 12:59:32,403 [INFO] 	Process 5 - batch 35999: mean_policy_losses: -72.335, mean_net_lifetime: 4171.6985, mean_mc_travel_dist: 1394.2465, mean_rewards: 226.9414, total_rewards: 2813.2218, mean_steps: 18.4200, mean_ecr: 0.0403 mean_entropies: 1.4946, took: 91.5038s
2022-10-09 12:59:33,882 [INFO] 	Process 3 - batch 35999: mean_policy_losses: -77.481, mean_net_lifetime: 4375.5708, mean_mc_travel_dist: 1501.6165, mean_rewards: 226.6665, total_rewards: 2908.6930, mean_steps: 19.1800, mean_ecr: 0.0397 mean_entropies: 1.5159, took: 91.7336s
2022-10-09 12:59:44,396 [INFO] 	Process 0 - batch 35899: mean_policy_losses: -104.597, mean_net_lifetime: 4161.7533, mean_mc_travel_dist: 1398.3793, mean_rewards: 231.1891, total_rewards: 2800.5461, mean_steps: 18.3600, mean_ecr: 0.0401 mean_entropies: 1.4663, took: 88.0799s
2022-10-09 13:00:29,338 [INFO] 	Process 4 - batch 35999: mean_policy_losses: -77.154, mean_net_lifetime: 4248.5372, mean_mc_travel_dist: 1453.1117, mean_rewards: 224.7833, total_rewards: 2841.2400, mean_steps: 18.7100, mean_ecr: 0.0398 mean_entropies: 1.5197, took: 86.4697s
2022-10-09 13:01:08,613 [INFO] 	Process 0 - batch 35999: mean_policy_losses: -47.061, mean_net_lifetime: 4331.7011, mean_mc_travel_dist: 1462.7538, mean_rewards: 229.8538, total_rewards: 2906.3042, mean_steps: 19.0500, mean_ecr: 0.0397 mean_entropies: 1.4915, took: 84.2163s
2022-10-09 13:08:19,415 [INFO] 	Process 6 - batch 36099: mean_policy_losses: -144.391, mean_net_lifetime: 4308.8413, mean_mc_travel_dist: 1480.6164, mean_rewards: 233.9627, total_rewards: 2862.0756, mean_steps: 18.5600, mean_ecr: 0.0399 mean_entropies: 1.5514, took: 699.2377s
2022-10-09 13:08:24,703 [INFO] 	Process 1 - batch 37599: mean_policy_losses: -92.406, mean_net_lifetime: 4611.2317, mean_mc_travel_dist: 1577.1333, mean_rewards: 228.9418, total_rewards: 3073.8283, mean_steps: 20.5700, mean_ecr: 0.0392 mean_entropies: 1.5115, took: 648.5157s
2022-10-09 13:09:42,099 [INFO] 	Process 2 - batch 36099: mean_policy_losses: -7.127, mean_net_lifetime: 4889.6323, mean_mc_travel_dist: 1685.6894, mean_rewards: 231.0567, total_rewards: 3250.6022, mean_steps: 21.4100, mean_ecr: 0.0394 mean_entropies: 1.5202, took: 689.5957s
2022-10-09 13:09:57,824 [INFO] 	Process 6 - batch 36199: mean_policy_losses: -14.760, mean_net_lifetime: 4652.4170, mean_mc_travel_dist: 1598.9191, mean_rewards: 221.8431, total_rewards: 3088.6241, mean_steps: 21.5800, mean_ecr: 0.0381 mean_entropies: 1.5124, took: 98.4089s
2022-10-09 13:10:22,728 [INFO] 	Process 1 - batch 37699: mean_policy_losses: -104.842, mean_net_lifetime: 5426.0461, mean_mc_travel_dist: 1892.3993, mean_rewards: 227.4137, total_rewards: 3576.0845, mean_steps: 26.5700, mean_ecr: 0.0393 mean_entropies: 1.4323, took: 118.0238s
2022-10-09 13:10:42,256 [INFO] 	Process 5 - batch 36099: mean_policy_losses: -131.372, mean_net_lifetime: 4243.5902, mean_mc_travel_dist: 1442.9317, mean_rewards: 229.2336, total_rewards: 2839.8375, mean_steps: 19.1900, mean_ecr: 0.0396 mean_entropies: 1.5066, took: 669.8531s
2022-10-09 13:11:20,956 [INFO] 	Process 2 - batch 36199: mean_policy_losses: -68.721, mean_net_lifetime: 4566.1075, mean_mc_travel_dist: 1568.5194, mean_rewards: 226.6082, total_rewards: 3038.4928, mean_steps: 20.8300, mean_ecr: 0.0384 mean_entropies: 1.4924, took: 98.8563s
2022-10-09 13:11:37,443 [INFO] 	Process 6 - batch 36299: mean_policy_losses: -64.144, mean_net_lifetime: 4747.2963, mean_mc_travel_dist: 1645.8290, mean_rewards: 239.9627, total_rewards: 3136.8386, mean_steps: 20.7100, mean_ecr: 0.0385 mean_entropies: 1.4294, took: 99.6198s
2022-10-09 13:11:52,502 [INFO] 	Process 3 - batch 36099: mean_policy_losses: -125.785, mean_net_lifetime: 4263.2967, mean_mc_travel_dist: 1433.1752, mean_rewards: 225.7979, total_rewards: 2866.1008, mean_steps: 18.7200, mean_ecr: 0.0399 mean_entropies: 1.5096, took: 738.6214s
2022-10-09 13:11:52,969 [INFO] 	Process 1 - batch 37799: mean_policy_losses: -173.497, mean_net_lifetime: 4040.4301, mean_mc_travel_dist: 1362.0410, mean_rewards: 226.7009, total_rewards: 2714.6712, mean_steps: 18.7300, mean_ecr: 0.0399 mean_entropies: 1.4181, took: 90.2415s
2022-10-09 13:12:35,506 [INFO] 	Process 5 - batch 36199: mean_policy_losses: -30.336, mean_net_lifetime: 4785.2158, mean_mc_travel_dist: 1651.3590, mean_rewards: 225.6463, total_rewards: 3184.4550, mean_steps: 21.9000, mean_ecr: 0.0385 mean_entropies: 1.5003, took: 113.2502s
2022-10-09 13:13:08,678 [INFO] 	Process 4 - batch 36099: mean_policy_losses: -183.471, mean_net_lifetime: 4696.4248, mean_mc_travel_dist: 1644.9580, mean_rewards: 225.6653, total_rewards: 3081.8199, mean_steps: 21.2200, mean_ecr: 0.0398 mean_entropies: 1.5268, took: 759.3394s
2022-10-09 13:13:13,722 [INFO] 	Process 2 - batch 36299: mean_policy_losses: -62.026, mean_net_lifetime: 4624.3347, mean_mc_travel_dist: 1594.4474, mean_rewards: 232.5474, total_rewards: 3060.8584, mean_steps: 20.6500, mean_ecr: 0.0389 mean_entropies: 1.4537, took: 112.7668s
2022-10-09 13:13:47,320 [INFO] 	Process 0 - batch 36099: mean_policy_losses: -148.205, mean_net_lifetime: 4211.8048, mean_mc_travel_dist: 1429.8419, mean_rewards: 231.6969, total_rewards: 2812.5594, mean_steps: 18.1600, mean_ecr: 0.0401 mean_entropies: 1.5188, took: 758.7076s
2022-10-09 13:13:48,519 [INFO] 	Process 3 - batch 36199: mean_policy_losses: -127.221, mean_net_lifetime: 4479.7403, mean_mc_travel_dist: 1527.6834, mean_rewards: 223.5190, total_rewards: 2988.6842, mean_steps: 20.2400, mean_ecr: 0.0383 mean_entropies: 1.5114, took: 116.0172s
2022-10-09 13:13:50,889 [INFO] 	Process 1 - batch 37899: mean_policy_losses: -72.273, mean_net_lifetime: 4662.8705, mean_mc_travel_dist: 1608.9667, mean_rewards: 225.6928, total_rewards: 3081.1350, mean_steps: 21.2300, mean_ecr: 0.0399 mean_entropies: 1.4295, took: 117.9196s
2022-10-09 13:13:55,744 [INFO] 	Process 6 - batch 36399: mean_policy_losses: -156.202, mean_net_lifetime: 5327.9884, mean_mc_travel_dist: 1945.9473, mean_rewards: 232.8942, total_rewards: 3415.6312, mean_steps: 25.5300, mean_ecr: 0.0402 mean_entropies: 1.3368, took: 138.3009s
2022-10-09 13:14:29,626 [INFO] 	Process 5 - batch 36299: mean_policy_losses: -88.715, mean_net_lifetime: 4614.2901, mean_mc_travel_dist: 1611.4594, mean_rewards: 235.9744, total_rewards: 3047.5956, mean_steps: 20.5200, mean_ecr: 0.0385 mean_entropies: 1.4190, took: 114.1208s
2022-10-09 13:15:02,103 [INFO] 	Process 4 - batch 36199: mean_policy_losses: -60.814, mean_net_lifetime: 4573.9899, mean_mc_travel_dist: 1586.6487, mean_rewards: 221.3683, total_rewards: 3028.6280, mean_steps: 20.8600, mean_ecr: 0.0382 mean_entropies: 1.4960, took: 113.4262s
2022-10-09 13:15:28,379 [INFO] 	Process 1 - batch 37999: mean_policy_losses: -134.268, mean_net_lifetime: 4238.8196, mean_mc_travel_dist: 1456.5395, mean_rewards: 231.3857, total_rewards: 2818.8752, mean_steps: 18.6700, mean_ecr: 0.0397 mean_entropies: 1.4540, took: 97.4897s
2022-10-09 13:15:31,550 [INFO] 	Process 3 - batch 36299: mean_policy_losses: -53.737, mean_net_lifetime: 4481.9974, mean_mc_travel_dist: 1540.1264, mean_rewards: 238.1610, total_rewards: 2978.0462, mean_steps: 19.5100, mean_ecr: 0.0389 mean_entropies: 1.4228, took: 103.0303s
2022-10-09 13:15:38,953 [INFO] 	Process 6 - batch 36499: mean_policy_losses: -126.202, mean_net_lifetime: 4258.6637, mean_mc_travel_dist: 1419.1937, mean_rewards: 228.1365, total_rewards: 2881.5788, mean_steps: 19.3100, mean_ecr: 0.0397 mean_entropies: 1.4802, took: 103.2079s
2022-10-09 13:15:40,075 [INFO] 	Process 2 - batch 36399: mean_policy_losses: -118.544, mean_net_lifetime: 5685.5093, mean_mc_travel_dist: 2124.3808, mean_rewards: 225.2112, total_rewards: 3594.3972, mean_steps: 28.1400, mean_ecr: 0.0402 mean_entropies: 1.3471, took: 146.3528s
2022-10-09 13:15:40,992 [INFO] 	Process 0 - batch 36199: mean_policy_losses: -19.461, mean_net_lifetime: 4801.1727, mean_mc_travel_dist: 1682.7780, mean_rewards: 221.1264, total_rewards: 3161.6624, mean_steps: 21.7700, mean_ecr: 0.0381 mean_entropies: 1.5005, took: 113.6728s
2022-10-09 13:16:11,311 [INFO] 	Process 5 - batch 36399: mean_policy_losses: -166.753, mean_net_lifetime: 4235.0293, mean_mc_travel_dist: 1479.3143, mean_rewards: 232.0902, total_rewards: 2794.0795, mean_steps: 19.1400, mean_ecr: 0.0406 mean_entropies: 1.3623, took: 101.6837s
2022-10-09 13:16:46,234 [INFO] 	Process 4 - batch 36299: mean_policy_losses: -66.172, mean_net_lifetime: 4386.5170, mean_mc_travel_dist: 1492.0959, mean_rewards: 238.5485, total_rewards: 2942.5104, mean_steps: 19.0300, mean_ecr: 0.0388 mean_entropies: 1.4517, took: 104.1304s
2022-10-09 13:17:24,353 [INFO] 	Process 3 - batch 36399: mean_policy_losses: -124.591, mean_net_lifetime: 4607.1788, mean_mc_travel_dist: 1613.7155, mean_rewards: 228.3456, total_rewards: 3032.7220, mean_steps: 21.2300, mean_ecr: 0.0396 mean_entropies: 1.3834, took: 112.8022s
2022-10-09 13:17:26,778 [INFO] 	Process 0 - batch 36299: mean_policy_losses: -57.627, mean_net_lifetime: 4476.5426, mean_mc_travel_dist: 1510.0456, mean_rewards: 239.1343, total_rewards: 3002.2710, mean_steps: 19.6400, mean_ecr: 0.0386 mean_entropies: 1.4760, took: 105.7860s
2022-10-09 13:17:27,210 [INFO] 	Process 6 - batch 36599: mean_policy_losses: -135.855, mean_net_lifetime: 4438.1324, mean_mc_travel_dist: 1534.1024, mean_rewards: 232.6441, total_rewards: 2953.1912, mean_steps: 20.2300, mean_ecr: 0.0402 mean_entropies: 1.4588, took: 108.2582s
2022-10-09 13:17:36,508 [INFO] 	Process 2 - batch 36499: mean_policy_losses: -124.317, mean_net_lifetime: 4631.1289, mean_mc_travel_dist: 1580.2240, mean_rewards: 222.8392, total_rewards: 3079.9672, mean_steps: 21.7000, mean_ecr: 0.0397 mean_entropies: 1.4794, took: 116.4340s
2022-10-09 13:17:51,506 [INFO] 	Process 5 - batch 36499: mean_policy_losses: -180.800, mean_net_lifetime: 4176.9475, mean_mc_travel_dist: 1407.7270, mean_rewards: 226.6157, total_rewards: 2815.6811, mean_steps: 18.7400, mean_ecr: 0.0396 mean_entropies: 1.4822, took: 100.1951s
2022-10-09 13:18:05,317 [INFO] 	Process 1 - batch 38099: mean_policy_losses: -75.368, mean_net_lifetime: 6406.5115, mean_mc_travel_dist: 2506.8605, mean_rewards: 229.9179, total_rewards: 3932.4684, mean_steps: 31.3800, mean_ecr: 0.0378 mean_entropies: 1.4895, took: 156.9384s
2022-10-09 13:18:49,697 [INFO] 	Process 4 - batch 36399: mean_policy_losses: -85.310, mean_net_lifetime: 5180.0728, mean_mc_travel_dist: 1863.5949, mean_rewards: 234.3015, total_rewards: 3354.8997, mean_steps: 24.1700, mean_ecr: 0.0403 mean_entropies: 1.3647, took: 123.4632s
2022-10-09 13:18:56,435 [INFO] 	Process 3 - batch 36499: mean_policy_losses: -148.596, mean_net_lifetime: 4001.0466, mean_mc_travel_dist: 1337.1082, mean_rewards: 226.9440, total_rewards: 2701.5844, mean_steps: 17.9400, mean_ecr: 0.0398 mean_entropies: 1.4417, took: 92.0831s
2022-10-09 13:19:04,049 [INFO] 	Process 6 - batch 36699: mean_policy_losses: -142.898, mean_net_lifetime: 4145.5165, mean_mc_travel_dist: 1409.4610, mean_rewards: 231.3908, total_rewards: 2775.5333, mean_steps: 18.6000, mean_ecr: 0.0393 mean_entropies: 1.4094, took: 96.8383s
2022-10-09 13:19:13,462 [INFO] 	Process 0 - batch 36399: mean_policy_losses: -69.758, mean_net_lifetime: 4505.1558, mean_mc_travel_dist: 1597.0988, mean_rewards: 230.6247, total_rewards: 2952.8657, mean_steps: 20.5700, mean_ecr: 0.0406 mean_entropies: 1.3591, took: 106.6833s
2022-10-09 13:19:19,798 [INFO] 	Process 2 - batch 36599: mean_policy_losses: -55.221, mean_net_lifetime: 4361.8039, mean_mc_travel_dist: 1510.5441, mean_rewards: 230.9247, total_rewards: 2889.6436, mean_steps: 20.0100, mean_ecr: 0.0402 mean_entropies: 1.4316, took: 103.2888s
2022-10-09 13:19:32,366 [INFO] 	Process 5 - batch 36599: mean_policy_losses: -105.418, mean_net_lifetime: 4236.1502, mean_mc_travel_dist: 1466.6901, mean_rewards: 228.8659, total_rewards: 2814.9887, mean_steps: 19.4200, mean_ecr: 0.0402 mean_entropies: 1.4220, took: 100.8581s
2022-10-09 13:19:55,432 [INFO] 	Process 1 - batch 38199: mean_policy_losses: -36.361, mean_net_lifetime: 4560.7965, mean_mc_travel_dist: 1665.7206, mean_rewards: 221.8475, total_rewards: 2935.7025, mean_steps: 21.9800, mean_ecr: 0.0393 mean_entropies: 1.4448, took: 110.1152s
2022-10-09 13:20:19,370 [INFO] 	Process 4 - batch 36499: mean_policy_losses: -87.155, mean_net_lifetime: 3965.4074, mean_mc_travel_dist: 1284.3375, mean_rewards: 239.5373, total_rewards: 2709.2967, mean_steps: 16.6600, mean_ecr: 0.0400 mean_entropies: 1.4667, took: 89.6731s
2022-10-09 13:20:32,171 [INFO] 	Process 3 - batch 36599: mean_policy_losses: -63.113, mean_net_lifetime: 4277.3772, mean_mc_travel_dist: 1468.9989, mean_rewards: 236.0132, total_rewards: 2840.9277, mean_steps: 18.5400, mean_ecr: 0.0399 mean_entropies: 1.4590, took: 95.7324s
2022-10-09 13:20:47,131 [INFO] 	Process 0 - batch 36499: mean_policy_losses: -137.670, mean_net_lifetime: 4061.3919, mean_mc_travel_dist: 1346.4456, mean_rewards: 234.7481, total_rewards: 2754.2600, mean_steps: 17.7100, mean_ecr: 0.0399 mean_entropies: 1.4486, took: 93.6691s
2022-10-09 13:20:52,155 [INFO] 	Process 2 - batch 36699: mean_policy_losses: -206.042, mean_net_lifetime: 4014.7795, mean_mc_travel_dist: 1385.6925, mean_rewards: 238.0411, total_rewards: 2675.2085, mean_steps: 17.1400, mean_ecr: 0.0390 mean_entropies: 1.4193, took: 92.3566s
2022-10-09 13:20:58,610 [INFO] 	Process 6 - batch 36799: mean_policy_losses: -135.265, mean_net_lifetime: 5021.0533, mean_mc_travel_dist: 1800.4824, mean_rewards: 236.8651, total_rewards: 3266.4617, mean_steps: 22.3300, mean_ecr: 0.0379 mean_entropies: 1.5542, took: 114.5617s
2022-10-09 13:21:01,415 [INFO] 	Process 5 - batch 36699: mean_policy_losses: -147.407, mean_net_lifetime: 3988.5543, mean_mc_travel_dist: 1363.3101, mean_rewards: 237.8459, total_rewards: 2659.2823, mean_steps: 16.8500, mean_ecr: 0.0393 mean_entropies: 1.4230, took: 89.0512s
2022-10-09 13:21:59,117 [INFO] 	Process 4 - batch 36599: mean_policy_losses: -114.062, mean_net_lifetime: 4351.0521, mean_mc_travel_dist: 1506.7312, mean_rewards: 239.8637, total_rewards: 2891.9308, mean_steps: 18.8700, mean_ecr: 0.0401 mean_entropies: 1.4527, took: 99.7471s
2022-10-09 13:21:59,395 [INFO] 	Process 3 - batch 36699: mean_policy_losses: -222.133, mean_net_lifetime: 3813.9238, mean_mc_travel_dist: 1314.3368, mean_rewards: 239.9655, total_rewards: 2543.1955, mean_steps: 16.3700, mean_ecr: 0.0395 mean_entropies: 1.4328, took: 87.2268s
2022-10-09 13:22:28,894 [INFO] 	Process 0 - batch 36599: mean_policy_losses: -127.465, mean_net_lifetime: 4353.6605, mean_mc_travel_dist: 1528.4087, mean_rewards: 234.1469, total_rewards: 2861.8415, mean_steps: 19.2500, mean_ecr: 0.0403 mean_entropies: 1.4800, took: 101.7641s
2022-10-09 13:22:35,144 [INFO] 	Process 6 - batch 36899: mean_policy_losses: -94.430, mean_net_lifetime: 4240.8712, mean_mc_travel_dist: 1449.6749, mean_rewards: 236.3629, total_rewards: 2820.1026, mean_steps: 18.3700, mean_ecr: 0.0400 mean_entropies: 1.4785, took: 96.5330s
2022-10-09 13:22:38,880 [INFO] 	Process 1 - batch 38299: mean_policy_losses: 36.616, mean_net_lifetime: 7172.9217, mean_mc_travel_dist: 2723.1418, mean_rewards: 232.6490, total_rewards: 4490.5596, mean_steps: 33.7600, mean_ecr: 0.0371 mean_entropies: 1.5724, took: 163.4482s
2022-10-09 13:22:40,266 [INFO] 	Process 2 - batch 36799: mean_policy_losses: -88.482, mean_net_lifetime: 4730.9991, mean_mc_travel_dist: 1612.7051, mean_rewards: 229.1880, total_rewards: 3152.7640, mean_steps: 20.6000, mean_ecr: 0.0377 mean_entropies: 1.5651, took: 108.1113s
2022-10-09 13:22:57,516 [INFO] 	Process 5 - batch 36799: mean_policy_losses: 8.362, mean_net_lifetime: 5138.1063, mean_mc_travel_dist: 1777.0934, mean_rewards: 233.6909, total_rewards: 3404.7736, mean_steps: 22.3400, mean_ecr: 0.0376 mean_entropies: 1.5613, took: 116.1017s
2022-10-09 13:23:39,853 [INFO] 	Process 4 - batch 36699: mean_policy_losses: -114.921, mean_net_lifetime: 4358.8893, mean_mc_travel_dist: 1472.4972, mean_rewards: 231.6628, total_rewards: 2925.0849, mean_steps: 19.1100, mean_ecr: 0.0389 mean_entropies: 1.4436, took: 100.7361s
2022-10-09 13:24:00,148 [INFO] 	Process 3 - batch 36799: mean_policy_losses: -14.872, mean_net_lifetime: 5330.9356, mean_mc_travel_dist: 1882.3058, mean_rewards: 231.9799, total_rewards: 3488.4582, mean_steps: 23.5800, mean_ecr: 0.0378 mean_entropies: 1.5741, took: 120.7539s
2022-10-09 13:24:04,250 [INFO] 	Process 0 - batch 36699: mean_policy_losses: -142.009, mean_net_lifetime: 4232.3017, mean_mc_travel_dist: 1439.7707, mean_rewards: 241.9036, total_rewards: 2834.9578, mean_steps: 18.1600, mean_ecr: 0.0389 mean_entropies: 1.4133, took: 95.3552s
2022-10-09 13:24:13,291 [INFO] 	Process 6 - batch 36999: mean_policy_losses: -83.285, mean_net_lifetime: 4220.3815, mean_mc_travel_dist: 1426.1358, mean_rewards: 236.3578, total_rewards: 2835.8149, mean_steps: 18.7400, mean_ecr: 0.0403 mean_entropies: 1.4786, took: 98.1476s
2022-10-09 13:24:24,371 [INFO] 	Process 2 - batch 36899: mean_policy_losses: -25.385, mean_net_lifetime: 4487.1587, mean_mc_travel_dist: 1569.7418, mean_rewards: 240.3633, total_rewards: 2958.5447, mean_steps: 19.9200, mean_ecr: 0.0398 mean_entropies: 1.4416, took: 104.1055s
2022-10-09 13:24:28,645 [INFO] 	Process 1 - batch 38399: mean_policy_losses: -80.564, mean_net_lifetime: 4672.8811, mean_mc_travel_dist: 1641.4913, mean_rewards: 229.9648, total_rewards: 3068.3267, mean_steps: 21.9500, mean_ecr: 0.0395 mean_entropies: 1.4813, took: 109.7648s
2022-10-09 13:24:42,388 [INFO] 	Process 5 - batch 36899: mean_policy_losses: -41.678, mean_net_lifetime: 4506.9102, mean_mc_travel_dist: 1554.3209, mean_rewards: 240.0601, total_rewards: 2989.0464, mean_steps: 20.1500, mean_ecr: 0.0399 mean_entropies: 1.4716, took: 104.8719s
2022-10-09 13:25:36,859 [INFO] 	Process 3 - batch 36899: mean_policy_losses: -211.383, mean_net_lifetime: 4077.5255, mean_mc_travel_dist: 1409.3181, mean_rewards: 236.0555, total_rewards: 2699.7756, mean_steps: 18.2700, mean_ecr: 0.0400 mean_entropies: 1.4703, took: 96.7113s
2022-10-09 13:25:43,883 [INFO] 	Process 4 - batch 36799: mean_policy_losses: -122.372, mean_net_lifetime: 5288.0756, mean_mc_travel_dist: 1871.4074, mean_rewards: 227.7036, total_rewards: 3459.8593, mean_steps: 24.1800, mean_ecr: 0.0380 mean_entropies: 1.5550, took: 124.0300s
2022-10-09 13:25:55,778 [INFO] 	Process 6 - batch 37099: mean_policy_losses: -46.694, mean_net_lifetime: 4427.7852, mean_mc_travel_dist: 1507.9349, mean_rewards: 224.4927, total_rewards: 2958.5555, mean_steps: 19.9100, mean_ecr: 0.0387 mean_entropies: 1.4239, took: 102.4871s
2022-10-09 13:26:09,873 [INFO] 	Process 2 - batch 36999: mean_policy_losses: -179.496, mean_net_lifetime: 4381.1082, mean_mc_travel_dist: 1505.9496, mean_rewards: 229.5731, total_rewards: 2910.5166, mean_steps: 20.1100, mean_ecr: 0.0402 mean_entropies: 1.4560, took: 105.5021s
2022-10-09 13:26:12,947 [INFO] 	Process 0 - batch 36799: mean_policy_losses: -115.687, mean_net_lifetime: 5374.2042, mean_mc_travel_dist: 1862.2645, mean_rewards: 223.0294, total_rewards: 3559.1110, mean_steps: 25.0500, mean_ecr: 0.0377 mean_entropies: 1.5713, took: 128.6969s
2022-10-09 13:26:18,672 [INFO] 	Process 1 - batch 38499: mean_policy_losses: -118.723, mean_net_lifetime: 4837.3716, mean_mc_travel_dist: 1689.2497, mean_rewards: 236.5749, total_rewards: 3191.2348, mean_steps: 21.8500, mean_ecr: 0.0393 mean_entropies: 1.4652, took: 110.0271s
2022-10-09 13:26:27,285 [INFO] 	Process 5 - batch 36999: mean_policy_losses: -128.401, mean_net_lifetime: 4338.1227, mean_mc_travel_dist: 1473.9421, mean_rewards: 232.2909, total_rewards: 2896.7232, mean_steps: 19.8200, mean_ecr: 0.0402 mean_entropies: 1.4480, took: 104.8961s
2022-10-09 13:27:11,361 [INFO] 	Process 3 - batch 36999: mean_policy_losses: -182.922, mean_net_lifetime: 4101.0288, mean_mc_travel_dist: 1375.4430, mean_rewards: 233.1657, total_rewards: 2758.5241, mean_steps: 18.1700, mean_ecr: 0.0403 mean_entropies: 1.4438, took: 94.5000s
2022-10-09 13:27:24,112 [INFO] 	Process 4 - batch 36899: mean_policy_losses: -85.346, mean_net_lifetime: 4304.5046, mean_mc_travel_dist: 1470.3008, mean_rewards: 238.5221, total_rewards: 2884.1439, mean_steps: 19.0200, mean_ecr: 0.0401 mean_entropies: 1.4791, took: 100.2280s
2022-10-09 13:27:36,424 [INFO] 	Process 6 - batch 37199: mean_policy_losses: -111.373, mean_net_lifetime: 4241.5091, mean_mc_travel_dist: 1399.1084, mean_rewards: 235.5046, total_rewards: 2871.4697, mean_steps: 18.6800, mean_ecr: 0.0384 mean_entropies: 1.4651, took: 100.6456s
2022-10-09 13:27:52,715 [INFO] 	Process 2 - batch 37099: mean_policy_losses: -86.868, mean_net_lifetime: 4449.1270, mean_mc_travel_dist: 1497.1530, mean_rewards: 225.0730, total_rewards: 2990.6251, mean_steps: 19.9100, mean_ecr: 0.0384 mean_entropies: 1.4394, took: 102.8420s
2022-10-09 13:27:54,821 [INFO] 	Process 0 - batch 36899: mean_policy_losses: -122.487, mean_net_lifetime: 4391.9004, mean_mc_travel_dist: 1493.9526, mean_rewards: 234.3978, total_rewards: 2937.5935, mean_steps: 19.2900, mean_ecr: 0.0401 mean_entropies: 1.4675, took: 101.8739s
2022-10-09 13:28:06,297 [INFO] 	Process 1 - batch 38599: mean_policy_losses: -97.765, mean_net_lifetime: 4650.1514, mean_mc_travel_dist: 1579.6599, mean_rewards: 224.3274, total_rewards: 3106.6421, mean_steps: 21.3800, mean_ecr: 0.0382 mean_entropies: 1.4724, took: 107.6249s
2022-10-09 13:28:23,577 [INFO] 	Process 5 - batch 37099: mean_policy_losses: -33.017, mean_net_lifetime: 4868.4678, mean_mc_travel_dist: 1717.5895, mean_rewards: 222.6197, total_rewards: 3192.8147, mean_steps: 22.2400, mean_ecr: 0.0384 mean_entropies: 1.4642, took: 116.2913s
2022-10-09 13:28:55,035 [INFO] 	Process 4 - batch 36999: mean_policy_losses: -228.246, mean_net_lifetime: 3951.8906, mean_mc_travel_dist: 1309.0820, mean_rewards: 237.2997, total_rewards: 2685.2109, mean_steps: 17.2300, mean_ecr: 0.0406 mean_entropies: 1.4454, took: 90.9245s
2022-10-09 13:29:01,786 [INFO] 	Process 3 - batch 37099: mean_policy_losses: -6.660, mean_net_lifetime: 4744.6925, mean_mc_travel_dist: 1602.5807, mean_rewards: 226.4610, total_rewards: 3177.6544, mean_steps: 21.4800, mean_ecr: 0.0384 mean_entropies: 1.4248, took: 110.4255s
2022-10-09 13:29:29,179 [INFO] 	Process 0 - batch 36999: mean_policy_losses: -122.332, mean_net_lifetime: 4016.1429, mean_mc_travel_dist: 1357.5118, mean_rewards: 236.6148, total_rewards: 2700.4258, mean_steps: 17.6100, mean_ecr: 0.0403 mean_entropies: 1.4563, took: 94.3579s
2022-10-09 13:29:32,017 [INFO] 	Process 2 - batch 37199: mean_policy_losses: -126.132, mean_net_lifetime: 4089.2109, mean_mc_travel_dist: 1367.7658, mean_rewards: 229.9045, total_rewards: 2753.4310, mean_steps: 18.7100, mean_ecr: 0.0389 mean_entropies: 1.4285, took: 99.3026s
2022-10-09 13:29:43,890 [INFO] 	Process 6 - batch 37299: mean_policy_losses: -87.686, mean_net_lifetime: 5433.9896, mean_mc_travel_dist: 2023.0142, mean_rewards: 232.5800, total_rewards: 3439.7675, mean_steps: 25.2600, mean_ecr: 0.0388 mean_entropies: 1.3921, took: 127.4662s
2022-10-09 13:29:47,055 [INFO] 	Process 1 - batch 38699: mean_policy_losses: -212.243, mean_net_lifetime: 4424.7114, mean_mc_travel_dist: 1471.9471, mean_rewards: 242.3119, total_rewards: 2986.1632, mean_steps: 19.8900, mean_ecr: 0.0385 mean_entropies: 1.4403, took: 100.7582s
2022-10-09 13:30:06,043 [INFO] 	Process 5 - batch 37199: mean_policy_losses: -78.420, mean_net_lifetime: 4394.3886, mean_mc_travel_dist: 1487.7040, mean_rewards: 234.2503, total_rewards: 2942.9379, mean_steps: 19.4600, mean_ecr: 0.0386 mean_entropies: 1.4349, took: 102.4667s
2022-10-09 13:30:40,674 [INFO] 	Process 4 - batch 37099: mean_policy_losses: -52.292, mean_net_lifetime: 4410.6514, mean_mc_travel_dist: 1503.3762, mean_rewards: 227.2362, total_rewards: 2945.1942, mean_steps: 20.0400, mean_ecr: 0.0383 mean_entropies: 1.4169, took: 105.6392s
2022-10-09 13:30:53,973 [INFO] 	Process 3 - batch 37199: mean_policy_losses: -52.744, mean_net_lifetime: 4617.5050, mean_mc_travel_dist: 1571.1092, mean_rewards: 222.2295, total_rewards: 3089.2693, mean_steps: 21.7500, mean_ecr: 0.0382 mean_entropies: 1.4183, took: 112.1881s
2022-10-09 13:31:18,788 [INFO] 	Process 0 - batch 37099: mean_policy_losses: -18.718, mean_net_lifetime: 4579.4188, mean_mc_travel_dist: 1562.7123, mean_rewards: 227.2483, total_rewards: 3055.8105, mean_steps: 20.9600, mean_ecr: 0.0386 mean_entropies: 1.4049, took: 109.6089s
2022-10-09 13:31:27,510 [INFO] 	Process 2 - batch 37299: mean_policy_losses: -96.157, mean_net_lifetime: 4967.9759, mean_mc_travel_dist: 1735.6718, mean_rewards: 233.8255, total_rewards: 3260.6445, mean_steps: 22.6900, mean_ecr: 0.0388 mean_entropies: 1.4100, took: 115.4930s
2022-10-09 13:31:34,544 [INFO] 	Process 1 - batch 38799: mean_policy_losses: -117.478, mean_net_lifetime: 4534.9444, mean_mc_travel_dist: 1607.2528, mean_rewards: 226.5983, total_rewards: 2972.3263, mean_steps: 21.4200, mean_ecr: 0.0386 mean_entropies: 1.4644, took: 107.4888s
2022-10-09 13:31:49,477 [INFO] 	Process 5 - batch 37299: mean_policy_losses: -89.079, mean_net_lifetime: 4401.5311, mean_mc_travel_dist: 1563.8966, mean_rewards: 231.3143, total_rewards: 2884.3811, mean_steps: 19.7500, mean_ecr: 0.0389 mean_entropies: 1.4206, took: 103.4337s
2022-10-09 13:32:22,538 [INFO] 	Process 6 - batch 37399: mean_policy_losses: -174.018, mean_net_lifetime: 6778.6811, mean_mc_travel_dist: 2339.1881, mean_rewards: 226.5941, total_rewards: 4471.0722, mean_steps: 31.6400, mean_ecr: 0.0390 mean_entropies: 1.4701, took: 158.6472s
2022-10-09 13:32:25,115 [INFO] 	Process 4 - batch 37199: mean_policy_losses: -117.813, mean_net_lifetime: 4266.0015, mean_mc_travel_dist: 1468.2172, mean_rewards: 233.8322, total_rewards: 2833.3273, mean_steps: 20.0800, mean_ecr: 0.0382 mean_entropies: 1.4155, took: 104.4402s
2022-10-09 13:33:11,115 [INFO] 	Process 0 - batch 37199: mean_policy_losses: -66.154, mean_net_lifetime: 4686.7316, mean_mc_travel_dist: 1598.2685, mean_rewards: 227.1296, total_rewards: 3130.7174, mean_steps: 21.6000, mean_ecr: 0.0385 mean_entropies: 1.4486, took: 112.3272s
2022-10-09 13:33:22,988 [INFO] 	Process 2 - batch 37399: mean_policy_losses: -170.435, mean_net_lifetime: 4873.8561, mean_mc_travel_dist: 1696.7166, mean_rewards: 225.5115, total_rewards: 3216.6021, mean_steps: 22.0800, mean_ecr: 0.0388 mean_entropies: 1.4459, took: 115.4772s
2022-10-09 13:33:29,129 [INFO] 	Process 3 - batch 37299: mean_policy_losses: -121.420, mean_net_lifetime: 6619.7034, mean_mc_travel_dist: 2746.3040, mean_rewards: 236.8308, total_rewards: 3905.3943, mean_steps: 31.4900, mean_ecr: 0.0387 mean_entropies: 1.4328, took: 155.1557s
2022-10-09 13:33:39,547 [INFO] 	Process 5 - batch 37399: mean_policy_losses: -154.813, mean_net_lifetime: 4593.7262, mean_mc_travel_dist: 1594.8170, mean_rewards: 229.2583, total_rewards: 3035.3631, mean_steps: 21.0300, mean_ecr: 0.0390 mean_entropies: 1.4739, took: 110.0695s
2022-10-09 13:33:45,862 [INFO] 	Process 1 - batch 38899: mean_policy_losses: -146.501, mean_net_lifetime: 5463.9615, mean_mc_travel_dist: 2000.6082, mean_rewards: 220.5750, total_rewards: 3502.7297, mean_steps: 26.3500, mean_ecr: 0.0380 mean_entropies: 1.4752, took: 131.3185s
2022-10-09 13:34:16,292 [INFO] 	Process 6 - batch 37499: mean_policy_losses: -45.815, mean_net_lifetime: 4871.1614, mean_mc_travel_dist: 1642.4949, mean_rewards: 224.6323, total_rewards: 3268.2248, mean_steps: 22.1300, mean_ecr: 0.0384 mean_entropies: 1.4521, took: 113.7548s
2022-10-09 13:34:26,446 [INFO] 	Process 4 - batch 37299: mean_policy_losses: -119.373, mean_net_lifetime: 5248.7297, mean_mc_travel_dist: 1880.9428, mean_rewards: 233.8618, total_rewards: 3411.8494, mean_steps: 23.7500, mean_ecr: 0.0385 mean_entropies: 1.4031, took: 121.3313s
2022-10-09 13:35:12,727 [INFO] 	Process 2 - batch 37499: mean_policy_losses: 14.267, mean_net_lifetime: 4783.8310, mean_mc_travel_dist: 1585.0607, mean_rewards: 229.2721, total_rewards: 3244.5574, mean_steps: 21.1000, mean_ecr: 0.0385 mean_entropies: 1.4607, took: 109.7382s
2022-10-09 13:35:23,605 [INFO] 	Process 5 - batch 37499: mean_policy_losses: -61.400, mean_net_lifetime: 4686.6179, mean_mc_travel_dist: 1566.7791, mean_rewards: 236.0936, total_rewards: 3155.8201, mean_steps: 20.5700, mean_ecr: 0.0384 mean_entropies: 1.4697, took: 104.0587s
2022-10-09 13:35:31,513 [INFO] 	Process 0 - batch 37299: mean_policy_losses: -144.950, mean_net_lifetime: 6193.9086, mean_mc_travel_dist: 2426.8745, mean_rewards: 234.8631, total_rewards: 3800.7096, mean_steps: 28.4100, mean_ecr: 0.0390 mean_entropies: 1.4272, took: 140.3988s
2022-10-09 13:35:42,648 [INFO] 	Process 3 - batch 37399: mean_policy_losses: -203.553, mean_net_lifetime: 5863.7682, mean_mc_travel_dist: 2103.1379, mean_rewards: 232.7521, total_rewards: 3796.8025, mean_steps: 27.3000, mean_ecr: 0.0390 mean_entropies: 1.4933, took: 133.5183s
2022-10-09 13:35:52,502 [INFO] 	Process 1 - batch 38999: mean_policy_losses: -59.751, mean_net_lifetime: 5845.9446, mean_mc_travel_dist: 2084.3698, mean_rewards: 230.0572, total_rewards: 3802.9887, mean_steps: 26.6800, mean_ecr: 0.0378 mean_entropies: 1.4799, took: 126.6399s
2022-10-09 13:36:08,282 [INFO] 	Process 4 - batch 37399: mean_policy_losses: -172.886, mean_net_lifetime: 4779.2916, mean_mc_travel_dist: 1606.2166, mean_rewards: 240.0435, total_rewards: 3208.1136, mean_steps: 21.1800, mean_ecr: 0.0392 mean_entropies: 1.4806, took: 101.8354s
2022-10-09 13:37:17,350 [INFO] 	Process 0 - batch 37399: mean_policy_losses: -138.079, mean_net_lifetime: 5246.1258, mean_mc_travel_dist: 1796.0251, mean_rewards: 227.7500, total_rewards: 3485.3191, mean_steps: 23.1500, mean_ecr: 0.0390 mean_entropies: 1.4657, took: 105.8365s
2022-10-09 13:37:24,303 [INFO] 	Process 3 - batch 37499: mean_policy_losses: -96.959, mean_net_lifetime: 4923.2208, mean_mc_travel_dist: 1661.9843, mean_rewards: 229.2631, total_rewards: 3296.8568, mean_steps: 22.5400, mean_ecr: 0.0383 mean_entropies: 1.4565, took: 101.6556s
2022-10-09 13:37:39,762 [INFO] 	Process 4 - batch 37499: mean_policy_losses: -108.813, mean_net_lifetime: 4571.7792, mean_mc_travel_dist: 1527.4965, mean_rewards: 225.8830, total_rewards: 3082.8695, mean_steps: 20.6300, mean_ecr: 0.0384 mean_entropies: 1.4505, took: 91.4805s
2022-10-09 13:38:51,365 [INFO] 	Process 0 - batch 37499: mean_policy_losses: -98.214, mean_net_lifetime: 4792.9712, mean_mc_travel_dist: 1586.5894, mean_rewards: 229.1775, total_rewards: 3237.0382, mean_steps: 21.6300, mean_ecr: 0.0387 mean_entropies: 1.4186, took: 94.0139s
2022-10-09 13:46:50,750 [INFO] 	Process 6 - batch 37599: mean_policy_losses: -108.424, mean_net_lifetime: 4869.6715, mean_mc_travel_dist: 1688.0839, mean_rewards: 226.8862, total_rewards: 3207.1641, mean_steps: 22.6800, mean_ecr: 0.0389 mean_entropies: 1.4752, took: 754.4584s
2022-10-09 13:47:55,966 [INFO] 	Process 5 - batch 37599: mean_policy_losses: -102.507, mean_net_lifetime: 4720.4272, mean_mc_travel_dist: 1662.7267, mean_rewards: 226.1719, total_rewards: 3097.9654, mean_steps: 21.9500, mean_ecr: 0.0386 mean_entropies: 1.5186, took: 752.3607s
2022-10-09 13:48:22,752 [INFO] 	Process 1 - batch 39099: mean_policy_losses: -62.313, mean_net_lifetime: 4907.2936, mean_mc_travel_dist: 1689.3710, mean_rewards: 231.6463, total_rewards: 3247.3903, mean_steps: 22.5400, mean_ecr: 0.0380 mean_entropies: 1.4860, took: 750.2497s
2022-10-09 13:48:28,263 [INFO] 	Process 6 - batch 37699: mean_policy_losses: -190.960, mean_net_lifetime: 4478.4882, mean_mc_travel_dist: 1497.8321, mean_rewards: 240.9025, total_rewards: 3020.2819, mean_steps: 19.6800, mean_ecr: 0.0393 mean_entropies: 1.4428, took: 97.5118s
2022-10-09 13:48:34,975 [INFO] 	Process 2 - batch 37599: mean_policy_losses: -91.433, mean_net_lifetime: 4610.8706, mean_mc_travel_dist: 1613.4199, mean_rewards: 225.3859, total_rewards: 3032.2565, mean_steps: 21.0400, mean_ecr: 0.0387 mean_entropies: 1.5111, took: 802.2474s
2022-10-09 13:49:58,359 [INFO] 	Process 1 - batch 39199: mean_policy_losses: -43.609, mean_net_lifetime: 4560.3978, mean_mc_travel_dist: 1538.8058, mean_rewards: 237.9587, total_rewards: 3058.2497, mean_steps: 19.4500, mean_ecr: 0.0410 mean_entropies: 1.4279, took: 95.6057s
2022-10-09 13:50:07,192 [INFO] 	Process 6 - batch 37799: mean_policy_losses: -149.405, mean_net_lifetime: 4442.2051, mean_mc_travel_dist: 1486.5738, mean_rewards: 234.3226, total_rewards: 2996.0207, mean_steps: 19.8700, mean_ecr: 0.0395 mean_entropies: 1.4804, took: 98.9294s
2022-10-09 13:50:14,807 [INFO] 	Process 5 - batch 37699: mean_policy_losses: -142.749, mean_net_lifetime: 5838.2779, mean_mc_travel_dist: 2054.2619, mean_rewards: 235.4083, total_rewards: 3813.7600, mean_steps: 28.4300, mean_ecr: 0.0395 mean_entropies: 1.4429, took: 138.8421s
2022-10-09 13:50:34,844 [INFO] 	Process 2 - batch 37699: mean_policy_losses: -185.455, mean_net_lifetime: 5147.2408, mean_mc_travel_dist: 1775.3690, mean_rewards: 236.8733, total_rewards: 3406.8735, mean_steps: 24.3100, mean_ecr: 0.0392 mean_entropies: 1.4499, took: 119.8701s
2022-10-09 13:50:50,375 [INFO] 	Process 4 - batch 37599: mean_policy_losses: -143.244, mean_net_lifetime: 4761.1805, mean_mc_travel_dist: 1677.1514, mean_rewards: 232.7030, total_rewards: 3114.2896, mean_steps: 21.8100, mean_ecr: 0.0389 mean_entropies: 1.5033, took: 790.6123s
2022-10-09 13:51:42,758 [INFO] 	Process 1 - batch 39299: mean_policy_losses: -71.697, mean_net_lifetime: 4713.9605, mean_mc_travel_dist: 1587.0971, mean_rewards: 231.3003, total_rewards: 3168.1338, mean_steps: 20.7600, mean_ecr: 0.0396 mean_entropies: 1.4320, took: 104.4002s
2022-10-09 13:51:56,628 [INFO] 	Process 6 - batch 37899: mean_policy_losses: -72.886, mean_net_lifetime: 4590.5652, mean_mc_travel_dist: 1588.8128, mean_rewards: 218.2482, total_rewards: 3041.9441, mean_steps: 21.5000, mean_ecr: 0.0404 mean_entropies: 1.4030, took: 109.4352s
2022-10-09 13:52:00,145 [INFO] 	Process 5 - batch 37799: mean_policy_losses: -101.820, mean_net_lifetime: 4496.6655, mean_mc_travel_dist: 1510.8051, mean_rewards: 236.1219, total_rewards: 3018.0768, mean_steps: 20.2500, mean_ecr: 0.0395 mean_entropies: 1.4451, took: 105.3375s
2022-10-09 13:52:30,290 [INFO] 	Process 2 - batch 37799: mean_policy_losses: -135.159, mean_net_lifetime: 4798.8893, mean_mc_travel_dist: 1667.0094, mean_rewards: 231.5523, total_rewards: 3171.2291, mean_steps: 22.2200, mean_ecr: 0.0393 mean_entropies: 1.4374, took: 115.4464s
2022-10-09 13:52:49,112 [INFO] 	Process 0 - batch 37599: mean_policy_losses: -105.002, mean_net_lifetime: 4481.2005, mean_mc_travel_dist: 1560.8606, mean_rewards: 220.7342, total_rewards: 2962.2976, mean_steps: 20.4100, mean_ecr: 0.0388 mean_entropies: 1.5001, took: 837.7484s
2022-10-09 13:52:50,617 [INFO] 	Process 4 - batch 37699: mean_policy_losses: -119.072, mean_net_lifetime: 5052.9245, mean_mc_travel_dist: 1763.3981, mean_rewards: 233.3205, total_rewards: 3321.8215, mean_steps: 23.2900, mean_ecr: 0.0392 mean_entropies: 1.4483, took: 120.2423s
2022-10-09 13:53:09,322 [INFO] 	Process 1 - batch 39399: mean_policy_losses: -254.239, mean_net_lifetime: 3941.7994, mean_mc_travel_dist: 1368.0206, mean_rewards: 239.1070, total_rewards: 2610.8441, mean_steps: 16.5300, mean_ecr: 0.0403 mean_entropies: 1.4790, took: 86.5640s
2022-10-09 13:53:33,761 [INFO] 	Process 3 - batch 37599: mean_policy_losses: -34.870, mean_net_lifetime: 4663.6148, mean_mc_travel_dist: 1621.2425, mean_rewards: 232.1451, total_rewards: 3074.0639, mean_steps: 20.3900, mean_ecr: 0.0385 mean_entropies: 1.4967, took: 969.4589s
2022-10-09 13:53:36,912 [INFO] 	Process 6 - batch 37999: mean_policy_losses: -104.251, mean_net_lifetime: 4446.2802, mean_mc_travel_dist: 1517.0392, mean_rewards: 241.5885, total_rewards: 2966.1051, mean_steps: 19.1100, mean_ecr: 0.0401 mean_entropies: 1.4349, took: 100.2851s
2022-10-09 13:53:41,630 [INFO] 	Process 5 - batch 37899: mean_policy_losses: -29.469, mean_net_lifetime: 4327.6121, mean_mc_travel_dist: 1477.2967, mean_rewards: 227.2705, total_rewards: 2877.8147, mean_steps: 19.3400, mean_ecr: 0.0402 mean_entropies: 1.3887, took: 101.4848s
2022-10-09 13:54:09,667 [INFO] 	Process 2 - batch 37899: mean_policy_losses: -46.058, mean_net_lifetime: 4282.4658, mean_mc_travel_dist: 1457.9940, mean_rewards: 231.6352, total_rewards: 2854.1653, mean_steps: 18.6000, mean_ecr: 0.0403 mean_entropies: 1.4067, took: 99.3777s
2022-10-09 13:54:25,076 [INFO] 	Process 4 - batch 37799: mean_policy_losses: -127.306, mean_net_lifetime: 4203.2342, mean_mc_travel_dist: 1406.3886, mean_rewards: 235.8436, total_rewards: 2827.6400, mean_steps: 18.4500, mean_ecr: 0.0400 mean_entropies: 1.4343, took: 94.4591s
2022-10-09 13:54:26,051 [INFO] 	Process 0 - batch 37699: mean_policy_losses: -169.435, mean_net_lifetime: 4233.1902, mean_mc_travel_dist: 1422.0471, mean_rewards: 239.2165, total_rewards: 2851.1940, mean_steps: 18.6200, mean_ecr: 0.0392 mean_entropies: 1.4148, took: 96.9376s
2022-10-09 13:54:45,607 [INFO] 	Process 1 - batch 39499: mean_policy_losses: -74.001, mean_net_lifetime: 4356.1061, mean_mc_travel_dist: 1463.4680, mean_rewards: 233.5314, total_rewards: 2936.0928, mean_steps: 19.0900, mean_ecr: 0.0393 mean_entropies: 1.4120, took: 96.2847s
2022-10-09 13:55:10,647 [INFO] 	Process 3 - batch 37699: mean_policy_losses: -111.303, mean_net_lifetime: 4328.5839, mean_mc_travel_dist: 1457.0818, mean_rewards: 240.8921, total_rewards: 2906.3020, mean_steps: 18.6000, mean_ecr: 0.0391 mean_entropies: 1.4203, took: 96.8854s
2022-10-09 13:55:25,876 [INFO] 	Process 5 - batch 37999: mean_policy_losses: -62.449, mean_net_lifetime: 4674.7096, mean_mc_travel_dist: 1649.3253, mean_rewards: 243.1334, total_rewards: 3064.1810, mean_steps: 20.2400, mean_ecr: 0.0396 mean_entropies: 1.3919, took: 104.2460s
2022-10-09 13:55:58,015 [INFO] 	Process 4 - batch 37899: mean_policy_losses: -18.301, mean_net_lifetime: 4101.1757, mean_mc_travel_dist: 1429.1768, mean_rewards: 232.7772, total_rewards: 2716.3262, mean_steps: 18.0700, mean_ecr: 0.0401 mean_entropies: 1.3308, took: 92.9389s
2022-10-09 13:55:59,547 [INFO] 	Process 0 - batch 37799: mean_policy_losses: -87.205, mean_net_lifetime: 4096.6578, mean_mc_travel_dist: 1402.9484, mean_rewards: 233.8823, total_rewards: 2739.7993, mean_steps: 18.1100, mean_ecr: 0.0397 mean_entropies: 1.3889, took: 93.4969s
2022-10-09 13:56:12,051 [INFO] 	Process 2 - batch 37999: mean_policy_losses: -26.103, mean_net_lifetime: 5127.6146, mean_mc_travel_dist: 1826.0216, mean_rewards: 240.2864, total_rewards: 3339.5445, mean_steps: 23.6600, mean_ecr: 0.0392 mean_entropies: 1.3900, took: 122.3833s
2022-10-09 13:56:28,997 [INFO] 	Process 1 - batch 39599: mean_policy_losses: -90.856, mean_net_lifetime: 4546.2852, mean_mc_travel_dist: 1573.2070, mean_rewards: 231.1715, total_rewards: 3007.3861, mean_steps: 20.4900, mean_ecr: 0.0392 mean_entropies: 1.4343, took: 103.3901s
2022-10-09 13:56:35,322 [INFO] 	Process 6 - batch 38099: mean_policy_losses: -117.980, mean_net_lifetime: 7215.3521, mean_mc_travel_dist: 2909.2018, mean_rewards: 225.1395, total_rewards: 4334.4597, mean_steps: 36.4200, mean_ecr: 0.0377 mean_entropies: 1.4024, took: 178.4107s
2022-10-09 13:56:56,085 [INFO] 	Process 3 - batch 37799: mean_policy_losses: -55.717, mean_net_lifetime: 4367.5709, mean_mc_travel_dist: 1496.6612, mean_rewards: 227.6996, total_rewards: 2897.6113, mean_steps: 20.7400, mean_ecr: 0.0399 mean_entropies: 1.3711, took: 105.4383s
2022-10-09 13:57:41,622 [INFO] 	Process 4 - batch 37999: mean_policy_losses: -94.650, mean_net_lifetime: 4468.2312, mean_mc_travel_dist: 1529.8846, mean_rewards: 229.9287, total_rewards: 2979.1687, mean_steps: 20.0400, mean_ecr: 0.0397 mean_entropies: 1.3775, took: 103.6074s
2022-10-09 13:57:56,388 [INFO] 	Process 0 - batch 37899: mean_policy_losses: -103.353, mean_net_lifetime: 4617.2419, mean_mc_travel_dist: 1647.0325, mean_rewards: 219.6515, total_rewards: 3003.1765, mean_steps: 22.3500, mean_ecr: 0.0397 mean_entropies: 1.3430, took: 116.8405s
2022-10-09 13:58:05,061 [INFO] 	Process 5 - batch 38099: mean_policy_losses: -73.450, mean_net_lifetime: 6423.3370, mean_mc_travel_dist: 2604.7431, mean_rewards: 225.4655, total_rewards: 3854.6132, mean_steps: 32.0000, mean_ecr: 0.0374 mean_entropies: 1.4386, took: 159.1860s
2022-10-09 13:58:16,702 [INFO] 	Process 1 - batch 39699: mean_policy_losses: -121.062, mean_net_lifetime: 4635.8904, mean_mc_travel_dist: 1700.2931, mean_rewards: 228.3599, total_rewards: 2971.2731, mean_steps: 21.4300, mean_ecr: 0.0390 mean_entropies: 1.4399, took: 107.7038s
2022-10-09 13:58:24,224 [INFO] 	Process 6 - batch 38199: mean_policy_losses: -98.135, mean_net_lifetime: 4539.6346, mean_mc_travel_dist: 1579.8196, mean_rewards: 228.2637, total_rewards: 3001.9866, mean_steps: 20.8900, mean_ecr: 0.0393 mean_entropies: 1.3766, took: 108.9018s
2022-10-09 13:58:47,642 [INFO] 	Process 3 - batch 37899: mean_policy_losses: -9.891, mean_net_lifetime: 4678.8398, mean_mc_travel_dist: 1614.2188, mean_rewards: 226.7165, total_rewards: 3101.9279, mean_steps: 21.6300, mean_ecr: 0.0401 mean_entropies: 1.3597, took: 111.5555s
2022-10-09 13:59:10,257 [INFO] 	Process 2 - batch 38099: mean_policy_losses: -98.110, mean_net_lifetime: 6944.6202, mean_mc_travel_dist: 2777.3407, mean_rewards: 230.9698, total_rewards: 4206.6107, mean_steps: 35.4500, mean_ecr: 0.0375 mean_entropies: 1.4279, took: 178.2060s
2022-10-09 13:59:43,698 [INFO] 	Process 0 - batch 37999: mean_policy_losses: -92.463, mean_net_lifetime: 4682.8215, mean_mc_travel_dist: 1572.1995, mean_rewards: 238.1766, total_rewards: 3153.6669, mean_steps: 20.2900, mean_ecr: 0.0398 mean_entropies: 1.3953, took: 107.3103s
2022-10-09 13:59:52,035 [INFO] 	Process 1 - batch 39799: mean_policy_losses: -275.396, mean_net_lifetime: 4148.3889, mean_mc_travel_dist: 1432.6924, mean_rewards: 231.6679, total_rewards: 2754.8354, mean_steps: 18.5500, mean_ecr: 0.0382 mean_entropies: 1.3953, took: 95.3340s
2022-10-09 14:00:31,872 [INFO] 	Process 4 - batch 38099: mean_policy_losses: -49.046, mean_net_lifetime: 6863.7622, mean_mc_travel_dist: 2673.4950, mean_rewards: 225.3218, total_rewards: 4235.3681, mean_steps: 34.6800, mean_ecr: 0.0373 mean_entropies: 1.4576, took: 170.2502s
2022-10-09 14:00:46,784 [INFO] 	Process 3 - batch 37999: mean_policy_losses: -97.525, mean_net_lifetime: 5138.3378, mean_mc_travel_dist: 1798.1897, mean_rewards: 233.3752, total_rewards: 3389.8000, mean_steps: 23.6800, mean_ecr: 0.0394 mean_entropies: 1.4006, took: 119.1435s
2022-10-09 14:00:57,656 [INFO] 	Process 5 - batch 38199: mean_policy_losses: -62.172, mean_net_lifetime: 6490.1876, mean_mc_travel_dist: 2612.4423, mean_rewards: 228.9494, total_rewards: 3920.3082, mean_steps: 34.2900, mean_ecr: 0.0389 mean_entropies: 1.4027, took: 172.5940s
2022-10-09 14:01:16,330 [INFO] 	Process 2 - batch 38199: mean_policy_losses: -146.802, mean_net_lifetime: 4992.6560, mean_mc_travel_dist: 1826.3347, mean_rewards: 223.8461, total_rewards: 3209.3480, mean_steps: 24.5200, mean_ecr: 0.0393 mean_entropies: 1.4004, took: 126.0734s
2022-10-09 14:01:29,342 [INFO] 	Process 6 - batch 38299: mean_policy_losses: -12.266, mean_net_lifetime: 7195.8043, mean_mc_travel_dist: 2785.5788, mean_rewards: 226.5331, total_rewards: 4436.4950, mean_steps: 36.4600, mean_ecr: 0.0374 mean_entropies: 1.5333, took: 185.1179s
2022-10-09 14:01:42,755 [INFO] 	Process 1 - batch 39899: mean_policy_losses: -138.201, mean_net_lifetime: 4712.1281, mean_mc_travel_dist: 1650.9108, mean_rewards: 229.4732, total_rewards: 3102.8624, mean_steps: 21.9200, mean_ecr: 0.0398 mean_entropies: 1.3673, took: 110.7204s
2022-10-09 14:02:17,849 [INFO] 	Process 0 - batch 38099: mean_policy_losses: -33.423, mean_net_lifetime: 6145.0660, mean_mc_travel_dist: 2382.9043, mean_rewards: 229.8592, total_rewards: 3804.4739, mean_steps: 30.5700, mean_ecr: 0.0379 mean_entropies: 1.4377, took: 154.1511s
2022-10-09 14:02:36,487 [INFO] 	Process 4 - batch 38199: mean_policy_losses: -135.107, mean_net_lifetime: 4997.1175, mean_mc_travel_dist: 1873.3826, mean_rewards: 227.7663, total_rewards: 3161.4477, mean_steps: 23.7300, mean_ecr: 0.0396 mean_entropies: 1.3932, took: 124.6151s
2022-10-09 14:02:51,164 [INFO] 	Process 5 - batch 38299: mean_policy_losses: -99.687, mean_net_lifetime: 4790.1968, mean_mc_travel_dist: 1708.3481, mean_rewards: 231.6825, total_rewards: 3111.2859, mean_steps: 21.9100, mean_ecr: 0.0375 mean_entropies: 1.4937, took: 113.5079s
2022-10-09 14:03:35,392 [INFO] 	Process 6 - batch 38399: mean_policy_losses: -131.587, mean_net_lifetime: 4945.9429, mean_mc_travel_dist: 1817.3489, mean_rewards: 225.1003, total_rewards: 3163.3911, mean_steps: 24.5200, mean_ecr: 0.0401 mean_entropies: 1.4172, took: 126.0498s
2022-10-09 14:03:36,583 [INFO] 	Process 3 - batch 38099: mean_policy_losses: -29.802, mean_net_lifetime: 6945.7419, mean_mc_travel_dist: 2751.9254, mean_rewards: 224.2373, total_rewards: 4226.3029, mean_steps: 34.1200, mean_ecr: 0.0374 mean_entropies: 1.4388, took: 169.7982s
2022-10-09 14:03:37,246 [INFO] 	Process 1 - batch 39999: mean_policy_losses: -96.025, mean_net_lifetime: 4811.5238, mean_mc_travel_dist: 1827.3807, mean_rewards: 237.5440, total_rewards: 3019.5439, mean_steps: 22.8300, mean_ecr: 0.0411 mean_entropies: 1.3472, took: 114.4904s
2022-10-09 14:04:06,778 [INFO] 	Process 2 - batch 38299: mean_policy_losses: -63.072, mean_net_lifetime: 6841.1263, mean_mc_travel_dist: 2584.6958, mean_rewards: 219.6831, total_rewards: 4295.1488, mean_steps: 34.1500, mean_ecr: 0.0370 mean_entropies: 1.4985, took: 170.4479s
2022-10-09 14:04:14,172 [INFO] 	Process 0 - batch 38199: mean_policy_losses: -120.672, mean_net_lifetime: 4720.3270, mean_mc_travel_dist: 1682.5706, mean_rewards: 223.8925, total_rewards: 3092.5997, mean_steps: 22.0800, mean_ecr: 0.0393 mean_entropies: 1.3562, took: 116.3233s
2022-10-09 14:04:51,749 [INFO] 	Process 5 - batch 38399: mean_policy_losses: -90.418, mean_net_lifetime: 4859.3402, mean_mc_travel_dist: 1740.7447, mean_rewards: 222.1452, total_rewards: 3147.0401, mean_steps: 23.7200, mean_ecr: 0.0391 mean_entropies: 1.4368, took: 120.5860s
2022-10-09 14:04:58,027 [INFO] 	Process 4 - batch 38299: mean_policy_losses: -34.441, mean_net_lifetime: 5814.7680, mean_mc_travel_dist: 2125.7392, mean_rewards: 228.5544, total_rewards: 3728.1115, mean_steps: 28.0400, mean_ecr: 0.0373 mean_entropies: 1.4570, took: 141.5396s
2022-10-09 14:05:12,995 [INFO] 	Process 6 - batch 38499: mean_policy_losses: -195.724, mean_net_lifetime: 4272.5938, mean_mc_travel_dist: 1458.2828, mean_rewards: 237.3505, total_rewards: 2861.0709, mean_steps: 18.6100, mean_ecr: 0.0391 mean_entropies: 1.3937, took: 97.6024s
2022-10-09 14:05:28,689 [INFO] 	Process 1 - batch 40099: mean_policy_losses: -43.665, mean_net_lifetime: 4839.2763, mean_mc_travel_dist: 1675.5959, mean_rewards: 232.7511, total_rewards: 3199.8840, mean_steps: 22.0500, mean_ecr: 0.0388 mean_entropies: 1.4155, took: 111.4441s
2022-10-09 14:05:40,205 [INFO] 	Process 3 - batch 38199: mean_policy_losses: -71.832, mean_net_lifetime: 5081.9842, mean_mc_travel_dist: 1798.8505, mean_rewards: 224.1939, total_rewards: 3318.0676, mean_steps: 24.3600, mean_ecr: 0.0393 mean_entropies: 1.3832, took: 123.6184s
2022-10-09 14:05:59,423 [INFO] 	Process 2 - batch 38399: mean_policy_losses: -80.005, mean_net_lifetime: 4557.2249, mean_mc_travel_dist: 1577.3964, mean_rewards: 227.6839, total_rewards: 3011.8836, mean_steps: 21.1700, mean_ecr: 0.0396 mean_entropies: 1.4598, took: 112.6454s
2022-10-09 14:06:12,200 [INFO] 	Process 0 - batch 38299: mean_policy_losses: -47.784, mean_net_lifetime: 4870.1912, mean_mc_travel_dist: 1693.9529, mean_rewards: 228.7130, total_rewards: 3218.8673, mean_steps: 22.6400, mean_ecr: 0.0374 mean_entropies: 1.4965, took: 118.0282s
2022-10-09 14:06:23,143 [INFO] 	Process 5 - batch 38499: mean_policy_losses: -197.588, mean_net_lifetime: 4106.8698, mean_mc_travel_dist: 1377.7083, mean_rewards: 244.5495, total_rewards: 2763.3271, mean_steps: 17.1500, mean_ecr: 0.0396 mean_entropies: 1.4084, took: 91.3939s
2022-10-09 14:06:55,310 [INFO] 	Process 4 - batch 38399: mean_policy_losses: -178.480, mean_net_lifetime: 4780.8921, mean_mc_travel_dist: 1702.4625, mean_rewards: 227.3995, total_rewards: 3117.5514, mean_steps: 22.8800, mean_ecr: 0.0393 mean_entropies: 1.4835, took: 117.2820s
2022-10-09 14:06:55,866 [INFO] 	Process 6 - batch 38599: mean_policy_losses: -83.653, mean_net_lifetime: 4303.1842, mean_mc_travel_dist: 1443.3504, mean_rewards: 226.7651, total_rewards: 2897.0646, mean_steps: 19.5800, mean_ecr: 0.0381 mean_entropies: 1.4664, took: 102.8711s
2022-10-09 14:07:25,854 [INFO] 	Process 1 - batch 40199: mean_policy_losses: -46.207, mean_net_lifetime: 5173.6598, mean_mc_travel_dist: 1876.0830, mean_rewards: 233.2576, total_rewards: 3331.4379, mean_steps: 23.3700, mean_ecr: 0.0379 mean_entropies: 1.4494, took: 117.1652s
2022-10-09 14:07:49,449 [INFO] 	Process 3 - batch 38299: mean_policy_losses: -57.852, mean_net_lifetime: 5430.2555, mean_mc_travel_dist: 1974.1720, mean_rewards: 223.9368, total_rewards: 3496.5635, mean_steps: 25.8100, mean_ecr: 0.0373 mean_entropies: 1.5249, took: 129.2472s
2022-10-09 14:07:59,130 [INFO] 	Process 2 - batch 38499: mean_policy_losses: -111.223, mean_net_lifetime: 4917.8053, mean_mc_travel_dist: 1761.2630, mean_rewards: 236.8109, total_rewards: 3207.6907, mean_steps: 22.5900, mean_ecr: 0.0392 mean_entropies: 1.4248, took: 119.7061s
2022-10-09 14:08:01,537 [INFO] 	Process 0 - batch 38399: mean_policy_losses: -82.741, mean_net_lifetime: 4510.6317, mean_mc_travel_dist: 1559.9737, mean_rewards: 225.2454, total_rewards: 2991.7890, mean_steps: 20.8100, mean_ecr: 0.0394 mean_entropies: 1.4588, took: 109.3372s
2022-10-09 14:08:19,022 [INFO] 	Process 5 - batch 38599: mean_policy_losses: -9.379, mean_net_lifetime: 4723.8314, mean_mc_travel_dist: 1604.2530, mean_rewards: 220.3065, total_rewards: 3156.0765, mean_steps: 22.4200, mean_ecr: 0.0380 mean_entropies: 1.4692, took: 115.8787s
2022-10-09 14:08:40,514 [INFO] 	Process 6 - batch 38699: mean_policy_losses: -185.224, mean_net_lifetime: 4366.9342, mean_mc_travel_dist: 1445.3703, mean_rewards: 231.7490, total_rewards: 2960.1114, mean_steps: 20.1000, mean_ecr: 0.0387 mean_entropies: 1.3967, took: 104.6490s
2022-10-09 14:09:09,491 [INFO] 	Process 1 - batch 40299: mean_policy_losses: -57.885, mean_net_lifetime: 4609.4987, mean_mc_travel_dist: 1556.1751, mean_rewards: 231.5429, total_rewards: 3099.2086, mean_steps: 20.5200, mean_ecr: 0.0393 mean_entropies: 1.4158, took: 103.6367s
2022-10-09 14:09:27,262 [INFO] 	Process 4 - batch 38499: mean_policy_losses: -124.629, mean_net_lifetime: 6513.0804, mean_mc_travel_dist: 2354.3373, mean_rewards: 238.4406, total_rewards: 4197.4135, mean_steps: 30.2800, mean_ecr: 0.0393 mean_entropies: 1.4354, took: 151.9536s
2022-10-09 14:09:36,970 [INFO] 	Process 0 - batch 38499: mean_policy_losses: -212.819, mean_net_lifetime: 4268.1753, mean_mc_travel_dist: 1444.7766, mean_rewards: 244.0022, total_rewards: 2859.1298, mean_steps: 17.9600, mean_ecr: 0.0394 mean_entropies: 1.4216, took: 95.4325s
2022-10-09 14:09:40,252 [INFO] 	Process 2 - batch 38599: mean_policy_losses: -55.459, mean_net_lifetime: 4516.3549, mean_mc_travel_dist: 1508.4862, mean_rewards: 230.3029, total_rewards: 3047.3794, mean_steps: 19.6000, mean_ecr: 0.0380 mean_entropies: 1.4666, took: 101.1232s
2022-10-09 14:09:44,075 [INFO] 	Process 3 - batch 38399: mean_policy_losses: -96.842, mean_net_lifetime: 4776.4288, mean_mc_travel_dist: 1654.8307, mean_rewards: 229.3074, total_rewards: 3162.4968, mean_steps: 21.7300, mean_ecr: 0.0394 mean_entropies: 1.4975, took: 114.6262s
2022-10-09 14:09:59,551 [INFO] 	Process 5 - batch 38699: mean_policy_losses: -221.435, mean_net_lifetime: 4452.7101, mean_mc_travel_dist: 1483.8801, mean_rewards: 242.8762, total_rewards: 3016.3659, mean_steps: 19.2900, mean_ecr: 0.0385 mean_entropies: 1.4137, took: 100.5291s
2022-10-09 14:10:53,313 [INFO] 	Process 1 - batch 40399: mean_policy_losses: -132.194, mean_net_lifetime: 4492.5201, mean_mc_travel_dist: 1566.2258, mean_rewards: 226.9625, total_rewards: 2963.4343, mean_steps: 20.5500, mean_ecr: 0.0381 mean_entropies: 1.4336, took: 103.8224s
2022-10-09 14:11:04,219 [INFO] 	Process 6 - batch 38799: mean_policy_losses: -59.239, mean_net_lifetime: 5735.8400, mean_mc_travel_dist: 2115.6552, mean_rewards: 231.4271, total_rewards: 3654.8844, mean_steps: 28.7000, mean_ecr: 0.0381 mean_entropies: 1.4610, took: 143.7047s
2022-10-09 14:11:18,185 [INFO] 	Process 4 - batch 38599: mean_policy_losses: -83.595, mean_net_lifetime: 4619.5431, mean_mc_travel_dist: 1576.2375, mean_rewards: 224.3211, total_rewards: 3084.2461, mean_steps: 21.5200, mean_ecr: 0.0380 mean_entropies: 1.4554, took: 110.9216s
2022-10-09 14:11:27,974 [INFO] 	Process 0 - batch 38599: mean_policy_losses: -43.749, mean_net_lifetime: 4640.2702, mean_mc_travel_dist: 1575.5497, mean_rewards: 223.3183, total_rewards: 3101.8089, mean_steps: 21.3100, mean_ecr: 0.0380 mean_entropies: 1.4787, took: 111.0035s
2022-10-09 14:11:29,309 [INFO] 	Process 2 - batch 38699: mean_policy_losses: -115.893, mean_net_lifetime: 4662.5912, mean_mc_travel_dist: 1558.8567, mean_rewards: 233.2662, total_rewards: 3143.5293, mean_steps: 21.0500, mean_ecr: 0.0382 mean_entropies: 1.4203, took: 109.0563s
2022-10-09 14:11:39,238 [INFO] 	Process 3 - batch 38499: mean_policy_losses: -157.074, mean_net_lifetime: 5016.4471, mean_mc_travel_dist: 1776.6237, mean_rewards: 247.4860, total_rewards: 3276.3061, mean_steps: 22.1400, mean_ecr: 0.0394 mean_entropies: 1.4273, took: 115.1640s
2022-10-09 14:11:56,028 [INFO] 	Process 5 - batch 38799: mean_policy_losses: 3.339, mean_net_lifetime: 4991.7170, mean_mc_travel_dist: 1768.5199, mean_rewards: 235.6916, total_rewards: 3269.5568, mean_steps: 22.4500, mean_ecr: 0.0383 mean_entropies: 1.4661, took: 116.4774s
2022-10-09 14:12:27,703 [INFO] 	Process 1 - batch 40499: mean_policy_losses: -84.110, mean_net_lifetime: 4247.7155, mean_mc_travel_dist: 1426.2135, mean_rewards: 232.3936, total_rewards: 2852.4274, mean_steps: 18.4800, mean_ecr: 0.0389 mean_entropies: 1.3949, took: 94.3892s
2022-10-09 14:12:50,187 [INFO] 	Process 6 - batch 38899: mean_policy_losses: -125.680, mean_net_lifetime: 4436.0485, mean_mc_travel_dist: 1542.7652, mean_rewards: 227.1409, total_rewards: 2930.5849, mean_steps: 20.0600, mean_ecr: 0.0385 mean_entropies: 1.4114, took: 105.9681s
2022-10-09 14:13:02,534 [INFO] 	Process 4 - batch 38699: mean_policy_losses: -112.175, mean_net_lifetime: 4564.4288, mean_mc_travel_dist: 1571.7514, mean_rewards: 240.5999, total_rewards: 3028.0913, mean_steps: 20.3200, mean_ecr: 0.0385 mean_entropies: 1.3982, took: 104.3491s
2022-10-09 14:13:08,544 [INFO] 	Process 0 - batch 38699: mean_policy_losses: -125.689, mean_net_lifetime: 4446.6140, mean_mc_travel_dist: 1514.9018, mean_rewards: 239.4293, total_rewards: 2970.0799, mean_steps: 19.4700, mean_ecr: 0.0383 mean_entropies: 1.4277, took: 100.5703s
2022-10-09 14:13:09,219 [INFO] 	Process 2 - batch 38799: mean_policy_losses: -14.525, mean_net_lifetime: 4405.4754, mean_mc_travel_dist: 1529.3865, mean_rewards: 237.1743, total_rewards: 2912.0899, mean_steps: 19.5600, mean_ecr: 0.0388 mean_entropies: 1.4134, took: 99.9100s
2022-10-09 14:13:20,454 [INFO] 	Process 3 - batch 38599: mean_policy_losses: -60.223, mean_net_lifetime: 4411.5770, mean_mc_travel_dist: 1534.6394, mean_rewards: 227.8505, total_rewards: 2920.3479, mean_steps: 20.0400, mean_ecr: 0.0378 mean_entropies: 1.4323, took: 101.2157s
2022-10-09 14:13:57,733 [INFO] 	Process 5 - batch 38899: mean_policy_losses: -71.769, mean_net_lifetime: 5355.2191, mean_mc_travel_dist: 1998.3185, mean_rewards: 231.4777, total_rewards: 3381.3206, mean_steps: 24.9400, mean_ecr: 0.0384 mean_entropies: 1.4026, took: 121.7050s
2022-10-09 14:14:38,180 [INFO] 	Process 4 - batch 38799: mean_policy_losses: -54.663, mean_net_lifetime: 4255.4978, mean_mc_travel_dist: 1459.5476, mean_rewards: 233.8672, total_rewards: 2827.7312, mean_steps: 18.8000, mean_ecr: 0.0382 mean_entropies: 1.4185, took: 95.6463s
2022-10-09 14:14:49,670 [INFO] 	Process 0 - batch 38799: mean_policy_losses: -0.063, mean_net_lifetime: 4467.9735, mean_mc_travel_dist: 1528.4480, mean_rewards: 235.1165, total_rewards: 2972.5310, mean_steps: 19.7500, mean_ecr: 0.0386 mean_entropies: 1.4135, took: 101.1263s
2022-10-09 14:14:52,018 [INFO] 	Process 2 - batch 38899: mean_policy_losses: -96.726, mean_net_lifetime: 4465.5805, mean_mc_travel_dist: 1541.0241, mean_rewards: 228.9850, total_rewards: 2960.2357, mean_steps: 20.4700, mean_ecr: 0.0382 mean_entropies: 1.4093, took: 102.7980s
2022-10-09 14:14:58,810 [INFO] 	Process 3 - batch 38699: mean_policy_losses: -137.976, mean_net_lifetime: 4343.6610, mean_mc_travel_dist: 1486.0444, mean_rewards: 234.8044, total_rewards: 2895.5854, mean_steps: 19.7100, mean_ecr: 0.0385 mean_entropies: 1.3884, took: 98.3558s
2022-10-09 14:15:00,680 [INFO] 	Process 6 - batch 38999: mean_policy_losses: -27.602, mean_net_lifetime: 5725.3482, mean_mc_travel_dist: 2049.4095, mean_rewards: 226.8397, total_rewards: 3710.7185, mean_steps: 26.7200, mean_ecr: 0.0376 mean_entropies: 1.4780, took: 130.4926s
2022-10-09 14:15:50,396 [INFO] 	Process 5 - batch 38999: mean_policy_losses: -29.729, mean_net_lifetime: 5109.2964, mean_mc_travel_dist: 1802.6021, mean_rewards: 231.7235, total_rewards: 3347.1951, mean_steps: 22.7700, mean_ecr: 0.0374 mean_entropies: 1.4554, took: 112.6626s
2022-10-09 14:16:20,946 [INFO] 	Process 4 - batch 38899: mean_policy_losses: -117.465, mean_net_lifetime: 4629.6873, mean_mc_travel_dist: 1632.7860, mean_rewards: 227.3416, total_rewards: 3035.1860, mean_steps: 21.2700, mean_ecr: 0.0382 mean_entropies: 1.3808, took: 102.7670s
2022-10-09 14:16:33,020 [INFO] 	Process 0 - batch 38899: mean_policy_losses: -92.114, mean_net_lifetime: 4675.3149, mean_mc_travel_dist: 1629.8468, mean_rewards: 227.3630, total_rewards: 3077.6296, mean_steps: 21.4500, mean_ecr: 0.0381 mean_entropies: 1.4309, took: 103.3488s
2022-10-09 14:16:35,415 [INFO] 	Process 3 - batch 38799: mean_policy_losses: -39.801, mean_net_lifetime: 4559.5999, mean_mc_travel_dist: 1589.5414, mean_rewards: 234.1393, total_rewards: 3003.4438, mean_steps: 20.3100, mean_ecr: 0.0383 mean_entropies: 1.4264, took: 96.6047s
2022-10-09 14:16:43,219 [INFO] 	Process 2 - batch 38999: mean_policy_losses: -2.906, mean_net_lifetime: 5030.7216, mean_mc_travel_dist: 1775.8513, mean_rewards: 228.4094, total_rewards: 3289.2268, mean_steps: 22.7500, mean_ecr: 0.0374 mean_entropies: 1.4353, took: 111.2015s
2022-10-09 14:18:04,838 [INFO] 	Process 4 - batch 38999: mean_policy_losses: -49.512, mean_net_lifetime: 5187.0061, mean_mc_travel_dist: 1855.9946, mean_rewards: 226.7407, total_rewards: 3372.6474, mean_steps: 23.6300, mean_ecr: 0.0372 mean_entropies: 1.4909, took: 103.8908s
2022-10-09 14:18:12,613 [INFO] 	Process 3 - batch 38899: mean_policy_losses: -61.385, mean_net_lifetime: 4734.5528, mean_mc_travel_dist: 1633.0283, mean_rewards: 223.5648, total_rewards: 3138.1671, mean_steps: 21.8000, mean_ecr: 0.0381 mean_entropies: 1.4215, took: 97.1982s
2022-10-09 14:18:19,521 [INFO] 	Process 0 - batch 38999: mean_policy_losses: -29.828, mean_net_lifetime: 5292.3435, mean_mc_travel_dist: 1870.4881, mean_rewards: 228.7735, total_rewards: 3470.0512, mean_steps: 23.9200, mean_ecr: 0.0372 mean_entropies: 1.4583, took: 106.5022s
2022-10-09 14:19:45,400 [INFO] 	Process 3 - batch 38999: mean_policy_losses: -76.050, mean_net_lifetime: 5023.4054, mean_mc_travel_dist: 1797.8768, mean_rewards: 225.4851, total_rewards: 3271.5134, mean_steps: 23.0100, mean_ecr: 0.0375 mean_entropies: 1.4667, took: 92.7867s
2022-10-09 14:23:53,018 [INFO] 	Process 1 - batch 40599: mean_policy_losses: -94.504, mean_net_lifetime: 3822.7019, mean_mc_travel_dist: 1253.7172, mean_rewards: 238.4690, total_rewards: 2598.6795, mean_steps: 16.6300, mean_ecr: 0.0406 mean_entropies: 1.3966, took: 685.3154s
2022-10-09 14:25:25,755 [INFO] 	Process 1 - batch 40699: mean_policy_losses: -91.216, mean_net_lifetime: 5237.5811, mean_mc_travel_dist: 1889.7982, mean_rewards: 235.5559, total_rewards: 3387.4797, mean_steps: 23.1100, mean_ecr: 0.0391 mean_entropies: 1.4761, took: 92.7364s
2022-10-09 14:26:31,713 [INFO] 	Process 6 - batch 39099: mean_policy_losses: -115.615, mean_net_lifetime: 4426.4587, mean_mc_travel_dist: 1511.4536, mean_rewards: 233.3436, total_rewards: 2954.8305, mean_steps: 19.7600, mean_ecr: 0.0382 mean_entropies: 1.4422, took: 691.0331s
2022-10-09 14:26:49,738 [INFO] 	Process 1 - batch 40799: mean_policy_losses: -74.231, mean_net_lifetime: 4301.5870, mean_mc_travel_dist: 1454.8234, mean_rewards: 236.1095, total_rewards: 2880.9614, mean_steps: 19.0700, mean_ecr: 0.0404 mean_entropies: 1.3727, took: 83.9828s
2022-10-09 14:27:24,657 [INFO] 	Process 5 - batch 39099: mean_policy_losses: -104.553, mean_net_lifetime: 4464.2394, mean_mc_travel_dist: 1509.9320, mean_rewards: 225.1908, total_rewards: 2988.9692, mean_steps: 20.8300, mean_ecr: 0.0384 mean_entropies: 1.4433, took: 694.2607s
2022-10-09 14:28:11,665 [INFO] 	Process 6 - batch 39199: mean_policy_losses: -104.016, mean_net_lifetime: 4575.5568, mean_mc_travel_dist: 1540.1013, mean_rewards: 233.5828, total_rewards: 3067.8501, mean_steps: 20.4800, mean_ecr: 0.0408 mean_entropies: 1.3699, took: 99.9526s
2022-10-09 14:28:43,583 [INFO] 	Process 4 - batch 39099: mean_policy_losses: -152.068, mean_net_lifetime: 4691.4573, mean_mc_travel_dist: 1589.1594, mean_rewards: 229.0397, total_rewards: 3143.1269, mean_steps: 21.1100, mean_ecr: 0.0382 mean_entropies: 1.4561, took: 638.7455s
2022-10-09 14:28:49,005 [INFO] 	Process 0 - batch 39099: mean_policy_losses: -175.609, mean_net_lifetime: 4494.6390, mean_mc_travel_dist: 1480.6407, mean_rewards: 236.5080, total_rewards: 3057.2084, mean_steps: 19.5800, mean_ecr: 0.0381 mean_entropies: 1.4662, took: 629.4840s
2022-10-09 14:28:49,893 [INFO] 	Process 1 - batch 40899: mean_policy_losses: -165.414, mean_net_lifetime: 5497.9987, mean_mc_travel_dist: 1900.7229, mean_rewards: 232.0941, total_rewards: 3635.9630, mean_steps: 25.3800, mean_ecr: 0.0390 mean_entropies: 1.4666, took: 120.1548s
2022-10-09 14:29:08,669 [INFO] 	Process 5 - batch 39199: mean_policy_losses: -61.675, mean_net_lifetime: 4694.6813, mean_mc_travel_dist: 1598.1038, mean_rewards: 234.9176, total_rewards: 3132.0053, mean_steps: 20.5200, mean_ecr: 0.0410 mean_entropies: 1.3918, took: 104.0127s
2022-10-09 14:29:28,342 [INFO] 	Process 2 - batch 39099: mean_policy_losses: -141.807, mean_net_lifetime: 5113.7151, mean_mc_travel_dist: 1819.9869, mean_rewards: 230.5419, total_rewards: 3335.1804, mean_steps: 24.6200, mean_ecr: 0.0381 mean_entropies: 1.4291, took: 765.1238s
2022-10-09 14:29:53,582 [INFO] 	Process 6 - batch 39299: mean_policy_losses: -90.984, mean_net_lifetime: 4623.7826, mean_mc_travel_dist: 1545.4292, mean_rewards: 228.7237, total_rewards: 3115.3931, mean_steps: 20.4400, mean_ecr: 0.0399 mean_entropies: 1.4073, took: 101.9166s
2022-10-09 14:30:24,372 [INFO] 	Process 0 - batch 39199: mean_policy_losses: -95.365, mean_net_lifetime: 4126.0348, mean_mc_travel_dist: 1394.5197, mean_rewards: 228.4689, total_rewards: 2771.1038, mean_steps: 18.6900, mean_ecr: 0.0413 mean_entropies: 1.3794, took: 95.3662s
2022-10-09 14:30:29,551 [INFO] 	Process 4 - batch 39199: mean_policy_losses: -76.774, mean_net_lifetime: 4802.1957, mean_mc_travel_dist: 1617.3941, mean_rewards: 228.5200, total_rewards: 3221.6050, mean_steps: 21.3800, mean_ecr: 0.0405 mean_entropies: 1.3897, took: 105.9678s
2022-10-09 14:30:49,791 [INFO] 	Process 5 - batch 39299: mean_policy_losses: -69.570, mean_net_lifetime: 4448.0223, mean_mc_travel_dist: 1484.5188, mean_rewards: 227.2743, total_rewards: 2990.0952, mean_steps: 20.0400, mean_ecr: 0.0396 mean_entropies: 1.4089, took: 101.1212s
2022-10-09 14:30:59,588 [INFO] 	Process 1 - batch 40999: mean_policy_losses: -226.869, mean_net_lifetime: 5436.7425, mean_mc_travel_dist: 1998.9818, mean_rewards: 234.7649, total_rewards: 3466.9361, mean_steps: 26.6400, mean_ecr: 0.0421 mean_entropies: 1.3375, took: 129.6956s
2022-10-09 14:31:08,716 [INFO] 	Process 2 - batch 39199: mean_policy_losses: -95.170, mean_net_lifetime: 4240.2595, mean_mc_travel_dist: 1439.6322, mean_rewards: 222.3365, total_rewards: 2837.6718, mean_steps: 19.7000, mean_ecr: 0.0410 mean_entropies: 1.3878, took: 100.3723s
2022-10-09 14:31:36,693 [INFO] 	Process 6 - batch 39399: mean_policy_losses: -195.512, mean_net_lifetime: 4341.5259, mean_mc_travel_dist: 1579.5157, mean_rewards: 237.8198, total_rewards: 2799.3711, mean_steps: 20.1400, mean_ecr: 0.0402 mean_entropies: 1.4033, took: 103.1098s
2022-10-09 14:32:06,794 [INFO] 	Process 0 - batch 39299: mean_policy_losses: -62.187, mean_net_lifetime: 4399.1727, mean_mc_travel_dist: 1474.5229, mean_rewards: 233.4331, total_rewards: 2959.6210, mean_steps: 19.3200, mean_ecr: 0.0397 mean_entropies: 1.4263, took: 102.4230s
2022-10-09 14:32:15,823 [INFO] 	Process 4 - batch 39299: mean_policy_losses: -66.329, mean_net_lifetime: 4553.8526, mean_mc_travel_dist: 1524.1266, mean_rewards: 230.1823, total_rewards: 3063.8619, mean_steps: 20.5300, mean_ecr: 0.0399 mean_entropies: 1.3997, took: 106.2720s
2022-10-09 14:32:25,042 [INFO] 	Process 3 - batch 39099: mean_policy_losses: -48.635, mean_net_lifetime: 4595.6556, mean_mc_travel_dist: 1560.7697, mean_rewards: 226.6519, total_rewards: 3082.9841, mean_steps: 20.8800, mean_ecr: 0.0382 mean_entropies: 1.4522, took: 759.6427s
2022-10-09 14:32:27,616 [INFO] 	Process 5 - batch 39399: mean_policy_losses: -235.818, mean_net_lifetime: 4047.9315, mean_mc_travel_dist: 1442.1959, mean_rewards: 233.7675, total_rewards: 2646.1487, mean_steps: 18.4200, mean_ecr: 0.0405 mean_entropies: 1.4456, took: 97.8259s
2022-10-09 14:32:40,638 [INFO] 	Process 1 - batch 41099: mean_policy_losses: -58.152, mean_net_lifetime: 4385.6507, mean_mc_travel_dist: 1467.8617, mean_rewards: 232.1768, total_rewards: 2960.6236, mean_steps: 19.6300, mean_ecr: 0.0400 mean_entropies: 1.4463, took: 101.0483s
2022-10-09 14:32:49,465 [INFO] 	Process 2 - batch 39299: mean_policy_losses: -27.071, mean_net_lifetime: 4332.7687, mean_mc_travel_dist: 1451.2205, mean_rewards: 230.2463, total_rewards: 2923.7183, mean_steps: 19.1300, mean_ecr: 0.0398 mean_entropies: 1.4326, took: 100.7495s
2022-10-09 14:33:25,531 [INFO] 	Process 6 - batch 39499: mean_policy_losses: -36.997, mean_net_lifetime: 4716.8293, mean_mc_travel_dist: 1626.5055, mean_rewards: 233.3754, total_rewards: 3122.3779, mean_steps: 21.0800, mean_ecr: 0.0391 mean_entropies: 1.4609, took: 108.8393s
2022-10-09 14:33:39,194 [INFO] 	Process 0 - batch 39399: mean_policy_losses: -227.935, mean_net_lifetime: 4018.7202, mean_mc_travel_dist: 1407.1049, mean_rewards: 241.4214, total_rewards: 2651.2134, mean_steps: 17.4600, mean_ecr: 0.0402 mean_entropies: 1.4610, took: 92.3999s
2022-10-09 14:33:46,368 [INFO] 	Process 4 - batch 39399: mean_policy_losses: -106.098, mean_net_lifetime: 3949.4907, mean_mc_travel_dist: 1351.1128, mean_rewards: 237.2021, total_rewards: 2633.7935, mean_steps: 17.1000, mean_ecr: 0.0403 mean_entropies: 1.4193, took: 90.5448s
2022-10-09 14:34:04,810 [INFO] 	Process 3 - batch 39199: mean_policy_losses: -58.915, mean_net_lifetime: 4392.5626, mean_mc_travel_dist: 1529.1844, mean_rewards: 232.1959, total_rewards: 2905.7360, mean_steps: 19.3300, mean_ecr: 0.0406 mean_entropies: 1.4108, took: 99.7673s
2022-10-09 14:34:09,035 [INFO] 	Process 5 - batch 39499: mean_policy_losses: -65.701, mean_net_lifetime: 4433.7106, mean_mc_travel_dist: 1541.0842, mean_rewards: 231.6215, total_rewards: 2928.4555, mean_steps: 19.5600, mean_ecr: 0.0395 mean_entropies: 1.4322, took: 101.4186s
2022-10-09 14:34:29,802 [INFO] 	Process 2 - batch 39399: mean_policy_losses: -197.208, mean_net_lifetime: 4239.4775, mean_mc_travel_dist: 1536.6189, mean_rewards: 241.9698, total_rewards: 2749.8356, mean_steps: 19.0800, mean_ecr: 0.0399 mean_entropies: 1.4183, took: 100.3378s
2022-10-09 14:34:45,203 [INFO] 	Process 1 - batch 41199: mean_policy_losses: -56.313, mean_net_lifetime: 5557.0718, mean_mc_travel_dist: 1954.2908, mean_rewards: 227.8013, total_rewards: 3635.1689, mean_steps: 24.8800, mean_ecr: 0.0379 mean_entropies: 1.5023, took: 124.5667s
2022-10-09 14:35:04,112 [INFO] 	Process 6 - batch 39599: mean_policy_losses: -141.706, mean_net_lifetime: 4363.2214, mean_mc_travel_dist: 1544.1259, mean_rewards: 234.3760, total_rewards: 2855.7552, mean_steps: 18.8000, mean_ecr: 0.0394 mean_entropies: 1.4980, took: 98.5795s
2022-10-09 14:35:24,795 [INFO] 	Process 0 - batch 39499: mean_policy_losses: -54.780, mean_net_lifetime: 4618.9803, mean_mc_travel_dist: 1631.1178, mean_rewards: 234.5105, total_rewards: 3022.3068, mean_steps: 20.0900, mean_ecr: 0.0393 mean_entropies: 1.4653, took: 105.6004s
2022-10-09 14:35:32,959 [INFO] 	Process 4 - batch 39499: mean_policy_losses: -53.127, mean_net_lifetime: 4658.8084, mean_mc_travel_dist: 1636.7662, mean_rewards: 231.6244, total_rewards: 3061.3001, mean_steps: 20.5400, mean_ecr: 0.0393 mean_entropies: 1.4672, took: 106.5911s
2022-10-09 14:35:35,140 [INFO] 	Process 3 - batch 39299: mean_policy_losses: -152.999, mean_net_lifetime: 4035.7417, mean_mc_travel_dist: 1392.7981, mean_rewards: 236.2259, total_rewards: 2677.5855, mean_steps: 17.2500, mean_ecr: 0.0398 mean_entropies: 1.4566, took: 90.3302s
2022-10-09 14:35:44,732 [INFO] 	Process 5 - batch 39599: mean_policy_losses: -84.576, mean_net_lifetime: 4298.6189, mean_mc_travel_dist: 1520.0798, mean_rewards: 237.0486, total_rewards: 2817.0839, mean_steps: 18.1500, mean_ecr: 0.0394 mean_entropies: 1.5243, took: 95.6974s
2022-10-09 14:36:12,546 [INFO] 	Process 2 - batch 39499: mean_policy_losses: -96.793, mean_net_lifetime: 4379.9618, mean_mc_travel_dist: 1562.6275, mean_rewards: 234.9596, total_rewards: 2866.8982, mean_steps: 19.7900, mean_ecr: 0.0389 mean_entropies: 1.4483, took: 102.7433s
2022-10-09 14:36:22,961 [INFO] 	Process 1 - batch 41299: mean_policy_losses: -64.279, mean_net_lifetime: 4351.1998, mean_mc_travel_dist: 1559.6761, mean_rewards: 227.5122, total_rewards: 2829.6614, mean_steps: 19.1000, mean_ecr: 0.0393 mean_entropies: 1.5042, took: 97.7577s
2022-10-09 14:36:38,501 [INFO] 	Process 6 - batch 39699: mean_policy_losses: -208.733, mean_net_lifetime: 4081.9875, mean_mc_travel_dist: 1437.0863, mean_rewards: 238.0306, total_rewards: 2684.0497, mean_steps: 18.0000, mean_ecr: 0.0387 mean_entropies: 1.4493, took: 94.3908s
2022-10-09 14:37:02,870 [INFO] 	Process 3 - batch 39399: mean_policy_losses: -155.268, mean_net_lifetime: 3754.4939, mean_mc_travel_dist: 1280.9211, mean_rewards: 238.2964, total_rewards: 2512.4440, mean_steps: 16.3400, mean_ecr: 0.0403 mean_entropies: 1.4122, took: 87.7299s
2022-10-09 14:37:07,715 [INFO] 	Process 0 - batch 39599: mean_policy_losses: -23.231, mean_net_lifetime: 4488.6404, mean_mc_travel_dist: 1574.0851, mean_rewards: 235.0461, total_rewards: 2957.0917, mean_steps: 19.4700, mean_ecr: 0.0390 mean_entropies: 1.4750, took: 102.9199s
2022-10-09 14:37:27,314 [INFO] 	Process 5 - batch 39699: mean_policy_losses: -100.909, mean_net_lifetime: 4326.8849, mean_mc_travel_dist: 1533.9652, mean_rewards: 227.5725, total_rewards: 2830.7324, mean_steps: 19.4300, mean_ecr: 0.0387 mean_entropies: 1.4398, took: 102.5805s
2022-10-09 14:37:29,844 [INFO] 	Process 4 - batch 39599: mean_policy_losses: -23.717, mean_net_lifetime: 4908.7252, mean_mc_travel_dist: 1756.1105, mean_rewards: 230.0971, total_rewards: 3189.7800, mean_steps: 22.4600, mean_ecr: 0.0387 mean_entropies: 1.4593, took: 116.8856s
2022-10-09 14:38:08,033 [INFO] 	Process 2 - batch 39599: mean_policy_losses: -9.552, mean_net_lifetime: 4762.2123, mean_mc_travel_dist: 1660.5610, mean_rewards: 229.4848, total_rewards: 3132.1541, mean_steps: 21.7100, mean_ecr: 0.0392 mean_entropies: 1.4302, took: 115.4874s
2022-10-09 14:38:08,706 [INFO] 	Process 1 - batch 41399: mean_policy_losses: -76.161, mean_net_lifetime: 4492.4426, mean_mc_travel_dist: 1582.2401, mean_rewards: 224.5251, total_rewards: 2941.5204, mean_steps: 20.8000, mean_ecr: 0.0408 mean_entropies: 1.3594, took: 105.7443s
2022-10-09 14:38:21,301 [INFO] 	Process 6 - batch 39799: mean_policy_losses: -205.960, mean_net_lifetime: 4306.7956, mean_mc_travel_dist: 1526.9335, mean_rewards: 235.9315, total_rewards: 2819.1615, mean_steps: 19.7000, mean_ecr: 0.0384 mean_entropies: 1.3674, took: 102.7990s
2022-10-09 14:38:44,312 [INFO] 	Process 0 - batch 39699: mean_policy_losses: -102.742, mean_net_lifetime: 4098.1425, mean_mc_travel_dist: 1379.2424, mean_rewards: 235.0779, total_rewards: 2756.6108, mean_steps: 17.8900, mean_ecr: 0.0394 mean_entropies: 1.4169, took: 96.5962s
2022-10-09 14:38:50,625 [INFO] 	Process 3 - batch 39499: mean_policy_losses: -6.458, mean_net_lifetime: 4552.5892, mean_mc_travel_dist: 1582.6530, mean_rewards: 232.9462, total_rewards: 3010.9992, mean_steps: 20.5100, mean_ecr: 0.0393 mean_entropies: 1.3768, took: 107.7536s
2022-10-09 14:39:04,453 [INFO] 	Process 5 - batch 39799: mean_policy_losses: -180.812, mean_net_lifetime: 4155.1246, mean_mc_travel_dist: 1425.9100, mean_rewards: 242.3117, total_rewards: 2763.8224, mean_steps: 18.0300, mean_ecr: 0.0380 mean_entropies: 1.3678, took: 97.1404s
2022-10-09 14:39:10,386 [INFO] 	Process 4 - batch 39699: mean_policy_losses: -87.632, mean_net_lifetime: 4213.5882, mean_mc_travel_dist: 1482.3971, mean_rewards: 233.7307, total_rewards: 2759.8626, mean_steps: 18.9400, mean_ecr: 0.0391 mean_entropies: 1.3953, took: 100.5418s
2022-10-09 14:39:47,809 [INFO] 	Process 2 - batch 39699: mean_policy_losses: -109.046, mean_net_lifetime: 4264.3492, mean_mc_travel_dist: 1453.1815, mean_rewards: 230.0954, total_rewards: 2844.6479, mean_steps: 18.8200, mean_ecr: 0.0391 mean_entropies: 1.3951, took: 99.7757s
2022-10-09 14:39:48,651 [INFO] 	Process 1 - batch 41499: mean_policy_losses: -30.139, mean_net_lifetime: 4389.4867, mean_mc_travel_dist: 1501.5290, mean_rewards: 229.6898, total_rewards: 2922.2382, mean_steps: 19.9400, mean_ecr: 0.0400 mean_entropies: 1.3979, took: 99.9463s
2022-10-09 14:40:15,595 [INFO] 	Process 6 - batch 39899: mean_policy_losses: -89.024, mean_net_lifetime: 4872.5984, mean_mc_travel_dist: 1704.5211, mean_rewards: 234.7350, total_rewards: 3210.9551, mean_steps: 21.7400, mean_ecr: 0.0401 mean_entropies: 1.3706, took: 114.2950s
2022-10-09 14:40:23,176 [INFO] 	Process 0 - batch 39799: mean_policy_losses: -113.946, mean_net_lifetime: 4355.2595, mean_mc_travel_dist: 1506.1048, mean_rewards: 246.0434, total_rewards: 2878.4210, mean_steps: 18.3800, mean_ecr: 0.0380 mean_entropies: 1.3670, took: 98.8641s
2022-10-09 14:40:39,654 [INFO] 	Process 3 - batch 39599: mean_policy_losses: -15.662, mean_net_lifetime: 4776.2910, mean_mc_travel_dist: 1623.4379, mean_rewards: 240.1843, total_rewards: 3186.6530, mean_steps: 20.6500, mean_ecr: 0.0392 mean_entropies: 1.4352, took: 109.0302s
2022-10-09 14:40:43,845 [INFO] 	Process 5 - batch 39899: mean_policy_losses: -111.233, mean_net_lifetime: 4095.9638, mean_mc_travel_dist: 1390.5832, mean_rewards: 236.2730, total_rewards: 2746.0065, mean_steps: 18.3700, mean_ecr: 0.0402 mean_entropies: 1.3481, took: 99.3905s
2022-10-09 14:40:54,053 [INFO] 	Process 4 - batch 39799: mean_policy_losses: -124.677, mean_net_lifetime: 4378.0432, mean_mc_travel_dist: 1544.2077, mean_rewards: 234.7159, total_rewards: 2873.5221, mean_steps: 19.4800, mean_ecr: 0.0381 mean_entropies: 1.3793, took: 103.6668s
2022-10-09 14:41:28,761 [INFO] 	Process 1 - batch 41599: mean_policy_losses: -60.609, mean_net_lifetime: 4287.4697, mean_mc_travel_dist: 1485.3970, mean_rewards: 228.3490, total_rewards: 2843.3754, mean_steps: 19.5100, mean_ecr: 0.0392 mean_entropies: 1.3948, took: 100.1096s
2022-10-09 14:41:38,002 [INFO] 	Process 2 - batch 39799: mean_policy_losses: -130.602, mean_net_lifetime: 4580.8298, mean_mc_travel_dist: 1630.9114, mean_rewards: 229.3012, total_rewards: 2994.5959, mean_steps: 20.9900, mean_ecr: 0.0378 mean_entropies: 1.3844, took: 110.1928s
2022-10-09 14:41:59,618 [INFO] 	Process 6 - batch 39999: mean_policy_losses: -59.230, mean_net_lifetime: 4255.4216, mean_mc_travel_dist: 1447.5270, mean_rewards: 233.5602, total_rewards: 2853.8193, mean_steps: 19.6400, mean_ecr: 0.0413 mean_entropies: 1.3207, took: 104.0214s
2022-10-09 14:42:09,189 [INFO] 	Process 0 - batch 39899: mean_policy_losses: -74.898, mean_net_lifetime: 4320.5500, mean_mc_travel_dist: 1483.9968, mean_rewards: 232.0339, total_rewards: 2869.9780, mean_steps: 19.9000, mean_ecr: 0.0398 mean_entropies: 1.3394, took: 106.0147s
2022-10-09 14:42:28,355 [INFO] 	Process 3 - batch 39699: mean_policy_losses: -114.095, mean_net_lifetime: 4438.2354, mean_mc_travel_dist: 1569.2026, mean_rewards: 226.3406, total_rewards: 2903.6246, mean_steps: 20.3800, mean_ecr: 0.0390 mean_entropies: 1.4160, took: 108.7013s
2022-10-09 14:42:51,040 [INFO] 	Process 4 - batch 39899: mean_policy_losses: -55.679, mean_net_lifetime: 4809.2216, mean_mc_travel_dist: 1666.5578, mean_rewards: 229.8668, total_rewards: 3173.6734, mean_steps: 22.0400, mean_ecr: 0.0400 mean_entropies: 1.3684, took: 116.9857s
2022-10-09 14:43:20,774 [INFO] 	Process 5 - batch 39999: mean_policy_losses: -28.443, mean_net_lifetime: 6415.7191, mean_mc_travel_dist: 2665.9732, mean_rewards: 236.7120, total_rewards: 3790.7504, mean_steps: 30.4600, mean_ecr: 0.0410 mean_entropies: 1.3728, took: 156.9293s
2022-10-09 14:43:26,114 [INFO] 	Process 1 - batch 41699: mean_policy_losses: -95.600, mean_net_lifetime: 5067.8461, mean_mc_travel_dist: 1790.6747, mean_rewards: 224.9187, total_rewards: 3317.9480, mean_steps: 23.2700, mean_ecr: 0.0389 mean_entropies: 1.4095, took: 117.3528s
2022-10-09 14:43:28,140 [INFO] 	Process 2 - batch 39899: mean_policy_losses: -104.983, mean_net_lifetime: 4594.7883, mean_mc_travel_dist: 1572.9641, mean_rewards: 233.5862, total_rewards: 3057.0412, mean_steps: 20.6400, mean_ecr: 0.0399 mean_entropies: 1.3881, took: 110.1391s
2022-10-09 14:43:51,964 [INFO] 	Process 6 - batch 40099: mean_policy_losses: -137.396, mean_net_lifetime: 4801.0339, mean_mc_travel_dist: 1646.6311, mean_rewards: 237.6107, total_rewards: 3188.6975, mean_steps: 21.3300, mean_ecr: 0.0385 mean_entropies: 1.4562, took: 112.3467s
2022-10-09 14:44:06,515 [INFO] 	Process 0 - batch 39999: mean_policy_losses: -104.971, mean_net_lifetime: 4834.0495, mean_mc_travel_dist: 1731.5688, mean_rewards: 243.6966, total_rewards: 3131.6093, mean_steps: 22.0500, mean_ecr: 0.0412 mean_entropies: 1.4104, took: 117.3255s
2022-10-09 14:44:08,127 [INFO] 	Process 3 - batch 39799: mean_policy_losses: -138.893, mean_net_lifetime: 4327.2582, mean_mc_travel_dist: 1482.1303, mean_rewards: 234.3440, total_rewards: 2893.5127, mean_steps: 18.8100, mean_ecr: 0.0377 mean_entropies: 1.4305, took: 99.7709s
2022-10-09 14:44:40,239 [INFO] 	Process 4 - batch 39999: mean_policy_losses: -71.553, mean_net_lifetime: 4629.2048, mean_mc_travel_dist: 1574.6086, mean_rewards: 243.3679, total_rewards: 3096.9614, mean_steps: 20.5100, mean_ecr: 0.0416 mean_entropies: 1.4027, took: 109.1992s
2022-10-09 14:45:12,751 [INFO] 	Process 5 - batch 40099: mean_policy_losses: -22.311, mean_net_lifetime: 4850.9546, mean_mc_travel_dist: 1670.1860, mean_rewards: 236.6417, total_rewards: 3225.0383, mean_steps: 20.9600, mean_ecr: 0.0387 mean_entropies: 1.4473, took: 111.9766s
2022-10-09 14:45:22,744 [INFO] 	Process 1 - batch 41799: mean_policy_losses: -13.368, mean_net_lifetime: 5174.4313, mean_mc_travel_dist: 1802.4085, mean_rewards: 237.3289, total_rewards: 3409.4351, mean_steps: 23.0300, mean_ecr: 0.0398 mean_entropies: 1.4475, took: 116.6304s
2022-10-09 14:45:32,810 [INFO] 	Process 6 - batch 40199: mean_policy_losses: -72.170, mean_net_lifetime: 4416.6878, mean_mc_travel_dist: 1553.0400, mean_rewards: 238.6600, total_rewards: 2910.1051, mean_steps: 18.8800, mean_ecr: 0.0380 mean_entropies: 1.4276, took: 100.8461s
2022-10-09 14:45:34,187 [INFO] 	Process 2 - batch 39999: mean_policy_losses: -36.030, mean_net_lifetime: 5243.6470, mean_mc_travel_dist: 1841.8655, mean_rewards: 242.5706, total_rewards: 3437.6406, mean_steps: 23.8400, mean_ecr: 0.0415 mean_entropies: 1.4064, took: 126.0459s
2022-10-09 14:45:49,365 [INFO] 	Process 0 - batch 40099: mean_policy_losses: -80.395, mean_net_lifetime: 4377.9177, mean_mc_travel_dist: 1470.1782, mean_rewards: 237.3133, total_rewards: 2945.2035, mean_steps: 18.7700, mean_ecr: 0.0389 mean_entropies: 1.4467, took: 102.8497s
2022-10-09 14:46:13,515 [INFO] 	Process 3 - batch 39899: mean_policy_losses: -123.386, mean_net_lifetime: 5243.5995, mean_mc_travel_dist: 1832.8576, mean_rewards: 227.8547, total_rewards: 3450.0877, mean_steps: 23.6500, mean_ecr: 0.0400 mean_entropies: 1.3922, took: 125.3889s
2022-10-09 14:46:39,514 [INFO] 	Process 4 - batch 40099: mean_policy_losses: -86.122, mean_net_lifetime: 5084.8291, mean_mc_travel_dist: 1779.0168, mean_rewards: 238.8695, total_rewards: 3349.4568, mean_steps: 22.6400, mean_ecr: 0.0386 mean_entropies: 1.4718, took: 119.2759s
2022-10-09 14:47:07,969 [INFO] 	Process 1 - batch 41899: mean_policy_losses: -144.563, mean_net_lifetime: 4496.5121, mean_mc_travel_dist: 1534.7831, mean_rewards: 229.7356, total_rewards: 3004.8224, mean_steps: 20.6900, mean_ecr: 0.0406 mean_entropies: 1.4405, took: 105.2254s
2022-10-09 14:47:10,346 [INFO] 	Process 6 - batch 40299: mean_policy_losses: -114.842, mean_net_lifetime: 4079.1616, mean_mc_travel_dist: 1358.7381, mean_rewards: 237.0156, total_rewards: 2755.8092, mean_steps: 17.7400, mean_ecr: 0.0398 mean_entropies: 1.4303, took: 97.5347s
2022-10-09 14:47:26,275 [INFO] 	Process 2 - batch 40099: mean_policy_losses: -87.461, mean_net_lifetime: 4774.6224, mean_mc_travel_dist: 1628.4763, mean_rewards: 232.2535, total_rewards: 3178.2509, mean_steps: 21.1200, mean_ecr: 0.0386 mean_entropies: 1.4620, took: 112.0880s
2022-10-09 14:47:46,445 [INFO] 	Process 0 - batch 40199: mean_policy_losses: -69.144, mean_net_lifetime: 4911.1350, mean_mc_travel_dist: 1729.4072, mean_rewards: 229.1521, total_rewards: 3223.7080, mean_steps: 21.9100, mean_ecr: 0.0378 mean_entropies: 1.4551, took: 117.0808s
2022-10-09 14:47:54,528 [INFO] 	Process 5 - batch 40199: mean_policy_losses: -63.313, mean_net_lifetime: 6374.4826, mean_mc_travel_dist: 2429.0861, mean_rewards: 231.2813, total_rewards: 3984.8829, mean_steps: 31.2000, mean_ecr: 0.0378 mean_entropies: 1.4372, took: 161.7774s
2022-10-09 14:48:41,873 [INFO] 	Process 3 - batch 39999: mean_policy_losses: -107.057, mean_net_lifetime: 5522.0423, mean_mc_travel_dist: 2105.3894, mean_rewards: 234.3977, total_rewards: 3457.6122, mean_steps: 28.3000, mean_ecr: 0.0413 mean_entropies: 1.4160, took: 148.3572s
2022-10-09 14:48:56,688 [INFO] 	Process 6 - batch 40399: mean_policy_losses: -160.894, mean_net_lifetime: 4332.3101, mean_mc_travel_dist: 1478.2437, mean_rewards: 230.9230, total_rewards: 2883.2680, mean_steps: 19.8200, mean_ecr: 0.0381 mean_entropies: 1.4005, took: 106.3442s
2022-10-09 14:49:00,505 [INFO] 	Process 1 - batch 41999: mean_policy_losses: -40.433, mean_net_lifetime: 4813.2342, mean_mc_travel_dist: 1690.9493, mean_rewards: 222.7374, total_rewards: 3160.2393, mean_steps: 22.6000, mean_ecr: 0.0377 mean_entropies: 1.4299, took: 112.5352s
2022-10-09 14:49:08,252 [INFO] 	Process 4 - batch 40199: mean_policy_losses: -152.398, mean_net_lifetime: 5836.5137, mean_mc_travel_dist: 2209.8752, mean_rewards: 236.6230, total_rewards: 3666.7725, mean_steps: 28.7300, mean_ecr: 0.0379 mean_entropies: 1.4060, took: 148.7368s
2022-10-09 14:49:26,153 [INFO] 	Process 2 - batch 40199: mean_policy_losses: -80.291, mean_net_lifetime: 4881.4212, mean_mc_travel_dist: 1732.0983, mean_rewards: 223.7457, total_rewards: 3189.5587, mean_steps: 22.9500, mean_ecr: 0.0377 mean_entropies: 1.4404, took: 119.8792s
2022-10-09 14:49:39,783 [INFO] 	Process 0 - batch 40299: mean_policy_losses: -49.674, mean_net_lifetime: 4828.5171, mean_mc_travel_dist: 1631.2218, mean_rewards: 230.4457, total_rewards: 3231.9463, mean_steps: 21.6600, mean_ecr: 0.0394 mean_entropies: 1.4062, took: 113.3366s
2022-10-09 14:49:41,361 [INFO] 	Process 5 - batch 40299: mean_policy_losses: -77.022, mean_net_lifetime: 4442.0982, mean_mc_travel_dist: 1515.8794, mean_rewards: 223.8963, total_rewards: 2954.0068, mean_steps: 20.2500, mean_ecr: 0.0396 mean_entropies: 1.3999, took: 106.8335s
2022-10-09 14:50:26,356 [INFO] 	Process 3 - batch 40099: mean_policy_losses: -80.968, mean_net_lifetime: 4471.7434, mean_mc_travel_dist: 1513.8444, mean_rewards: 234.1901, total_rewards: 2993.9687, mean_steps: 20.2100, mean_ecr: 0.0386 mean_entropies: 1.4085, took: 104.4837s
2022-10-09 14:50:45,155 [INFO] 	Process 4 - batch 40299: mean_policy_losses: -143.884, mean_net_lifetime: 4154.8284, mean_mc_travel_dist: 1387.9696, mean_rewards: 231.6230, total_rewards: 2803.2246, mean_steps: 18.6200, mean_ecr: 0.0396 mean_entropies: 1.3795, took: 96.9035s
2022-10-09 14:50:47,044 [INFO] 	Process 6 - batch 40499: mean_policy_losses: -103.289, mean_net_lifetime: 4512.8576, mean_mc_travel_dist: 1556.1690, mean_rewards: 217.6838, total_rewards: 2990.1430, mean_steps: 21.5200, mean_ecr: 0.0387 mean_entropies: 1.4376, took: 110.3551s
2022-10-09 14:51:08,991 [INFO] 	Process 2 - batch 40299: mean_policy_losses: 24.668, mean_net_lifetime: 4423.9931, mean_mc_travel_dist: 1482.7721, mean_rewards: 233.1688, total_rewards: 2981.3843, mean_steps: 19.5200, mean_ecr: 0.0394 mean_entropies: 1.4057, took: 102.8371s
2022-10-09 14:51:22,355 [INFO] 	Process 5 - batch 40399: mean_policy_losses: -170.008, mean_net_lifetime: 4439.2393, mean_mc_travel_dist: 1529.0001, mean_rewards: 234.8173, total_rewards: 2945.7274, mean_steps: 19.8900, mean_ecr: 0.0381 mean_entropies: 1.4113, took: 100.9930s
2022-10-09 14:51:30,608 [INFO] 	Process 0 - batch 40399: mean_policy_losses: -138.260, mean_net_lifetime: 4862.2795, mean_mc_travel_dist: 1698.2913, mean_rewards: 236.1549, total_rewards: 3202.6614, mean_steps: 21.7300, mean_ecr: 0.0383 mean_entropies: 1.4144, took: 110.8258s
2022-10-09 14:52:11,830 [INFO] 	Process 3 - batch 40199: mean_policy_losses: 25.153, mean_net_lifetime: 4777.1740, mean_mc_travel_dist: 1675.7847, mean_rewards: 235.7889, total_rewards: 3143.5070, mean_steps: 20.9200, mean_ecr: 0.0376 mean_entropies: 1.4638, took: 105.4736s
2022-10-09 14:52:18,168 [INFO] 	Process 4 - batch 40399: mean_policy_losses: -87.837, mean_net_lifetime: 4204.6066, mean_mc_travel_dist: 1425.4073, mean_rewards: 244.0815, total_rewards: 2815.1217, mean_steps: 18.2400, mean_ecr: 0.0382 mean_entropies: 1.4173, took: 93.0134s
2022-10-09 14:52:48,324 [INFO] 	Process 2 - batch 40399: mean_policy_losses: -138.549, mean_net_lifetime: 4360.3246, mean_mc_travel_dist: 1510.3027, mean_rewards: 235.3974, total_rewards: 2879.2332, mean_steps: 19.9400, mean_ecr: 0.0380 mean_entropies: 1.4377, took: 99.3332s
2022-10-09 14:52:59,026 [INFO] 	Process 5 - batch 40499: mean_policy_losses: -26.410, mean_net_lifetime: 4440.2822, mean_mc_travel_dist: 1497.0979, mean_rewards: 236.9786, total_rewards: 2989.4364, mean_steps: 19.1900, mean_ecr: 0.0387 mean_entropies: 1.3999, took: 96.6729s
2022-10-09 14:53:06,505 [INFO] 	Process 0 - batch 40499: mean_policy_losses: -147.015, mean_net_lifetime: 4216.7103, mean_mc_travel_dist: 1428.9298, mean_rewards: 235.6809, total_rewards: 2826.1820, mean_steps: 18.6100, mean_ecr: 0.0391 mean_entropies: 1.3818, took: 95.8965s
2022-10-09 14:53:46,203 [INFO] 	Process 3 - batch 40299: mean_policy_losses: -51.033, mean_net_lifetime: 4511.1296, mean_mc_travel_dist: 1497.4457, mean_rewards: 236.9451, total_rewards: 3044.2318, mean_steps: 19.4200, mean_ecr: 0.0395 mean_entropies: 1.4165, took: 94.3741s
2022-10-09 14:53:52,875 [INFO] 	Process 4 - batch 40499: mean_policy_losses: -174.835, mean_net_lifetime: 4407.8665, mean_mc_travel_dist: 1520.9409, mean_rewards: 230.5344, total_rewards: 2918.9774, mean_steps: 19.7400, mean_ecr: 0.0387 mean_entropies: 1.3902, took: 94.7068s
2022-10-09 14:54:24,475 [INFO] 	Process 2 - batch 40499: mean_policy_losses: -135.898, mean_net_lifetime: 4666.7610, mean_mc_travel_dist: 1584.5144, mean_rewards: 238.7378, total_rewards: 3119.9389, mean_steps: 20.6900, mean_ecr: 0.0388 mean_entropies: 1.4169, took: 96.1508s
2022-10-09 14:55:17,081 [INFO] 	Process 3 - batch 40399: mean_policy_losses: -98.653, mean_net_lifetime: 4666.2043, mean_mc_travel_dist: 1632.4838, mean_rewards: 236.8162, total_rewards: 3069.0303, mean_steps: 20.9900, mean_ecr: 0.0380 mean_entropies: 1.4144, took: 90.8778s
2022-10-09 14:56:39,111 [INFO] 	Process 3 - batch 40499: mean_policy_losses: -125.996, mean_net_lifetime: 4302.1922, mean_mc_travel_dist: 1443.2657, mean_rewards: 234.0559, total_rewards: 2895.7052, mean_steps: 18.9400, mean_ecr: 0.0390 mean_entropies: 1.4129, took: 82.0295s
2022-10-09 15:00:55,956 [INFO] 	Process 1 - batch 42099: mean_policy_losses: -124.265, mean_net_lifetime: 4190.3315, mean_mc_travel_dist: 1404.5108, mean_rewards: 233.8362, total_rewards: 2821.5158, mean_steps: 18.7400, mean_ecr: 0.0396 mean_entropies: 1.4198, took: 715.4510s
2022-10-09 15:02:26,960 [INFO] 	Process 1 - batch 42199: mean_policy_losses: -63.128, mean_net_lifetime: 4978.8737, mean_mc_travel_dist: 1774.3359, mean_rewards: 231.8888, total_rewards: 3236.4507, mean_steps: 22.5500, mean_ecr: 0.0390 mean_entropies: 1.4484, took: 91.0046s
2022-10-09 15:02:51,114 [INFO] 	Process 6 - batch 40599: mean_policy_losses: -163.453, mean_net_lifetime: 3982.7541, mean_mc_travel_dist: 1345.1300, mean_rewards: 235.0497, total_rewards: 2680.8152, mean_steps: 17.0900, mean_ecr: 0.0407 mean_entropies: 1.4209, took: 724.0711s
2022-10-09 15:04:06,298 [INFO] 	Process 1 - batch 42299: mean_policy_losses: -145.879, mean_net_lifetime: 5214.3018, mean_mc_travel_dist: 1850.7658, mean_rewards: 233.1133, total_rewards: 3397.0171, mean_steps: 24.1500, mean_ecr: 0.0377 mean_entropies: 1.4346, took: 99.3375s
2022-10-09 15:04:30,311 [INFO] 	Process 6 - batch 40699: mean_policy_losses: -101.106, mean_net_lifetime: 4842.3211, mean_mc_travel_dist: 1661.2606, mean_rewards: 229.2170, total_rewards: 3218.2953, mean_steps: 22.0400, mean_ecr: 0.0391 mean_entropies: 1.4530, took: 99.1956s
2022-10-09 15:05:53,957 [INFO] 	Process 5 - batch 40599: mean_policy_losses: -111.893, mean_net_lifetime: 4182.6511, mean_mc_travel_dist: 1419.2089, mean_rewards: 224.8866, total_rewards: 2800.3135, mean_steps: 18.9600, mean_ecr: 0.0403 mean_entropies: 1.3777, took: 774.9287s
2022-10-09 15:05:57,944 [INFO] 	Process 1 - batch 42399: mean_policy_losses: -145.133, mean_net_lifetime: 5068.8848, mean_mc_travel_dist: 1818.0396, mean_rewards: 218.9191, total_rewards: 3285.6182, mean_steps: 25.1700, mean_ecr: 0.0384 mean_entropies: 1.3770, took: 111.6468s
2022-10-09 15:06:21,570 [INFO] 	Process 4 - batch 40599: mean_policy_losses: -125.867, mean_net_lifetime: 4388.5078, mean_mc_travel_dist: 1479.9145, mean_rewards: 235.3545, total_rewards: 2944.1683, mean_steps: 19.5000, mean_ecr: 0.0407 mean_entropies: 1.3823, took: 748.6958s
2022-10-09 15:06:22,258 [INFO] 	Process 0 - batch 40599: mean_policy_losses: -114.642, mean_net_lifetime: 4521.2546, mean_mc_travel_dist: 1528.3894, mean_rewards: 225.3553, total_rewards: 3019.4982, mean_steps: 20.5100, mean_ecr: 0.0406 mean_entropies: 1.3938, took: 795.7534s
2022-10-09 15:06:30,029 [INFO] 	Process 6 - batch 40799: mean_policy_losses: -41.463, mean_net_lifetime: 5112.1631, mean_mc_travel_dist: 1815.8285, mean_rewards: 227.1251, total_rewards: 3324.0425, mean_steps: 23.8700, mean_ecr: 0.0394 mean_entropies: 1.4096, took: 119.7189s
2022-10-09 15:07:12,388 [INFO] 	Process 2 - batch 40599: mean_policy_losses: -107.733, mean_net_lifetime: 4259.8826, mean_mc_travel_dist: 1407.9441, mean_rewards: 229.2821, total_rewards: 2891.2861, mean_steps: 18.8800, mean_ecr: 0.0403 mean_entropies: 1.3941, took: 767.9126s
2022-10-09 15:07:59,414 [INFO] 	Process 5 - batch 40699: mean_policy_losses: -197.284, mean_net_lifetime: 5187.9881, mean_mc_travel_dist: 1844.0959, mean_rewards: 222.4215, total_rewards: 3386.2584, mean_steps: 24.4900, mean_ecr: 0.0392 mean_entropies: 1.4706, took: 125.4585s
2022-10-09 15:08:15,646 [INFO] 	Process 6 - batch 40899: mean_policy_losses: -148.509, mean_net_lifetime: 4547.2725, mean_mc_travel_dist: 1541.0816, mean_rewards: 237.2944, total_rewards: 3044.0659, mean_steps: 20.6100, mean_ecr: 0.0396 mean_entropies: 1.4371, took: 105.6159s
2022-10-09 15:08:19,083 [INFO] 	Process 4 - batch 40699: mean_policy_losses: -78.396, mean_net_lifetime: 4969.9123, mean_mc_travel_dist: 1745.1350, mean_rewards: 222.4558, total_rewards: 3259.4207, mean_steps: 23.1000, mean_ecr: 0.0390 mean_entropies: 1.4585, took: 117.5134s
2022-10-09 15:08:34,819 [INFO] 	Process 1 - batch 42499: mean_policy_losses: -194.019, mean_net_lifetime: 6688.7741, mean_mc_travel_dist: 2473.4153, mean_rewards: 239.8764, total_rewards: 4253.3556, mean_steps: 33.3000, mean_ecr: 0.0392 mean_entropies: 1.4115, took: 156.8743s
2022-10-09 15:09:00,435 [INFO] 	Process 0 - batch 40699: mean_policy_losses: -42.216, mean_net_lifetime: 6613.7959, mean_mc_travel_dist: 2459.8698, mean_rewards: 224.0970, total_rewards: 4188.6813, mean_steps: 31.3800, mean_ecr: 0.0390 mean_entropies: 1.4670, took: 158.1770s
2022-10-09 15:09:09,048 [INFO] 	Process 2 - batch 40699: mean_policy_losses: -82.510, mean_net_lifetime: 5044.5441, mean_mc_travel_dist: 1766.5193, mean_rewards: 227.4748, total_rewards: 3322.3879, mean_steps: 23.0600, mean_ecr: 0.0390 mean_entropies: 1.4639, took: 116.6615s
2022-10-09 15:09:58,406 [INFO] 	Process 5 - batch 40799: mean_policy_losses: -74.932, mean_net_lifetime: 5101.1840, mean_mc_travel_dist: 1828.5934, mean_rewards: 239.1276, total_rewards: 3317.2389, mean_steps: 22.9900, mean_ecr: 0.0394 mean_entropies: 1.3974, took: 118.9924s
2022-10-09 15:10:11,968 [INFO] 	Process 4 - batch 40799: mean_policy_losses: -26.330, mean_net_lifetime: 4890.2227, mean_mc_travel_dist: 1717.8215, mean_rewards: 229.2260, total_rewards: 3215.2191, mean_steps: 21.9900, mean_ecr: 0.0397 mean_entropies: 1.4048, took: 112.8833s
2022-10-09 15:10:14,080 [INFO] 	Process 1 - batch 42599: mean_policy_losses: -2.074, mean_net_lifetime: 4640.7555, mean_mc_travel_dist: 1584.1698, mean_rewards: 230.6854, total_rewards: 3099.5279, mean_steps: 20.5500, mean_ecr: 0.0389 mean_entropies: 1.4386, took: 99.2608s
2022-10-09 15:10:33,745 [INFO] 	Process 0 - batch 40799: mean_policy_losses: -105.612, mean_net_lifetime: 4104.3085, mean_mc_travel_dist: 1365.3917, mean_rewards: 244.7184, total_rewards: 2774.4568, mean_steps: 17.9400, mean_ecr: 0.0404 mean_entropies: 1.3659, took: 93.3100s
2022-10-09 15:10:33,904 [INFO] 	Process 6 - batch 40999: mean_policy_losses: -189.815, mean_net_lifetime: 5513.6514, mean_mc_travel_dist: 2062.9776, mean_rewards: 236.3963, total_rewards: 3487.9372, mean_steps: 27.1300, mean_ecr: 0.0422 mean_entropies: 1.3216, took: 138.2593s
2022-10-09 15:10:47,160 [INFO] 	Process 2 - batch 40799: mean_policy_losses: -43.447, mean_net_lifetime: 4306.4628, mean_mc_travel_dist: 1439.7309, mean_rewards: 232.3394, total_rewards: 2905.1693, mean_steps: 18.7700, mean_ecr: 0.0401 mean_entropies: 1.3879, took: 98.1101s
2022-10-09 15:11:49,726 [INFO] 	Process 5 - batch 40899: mean_policy_losses: -67.869, mean_net_lifetime: 4684.7750, mean_mc_travel_dist: 1597.1256, mean_rewards: 226.6893, total_rewards: 3125.0955, mean_steps: 21.7200, mean_ecr: 0.0391 mean_entropies: 1.4216, took: 111.3197s
2022-10-09 15:11:59,500 [INFO] 	Process 4 - batch 40899: mean_policy_losses: -78.141, mean_net_lifetime: 4650.9930, mean_mc_travel_dist: 1554.1158, mean_rewards: 233.9037, total_rewards: 3132.2733, mean_steps: 20.8300, mean_ecr: 0.0394 mean_entropies: 1.4264, took: 107.5320s
2022-10-09 15:12:00,349 [INFO] 	Process 1 - batch 42699: mean_policy_losses: -151.906, mean_net_lifetime: 4743.8563, mean_mc_travel_dist: 1669.7903, mean_rewards: 232.8900, total_rewards: 3106.7926, mean_steps: 21.8000, mean_ecr: 0.0380 mean_entropies: 1.3922, took: 106.2695s
2022-10-09 15:12:16,564 [INFO] 	Process 6 - batch 41099: mean_policy_losses: -55.205, mean_net_lifetime: 4436.0083, mean_mc_travel_dist: 1454.4403, mean_rewards: 233.8033, total_rewards: 3016.0994, mean_steps: 19.7400, mean_ecr: 0.0403 mean_entropies: 1.3947, took: 102.6604s
2022-10-09 15:12:41,795 [INFO] 	Process 2 - batch 40899: mean_policy_losses: -36.161, mean_net_lifetime: 4873.2654, mean_mc_travel_dist: 1650.5384, mean_rewards: 232.0455, total_rewards: 3267.6789, mean_steps: 22.2600, mean_ecr: 0.0392 mean_entropies: 1.4211, took: 114.6360s
2022-10-09 15:12:42,121 [INFO] 	Process 0 - batch 40899: mean_policy_losses: -80.882, mean_net_lifetime: 5381.0878, mean_mc_travel_dist: 1907.8198, mean_rewards: 230.5167, total_rewards: 3512.1763, mean_steps: 24.9000, mean_ecr: 0.0389 mean_entropies: 1.4213, took: 128.3758s
2022-10-09 15:12:59,732 [INFO] 	Process 3 - batch 40599: mean_policy_losses: -113.327, mean_net_lifetime: 4073.6636, mean_mc_travel_dist: 1357.1315, mean_rewards: 235.4586, total_rewards: 2756.5591, mean_steps: 17.7800, mean_ecr: 0.0401 mean_entropies: 1.3912, took: 980.6218s
2022-10-09 15:14:04,665 [INFO] 	Process 5 - batch 40999: mean_policy_losses: -165.937, mean_net_lifetime: 5512.3661, mean_mc_travel_dist: 2017.4498, mean_rewards: 240.3863, total_rewards: 3529.4097, mean_steps: 26.0400, mean_ecr: 0.0422 mean_entropies: 1.3086, took: 134.9372s
2022-10-09 15:14:05,969 [INFO] 	Process 6 - batch 41199: mean_policy_losses: -55.347, mean_net_lifetime: 4561.8003, mean_mc_travel_dist: 1557.7629, mean_rewards: 224.9842, total_rewards: 3035.8164, mean_steps: 20.6300, mean_ecr: 0.0382 mean_entropies: 1.4165, took: 109.4043s
2022-10-09 15:14:08,571 [INFO] 	Process 2 - batch 40999: mean_policy_losses: -139.610, mean_net_lifetime: 3670.7752, mean_mc_travel_dist: 1208.9777, mean_rewards: 235.9328, total_rewards: 2495.1974, mean_steps: 15.9900, mean_ecr: 0.0424 mean_entropies: 1.3118, took: 86.7761s
2022-10-09 15:14:10,375 [INFO] 	Process 1 - batch 42799: mean_policy_losses: -25.946, mean_net_lifetime: 5486.8548, mean_mc_travel_dist: 2035.0899, mean_rewards: 220.7627, total_rewards: 3485.0885, mean_steps: 26.6300, mean_ecr: 0.0383 mean_entropies: 1.3916, took: 130.0257s
2022-10-09 15:14:17,380 [INFO] 	Process 0 - batch 40999: mean_policy_losses: -116.870, mean_net_lifetime: 3955.4450, mean_mc_travel_dist: 1338.5851, mean_rewards: 232.0333, total_rewards: 2647.0241, mean_steps: 17.8500, mean_ecr: 0.0419 mean_entropies: 1.2869, took: 95.2583s
2022-10-09 15:14:18,019 [INFO] 	Process 4 - batch 40999: mean_policy_losses: -107.720, mean_net_lifetime: 5647.6079, mean_mc_travel_dist: 2053.4792, mean_rewards: 242.0753, total_rewards: 3620.1357, mean_steps: 26.8900, mean_ecr: 0.0420 mean_entropies: 1.3033, took: 138.5203s
2022-10-09 15:14:53,325 [INFO] 	Process 3 - batch 40699: mean_policy_losses: -47.596, mean_net_lifetime: 4760.5907, mean_mc_travel_dist: 1654.0685, mean_rewards: 225.8956, total_rewards: 3145.3058, mean_steps: 22.0300, mean_ecr: 0.0390 mean_entropies: 1.4260, took: 113.5925s
2022-10-09 15:15:47,916 [INFO] 	Process 1 - batch 42899: mean_policy_losses: -50.625, mean_net_lifetime: 4245.4036, mean_mc_travel_dist: 1430.1039, mean_rewards: 224.6007, total_rewards: 2848.2227, mean_steps: 19.4100, mean_ecr: 0.0400 mean_entropies: 1.3424, took: 97.5405s
2022-10-09 15:15:48,289 [INFO] 	Process 5 - batch 41099: mean_policy_losses: -43.302, mean_net_lifetime: 4297.6653, mean_mc_travel_dist: 1452.6541, mean_rewards: 228.5362, total_rewards: 2876.2353, mean_steps: 19.5900, mean_ecr: 0.0402 mean_entropies: 1.4047, took: 103.6257s
2022-10-09 15:15:57,421 [INFO] 	Process 2 - batch 41099: mean_policy_losses: -24.154, mean_net_lifetime: 4537.9519, mean_mc_travel_dist: 1522.3909, mean_rewards: 233.5817, total_rewards: 3049.6880, mean_steps: 20.3100, mean_ecr: 0.0402 mean_entropies: 1.4226, took: 108.8503s
2022-10-09 15:16:04,189 [INFO] 	Process 0 - batch 41099: mean_policy_losses: -66.468, mean_net_lifetime: 4414.5722, mean_mc_travel_dist: 1459.2500, mean_rewards: 235.1374, total_rewards: 2987.3991, mean_steps: 19.9100, mean_ecr: 0.0405 mean_entropies: 1.3998, took: 106.8104s
2022-10-09 15:16:16,479 [INFO] 	Process 4 - batch 41099: mean_policy_losses: -123.867, mean_net_lifetime: 4856.7042, mean_mc_travel_dist: 1678.7314, mean_rewards: 230.7289, total_rewards: 3212.8914, mean_steps: 22.6900, mean_ecr: 0.0403 mean_entropies: 1.4262, took: 118.4596s
2022-10-09 15:16:50,273 [INFO] 	Process 6 - batch 41299: mean_policy_losses: -67.569, mean_net_lifetime: 6832.3359, mean_mc_travel_dist: 2452.9211, mean_rewards: 214.1887, total_rewards: 4412.7467, mean_steps: 32.3500, mean_ecr: 0.0392 mean_entropies: 1.4737, took: 164.3043s
2022-10-09 15:17:20,537 [INFO] 	Process 3 - batch 40799: mean_policy_losses: -124.411, mean_net_lifetime: 5934.0766, mean_mc_travel_dist: 2204.6341, mean_rewards: 229.7573, total_rewards: 3763.2219, mean_steps: 28.8300, mean_ecr: 0.0399 mean_entropies: 1.4010, took: 147.2044s
2022-10-09 15:17:54,440 [INFO] 	Process 5 - batch 41199: mean_policy_losses: -106.005, mean_net_lifetime: 5137.2713, mean_mc_travel_dist: 1808.9745, mean_rewards: 226.3809, total_rewards: 3365.3648, mean_steps: 24.2600, mean_ecr: 0.0380 mean_entropies: 1.4835, took: 126.1514s
2022-10-09 15:17:56,612 [INFO] 	Process 0 - batch 41199: mean_policy_losses: -132.771, mean_net_lifetime: 4596.5687, mean_mc_travel_dist: 1571.3374, mean_rewards: 220.2658, total_rewards: 3053.4991, mean_steps: 20.9500, mean_ecr: 0.0382 mean_entropies: 1.4834, took: 112.4225s
2022-10-09 15:18:04,658 [INFO] 	Process 2 - batch 41199: mean_policy_losses: -43.213, mean_net_lifetime: 5413.5419, mean_mc_travel_dist: 1836.5691, mean_rewards: 226.1537, total_rewards: 3610.7804, mean_steps: 24.8100, mean_ecr: 0.0379 mean_entropies: 1.4886, took: 127.2365s
2022-10-09 15:18:24,903 [INFO] 	Process 4 - batch 41199: mean_policy_losses: -158.944, mean_net_lifetime: 5141.7215, mean_mc_travel_dist: 1808.8325, mean_rewards: 225.4629, total_rewards: 3372.3660, mean_steps: 24.3000, mean_ecr: 0.0379 mean_entropies: 1.4823, took: 128.4239s
2022-10-09 15:18:32,115 [INFO] 	Process 1 - batch 42999: mean_policy_losses: -107.088, mean_net_lifetime: 6613.5186, mean_mc_travel_dist: 2531.3249, mean_rewards: 224.9601, total_rewards: 4109.4835, mean_steps: 33.9100, mean_ecr: 0.0390 mean_entropies: 1.3618, took: 164.1997s
2022-10-09 15:18:43,858 [INFO] 	Process 6 - batch 41399: mean_policy_losses: -171.257, mean_net_lifetime: 4632.0596, mean_mc_travel_dist: 1617.9679, mean_rewards: 216.3338, total_rewards: 3053.2018, mean_steps: 21.7300, mean_ecr: 0.0403 mean_entropies: 1.3745, took: 113.5848s
2022-10-09 15:19:05,623 [INFO] 	Process 3 - batch 40899: mean_policy_losses: -141.358, mean_net_lifetime: 4510.7138, mean_mc_travel_dist: 1504.1939, mean_rewards: 235.1615, total_rewards: 3045.7335, mean_steps: 19.9500, mean_ecr: 0.0393 mean_entropies: 1.4486, took: 105.0943s
2022-10-09 15:19:48,671 [INFO] 	Process 0 - batch 41299: mean_policy_losses: -132.559, mean_net_lifetime: 4717.5019, mean_mc_travel_dist: 1613.0404, mean_rewards: 232.7748, total_rewards: 3140.4081, mean_steps: 21.1400, mean_ecr: 0.0394 mean_entropies: 1.4536, took: 112.0586s
2022-10-09 15:19:56,727 [INFO] 	Process 5 - batch 41299: mean_policy_losses: -117.818, mean_net_lifetime: 5119.0506, mean_mc_travel_dist: 1767.3930, mean_rewards: 228.0152, total_rewards: 3383.6453, mean_steps: 23.4500, mean_ecr: 0.0390 mean_entropies: 1.4262, took: 122.2863s
2022-10-09 15:20:05,623 [INFO] 	Process 2 - batch 41299: mean_policy_losses: -100.855, mean_net_lifetime: 5042.8246, mean_mc_travel_dist: 1731.3200, mean_rewards: 228.1912, total_rewards: 3349.5128, mean_steps: 22.9200, mean_ecr: 0.0392 mean_entropies: 1.4437, took: 120.9651s
2022-10-09 15:20:20,530 [INFO] 	Process 1 - batch 43099: mean_policy_losses: -80.270, mean_net_lifetime: 4793.3778, mean_mc_travel_dist: 1705.0792, mean_rewards: 234.5982, total_rewards: 3120.5533, mean_steps: 21.9000, mean_ecr: 0.0395 mean_entropies: 1.4570, took: 108.4148s
2022-10-09 15:20:26,951 [INFO] 	Process 4 - batch 41299: mean_policy_losses: -145.630, mean_net_lifetime: 5205.3544, mean_mc_travel_dist: 1810.9786, mean_rewards: 229.7246, total_rewards: 3436.5976, mean_steps: 23.9100, mean_ecr: 0.0392 mean_entropies: 1.4406, took: 122.0477s
2022-10-09 15:20:30,790 [INFO] 	Process 6 - batch 41499: mean_policy_losses: -59.722, mean_net_lifetime: 4545.1161, mean_mc_travel_dist: 1559.8288, mean_rewards: 229.2650, total_rewards: 3018.5961, mean_steps: 20.3800, mean_ecr: 0.0397 mean_entropies: 1.4474, took: 106.9314s
2022-10-09 15:21:19,886 [INFO] 	Process 3 - batch 40999: mean_policy_losses: -110.633, mean_net_lifetime: 5486.5234, mean_mc_travel_dist: 2015.9164, mean_rewards: 244.6934, total_rewards: 3501.7164, mean_steps: 26.4700, mean_ecr: 0.0416 mean_entropies: 1.3331, took: 134.2624s
2022-10-09 15:21:44,742 [INFO] 	Process 0 - batch 41399: mean_policy_losses: -106.594, mean_net_lifetime: 4753.4590, mean_mc_travel_dist: 1647.3571, mean_rewards: 221.1512, total_rewards: 3149.9564, mean_steps: 21.7400, mean_ecr: 0.0404 mean_entropies: 1.3642, took: 116.0713s
2022-10-09 15:21:55,717 [INFO] 	Process 2 - batch 41399: mean_policy_losses: -84.760, mean_net_lifetime: 4715.8421, mean_mc_travel_dist: 1603.0555, mean_rewards: 228.0807, total_rewards: 3146.8904, mean_steps: 21.0300, mean_ecr: 0.0408 mean_entropies: 1.3847, took: 110.0944s
2022-10-09 15:22:07,171 [INFO] 	Process 5 - batch 41399: mean_policy_losses: -119.413, mean_net_lifetime: 5398.0537, mean_mc_travel_dist: 1990.1564, mean_rewards: 224.5740, total_rewards: 3435.9763, mean_steps: 25.5200, mean_ecr: 0.0408 mean_entropies: 1.3612, took: 130.4445s
2022-10-09 15:22:11,965 [INFO] 	Process 6 - batch 41599: mean_policy_losses: -159.470, mean_net_lifetime: 4353.4884, mean_mc_travel_dist: 1475.5163, mean_rewards: 237.5751, total_rewards: 2917.6752, mean_steps: 19.0300, mean_ecr: 0.0397 mean_entropies: 1.3832, took: 101.1750s
2022-10-09 15:22:21,301 [INFO] 	Process 4 - batch 41399: mean_policy_losses: -87.560, mean_net_lifetime: 4853.3409, mean_mc_travel_dist: 1683.8126, mean_rewards: 226.9971, total_rewards: 3200.1539, mean_steps: 21.7600, mean_ecr: 0.0403 mean_entropies: 1.3873, took: 114.3512s
2022-10-09 15:22:26,061 [INFO] 	Process 1 - batch 43199: mean_policy_losses: -101.043, mean_net_lifetime: 5591.9232, mean_mc_travel_dist: 2058.5781, mean_rewards: 234.1979, total_rewards: 3577.0954, mean_steps: 25.4100, mean_ecr: 0.0389 mean_entropies: 1.4843, took: 125.5310s
2022-10-09 15:22:58,304 [INFO] 	Process 3 - batch 41099: mean_policy_losses: -137.629, mean_net_lifetime: 4235.2409, mean_mc_travel_dist: 1389.8966, mean_rewards: 242.2892, total_rewards: 2879.1649, mean_steps: 18.8400, mean_ecr: 0.0407 mean_entropies: 1.4044, took: 98.4184s
2022-10-09 15:23:26,467 [INFO] 	Process 0 - batch 41499: mean_policy_losses: -110.098, mean_net_lifetime: 4332.3456, mean_mc_travel_dist: 1475.5248, mean_rewards: 226.3604, total_rewards: 2889.9895, mean_steps: 19.3500, mean_ecr: 0.0404 mean_entropies: 1.4018, took: 101.7247s
2022-10-09 15:23:40,694 [INFO] 	Process 2 - batch 41499: mean_policy_losses: -96.276, mean_net_lifetime: 4599.1925, mean_mc_travel_dist: 1558.1816, mean_rewards: 229.2399, total_rewards: 3076.8099, mean_steps: 20.0800, mean_ecr: 0.0399 mean_entropies: 1.4103, took: 104.9759s
2022-10-09 15:23:43,567 [INFO] 	Process 5 - batch 41499: mean_policy_losses: -106.244, mean_net_lifetime: 4201.5226, mean_mc_travel_dist: 1399.5872, mean_rewards: 236.0384, total_rewards: 2845.3084, mean_steps: 18.1400, mean_ecr: 0.0398 mean_entropies: 1.3858, took: 96.3957s
2022-10-09 15:24:08,717 [INFO] 	Process 1 - batch 43299: mean_policy_losses: -138.766, mean_net_lifetime: 4484.5730, mean_mc_travel_dist: 1560.9308, mean_rewards: 232.1252, total_rewards: 2958.9380, mean_steps: 20.4000, mean_ecr: 0.0377 mean_entropies: 1.4231, took: 102.6561s
2022-10-09 15:24:18,879 [INFO] 	Process 4 - batch 41499: mean_policy_losses: -73.444, mean_net_lifetime: 4989.3556, mean_mc_travel_dist: 1748.1320, mean_rewards: 225.7492, total_rewards: 3277.9907, mean_steps: 22.5900, mean_ecr: 0.0397 mean_entropies: 1.3986, took: 117.5777s
2022-10-09 15:24:19,822 [INFO] 	Process 6 - batch 41699: mean_policy_losses: -60.699, mean_net_lifetime: 5365.8446, mean_mc_travel_dist: 1907.4584, mean_rewards: 228.3077, total_rewards: 3498.3731, mean_steps: 24.6300, mean_ecr: 0.0388 mean_entropies: 1.4035, took: 127.8580s
2022-10-09 15:24:46,717 [INFO] 	Process 3 - batch 41199: mean_policy_losses: -94.814, mean_net_lifetime: 4663.7688, mean_mc_travel_dist: 1616.0604, mean_rewards: 228.9664, total_rewards: 3090.4996, mean_steps: 20.8600, mean_ecr: 0.0380 mean_entropies: 1.4579, took: 108.4125s
2022-10-09 15:25:05,316 [INFO] 	Process 0 - batch 41599: mean_policy_losses: -190.790, mean_net_lifetime: 4152.6393, mean_mc_travel_dist: 1407.4839, mean_rewards: 239.1862, total_rewards: 2781.0641, mean_steps: 18.4700, mean_ecr: 0.0394 mean_entropies: 1.4009, took: 98.8497s
2022-10-09 15:25:22,511 [INFO] 	Process 5 - batch 41599: mean_policy_losses: -115.379, mean_net_lifetime: 4210.9306, mean_mc_travel_dist: 1382.8121, mean_rewards: 236.3509, total_rewards: 2865.4272, mean_steps: 18.5300, mean_ecr: 0.0393 mean_entropies: 1.3912, took: 98.9445s
2022-10-09 15:25:25,103 [INFO] 	Process 2 - batch 41599: mean_policy_losses: -118.958, mean_net_lifetime: 4418.9517, mean_mc_travel_dist: 1476.8356, mean_rewards: 234.4775, total_rewards: 2978.3020, mean_steps: 19.8100, mean_ecr: 0.0394 mean_entropies: 1.3929, took: 104.4091s
2022-10-09 15:25:44,002 [INFO] 	Process 1 - batch 43399: mean_policy_losses: -83.223, mean_net_lifetime: 4222.6143, mean_mc_travel_dist: 1379.8765, mean_rewards: 232.9472, total_rewards: 2872.5014, mean_steps: 18.8300, mean_ecr: 0.0392 mean_entropies: 1.4238, took: 95.2844s
2022-10-09 15:26:03,533 [INFO] 	Process 4 - batch 41599: mean_policy_losses: -162.937, mean_net_lifetime: 4443.4195, mean_mc_travel_dist: 1546.3005, mean_rewards: 233.9492, total_rewards: 2924.8782, mean_steps: 19.8900, mean_ecr: 0.0391 mean_entropies: 1.4206, took: 104.6526s
2022-10-09 15:26:30,046 [INFO] 	Process 3 - batch 41299: mean_policy_losses: -134.188, mean_net_lifetime: 4293.8710, mean_mc_travel_dist: 1469.6274, mean_rewards: 227.7964, total_rewards: 2858.9685, mean_steps: 19.3700, mean_ecr: 0.0392 mean_entropies: 1.4364, took: 103.3280s
2022-10-09 15:26:33,374 [INFO] 	Process 6 - batch 41799: mean_policy_losses: -49.151, mean_net_lifetime: 5417.6865, mean_mc_travel_dist: 1948.1508, mean_rewards: 221.9065, total_rewards: 3511.8992, mean_steps: 26.1300, mean_ecr: 0.0398 mean_entropies: 1.4305, took: 133.5516s
2022-10-09 15:26:56,326 [INFO] 	Process 0 - batch 41699: mean_policy_losses: -87.765, mean_net_lifetime: 4672.3022, mean_mc_travel_dist: 1608.4281, mean_rewards: 232.8504, total_rewards: 3094.4715, mean_steps: 21.1000, mean_ecr: 0.0388 mean_entropies: 1.4346, took: 111.0103s
2022-10-09 15:27:17,671 [INFO] 	Process 2 - batch 41699: mean_policy_losses: -11.192, mean_net_lifetime: 4758.3190, mean_mc_travel_dist: 1639.9562, mean_rewards: 234.5637, total_rewards: 3152.4640, mean_steps: 21.2700, mean_ecr: 0.0389 mean_entropies: 1.4262, took: 112.5685s
2022-10-09 15:27:21,874 [INFO] 	Process 1 - batch 43499: mean_policy_losses: -117.067, mean_net_lifetime: 4377.7722, mean_mc_travel_dist: 1490.4818, mean_rewards: 236.7362, total_rewards: 2918.0505, mean_steps: 19.3000, mean_ecr: 0.0389 mean_entropies: 1.4815, took: 97.8725s
2022-10-09 15:27:22,460 [INFO] 	Process 5 - batch 41699: mean_policy_losses: 0.603, mean_net_lifetime: 5147.7745, mean_mc_travel_dist: 1807.5109, mean_rewards: 225.1330, total_rewards: 3377.2425, mean_steps: 23.3800, mean_ecr: 0.0389 mean_entropies: 1.4450, took: 119.9482s
2022-10-09 15:28:00,057 [INFO] 	Process 4 - batch 41699: mean_policy_losses: -59.334, mean_net_lifetime: 5068.0982, mean_mc_travel_dist: 1791.6011, mean_rewards: 233.5738, total_rewards: 3314.1444, mean_steps: 22.7300, mean_ecr: 0.0387 mean_entropies: 1.4159, took: 116.5254s
2022-10-09 15:28:06,368 [INFO] 	Process 3 - batch 41399: mean_policy_losses: -98.519, mean_net_lifetime: 4270.3504, mean_mc_travel_dist: 1455.2392, mean_rewards: 225.2430, total_rewards: 2853.3415, mean_steps: 19.1600, mean_ecr: 0.0408 mean_entropies: 1.3596, took: 96.3235s
2022-10-09 15:28:11,518 [INFO] 	Process 6 - batch 41899: mean_policy_losses: -140.479, mean_net_lifetime: 4298.4280, mean_mc_travel_dist: 1473.8397, mean_rewards: 233.8511, total_rewards: 2853.4817, mean_steps: 19.4000, mean_ecr: 0.0408 mean_entropies: 1.3833, took: 98.1440s
2022-10-09 15:28:57,049 [INFO] 	Process 0 - batch 41799: mean_policy_losses: -93.359, mean_net_lifetime: 5282.2216, mean_mc_travel_dist: 1918.3874, mean_rewards: 233.9985, total_rewards: 3398.6035, mean_steps: 24.5000, mean_ecr: 0.0397 mean_entropies: 1.4046, took: 120.7232s
2022-10-09 15:29:04,141 [INFO] 	Process 2 - batch 41799: mean_policy_losses: -140.139, mean_net_lifetime: 4517.7214, mean_mc_travel_dist: 1591.8535, mean_rewards: 227.8616, total_rewards: 2969.9526, mean_steps: 21.5100, mean_ecr: 0.0397 mean_entropies: 1.3717, took: 106.4700s
2022-10-09 15:29:08,437 [INFO] 	Process 5 - batch 41799: mean_policy_losses: -152.045, mean_net_lifetime: 4674.0848, mean_mc_travel_dist: 1630.5503, mean_rewards: 232.4448, total_rewards: 3084.7875, mean_steps: 21.4800, mean_ecr: 0.0401 mean_entropies: 1.3767, took: 105.9775s
2022-10-09 15:29:46,287 [INFO] 	Process 3 - batch 41499: mean_policy_losses: -123.431, mean_net_lifetime: 4555.3273, mean_mc_travel_dist: 1596.1430, mean_rewards: 230.6957, total_rewards: 2996.2609, mean_steps: 20.4200, mean_ecr: 0.0398 mean_entropies: 1.3918, took: 99.9194s
2022-10-09 15:29:56,657 [INFO] 	Process 4 - batch 41799: mean_policy_losses: -131.367, mean_net_lifetime: 5113.0528, mean_mc_travel_dist: 1837.9049, mean_rewards: 224.5469, total_rewards: 3317.9518, mean_steps: 24.0300, mean_ecr: 0.0395 mean_entropies: 1.3957, took: 116.6005s
2022-10-09 15:30:00,511 [INFO] 	Process 6 - batch 41999: mean_policy_losses: -73.203, mean_net_lifetime: 4729.5587, mean_mc_travel_dist: 1687.4513, mean_rewards: 220.9218, total_rewards: 3085.1653, mean_steps: 22.2100, mean_ecr: 0.0377 mean_entropies: 1.4000, took: 108.9924s
2022-10-09 15:30:39,219 [INFO] 	Process 2 - batch 41899: mean_policy_losses: -153.784, mean_net_lifetime: 4250.1081, mean_mc_travel_dist: 1473.2122, mean_rewards: 228.7182, total_rewards: 2814.3485, mean_steps: 19.2700, mean_ecr: 0.0409 mean_entropies: 1.3824, took: 95.0783s
2022-10-09 15:30:43,337 [INFO] 	Process 0 - batch 41899: mean_policy_losses: -93.619, mean_net_lifetime: 4791.2591, mean_mc_travel_dist: 1682.6042, mean_rewards: 235.4421, total_rewards: 3143.0443, mean_steps: 21.6000, mean_ecr: 0.0407 mean_entropies: 1.3933, took: 106.2872s
2022-10-09 15:30:52,033 [INFO] 	Process 5 - batch 41899: mean_policy_losses: -89.441, mean_net_lifetime: 4668.6635, mean_mc_travel_dist: 1618.4797, mean_rewards: 231.0990, total_rewards: 3089.5101, mean_steps: 21.2100, mean_ecr: 0.0407 mean_entropies: 1.4046, took: 103.5956s
2022-10-09 15:31:28,737 [INFO] 	Process 3 - batch 41599: mean_policy_losses: -42.945, mean_net_lifetime: 4837.6264, mean_mc_travel_dist: 1680.5291, mean_rewards: 232.1720, total_rewards: 3196.5474, mean_steps: 21.5600, mean_ecr: 0.0392 mean_entropies: 1.4215, took: 102.4476s
2022-10-09 15:31:43,257 [INFO] 	Process 4 - batch 41899: mean_policy_losses: -126.393, mean_net_lifetime: 4864.4405, mean_mc_travel_dist: 1723.6518, mean_rewards: 228.8249, total_rewards: 3174.6798, mean_steps: 22.3600, mean_ecr: 0.0409 mean_entropies: 1.4061, took: 106.5997s
2022-10-09 15:32:40,912 [INFO] 	Process 2 - batch 41999: mean_policy_losses: -29.580, mean_net_lifetime: 5429.4730, mean_mc_travel_dist: 1907.5778, mean_rewards: 228.0360, total_rewards: 3558.4922, mean_steps: 25.6800, mean_ecr: 0.0377 mean_entropies: 1.4064, took: 121.6939s
2022-10-09 15:32:46,824 [INFO] 	Process 0 - batch 41999: mean_policy_losses: -16.820, mean_net_lifetime: 5454.4925, mean_mc_travel_dist: 1956.3801, mean_rewards: 230.0568, total_rewards: 3534.5696, mean_steps: 25.9200, mean_ecr: 0.0378 mean_entropies: 1.4072, took: 123.4866s
2022-10-09 15:32:50,014 [INFO] 	Process 5 - batch 41999: mean_policy_losses: -50.609, mean_net_lifetime: 5204.7254, mean_mc_travel_dist: 1862.3488, mean_rewards: 221.9156, total_rewards: 3375.7059, mean_steps: 25.0700, mean_ecr: 0.0377 mean_entropies: 1.4014, took: 117.9823s
2022-10-09 15:33:14,136 [INFO] 	Process 3 - batch 41699: mean_policy_losses: -127.055, mean_net_lifetime: 4911.4101, mean_mc_travel_dist: 1759.0265, mean_rewards: 223.4375, total_rewards: 3184.8508, mean_steps: 22.9500, mean_ecr: 0.0387 mean_entropies: 1.4295, took: 105.4000s
2022-10-09 15:33:29,540 [INFO] 	Process 4 - batch 41999: mean_policy_losses: -83.921, mean_net_lifetime: 4938.9208, mean_mc_travel_dist: 1787.0182, mean_rewards: 223.1628, total_rewards: 3184.4921, mean_steps: 23.4900, mean_ecr: 0.0376 mean_entropies: 1.4022, took: 106.2828s
2022-10-09 15:34:49,459 [INFO] 	Process 3 - batch 41799: mean_policy_losses: -152.383, mean_net_lifetime: 5025.8385, mean_mc_travel_dist: 1740.2656, mean_rewards: 240.8057, total_rewards: 3327.3111, mean_steps: 22.5500, mean_ecr: 0.0397 mean_entropies: 1.4382, took: 95.3235s
2022-10-09 15:36:16,323 [INFO] 	Process 3 - batch 41899: mean_policy_losses: -168.919, mean_net_lifetime: 4543.7651, mean_mc_travel_dist: 1527.3225, mean_rewards: 236.5426, total_rewards: 3058.1004, mean_steps: 20.2200, mean_ecr: 0.0407 mean_entropies: 1.4042, took: 86.8637s
2022-10-09 15:38:08,718 [INFO] 	Process 3 - batch 41999: mean_policy_losses: -60.102, mean_net_lifetime: 5567.6940, mean_mc_travel_dist: 2025.2490, mean_rewards: 230.7064, total_rewards: 3572.1952, mean_steps: 26.3800, mean_ecr: 0.0376 mean_entropies: 1.4366, took: 112.3950s
2022-10-09 15:39:22,433 [INFO] 	Process 1 - batch 43599: mean_policy_losses: -132.643, mean_net_lifetime: 6414.1166, mean_mc_travel_dist: 2524.9912, mean_rewards: 236.1721, total_rewards: 3927.6861, mean_steps: 31.0800, mean_ecr: 0.0404 mean_entropies: 1.4002, took: 720.5594s
2022-10-09 15:40:57,483 [INFO] 	Process 1 - batch 43699: mean_policy_losses: -33.857, mean_net_lifetime: 5237.4459, mean_mc_travel_dist: 1818.5883, mean_rewards: 223.4930, total_rewards: 3451.5342, mean_steps: 23.7200, mean_ecr: 0.0390 mean_entropies: 1.4436, took: 95.0503s
2022-10-09 15:41:57,542 [INFO] 	Process 6 - batch 42099: mean_policy_losses: -75.850, mean_net_lifetime: 4381.0105, mean_mc_travel_dist: 1453.8530, mean_rewards: 234.0425, total_rewards: 2965.1042, mean_steps: 18.7400, mean_ecr: 0.0399 mean_entropies: 1.4247, took: 717.0306s
2022-10-09 15:43:06,908 [INFO] 	Process 1 - batch 43799: mean_policy_losses: -54.656, mean_net_lifetime: 6962.6148, mean_mc_travel_dist: 2680.9177, mean_rewards: 239.0040, total_rewards: 4322.6526, mean_steps: 32.0600, mean_ecr: 0.0380 mean_entropies: 1.4855, took: 129.4245s
2022-10-09 15:43:30,372 [INFO] 	Process 6 - batch 42199: mean_policy_losses: -80.273, mean_net_lifetime: 4895.0942, mean_mc_travel_dist: 1709.7378, mean_rewards: 243.6059, total_rewards: 3219.6029, mean_steps: 20.7800, mean_ecr: 0.0393 mean_entropies: 1.4911, took: 92.8292s
2022-10-09 15:44:47,197 [INFO] 	Process 1 - batch 43899: mean_policy_losses: -76.528, mean_net_lifetime: 4957.0602, mean_mc_travel_dist: 1729.3322, mean_rewards: 231.8664, total_rewards: 3256.9686, mean_steps: 22.6800, mean_ecr: 0.0391 mean_entropies: 1.4540, took: 100.2888s
2022-10-09 15:45:12,706 [INFO] 	Process 6 - batch 42299: mean_policy_losses: -96.151, mean_net_lifetime: 4740.3054, mean_mc_travel_dist: 1646.4258, mean_rewards: 234.6784, total_rewards: 3131.1239, mean_steps: 21.0500, mean_ecr: 0.0375 mean_entropies: 1.4617, took: 102.3355s
2022-10-09 15:45:42,150 [INFO] 	Process 4 - batch 42099: mean_policy_losses: -114.875, mean_net_lifetime: 4960.3491, mean_mc_travel_dist: 1734.9425, mean_rewards: 235.6344, total_rewards: 3259.3849, mean_steps: 22.3100, mean_ecr: 0.0399 mean_entropies: 1.4074, took: 732.6103s
2022-10-09 15:45:44,256 [INFO] 	Process 0 - batch 42099: mean_policy_losses: -164.446, mean_net_lifetime: 4651.2878, mean_mc_travel_dist: 1568.9778, mean_rewards: 238.2660, total_rewards: 3112.5548, mean_steps: 20.8200, mean_ecr: 0.0399 mean_entropies: 1.3937, took: 777.4318s
2022-10-09 15:45:45,261 [INFO] 	Process 5 - batch 42099: mean_policy_losses: -67.835, mean_net_lifetime: 5628.7656, mean_mc_travel_dist: 1990.7727, mean_rewards: 231.5932, total_rewards: 3673.6136, mean_steps: 26.1900, mean_ecr: 0.0396 mean_entropies: 1.4086, took: 775.2462s
2022-10-09 15:46:26,939 [INFO] 	Process 2 - batch 42099: mean_policy_losses: -77.298, mean_net_lifetime: 4357.0617, mean_mc_travel_dist: 1444.0074, mean_rewards: 239.4949, total_rewards: 2947.7967, mean_steps: 19.0400, mean_ecr: 0.0398 mean_entropies: 1.3933, took: 826.0252s
2022-10-09 15:46:28,116 [INFO] 	Process 1 - batch 43999: mean_policy_losses: -72.317, mean_net_lifetime: 4623.1992, mean_mc_travel_dist: 1597.1220, mean_rewards: 226.7857, total_rewards: 3064.2612, mean_steps: 20.8900, mean_ecr: 0.0382 mean_entropies: 1.4360, took: 100.9189s
2022-10-09 15:46:56,653 [INFO] 	Process 6 - batch 42399: mean_policy_losses: -91.802, mean_net_lifetime: 4437.0177, mean_mc_travel_dist: 1517.7259, mean_rewards: 224.1349, total_rewards: 2958.1840, mean_steps: 19.9200, mean_ecr: 0.0389 mean_entropies: 1.3822, took: 103.9468s
2022-10-09 15:47:17,641 [INFO] 	Process 4 - batch 42199: mean_policy_losses: -113.693, mean_net_lifetime: 4237.9020, mean_mc_travel_dist: 1435.1346, mean_rewards: 236.1703, total_rewards: 2835.6847, mean_steps: 18.5600, mean_ecr: 0.0396 mean_entropies: 1.4159, took: 95.4910s
2022-10-09 15:47:19,703 [INFO] 	Process 0 - batch 42199: mean_policy_losses: -141.359, mean_net_lifetime: 4126.2489, mean_mc_travel_dist: 1419.0941, mean_rewards: 237.7956, total_rewards: 2748.0392, mean_steps: 18.0500, mean_ecr: 0.0393 mean_entropies: 1.4066, took: 95.4469s
2022-10-09 15:47:21,209 [INFO] 	Process 5 - batch 42199: mean_policy_losses: -97.690, mean_net_lifetime: 4285.0537, mean_mc_travel_dist: 1452.5884, mean_rewards: 239.3396, total_rewards: 2870.2856, mean_steps: 18.5800, mean_ecr: 0.0393 mean_entropies: 1.4121, took: 95.9484s
2022-10-09 15:48:19,608 [INFO] 	Process 1 - batch 44099: mean_policy_losses: -71.779, mean_net_lifetime: 5192.0869, mean_mc_travel_dist: 1862.2066, mean_rewards: 234.9711, total_rewards: 3372.4049, mean_steps: 23.1800, mean_ecr: 0.0392 mean_entropies: 1.4203, took: 111.4918s
2022-10-09 15:48:20,425 [INFO] 	Process 2 - batch 42199: mean_policy_losses: -133.831, mean_net_lifetime: 4815.8488, mean_mc_travel_dist: 1678.6878, mean_rewards: 228.7369, total_rewards: 3179.7927, mean_steps: 21.9600, mean_ecr: 0.0393 mean_entropies: 1.4162, took: 113.4867s
2022-10-09 15:49:07,762 [INFO] 	Process 0 - batch 42299: mean_policy_losses: -107.681, mean_net_lifetime: 4506.1754, mean_mc_travel_dist: 1557.3874, mean_rewards: 228.6257, total_rewards: 2985.9321, mean_steps: 20.8500, mean_ecr: 0.0381 mean_entropies: 1.3961, took: 108.0577s
2022-10-09 15:49:10,016 [INFO] 	Process 5 - batch 42299: mean_policy_losses: -64.348, mean_net_lifetime: 4753.1546, mean_mc_travel_dist: 1622.6627, mean_rewards: 230.1411, total_rewards: 3172.1937, mean_steps: 21.4600, mean_ecr: 0.0372 mean_entropies: 1.4104, took: 108.8068s
2022-10-09 15:49:11,935 [INFO] 	Process 4 - batch 42299: mean_policy_losses: -17.212, mean_net_lifetime: 4978.3102, mean_mc_travel_dist: 1710.9071, mean_rewards: 234.3027, total_rewards: 3300.9939, mean_steps: 22.7300, mean_ecr: 0.0372 mean_entropies: 1.3954, took: 114.2931s
2022-10-09 15:49:38,157 [INFO] 	Process 6 - batch 42499: mean_policy_losses: -215.395, mean_net_lifetime: 6539.2943, mean_mc_travel_dist: 2435.2677, mean_rewards: 239.8318, total_rewards: 4140.6382, mean_steps: 33.5300, mean_ecr: 0.0390 mean_entropies: 1.3907, took: 161.5040s
2022-10-09 15:50:04,237 [INFO] 	Process 1 - batch 44199: mean_policy_losses: -145.501, mean_net_lifetime: 4754.5734, mean_mc_travel_dist: 1582.5941, mean_rewards: 231.9943, total_rewards: 3207.0456, mean_steps: 21.6000, mean_ecr: 0.0392 mean_entropies: 1.3741, took: 104.6299s
2022-10-09 15:50:18,032 [INFO] 	Process 2 - batch 42299: mean_policy_losses: -94.615, mean_net_lifetime: 5007.6925, mean_mc_travel_dist: 1757.6661, mean_rewards: 227.8477, total_rewards: 3291.5747, mean_steps: 23.2400, mean_ecr: 0.0381 mean_entropies: 1.4222, took: 117.6061s
2022-10-09 15:51:19,575 [INFO] 	Process 0 - batch 42399: mean_policy_losses: -61.921, mean_net_lifetime: 5232.0956, mean_mc_travel_dist: 1867.2588, mean_rewards: 214.7946, total_rewards: 3400.4026, mean_steps: 25.6500, mean_ecr: 0.0387 mean_entropies: 1.4080, took: 131.8142s
2022-10-09 15:51:21,315 [INFO] 	Process 6 - batch 42599: mean_policy_losses: -136.707, mean_net_lifetime: 4314.7947, mean_mc_travel_dist: 1471.6136, mean_rewards: 229.2637, total_rewards: 2881.0722, mean_steps: 19.9400, mean_ecr: 0.0394 mean_entropies: 1.4364, took: 103.1568s
2022-10-09 15:51:21,881 [INFO] 	Process 4 - batch 42399: mean_policy_losses: -149.471, mean_net_lifetime: 5121.8119, mean_mc_travel_dist: 1912.7143, mean_rewards: 216.8978, total_rewards: 3248.0354, mean_steps: 25.9700, mean_ecr: 0.0389 mean_entropies: 1.3934, took: 129.9470s
2022-10-09 15:51:30,244 [INFO] 	Process 5 - batch 42399: mean_policy_losses: -65.990, mean_net_lifetime: 5667.5633, mean_mc_travel_dist: 2093.5800, mean_rewards: 219.5244, total_rewards: 3616.9789, mean_steps: 28.7600, mean_ecr: 0.0386 mean_entropies: 1.4100, took: 140.2283s
2022-10-09 15:51:48,565 [INFO] 	Process 1 - batch 44299: mean_policy_losses: -27.327, mean_net_lifetime: 4733.7267, mean_mc_travel_dist: 1570.9672, mean_rewards: 230.4101, total_rewards: 3204.4935, mean_steps: 21.3800, mean_ecr: 0.0399 mean_entropies: 1.4193, took: 104.3276s
2022-10-09 15:52:59,543 [INFO] 	Process 2 - batch 42399: mean_policy_losses: -92.843, mean_net_lifetime: 6017.7186, mean_mc_travel_dist: 2303.6176, mean_rewards: 219.8428, total_rewards: 3744.2447, mean_steps: 32.0300, mean_ecr: 0.0386 mean_entropies: 1.4083, took: 161.5117s
2022-10-09 15:53:09,083 [INFO] 	Process 3 - batch 42099: mean_policy_losses: -46.072, mean_net_lifetime: 4383.2081, mean_mc_travel_dist: 1424.8967, mean_rewards: 233.7225, total_rewards: 2998.6790, mean_steps: 19.3900, mean_ecr: 0.0394 mean_entropies: 1.3725, took: 900.3654s
2022-10-09 15:53:21,040 [INFO] 	Process 0 - batch 42499: mean_policy_losses: -153.021, mean_net_lifetime: 4985.3732, mean_mc_travel_dist: 1741.1644, mean_rewards: 232.4552, total_rewards: 3290.1548, mean_steps: 23.1400, mean_ecr: 0.0395 mean_entropies: 1.3826, took: 121.4666s
2022-10-09 15:53:41,020 [INFO] 	Process 5 - batch 42499: mean_policy_losses: -77.493, mean_net_lifetime: 5370.6407, mean_mc_travel_dist: 1911.6457, mean_rewards: 232.0773, total_rewards: 3490.6632, mean_steps: 25.2100, mean_ecr: 0.0392 mean_entropies: 1.3794, took: 130.7759s
2022-10-09 15:53:51,559 [INFO] 	Process 6 - batch 42699: mean_policy_losses: -172.132, mean_net_lifetime: 5994.5460, mean_mc_travel_dist: 2324.6917, mean_rewards: 229.6464, total_rewards: 3713.5616, mean_steps: 29.4100, mean_ecr: 0.0383 mean_entropies: 1.3952, took: 150.2447s
2022-10-09 15:54:02,606 [INFO] 	Process 4 - batch 42499: mean_policy_losses: -82.507, mean_net_lifetime: 6607.2232, mean_mc_travel_dist: 2425.1321, mean_rewards: 227.1607, total_rewards: 4222.5941, mean_steps: 32.0800, mean_ecr: 0.0391 mean_entropies: 1.3734, took: 160.7242s
2022-10-09 15:54:18,757 [INFO] 	Process 1 - batch 44399: mean_policy_losses: -78.721, mean_net_lifetime: 6273.2998, mean_mc_travel_dist: 2452.2644, mean_rewards: 222.9493, total_rewards: 3859.2343, mean_steps: 30.6700, mean_ecr: 0.0409 mean_entropies: 1.3912, took: 150.1918s
2022-10-09 15:55:22,044 [INFO] 	Process 0 - batch 42599: mean_policy_losses: -102.425, mean_net_lifetime: 4883.2498, mean_mc_travel_dist: 1685.0261, mean_rewards: 218.0667, total_rewards: 3236.6037, mean_steps: 23.2400, mean_ecr: 0.0386 mean_entropies: 1.4368, took: 121.0031s
2022-10-09 15:55:37,060 [INFO] 	Process 5 - batch 42599: mean_policy_losses: -126.471, mean_net_lifetime: 4680.0661, mean_mc_travel_dist: 1610.6986, mean_rewards: 223.0716, total_rewards: 3108.0401, mean_steps: 22.0800, mean_ecr: 0.0390 mean_entropies: 1.4168, took: 116.0397s
2022-10-09 15:55:42,193 [INFO] 	Process 3 - batch 42199: mean_policy_losses: -131.004, mean_net_lifetime: 6293.1215, mean_mc_travel_dist: 2366.0172, mean_rewards: 233.7141, total_rewards: 3957.0125, mean_steps: 30.0900, mean_ecr: 0.0390 mean_entropies: 1.4231, took: 153.1107s
2022-10-09 15:55:52,907 [INFO] 	Process 4 - batch 42599: mean_policy_losses: -99.954, mean_net_lifetime: 4486.0453, mean_mc_travel_dist: 1498.8199, mean_rewards: 223.4018, total_rewards: 3026.4140, mean_steps: 20.9000, mean_ecr: 0.0390 mean_entropies: 1.4281, took: 110.3014s
2022-10-09 15:55:54,430 [INFO] 	Process 2 - batch 42499: mean_policy_losses: -74.468, mean_net_lifetime: 6736.4450, mean_mc_travel_dist: 2523.3616, mean_rewards: 224.2307, total_rewards: 4252.1575, mean_steps: 34.2500, mean_ecr: 0.0393 mean_entropies: 1.3719, took: 174.8863s
2022-10-09 15:55:59,653 [INFO] 	Process 1 - batch 44499: mean_policy_losses: -181.247, mean_net_lifetime: 4464.5359, mean_mc_travel_dist: 1535.3825, mean_rewards: 231.3428, total_rewards: 2966.0273, mean_steps: 20.0400, mean_ecr: 0.0377 mean_entropies: 1.4794, took: 100.8962s
2022-10-09 15:56:22,788 [INFO] 	Process 6 - batch 42799: mean_policy_losses: -66.985, mean_net_lifetime: 5993.9452, mean_mc_travel_dist: 2193.9344, mean_rewards: 220.4015, total_rewards: 3837.4395, mean_steps: 29.2500, mean_ecr: 0.0385 mean_entropies: 1.4310, took: 151.2282s
2022-10-09 15:57:17,637 [INFO] 	Process 0 - batch 42699: mean_policy_losses: -111.029, mean_net_lifetime: 4875.1704, mean_mc_travel_dist: 1712.3868, mean_rewards: 229.5247, total_rewards: 3194.2057, mean_steps: 22.3000, mean_ecr: 0.0376 mean_entropies: 1.4123, took: 115.5926s
2022-10-09 15:57:29,816 [INFO] 	Process 5 - batch 42699: mean_policy_losses: -180.210, mean_net_lifetime: 4683.5314, mean_mc_travel_dist: 1662.1159, mean_rewards: 230.1228, total_rewards: 3056.7721, mean_steps: 21.4600, mean_ecr: 0.0381 mean_entropies: 1.4417, took: 112.7552s
2022-10-09 15:57:35,989 [INFO] 	Process 1 - batch 44599: mean_policy_losses: -84.247, mean_net_lifetime: 4444.9557, mean_mc_travel_dist: 1486.0738, mean_rewards: 240.1656, total_rewards: 2999.3408, mean_steps: 19.0700, mean_ecr: 0.0387 mean_entropies: 1.3823, took: 96.3352s
2022-10-09 15:57:44,346 [INFO] 	Process 3 - batch 42299: mean_policy_losses: -107.700, mean_net_lifetime: 5155.5718, mean_mc_travel_dist: 1810.4001, mean_rewards: 232.3550, total_rewards: 3377.9158, mean_steps: 23.6700, mean_ecr: 0.0376 mean_entropies: 1.4034, took: 122.1514s
2022-10-09 15:57:57,238 [INFO] 	Process 2 - batch 42599: mean_policy_losses: -100.301, mean_net_lifetime: 4891.7979, mean_mc_travel_dist: 1747.4602, mean_rewards: 227.6905, total_rewards: 3173.0939, mean_steps: 23.1100, mean_ecr: 0.0390 mean_entropies: 1.4243, took: 122.8090s
2022-10-09 15:58:00,474 [INFO] 	Process 4 - batch 42699: mean_policy_losses: -102.588, mean_net_lifetime: 5388.7084, mean_mc_travel_dist: 1998.7214, mean_rewards: 230.7618, total_rewards: 3441.4309, mean_steps: 25.0200, mean_ecr: 0.0381 mean_entropies: 1.4172, took: 127.5668s
2022-10-09 15:58:19,691 [INFO] 	Process 6 - batch 42899: mean_policy_losses: -110.883, mean_net_lifetime: 4694.2952, mean_mc_travel_dist: 1634.1895, mean_rewards: 227.9620, total_rewards: 3105.4539, mean_steps: 22.4300, mean_ecr: 0.0395 mean_entropies: 1.3136, took: 116.9046s
2022-10-09 15:59:14,913 [INFO] 	Process 1 - batch 44699: mean_policy_losses: -52.262, mean_net_lifetime: 4521.4193, mean_mc_travel_dist: 1566.9941, mean_rewards: 238.3271, total_rewards: 2993.0210, mean_steps: 19.4900, mean_ecr: 0.0400 mean_entropies: 1.3922, took: 98.9244s
2022-10-09 15:59:34,502 [INFO] 	Process 0 - batch 42799: mean_policy_losses: -85.733, mean_net_lifetime: 5411.1457, mean_mc_travel_dist: 1940.1630, mean_rewards: 218.7789, total_rewards: 3507.7707, mean_steps: 26.4200, mean_ecr: 0.0387 mean_entropies: 1.4204, took: 136.8654s
2022-10-09 15:59:39,255 [INFO] 	Process 5 - batch 42799: mean_policy_losses: -20.507, mean_net_lifetime: 5182.6070, mean_mc_travel_dist: 1819.2298, mean_rewards: 224.5645, total_rewards: 3401.7713, mean_steps: 24.6900, mean_ecr: 0.0386 mean_entropies: 1.4148, took: 129.4398s
2022-10-09 15:59:53,287 [INFO] 	Process 3 - batch 42399: mean_policy_losses: -186.082, mean_net_lifetime: 4967.7901, mean_mc_travel_dist: 1813.5697, mean_rewards: 219.9861, total_rewards: 3190.7842, mean_steps: 25.0500, mean_ecr: 0.0388 mean_entropies: 1.3776, took: 128.9420s
2022-10-09 15:59:55,997 [INFO] 	Process 2 - batch 42699: mean_policy_losses: -181.906, mean_net_lifetime: 4944.0357, mean_mc_travel_dist: 1821.3223, mean_rewards: 228.9451, total_rewards: 3160.5043, mean_steps: 22.7500, mean_ecr: 0.0382 mean_entropies: 1.3643, took: 118.7595s
2022-10-09 16:00:06,555 [INFO] 	Process 4 - batch 42799: mean_policy_losses: -99.781, mean_net_lifetime: 5314.2214, mean_mc_travel_dist: 1902.2653, mean_rewards: 234.9501, total_rewards: 3445.9987, mean_steps: 24.4800, mean_ecr: 0.0385 mean_entropies: 1.4045, took: 126.0812s
2022-10-09 16:00:54,195 [INFO] 	Process 1 - batch 44799: mean_policy_losses: -87.560, mean_net_lifetime: 4526.9386, mean_mc_travel_dist: 1560.7067, mean_rewards: 233.4899, total_rewards: 3003.8905, mean_steps: 19.7400, mean_ecr: 0.0392 mean_entropies: 1.3819, took: 99.2824s
2022-10-09 16:01:04,585 [INFO] 	Process 6 - batch 42999: mean_policy_losses: -23.005, mean_net_lifetime: 6429.9170, mean_mc_travel_dist: 2463.3346, mean_rewards: 228.8401, total_rewards: 3998.3738, mean_steps: 32.2100, mean_ecr: 0.0388 mean_entropies: 1.3610, took: 164.8937s
2022-10-09 16:01:15,216 [INFO] 	Process 0 - batch 42899: mean_policy_losses: -77.377, mean_net_lifetime: 4166.0601, mean_mc_travel_dist: 1425.4809, mean_rewards: 228.6890, total_rewards: 2782.6722, mean_steps: 18.7800, mean_ecr: 0.0400 mean_entropies: 1.2973, took: 100.7145s
2022-10-09 16:01:28,082 [INFO] 	Process 5 - batch 42899: mean_policy_losses: -78.724, mean_net_lifetime: 4679.0835, mean_mc_travel_dist: 1606.4588, mean_rewards: 236.7630, total_rewards: 3104.9393, mean_steps: 20.9200, mean_ecr: 0.0394 mean_entropies: 1.2986, took: 108.8264s
2022-10-09 16:01:46,582 [INFO] 	Process 3 - batch 42499: mean_policy_losses: -117.851, mean_net_lifetime: 4758.4225, mean_mc_travel_dist: 1707.6896, mean_rewards: 232.9238, total_rewards: 3097.8251, mean_steps: 21.9600, mean_ecr: 0.0389 mean_entropies: 1.3257, took: 113.2945s
2022-10-09 16:01:48,274 [INFO] 	Process 4 - batch 42899: mean_policy_losses: -67.204, mean_net_lifetime: 4387.5819, mean_mc_travel_dist: 1495.0295, mean_rewards: 230.6994, total_rewards: 2925.5471, mean_steps: 19.4100, mean_ecr: 0.0396 mean_entropies: 1.2932, took: 101.7183s
2022-10-09 16:02:20,213 [INFO] 	Process 2 - batch 42799: mean_policy_losses: -78.163, mean_net_lifetime: 5764.0338, mean_mc_travel_dist: 2127.0565, mean_rewards: 220.9573, total_rewards: 3673.0971, mean_steps: 28.0100, mean_ecr: 0.0381 mean_entropies: 1.4107, took: 144.2157s
2022-10-09 16:02:44,834 [INFO] 	Process 1 - batch 44899: mean_policy_losses: -27.968, mean_net_lifetime: 4980.4319, mean_mc_travel_dist: 1721.4413, mean_rewards: 229.3419, total_rewards: 3300.9748, mean_steps: 22.3200, mean_ecr: 0.0393 mean_entropies: 1.4212, took: 110.6384s
2022-10-09 16:02:58,694 [INFO] 	Process 6 - batch 43099: mean_policy_losses: -99.084, mean_net_lifetime: 4853.2553, mean_mc_travel_dist: 1731.0006, mean_rewards: 232.9058, total_rewards: 3165.9335, mean_steps: 21.7600, mean_ecr: 0.0397 mean_entropies: 1.3874, took: 114.1091s
2022-10-09 16:03:31,792 [INFO] 	Process 3 - batch 42599: mean_policy_losses: -38.103, mean_net_lifetime: 4438.6391, mean_mc_travel_dist: 1487.9799, mean_rewards: 233.9662, total_rewards: 2989.0442, mean_steps: 19.4600, mean_ecr: 0.0388 mean_entropies: 1.4486, took: 105.2109s
2022-10-09 16:03:54,683 [INFO] 	Process 5 - batch 42999: mean_policy_losses: -119.058, mean_net_lifetime: 5762.9592, mean_mc_travel_dist: 2180.8450, mean_rewards: 236.4115, total_rewards: 3617.5354, mean_steps: 28.7300, mean_ecr: 0.0391 mean_entropies: 1.3552, took: 146.6017s
2022-10-09 16:03:56,590 [INFO] 	Process 0 - batch 42999: mean_policy_losses: -46.019, mean_net_lifetime: 6275.1000, mean_mc_travel_dist: 2394.4712, mean_rewards: 225.6141, total_rewards: 3918.6931, mean_steps: 31.8300, mean_ecr: 0.0391 mean_entropies: 1.3735, took: 161.3736s
2022-10-09 16:04:04,123 [INFO] 	Process 2 - batch 42899: mean_policy_losses: -122.798, mean_net_lifetime: 4381.3270, mean_mc_travel_dist: 1499.4300, mean_rewards: 236.5819, total_rewards: 2912.9164, mean_steps: 19.3900, mean_ecr: 0.0400 mean_entropies: 1.3284, took: 103.9104s
2022-10-09 16:04:18,957 [INFO] 	Process 4 - batch 42999: mean_policy_losses: -88.147, mean_net_lifetime: 5892.7311, mean_mc_travel_dist: 2249.2489, mean_rewards: 233.3605, total_rewards: 3670.2795, mean_steps: 29.2400, mean_ecr: 0.0390 mean_entropies: 1.3951, took: 150.6830s
2022-10-09 16:04:28,227 [INFO] 	Process 1 - batch 44999: mean_policy_losses: -39.839, mean_net_lifetime: 4713.0402, mean_mc_travel_dist: 1594.3252, mean_rewards: 237.3124, total_rewards: 3165.7244, mean_steps: 20.7500, mean_ecr: 0.0381 mean_entropies: 1.4290, took: 103.3932s
2022-10-09 16:04:58,696 [INFO] 	Process 6 - batch 43199: mean_policy_losses: -98.529, mean_net_lifetime: 5193.5968, mean_mc_travel_dist: 1872.3599, mean_rewards: 233.4209, total_rewards: 3359.7000, mean_steps: 23.1300, mean_ecr: 0.0390 mean_entropies: 1.5011, took: 120.0015s
2022-10-09 16:05:24,969 [INFO] 	Process 3 - batch 42699: mean_policy_losses: -153.001, mean_net_lifetime: 4904.9804, mean_mc_travel_dist: 1735.9402, mean_rewards: 228.2353, total_rewards: 3206.8179, mean_steps: 22.1100, mean_ecr: 0.0383 mean_entropies: 1.4217, took: 113.1772s
2022-10-09 16:05:36,829 [INFO] 	Process 5 - batch 43099: mean_policy_losses: -146.401, mean_net_lifetime: 4476.4659, mean_mc_travel_dist: 1560.0500, mean_rewards: 229.6237, total_rewards: 2947.6544, mean_steps: 20.0400, mean_ecr: 0.0404 mean_entropies: 1.4338, took: 102.1459s
2022-10-09 16:06:08,107 [INFO] 	Process 0 - batch 43099: mean_policy_losses: -38.288, mean_net_lifetime: 5486.3212, mean_mc_travel_dist: 1975.8542, mean_rewards: 231.1139, total_rewards: 3536.5286, mean_steps: 25.4900, mean_ecr: 0.0405 mean_entropies: 1.4182, took: 131.5160s
2022-10-09 16:06:09,588 [INFO] 	Process 4 - batch 43099: mean_policy_losses: -152.364, mean_net_lifetime: 4764.5098, mean_mc_travel_dist: 1705.0186, mean_rewards: 233.5836, total_rewards: 3102.4596, mean_steps: 21.6000, mean_ecr: 0.0399 mean_entropies: 1.4035, took: 110.6314s
2022-10-09 16:06:37,120 [INFO] 	Process 2 - batch 42999: mean_policy_losses: -110.245, mean_net_lifetime: 6317.8751, mean_mc_travel_dist: 2373.5661, mean_rewards: 234.0354, total_rewards: 3979.6775, mean_steps: 30.7600, mean_ecr: 0.0391 mean_entropies: 1.4322, took: 152.9962s
2022-10-09 16:06:59,100 [INFO] 	Process 6 - batch 43299: mean_policy_losses: -92.123, mean_net_lifetime: 5192.8411, mean_mc_travel_dist: 1818.0369, mean_rewards: 237.1853, total_rewards: 3410.4199, mean_steps: 23.6700, mean_ecr: 0.0378 mean_entropies: 1.4724, took: 120.4046s
2022-10-09 16:07:16,427 [INFO] 	Process 3 - batch 42799: mean_policy_losses: -88.109, mean_net_lifetime: 4790.7910, mean_mc_travel_dist: 1650.4966, mean_rewards: 222.8651, total_rewards: 3176.3953, mean_steps: 22.0400, mean_ecr: 0.0382 mean_entropies: 1.4538, took: 111.4559s
2022-10-09 16:07:34,201 [INFO] 	Process 5 - batch 43199: mean_policy_losses: -100.798, mean_net_lifetime: 5291.0350, mean_mc_travel_dist: 1931.1990, mean_rewards: 234.6977, total_rewards: 3397.8433, mean_steps: 23.5900, mean_ecr: 0.0390 mean_entropies: 1.4972, took: 117.3713s
2022-10-09 16:08:32,635 [INFO] 	Process 6 - batch 43399: mean_policy_losses: -60.992, mean_net_lifetime: 4207.0225, mean_mc_travel_dist: 1373.7629, mean_rewards: 237.8730, total_rewards: 2872.9872, mean_steps: 17.9600, mean_ecr: 0.0395 mean_entropies: 1.4803, took: 93.5352s
2022-10-09 16:08:53,568 [INFO] 	Process 2 - batch 43099: mean_policy_losses: -107.596, mean_net_lifetime: 5997.3115, mean_mc_travel_dist: 2200.9961, mean_rewards: 233.8010, total_rewards: 3837.5024, mean_steps: 27.7700, mean_ecr: 0.0400 mean_entropies: 1.4175, took: 136.4491s
2022-10-09 16:09:00,230 [INFO] 	Process 4 - batch 43199: mean_policy_losses: -121.051, mean_net_lifetime: 7074.6123, mean_mc_travel_dist: 2955.2755, mean_rewards: 235.3311, total_rewards: 4155.5756, mean_steps: 35.5300, mean_ecr: 0.0391 mean_entropies: 1.4978, took: 170.6422s
2022-10-09 16:09:03,920 [INFO] 	Process 3 - batch 42899: mean_policy_losses: -37.303, mean_net_lifetime: 4693.5969, mean_mc_travel_dist: 1605.0836, mean_rewards: 233.3441, total_rewards: 3123.1900, mean_steps: 20.8400, mean_ecr: 0.0399 mean_entropies: 1.3593, took: 107.4942s
2022-10-09 16:09:14,457 [INFO] 	Process 0 - batch 43199: mean_policy_losses: -157.451, mean_net_lifetime: 7532.2433, mean_mc_travel_dist: 3146.9577, mean_rewards: 235.3983, total_rewards: 4420.8455, mean_steps: 37.6900, mean_ecr: 0.0389 mean_entropies: 1.4953, took: 186.3505s
2022-10-09 16:09:30,987 [INFO] 	Process 5 - batch 43299: mean_policy_losses: -79.680, mean_net_lifetime: 5159.4259, mean_mc_travel_dist: 1821.5325, mean_rewards: 238.8695, total_rewards: 3369.1718, mean_steps: 23.2400, mean_ecr: 0.0378 mean_entropies: 1.4721, took: 116.7872s
2022-10-09 16:10:12,705 [INFO] 	Process 6 - batch 43499: mean_policy_losses: -172.742, mean_net_lifetime: 4463.4254, mean_mc_travel_dist: 1511.1958, mean_rewards: 236.1812, total_rewards: 2992.7603, mean_steps: 19.6500, mean_ecr: 0.0389 mean_entropies: 1.4488, took: 100.0702s
2022-10-09 16:10:57,115 [INFO] 	Process 4 - batch 43299: mean_policy_losses: -163.520, mean_net_lifetime: 5227.5301, mean_mc_travel_dist: 1890.2372, mean_rewards: 244.9195, total_rewards: 3379.7798, mean_steps: 23.4800, mean_ecr: 0.0377 mean_entropies: 1.4566, took: 116.8847s
2022-10-09 16:11:02,051 [INFO] 	Process 0 - batch 43299: mean_policy_losses: -112.156, mean_net_lifetime: 4818.9193, mean_mc_travel_dist: 1663.6343, mean_rewards: 243.5812, total_rewards: 3182.2441, mean_steps: 21.2200, mean_ecr: 0.0376 mean_entropies: 1.4370, took: 107.5943s
2022-10-09 16:11:05,547 [INFO] 	Process 5 - batch 43399: mean_policy_losses: -114.770, mean_net_lifetime: 4422.0443, mean_mc_travel_dist: 1451.8276, mean_rewards: 238.2431, total_rewards: 3002.8699, mean_steps: 18.8100, mean_ecr: 0.0393 mean_entropies: 1.4708, took: 94.5589s
2022-10-09 16:11:39,623 [INFO] 	Process 3 - batch 42999: mean_policy_losses: -65.822, mean_net_lifetime: 6450.6478, mean_mc_travel_dist: 2501.5441, mean_rewards: 225.5842, total_rewards: 3990.7856, mean_steps: 32.4900, mean_ecr: 0.0390 mean_entropies: 1.3858, took: 155.7031s
2022-10-09 16:11:45,633 [INFO] 	Process 2 - batch 43199: mean_policy_losses: -162.347, mean_net_lifetime: 7293.6183, mean_mc_travel_dist: 3056.3142, mean_rewards: 230.7903, total_rewards: 4268.1424, mean_steps: 35.9400, mean_ecr: 0.0389 mean_entropies: 1.4704, took: 172.0628s
2022-10-09 16:12:26,287 [INFO] 	Process 4 - batch 43399: mean_policy_losses: -132.477, mean_net_lifetime: 4141.2923, mean_mc_travel_dist: 1336.5682, mean_rewards: 239.0367, total_rewards: 2832.7870, mean_steps: 17.7000, mean_ecr: 0.0396 mean_entropies: 1.4472, took: 89.1720s
2022-10-09 16:12:37,483 [INFO] 	Process 5 - batch 43499: mean_policy_losses: -186.855, mean_net_lifetime: 4166.5900, mean_mc_travel_dist: 1396.4872, mean_rewards: 236.1829, total_rewards: 2807.9626, mean_steps: 18.2300, mean_ecr: 0.0392 mean_entropies: 1.4384, took: 91.9371s
2022-10-09 16:12:38,779 [INFO] 	Process 0 - batch 43399: mean_policy_losses: -85.493, mean_net_lifetime: 4469.9717, mean_mc_travel_dist: 1477.3870, mean_rewards: 236.7354, total_rewards: 3028.5656, mean_steps: 19.2900, mean_ecr: 0.0392 mean_entropies: 1.4561, took: 96.7275s
2022-10-09 16:13:28,701 [INFO] 	Process 3 - batch 43099: mean_policy_losses: -59.227, mean_net_lifetime: 5110.2820, mean_mc_travel_dist: 1822.1085, mean_rewards: 236.6060, total_rewards: 3332.5870, mean_steps: 22.4600, mean_ecr: 0.0401 mean_entropies: 1.4062, took: 109.0782s
2022-10-09 16:13:51,608 [INFO] 	Process 2 - batch 43299: mean_policy_losses: -78.599, mean_net_lifetime: 5710.9649, mean_mc_travel_dist: 2056.3666, mean_rewards: 233.5365, total_rewards: 3688.2736, mean_steps: 26.8600, mean_ecr: 0.0375 mean_entropies: 1.4528, took: 125.9733s
2022-10-09 16:13:59,512 [INFO] 	Process 4 - batch 43499: mean_policy_losses: -142.101, mean_net_lifetime: 4235.0279, mean_mc_travel_dist: 1422.5041, mean_rewards: 233.6860, total_rewards: 2841.7064, mean_steps: 19.1200, mean_ecr: 0.0391 mean_entropies: 1.4306, took: 93.2253s
2022-10-09 16:14:16,070 [INFO] 	Process 0 - batch 43499: mean_policy_losses: -171.508, mean_net_lifetime: 4453.5326, mean_mc_travel_dist: 1524.2835, mean_rewards: 235.9027, total_rewards: 2962.9238, mean_steps: 19.9100, mean_ecr: 0.0388 mean_entropies: 1.4191, took: 97.2918s
2022-10-09 16:15:14,287 [INFO] 	Process 3 - batch 43199: mean_policy_losses: -59.558, mean_net_lifetime: 5222.8639, mean_mc_travel_dist: 1887.3622, mean_rewards: 230.6475, total_rewards: 3384.0386, mean_steps: 23.6000, mean_ecr: 0.0387 mean_entropies: 1.4589, took: 105.5855s
2022-10-09 16:15:17,850 [INFO] 	Process 2 - batch 43399: mean_policy_losses: -122.802, mean_net_lifetime: 4331.5651, mean_mc_travel_dist: 1416.9814, mean_rewards: 237.3075, total_rewards: 2945.5854, mean_steps: 18.9300, mean_ecr: 0.0394 mean_entropies: 1.4261, took: 86.2445s
2022-10-09 16:16:40,461 [INFO] 	Process 2 - batch 43499: mean_policy_losses: -80.592, mean_net_lifetime: 4174.6191, mean_mc_travel_dist: 1432.2105, mean_rewards: 241.9472, total_rewards: 2780.3976, mean_steps: 18.1100, mean_ecr: 0.0385 mean_entropies: 1.4245, took: 82.6105s
2022-10-09 16:16:57,612 [INFO] 	Process 3 - batch 43299: mean_policy_losses: 8.459, mean_net_lifetime: 5134.2473, mean_mc_travel_dist: 1825.2248, mean_rewards: 239.3008, total_rewards: 3348.5641, mean_steps: 23.6500, mean_ecr: 0.0378 mean_entropies: 1.4269, took: 103.3246s
2022-10-09 16:18:02,882 [INFO] 	Process 1 - batch 45099: mean_policy_losses: -116.523, mean_net_lifetime: 4573.6149, mean_mc_travel_dist: 1615.1497, mean_rewards: 230.3896, total_rewards: 2995.0918, mean_steps: 21.8500, mean_ecr: 0.0395 mean_entropies: 1.3383, took: 814.6551s
2022-10-09 16:18:20,558 [INFO] 	Process 3 - batch 43399: mean_policy_losses: -105.829, mean_net_lifetime: 4169.4150, mean_mc_travel_dist: 1360.3789, mean_rewards: 236.9863, total_rewards: 2845.8203, mean_steps: 18.2600, mean_ecr: 0.0395 mean_entropies: 1.3818, took: 82.9475s
2022-10-09 16:19:30,935 [INFO] 	Process 1 - batch 45199: mean_policy_losses: -61.745, mean_net_lifetime: 4754.0154, mean_mc_travel_dist: 1636.0294, mean_rewards: 227.1898, total_rewards: 3153.7840, mean_steps: 21.3600, mean_ecr: 0.0377 mean_entropies: 1.4081, took: 88.0524s
2022-10-09 16:19:57,291 [INFO] 	Process 3 - batch 43499: mean_policy_losses: -164.837, mean_net_lifetime: 4753.4634, mean_mc_travel_dist: 1631.9186, mean_rewards: 231.2230, total_rewards: 3152.4197, mean_steps: 21.8100, mean_ecr: 0.0389 mean_entropies: 1.4194, took: 96.7323s
2022-10-09 16:20:54,567 [INFO] 	Process 1 - batch 45299: mean_policy_losses: -20.962, mean_net_lifetime: 4722.7062, mean_mc_travel_dist: 1593.9708, mean_rewards: 232.4154, total_rewards: 3170.1781, mean_steps: 20.6500, mean_ecr: 0.0389 mean_entropies: 1.4463, took: 83.6324s
2022-10-09 16:23:05,242 [INFO] 	Process 1 - batch 45399: mean_policy_losses: -42.733, mean_net_lifetime: 6643.1739, mean_mc_travel_dist: 2466.3210, mean_rewards: 232.1397, total_rewards: 4215.5862, mean_steps: 31.1100, mean_ecr: 0.0369 mean_entropies: 1.4607, took: 130.6746s
2022-10-09 16:23:13,196 [INFO] 	Process 6 - batch 43599: mean_policy_losses: -135.747, mean_net_lifetime: 6207.7080, mean_mc_travel_dist: 2351.4789, mean_rewards: 232.6535, total_rewards: 3885.5119, mean_steps: 29.5000, mean_ecr: 0.0402 mean_entropies: 1.3764, took: 780.4904s
2022-10-09 16:23:30,465 [INFO] 	Process 5 - batch 43599: mean_policy_losses: -91.580, mean_net_lifetime: 4669.7709, mean_mc_travel_dist: 1597.6436, mean_rewards: 232.7377, total_rewards: 3120.8235, mean_steps: 20.4600, mean_ecr: 0.0408 mean_entropies: 1.3621, took: 652.9811s
2022-10-09 16:24:29,806 [INFO] 	Process 1 - batch 45499: mean_policy_losses: -91.416, mean_net_lifetime: 4444.7166, mean_mc_travel_dist: 1494.3088, mean_rewards: 236.6493, total_rewards: 2988.1575, mean_steps: 19.4600, mean_ecr: 0.0377 mean_entropies: 1.4014, took: 84.5644s
2022-10-09 16:25:10,098 [INFO] 	Process 5 - batch 43699: mean_policy_losses: -94.852, mean_net_lifetime: 4540.9458, mean_mc_travel_dist: 1536.9749, mean_rewards: 221.0396, total_rewards: 3039.5769, mean_steps: 20.9800, mean_ecr: 0.0388 mean_entropies: 1.3698, took: 99.6330s
2022-10-09 16:25:11,314 [INFO] 	Process 6 - batch 43699: mean_policy_losses: -114.523, mean_net_lifetime: 5685.6875, mean_mc_travel_dist: 1957.9533, mean_rewards: 227.0647, total_rewards: 3754.7995, mean_steps: 26.1900, mean_ecr: 0.0383 mean_entropies: 1.3712, took: 118.1181s
2022-10-09 16:26:01,044 [INFO] 	Process 1 - batch 45599: mean_policy_losses: -72.313, mean_net_lifetime: 4426.3736, mean_mc_travel_dist: 1480.2437, mean_rewards: 231.6139, total_rewards: 2984.2483, mean_steps: 19.7500, mean_ecr: 0.0403 mean_entropies: 1.3527, took: 91.2386s
2022-10-09 16:26:43,853 [INFO] 	Process 0 - batch 43599: mean_policy_losses: -47.255, mean_net_lifetime: 4563.9615, mean_mc_travel_dist: 1557.3573, mean_rewards: 230.1097, total_rewards: 3049.0195, mean_steps: 20.2900, mean_ecr: 0.0405 mean_entropies: 1.3592, took: 747.7824s
2022-10-09 16:27:07,694 [INFO] 	Process 6 - batch 43799: mean_policy_losses: -173.263, mean_net_lifetime: 4931.8186, mean_mc_travel_dist: 1809.7530, mean_rewards: 227.6721, total_rewards: 3164.1369, mean_steps: 23.6200, mean_ecr: 0.0383 mean_entropies: 1.4058, took: 116.3798s
2022-10-09 16:27:23,873 [INFO] 	Process 5 - batch 43799: mean_policy_losses: -109.274, mean_net_lifetime: 5880.8718, mean_mc_travel_dist: 2218.4356, mean_rewards: 228.7169, total_rewards: 3700.2047, mean_steps: 27.8500, mean_ecr: 0.0384 mean_entropies: 1.4115, took: 133.7755s
2022-10-09 16:27:24,978 [INFO] 	Process 4 - batch 43599: mean_policy_losses: -67.782, mean_net_lifetime: 6490.9868, mean_mc_travel_dist: 2538.5120, mean_rewards: 229.7501, total_rewards: 3986.9881, mean_steps: 31.9800, mean_ecr: 0.0402 mean_entropies: 1.3407, took: 805.4660s
2022-10-09 16:27:38,487 [INFO] 	Process 1 - batch 45699: mean_policy_losses: -88.485, mean_net_lifetime: 4599.9031, mean_mc_travel_dist: 1599.8263, mean_rewards: 227.2775, total_rewards: 3033.4693, mean_steps: 20.7900, mean_ecr: 0.0391 mean_entropies: 1.3981, took: 97.4424s
2022-10-09 16:28:48,384 [INFO] 	Process 0 - batch 43699: mean_policy_losses: 0.615, mean_net_lifetime: 5371.9509, mean_mc_travel_dist: 1850.4106, mean_rewards: 221.9459, total_rewards: 3553.7210, mean_steps: 24.8800, mean_ecr: 0.0388 mean_entropies: 1.3826, took: 124.5315s
2022-10-09 16:29:23,653 [INFO] 	Process 6 - batch 43899: mean_policy_losses: -88.224, mean_net_lifetime: 5956.6824, mean_mc_travel_dist: 2146.9851, mean_rewards: 235.7804, total_rewards: 3844.8151, mean_steps: 27.8300, mean_ecr: 0.0389 mean_entropies: 1.3678, took: 135.9593s
2022-10-09 16:29:29,769 [INFO] 	Process 4 - batch 43699: mean_policy_losses: -28.746, mean_net_lifetime: 5430.7625, mean_mc_travel_dist: 1892.1623, mean_rewards: 228.5753, total_rewards: 3565.3481, mean_steps: 25.1600, mean_ecr: 0.0389 mean_entropies: 1.3785, took: 124.7908s
2022-10-09 16:29:33,320 [INFO] 	Process 5 - batch 43899: mean_policy_losses: -102.873, mean_net_lifetime: 5487.6260, mean_mc_travel_dist: 1937.1425, mean_rewards: 235.0731, total_rewards: 3584.9627, mean_steps: 26.0600, mean_ecr: 0.0387 mean_entropies: 1.3727, took: 129.4475s
2022-10-09 16:30:05,998 [INFO] 	Process 1 - batch 45799: mean_policy_losses: -61.275, mean_net_lifetime: 6651.3641, mean_mc_travel_dist: 2330.6111, mean_rewards: 235.9225, total_rewards: 4354.4963, mean_steps: 31.3900, mean_ecr: 0.0386 mean_entropies: 1.4142, took: 147.5114s
2022-10-09 16:30:38,397 [INFO] 	Process 2 - batch 43599: mean_policy_losses: -116.291, mean_net_lifetime: 5640.9246, mean_mc_travel_dist: 2029.0053, mean_rewards: 234.1611, total_rewards: 3642.6417, mean_steps: 26.9800, mean_ecr: 0.0407 mean_entropies: 1.3350, took: 837.9374s
2022-10-09 16:31:03,521 [INFO] 	Process 0 - batch 43799: mean_policy_losses: -162.884, mean_net_lifetime: 5536.9573, mean_mc_travel_dist: 2079.8524, mean_rewards: 223.7036, total_rewards: 3494.6616, mean_steps: 27.0400, mean_ecr: 0.0382 mean_entropies: 1.4345, took: 135.1373s
2022-10-09 16:31:07,934 [INFO] 	Process 6 - batch 43999: mean_policy_losses: -115.380, mean_net_lifetime: 4604.8344, mean_mc_travel_dist: 1585.0398, mean_rewards: 232.1984, total_rewards: 3049.4768, mean_steps: 20.6200, mean_ecr: 0.0385 mean_entropies: 1.4224, took: 104.2817s
2022-10-09 16:31:34,270 [INFO] 	Process 5 - batch 43999: mean_policy_losses: -44.615, mean_net_lifetime: 5130.4927, mean_mc_travel_dist: 1849.9520, mean_rewards: 225.0724, total_rewards: 3328.3593, mean_steps: 23.6800, mean_ecr: 0.0383 mean_entropies: 1.4240, took: 120.9494s
2022-10-09 16:31:41,134 [INFO] 	Process 1 - batch 45899: mean_policy_losses: -65.163, mean_net_lifetime: 4375.2908, mean_mc_travel_dist: 1477.6942, mean_rewards: 238.4828, total_rewards: 2932.7383, mean_steps: 19.1700, mean_ecr: 0.0399 mean_entropies: 1.3604, took: 95.1362s
2022-10-09 16:32:01,331 [INFO] 	Process 4 - batch 43799: mean_policy_losses: -121.779, mean_net_lifetime: 6626.0505, mean_mc_travel_dist: 2532.3838, mean_rewards: 236.7044, total_rewards: 4125.0101, mean_steps: 31.4900, mean_ecr: 0.0382 mean_entropies: 1.4203, took: 151.5622s
2022-10-09 16:32:42,190 [INFO] 	Process 2 - batch 43699: mean_policy_losses: -51.949, mean_net_lifetime: 5200.4947, mean_mc_travel_dist: 1793.0404, mean_rewards: 228.7323, total_rewards: 3442.8491, mean_steps: 23.2200, mean_ecr: 0.0390 mean_entropies: 1.3967, took: 123.7922s
2022-10-09 16:33:22,242 [INFO] 	Process 6 - batch 44099: mean_policy_losses: -79.858, mean_net_lifetime: 4754.8088, mean_mc_travel_dist: 1666.3362, mean_rewards: 231.5110, total_rewards: 3119.4156, mean_steps: 21.2000, mean_ecr: 0.0397 mean_entropies: 1.4103, took: 134.3068s
2022-10-09 16:33:32,158 [INFO] 	Process 0 - batch 43899: mean_policy_losses: -68.122, mean_net_lifetime: 4954.4269, mean_mc_travel_dist: 1736.9578, mean_rewards: 225.9652, total_rewards: 3251.5380, mean_steps: 23.0900, mean_ecr: 0.0389 mean_entropies: 1.4069, took: 148.6357s
2022-10-09 16:34:07,550 [INFO] 	Process 5 - batch 44099: mean_policy_losses: -102.171, mean_net_lifetime: 4523.4716, mean_mc_travel_dist: 1599.5161, mean_rewards: 225.4682, total_rewards: 2960.4855, mean_steps: 20.6000, mean_ecr: 0.0392 mean_entropies: 1.4173, took: 153.2808s
2022-10-09 16:34:18,590 [INFO] 	Process 1 - batch 45999: mean_policy_losses: -44.070, mean_net_lifetime: 4680.5304, mean_mc_travel_dist: 1627.6137, mean_rewards: 227.8817, total_rewards: 3091.2730, mean_steps: 21.0700, mean_ecr: 0.0396 mean_entropies: 1.4232, took: 157.4559s
2022-10-09 16:35:28,834 [INFO] 	Process 4 - batch 43899: mean_policy_losses: -74.999, mean_net_lifetime: 4946.9964, mean_mc_travel_dist: 1696.3801, mean_rewards: 230.5899, total_rewards: 3286.6965, mean_steps: 23.1600, mean_ecr: 0.0388 mean_entropies: 1.3646, took: 207.5017s
2022-10-09 16:37:02,100 [INFO] 	Process 6 - batch 44199: mean_policy_losses: -54.000, mean_net_lifetime: 4575.1843, mean_mc_travel_dist: 1520.3657, mean_rewards: 228.8413, total_rewards: 3085.6851, mean_steps: 20.2300, mean_ecr: 0.0391 mean_entropies: 1.4122, took: 219.8587s
2022-10-09 16:37:05,371 [INFO] 	Process 0 - batch 43999: mean_policy_losses: -130.792, mean_net_lifetime: 4464.2726, mean_mc_travel_dist: 1489.4105, mean_rewards: 235.8897, total_rewards: 3017.7579, mean_steps: 19.6100, mean_ecr: 0.0384 mean_entropies: 1.3921, took: 213.2148s
2022-10-09 16:37:43,859 [INFO] 	Process 2 - batch 43799: mean_policy_losses: -202.810, mean_net_lifetime: 5927.7272, mean_mc_travel_dist: 2270.0850, mean_rewards: 226.3545, total_rewards: 3696.4245, mean_steps: 28.8400, mean_ecr: 0.0381 mean_entropies: 1.4015, took: 301.6696s
2022-10-09 16:38:50,819 [INFO] 	Process 1 - batch 46099: mean_policy_losses: -123.536, mean_net_lifetime: 5724.1595, mean_mc_travel_dist: 2257.2571, mean_rewards: 237.7525, total_rewards: 3496.6395, mean_steps: 27.2600, mean_ecr: 0.0379 mean_entropies: 1.4053, took: 272.2291s
2022-10-09 16:38:58,328 [INFO] 	Process 5 - batch 44199: mean_policy_losses: -79.258, mean_net_lifetime: 6192.3181, mean_mc_travel_dist: 2075.3497, mean_rewards: 234.6129, total_rewards: 4151.9543, mean_steps: 28.7700, mean_ecr: 0.0393 mean_entropies: 1.3833, took: 290.7768s
2022-10-09 16:39:05,350 [INFO] 	Process 4 - batch 43999: mean_policy_losses: -58.824, mean_net_lifetime: 4837.5189, mean_mc_travel_dist: 1691.3698, mean_rewards: 229.6796, total_rewards: 3180.6936, mean_steps: 21.8300, mean_ecr: 0.0382 mean_entropies: 1.4156, took: 216.5168s
2022-10-09 16:39:29,283 [INFO] 	Process 6 - batch 44299: mean_policy_losses: -195.034, mean_net_lifetime: 3981.6705, mean_mc_travel_dist: 1316.1137, mean_rewards: 233.6136, total_rewards: 2701.3432, mean_steps: 17.5100, mean_ecr: 0.0403 mean_entropies: 1.3762, took: 147.1820s
2022-10-09 16:39:32,665 [INFO] 	Process 3 - batch 43599: mean_policy_losses: -59.477, mean_net_lifetime: 5164.2779, mean_mc_travel_dist: 1883.1990, mean_rewards: 235.8797, total_rewards: 3309.7532, mean_steps: 25.5100, mean_ecr: 0.0408 mean_entropies: 1.3063, took: 1175.3743s
2022-10-09 16:39:41,956 [INFO] 	Process 0 - batch 44099: mean_policy_losses: -46.701, mean_net_lifetime: 4616.8572, mean_mc_travel_dist: 1581.4623, mean_rewards: 239.4886, total_rewards: 3070.1764, mean_steps: 19.7600, mean_ecr: 0.0390 mean_entropies: 1.3952, took: 156.5832s
2022-10-09 16:40:21,227 [INFO] 	Process 2 - batch 43899: mean_policy_losses: -7.733, mean_net_lifetime: 5147.3621, mean_mc_travel_dist: 1789.2531, mean_rewards: 231.5042, total_rewards: 3392.2199, mean_steps: 23.7300, mean_ecr: 0.0387 mean_entropies: 1.4044, took: 157.3683s
2022-10-09 16:40:45,386 [INFO] 	Process 1 - batch 46199: mean_policy_losses: -133.299, mean_net_lifetime: 4877.7997, mean_mc_travel_dist: 1733.4978, mean_rewards: 224.1496, total_rewards: 3178.0820, mean_steps: 22.9300, mean_ecr: 0.0381 mean_entropies: 1.4020, took: 114.5662s
2022-10-09 16:40:46,593 [INFO] 	Process 5 - batch 44299: mean_policy_losses: -136.888, mean_net_lifetime: 4473.1917, mean_mc_travel_dist: 1532.5802, mean_rewards: 226.9340, total_rewards: 2988.3513, mean_steps: 20.4200, mean_ecr: 0.0398 mean_entropies: 1.3825, took: 108.2657s
2022-10-09 16:41:06,705 [INFO] 	Process 4 - batch 44099: mean_policy_losses: -8.024, mean_net_lifetime: 5119.0543, mean_mc_travel_dist: 1842.5824, mean_rewards: 232.1712, total_rewards: 3313.3787, mean_steps: 23.1700, mean_ecr: 0.0393 mean_entropies: 1.4104, took: 121.3557s
2022-10-09 16:41:30,172 [INFO] 	Process 3 - batch 43699: mean_policy_losses: -104.808, mean_net_lifetime: 4848.7163, mean_mc_travel_dist: 1701.1265, mean_rewards: 221.3130, total_rewards: 3194.3147, mean_steps: 22.4300, mean_ecr: 0.0391 mean_entropies: 1.3756, took: 117.5062s
2022-10-09 16:41:55,310 [INFO] 	Process 6 - batch 44399: mean_policy_losses: -48.243, mean_net_lifetime: 5628.6343, mean_mc_travel_dist: 2069.2932, mean_rewards: 232.6282, total_rewards: 3594.0738, mean_steps: 28.4000, mean_ecr: 0.0406 mean_entropies: 1.3693, took: 146.0280s
2022-10-09 16:42:11,715 [INFO] 	Process 0 - batch 44199: mean_policy_losses: -53.308, mean_net_lifetime: 5821.1750, mean_mc_travel_dist: 2007.9539, mean_rewards: 234.7172, total_rewards: 3855.4232, mean_steps: 26.8000, mean_ecr: 0.0392 mean_entropies: 1.3975, took: 149.7598s
2022-10-09 16:42:27,841 [INFO] 	Process 2 - batch 43999: mean_policy_losses: -46.196, mean_net_lifetime: 4558.9168, mean_mc_travel_dist: 1521.9845, mean_rewards: 233.6293, total_rewards: 3065.0401, mean_steps: 20.3300, mean_ecr: 0.0385 mean_entropies: 1.3899, took: 126.6139s
2022-10-09 16:43:17,580 [INFO] 	Process 1 - batch 46299: mean_policy_losses: -58.753, mean_net_lifetime: 4760.4925, mean_mc_travel_dist: 1653.0871, mean_rewards: 230.8651, total_rewards: 3143.4902, mean_steps: 21.4100, mean_ecr: 0.0397 mean_entropies: 1.3952, took: 152.1947s
2022-10-09 16:43:51,602 [INFO] 	Process 4 - batch 44199: mean_policy_losses: -52.029, mean_net_lifetime: 4526.3862, mean_mc_travel_dist: 1496.1220, mean_rewards: 240.5559, total_rewards: 3060.4881, mean_steps: 19.6200, mean_ecr: 0.0393 mean_entropies: 1.3756, took: 164.8966s
2022-10-09 16:44:54,507 [INFO] 	Process 5 - batch 44399: mean_policy_losses: -104.642, mean_net_lifetime: 5700.5972, mean_mc_travel_dist: 2200.7898, mean_rewards: 219.6873, total_rewards: 3544.1319, mean_steps: 29.8200, mean_ecr: 0.0407 mean_entropies: 1.4047, took: 247.9139s
2022-10-09 16:45:23,984 [INFO] 	Process 6 - batch 44499: mean_policy_losses: -227.944, mean_net_lifetime: 4199.9798, mean_mc_travel_dist: 1416.8795, mean_rewards: 233.3794, total_rewards: 2829.8892, mean_steps: 18.4000, mean_ecr: 0.0377 mean_entropies: 1.4087, took: 208.6723s
2022-10-09 16:45:59,464 [INFO] 	Process 0 - batch 44299: mean_policy_losses: -33.348, mean_net_lifetime: 4531.3874, mean_mc_travel_dist: 1506.7342, mean_rewards: 225.1806, total_rewards: 3061.8581, mean_steps: 20.2900, mean_ecr: 0.0398 mean_entropies: 1.4073, took: 227.7474s
2022-10-09 16:46:39,335 [INFO] 	Process 3 - batch 43799: mean_policy_losses: -132.699, mean_net_lifetime: 6467.9734, mean_mc_travel_dist: 2481.5388, mean_rewards: 225.0918, total_rewards: 4022.3079, mean_steps: 31.3100, mean_ecr: 0.0383 mean_entropies: 1.4190, took: 309.1638s
2022-10-09 16:47:07,439 [INFO] 	Process 2 - batch 44099: mean_policy_losses: -15.252, mean_net_lifetime: 5731.8933, mean_mc_travel_dist: 2077.6691, mean_rewards: 235.5280, total_rewards: 3690.2074, mean_steps: 25.6600, mean_ecr: 0.0394 mean_entropies: 1.4056, took: 279.5976s
2022-10-09 16:47:27,715 [INFO] 	Process 4 - batch 44299: mean_policy_losses: -184.855, mean_net_lifetime: 4339.0997, mean_mc_travel_dist: 1448.1408, mean_rewards: 233.8285, total_rewards: 2934.4121, mean_steps: 19.1200, mean_ecr: 0.0399 mean_entropies: 1.3905, took: 216.1133s
2022-10-09 16:47:31,237 [INFO] 	Process 1 - batch 46399: mean_policy_losses: -179.291, mean_net_lifetime: 5225.7514, mean_mc_travel_dist: 1883.6890, mean_rewards: 232.7579, total_rewards: 3379.5406, mean_steps: 23.8700, mean_ecr: 0.0397 mean_entropies: 1.4284, took: 253.6558s
2022-10-09 16:48:30,167 [INFO] 	Process 5 - batch 44499: mean_policy_losses: -107.413, mean_net_lifetime: 5173.9205, mean_mc_travel_dist: 1829.7074, mean_rewards: 236.2609, total_rewards: 3379.0039, mean_steps: 22.7000, mean_ecr: 0.0376 mean_entropies: 1.4238, took: 215.6594s

2022-08-08 20:51:12,501 [INFO] Running on device: cuda
2022-08-08 20:51:12,501 [INFO] Log dir: logs/test_08_08_2022_20_51_12
2022-08-08 20:51:12,502 [INFO] Running problem with 20 sensors 10 targets: (checkpoint: None, seed : 123, config: configs/test.yml)
2022-08-08 20:52:16,065 [INFO] 	Process 0 - batch 99: mean_policy_losses: 551.375, mean_net_lifetime: 2885.6172, mean_mc_travel_dist: 1901.7063, mean_rewards: 164.6324, total_rewards: 1068.0792, mean_steps: 16.5700, mean_ecr: 0.0419 mean_entropies: 2.9941, took: 41.0350s
2022-08-08 20:52:24,759 [INFO] 	Process 1 - batch 99: mean_policy_losses: 424.181, mean_net_lifetime: 3009.8530, mean_mc_travel_dist: 1984.9491, mean_rewards: 167.5203, total_rewards: 1105.6502, mean_steps: 16.7500, mean_ecr: 0.0416 mean_entropies: 2.9919, took: 46.2144s
2022-08-08 20:52:26,627 [INFO] 	Process 2 - batch 99: mean_policy_losses: 331.160, mean_net_lifetime: 3032.3581, mean_mc_travel_dist: 2011.8761, mean_rewards: 158.7833, total_rewards: 1091.3712, mean_steps: 17.6300, mean_ecr: 0.0413 mean_entropies: 2.9910, took: 44.0977s
2022-08-08 20:52:35,276 [INFO] 	Process 4 - batch 99: mean_policy_losses: 184.528, mean_net_lifetime: 3020.3385, mean_mc_travel_dist: 1957.7522, mean_rewards: 163.9034, total_rewards: 1136.9551, mean_steps: 17.2600, mean_ecr: 0.0413 mean_entropies: 2.9895, took: 43.5961s
2022-08-08 20:52:37,106 [INFO] 	Process 3 - batch 99: mean_policy_losses: 215.132, mean_net_lifetime: 2982.0134, mean_mc_travel_dist: 1945.6964, mean_rewards: 159.1850, total_rewards: 1101.5210, mean_steps: 17.4000, mean_ecr: 0.0417 mean_entropies: 2.9899, took: 49.6712s
2022-08-08 20:52:38,919 [INFO] 	Process 5 - batch 99: mean_policy_losses: 136.095, mean_net_lifetime: 2948.7757, mean_mc_travel_dist: 1923.2487, mean_rewards: 167.9463, total_rewards: 1083.7871, mean_steps: 16.5300, mean_ecr: 0.0414 mean_entropies: 2.9889, took: 42.8750s
2022-08-08 20:52:50,576 [INFO] 	Process 6 - batch 99: mean_policy_losses: 85.097, mean_net_lifetime: 3035.5377, mean_mc_travel_dist: 1964.2737, mean_rewards: 164.7943, total_rewards: 1141.5794, mean_steps: 17.2200, mean_ecr: 0.0412 mean_entropies: 2.9764, took: 50.0995s
2022-08-08 20:52:56,137 [INFO] 	Process 0 - batch 199: mean_policy_losses: 62.071, mean_net_lifetime: 3136.6807, mean_mc_travel_dist: 2049.3980, mean_rewards: 172.0191, total_rewards: 1157.8660, mean_steps: 17.5000, mean_ecr: 0.0399 mean_entropies: 2.9317, took: 40.0724s
2022-08-08 20:53:03,162 [INFO] 	Process 2 - batch 199: mean_policy_losses: -3.195, mean_net_lifetime: 2832.8344, mean_mc_travel_dist: 1888.8641, mean_rewards: 181.0579, total_rewards: 1026.5801, mean_steps: 15.4900, mean_ecr: 0.0402 mean_entropies: 2.7659, took: 36.5344s
2022-08-08 20:53:03,858 [INFO] 	Process 1 - batch 199: mean_policy_losses: 15.641, mean_net_lifetime: 2880.9767, mean_mc_travel_dist: 1899.8979, mean_rewards: 186.4309, total_rewards: 1071.4646, mean_steps: 15.1300, mean_ecr: 0.0398 mean_entropies: 2.7358, took: 39.1005s
2022-08-08 20:53:09,149 [INFO] 	Process 4 - batch 199: mean_policy_losses: 33.264, mean_net_lifetime: 2752.6406, mean_mc_travel_dist: 1729.9392, mean_rewards: 200.5345, total_rewards: 1121.1925, mean_steps: 13.6200, mean_ecr: 0.0398 mean_entropies: 2.4790, took: 33.8737s
2022-08-08 20:53:09,765 [INFO] 	Process 3 - batch 199: mean_policy_losses: 6.387, mean_net_lifetime: 2666.3209, mean_mc_travel_dist: 1713.4415, mean_rewards: 200.7235, total_rewards: 1034.4363, mean_steps: 13.2000, mean_ecr: 0.0399 mean_entropies: 2.3894, took: 32.6600s
2022-08-08 20:53:10,393 [INFO] 	Process 5 - batch 199: mean_policy_losses: 43.999, mean_net_lifetime: 2729.7298, mean_mc_travel_dist: 1715.5424, mean_rewards: 205.8642, total_rewards: 1115.2306, mean_steps: 12.9700, mean_ecr: 0.0398 mean_entropies: 2.3557, took: 31.4744s
2022-08-08 20:53:17,920 [INFO] 	Process 6 - batch 199: mean_policy_losses: -73.021, mean_net_lifetime: 2490.3159, mean_mc_travel_dist: 1503.1531, mean_rewards: 227.4679, total_rewards: 1095.6859, mean_steps: 10.7700, mean_ecr: 0.0398 mean_entropies: 1.8801, took: 27.3452s
2022-08-08 20:53:24,773 [INFO] 	Process 0 - batch 299: mean_policy_losses: -57.315, mean_net_lifetime: 2548.8164, mean_mc_travel_dist: 1466.8557, mean_rewards: 227.4898, total_rewards: 1205.2477, mean_steps: 10.5800, mean_ecr: 0.0395 mean_entropies: 1.6793, took: 28.6356s
2022-08-08 20:53:30,278 [INFO] 	Process 1 - batch 299: mean_policy_losses: -99.034, mean_net_lifetime: 2578.3078, mean_mc_travel_dist: 1394.3344, mean_rewards: 242.3723, total_rewards: 1297.0036, mean_steps: 10.1200, mean_ecr: 0.0395 mean_entropies: 1.4682, took: 26.4194s
2022-08-08 20:53:31,093 [INFO] 	Process 2 - batch 299: mean_policy_losses: -113.466, mean_net_lifetime: 2513.4011, mean_mc_travel_dist: 1376.2756, mean_rewards: 236.6799, total_rewards: 1250.4042, mean_steps: 10.1900, mean_ecr: 0.0394 mean_entropies: 1.4762, took: 27.9315s
2022-08-08 20:53:36,227 [INFO] 	Process 3 - batch 299: mean_policy_losses: -127.879, mean_net_lifetime: 2560.2702, mean_mc_travel_dist: 1371.3546, mean_rewards: 235.6463, total_rewards: 1291.8009, mean_steps: 10.2100, mean_ecr: 0.0392 mean_entropies: 1.3942, took: 26.4626s
2022-08-08 20:53:38,247 [INFO] 	Process 5 - batch 299: mean_policy_losses: -133.135, mean_net_lifetime: 2578.1873, mean_mc_travel_dist: 1394.7867, mean_rewards: 238.9729, total_rewards: 1292.2468, mean_steps: 10.5800, mean_ecr: 0.0394 mean_entropies: 1.3893, took: 27.8536s
2022-08-08 20:53:38,921 [INFO] 	Process 4 - batch 299: mean_policy_losses: -101.743, mean_net_lifetime: 2724.1126, mean_mc_travel_dist: 1464.0770, mean_rewards: 229.5351, total_rewards: 1362.3195, mean_steps: 11.5700, mean_ecr: 0.0390 mean_entropies: 1.4092, took: 29.7716s
2022-08-08 20:53:45,055 [INFO] 	Process 6 - batch 299: mean_policy_losses: -142.563, mean_net_lifetime: 2518.0365, mean_mc_travel_dist: 1332.8001, mean_rewards: 222.9332, total_rewards: 1297.0617, mean_steps: 10.7200, mean_ecr: 0.0395 mean_entropies: 1.3684, took: 27.1344s
2022-08-08 20:53:55,981 [INFO] 	Process 0 - batch 399: mean_policy_losses: -134.887, mean_net_lifetime: 2633.9742, mean_mc_travel_dist: 1413.8944, mean_rewards: 220.8228, total_rewards: 1334.1669, mean_steps: 11.5300, mean_ecr: 0.0391 mean_entropies: 1.3333, took: 31.2074s
2022-08-08 20:53:57,695 [INFO] 	Process 1 - batch 399: mean_policy_losses: -146.561, mean_net_lifetime: 2512.6035, mean_mc_travel_dist: 1319.5196, mean_rewards: 221.9802, total_rewards: 1289.6124, mean_steps: 10.8700, mean_ecr: 0.0392 mean_entropies: 1.3214, took: 27.4167s
2022-08-08 20:54:01,088 [INFO] 	Process 2 - batch 399: mean_policy_losses: -139.459, mean_net_lifetime: 2550.6137, mean_mc_travel_dist: 1335.0331, mean_rewards: 214.0961, total_rewards: 1311.7289, mean_steps: 11.2300, mean_ecr: 0.0392 mean_entropies: 1.3244, took: 29.9955s
2022-08-08 20:54:05,200 [INFO] 	Process 3 - batch 399: mean_policy_losses: -135.101, mean_net_lifetime: 2628.9442, mean_mc_travel_dist: 1380.6490, mean_rewards: 224.7221, total_rewards: 1363.0370, mean_steps: 11.3600, mean_ecr: 0.0388 mean_entropies: 1.2902, took: 28.9735s
2022-08-08 20:54:06,690 [INFO] 	Process 5 - batch 399: mean_policy_losses: -147.148, mean_net_lifetime: 2553.6418, mean_mc_travel_dist: 1324.0239, mean_rewards: 220.4724, total_rewards: 1331.8293, mean_steps: 10.9500, mean_ecr: 0.0393 mean_entropies: 1.3040, took: 28.4433s
2022-08-08 20:54:09,441 [INFO] 	Process 4 - batch 399: mean_policy_losses: -122.163, mean_net_lifetime: 2698.8891, mean_mc_travel_dist: 1396.1212, mean_rewards: 214.3976, total_rewards: 1403.0296, mean_steps: 12.2400, mean_ecr: 0.0393 mean_entropies: 1.2983, took: 30.5202s
2022-08-08 20:54:14,852 [INFO] 	Process 6 - batch 399: mean_policy_losses: -121.083, mean_net_lifetime: 2765.3447, mean_mc_travel_dist: 1431.7144, mean_rewards: 218.6604, total_rewards: 1428.8020, mean_steps: 12.1300, mean_ecr: 0.0392 mean_entropies: 1.2862, took: 29.7967s
2022-08-08 20:54:24,072 [INFO] 	Process 0 - batch 499: mean_policy_losses: -164.756, mean_net_lifetime: 2448.9375, mean_mc_travel_dist: 1221.0422, mean_rewards: 219.5797, total_rewards: 1320.5840, mean_steps: 10.6100, mean_ecr: 0.0423 mean_entropies: 1.2709, took: 28.0923s
2022-08-08 20:54:24,757 [INFO] 	Process 1 - batch 499: mean_policy_losses: -160.523, mean_net_lifetime: 2471.4835, mean_mc_travel_dist: 1258.6730, mean_rewards: 218.4921, total_rewards: 1306.7806, mean_steps: 10.6200, mean_ecr: 0.0424 mean_entropies: 1.2731, took: 27.0623s
2022-08-08 20:54:29,144 [INFO] 	Process 2 - batch 499: mean_policy_losses: -134.856, mean_net_lifetime: 2471.6637, mean_mc_travel_dist: 1239.7445, mean_rewards: 223.0609, total_rewards: 1328.9111, mean_steps: 10.5900, mean_ecr: 0.0422 mean_entropies: 1.2476, took: 28.0558s
2022-08-08 20:54:33,723 [INFO] 	Process 3 - batch 499: mean_policy_losses: -127.860, mean_net_lifetime: 2556.9468, mean_mc_travel_dist: 1287.9810, mean_rewards: 218.5777, total_rewards: 1369.4101, mean_steps: 11.4300, mean_ecr: 0.0424 mean_entropies: 1.2518, took: 28.5224s
2022-08-08 20:54:35,442 [INFO] 	Process 5 - batch 499: mean_policy_losses: -130.533, mean_net_lifetime: 2519.5226, mean_mc_travel_dist: 1270.2974, mean_rewards: 217.2818, total_rewards: 1341.5035, mean_steps: 11.1400, mean_ecr: 0.0420 mean_entropies: 1.2469, took: 28.7515s
2022-08-08 20:54:36,446 [INFO] 	Process 4 - batch 499: mean_policy_losses: -151.511, mean_net_lifetime: 2457.7858, mean_mc_travel_dist: 1253.9066, mean_rewards: 217.3658, total_rewards: 1296.9315, mean_steps: 10.7800, mean_ecr: 0.0419 mean_entropies: 1.2491, took: 27.0041s
2022-08-08 20:54:42,699 [INFO] 	Process 6 - batch 499: mean_policy_losses: -128.646, mean_net_lifetime: 2514.3202, mean_mc_travel_dist: 1273.6507, mean_rewards: 218.1380, total_rewards: 1343.0725, mean_steps: 11.0700, mean_ecr: 0.0422 mean_entropies: 1.2279, took: 27.8479s
2022-08-08 20:54:56,100 [INFO] 	Process 0 - batch 599: mean_policy_losses: -96.554, mean_net_lifetime: 2869.0474, mean_mc_travel_dist: 1475.6086, mean_rewards: 210.7699, total_rewards: 1489.2115, mean_steps: 13.5100, mean_ecr: 0.0398 mean_entropies: 1.2173, took: 32.0275s
2022-08-08 20:54:56,784 [INFO] 	Process 1 - batch 599: mean_policy_losses: -126.763, mean_net_lifetime: 2756.0656, mean_mc_travel_dist: 1415.4198, mean_rewards: 203.5859, total_rewards: 1420.7533, mean_steps: 13.4600, mean_ecr: 0.0400 mean_entropies: 1.2207, took: 32.0270s
2022-08-08 20:54:59,292 [INFO] 	Process 2 - batch 599: mean_policy_losses: -108.461, mean_net_lifetime: 2700.3240, mean_mc_travel_dist: 1368.4420, mean_rewards: 211.0999, total_rewards: 1421.7386, mean_steps: 12.5100, mean_ecr: 0.0398 mean_entropies: 1.2118, took: 30.1479s
2022-08-08 20:55:04,657 [INFO] 	Process 3 - batch 599: mean_policy_losses: -98.178, mean_net_lifetime: 2833.0666, mean_mc_travel_dist: 1450.9329, mean_rewards: 207.7783, total_rewards: 1473.9746, mean_steps: 13.1700, mean_ecr: 0.0400 mean_entropies: 1.2164, took: 30.9346s
2022-08-08 20:55:04,701 [INFO] 	Process 5 - batch 599: mean_policy_losses: -142.538, mean_net_lifetime: 2585.8983, mean_mc_travel_dist: 1334.9698, mean_rewards: 207.6804, total_rewards: 1340.5614, mean_steps: 12.1400, mean_ecr: 0.0402 mean_entropies: 1.2068, took: 29.2596s
2022-08-08 20:55:05,893 [INFO] 	Process 4 - batch 599: mean_policy_losses: -141.452, mean_net_lifetime: 2654.6694, mean_mc_travel_dist: 1358.6503, mean_rewards: 213.8558, total_rewards: 1391.6168, mean_steps: 12.3100, mean_ecr: 0.0402 mean_entropies: 1.2241, took: 29.4473s
2022-08-08 20:55:12,755 [INFO] 	Process 6 - batch 599: mean_policy_losses: -124.851, mean_net_lifetime: 2705.3374, mean_mc_travel_dist: 1367.7985, mean_rewards: 214.9479, total_rewards: 1417.5380, mean_steps: 12.5000, mean_ecr: 0.0403 mean_entropies: 1.2123, took: 30.0558s
2022-08-08 20:55:24,336 [INFO] 	Process 0 - batch 699: mean_policy_losses: -154.009, mean_net_lifetime: 2555.3611, mean_mc_travel_dist: 1303.3214, mean_rewards: 217.1143, total_rewards: 1342.8970, mean_steps: 11.6500, mean_ecr: 0.0388 mean_entropies: 1.1974, took: 28.2363s
2022-08-08 20:55:26,573 [INFO] 	Process 1 - batch 699: mean_policy_losses: -133.541, mean_net_lifetime: 2580.0439, mean_mc_travel_dist: 1306.8283, mean_rewards: 219.1766, total_rewards: 1378.4318, mean_steps: 11.9400, mean_ecr: 0.0392 mean_entropies: 1.1763, took: 29.7887s
2022-08-08 20:55:28,485 [INFO] 	Process 2 - batch 699: mean_policy_losses: -120.946, mean_net_lifetime: 2624.4745, mean_mc_travel_dist: 1329.4286, mean_rewards: 224.3128, total_rewards: 1395.3400, mean_steps: 11.9400, mean_ecr: 0.0392 mean_entropies: 1.1862, took: 29.1932s
2022-08-08 20:55:33,247 [INFO] 	Process 3 - batch 699: mean_policy_losses: -153.392, mean_net_lifetime: 2542.5722, mean_mc_travel_dist: 1273.5443, mean_rewards: 218.6356, total_rewards: 1355.1948, mean_steps: 11.6700, mean_ecr: 0.0390 mean_entropies: 1.1870, took: 28.5893s
2022-08-08 20:55:34,269 [INFO] 	Process 5 - batch 699: mean_policy_losses: -144.563, mean_net_lifetime: 2639.4630, mean_mc_travel_dist: 1356.4653, mean_rewards: 212.9525, total_rewards: 1370.4518, mean_steps: 12.3900, mean_ecr: 0.0388 mean_entropies: 1.1757, took: 29.5685s
2022-08-08 20:55:35,185 [INFO] 	Process 4 - batch 699: mean_policy_losses: -134.976, mean_net_lifetime: 2623.1180, mean_mc_travel_dist: 1327.1163, mean_rewards: 215.7133, total_rewards: 1386.5331, mean_steps: 12.2100, mean_ecr: 0.0392 mean_entropies: 1.1688, took: 29.2923s
2022-08-08 20:55:41,165 [INFO] 	Process 6 - batch 699: mean_policy_losses: -177.704, mean_net_lifetime: 2500.2488, mean_mc_travel_dist: 1273.6849, mean_rewards: 213.0162, total_rewards: 1308.6938, mean_steps: 11.8300, mean_ecr: 0.0391 mean_entropies: 1.1892, took: 28.4103s
2022-08-08 20:55:55,905 [INFO] 	Process 0 - batch 799: mean_policy_losses: -121.816, mean_net_lifetime: 2847.7500, mean_mc_travel_dist: 1455.3511, mean_rewards: 213.1123, total_rewards: 1486.6080, mean_steps: 13.0400, mean_ecr: 0.0380 mean_entropies: 1.1874, took: 31.5686s
2022-08-08 20:55:56,711 [INFO] 	Process 1 - batch 799: mean_policy_losses: -120.708, mean_net_lifetime: 2868.0986, mean_mc_travel_dist: 1481.0941, mean_rewards: 219.0813, total_rewards: 1474.8806, mean_steps: 12.7000, mean_ecr: 0.0380 mean_entropies: 1.1877, took: 30.1386s
2022-08-08 20:55:59,777 [INFO] 	Process 2 - batch 799: mean_policy_losses: -133.409, mean_net_lifetime: 2849.5695, mean_mc_travel_dist: 1471.8965, mean_rewards: 223.2316, total_rewards: 1464.4479, mean_steps: 12.8300, mean_ecr: 0.0381 mean_entropies: 1.1832, took: 31.2914s
2022-08-08 20:56:00,848 [INFO] 	Process 3 - batch 799: mean_policy_losses: -153.221, mean_net_lifetime: 2623.0409, mean_mc_travel_dist: 1349.2322, mean_rewards: 221.3501, total_rewards: 1365.4313, mean_steps: 11.5200, mean_ecr: 0.0380 mean_entropies: 1.1751, took: 27.6013s
2022-08-08 20:56:03,095 [INFO] 	Process 5 - batch 799: mean_policy_losses: -139.083, mean_net_lifetime: 2665.8773, mean_mc_travel_dist: 1353.9935, mean_rewards: 220.8272, total_rewards: 1409.9619, mean_steps: 11.7800, mean_ecr: 0.0380 mean_entropies: 1.1615, took: 28.8251s
2022-08-08 20:56:03,781 [INFO] 	Process 4 - batch 799: mean_policy_losses: -145.016, mean_net_lifetime: 2709.3374, mean_mc_travel_dist: 1389.8470, mean_rewards: 220.0940, total_rewards: 1405.4283, mean_steps: 11.9300, mean_ecr: 0.0377 mean_entropies: 1.1757, took: 28.5964s
2022-08-08 20:56:11,885 [INFO] 	Process 6 - batch 799: mean_policy_losses: -119.208, mean_net_lifetime: 2894.3285, mean_mc_travel_dist: 1466.6597, mean_rewards: 221.4082, total_rewards: 1513.9752, mean_steps: 12.6800, mean_ecr: 0.0380 mean_entropies: 1.1611, took: 30.7192s
2022-08-08 20:56:23,069 [INFO] 	Process 1 - batch 899: mean_policy_losses: -153.585, mean_net_lifetime: 2446.4183, mean_mc_travel_dist: 1181.8823, mean_rewards: 226.2792, total_rewards: 1342.4226, mean_steps: 10.3000, mean_ecr: 0.0397 mean_entropies: 1.1504, took: 26.3584s
2022-08-08 20:56:24,360 [INFO] 	Process 0 - batch 899: mean_policy_losses: -152.980, mean_net_lifetime: 2649.8665, mean_mc_travel_dist: 1323.2953, mean_rewards: 226.0755, total_rewards: 1424.1983, mean_steps: 11.5800, mean_ecr: 0.0394 mean_entropies: 1.1454, took: 28.4551s
2022-08-08 20:56:26,284 [INFO] 	Process 2 - batch 899: mean_policy_losses: -165.887, mean_net_lifetime: 2526.7008, mean_mc_travel_dist: 1265.5948, mean_rewards: 227.6388, total_rewards: 1364.0922, mean_steps: 10.7300, mean_ecr: 0.0399 mean_entropies: 1.1477, took: 26.5075s
2022-08-08 20:56:28,780 [INFO] 	Process 3 - batch 899: mean_policy_losses: -153.174, mean_net_lifetime: 2580.7417, mean_mc_travel_dist: 1267.4453, mean_rewards: 222.4423, total_rewards: 1405.3872, mean_steps: 11.3400, mean_ecr: 0.0394 mean_entropies: 1.1508, took: 27.9317s
2022-08-08 20:56:29,925 [INFO] 	Process 5 - batch 899: mean_policy_losses: -141.523, mean_net_lifetime: 2575.5046, mean_mc_travel_dist: 1256.1129, mean_rewards: 226.0771, total_rewards: 1417.0399, mean_steps: 10.8300, mean_ecr: 0.0398 mean_entropies: 1.1421, took: 26.8292s
2022-08-08 20:56:32,496 [INFO] 	Process 4 - batch 899: mean_policy_losses: -146.614, mean_net_lifetime: 2679.0731, mean_mc_travel_dist: 1339.9755, mean_rewards: 219.0312, total_rewards: 1422.8246, mean_steps: 11.9900, mean_ecr: 0.0399 mean_entropies: 1.1693, took: 28.7142s
2022-08-08 20:56:40,603 [INFO] 	Process 6 - batch 899: mean_policy_losses: -125.212, mean_net_lifetime: 2704.6077, mean_mc_travel_dist: 1341.8048, mean_rewards: 217.6807, total_rewards: 1448.9024, mean_steps: 11.9600, mean_ecr: 0.0395 mean_entropies: 1.1471, took: 28.7178s
2022-08-08 20:56:52,608 [INFO] 	Process 1 - batch 999: mean_policy_losses: -133.586, mean_net_lifetime: 2719.0112, mean_mc_travel_dist: 1401.2564, mean_rewards: 224.1274, total_rewards: 1401.2333, mean_steps: 12.0600, mean_ecr: 0.0400 mean_entropies: 1.1128, took: 29.5385s
2022-08-08 20:56:53,085 [INFO] 	Process 0 - batch 999: mean_policy_losses: -146.434, mean_net_lifetime: 2670.6751, mean_mc_travel_dist: 1408.7071, mean_rewards: 216.6033, total_rewards: 1367.1294, mean_steps: 11.7900, mean_ecr: 0.0401 mean_entropies: 1.1183, took: 28.7248s
2022-08-08 20:56:55,463 [INFO] 	Process 2 - batch 999: mean_policy_losses: -122.085, mean_net_lifetime: 2757.8991, mean_mc_travel_dist: 1419.9549, mean_rewards: 220.6910, total_rewards: 1418.4420, mean_steps: 12.0600, mean_ecr: 0.0399 mean_entropies: 1.1237, took: 29.1792s
2022-08-08 20:56:56,449 [INFO] 	Process 3 - batch 999: mean_policy_losses: -142.004, mean_net_lifetime: 2682.9627, mean_mc_travel_dist: 1406.5033, mean_rewards: 231.1882, total_rewards: 1378.7480, mean_steps: 11.2000, mean_ecr: 0.0401 mean_entropies: 1.1035, took: 27.6690s
2022-08-08 20:56:58,428 [INFO] 	Process 5 - batch 999: mean_policy_losses: -141.603, mean_net_lifetime: 2745.6217, mean_mc_travel_dist: 1432.0138, mean_rewards: 223.3591, total_rewards: 1404.3231, mean_steps: 11.7300, mean_ecr: 0.0399 mean_entropies: 1.1110, took: 28.5049s
2022-08-08 20:57:00,455 [INFO] 	Process 4 - batch 999: mean_policy_losses: -128.225, mean_net_lifetime: 2693.0248, mean_mc_travel_dist: 1369.8876, mean_rewards: 222.0807, total_rewards: 1416.0512, mean_steps: 11.5800, mean_ecr: 0.0398 mean_entropies: 1.1153, took: 27.9600s
2022-08-08 20:57:09,783 [INFO] 	Process 6 - batch 999: mean_policy_losses: -168.542, mean_net_lifetime: 2664.7008, mean_mc_travel_dist: 1367.9568, mean_rewards: 215.7768, total_rewards: 1385.5992, mean_steps: 11.8000, mean_ecr: 0.0402 mean_entropies: 1.1093, took: 29.1807s
2022-08-08 20:57:21,727 [INFO] 	Process 0 - batch 1099: mean_policy_losses: -152.099, mean_net_lifetime: 2830.8383, mean_mc_travel_dist: 1442.1627, mean_rewards: 235.8055, total_rewards: 1471.9886, mean_steps: 11.6200, mean_ecr: 0.0399 mean_entropies: 1.1135, took: 28.6424s
2022-08-08 20:57:22,372 [INFO] 	Process 1 - batch 1099: mean_policy_losses: -137.736, mean_net_lifetime: 2862.2957, mean_mc_travel_dist: 1440.1771, mean_rewards: 231.1354, total_rewards: 1516.1726, mean_steps: 12.0200, mean_ecr: 0.0399 mean_entropies: 1.1048, took: 29.7648s
2022-08-08 20:57:25,070 [INFO] 	Process 2 - batch 1099: mean_policy_losses: -152.329, mean_net_lifetime: 2864.2222, mean_mc_travel_dist: 1454.4858, mean_rewards: 228.8919, total_rewards: 1504.8788, mean_steps: 12.0700, mean_ecr: 0.0400 mean_entropies: 1.1253, took: 29.6073s
2022-08-08 20:57:25,128 [INFO] 	Process 3 - batch 1099: mean_policy_losses: -139.046, mean_net_lifetime: 2819.6473, mean_mc_travel_dist: 1405.3477, mean_rewards: 234.8682, total_rewards: 1504.2049, mean_steps: 11.5600, mean_ecr: 0.0400 mean_entropies: 1.1111, took: 28.6794s
2022-08-08 20:57:27,643 [INFO] 	Process 5 - batch 1099: mean_policy_losses: -161.467, mean_net_lifetime: 2782.9700, mean_mc_travel_dist: 1398.9221, mean_rewards: 228.5470, total_rewards: 1467.5554, mean_steps: 12.0100, mean_ecr: 0.0401 mean_entropies: 1.1131, took: 29.2148s
2022-08-08 20:57:30,158 [INFO] 	Process 4 - batch 1099: mean_policy_losses: -142.008, mean_net_lifetime: 2949.3957, mean_mc_travel_dist: 1492.4330, mean_rewards: 226.0541, total_rewards: 1550.7153, mean_steps: 12.6700, mean_ecr: 0.0396 mean_entropies: 1.1142, took: 29.7026s
2022-08-08 20:57:38,365 [INFO] 	Process 6 - batch 1099: mean_policy_losses: -166.561, mean_net_lifetime: 2727.5731, mean_mc_travel_dist: 1358.0515, mean_rewards: 224.3985, total_rewards: 1454.2417, mean_steps: 11.7600, mean_ecr: 0.0401 mean_entropies: 1.1012, took: 28.5822s
2022-08-08 20:57:49,428 [INFO] 	Process 0 - batch 1199: mean_policy_losses: -161.408, mean_net_lifetime: 2570.3472, mean_mc_travel_dist: 1295.4847, mean_rewards: 229.2574, total_rewards: 1362.1739, mean_steps: 11.0600, mean_ecr: 0.0408 mean_entropies: 1.0718, took: 27.7006s
2022-08-08 20:57:51,793 [INFO] 	Process 1 - batch 1199: mean_policy_losses: -128.046, mean_net_lifetime: 2765.7629, mean_mc_travel_dist: 1387.6110, mean_rewards: 229.7616, total_rewards: 1464.4761, mean_steps: 11.8900, mean_ecr: 0.0407 mean_entropies: 1.0447, took: 29.4200s
2022-08-08 20:57:53,178 [INFO] 	Process 3 - batch 1199: mean_policy_losses: -137.690, mean_net_lifetime: 2629.1449, mean_mc_travel_dist: 1318.6326, mean_rewards: 223.8792, total_rewards: 1390.9896, mean_steps: 11.6300, mean_ecr: 0.0410 mean_entropies: 1.0687, took: 28.0495s
2022-08-08 20:57:53,791 [INFO] 	Process 2 - batch 1199: mean_policy_losses: -141.002, mean_net_lifetime: 2640.4420, mean_mc_travel_dist: 1339.1828, mean_rewards: 222.9686, total_rewards: 1373.2151, mean_steps: 11.6300, mean_ecr: 0.0408 mean_entropies: 1.0598, took: 28.7207s
2022-08-08 20:57:54,913 [INFO] 	Process 5 - batch 1199: mean_policy_losses: -162.694, mean_net_lifetime: 2588.4171, mean_mc_travel_dist: 1310.8314, mean_rewards: 226.9892, total_rewards: 1354.4285, mean_steps: 11.2500, mean_ecr: 0.0407 mean_entropies: 1.0587, took: 27.2690s
2022-08-08 20:57:57,018 [INFO] 	Process 4 - batch 1199: mean_policy_losses: -128.070, mean_net_lifetime: 2556.0011, mean_mc_travel_dist: 1268.0578, mean_rewards: 225.3050, total_rewards: 1382.1408, mean_steps: 11.0800, mean_ecr: 0.0406 mean_entropies: 1.0347, took: 26.8601s
2022-08-08 20:58:07,343 [INFO] 	Process 6 - batch 1199: mean_policy_losses: -147.243, mean_net_lifetime: 2667.7174, mean_mc_travel_dist: 1343.4910, mean_rewards: 233.1008, total_rewards: 1416.5634, mean_steps: 11.2500, mean_ecr: 0.0402 mean_entropies: 1.0718, took: 28.9763s
2022-08-08 20:58:16,530 [INFO] 	Process 0 - batch 1299: mean_policy_losses: -149.689, mean_net_lifetime: 2718.0774, mean_mc_travel_dist: 1331.5747, mean_rewards: 242.5881, total_rewards: 1469.6031, mean_steps: 11.1300, mean_ecr: 0.0410 mean_entropies: 1.1263, took: 27.1024s
2022-08-08 20:58:21,442 [INFO] 	Process 2 - batch 1299: mean_policy_losses: -159.378, mean_net_lifetime: 2769.9468, mean_mc_travel_dist: 1362.1062, mean_rewards: 233.4965, total_rewards: 1491.0117, mean_steps: 11.5200, mean_ecr: 0.0409 mean_entropies: 1.1448, took: 27.6516s
2022-08-08 20:58:21,577 [INFO] 	Process 5 - batch 1299: mean_policy_losses: -178.320, mean_net_lifetime: 2685.6391, mean_mc_travel_dist: 1322.9348, mean_rewards: 235.3474, total_rewards: 1461.3724, mean_steps: 11.2000, mean_ecr: 0.0409 mean_entropies: 1.1297, took: 26.6642s
2022-08-08 20:58:23,730 [INFO] 	Process 4 - batch 1299: mean_policy_losses: -160.981, mean_net_lifetime: 2770.1755, mean_mc_travel_dist: 1344.6632, mean_rewards: 241.2128, total_rewards: 1508.3598, mean_steps: 11.1400, mean_ecr: 0.0409 mean_entropies: 1.1302, took: 26.7124s
2022-08-08 20:58:24,335 [INFO] 	Process 1 - batch 1299: mean_policy_losses: -150.943, mean_net_lifetime: 2785.9346, mean_mc_travel_dist: 1381.5612, mean_rewards: 232.1769, total_rewards: 1494.2922, mean_steps: 11.6200, mean_ecr: 0.0407 mean_entropies: 1.1454, took: 32.5421s
2022-08-08 20:58:24,741 [INFO] 	Process 3 - batch 1299: mean_policy_losses: -143.550, mean_net_lifetime: 2782.9044, mean_mc_travel_dist: 1365.1399, mean_rewards: 229.4112, total_rewards: 1522.4288, mean_steps: 11.6900, mean_ecr: 0.0406 mean_entropies: 1.1462, took: 31.5635s
2022-08-08 20:58:38,494 [INFO] 	Process 6 - batch 1299: mean_policy_losses: -176.453, mean_net_lifetime: 2844.9524, mean_mc_travel_dist: 1393.5669, mean_rewards: 236.6743, total_rewards: 1537.7389, mean_steps: 11.8600, mean_ecr: 0.0405 mean_entropies: 1.1395, took: 31.1528s
2022-08-08 20:58:46,522 [INFO] 	Process 0 - batch 1399: mean_policy_losses: -149.852, mean_net_lifetime: 3032.5404, mean_mc_travel_dist: 1518.5928, mean_rewards: 236.2667, total_rewards: 1594.6678, mean_steps: 12.6100, mean_ecr: 0.0393 mean_entropies: 1.1179, took: 29.9912s
2022-08-08 20:58:50,561 [INFO] 	Process 2 - batch 1399: mean_policy_losses: -148.825, mean_net_lifetime: 2985.8628, mean_mc_travel_dist: 1485.8084, mean_rewards: 241.6807, total_rewards: 1597.4937, mean_steps: 12.2500, mean_ecr: 0.0400 mean_entropies: 1.1091, took: 29.1182s
2022-08-08 20:58:50,814 [INFO] 	Process 5 - batch 1399: mean_policy_losses: -124.045, mean_net_lifetime: 3011.4506, mean_mc_travel_dist: 1464.4909, mean_rewards: 237.7115, total_rewards: 1636.4626, mean_steps: 12.3700, mean_ecr: 0.0398 mean_entropies: 1.0988, took: 29.2370s
2022-08-08 20:58:54,672 [INFO] 	Process 4 - batch 1399: mean_policy_losses: -125.148, mean_net_lifetime: 3141.1930, mean_mc_travel_dist: 1562.4776, mean_rewards: 228.7249, total_rewards: 1670.9299, mean_steps: 13.5900, mean_ecr: 0.0396 mean_entropies: 1.1129, took: 30.9409s
2022-08-08 20:59:00,022 [INFO] 	Process 3 - batch 1399: mean_policy_losses: -111.359, mean_net_lifetime: 3082.1806, mean_mc_travel_dist: 1524.8220, mean_rewards: 235.7192, total_rewards: 1642.1492, mean_steps: 12.8700, mean_ecr: 0.0400 mean_entropies: 1.1095, took: 35.2807s
2022-08-08 20:59:00,271 [INFO] 	Process 1 - batch 1399: mean_policy_losses: -124.215, mean_net_lifetime: 3083.9049, mean_mc_travel_dist: 1517.7705, mean_rewards: 231.7422, total_rewards: 1650.9540, mean_steps: 13.2200, mean_ecr: 0.0398 mean_entropies: 1.1161, took: 35.9355s
2022-08-08 20:59:13,926 [INFO] 	Process 6 - batch 1399: mean_policy_losses: -99.057, mean_net_lifetime: 3172.0134, mean_mc_travel_dist: 1556.9376, mean_rewards: 235.5067, total_rewards: 1708.0178, mean_steps: 13.2500, mean_ecr: 0.0395 mean_entropies: 1.0926, took: 35.4313s
2022-08-08 20:59:15,000 [INFO] 	Process 0 - batch 1499: mean_policy_losses: -141.696, mean_net_lifetime: 2898.5738, mean_mc_travel_dist: 1412.1876, mean_rewards: 241.3032, total_rewards: 1580.3776, mean_steps: 11.7600, mean_ecr: 0.0401 mean_entropies: 1.0806, took: 28.4781s
2022-08-08 20:59:19,000 [INFO] 	Process 5 - batch 1499: mean_policy_losses: -150.892, mean_net_lifetime: 2940.5338, mean_mc_travel_dist: 1442.3799, mean_rewards: 238.5832, total_rewards: 1576.0015, mean_steps: 12.0000, mean_ecr: 0.0402 mean_entropies: 1.0889, took: 28.1863s
2022-08-08 20:59:20,778 [INFO] 	Process 2 - batch 1499: mean_policy_losses: -111.880, mean_net_lifetime: 3095.2397, mean_mc_travel_dist: 1529.8072, mean_rewards: 231.1123, total_rewards: 1650.0500, mean_steps: 13.0000, mean_ecr: 0.0400 mean_entropies: 1.0970, took: 30.2168s
2022-08-08 20:59:22,536 [INFO] 	Process 4 - batch 1499: mean_policy_losses: -152.591, mean_net_lifetime: 2933.7136, mean_mc_travel_dist: 1434.1298, mean_rewards: 237.7723, total_rewards: 1587.9186, mean_steps: 11.9100, mean_ecr: 0.0400 mean_entropies: 1.0946, took: 27.8642s
2022-08-08 20:59:31,259 [INFO] 	Process 1 - batch 1499: mean_policy_losses: -163.501, mean_net_lifetime: 2897.9459, mean_mc_travel_dist: 1424.6693, mean_rewards: 238.0648, total_rewards: 1570.6562, mean_steps: 11.9900, mean_ecr: 0.0395 mean_entropies: 1.0877, took: 30.9886s
2022-08-08 20:59:31,387 [INFO] 	Process 3 - batch 1499: mean_policy_losses: -149.898, mean_net_lifetime: 2913.5995, mean_mc_travel_dist: 1429.2112, mean_rewards: 232.0777, total_rewards: 1571.6153, mean_steps: 12.2000, mean_ecr: 0.0402 mean_entropies: 1.1006, took: 31.3655s
2022-08-08 20:59:43,969 [INFO] 	Process 6 - batch 1499: mean_policy_losses: -155.091, mean_net_lifetime: 2933.2566, mean_mc_travel_dist: 1438.4682, mean_rewards: 232.9213, total_rewards: 1594.3979, mean_steps: 12.1200, mean_ecr: 0.0401 mean_entropies: 1.1071, took: 30.0431s
2022-08-08 21:01:53,466 [INFO] Process 5 - epoch 1: mean_policy_losses: -114.497, mean_net_lifetime: 2703.4155, mean_mc_travel_dist: 1420.0676, mean_entropies: 1.3714, m_net_lifetime_valid: 3077.8333, took: 597.4236s, (27.6848 / 100 batches)

2022-08-08 21:01:58,232 [INFO] Process 2 - epoch 1: mean_policy_losses: -94.934, mean_net_lifetime: 2747.7035, mean_mc_travel_dist: 1458.5667, mean_entropies: 1.4129, m_net_lifetime_valid: 3101.2269, took: 615.7047s, (28.6405 / 100 batches)

2022-08-08 21:02:00,464 [INFO] Process 4 - epoch 1: mean_policy_losses: -104.180, mean_net_lifetime: 2757.5645, mean_mc_travel_dist: 1445.9356, mean_entropies: 1.3843, m_net_lifetime_valid: 3079.7185, took: 608.7856s, (28.1785 / 100 batches)

2022-08-08 21:02:00,788 [INFO] Process 0 - epoch 1: mean_policy_losses: -78.003, mean_net_lifetime: 2753.1402, mean_mc_travel_dist: 1467.9455, mean_entropies: 1.4390, m_net_lifetime_valid: 3232.5627, took: 625.7596s, (28.7481 / 100 batches)

2022-08-08 21:02:21,056 [INFO] 	Process 5 - batch 1599: mean_policy_losses: -141.073, mean_net_lifetime: 2816.0831, mean_mc_travel_dist: 1361.7927, mean_rewards: 238.8772, total_rewards: 1538.8578, mean_steps: 11.4800, mean_ecr: 0.0396 mean_entropies: 1.0740, took: 182.0559s
2022-08-08 21:02:23,929 [INFO] Process 3 - epoch 1: mean_policy_losses: -103.389, mean_net_lifetime: 2725.6238, mean_mc_travel_dist: 1432.6622, mean_entropies: 1.3789, m_net_lifetime_valid: 3180.8798, took: 636.4970s, (28.9971 / 100 batches)

2022-08-08 21:02:26,569 [INFO] Process 1 - epoch 1: mean_policy_losses: -89.261, mean_net_lifetime: 2747.9137, mean_mc_travel_dist: 1453.0429, mean_entropies: 1.4091, m_net_lifetime_valid: 3336.8892, took: 648.0271s, (29.5447 / 100 batches)

2022-08-08 21:02:27,088 [INFO] 	Process 2 - batch 1599: mean_policy_losses: -151.660, mean_net_lifetime: 2883.4974, mean_mc_travel_dist: 1427.7911, mean_rewards: 243.3023, total_rewards: 1539.0853, mean_steps: 11.7500, mean_ecr: 0.0396 mean_entropies: 1.0702, took: 186.3109s
2022-08-08 21:02:27,790 [INFO] 	Process 4 - batch 1599: mean_policy_losses: -149.374, mean_net_lifetime: 2828.1437, mean_mc_travel_dist: 1383.8262, mean_rewards: 245.3344, total_rewards: 1536.4221, mean_steps: 11.2600, mean_ecr: 0.0397 mean_entropies: 1.0622, took: 185.2548s
2022-08-08 21:02:28,936 [INFO] 	Process 0 - batch 1599: mean_policy_losses: -171.668, mean_net_lifetime: 2791.4183, mean_mc_travel_dist: 1366.9308, mean_rewards: 239.3273, total_rewards: 1505.5922, mean_steps: 11.1000, mean_ecr: 0.0393 mean_entropies: 1.0835, took: 193.9363s
2022-08-08 21:02:39,209 [INFO] Process 6 - epoch 1: mean_policy_losses: -122.676, mean_net_lifetime: 2742.5527, mean_mc_travel_dist: 1427.6008, mean_entropies: 1.3380, m_net_lifetime_valid: 3240.7703, took: 638.7348s, (28.9683 / 100 batches)

2022-08-08 21:02:50,360 [INFO] 	Process 5 - batch 1699: mean_policy_losses: -143.412, mean_net_lifetime: 3080.6087, mean_mc_travel_dist: 1520.5854, mean_rewards: 250.4686, total_rewards: 1647.4054, mean_steps: 11.9100, mean_ecr: 0.0403 mean_entropies: 1.0646, took: 29.3043s
2022-08-08 21:02:56,459 [INFO] 	Process 2 - batch 1699: mean_policy_losses: -145.035, mean_net_lifetime: 3031.0206, mean_mc_travel_dist: 1494.2974, mean_rewards: 251.2686, total_rewards: 1627.3246, mean_steps: 11.5000, mean_ecr: 0.0402 mean_entropies: 1.0443, took: 29.3705s
2022-08-08 21:02:56,869 [INFO] 	Process 3 - batch 1599: mean_policy_losses: -158.314, mean_net_lifetime: 2893.9173, mean_mc_travel_dist: 1419.6910, mean_rewards: 241.7139, total_rewards: 1562.6651, mean_steps: 11.5600, mean_ecr: 0.0394 mean_entropies: 1.0521, took: 205.4822s
2022-08-08 21:02:57,366 [INFO] 	Process 4 - batch 1699: mean_policy_losses: -109.105, mean_net_lifetime: 3104.8360, mean_mc_travel_dist: 1529.2311, mean_rewards: 248.9507, total_rewards: 1683.7154, mean_steps: 11.9300, mean_ecr: 0.0400 mean_entropies: 1.0472, took: 29.5755s
2022-08-08 21:02:57,565 [INFO] 	Process 0 - batch 1699: mean_policy_losses: -161.699, mean_net_lifetime: 2941.5674, mean_mc_travel_dist: 1438.4263, mean_rewards: 250.7576, total_rewards: 1595.5447, mean_steps: 11.2800, mean_ecr: 0.0407 mean_entropies: 1.0537, took: 28.6293s
2022-08-08 21:02:58,375 [INFO] 	Process 1 - batch 1599: mean_policy_losses: -167.253, mean_net_lifetime: 2872.3599, mean_mc_travel_dist: 1415.6130, mean_rewards: 246.7112, total_rewards: 1561.5314, mean_steps: 11.3300, mean_ecr: 0.0393 mean_entropies: 1.0582, took: 207.1155s
2022-08-08 21:03:11,025 [INFO] 	Process 6 - batch 1599: mean_policy_losses: -199.834, mean_net_lifetime: 2902.2937, mean_mc_travel_dist: 1448.9383, mean_rewards: 242.3165, total_rewards: 1554.9000, mean_steps: 11.6900, mean_ecr: 0.0401 mean_entropies: 1.0368, took: 207.0562s
2022-08-08 21:03:20,011 [INFO] 	Process 5 - batch 1799: mean_policy_losses: -138.672, mean_net_lifetime: 2984.8113, mean_mc_travel_dist: 1420.4690, mean_rewards: 247.7537, total_rewards: 1659.5071, mean_steps: 11.6900, mean_ecr: 0.0401 mean_entropies: 1.0371, took: 29.6505s
2022-08-08 21:03:25,994 [INFO] 	Process 2 - batch 1799: mean_policy_losses: -189.536, mean_net_lifetime: 2842.6526, mean_mc_travel_dist: 1329.4053, mean_rewards: 264.6666, total_rewards: 1585.3865, mean_steps: 10.7100, mean_ecr: 0.0394 mean_entropies: 1.0240, took: 29.5343s
2022-08-08 21:03:27,808 [INFO] 	Process 3 - batch 1699: mean_policy_losses: -150.378, mean_net_lifetime: 3073.8794, mean_mc_travel_dist: 1516.2777, mean_rewards: 250.2436, total_rewards: 1641.7911, mean_steps: 11.7900, mean_ecr: 0.0400 mean_entropies: 1.0264, took: 30.9381s
2022-08-08 21:03:27,892 [INFO] 	Process 1 - batch 1699: mean_policy_losses: -151.436, mean_net_lifetime: 2881.6445, mean_mc_travel_dist: 1384.2179, mean_rewards: 246.8633, total_rewards: 1592.0924, mean_steps: 11.2700, mean_ecr: 0.0404 mean_entropies: 1.0124, took: 29.5180s
2022-08-08 21:03:28,025 [INFO] 	Process 0 - batch 1799: mean_policy_losses: -177.027, mean_net_lifetime: 2972.5881, mean_mc_travel_dist: 1400.0714, mean_rewards: 255.0527, total_rewards: 1650.9812, mean_steps: 11.3200, mean_ecr: 0.0394 mean_entropies: 1.0361, took: 30.4607s
2022-08-08 21:03:28,036 [INFO] 	Process 4 - batch 1799: mean_policy_losses: -164.907, mean_net_lifetime: 2950.1251, mean_mc_travel_dist: 1392.2018, mean_rewards: 259.7980, total_rewards: 1631.6064, mean_steps: 10.9600, mean_ecr: 0.0396 mean_entropies: 1.0290, took: 30.6700s
2022-08-08 21:03:39,911 [INFO] 	Process 6 - batch 1699: mean_policy_losses: -148.544, mean_net_lifetime: 3046.0737, mean_mc_travel_dist: 1466.3066, mean_rewards: 254.2495, total_rewards: 1658.7357, mean_steps: 11.5000, mean_ecr: 0.0395 mean_entropies: 0.9980, took: 28.8866s
2022-08-08 21:03:54,999 [INFO] 	Process 5 - batch 1899: mean_policy_losses: -148.701, mean_net_lifetime: 3249.0901, mean_mc_travel_dist: 1601.1836, mean_rewards: 249.5677, total_rewards: 1736.2606, mean_steps: 12.8600, mean_ecr: 0.0392 mean_entropies: 0.9935, took: 34.9882s
2022-08-08 21:03:56,937 [INFO] 	Process 3 - batch 1799: mean_policy_losses: -164.215, mean_net_lifetime: 2979.3075, mean_mc_travel_dist: 1408.9612, mean_rewards: 245.1624, total_rewards: 1647.6013, mean_steps: 11.7000, mean_ecr: 0.0396 mean_entropies: 0.9940, took: 29.1297s
2022-08-08 21:03:57,297 [INFO] 	Process 1 - batch 1799: mean_policy_losses: -140.065, mean_net_lifetime: 2927.1546, mean_mc_travel_dist: 1370.4491, mean_rewards: 254.1541, total_rewards: 1651.1152, mean_steps: 11.3000, mean_ecr: 0.0398 mean_entropies: 0.9816, took: 29.4041s
2022-08-08 21:04:00,218 [INFO] 	Process 2 - batch 1899: mean_policy_losses: -147.603, mean_net_lifetime: 3183.4117, mean_mc_travel_dist: 1564.9821, mean_rewards: 249.6142, total_rewards: 1703.2428, mean_steps: 12.5300, mean_ecr: 0.0394 mean_entropies: 0.9878, took: 34.2242s
2022-08-08 21:04:01,634 [INFO] 	Process 0 - batch 1899: mean_policy_losses: -144.087, mean_net_lifetime: 3128.4350, mean_mc_travel_dist: 1526.5577, mean_rewards: 248.7501, total_rewards: 1690.1383, mean_steps: 12.2200, mean_ecr: 0.0395 mean_entropies: 0.9761, took: 33.6076s
2022-08-08 21:04:06,444 [INFO] 	Process 4 - batch 1899: mean_policy_losses: -129.253, mean_net_lifetime: 3574.7225, mean_mc_travel_dist: 1808.4447, mean_rewards: 242.5269, total_rewards: 1865.5495, mean_steps: 14.3700, mean_ecr: 0.0393 mean_entropies: 0.9769, took: 38.4076s
2022-08-08 21:04:07,722 [INFO] 	Process 6 - batch 1799: mean_policy_losses: -186.095, mean_net_lifetime: 2848.7653, mean_mc_travel_dist: 1339.6551, mean_rewards: 256.9551, total_rewards: 1608.1931, mean_steps: 10.7200, mean_ecr: 0.0402 mean_entropies: 0.9515, took: 27.8099s
2022-08-08 21:04:27,232 [INFO] 	Process 5 - batch 1999: mean_policy_losses: -139.849, mean_net_lifetime: 3280.9748, mean_mc_travel_dist: 1564.1952, mean_rewards: 259.6270, total_rewards: 1794.9252, mean_steps: 12.3300, mean_ecr: 0.0398 mean_entropies: 0.9124, took: 32.2333s
2022-08-08 21:04:28,868 [INFO] 	Process 3 - batch 1899: mean_policy_losses: -121.503, mean_net_lifetime: 3373.5341, mean_mc_travel_dist: 1659.1300, mean_rewards: 255.7932, total_rewards: 1810.3890, mean_steps: 12.8900, mean_ecr: 0.0396 mean_entropies: 0.9288, took: 31.9302s
2022-08-08 21:04:28,949 [INFO] 	Process 1 - batch 1899: mean_policy_losses: -186.028, mean_net_lifetime: 3344.5707, mean_mc_travel_dist: 1661.5684, mean_rewards: 259.3026, total_rewards: 1783.9240, mean_steps: 12.6400, mean_ecr: 0.0392 mean_entropies: 0.9295, took: 31.6520s
2022-08-08 21:04:32,041 [INFO] 	Process 2 - batch 1999: mean_policy_losses: -145.708, mean_net_lifetime: 3124.0057, mean_mc_travel_dist: 1501.7636, mean_rewards: 255.7654, total_rewards: 1718.2303, mean_steps: 12.0300, mean_ecr: 0.0395 mean_entropies: 0.9092, took: 31.8242s
2022-08-08 21:04:33,901 [INFO] 	Process 0 - batch 1999: mean_policy_losses: -135.853, mean_net_lifetime: 3166.9889, mean_mc_travel_dist: 1527.9277, mean_rewards: 258.0803, total_rewards: 1734.1490, mean_steps: 11.9200, mean_ecr: 0.0396 mean_entropies: 0.9151, took: 32.2671s
2022-08-08 21:04:38,251 [INFO] 	Process 4 - batch 1999: mean_policy_losses: -115.751, mean_net_lifetime: 3291.5061, mean_mc_travel_dist: 1577.6705, mean_rewards: 263.8777, total_rewards: 1804.4577, mean_steps: 12.4100, mean_ecr: 0.0397 mean_entropies: 0.9026, took: 31.8072s
2022-08-08 21:04:40,461 [INFO] 	Process 6 - batch 1899: mean_policy_losses: -124.677, mean_net_lifetime: 3496.9017, mean_mc_travel_dist: 1756.3087, mean_rewards: 254.0016, total_rewards: 1838.6160, mean_steps: 13.4700, mean_ecr: 0.0384 mean_entropies: 0.9308, took: 32.7385s
2022-08-08 21:04:58,640 [INFO] 	Process 3 - batch 1999: mean_policy_losses: -117.273, mean_net_lifetime: 3245.0602, mean_mc_travel_dist: 1537.4542, mean_rewards: 262.3772, total_rewards: 1796.7039, mean_steps: 11.9600, mean_ecr: 0.0394 mean_entropies: 0.8774, took: 29.7728s
2022-08-08 21:04:59,358 [INFO] 	Process 5 - batch 2099: mean_policy_losses: -159.851, mean_net_lifetime: 3329.2083, mean_mc_travel_dist: 1586.5064, mean_rewards: 258.5079, total_rewards: 1828.5519, mean_steps: 12.5300, mean_ecr: 0.0395 mean_entropies: 0.9151, took: 32.1257s
2022-08-08 21:04:59,887 [INFO] 	Process 1 - batch 1999: mean_policy_losses: -108.224, mean_net_lifetime: 3322.3039, mean_mc_travel_dist: 1587.9224, mean_rewards: 261.2428, total_rewards: 1831.9667, mean_steps: 12.3600, mean_ecr: 0.0392 mean_entropies: 0.8890, took: 30.9382s

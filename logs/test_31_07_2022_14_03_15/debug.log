2022-07-31 14:03:15,903 [INFO] Process 1: Begin training phase
2022-07-31 14:03:21,487 [INFO] Process 1: Start epoch 0
2022-07-31 14:05:53,503 [INFO] 	Process 1: Batch 99/10000, mean_policy_losses: 350.580, mean_net_lifetime: 5885.6369, mean_mc_travel_dist: 9343.4145, mean_rewards: 69.5693, total_rewards: 4024.6059, mean_steps: 82.2300, mean_ecr: 0.0409 mean_entropies: 2.9605, took: 152.0103s
2022-07-31 14:08:53,913 [INFO] 	Process 1: Batch 199/10000, mean_policy_losses: -33.131, mean_net_lifetime: 6418.2197, mean_mc_travel_dist: 10451.9379, mean_rewards: 66.3176, total_rewards: 4331.4539, mean_steps: 97.2100, mean_ecr: 0.0411 mean_entropies: 2.9604, took: 180.4112s
2022-07-31 14:11:54,585 [INFO] 	Process 1: Batch 299/10000, mean_policy_losses: 18.594, mean_net_lifetime: 6290.0040, mean_mc_travel_dist: 9751.1585, mean_rewards: 66.0175, total_rewards: 4345.3810, mean_steps: 96.0600, mean_ecr: 0.0409 mean_entropies: 2.9290, took: 180.6708s
2022-07-31 14:16:11,985 [INFO] 	Process 1: Batch 399/10000, mean_policy_losses: 14.137, mean_net_lifetime: 8956.1668, mean_mc_travel_dist: 13356.5238, mean_rewards: 69.9269, total_rewards: 6289.6562, mean_steps: 135.7900, mean_ecr: 0.0411 mean_entropies: 2.8713, took: 257.3992s
2022-07-31 14:20:57,809 [INFO] 	Process 1: Batch 499/10000, mean_policy_losses: -19.473, mean_net_lifetime: 8982.4972, mean_mc_travel_dist: 14533.5083, mean_rewards: 66.1519, total_rewards: 6080.3500, mean_steps: 146.3800, mean_ecr: 0.0407 mean_entropies: 2.8305, took: 285.8248s
2022-07-31 14:23:41,050 [INFO] 	Process 1: Batch 599/10000, mean_policy_losses: -0.415, mean_net_lifetime: 5121.4123, mean_mc_travel_dist: 7943.0316, mean_rewards: 65.3481, total_rewards: 3536.5186, mean_steps: 82.9700, mean_ecr: 0.0418 mean_entropies: 2.7785, took: 163.2419s
2022-07-31 14:26:43,946 [INFO] 	Process 1: Batch 699/10000, mean_policy_losses: 1.360, mean_net_lifetime: 6259.7479, mean_mc_travel_dist: 9046.7474, mean_rewards: 70.2711, total_rewards: 4452.3351, mean_steps: 94.2500, mean_ecr: 0.0407 mean_entropies: 2.7670, took: 182.8959s
2022-07-31 14:31:25,430 [INFO] 	Process 1: Batch 799/10000, mean_policy_losses: 1.005, mean_net_lifetime: 10283.8474, mean_mc_travel_dist: 14444.5096, mean_rewards: 74.6900, total_rewards: 7400.1984, mean_steps: 148.6400, mean_ecr: 0.0386 mean_entropies: 2.7729, took: 281.4834s
2022-07-31 14:34:56,312 [INFO] 	Process 1: Batch 899/10000, mean_policy_losses: -25.405, mean_net_lifetime: 7626.6387, mean_mc_travel_dist: 10967.2587, mean_rewards: 72.6504, total_rewards: 5436.6546, mean_steps: 114.2800, mean_ecr: 0.0397 mean_entropies: 2.7232, took: 210.8822s
2022-07-31 14:38:37,881 [INFO] 	Process 1: Batch 999/10000, mean_policy_losses: 0.313, mean_net_lifetime: 7874.0157, mean_mc_travel_dist: 10762.6102, mean_rewards: 73.1999, total_rewards: 5722.2590, mean_steps: 117.1800, mean_ecr: 0.0391 mean_entropies: 2.7072, took: 221.5689s
2022-07-31 14:42:56,189 [INFO] 	Process 1: Batch 1099/10000, mean_policy_losses: 16.469, mean_net_lifetime: 9845.2565, mean_mc_travel_dist: 12735.7241, mean_rewards: 82.0512, total_rewards: 7299.7428, mean_steps: 135.8300, mean_ecr: 0.0413 mean_entropies: 2.6279, took: 258.3073s
2022-07-31 14:48:03,638 [INFO] 	Process 1: Batch 1199/10000, mean_policy_losses: -69.450, mean_net_lifetime: 10877.0547, mean_mc_travel_dist: 14507.3261, mean_rewards: 82.4988, total_rewards: 7977.9336, mean_steps: 157.3300, mean_ecr: 0.0397 mean_entropies: 2.6159, took: 307.4497s
2022-07-31 14:53:10,457 [INFO] 	Process 1: Batch 1299/10000, mean_policy_losses: -31.459, mean_net_lifetime: 11515.8065, mean_mc_travel_dist: 14425.0517, mean_rewards: 84.6478, total_rewards: 8632.0840, mean_steps: 159.6100, mean_ecr: 0.0395 mean_entropies: 2.5304, took: 306.8181s
2022-07-31 14:56:36,374 [INFO] 	Process 1: Batch 1399/10000, mean_policy_losses: -18.173, mean_net_lifetime: 7845.5204, mean_mc_travel_dist: 9710.5236, mean_rewards: 81.4259, total_rewards: 5903.7396, mean_steps: 108.4300, mean_ecr: 0.0398 mean_entropies: 2.4512, took: 205.9182s
2022-07-31 14:59:08,917 [INFO] 	Process 1: Batch 1499/10000, mean_policy_losses: -48.807, mean_net_lifetime: 6169.6278, mean_mc_travel_dist: 7263.3154, mean_rewards: 80.4510, total_rewards: 4717.6303, mean_steps: 80.3600, mean_ecr: 0.0404 mean_entropies: 2.3796, took: 152.5419s
2022-07-31 15:02:04,810 [INFO] 	Process 1: Batch 1599/10000, mean_policy_losses: -0.270, mean_net_lifetime: 7111.3160, mean_mc_travel_dist: 8331.9175, mean_rewards: 80.6871, total_rewards: 5446.0944, mean_steps: 93.1200, mean_ecr: 0.0396 mean_entropies: 2.3092, took: 175.8938s
2022-07-31 15:05:10,386 [INFO] 	Process 1: Batch 1699/10000, mean_policy_losses: -17.820, mean_net_lifetime: 7597.1338, mean_mc_travel_dist: 8949.6840, mean_rewards: 81.7155, total_rewards: 5808.5849, mean_steps: 99.2200, mean_ecr: 0.0401 mean_entropies: 2.2923, took: 185.5761s
2022-07-31 15:09:01,891 [INFO] 	Process 1: Batch 1799/10000, mean_policy_losses: -17.351, mean_net_lifetime: 8995.1968, mean_mc_travel_dist: 10817.9586, mean_rewards: 84.4800, total_rewards: 6832.4408, mean_steps: 120.9600, mean_ecr: 0.0393 mean_entropies: 2.2673, took: 231.5048s
2022-07-31 15:11:54,068 [INFO] 	Process 1: Batch 1899/10000, mean_policy_losses: -40.476, mean_net_lifetime: 6877.9282, mean_mc_travel_dist: 7792.4180, mean_rewards: 85.4407, total_rewards: 5319.7255, mean_steps: 86.9300, mean_ecr: 0.0413 mean_entropies: 2.2023, took: 172.1775s
2022-07-31 15:14:54,125 [INFO] 	Process 1: Batch 1999/10000, mean_policy_losses: -37.322, mean_net_lifetime: 7114.6676, mean_mc_travel_dist: 7871.3583, mean_rewards: 87.7988, total_rewards: 5540.9780, mean_steps: 92.1200, mean_ecr: 0.0415 mean_entropies: 2.1706, took: 180.0565s
2022-07-31 15:17:24,810 [INFO] 	Process 1: Batch 2099/10000, mean_policy_losses: -90.130, mean_net_lifetime: 6075.5954, mean_mc_travel_dist: 6781.6863, mean_rewards: 84.8344, total_rewards: 4720.5752, mean_steps: 76.1500, mean_ecr: 0.0410 mean_entropies: 2.1790, took: 150.6840s
2022-07-31 15:19:49,234 [INFO] 	Process 1: Batch 2199/10000, mean_policy_losses: -44.403, mean_net_lifetime: 6072.1321, mean_mc_travel_dist: 6571.5437, mean_rewards: 89.9264, total_rewards: 4758.6098, mean_steps: 72.6300, mean_ecr: 0.0417 mean_entropies: 2.0791, took: 144.4241s
2022-07-31 15:22:16,541 [INFO] 	Process 1: Batch 2299/10000, mean_policy_losses: -56.075, mean_net_lifetime: 6127.7401, mean_mc_travel_dist: 6887.0448, mean_rewards: 86.5885, total_rewards: 4750.8697, mean_steps: 75.1700, mean_ecr: 0.0401 mean_entropies: 2.1611, took: 147.3075s
2022-07-31 15:24:38,087 [INFO] 	Process 1: Batch 2399/10000, mean_policy_losses: -40.948, mean_net_lifetime: 5930.9971, mean_mc_travel_dist: 6634.2951, mean_rewards: 86.8345, total_rewards: 4605.0019, mean_steps: 73.9200, mean_ecr: 0.0412 mean_entropies: 2.1449, took: 141.5458s
2022-07-31 15:27:01,569 [INFO] 	Process 1: Batch 2499/10000, mean_policy_losses: -49.125, mean_net_lifetime: 6115.2880, mean_mc_travel_dist: 6681.0510, mean_rewards: 87.3466, total_rewards: 4780.0143, mean_steps: 75.3800, mean_ecr: 0.0411 mean_entropies: 2.0781, took: 143.4821s
2022-07-31 15:29:21,536 [INFO] 	Process 1: Batch 2599/10000, mean_policy_losses: -40.411, mean_net_lifetime: 6094.8085, mean_mc_travel_dist: 6701.1219, mean_rewards: 88.4914, total_rewards: 4754.8162, mean_steps: 74.1000, mean_ecr: 0.0409 mean_entropies: 2.1544, took: 139.9677s
2022-07-31 15:31:43,353 [INFO] 	Process 1: Batch 2699/10000, mean_policy_losses: -53.390, mean_net_lifetime: 6090.5654, mean_mc_travel_dist: 6701.4821, mean_rewards: 90.3368, total_rewards: 4750.8164, mean_steps: 73.9100, mean_ecr: 0.0405 mean_entropies: 2.1360, took: 141.8173s
2022-07-31 15:34:06,222 [INFO] 	Process 1: Batch 2799/10000, mean_policy_losses: -37.002, mean_net_lifetime: 6217.3745, mean_mc_travel_dist: 6694.9299, mean_rewards: 89.7515, total_rewards: 4878.3885, mean_steps: 74.2700, mean_ecr: 0.0400 mean_entropies: 2.0753, took: 142.8672s
2022-07-31 15:36:33,822 [INFO] 	Process 1: Batch 2899/10000, mean_policy_losses: -35.858, mean_net_lifetime: 6040.9429, mean_mc_travel_dist: 6752.2435, mean_rewards: 87.2916, total_rewards: 4690.9434, mean_steps: 75.5000, mean_ecr: 0.0398 mean_entropies: 2.0648, took: 147.6021s
2022-07-31 15:38:59,479 [INFO] 	Process 1: Batch 2999/10000, mean_policy_losses: -64.552, mean_net_lifetime: 6139.8116, mean_mc_travel_dist: 6775.8062, mean_rewards: 89.5838, total_rewards: 4784.9923, mean_steps: 74.1700, mean_ecr: 0.0397 mean_entropies: 2.0636, took: 145.6563s
2022-07-31 15:41:37,620 [INFO] 	Process 1: Batch 3099/10000, mean_policy_losses: -17.846, mean_net_lifetime: 6314.4638, mean_mc_travel_dist: 6904.1296, mean_rewards: 88.9258, total_rewards: 4934.2935, mean_steps: 77.7300, mean_ecr: 0.0395 mean_entropies: 2.0431, took: 158.1415s
2022-07-31 15:44:17,496 [INFO] 	Process 1: Batch 3199/10000, mean_policy_losses: -57.371, mean_net_lifetime: 6881.4849, mean_mc_travel_dist: 7415.0122, mean_rewards: 94.3872, total_rewards: 5399.0027, mean_steps: 81.6100, mean_ecr: 0.0397 mean_entropies: 2.0660, took: 159.8760s
2022-07-31 15:46:44,021 [INFO] 	Process 1: Batch 3299/10000, mean_policy_losses: -66.422, mean_net_lifetime: 6493.9066, mean_mc_travel_dist: 6536.6889, mean_rewards: 96.4479, total_rewards: 5187.2982, mean_steps: 72.0600, mean_ecr: 0.0410 mean_entropies: 1.9705, took: 146.5243s
2022-07-31 15:49:04,756 [INFO] 	Process 1: Batch 3399/10000, mean_policy_losses: -10.491, mean_net_lifetime: 6371.8961, mean_mc_travel_dist: 6332.6918, mean_rewards: 97.2980, total_rewards: 5105.9961, mean_steps: 70.5600, mean_ecr: 0.0412 mean_entropies: 1.9781, took: 140.7341s
2022-07-31 15:51:21,131 [INFO] 	Process 1: Batch 3499/10000, mean_policy_losses: -79.468, mean_net_lifetime: 6281.9383, mean_mc_travel_dist: 6345.7296, mean_rewards: 95.4415, total_rewards: 5013.6253, mean_steps: 70.0800, mean_ecr: 0.0416 mean_entropies: 1.9956, took: 136.3765s
2022-07-31 15:53:38,816 [INFO] 	Process 1: Batch 3599/10000, mean_policy_losses: -67.873, mean_net_lifetime: 6311.0440, mean_mc_travel_dist: 6560.7057, mean_rewards: 95.5037, total_rewards: 4999.3035, mean_steps: 72.7200, mean_ecr: 0.0400 mean_entropies: 1.9313, took: 137.6838s
2022-07-31 15:56:01,411 [INFO] 	Process 1: Batch 3699/10000, mean_policy_losses: -56.472, mean_net_lifetime: 6138.2116, mean_mc_travel_dist: 6519.5126, mean_rewards: 93.2661, total_rewards: 4834.5485, mean_steps: 73.0400, mean_ecr: 0.0406 mean_entropies: 1.9598, took: 142.5951s
2022-07-31 15:58:25,327 [INFO] 	Process 1: Batch 3799/10000, mean_policy_losses: -75.070, mean_net_lifetime: 6369.3608, mean_mc_travel_dist: 6477.8249, mean_rewards: 97.0009, total_rewards: 5074.3273, mean_steps: 72.5300, mean_ecr: 0.0404 mean_entropies: 1.9244, took: 143.9164s
2022-07-31 16:00:55,700 [INFO] 	Process 1: Batch 3899/10000, mean_policy_losses: -42.922, mean_net_lifetime: 6422.7497, mean_mc_travel_dist: 6907.9378, mean_rewards: 91.5638, total_rewards: 5041.6960, mean_steps: 76.3300, mean_ecr: 0.0386 mean_entropies: 1.9211, took: 150.3741s
2022-07-31 16:03:18,357 [INFO] 	Process 1: Batch 3999/10000, mean_policy_losses: -39.658, mean_net_lifetime: 6404.6243, mean_mc_travel_dist: 6266.0445, mean_rewards: 101.4211, total_rewards: 5151.9581, mean_steps: 68.1600, mean_ecr: 0.0416 mean_entropies: 1.8894, took: 142.6557s
2022-07-31 16:05:42,506 [INFO] 	Process 1: Batch 4099/10000, mean_policy_losses: -107.161, mean_net_lifetime: 6265.7005, mean_mc_travel_dist: 6324.3161, mean_rewards: 100.7459, total_rewards: 5001.6056, mean_steps: 68.9500, mean_ecr: 0.0415 mean_entropies: 1.8442, took: 144.1496s
2022-07-31 16:08:08,106 [INFO] 	Process 1: Batch 4199/10000, mean_policy_losses: -39.288, mean_net_lifetime: 6367.6519, mean_mc_travel_dist: 6425.0773, mean_rewards: 98.5604, total_rewards: 5083.4241, mean_steps: 70.2000, mean_ecr: 0.0409 mean_entropies: 1.9294, took: 145.5994s
2022-07-31 16:10:22,811 [INFO] 	Process 1: Batch 4299/10000, mean_policy_losses: -66.356, mean_net_lifetime: 6218.1465, mean_mc_travel_dist: 6294.3091, mean_rewards: 101.7313, total_rewards: 4960.3654, mean_steps: 68.1700, mean_ecr: 0.0410 mean_entropies: 1.8464, took: 134.7052s
2022-07-31 16:12:37,434 [INFO] 	Process 1: Batch 4399/10000, mean_policy_losses: -136.086, mean_net_lifetime: 6301.3972, mean_mc_travel_dist: 6480.4847, mean_rewards: 101.1839, total_rewards: 5006.3255, mean_steps: 69.4500, mean_ecr: 0.0405 mean_entropies: 1.8889, took: 134.6224s
2022-07-31 16:15:07,435 [INFO] 	Process 1: Batch 4499/10000, mean_policy_losses: -57.645, mean_net_lifetime: 6266.5311, mean_mc_travel_dist: 6611.0475, mean_rewards: 94.7555, total_rewards: 4944.6121, mean_steps: 72.8000, mean_ecr: 0.0394 mean_entropies: 1.8673, took: 150.0006s
2022-07-31 16:17:27,868 [INFO] 	Process 1: Batch 4599/10000, mean_policy_losses: -57.530, mean_net_lifetime: 6344.4495, mean_mc_travel_dist: 6418.8748, mean_rewards: 100.8082, total_rewards: 5060.9486, mean_steps: 70.0000, mean_ecr: 0.0410 mean_entropies: 1.8317, took: 140.4335s
2022-07-31 16:19:49,841 [INFO] 	Process 1: Batch 4699/10000, mean_policy_losses: -82.806, mean_net_lifetime: 6546.3664, mean_mc_travel_dist: 6397.1452, mean_rewards: 101.9709, total_rewards: 5267.6373, mean_steps: 68.6300, mean_ecr: 0.0407 mean_entropies: 1.8068, took: 141.9709s
2022-07-31 16:22:12,643 [INFO] 	Process 1: Batch 4799/10000, mean_policy_losses: -108.236, mean_net_lifetime: 6513.0490, mean_mc_travel_dist: 6624.3360, mean_rewards: 98.4604, total_rewards: 5189.4651, mean_steps: 71.1100, mean_ecr: 0.0394 mean_entropies: 1.8091, took: 142.8042s
2022-07-31 16:24:35,346 [INFO] 	Process 1: Batch 4899/10000, mean_policy_losses: -29.785, mean_net_lifetime: 6518.6116, mean_mc_travel_dist: 6300.4789, mean_rewards: 103.2513, total_rewards: 5259.0811, mean_steps: 67.7300, mean_ecr: 0.0412 mean_entropies: 1.7785, took: 142.7032s
2022-07-31 16:26:57,415 [INFO] 	Process 1: Batch 4999/10000, mean_policy_losses: 4.105, mean_net_lifetime: 6348.8796, mean_mc_travel_dist: 6687.0123, mean_rewards: 95.5990, total_rewards: 5012.3609, mean_steps: 73.1900, mean_ecr: 0.0389 mean_entropies: 1.7711, took: 142.0690s
2022-07-31 16:29:09,094 [INFO] 	Process 1: Batch 5099/10000, mean_policy_losses: -111.586, mean_net_lifetime: 6388.6489, mean_mc_travel_dist: 6438.2311, mean_rewards: 98.7033, total_rewards: 5101.2415, mean_steps: 70.3300, mean_ecr: 0.0402 mean_entropies: 1.7690, took: 131.6797s
2022-07-31 16:31:21,467 [INFO] 	Process 1: Batch 5199/10000, mean_policy_losses: -65.888, mean_net_lifetime: 6479.4944, mean_mc_travel_dist: 6282.9808, mean_rewards: 101.5647, total_rewards: 5223.4612, mean_steps: 68.5600, mean_ecr: 0.0407 mean_entropies: 1.7253, took: 132.3724s
2022-07-31 16:33:43,691 [INFO] 	Process 1: Batch 5299/10000, mean_policy_losses: -70.295, mean_net_lifetime: 6326.7537, mean_mc_travel_dist: 6301.3513, mean_rewards: 101.7542, total_rewards: 5066.9113, mean_steps: 69.4000, mean_ecr: 0.0409 mean_entropies: 1.7401, took: 142.2244s
2022-07-31 16:35:57,960 [INFO] 	Process 1: Batch 5399/10000, mean_policy_losses: -83.485, mean_net_lifetime: 6509.2868, mean_mc_travel_dist: 6266.1662, mean_rewards: 105.0788, total_rewards: 5256.0536, mean_steps: 67.1600, mean_ecr: 0.0412 mean_entropies: 1.7047, took: 134.2684s
2022-07-31 16:38:12,367 [INFO] 	Process 1: Batch 5499/10000, mean_policy_losses: -40.255, mean_net_lifetime: 6550.9119, mean_mc_travel_dist: 6230.8268, mean_rewards: 103.7360, total_rewards: 5305.4696, mean_steps: 68.7700, mean_ecr: 0.0410 mean_entropies: 1.6954, took: 134.4071s
2022-07-31 16:40:25,812 [INFO] 	Process 1: Batch 5599/10000, mean_policy_losses: -87.509, mean_net_lifetime: 6179.7583, mean_mc_travel_dist: 6293.5796, mean_rewards: 101.2188, total_rewards: 4921.8994, mean_steps: 68.1400, mean_ecr: 0.0406 mean_entropies: 1.7110, took: 133.4449s
2022-07-31 16:43:00,708 [INFO] 	Process 1: Batch 5699/10000, mean_policy_losses: -84.070, mean_net_lifetime: 6329.4223, mean_mc_travel_dist: 6712.9374, mean_rewards: 94.7515, total_rewards: 4987.2614, mean_steps: 73.9100, mean_ecr: 0.0386 mean_entropies: 1.7274, took: 154.8953s
2022-07-31 16:45:25,307 [INFO] 	Process 1: Batch 5799/10000, mean_policy_losses: -107.629, mean_net_lifetime: 6474.3561, mean_mc_travel_dist: 6546.0133, mean_rewards: 98.4484, total_rewards: 5165.5938, mean_steps: 71.8900, mean_ecr: 0.0395 mean_entropies: 1.6534, took: 144.5996s
2022-07-31 16:47:44,043 [INFO] 	Process 1: Batch 5899/10000, mean_policy_losses: -105.123, mean_net_lifetime: 6401.5576, mean_mc_travel_dist: 6508.8594, mean_rewards: 96.9901, total_rewards: 5100.1441, mean_steps: 72.7700, mean_ecr: 0.0397 mean_entropies: 1.6833, took: 138.7363s
2022-07-31 16:49:57,496 [INFO] 	Process 1: Batch 5999/10000, mean_policy_losses: -82.764, mean_net_lifetime: 6581.1886, mean_mc_travel_dist: 6338.4209, mean_rewards: 102.8139, total_rewards: 5313.9960, mean_steps: 69.8600, mean_ecr: 0.0408 mean_entropies: 1.6235, took: 133.4537s
2022-07-31 16:52:14,794 [INFO] 	Process 1: Batch 6099/10000, mean_policy_losses: -115.611, mean_net_lifetime: 6384.9008, mean_mc_travel_dist: 6419.4172, mean_rewards: 101.2445, total_rewards: 5102.6597, mean_steps: 70.2800, mean_ecr: 0.0402 mean_entropies: 1.6292, took: 137.2979s
2022-07-31 16:54:42,346 [INFO] 	Process 1: Batch 6199/10000, mean_policy_losses: -85.165, mean_net_lifetime: 6377.8486, mean_mc_travel_dist: 6292.9756, mean_rewards: 100.8054, total_rewards: 5120.2472, mean_steps: 69.3800, mean_ecr: 0.0410 mean_entropies: 1.5968, took: 147.5512s
2022-07-31 16:56:53,827 [INFO] 	Process 1: Batch 6299/10000, mean_policy_losses: -69.966, mean_net_lifetime: 6525.2355, mean_mc_travel_dist: 6042.9646, mean_rewards: 108.5759, total_rewards: 5317.6087, mean_steps: 65.6100, mean_ecr: 0.0420 mean_entropies: 1.5477, took: 131.4801s
2022-07-31 16:59:12,383 [INFO] 	Process 1: Batch 6399/10000, mean_policy_losses: -51.741, mean_net_lifetime: 6448.8400, mean_mc_travel_dist: 6554.2682, mean_rewards: 98.2798, total_rewards: 5137.9864, mean_steps: 71.4600, mean_ecr: 0.0395 mean_entropies: 1.6207, took: 138.5581s
2022-07-31 17:01:36,100 [INFO] 	Process 1: Batch 6499/10000, mean_policy_losses: -132.137, mean_net_lifetime: 6454.5703, mean_mc_travel_dist: 6367.0094, mean_rewards: 103.0445, total_rewards: 5181.4285, mean_steps: 70.2400, mean_ecr: 0.0404 mean_entropies: 1.5498, took: 143.7170s
2022-07-31 17:03:53,625 [INFO] 	Process 1: Batch 6599/10000, mean_policy_losses: -91.047, mean_net_lifetime: 6335.1849, mean_mc_travel_dist: 6110.3298, mean_rewards: 105.6976, total_rewards: 5113.9523, mean_steps: 66.0000, mean_ecr: 0.0420 mean_entropies: 1.5290, took: 137.5243s
2022-07-31 17:06:17,381 [INFO] 	Process 1: Batch 6699/10000, mean_policy_losses: -45.689, mean_net_lifetime: 6512.4385, mean_mc_travel_dist: 6675.5594, mean_rewards: 96.9671, total_rewards: 5177.5031, mean_steps: 74.5300, mean_ecr: 0.0393 mean_entropies: 1.5729, took: 143.7546s
2022-07-31 17:08:39,111 [INFO] 	Process 1: Batch 6799/10000, mean_policy_losses: -39.792, mean_net_lifetime: 6533.0779, mean_mc_travel_dist: 6470.8468, mean_rewards: 99.0433, total_rewards: 5239.3351, mean_steps: 72.1100, mean_ecr: 0.0401 mean_entropies: 1.5086, took: 141.7301s
2022-07-31 17:10:49,849 [INFO] 	Process 1: Batch 6899/10000, mean_policy_losses: -78.046, mean_net_lifetime: 6401.2580, mean_mc_travel_dist: 6209.0021, mean_rewards: 104.3665, total_rewards: 5160.3184, mean_steps: 67.9500, mean_ecr: 0.0413 mean_entropies: 1.4812, took: 130.7381s
2022-07-31 17:13:07,169 [INFO] 	Process 1: Batch 6999/10000, mean_policy_losses: -67.366, mean_net_lifetime: 6380.8335, mean_mc_travel_dist: 6270.3202, mean_rewards: 101.9640, total_rewards: 5126.9367, mean_steps: 69.3400, mean_ecr: 0.0410 mean_entropies: 1.5135, took: 137.3214s
2022-07-31 17:15:30,531 [INFO] 	Process 1: Batch 7099/10000, mean_policy_losses: -44.939, mean_net_lifetime: 6463.3298, mean_mc_travel_dist: 6375.5516, mean_rewards: 101.4790, total_rewards: 5188.8538, mean_steps: 68.7200, mean_ecr: 0.0407 mean_entropies: 1.5039, took: 143.3613s
2022-07-31 17:18:00,911 [INFO] 	Process 1: Batch 7199/10000, mean_policy_losses: -68.519, mean_net_lifetime: 6480.0132, mean_mc_travel_dist: 6525.3859, mean_rewards: 97.4959, total_rewards: 5175.6380, mean_steps: 73.1400, mean_ecr: 0.0397 mean_entropies: 1.5133, took: 150.3799s
2022-07-31 17:20:20,590 [INFO] 	Process 1: Batch 7299/10000, mean_policy_losses: -97.824, mean_net_lifetime: 6553.6804, mean_mc_travel_dist: 6223.2512, mean_rewards: 105.0515, total_rewards: 5309.7276, mean_steps: 68.0300, mean_ecr: 0.0410 mean_entropies: 1.4295, took: 139.6774s
2022-07-31 17:22:35,132 [INFO] 	Process 1: Batch 7399/10000, mean_policy_losses: -64.797, mean_net_lifetime: 6446.6424, mean_mc_travel_dist: 6440.4557, mean_rewards: 100.3121, total_rewards: 5159.5241, mean_steps: 69.8400, mean_ecr: 0.0402 mean_entropies: 1.4913, took: 134.5439s
2022-07-31 17:24:51,232 [INFO] 	Process 1: Batch 7499/10000, mean_policy_losses: -52.557, mean_net_lifetime: 6450.1643, mean_mc_travel_dist: 6445.6166, mean_rewards: 100.1387, total_rewards: 5161.3681, mean_steps: 71.3800, mean_ecr: 0.0400 mean_entropies: 1.4499, took: 136.1012s
2022-07-31 17:26:59,580 [INFO] 	Process 1: Batch 7599/10000, mean_policy_losses: -34.950, mean_net_lifetime: 6636.8329, mean_mc_travel_dist: 6120.1839, mean_rewards: 108.8625, total_rewards: 5413.4353, mean_steps: 65.7400, mean_ecr: 0.0416 mean_entropies: 1.4126, took: 128.3479s
2022-07-31 17:29:13,716 [INFO] 	Process 1: Batch 7699/10000, mean_policy_losses: -44.299, mean_net_lifetime: 6499.4845, mean_mc_travel_dist: 6412.9625, mean_rewards: 101.1721, total_rewards: 5217.1989, mean_steps: 68.9500, mean_ecr: 0.0403 mean_entropies: 1.4655, took: 134.1359s
2022-07-31 17:31:31,896 [INFO] 	Process 1: Batch 7799/10000, mean_policy_losses: -62.425, mean_net_lifetime: 6431.7487, mean_mc_travel_dist: 6273.9001, mean_rewards: 105.2142, total_rewards: 5178.1541, mean_steps: 67.8400, mean_ecr: 0.0408 mean_entropies: 1.4494, took: 138.1797s
2022-07-31 17:34:00,132 [INFO] 	Process 1: Batch 7899/10000, mean_policy_losses: -88.372, mean_net_lifetime: 6476.5048, mean_mc_travel_dist: 6733.9733, mean_rewards: 97.3357, total_rewards: 5130.0408, mean_steps: 74.4300, mean_ecr: 0.0385 mean_entropies: 1.5040, took: 148.2334s
2022-07-31 17:36:26,749 [INFO] 	Process 1: Batch 7999/10000, mean_policy_losses: -52.871, mean_net_lifetime: 6595.2820, mean_mc_travel_dist: 6481.7923, mean_rewards: 103.3956, total_rewards: 5298.9235, mean_steps: 70.2000, mean_ecr: 0.0400 mean_entropies: 1.4642, took: 146.6193s
2022-07-31 17:38:54,915 [INFO] 	Process 1: Batch 8099/10000, mean_policy_losses: -70.081, mean_net_lifetime: 6628.6850, mean_mc_travel_dist: 6426.7432, mean_rewards: 101.9359, total_rewards: 5344.0170, mean_steps: 70.2000, mean_ecr: 0.0400 mean_entropies: 1.4187, took: 148.1666s
2022-07-31 17:41:15,966 [INFO] 	Process 1: Batch 8199/10000, mean_policy_losses: -69.376, mean_net_lifetime: 6447.2412, mean_mc_travel_dist: 6439.6914, mean_rewards: 100.2107, total_rewards: 5159.6294, mean_steps: 71.4300, mean_ecr: 0.0399 mean_entropies: 1.4528, took: 141.0490s
2022-07-31 17:43:57,982 [INFO] 	Process 1: Batch 8299/10000, mean_policy_losses: -33.355, mean_net_lifetime: 10339.6672, mean_mc_travel_dist: 7935.7585, mean_rewards: 115.4720, total_rewards: 8752.8419, mean_steps: 84.1100, mean_ecr: 0.0408 mean_entropies: 1.3465, took: 162.0110s
2022-07-31 17:46:25,986 [INFO] 	Process 1: Batch 8399/10000, mean_policy_losses: -148.552, mean_net_lifetime: 7028.3871, mean_mc_travel_dist: 7064.7766, mean_rewards: 109.9368, total_rewards: 5615.7501, mean_steps: 75.1200, mean_ecr: 0.0408 mean_entropies: 1.3671, took: 148.0093s
2022-07-31 17:48:44,390 [INFO] 	Process 1: Batch 8499/10000, mean_policy_losses: -93.234, mean_net_lifetime: 6523.0931, mean_mc_travel_dist: 6323.2261, mean_rewards: 104.4033, total_rewards: 5259.1861, mean_steps: 68.6200, mean_ecr: 0.0406 mean_entropies: 1.4234, took: 138.4040s
2022-07-31 17:51:00,932 [INFO] 	Process 1: Batch 8599/10000, mean_policy_losses: -68.258, mean_net_lifetime: 6578.2452, mean_mc_travel_dist: 6441.8818, mean_rewards: 104.1291, total_rewards: 5290.0365, mean_steps: 69.7600, mean_ecr: 0.0400 mean_entropies: 1.3433, took: 136.5430s
2022-07-31 17:53:16,763 [INFO] 	Process 1: Batch 8699/10000, mean_policy_losses: -77.609, mean_net_lifetime: 6613.0915, mean_mc_travel_dist: 6626.5206, mean_rewards: 99.4052, total_rewards: 5288.7968, mean_steps: 71.7500, mean_ecr: 0.0390 mean_entropies: 1.4088, took: 135.8286s
2022-07-31 17:55:36,895 [INFO] 	Process 1: Batch 8799/10000, mean_policy_losses: -56.484, mean_net_lifetime: 6437.5683, mean_mc_travel_dist: 6477.9156, mean_rewards: 98.5881, total_rewards: 5142.7688, mean_steps: 71.5500, mean_ecr: 0.0393 mean_entropies: 1.3452, took: 140.1339s
2022-07-31 17:58:07,761 [INFO] 	Process 1: Batch 8899/10000, mean_policy_losses: -55.775, mean_net_lifetime: 6559.3065, mean_mc_travel_dist: 6842.6518, mean_rewards: 92.8320, total_rewards: 5191.2729, mean_steps: 76.7000, mean_ecr: 0.0382 mean_entropies: 1.3896, took: 150.8666s
2022-07-31 18:00:20,898 [INFO] 	Process 1: Batch 8999/10000, mean_policy_losses: -76.904, mean_net_lifetime: 6476.7271, mean_mc_travel_dist: 6337.8154, mean_rewards: 104.0478, total_rewards: 5209.9599, mean_steps: 69.0200, mean_ecr: 0.0406 mean_entropies: 1.3286, took: 133.1357s
2022-07-31 18:02:32,118 [INFO] 	Process 1: Batch 9099/10000, mean_policy_losses: -66.731, mean_net_lifetime: 6472.8149, mean_mc_travel_dist: 6464.2850, mean_rewards: 101.9056, total_rewards: 5180.1403, mean_steps: 70.1100, mean_ecr: 0.0399 mean_entropies: 1.3124, took: 131.2180s
2022-07-31 18:04:42,540 [INFO] 	Process 1: Batch 9199/10000, mean_policy_losses: -47.090, mean_net_lifetime: 6586.9451, mean_mc_travel_dist: 6518.8254, mean_rewards: 102.0522, total_rewards: 5284.6892, mean_steps: 69.8300, mean_ecr: 0.0398 mean_entropies: 1.3278, took: 130.4245s
2022-07-31 18:06:52,832 [INFO] 	Process 1: Batch 9299/10000, mean_policy_losses: -79.093, mean_net_lifetime: 6617.3385, mean_mc_travel_dist: 6147.6450, mean_rewards: 107.3245, total_rewards: 5388.4762, mean_steps: 67.6800, mean_ecr: 0.0414 mean_entropies: 1.2289, took: 130.2926s
2022-07-31 18:09:01,524 [INFO] 	Process 1: Batch 9399/10000, mean_policy_losses: -52.966, mean_net_lifetime: 6448.1122, mean_mc_travel_dist: 5987.9239, mean_rewards: 108.1470, total_rewards: 5251.1488, mean_steps: 65.0200, mean_ecr: 0.0427 mean_entropies: 1.2273, took: 128.6920s
2022-07-31 18:11:32,183 [INFO] 	Process 1: Batch 9499/10000, mean_policy_losses: -45.730, mean_net_lifetime: 6493.3790, mean_mc_travel_dist: 6755.6246, mean_rewards: 96.3395, total_rewards: 5142.8125, mean_steps: 75.8700, mean_ecr: 0.0385 mean_entropies: 1.2855, took: 150.6592s
2022-07-31 18:13:48,052 [INFO] 	Process 1: Batch 9599/10000, mean_policy_losses: -48.070, mean_net_lifetime: 6484.3741, mean_mc_travel_dist: 6324.4084, mean_rewards: 103.7058, total_rewards: 5220.2604, mean_steps: 69.2400, mean_ecr: 0.0404 mean_entropies: 1.2629, took: 135.8686s
2022-07-31 18:16:02,596 [INFO] 	Process 1: Batch 9699/10000, mean_policy_losses: -75.469, mean_net_lifetime: 6497.5191, mean_mc_travel_dist: 6473.9598, mean_rewards: 102.5954, total_rewards: 5202.8993, mean_steps: 70.1300, mean_ecr: 0.0398 mean_entropies: 1.2763, took: 134.5439s
2022-07-31 18:18:15,098 [INFO] 	Process 1: Batch 9799/10000, mean_policy_losses: -69.013, mean_net_lifetime: 6368.1135, mean_mc_travel_dist: 6250.1364, mean_rewards: 103.7343, total_rewards: 5118.6461, mean_steps: 67.9200, mean_ecr: 0.0409 mean_entropies: 1.2788, took: 132.5006s
2022-07-31 18:20:31,425 [INFO] 	Process 1: Batch 9899/10000, mean_policy_losses: -63.344, mean_net_lifetime: 6532.7323, mean_mc_travel_dist: 6278.8013, mean_rewards: 102.3213, total_rewards: 5277.0914, mean_steps: 69.7400, mean_ecr: 0.0412 mean_entropies: 1.2563, took: 136.3291s
2022-07-31 18:22:50,867 [INFO] 	Process 1: Batch 9999/10000, mean_policy_losses: -77.237, mean_net_lifetime: 6380.3963, mean_mc_travel_dist: 6449.4285, mean_rewards: 100.9475, total_rewards: 5090.9334, mean_steps: 71.1400, mean_ecr: 0.0403 mean_entropies: 1.2838, took: 139.4413s
2022-07-31 18:34:13,879 [INFO] Process 1: Epoch 0: mean_policy_losses: -52.645, mean_net_lifetime: 6743.5640, mean_mc_travel_dist: 7329.4969, mean_entropies: 1.8517, m_net_lifetime_valid: 6557.9511, took: 16252.3885s, (154.1522 / 100 batches)

2022-07-31 18:34:13,879 [INFO] Process 1: Start epoch 1
2022-07-31 18:36:39,124 [INFO] 	Process 1: Batch 99/10000, mean_policy_losses: 143.031, mean_net_lifetime: 5193.7336, mean_mc_travel_dist: 7953.1414, mean_rewards: 65.5221, total_rewards: 3608.1778, mean_steps: 75.7700, mean_ecr: 0.0420 mean_entropies: 2.9584, took: 145.2383s
2022-07-31 18:40:36,248 [INFO] 	Process 1: Batch 199/10000, mean_policy_losses: -29.648, mean_net_lifetime: 8780.3583, mean_mc_travel_dist: 14128.0906, mean_rewards: 70.2833, total_rewards: 5958.9269, mean_steps: 136.1800, mean_ecr: 0.0397 mean_entropies: 2.9237, took: 237.1265s
2022-07-31 18:43:25,407 [INFO] 	Process 1: Batch 299/10000, mean_policy_losses: -17.991, mean_net_lifetime: 5394.0495, mean_mc_travel_dist: 8607.2306, mean_rewards: 64.1129, total_rewards: 3674.7973, mean_steps: 87.0800, mean_ecr: 0.0396 mean_entropies: 2.8048, took: 169.1581s
2022-07-31 18:45:56,266 [INFO] 	Process 1: Batch 399/10000, mean_policy_losses: -26.216, mean_net_lifetime: 4610.4206, mean_mc_travel_dist: 7164.4457, mean_rewards: 62.7135, total_rewards: 3179.4804, mean_steps: 75.0900, mean_ecr: 0.0403 mean_entropies: 2.7856, took: 150.8590s
2022-07-31 18:48:22,323 [INFO] 	Process 1: Batch 499/10000, mean_policy_losses: -15.427, mean_net_lifetime: 4763.3782, mean_mc_travel_dist: 6925.9369, mean_rewards: 67.9245, total_rewards: 3381.0354, mean_steps: 74.2800, mean_ecr: 0.0411 mean_entropies: 2.6887, took: 146.0572s
2022-07-31 18:50:46,991 [INFO] 	Process 1: Batch 599/10000, mean_policy_losses: -38.958, mean_net_lifetime: 4771.5943, mean_mc_travel_dist: 6961.4108, mean_rewards: 67.6103, total_rewards: 3380.7924, mean_steps: 73.9500, mean_ecr: 0.0408 mean_entropies: 2.6422, took: 144.6685s
2022-07-31 18:53:10,884 [INFO] 	Process 1: Batch 699/10000, mean_policy_losses: -25.220, mean_net_lifetime: 4908.2738, mean_mc_travel_dist: 6710.6595, mean_rewards: 68.5284, total_rewards: 3568.7227, mean_steps: 74.8600, mean_ecr: 0.0416 mean_entropies: 2.6665, took: 143.8928s
2022-07-31 18:55:34,924 [INFO] 	Process 1: Batch 799/10000, mean_policy_losses: -28.908, mean_net_lifetime: 5213.5141, mean_mc_travel_dist: 6962.5587, mean_rewards: 72.0155, total_rewards: 3823.3297, mean_steps: 75.9500, mean_ecr: 0.0406 mean_entropies: 2.6581, took: 144.0403s
2022-07-31 18:58:36,996 [INFO] 	Process 1: Batch 899/10000, mean_policy_losses: -51.801, mean_net_lifetime: 6934.5999, mean_mc_travel_dist: 8712.6657, mean_rewards: 79.2839, total_rewards: 5194.8349, mean_steps: 96.3800, mean_ecr: 0.0405 mean_entropies: 2.6321, took: 182.0711s
2022-07-31 19:02:06,069 [INFO] 	Process 1: Batch 999/10000, mean_policy_losses: -74.538, mean_net_lifetime: 7811.5518, mean_mc_travel_dist: 9919.6243, mean_rewards: 77.6358, total_rewards: 5828.5570, mean_steps: 108.2600, mean_ecr: 0.0390 mean_entropies: 2.5989, took: 209.0730s
2022-07-31 19:07:09,806 [INFO] 	Process 1: Batch 1099/10000, mean_policy_losses: -58.812, mean_net_lifetime: 12559.0412, mean_mc_travel_dist: 14463.5855, mean_rewards: 88.9292, total_rewards: 9667.9193, mean_steps: 155.3100, mean_ecr: 0.0392 mean_entropies: 2.4962, took: 303.7377s
2022-07-31 19:09:54,591 [INFO] 	Process 1: Batch 1199/10000, mean_policy_losses: -13.430, mean_net_lifetime: 6093.7211, mean_mc_travel_dist: 7194.8738, mean_rewards: 83.0619, total_rewards: 4655.0390, mean_steps: 81.4700, mean_ecr: 0.0396 mean_entropies: 2.3602, took: 164.7847s
2022-07-31 19:12:27,339 [INFO] 	Process 1: Batch 1299/10000, mean_policy_losses: -21.166, mean_net_lifetime: 5749.7397, mean_mc_travel_dist: 7019.8900, mean_rewards: 79.8319, total_rewards: 4346.0470, mean_steps: 78.7500, mean_ecr: 0.0394 mean_entropies: 2.3852, took: 152.7487s
2022-07-31 19:15:35,049 [INFO] 	Process 1: Batch 1399/10000, mean_policy_losses: -59.014, mean_net_lifetime: 7442.3348, mean_mc_travel_dist: 8813.9664, mean_rewards: 88.5370, total_rewards: 5680.5492, mean_steps: 98.2000, mean_ecr: 0.0403 mean_entropies: 2.3200, took: 187.7097s
2022-07-31 19:18:21,777 [INFO] 	Process 1: Batch 1499/10000, mean_policy_losses: -43.938, mean_net_lifetime: 6751.2331, mean_mc_travel_dist: 7922.1837, mean_rewards: 85.2375, total_rewards: 5167.8531, mean_steps: 90.2800, mean_ecr: 0.0407 mean_entropies: 2.1912, took: 166.7276s
2022-07-31 19:20:32,821 [INFO] 	Process 1: Batch 1599/10000, mean_policy_losses: -79.636, mean_net_lifetime: 5970.1126, mean_mc_travel_dist: 6218.5223, mean_rewards: 91.4603, total_rewards: 4727.4507, mean_steps: 70.1100, mean_ecr: 0.0431 mean_entropies: 2.1398, took: 131.0443s
2022-07-31 19:23:14,609 [INFO] 	Process 1: Batch 1699/10000, mean_policy_losses: -76.930, mean_net_lifetime: 6399.6189, mean_mc_travel_dist: 7293.0314, mean_rewards: 87.0500, total_rewards: 4941.8826, mean_steps: 80.0100, mean_ecr: 0.0392 mean_entropies: 2.2850, took: 161.7857s
2022-07-31 19:25:54,403 [INFO] 	Process 1: Batch 1799/10000, mean_policy_losses: -101.940, mean_net_lifetime: 6338.4297, mean_mc_travel_dist: 7084.1503, mean_rewards: 90.1843, total_rewards: 4922.0664, mean_steps: 78.3700, mean_ecr: 0.0407 mean_entropies: 2.1812, took: 159.7956s
2022-07-31 19:28:32,095 [INFO] 	Process 1: Batch 1899/10000, mean_policy_losses: -90.181, mean_net_lifetime: 6134.6928, mean_mc_travel_dist: 6939.2877, mean_rewards: 87.1754, total_rewards: 4747.1311, mean_steps: 77.2700, mean_ecr: 0.0395 mean_entropies: 2.2020, took: 157.6923s
2022-07-31 19:31:02,100 [INFO] 	Process 1: Batch 1999/10000, mean_policy_losses: -16.328, mean_net_lifetime: 6113.6151, mean_mc_travel_dist: 6761.9444, mean_rewards: 90.8771, total_rewards: 4761.9418, mean_steps: 74.1000, mean_ecr: 0.0402 mean_entropies: 2.1682, took: 150.0048s
2022-07-31 19:33:28,505 [INFO] 	Process 1: Batch 2099/10000, mean_policy_losses: -76.515, mean_net_lifetime: 6040.6715, mean_mc_travel_dist: 6867.2433, mean_rewards: 85.7099, total_rewards: 4667.4961, mean_steps: 76.4600, mean_ecr: 0.0393 mean_entropies: 2.1477, took: 146.4050s
2022-07-31 19:35:59,970 [INFO] 	Process 1: Batch 2199/10000, mean_policy_losses: 2.910, mean_net_lifetime: 6122.1198, mean_mc_travel_dist: 6734.1709, mean_rewards: 89.9755, total_rewards: 4775.6733, mean_steps: 73.3700, mean_ecr: 0.0399 mean_entropies: 2.1411, took: 151.4646s
2022-07-31 19:38:18,572 [INFO] 	Process 1: Batch 2299/10000, mean_policy_losses: -82.646, mean_net_lifetime: 6136.6976, mean_mc_travel_dist: 6559.2063, mean_rewards: 93.2962, total_rewards: 4825.5124, mean_steps: 72.9900, mean_ecr: 0.0409 mean_entropies: 2.1120, took: 138.6020s
2022-07-31 19:40:34,851 [INFO] 	Process 1: Batch 2399/10000, mean_policy_losses: -22.124, mean_net_lifetime: 6308.5162, mean_mc_travel_dist: 6562.5220, mean_rewards: 94.6533, total_rewards: 4997.4034, mean_steps: 72.2900, mean_ecr: 0.0408 mean_entropies: 2.0641, took: 136.2798s
2022-07-31 19:42:56,130 [INFO] 	Process 1: Batch 2499/10000, mean_policy_losses: -77.924, mean_net_lifetime: 6102.0071, mean_mc_travel_dist: 6557.4638, mean_rewards: 92.3289, total_rewards: 4791.3172, mean_steps: 72.0200, mean_ecr: 0.0405 mean_entropies: 2.1193, took: 141.2779s
2022-07-31 19:45:21,380 [INFO] 	Process 1: Batch 2599/10000, mean_policy_losses: -49.120, mean_net_lifetime: 6250.0905, mean_mc_travel_dist: 6751.9454, mean_rewards: 92.7032, total_rewards: 4900.6957, mean_steps: 75.1100, mean_ecr: 0.0400 mean_entropies: 2.0467, took: 145.2505s
2022-07-31 19:47:42,205 [INFO] 	Process 1: Batch 2699/10000, mean_policy_losses: -73.114, mean_net_lifetime: 6299.3722, mean_mc_travel_dist: 6585.6337, mean_rewards: 94.0238, total_rewards: 4982.9083, mean_steps: 72.5000, mean_ecr: 0.0402 mean_entropies: 2.0515, took: 140.8240s
2022-07-31 19:50:04,448 [INFO] 	Process 1: Batch 2799/10000, mean_policy_losses: -89.360, mean_net_lifetime: 6243.1739, mean_mc_travel_dist: 6511.9433, mean_rewards: 95.0883, total_rewards: 4941.1443, mean_steps: 71.2900, mean_ecr: 0.0405 mean_entropies: 2.0362, took: 142.2447s
2022-07-31 19:52:29,635 [INFO] 	Process 1: Batch 2899/10000, mean_policy_losses: -60.551, mean_net_lifetime: 6228.1377, mean_mc_travel_dist: 6578.6222, mean_rewards: 93.8932, total_rewards: 4912.8823, mean_steps: 73.4900, mean_ecr: 0.0404 mean_entropies: 1.9404, took: 145.1864s
2022-07-31 19:54:50,562 [INFO] 	Process 1: Batch 2999/10000, mean_policy_losses: -44.776, mean_net_lifetime: 6429.0021, mean_mc_travel_dist: 6433.7117, mean_rewards: 97.0685, total_rewards: 5143.4790, mean_steps: 71.5000, mean_ecr: 0.0409 mean_entropies: 1.9805, took: 140.9270s
2022-07-31 19:57:10,754 [INFO] 	Process 1: Batch 3099/10000, mean_policy_losses: -61.772, mean_net_lifetime: 6255.9780, mean_mc_travel_dist: 6659.3522, mean_rewards: 92.6967, total_rewards: 4924.6462, mean_steps: 72.5900, mean_ecr: 0.0397 mean_entropies: 2.0210, took: 140.1910s
2022-07-31 19:59:29,331 [INFO] 	Process 1: Batch 3199/10000, mean_policy_losses: -62.582, mean_net_lifetime: 6478.3533, mean_mc_travel_dist: 6616.5292, mean_rewards: 96.1027, total_rewards: 5156.2332, mean_steps: 73.1300, mean_ecr: 0.0394 mean_entropies: 1.9620, took: 138.5769s
2022-07-31 20:01:46,099 [INFO] 	Process 1: Batch 3299/10000, mean_policy_losses: -71.435, mean_net_lifetime: 6385.9149, mean_mc_travel_dist: 6360.5555, mean_rewards: 101.3776, total_rewards: 5114.5588, mean_steps: 68.0700, mean_ecr: 0.0409 mean_entropies: 1.9171, took: 136.7689s
2022-07-31 20:04:05,861 [INFO] 	Process 1: Batch 3399/10000, mean_policy_losses: -45.461, mean_net_lifetime: 6476.1416, mean_mc_travel_dist: 6308.6232, mean_rewards: 101.8101, total_rewards: 5215.5055, mean_steps: 69.6100, mean_ecr: 0.0415 mean_entropies: 1.8955, took: 139.7609s
2022-07-31 20:06:42,490 [INFO] 	Process 1: Batch 3499/10000, mean_policy_losses: -79.003, mean_net_lifetime: 6184.0129, mean_mc_travel_dist: 7057.1340, mean_rewards: 86.2838, total_rewards: 4772.7869, mean_steps: 79.0400, mean_ecr: 0.0375 mean_entropies: 1.9966, took: 156.6302s
2022-07-31 20:09:09,935 [INFO] 	Process 1: Batch 3599/10000, mean_policy_losses: -42.812, mean_net_lifetime: 6481.3701, mean_mc_travel_dist: 6607.5806, mean_rewards: 94.0829, total_rewards: 5160.5388, mean_steps: 74.8200, mean_ecr: 0.0395 mean_entropies: 1.8739, took: 147.4445s
2022-07-31 20:11:29,367 [INFO] 	Process 1: Batch 3699/10000, mean_policy_losses: -69.257, mean_net_lifetime: 6594.5457, mean_mc_travel_dist: 6387.8666, mean_rewards: 100.7304, total_rewards: 5317.7395, mean_steps: 70.7000, mean_ecr: 0.0408 mean_entropies: 1.8034, took: 139.4325s
2022-07-31 20:13:42,293 [INFO] 	Process 1: Batch 3799/10000, mean_policy_losses: -76.820, mean_net_lifetime: 6485.4990, mean_mc_travel_dist: 6204.1098, mean_rewards: 103.8696, total_rewards: 5245.3025, mean_steps: 67.0200, mean_ecr: 0.0415 mean_entropies: 1.7890, took: 132.9264s
2022-07-31 20:16:06,802 [INFO] 	Process 1: Batch 3899/10000, mean_policy_losses: -64.603, mean_net_lifetime: 6406.9068, mean_mc_travel_dist: 6453.3837, mean_rewards: 97.2984, total_rewards: 5117.1637, mean_steps: 70.8200, mean_ecr: 0.0404 mean_entropies: 1.8631, took: 144.5088s
2022-07-31 20:18:19,702 [INFO] 	Process 1: Batch 3999/10000, mean_policy_losses: -53.656, mean_net_lifetime: 6441.9311, mean_mc_travel_dist: 6437.7321, mean_rewards: 99.2822, total_rewards: 5155.2080, mean_steps: 69.9700, mean_ecr: 0.0403 mean_entropies: 1.8405, took: 132.9008s
2022-07-31 20:20:40,720 [INFO] 	Process 1: Batch 4099/10000, mean_policy_losses: -69.043, mean_net_lifetime: 6467.5964, mean_mc_travel_dist: 6637.1692, mean_rewards: 95.8327, total_rewards: 5140.2371, mean_steps: 72.8100, mean_ecr: 0.0396 mean_entropies: 1.7981, took: 141.0154s
2022-07-31 20:23:00,639 [INFO] 	Process 1: Batch 4199/10000, mean_policy_losses: -58.592, mean_net_lifetime: 6374.6565, mean_mc_travel_dist: 6521.4399, mean_rewards: 97.7928, total_rewards: 5071.0353, mean_steps: 72.0800, mean_ecr: 0.0401 mean_entropies: 1.7984, took: 139.9189s
2022-07-31 20:25:16,274 [INFO] 	Process 1: Batch 4299/10000, mean_policy_losses: -83.653, mean_net_lifetime: 6570.1493, mean_mc_travel_dist: 6331.5282, mean_rewards: 99.1672, total_rewards: 5304.8618, mean_steps: 70.5100, mean_ecr: 0.0408 mean_entropies: 1.7537, took: 135.6357s
2022-07-31 20:27:31,223 [INFO] 	Process 1: Batch 4399/10000, mean_policy_losses: -49.323, mean_net_lifetime: 6720.2477, mean_mc_travel_dist: 6344.9373, mean_rewards: 104.9705, total_rewards: 5451.7469, mean_steps: 69.6000, mean_ecr: 0.0408 mean_entropies: 1.7527, took: 134.9481s
2022-07-31 20:29:53,436 [INFO] 	Process 1: Batch 4499/10000, mean_policy_losses: -41.147, mean_net_lifetime: 6565.5682, mean_mc_travel_dist: 6508.9628, mean_rewards: 100.9782, total_rewards: 5264.1112, mean_steps: 72.1300, mean_ecr: 0.0403 mean_entropies: 1.7247, took: 142.2152s
2022-07-31 20:32:12,673 [INFO] 	Process 1: Batch 4599/10000, mean_policy_losses: -50.825, mean_net_lifetime: 6363.6553, mean_mc_travel_dist: 6651.3490, mean_rewards: 95.9629, total_rewards: 5033.9106, mean_steps: 73.2100, mean_ecr: 0.0393 mean_entropies: 1.7545, took: 139.2377s
2022-07-31 20:34:19,968 [INFO] 	Process 1: Batch 4699/10000, mean_policy_losses: -79.841, mean_net_lifetime: 6328.7611, mean_mc_travel_dist: 6120.7060, mean_rewards: 105.4618, total_rewards: 5104.8700, mean_steps: 67.0000, mean_ecr: 0.0418 mean_entropies: 1.7018, took: 127.2943s
2022-07-31 20:36:29,487 [INFO] 	Process 1: Batch 4799/10000, mean_policy_losses: -115.536, mean_net_lifetime: 6517.0617, mean_mc_travel_dist: 6243.0763, mean_rewards: 102.1152, total_rewards: 5268.9174, mean_steps: 68.7000, mean_ecr: 0.0415 mean_entropies: 1.7286, took: 129.5183s
2022-07-31 20:38:45,394 [INFO] 	Process 1: Batch 4899/10000, mean_policy_losses: -73.068, mean_net_lifetime: 6338.1283, mean_mc_travel_dist: 6625.6090, mean_rewards: 96.8330, total_rewards: 5013.0065, mean_steps: 72.2600, mean_ecr: 0.0395 mean_entropies: 1.7592, took: 135.9063s
2022-07-31 20:41:00,652 [INFO] 	Process 1: Batch 4999/10000, mean_policy_losses: -44.597, mean_net_lifetime: 6385.4403, mean_mc_travel_dist: 6595.3772, mean_rewards: 96.8129, total_rewards: 5067.2371, mean_steps: 72.6300, mean_ecr: 0.0389 mean_entropies: 1.7436, took: 135.2580s
2022-07-31 20:43:16,390 [INFO] 	Process 1: Batch 5099/10000, mean_policy_losses: -76.053, mean_net_lifetime: 6189.5467, mean_mc_travel_dist: 6719.9979, mean_rewards: 94.9583, total_rewards: 4846.1557, mean_steps: 72.8000, mean_ecr: 0.0389 mean_entropies: 1.7224, took: 135.7374s
2022-07-31 20:47:28,810 [INFO] 	Process 1: Batch 5199/10000, mean_policy_losses: -36.932, mean_net_lifetime: 13382.8900, mean_mc_travel_dist: 13346.6119, mean_rewards: 116.2708, total_rewards: 10714.1711, mean_steps: 133.5300, mean_ecr: 0.0402 mean_entropies: 1.5551, took: 252.4226s
2022-07-31 20:49:50,867 [INFO] 	Process 1: Batch 5299/10000, mean_policy_losses: -110.450, mean_net_lifetime: 6375.4234, mean_mc_travel_dist: 6532.2597, mean_rewards: 100.0046, total_rewards: 5069.2908, mean_steps: 70.9300, mean_ecr: 0.0398 mean_entropies: 1.6476, took: 142.0559s
2022-07-31 20:52:04,953 [INFO] 	Process 1: Batch 5399/10000, mean_policy_losses: -48.584, mean_net_lifetime: 6400.2484, mean_mc_travel_dist: 6279.2013, mean_rewards: 104.4774, total_rewards: 5144.7025, mean_steps: 68.6600, mean_ecr: 0.0413 mean_entropies: 1.5818, took: 134.0866s
2022-07-31 20:54:18,183 [INFO] 	Process 1: Batch 5499/10000, mean_policy_losses: -94.497, mean_net_lifetime: 6539.2317, mean_mc_travel_dist: 6385.9831, mean_rewards: 102.7836, total_rewards: 5262.5188, mean_steps: 70.3000, mean_ecr: 0.0411 mean_entropies: 1.6057, took: 133.2302s
2022-07-31 20:56:29,986 [INFO] 	Process 1: Batch 5599/10000, mean_policy_losses: -86.871, mean_net_lifetime: 6565.0357, mean_mc_travel_dist: 6196.6078, mean_rewards: 104.9001, total_rewards: 5326.5444, mean_steps: 66.5700, mean_ecr: 0.0412 mean_entropies: 1.5876, took: 131.8029s
2022-07-31 20:58:36,554 [INFO] 	Process 1: Batch 5699/10000, mean_policy_losses: -78.967, mean_net_lifetime: 6508.9377, mean_mc_travel_dist: 6038.3875, mean_rewards: 107.2799, total_rewards: 5301.9284, mean_steps: 65.9300, mean_ecr: 0.0421 mean_entropies: 1.5669, took: 126.5672s
2022-07-31 21:00:59,522 [INFO] 	Process 1: Batch 5799/10000, mean_policy_losses: -72.988, mean_net_lifetime: 6500.1802, mean_mc_travel_dist: 6742.8541, mean_rewards: 94.8426, total_rewards: 5152.0164, mean_steps: 75.1400, mean_ecr: 0.0389 mean_entropies: 1.6139, took: 142.9683s
2022-07-31 21:03:11,601 [INFO] 	Process 1: Batch 5899/10000, mean_policy_losses: -61.053, mean_net_lifetime: 6439.9648, mean_mc_travel_dist: 6221.3932, mean_rewards: 104.6919, total_rewards: 5196.5263, mean_steps: 69.3900, mean_ecr: 0.0417 mean_entropies: 1.5544, took: 132.0801s
2022-07-31 21:05:25,172 [INFO] 	Process 1: Batch 5999/10000, mean_policy_losses: -77.542, mean_net_lifetime: 6495.4255, mean_mc_travel_dist: 6554.6844, mean_rewards: 99.4730, total_rewards: 5184.8116, mean_steps: 71.2000, mean_ecr: 0.0399 mean_entropies: 1.5763, took: 133.5704s
2022-07-31 21:07:33,046 [INFO] 	Process 1: Batch 6099/10000, mean_policy_losses: -76.152, mean_net_lifetime: 6499.8489, mean_mc_travel_dist: 6423.1575, mean_rewards: 103.0882, total_rewards: 5215.5991, mean_steps: 68.8000, mean_ecr: 0.0402 mean_entropies: 1.5674, took: 127.8731s
2022-07-31 21:09:44,058 [INFO] 	Process 1: Batch 6199/10000, mean_policy_losses: -83.980, mean_net_lifetime: 6451.0480, mean_mc_travel_dist: 6586.8010, mean_rewards: 99.9077, total_rewards: 5134.2569, mean_steps: 70.9100, mean_ecr: 0.0392 mean_entropies: 1.5833, took: 131.0131s
2022-07-31 21:11:54,150 [INFO] 	Process 1: Batch 6299/10000, mean_policy_losses: -77.571, mean_net_lifetime: 6455.4268, mean_mc_travel_dist: 6350.6805, mean_rewards: 103.0048, total_rewards: 5186.1406, mean_steps: 68.9100, mean_ecr: 0.0408 mean_entropies: 1.5549, took: 130.0919s
2022-07-31 21:14:03,420 [INFO] 	Process 1: Batch 6399/10000, mean_policy_losses: -88.443, mean_net_lifetime: 6543.8816, mean_mc_travel_dist: 6290.9840, mean_rewards: 105.7976, total_rewards: 5285.9022, mean_steps: 68.0700, mean_ecr: 0.0408 mean_entropies: 1.5626, took: 129.2696s
2022-07-31 21:16:06,124 [INFO] 	Process 1: Batch 6499/10000, mean_policy_losses: -62.475, mean_net_lifetime: 6486.3264, mean_mc_travel_dist: 6052.1910, mean_rewards: 109.6807, total_rewards: 5276.8698, mean_steps: 63.6500, mean_ecr: 0.0421 mean_entropies: 1.5310, took: 122.7028s
2022-07-31 21:18:19,744 [INFO] 	Process 1: Batch 6599/10000, mean_policy_losses: -50.602, mean_net_lifetime: 6494.4473, mean_mc_travel_dist: 6303.7610, mean_rewards: 106.7099, total_rewards: 5234.0639, mean_steps: 68.0000, mean_ecr: 0.0412 mean_entropies: 1.5462, took: 133.6210s
2022-07-31 21:20:20,891 [INFO] 	Process 1: Batch 6699/10000, mean_policy_losses: -71.707, mean_net_lifetime: 6566.1982, mean_mc_travel_dist: 5804.9243, mean_rewards: 112.7445, total_rewards: 5406.1523, mean_steps: 62.5700, mean_ecr: 0.0431 mean_entropies: 1.4923, took: 121.1473s
2022-07-31 21:22:40,433 [INFO] 	Process 1: Batch 6799/10000, mean_policy_losses: -103.961, mean_net_lifetime: 6417.0814, mean_mc_travel_dist: 6234.4644, mean_rewards: 104.7383, total_rewards: 5170.4027, mean_steps: 67.7200, mean_ecr: 0.0415 mean_entropies: 1.5433, took: 139.5427s
2022-07-31 21:25:05,640 [INFO] 	Process 1: Batch 6899/10000, mean_policy_losses: -42.827, mean_net_lifetime: 6547.9875, mean_mc_travel_dist: 6387.0507, mean_rewards: 104.7576, total_rewards: 5271.0136, mean_steps: 68.2500, mean_ecr: 0.0404 mean_entropies: 1.5439, took: 145.2074s
2022-07-31 21:27:23,133 [INFO] 	Process 1: Batch 6999/10000, mean_policy_losses: -81.284, mean_net_lifetime: 6553.3379, mean_mc_travel_dist: 6616.0994, mean_rewards: 99.5826, total_rewards: 5230.2689, mean_steps: 71.1200, mean_ecr: 0.0394 mean_entropies: 1.5404, took: 137.4922s
2022-07-31 21:29:34,073 [INFO] 	Process 1: Batch 7099/10000, mean_policy_losses: -48.803, mean_net_lifetime: 6352.8162, mean_mc_travel_dist: 6369.4375, mean_rewards: 101.7573, total_rewards: 5080.3080, mean_steps: 69.4700, mean_ecr: 0.0406 mean_entropies: 1.4875, took: 130.9395s
2022-07-31 21:31:48,194 [INFO] 	Process 1: Batch 7199/10000, mean_policy_losses: -72.338, mean_net_lifetime: 6653.3971, mean_mc_travel_dist: 6549.5441, mean_rewards: 100.1381, total_rewards: 5343.6803, mean_steps: 71.0400, mean_ecr: 0.0393 mean_entropies: 1.4862, took: 134.1198s
2022-07-31 21:33:57,478 [INFO] 	Process 1: Batch 7299/10000, mean_policy_losses: -50.555, mean_net_lifetime: 6528.9572, mean_mc_travel_dist: 6253.5657, mean_rewards: 104.0275, total_rewards: 5278.4638, mean_steps: 68.5900, mean_ecr: 0.0409 mean_entropies: 1.4157, took: 129.2846s
2022-07-31 21:36:02,985 [INFO] 	Process 1: Batch 7399/10000, mean_policy_losses: -84.095, mean_net_lifetime: 6387.3242, mean_mc_travel_dist: 6209.6262, mean_rewards: 106.6699, total_rewards: 5145.6962, mean_steps: 66.4200, mean_ecr: 0.0412 mean_entropies: 1.4730, took: 125.5075s
2022-07-31 21:38:19,300 [INFO] 	Process 1: Batch 7499/10000, mean_policy_losses: -44.149, mean_net_lifetime: 6492.2757, mean_mc_travel_dist: 6625.5588, mean_rewards: 97.8830, total_rewards: 5167.6407, mean_steps: 72.1500, mean_ecr: 0.0391 mean_entropies: 1.4933, took: 136.3140s
2022-07-31 21:40:31,821 [INFO] 	Process 1: Batch 7599/10000, mean_policy_losses: -61.515, mean_net_lifetime: 6479.8611, mean_mc_travel_dist: 6487.8095, mean_rewards: 102.0660, total_rewards: 5182.2992, mean_steps: 69.1500, mean_ecr: 0.0398 mean_entropies: 1.4925, took: 132.5227s
2022-07-31 21:42:49,325 [INFO] 	Process 1: Batch 7699/10000, mean_policy_losses: -34.388, mean_net_lifetime: 6618.0317, mean_mc_travel_dist: 6398.5968, mean_rewards: 104.1445, total_rewards: 5339.3165, mean_steps: 68.5300, mean_ecr: 0.0406 mean_entropies: 1.4423, took: 137.5035s
2022-07-31 21:45:17,781 [INFO] 	Process 1: Batch 7799/10000, mean_policy_losses: -85.145, mean_net_lifetime: 6530.2664, mean_mc_travel_dist: 6597.0734, mean_rewards: 100.0509, total_rewards: 5211.6945, mean_steps: 70.6800, mean_ecr: 0.0391 mean_entropies: 1.4880, took: 148.4536s
2022-07-31 21:47:33,475 [INFO] 	Process 1: Batch 7899/10000, mean_policy_losses: -101.464, mean_net_lifetime: 6456.3788, mean_mc_travel_dist: 6447.4245, mean_rewards: 103.8871, total_rewards: 5167.4362, mean_steps: 69.2200, mean_ecr: 0.0398 mean_entropies: 1.4573, took: 135.6958s
2022-07-31 21:49:42,977 [INFO] 	Process 1: Batch 7999/10000, mean_policy_losses: -83.770, mean_net_lifetime: 6447.4811, mean_mc_travel_dist: 6418.7823, mean_rewards: 104.0580, total_rewards: 5164.4478, mean_steps: 67.5900, mean_ecr: 0.0402 mean_entropies: 1.4247, took: 129.5020s
2022-07-31 21:51:58,140 [INFO] 	Process 1: Batch 8099/10000, mean_policy_losses: -103.411, mean_net_lifetime: 6342.8503, mean_mc_travel_dist: 6493.2307, mean_rewards: 102.0744, total_rewards: 5045.5506, mean_steps: 67.7900, mean_ecr: 0.0397 mean_entropies: 1.3977, took: 135.1630s
2022-07-31 21:54:11,546 [INFO] 	Process 1: Batch 8199/10000, mean_policy_losses: -37.051, mean_net_lifetime: 6229.0414, mean_mc_travel_dist: 6654.1784, mean_rewards: 99.0766, total_rewards: 4898.2057, mean_steps: 70.8100, mean_ecr: 0.0397 mean_entropies: 1.4034, took: 133.4068s
2022-07-31 21:56:26,246 [INFO] 	Process 1: Batch 8299/10000, mean_policy_losses: -80.431, mean_net_lifetime: 6464.7813, mean_mc_travel_dist: 6694.8609, mean_rewards: 96.8535, total_rewards: 5126.4963, mean_steps: 72.0600, mean_ecr: 0.0389 mean_entropies: 1.4061, took: 134.6992s
2022-07-31 21:58:32,403 [INFO] 	Process 1: Batch 8399/10000, mean_policy_losses: -46.054, mean_net_lifetime: 6326.6636, mean_mc_travel_dist: 6253.3987, mean_rewards: 105.1988, total_rewards: 5077.1155, mean_steps: 66.2100, mean_ecr: 0.0412 mean_entropies: 1.2955, took: 126.1575s
2022-07-31 22:00:42,422 [INFO] 	Process 1: Batch 8499/10000, mean_policy_losses: -41.265, mean_net_lifetime: 6642.0718, mean_mc_travel_dist: 6370.6606, mean_rewards: 106.3854, total_rewards: 5368.0235, mean_steps: 67.8000, mean_ecr: 0.0401 mean_entropies: 1.2968, took: 130.0193s
2022-07-31 22:02:46,757 [INFO] 	Process 1: Batch 8599/10000, mean_policy_losses: -55.208, mean_net_lifetime: 6507.1088, mean_mc_travel_dist: 6196.2550, mean_rewards: 109.5016, total_rewards: 5268.2886, mean_steps: 64.4100, mean_ecr: 0.0416 mean_entropies: 1.2811, took: 124.3339s
2022-07-31 22:04:57,159 [INFO] 	Process 1: Batch 8699/10000, mean_policy_losses: -77.522, mean_net_lifetime: 6556.9000, mean_mc_travel_dist: 6016.6730, mean_rewards: 112.4970, total_rewards: 5354.1497, mean_steps: 63.6200, mean_ecr: 0.0420 mean_entropies: 1.2909, took: 130.4028s
2022-07-31 22:07:10,342 [INFO] 	Process 1: Batch 8799/10000, mean_policy_losses: -52.671, mean_net_lifetime: 6471.8568, mean_mc_travel_dist: 6214.1359, mean_rewards: 105.6165, total_rewards: 5229.2557, mean_steps: 66.0300, mean_ecr: 0.0410 mean_entropies: 1.3270, took: 133.1821s
2022-07-31 22:09:16,877 [INFO] 	Process 1: Batch 8899/10000, mean_policy_losses: -79.358, mean_net_lifetime: 6413.1163, mean_mc_travel_dist: 6423.0630, mean_rewards: 105.1524, total_rewards: 5129.4235, mean_steps: 66.0400, mean_ecr: 0.0401 mean_entropies: 1.3239, took: 126.5352s
2022-07-31 22:11:24,118 [INFO] 	Process 1: Batch 8999/10000, mean_policy_losses: -51.592, mean_net_lifetime: 6152.1700, mean_mc_travel_dist: 6152.4207, mean_rewards: 104.1313, total_rewards: 4922.3295, mean_steps: 65.5200, mean_ecr: 0.0413 mean_entropies: 1.2913, took: 127.2418s
2022-07-31 22:13:30,924 [INFO] 	Process 1: Batch 9099/10000, mean_policy_losses: -57.878, mean_net_lifetime: 6698.2758, mean_mc_travel_dist: 6475.8610, mean_rewards: 106.5482, total_rewards: 5403.9102, mean_steps: 67.2300, mean_ecr: 0.0402 mean_entropies: 1.2715, took: 126.8067s
2022-07-31 22:15:30,675 [INFO] 	Process 1: Batch 9199/10000, mean_policy_losses: -32.923, mean_net_lifetime: 6519.2804, mean_mc_travel_dist: 6332.2763, mean_rewards: 107.8343, total_rewards: 5253.4379, mean_steps: 64.8000, mean_ecr: 0.0408 mean_entropies: 1.2937, took: 119.7497s
2022-07-31 22:17:42,085 [INFO] 	Process 1: Batch 9299/10000, mean_policy_losses: -71.581, mean_net_lifetime: 6493.6102, mean_mc_travel_dist: 6330.3571, mean_rewards: 107.4249, total_rewards: 5229.4427, mean_steps: 66.3900, mean_ecr: 0.0407 mean_entropies: 1.2658, took: 131.4103s
2022-07-31 22:19:39,448 [INFO] 	Process 1: Batch 9399/10000, mean_policy_losses: -65.796, mean_net_lifetime: 6432.8117, mean_mc_travel_dist: 5914.6997, mean_rewards: 114.3597, total_rewards: 5250.5174, mean_steps: 60.7400, mean_ecr: 0.0427 mean_entropies: 1.2110, took: 117.3630s
2022-07-31 22:21:48,998 [INFO] 	Process 1: Batch 9499/10000, mean_policy_losses: -56.853, mean_net_lifetime: 6539.2606, mean_mc_travel_dist: 6683.9790, mean_rewards: 102.9500, total_rewards: 5202.4648, mean_steps: 69.6200, mean_ecr: 0.0393 mean_entropies: 1.3001, took: 129.5507s
2022-07-31 22:24:02,087 [INFO] 	Process 1: Batch 9599/10000, mean_policy_losses: -60.682, mean_net_lifetime: 6545.1446, mean_mc_travel_dist: 6296.0937, mean_rewards: 107.8669, total_rewards: 5286.4682, mean_steps: 67.7100, mean_ecr: 0.0410 mean_entropies: 1.2548, took: 133.0884s
2022-07-31 22:26:16,961 [INFO] 	Process 1: Batch 9699/10000, mean_policy_losses: -77.059, mean_net_lifetime: 6484.3011, mean_mc_travel_dist: 6462.1652, mean_rewards: 103.7083, total_rewards: 5192.2030, mean_steps: 68.9100, mean_ecr: 0.0398 mean_entropies: 1.2489, took: 134.8744s
2022-07-31 22:28:25,048 [INFO] 	Process 1: Batch 9799/10000, mean_policy_losses: -71.393, mean_net_lifetime: 6546.5077, mean_mc_travel_dist: 6618.9324, mean_rewards: 104.0588, total_rewards: 5223.9477, mean_steps: 68.4600, mean_ecr: 0.0395 mean_entropies: 1.2259, took: 128.0867s
2022-07-31 22:30:27,170 [INFO] 	Process 1: Batch 9899/10000, mean_policy_losses: -87.317, mean_net_lifetime: 6455.7406, mean_mc_travel_dist: 6246.4967, mean_rewards: 109.1445, total_rewards: 5206.7428, mean_steps: 65.3400, mean_ecr: 0.0412 mean_entropies: 1.1619, took: 122.1218s
2022-07-31 22:32:26,327 [INFO] 	Process 1: Batch 9999/10000, mean_policy_losses: -38.961, mean_net_lifetime: 6333.2354, mean_mc_travel_dist: 6106.3501, mean_rewards: 110.2729, total_rewards: 5113.5712, mean_steps: 64.1100, mean_ecr: 0.0419 mean_entropies: 1.1528, took: 119.1580s
2022-07-31 22:43:04,359 [INFO] Process 1: Epoch 1: mean_policy_losses: -59.875, mean_net_lifetime: 6494.2971, mean_mc_travel_dist: 6849.3429, mean_entropies: 1.7904, m_net_lifetime_valid: 6465.9598, took: 14930.4770s, (141.5093 / 100 batches)

2022-07-31 22:43:04,360 [INFO] Process 1: Start epoch 2
2022-07-31 22:46:13,759 [INFO] 	Process 1: Batch 99/10000, mean_policy_losses: 92.080, mean_net_lifetime: 6303.7008, mean_mc_travel_dist: 10320.7611, mean_rewards: 68.2579, total_rewards: 4246.5737, mean_steps: 93.8100, mean_ecr: 0.0416 mean_entropies: 2.8435, took: 189.3944s
2022-07-31 22:49:37,820 [INFO] 	Process 1: Batch 199/10000, mean_policy_losses: -25.196, mean_net_lifetime: 7168.0123, mean_mc_travel_dist: 11220.0890, mean_rewards: 67.5111, total_rewards: 4929.9548, mean_steps: 109.4800, mean_ecr: 0.0407 mean_entropies: 2.9334, took: 204.0590s
2022-07-31 22:52:54,037 [INFO] 	Process 1: Batch 299/10000, mean_policy_losses: -44.485, mean_net_lifetime: 7135.4510, mean_mc_travel_dist: 10571.8745, mean_rewards: 65.8023, total_rewards: 5024.4293, mean_steps: 108.2700, mean_ecr: 0.0396 mean_entropies: 2.8646, took: 196.2172s
2022-07-31 22:57:23,321 [INFO] 	Process 1: Batch 399/10000, mean_policy_losses: 8.773, mean_net_lifetime: 9973.3141, mean_mc_travel_dist: 14887.0977, mean_rewards: 74.2991, total_rewards: 7001.0847, mean_steps: 146.4500, mean_ecr: 0.0391 mean_entropies: 2.8237, took: 269.2850s
2022-07-31 23:01:32,895 [INFO] 	Process 1: Batch 499/10000, mean_policy_losses: -14.064, mean_net_lifetime: 8524.4800, mean_mc_travel_dist: 12713.5811, mean_rewards: 66.5926, total_rewards: 5987.8117, mean_steps: 134.7800, mean_ecr: 0.0382 mean_entropies: 2.7889, took: 249.5738s
2022-07-31 23:06:02,843 [INFO] 	Process 1: Batch 599/10000, mean_policy_losses: -19.445, mean_net_lifetime: 10110.1370, mean_mc_travel_dist: 13708.1274, mean_rewards: 73.8281, total_rewards: 7371.6229, mean_steps: 146.0100, mean_ecr: 0.0411 mean_entropies: 2.7607, took: 269.9475s
2022-07-31 23:09:58,507 [INFO] 	Process 1: Batch 699/10000, mean_policy_losses: 34.710, mean_net_lifetime: 7851.6555, mean_mc_travel_dist: 11967.2575, mean_rewards: 71.0390, total_rewards: 5461.6559, mean_steps: 129.4800, mean_ecr: 0.0397 mean_entropies: 2.6869, took: 235.6645s
2022-07-31 23:15:00,363 [INFO] 	Process 1: Batch 799/10000, mean_policy_losses: 28.475, mean_net_lifetime: 11394.4177, mean_mc_travel_dist: 15648.0723, mean_rewards: 82.6842, total_rewards: 8268.2166, mean_steps: 164.6400, mean_ecr: 0.0404 mean_entropies: 2.6498, took: 301.8560s
2022-07-31 23:19:17,636 [INFO] 	Process 1: Batch 899/10000, mean_policy_losses: -6.628, mean_net_lifetime: 10394.0824, mean_mc_travel_dist: 13107.8035, mean_rewards: 85.9085, total_rewards: 7774.0330, mean_steps: 141.5100, mean_ecr: 0.0416 mean_entropies: 2.6579, took: 257.2736s
2022-07-31 23:21:52,958 [INFO] 	Process 1: Batch 999/10000, mean_policy_losses: -23.560, mean_net_lifetime: 5892.7802, mean_mc_travel_dist: 7210.7083, mean_rewards: 77.1586, total_rewards: 4451.6172, mean_steps: 80.0900, mean_ecr: 0.0403 mean_entropies: 2.5979, took: 155.3204s
2022-07-31 23:24:21,471 [INFO] 	Process 1: Batch 1099/10000, mean_policy_losses: -69.726, mean_net_lifetime: 5601.4483, mean_mc_travel_dist: 6799.6179, mean_rewards: 78.9382, total_rewards: 4243.6879, mean_steps: 75.7800, mean_ecr: 0.0408 mean_entropies: 2.4994, took: 148.5139s
2022-07-31 23:26:39,937 [INFO] 	Process 1: Batch 1199/10000, mean_policy_losses: -68.844, mean_net_lifetime: 5637.5173, mean_mc_travel_dist: 6798.4956, mean_rewards: 81.3997, total_rewards: 4279.5679, mean_steps: 75.2600, mean_ecr: 0.0402 mean_entropies: 2.4262, took: 138.4670s
2022-07-31 23:28:57,428 [INFO] 	Process 1: Batch 1299/10000, mean_policy_losses: -68.101, mean_net_lifetime: 5675.4378, mean_mc_travel_dist: 6548.1704, mean_rewards: 84.0371, total_rewards: 4367.3826, mean_steps: 72.6900, mean_ecr: 0.0414 mean_entropies: 2.3922, took: 137.4893s
2022-07-31 23:31:25,512 [INFO] 	Process 1: Batch 1399/10000, mean_policy_losses: -72.855, mean_net_lifetime: 6209.4073, mean_mc_travel_dist: 7067.0506, mean_rewards: 84.5287, total_rewards: 4797.0785, mean_steps: 79.4200, mean_ecr: 0.0402 mean_entropies: 2.3775, took: 148.0848s
2022-07-31 23:34:00,505 [INFO] 	Process 1: Batch 1499/10000, mean_policy_losses: -31.442, mean_net_lifetime: 6190.7430, mean_mc_travel_dist: 7398.7557, mean_rewards: 81.4340, total_rewards: 4711.7765, mean_steps: 82.9200, mean_ecr: 0.0391 mean_entropies: 2.3050, took: 154.9929s
2022-07-31 23:36:43,241 [INFO] 	Process 1: Batch 1599/10000, mean_policy_losses: -36.439, mean_net_lifetime: 6616.7667, mean_mc_travel_dist: 7744.8022, mean_rewards: 81.6235, total_rewards: 5068.6084, mean_steps: 87.7500, mean_ecr: 0.0390 mean_entropies: 2.2441, took: 162.7357s
2022-07-31 23:39:07,433 [INFO] 	Process 1: Batch 1699/10000, mean_policy_losses: -29.779, mean_net_lifetime: 6143.9349, mean_mc_travel_dist: 6902.7105, mean_rewards: 86.3626, total_rewards: 4764.8691, mean_steps: 77.5000, mean_ecr: 0.0412 mean_entropies: 2.1929, took: 144.1922s
2022-07-31 23:41:28,827 [INFO] 	Process 1: Batch 1799/10000, mean_policy_losses: -84.706, mean_net_lifetime: 6006.9484, mean_mc_travel_dist: 6820.7451, mean_rewards: 86.2021, total_rewards: 4642.7994, mean_steps: 75.4200, mean_ecr: 0.0401 mean_entropies: 2.1737, took: 141.3932s
2022-07-31 23:43:58,348 [INFO] 	Process 1: Batch 1899/10000, mean_policy_losses: -43.278, mean_net_lifetime: 6289.3628, mean_mc_travel_dist: 6970.7983, mean_rewards: 86.1874, total_rewards: 4895.9488, mean_steps: 78.3400, mean_ecr: 0.0397 mean_entropies: 2.1939, took: 149.5222s
2022-07-31 23:46:10,236 [INFO] 	Process 1: Batch 1999/10000, mean_policy_losses: -49.549, mean_net_lifetime: 5872.4313, mean_mc_travel_dist: 6312.5826, mean_rewards: 90.8871, total_rewards: 4611.7140, mean_steps: 71.1600, mean_ecr: 0.0426 mean_entropies: 2.0632, took: 131.8867s
2022-07-31 23:48:23,356 [INFO] 	Process 1: Batch 2099/10000, mean_policy_losses: -58.446, mean_net_lifetime: 5984.1965, mean_mc_travel_dist: 6385.6835, mean_rewards: 90.5151, total_rewards: 4708.1573, mean_steps: 70.9000, mean_ecr: 0.0412 mean_entropies: 2.0931, took: 133.1209s
2022-07-31 23:50:44,820 [INFO] 	Process 1: Batch 2199/10000, mean_policy_losses: -79.953, mean_net_lifetime: 6222.6694, mean_mc_travel_dist: 6695.7542, mean_rewards: 89.2522, total_rewards: 4884.5093, mean_steps: 75.3100, mean_ecr: 0.0399 mean_entropies: 2.1591, took: 141.4627s
2022-07-31 23:52:59,617 [INFO] 	Process 1: Batch 2299/10000, mean_policy_losses: -45.285, mean_net_lifetime: 6170.2144, mean_mc_travel_dist: 6590.3699, mean_rewards: 91.5649, total_rewards: 4854.3114, mean_steps: 72.3100, mean_ecr: 0.0404 mean_entropies: 2.1359, took: 134.7987s
2022-07-31 23:55:15,353 [INFO] 	Process 1: Batch 2399/10000, mean_policy_losses: -28.295, mean_net_lifetime: 6264.3068, mean_mc_travel_dist: 6557.4329, mean_rewards: 93.1693, total_rewards: 4953.4030, mean_steps: 73.0600, mean_ecr: 0.0406 mean_entropies: 2.1037, took: 135.7359s
2022-07-31 23:57:20,974 [INFO] 	Process 1: Batch 2499/10000, mean_policy_losses: -72.981, mean_net_lifetime: 6179.5969, mean_mc_travel_dist: 6129.4689, mean_rewards: 98.8193, total_rewards: 4955.7808, mean_steps: 67.4000, mean_ecr: 0.0430 mean_entropies: 2.0212, took: 125.6199s
2022-07-31 23:59:50,769 [INFO] 	Process 1: Batch 2599/10000, mean_policy_losses: -29.110, mean_net_lifetime: 6315.7169, mean_mc_travel_dist: 7406.1966, mean_rewards: 84.7517, total_rewards: 4834.7064, mean_steps: 81.7800, mean_ecr: 0.0375 mean_entropies: 2.1407, took: 149.7950s
2022-08-01 00:02:06,069 [INFO] 	Process 1: Batch 2699/10000, mean_policy_losses: -43.121, mean_net_lifetime: 6126.7000, mean_mc_travel_dist: 6744.9878, mean_rewards: 92.1191, total_rewards: 4778.6898, mean_steps: 72.4300, mean_ecr: 0.0392 mean_entropies: 2.0163, took: 135.3006s
2022-08-01 00:04:23,704 [INFO] 	Process 1: Batch 2799/10000, mean_policy_losses: -53.124, mean_net_lifetime: 6370.0915, mean_mc_travel_dist: 6482.8559, mean_rewards: 95.3188, total_rewards: 5073.8714, mean_steps: 71.8000, mean_ecr: 0.0405 mean_entropies: 2.0092, took: 137.6351s
2022-08-01 00:06:38,619 [INFO] 	Process 1: Batch 2899/10000, mean_policy_losses: -62.673, mean_net_lifetime: 6559.4261, mean_mc_travel_dist: 6577.7680, mean_rewards: 96.2014, total_rewards: 5244.1067, mean_steps: 72.1800, mean_ecr: 0.0405 mean_entropies: 2.0491, took: 134.9144s
2022-08-01 00:08:55,941 [INFO] 	Process 1: Batch 2999/10000, mean_policy_losses: -37.982, mean_net_lifetime: 6229.5867, mean_mc_travel_dist: 6668.8234, mean_rewards: 94.5741, total_rewards: 4896.5640, mean_steps: 72.7200, mean_ecr: 0.0401 mean_entropies: 1.9954, took: 137.3220s
2022-08-01 00:11:06,840 [INFO] 	Process 1: Batch 3099/10000, mean_policy_losses: -90.286, mean_net_lifetime: 6356.8001, mean_mc_travel_dist: 6379.6093, mean_rewards: 100.8732, total_rewards: 5081.2540, mean_steps: 69.3800, mean_ecr: 0.0410 mean_entropies: 1.9679, took: 130.9002s
2022-08-01 00:13:19,904 [INFO] 	Process 1: Batch 3199/10000, mean_policy_losses: -79.082, mean_net_lifetime: 6430.8074, mean_mc_travel_dist: 6378.9908, mean_rewards: 98.0410, total_rewards: 5155.3114, mean_steps: 70.4100, mean_ecr: 0.0409 mean_entropies: 1.9298, took: 133.0631s
2022-08-01 00:15:29,656 [INFO] 	Process 1: Batch 3299/10000, mean_policy_losses: -85.681, mean_net_lifetime: 6094.0651, mean_mc_travel_dist: 6230.8295, mean_rewards: 99.0242, total_rewards: 4848.9665, mean_steps: 69.1900, mean_ecr: 0.0418 mean_entropies: 1.9106, took: 129.7509s
2022-08-01 00:17:43,792 [INFO] 	Process 1: Batch 3399/10000, mean_policy_losses: -108.629, mean_net_lifetime: 6377.1256, mean_mc_travel_dist: 6478.6858, mean_rewards: 96.1922, total_rewards: 5081.3885, mean_steps: 71.9200, mean_ecr: 0.0403 mean_entropies: 1.8905, took: 134.1376s
2022-08-01 00:19:54,138 [INFO] 	Process 1: Batch 3499/10000, mean_policy_losses: -61.002, mean_net_lifetime: 6517.8505, mean_mc_travel_dist: 6349.7678, mean_rewards: 100.1901, total_rewards: 5248.7922, mean_steps: 70.2400, mean_ecr: 0.0411 mean_entropies: 1.8206, took: 130.3449s
2022-08-01 00:22:04,281 [INFO] 	Process 1: Batch 3599/10000, mean_policy_losses: -53.767, mean_net_lifetime: 6438.4260, mean_mc_travel_dist: 6308.8301, mean_rewards: 99.8437, total_rewards: 5177.5916, mean_steps: 68.5500, mean_ecr: 0.0411 mean_entropies: 1.8275, took: 130.1426s
2022-08-01 00:24:16,816 [INFO] 	Process 1: Batch 3699/10000, mean_policy_losses: -62.563, mean_net_lifetime: 6174.9402, mean_mc_travel_dist: 6281.4895, mean_rewards: 100.7482, total_rewards: 4919.5653, mean_steps: 68.6000, mean_ecr: 0.0414 mean_entropies: 1.8134, took: 132.5370s
2022-08-01 00:26:30,733 [INFO] 	Process 1: Batch 3799/10000, mean_policy_losses: -68.328, mean_net_lifetime: 6494.1940, mean_mc_travel_dist: 6607.0529, mean_rewards: 98.4102, total_rewards: 5173.2125, mean_steps: 71.5100, mean_ecr: 0.0397 mean_entropies: 1.8564, took: 133.9164s
2022-08-01 00:28:34,265 [INFO] 	Process 1: Batch 3899/10000, mean_policy_losses: -82.282, mean_net_lifetime: 6386.8668, mean_mc_travel_dist: 6029.6698, mean_rewards: 107.9549, total_rewards: 5181.9616, mean_steps: 65.2000, mean_ecr: 0.0426 mean_entropies: 1.7838, took: 123.5323s
2022-08-01 00:30:44,191 [INFO] 	Process 1: Batch 3999/10000, mean_policy_losses: -77.104, mean_net_lifetime: 6270.8324, mean_mc_travel_dist: 6293.7446, mean_rewards: 101.0150, total_rewards: 5013.3634, mean_steps: 68.5800, mean_ecr: 0.0413 mean_entropies: 1.7749, took: 129.9251s
2022-08-01 00:32:56,612 [INFO] 	Process 1: Batch 4099/10000, mean_policy_losses: -65.484, mean_net_lifetime: 6367.5104, mean_mc_travel_dist: 6458.7739, mean_rewards: 97.7854, total_rewards: 5075.8719, mean_steps: 70.4100, mean_ecr: 0.0403 mean_entropies: 1.7933, took: 132.4220s
2022-08-01 00:35:13,017 [INFO] 	Process 1: Batch 4199/10000, mean_policy_losses: -48.753, mean_net_lifetime: 6334.4642, mean_mc_travel_dist: 6618.9246, mean_rewards: 98.1981, total_rewards: 5011.6285, mean_steps: 72.2500, mean_ecr: 0.0401 mean_entropies: 1.8208, took: 136.4049s
2022-08-01 00:37:25,519 [INFO] 	Process 1: Batch 4299/10000, mean_policy_losses: -70.586, mean_net_lifetime: 6432.7958, mean_mc_travel_dist: 6385.4103, mean_rewards: 99.9287, total_rewards: 5156.2762, mean_steps: 70.2800, mean_ecr: 0.0405 mean_entropies: 1.7427, took: 132.5024s
2022-08-01 00:39:37,430 [INFO] 	Process 1: Batch 4399/10000, mean_policy_losses: -67.326, mean_net_lifetime: 6544.3806, mean_mc_travel_dist: 6438.2188, mean_rewards: 100.4845, total_rewards: 5256.7369, mean_steps: 71.2200, mean_ecr: 0.0404 mean_entropies: 1.7016, took: 131.9107s
2022-08-01 00:41:48,264 [INFO] 	Process 1: Batch 4499/10000, mean_policy_losses: -113.672, mean_net_lifetime: 6495.2074, mean_mc_travel_dist: 6217.3037, mean_rewards: 102.1075, total_rewards: 5252.3208, mean_steps: 68.9500, mean_ecr: 0.0416 mean_entropies: 1.7438, took: 130.8329s
2022-08-01 00:44:04,350 [INFO] 	Process 1: Batch 4599/10000, mean_policy_losses: -70.514, mean_net_lifetime: 6492.0445, mean_mc_travel_dist: 6361.9492, mean_rewards: 99.4960, total_rewards: 5220.0013, mean_steps: 70.7300, mean_ecr: 0.0407 mean_entropies: 1.7168, took: 136.0864s
2022-08-01 00:46:25,643 [INFO] 	Process 1: Batch 4699/10000, mean_policy_losses: -41.248, mean_net_lifetime: 6219.6808, mean_mc_travel_dist: 6425.5458, mean_rewards: 97.0082, total_rewards: 4935.2606, mean_steps: 70.6400, mean_ecr: 0.0400 mean_entropies: 1.7311, took: 141.2931s
2022-08-01 00:48:52,452 [INFO] 	Process 1: Batch 4799/10000, mean_policy_losses: -95.255, mean_net_lifetime: 6578.0804, mean_mc_travel_dist: 6429.5244, mean_rewards: 101.3584, total_rewards: 5292.8668, mean_steps: 70.3400, mean_ecr: 0.0404 mean_entropies: 1.7242, took: 146.8089s
2022-08-01 00:52:07,377 [INFO] 	Process 1: Batch 4899/10000, mean_policy_losses: -65.544, mean_net_lifetime: 11629.9906, mean_mc_travel_dist: 11457.4238, mean_rewards: 125.9666, total_rewards: 9339.0788, mean_steps: 102.2300, mean_ecr: 0.0412 mean_entropies: 1.5167, took: 194.9257s
2022-08-01 00:54:22,768 [INFO] 	Process 1: Batch 4999/10000, mean_policy_losses: -146.794, mean_net_lifetime: 6224.2695, mean_mc_travel_dist: 6259.0148, mean_rewards: 101.1568, total_rewards: 4972.8723, mean_steps: 71.2700, mean_ecr: 0.0410 mean_entropies: 1.6151, took: 135.3904s
2022-08-01 00:56:37,985 [INFO] 	Process 1: Batch 5099/10000, mean_policy_losses: -92.486, mean_net_lifetime: 6435.0171, mean_mc_travel_dist: 6405.4940, mean_rewards: 99.8624, total_rewards: 5154.8929, mean_steps: 71.3000, mean_ecr: 0.0407 mean_entropies: 1.6840, took: 135.2166s
2022-08-01 00:58:57,960 [INFO] 	Process 1: Batch 5199/10000, mean_policy_losses: -115.744, mean_net_lifetime: 6604.1866, mean_mc_travel_dist: 6471.0960, mean_rewards: 102.7335, total_rewards: 5310.1230, mean_steps: 70.8400, mean_ecr: 0.0401 mean_entropies: 1.6591, took: 139.9756s
2022-08-01 01:01:18,506 [INFO] 	Process 1: Batch 5299/10000, mean_policy_losses: -70.562, mean_net_lifetime: 6573.7224, mean_mc_travel_dist: 6584.2072, mean_rewards: 97.1938, total_rewards: 5257.0675, mean_steps: 72.7200, mean_ecr: 0.0394 mean_entropies: 1.6746, took: 140.5443s
2022-08-01 01:03:45,006 [INFO] 	Process 1: Batch 5399/10000, mean_policy_losses: -74.709, mean_net_lifetime: 6266.9772, mean_mc_travel_dist: 6744.1559, mean_rewards: 94.4556, total_rewards: 4918.1460, mean_steps: 74.6200, mean_ecr: 0.0388 mean_entropies: 1.6780, took: 146.5018s
2022-08-01 01:06:09,041 [INFO] 	Process 1: Batch 5499/10000, mean_policy_losses: -58.408, mean_net_lifetime: 6452.3941, mean_mc_travel_dist: 6578.9698, mean_rewards: 99.0001, total_rewards: 5137.2425, mean_steps: 72.6900, mean_ecr: 0.0396 mean_entropies: 1.6104, took: 144.0346s
2022-08-01 01:08:40,689 [INFO] 	Process 1: Batch 5599/10000, mean_policy_losses: -61.298, mean_net_lifetime: 6443.5315, mean_mc_travel_dist: 6591.2698, mean_rewards: 97.2063, total_rewards: 5125.4171, mean_steps: 72.4800, mean_ecr: 0.0393 mean_entropies: 1.6330, took: 151.6472s
2022-08-01 01:11:01,629 [INFO] 	Process 1: Batch 5699/10000, mean_policy_losses: -52.663, mean_net_lifetime: 6377.5327, mean_mc_travel_dist: 6449.8641, mean_rewards: 100.6624, total_rewards: 5088.5609, mean_steps: 71.1600, mean_ecr: 0.0404 mean_entropies: 1.5624, took: 140.9410s
2022-08-01 01:13:14,233 [INFO] 	Process 1: Batch 5799/10000, mean_policy_losses: -73.036, mean_net_lifetime: 6505.5435, mean_mc_travel_dist: 6262.9692, mean_rewards: 103.7713, total_rewards: 5253.4145, mean_steps: 67.7600, mean_ecr: 0.0409 mean_entropies: 1.5351, took: 132.6043s
2022-08-01 01:15:35,907 [INFO] 	Process 1: Batch 5899/10000, mean_policy_losses: -52.252, mean_net_lifetime: 6484.4398, mean_mc_travel_dist: 6389.4270, mean_rewards: 100.5729, total_rewards: 5207.2427, mean_steps: 71.9900, mean_ecr: 0.0407 mean_entropies: 1.5234, took: 141.6738s
2022-08-01 01:18:02,655 [INFO] 	Process 1: Batch 5999/10000, mean_policy_losses: -102.358, mean_net_lifetime: 6264.7686, mean_mc_travel_dist: 6376.2687, mean_rewards: 100.2763, total_rewards: 4990.2799, mean_steps: 70.8300, mean_ecr: 0.0407 mean_entropies: 1.5220, took: 146.7481s
2022-08-01 01:20:28,735 [INFO] 	Process 1: Batch 6099/10000, mean_policy_losses: -82.262, mean_net_lifetime: 6483.1148, mean_mc_travel_dist: 6148.3534, mean_rewards: 106.4787, total_rewards: 5254.1485, mean_steps: 67.3300, mean_ecr: 0.0414 mean_entropies: 1.5051, took: 146.0799s
2022-08-01 01:22:57,944 [INFO] 	Process 1: Batch 6199/10000, mean_policy_losses: -72.209, mean_net_lifetime: 6645.2158, mean_mc_travel_dist: 6289.8019, mean_rewards: 104.9424, total_rewards: 5387.4742, mean_steps: 68.4000, mean_ecr: 0.0408 mean_entropies: 1.5362, took: 149.2079s
2022-08-01 01:26:42,979 [INFO] 	Process 1: Batch 6299/10000, mean_policy_losses: -103.043, mean_net_lifetime: 9472.4980, mean_mc_travel_dist: 10378.2826, mean_rewards: 106.3604, total_rewards: 7397.6225, mean_steps: 104.1400, mean_ecr: 0.0393 mean_entropies: 1.5193, took: 225.0352s
2022-08-01 01:29:18,966 [INFO] 	Process 1: Batch 6399/10000, mean_policy_losses: -58.487, mean_net_lifetime: 6368.1696, mean_mc_travel_dist: 6564.9317, mean_rewards: 98.3654, total_rewards: 5055.4134, mean_steps: 71.6600, mean_ecr: 0.0395 mean_entropies: 1.5822, took: 155.9864s
2022-08-01 01:31:55,306 [INFO] 	Process 1: Batch 6499/10000, mean_policy_losses: -62.837, mean_net_lifetime: 6366.0998, mean_mc_travel_dist: 6344.3461, mean_rewards: 97.7479, total_rewards: 5097.5796, mean_steps: 71.3200, mean_ecr: 0.0408 mean_entropies: 1.5330, took: 156.3395s
2022-08-01 01:34:22,552 [INFO] 	Process 1: Batch 6599/10000, mean_policy_losses: -37.875, mean_net_lifetime: 6554.4187, mean_mc_travel_dist: 6339.6159, mean_rewards: 102.9764, total_rewards: 5288.0860, mean_steps: 68.2100, mean_ecr: 0.0407 mean_entropies: 1.5245, took: 147.2471s
2022-08-01 01:36:50,592 [INFO] 	Process 1: Batch 6699/10000, mean_policy_losses: -53.879, mean_net_lifetime: 6568.6921, mean_mc_travel_dist: 6631.1590, mean_rewards: 99.5180, total_rewards: 5243.0639, mean_steps: 71.6200, mean_ecr: 0.0394 mean_entropies: 1.4877, took: 148.0392s
2022-08-01 01:39:26,341 [INFO] 	Process 1: Batch 6799/10000, mean_policy_losses: -87.563, mean_net_lifetime: 6449.0663, mean_mc_travel_dist: 6666.8277, mean_rewards: 96.3004, total_rewards: 5116.2891, mean_steps: 74.4400, mean_ecr: 0.0388 mean_entropies: 1.5332, took: 155.7492s
2022-08-01 01:41:39,405 [INFO] 	Process 1: Batch 6899/10000, mean_policy_losses: -61.952, mean_net_lifetime: 6672.4003, mean_mc_travel_dist: 6005.2237, mean_rewards: 108.6082, total_rewards: 5472.0052, mean_steps: 65.8800, mean_ecr: 0.0419 mean_entropies: 1.4503, took: 133.0658s
2022-08-01 01:43:53,849 [INFO] 	Process 1: Batch 6999/10000, mean_policy_losses: -74.738, mean_net_lifetime: 6458.9359, mean_mc_travel_dist: 6402.8378, mean_rewards: 103.6170, total_rewards: 5179.6322, mean_steps: 69.0200, mean_ecr: 0.0400 mean_entropies: 1.4763, took: 134.4441s
2022-08-01 01:46:56,831 [INFO] 	Process 1: Batch 7099/10000, mean_policy_losses: -79.422, mean_net_lifetime: 8683.3649, mean_mc_travel_dist: 9251.1248, mean_rewards: 116.6238, total_rewards: 6834.3119, mean_steps: 92.9100, mean_ecr: 0.0402 mean_entropies: 1.3654, took: 182.9812s
2022-08-01 01:53:49,469 [INFO] 	Process 1: Batch 7199/10000, mean_policy_losses: -55.678, mean_net_lifetime: 21844.0528, mean_mc_travel_dist: 23099.6554, mean_rewards: 162.5577, total_rewards: 17225.0480, mean_steps: 212.6500, mean_ecr: 0.0398 mean_entropies: 0.9819, took: 412.6385s
2022-08-01 02:00:16,246 [INFO] 	Process 1: Batch 7299/10000, mean_policy_losses: -81.599, mean_net_lifetime: 18461.9482, mean_mc_travel_dist: 21345.8038, mean_rewards: 183.9691, total_rewards: 14193.6194, mean_steps: 196.9800, mean_ecr: 0.0390 mean_entropies: 0.8885, took: 386.7718s
2022-08-01 02:07:49,739 [INFO] 	Process 1: Batch 7399/10000, mean_policy_losses: -115.367, mean_net_lifetime: 24327.2607, mean_mc_travel_dist: 23833.1308, mean_rewards: 178.7206, total_rewards: 19561.3534, mean_steps: 239.9700, mean_ecr: 0.0388 mean_entropies: 0.9184, took: 453.4978s
2022-08-01 02:15:16,812 [INFO] 	Process 1: Batch 7499/10000, mean_policy_losses: -79.788, mean_net_lifetime: 25602.0806, mean_mc_travel_dist: 24655.6491, mean_rewards: 189.5342, total_rewards: 20672.6559, mean_steps: 241.6500, mean_ecr: 0.0406 mean_entropies: 0.8369, took: 447.0723s
2022-08-01 02:22:50,698 [INFO] 	Process 1: Batch 7599/10000, mean_policy_losses: -106.894, mean_net_lifetime: 23355.0207, mean_mc_travel_dist: 21912.0100, mean_rewards: 189.2343, total_rewards: 18972.7496, mean_steps: 231.7200, mean_ecr: 0.0405 mean_entropies: 0.8699, took: 453.8869s
2022-08-01 02:31:20,326 [INFO] 	Process 1: Batch 7699/10000, mean_policy_losses: -110.435, mean_net_lifetime: 26190.2564, mean_mc_travel_dist: 27055.5559, mean_rewards: 180.2785, total_rewards: 20780.1953, mean_steps: 278.3000, mean_ecr: 0.0407 mean_entropies: 0.8753, took: 509.6284s
2022-08-01 02:37:29,615 [INFO] 	Process 1: Batch 7799/10000, mean_policy_losses: -100.430, mean_net_lifetime: 20847.8653, mean_mc_travel_dist: 19187.9387, mean_rewards: 197.3033, total_rewards: 17011.3500, mean_steps: 199.5900, mean_ecr: 0.0414 mean_entropies: 0.8455, took: 369.2894s
2022-08-01 02:44:25,978 [INFO] 	Process 1: Batch 7899/10000, mean_policy_losses: -95.632, mean_net_lifetime: 21287.6818, mean_mc_travel_dist: 20595.5459, mean_rewards: 184.1187, total_rewards: 17169.2684, mean_steps: 222.8800, mean_ecr: 0.0405 mean_entropies: 0.8763, took: 416.3616s
2022-08-01 02:53:57,951 [INFO] 	Process 1: Batch 7999/10000, mean_policy_losses: -137.414, mean_net_lifetime: 29786.4805, mean_mc_travel_dist: 31354.5881, mean_rewards: 178.5903, total_rewards: 23516.4142, mean_steps: 310.9600, mean_ecr: 0.0384 mean_entropies: 0.8998, took: 571.9690s
2022-08-01 03:01:16,629 [INFO] 	Process 1: Batch 8099/10000, mean_policy_losses: -108.385, mean_net_lifetime: 22900.2915, mean_mc_travel_dist: 20055.6265, mean_rewards: 188.5313, total_rewards: 18890.1689, mean_steps: 228.5300, mean_ecr: 0.0406 mean_entropies: 0.8639, took: 438.6823s
2022-08-01 03:10:43,004 [INFO] 	Process 1: Batch 8199/10000, mean_policy_losses: -86.775, mean_net_lifetime: 34343.4199, mean_mc_travel_dist: 31504.6435, mean_rewards: 189.9747, total_rewards: 28043.0319, mean_steps: 307.0400, mean_ecr: 0.0408 mean_entropies: 0.8312, took: 566.3759s
2022-08-01 03:22:07,666 [INFO] 	Process 1: Batch 8299/10000, mean_policy_losses: -146.528, mean_net_lifetime: 41254.1698, mean_mc_travel_dist: 33649.1084, mean_rewards: 182.9803, total_rewards: 34525.9008, mean_steps: 363.9200, mean_ecr: 0.0410 mean_entropies: 0.8875, took: 684.6607s
2022-08-01 03:32:46,700 [INFO] 	Process 1: Batch 8399/10000, mean_policy_losses: -172.756, mean_net_lifetime: 30913.6587, mean_mc_travel_dist: 30516.8336, mean_rewards: 172.2288, total_rewards: 24810.5565, mean_steps: 344.1500, mean_ecr: 0.0391 mean_entropies: 0.9355, took: 639.0273s
2022-08-01 03:44:00,447 [INFO] 	Process 1: Batch 8499/10000, mean_policy_losses: -104.984, mean_net_lifetime: 42664.7298, mean_mc_travel_dist: 33624.3274, mean_rewards: 183.8985, total_rewards: 35940.7173, mean_steps: 354.6400, mean_ecr: 0.0394 mean_entropies: 0.8342, took: 673.7538s
2022-08-01 03:53:16,183 [INFO] 	Process 1: Batch 8599/10000, mean_policy_losses: -96.392, mean_net_lifetime: 38204.3097, mean_mc_travel_dist: 28199.2042, mean_rewards: 196.9465, total_rewards: 32565.6646, mean_steps: 300.1900, mean_ecr: 0.0414 mean_entropies: 0.7884, took: 555.7373s
2022-08-01 04:04:58,525 [INFO] 	Process 1: Batch 8699/10000, mean_policy_losses: -118.520, mean_net_lifetime: 41833.4805, mean_mc_travel_dist: 34835.6016, mean_rewards: 185.9332, total_rewards: 34866.9540, mean_steps: 378.0400, mean_ecr: 0.0402 mean_entropies: 0.8589, took: 702.3364s
2022-08-01 04:16:09,023 [INFO] 	Process 1: Batch 8799/10000, mean_policy_losses: -137.736, mean_net_lifetime: 41095.0482, mean_mc_travel_dist: 35383.0872, mean_rewards: 190.9979, total_rewards: 34020.9151, mean_steps: 358.0900, mean_ecr: 0.0403 mean_entropies: 0.7945, took: 670.5016s
2022-08-01 04:29:18,378 [INFO] 	Process 1: Batch 8899/10000, mean_policy_losses: -123.755, mean_net_lifetime: 46714.3525, mean_mc_travel_dist: 40895.2422, mean_rewards: 179.4579, total_rewards: 38537.2550, mean_steps: 426.8000, mean_ecr: 0.0394 mean_entropies: 0.8763, took: 789.3566s
2022-08-01 04:40:26,396 [INFO] 	Process 1: Batch 8999/10000, mean_policy_losses: -119.207, mean_net_lifetime: 42758.2520, mean_mc_travel_dist: 34586.3627, mean_rewards: 190.1542, total_rewards: 35842.8422, mean_steps: 355.0300, mean_ecr: 0.0408 mean_entropies: 0.8295, took: 668.0177s
2022-08-01 04:52:44,479 [INFO] 	Process 1: Batch 9099/10000, mean_policy_losses: -145.230, mean_net_lifetime: 46435.2985, mean_mc_travel_dist: 39863.2864, mean_rewards: 181.6486, total_rewards: 38464.4156, mean_steps: 406.9000, mean_ecr: 0.0387 mean_entropies: 0.8615, took: 738.0825s
2022-08-01 05:05:43,174 [INFO] 	Process 1: Batch 9199/10000, mean_policy_losses: -79.402, mean_net_lifetime: 48972.5474, mean_mc_travel_dist: 42154.4009, mean_rewards: 179.8166, total_rewards: 40542.5721, mean_steps: 412.6700, mean_ecr: 0.0406 mean_entropies: 0.8232, took: 778.6959s
2022-08-01 05:17:13,392 [INFO] 	Process 1: Batch 9299/10000, mean_policy_losses: -115.545, mean_net_lifetime: 45280.9566, mean_mc_travel_dist: 34987.0742, mean_rewards: 185.4137, total_rewards: 38285.1757, mean_steps: 381.8700, mean_ecr: 0.0399 mean_entropies: 0.8572, took: 690.2178s
2022-08-01 05:27:12,810 [INFO] 	Process 1: Batch 9399/10000, mean_policy_losses: -106.894, mean_net_lifetime: 42333.8754, mean_mc_travel_dist: 29722.7595, mean_rewards: 192.2900, total_rewards: 36390.0918, mean_steps: 322.1700, mean_ecr: 0.0402 mean_entropies: 0.7745, took: 599.4178s
2022-08-01 05:39:23,975 [INFO] 	Process 1: Batch 9499/10000, mean_policy_losses: -89.534, mean_net_lifetime: 48171.3084, mean_mc_travel_dist: 37362.1113, mean_rewards: 188.2733, total_rewards: 40701.5541, mean_steps: 392.6200, mean_ecr: 0.0406 mean_entropies: 0.8008, took: 731.1652s
2022-08-01 05:49:52,084 [INFO] 	Process 1: Batch 9599/10000, mean_policy_losses: -119.016, mean_net_lifetime: 38273.8069, mean_mc_travel_dist: 29856.4639, mean_rewards: 195.7847, total_rewards: 32304.1574, mean_steps: 321.1200, mean_ecr: 0.0415 mean_entropies: 0.8167, took: 628.1093s
2022-08-01 06:02:27,264 [INFO] 	Process 1: Batch 9699/10000, mean_policy_losses: -83.514, mean_net_lifetime: 50098.6489, mean_mc_travel_dist: 35879.0001, mean_rewards: 191.8676, total_rewards: 42924.8192, mean_steps: 386.8200, mean_ecr: 0.0400 mean_entropies: 0.8028, took: 755.1668s
2022-08-01 06:14:37,555 [INFO] 	Process 1: Batch 9799/10000, mean_policy_losses: -103.122, mean_net_lifetime: 47926.3877, mean_mc_travel_dist: 34869.3694, mean_rewards: 191.6099, total_rewards: 40953.4145, mean_steps: 376.9300, mean_ecr: 0.0406 mean_entropies: 0.8007, took: 730.3037s
2022-08-01 06:25:46,072 [INFO] 	Process 1: Batch 9899/10000, mean_policy_losses: -132.046, mean_net_lifetime: 43469.9770, mean_mc_travel_dist: 33552.0933, mean_rewards: 193.9023, total_rewards: 36759.8786, mean_steps: 350.6900, mean_ecr: 0.0402 mean_entropies: 0.8121, took: 668.5145s
2022-08-01 06:38:01,469 [INFO] 	Process 1: Batch 9999/10000, mean_policy_losses: -125.227, mean_net_lifetime: 47016.0918, mean_mc_travel_dist: 37483.6959, mean_rewards: 185.5675, total_rewards: 39520.1952, mean_steps: 389.5800, mean_ecr: 0.0396 mean_entropies: 0.8421, took: 735.3927s
2022-08-01 07:41:09,146 [INFO] Process 1: Epoch 2: mean_policy_losses: -73.145, mean_net_lifetime: 15337.6821, mean_mc_travel_dist: 14232.4560, mean_entropies: 1.6416, m_net_lifetime_valid: 45282.5769, took: 32284.7816s, (282.1495 / 100 batches)

2022-08-01 07:41:09,147 [INFO] Process 1: Start epoch 3
2022-08-01 07:44:23,082 [INFO] 	Process 1: Batch 99/10000, mean_policy_losses: 75.309, mean_net_lifetime: 7084.0916, mean_mc_travel_dist: 12263.8353, mean_rewards: 64.0002, total_rewards: 4637.5201, mean_steps: 114.6000, mean_ecr: 0.0395 mean_entropies: 2.9405, took: 193.9290s
2022-08-01 07:47:59,186 [INFO] 	Process 1: Batch 199/10000, mean_policy_losses: -29.273, mean_net_lifetime: 7525.7829, mean_mc_travel_dist: 12129.8388, mean_rewards: 65.1143, total_rewards: 5108.3838, mean_steps: 118.4900, mean_ecr: 0.0386 mean_entropies: 2.8462, took: 216.1063s
2022-08-01 07:50:23,298 [INFO] 	Process 1: Batch 299/10000, mean_policy_losses: -1.231, mean_net_lifetime: 4932.8144, mean_mc_travel_dist: 7640.2130, mean_rewards: 63.4294, total_rewards: 3407.2942, mean_steps: 80.1100, mean_ecr: 0.0399 mean_entropies: 2.7553, took: 144.1092s
2022-08-01 07:54:15,174 [INFO] 	Process 1: Batch 399/10000, mean_policy_losses: 13.204, mean_net_lifetime: 7367.8715, mean_mc_travel_dist: 11488.4793, mean_rewards: 66.5916, total_rewards: 5074.2902, mean_steps: 121.6100, mean_ecr: 0.0397 mean_entropies: 2.7874, took: 231.8780s
2022-08-01 07:59:17,868 [INFO] 	Process 1: Batch 499/10000, mean_policy_losses: -18.147, mean_net_lifetime: 9731.9876, mean_mc_travel_dist: 13553.0186, mean_rewards: 71.1656, total_rewards: 7027.3451, mean_steps: 150.2000, mean_ecr: 0.0401 mean_entropies: 2.7668, took: 302.6923s
2022-08-01 08:03:13,590 [INFO] 	Process 1: Batch 599/10000, mean_policy_losses: -13.696, mean_net_lifetime: 7823.1713, mean_mc_travel_dist: 10644.9807, mean_rewards: 71.9647, total_rewards: 5695.5853, mean_steps: 115.8200, mean_ecr: 0.0401 mean_entropies: 2.7101, took: 235.7223s
2022-08-01 08:06:29,328 [INFO] 	Process 1: Batch 699/10000, mean_policy_losses: -37.585, mean_net_lifetime: 7537.6047, mean_mc_travel_dist: 9926.5499, mean_rewards: 74.4035, total_rewards: 5555.9178, mean_steps: 104.8500, mean_ecr: 0.0403 mean_entropies: 2.7000, took: 195.7387s
2022-08-01 08:09:33,721 [INFO] 	Process 1: Batch 799/10000, mean_policy_losses: 12.704, mean_net_lifetime: 6470.7890, mean_mc_travel_dist: 8645.2961, mean_rewards: 76.1698, total_rewards: 4743.2186, mean_steps: 95.8100, mean_ecr: 0.0408 mean_entropies: 2.6719, took: 184.3933s
2022-08-01 08:13:07,942 [INFO] 	Process 1: Batch 899/10000, mean_policy_losses: -9.254, mean_net_lifetime: 8185.8793, mean_mc_travel_dist: 10449.6879, mean_rewards: 81.0331, total_rewards: 6097.2026, mean_steps: 114.0700, mean_ecr: 0.0399 mean_entropies: 2.5879, took: 214.2219s
2022-08-01 08:17:24,145 [INFO] 	Process 1: Batch 999/10000, mean_policy_losses: -46.425, mean_net_lifetime: 11288.1532, mean_mc_travel_dist: 13172.1016, mean_rewards: 94.6258, total_rewards: 8655.1319, mean_steps: 140.0600, mean_ecr: 0.0414 mean_entropies: 2.5237, took: 256.2024s
2022-08-01 08:20:18,978 [INFO] 	Process 1: Batch 1099/10000, mean_policy_losses: -6.226, mean_net_lifetime: 6749.4464, mean_mc_travel_dist: 8273.1634, mean_rewards: 81.3080, total_rewards: 5095.4518, mean_steps: 90.8100, mean_ecr: 0.0392 mean_entropies: 2.4852, took: 174.8315s
2022-08-01 08:24:33,799 [INFO] 	Process 1: Batch 1199/10000, mean_policy_losses: -74.064, mean_net_lifetime: 9360.7102, mean_mc_travel_dist: 11761.6070, mean_rewards: 86.8431, total_rewards: 7009.7491, mean_steps: 129.6700, mean_ecr: 0.0392 mean_entropies: 2.3455, took: 254.8203s
2022-08-01 08:29:17,333 [INFO] 	Process 1: Batch 1299/10000, mean_policy_losses: -24.940, mean_net_lifetime: 9770.7421, mean_mc_travel_dist: 12896.6190, mean_rewards: 87.4440, total_rewards: 7191.6740, mean_steps: 145.2700, mean_ecr: 0.0401 mean_entropies: 2.2812, took: 283.5354s
2022-08-01 08:32:10,818 [INFO] 	Process 1: Batch 1399/10000, mean_policy_losses: -75.084, mean_net_lifetime: 7092.2668, mean_mc_travel_dist: 8083.6796, mean_rewards: 88.9382, total_rewards: 5476.1124, mean_steps: 88.9300, mean_ecr: 0.0395 mean_entropies: 2.2281, took: 173.4858s
2022-08-01 08:35:10,511 [INFO] 	Process 1: Batch 1499/10000, mean_policy_losses: -27.556, mean_net_lifetime: 7804.0251, mean_mc_travel_dist: 8354.2661, mean_rewards: 89.3595, total_rewards: 6135.0540, mean_steps: 95.0900, mean_ecr: 0.0412 mean_entropies: 2.2268, took: 179.6927s
2022-08-01 08:38:01,715 [INFO] 	Process 1: Batch 1599/10000, mean_policy_losses: -93.305, mean_net_lifetime: 6834.9897, mean_mc_travel_dist: 7995.5278, mean_rewards: 85.3252, total_rewards: 5236.5212, mean_steps: 89.8500, mean_ecr: 0.0395 mean_entropies: 2.2404, took: 171.2048s
2022-08-01 08:40:24,272 [INFO] 	Process 1: Batch 1699/10000, mean_policy_losses: -41.765, mean_net_lifetime: 6327.7928, mean_mc_travel_dist: 6962.7088, mean_rewards: 86.9188, total_rewards: 4936.7319, mean_steps: 76.4900, mean_ecr: 0.0397 mean_entropies: 2.1781, took: 142.5560s
2022-08-01 08:42:49,640 [INFO] 	Process 1: Batch 1799/10000, mean_policy_losses: -92.566, mean_net_lifetime: 6160.7674, mean_mc_travel_dist: 6945.0959, mean_rewards: 88.2826, total_rewards: 4773.5292, mean_steps: 77.4800, mean_ecr: 0.0402 mean_entropies: 2.0944, took: 145.3685s
2022-08-01 08:45:11,807 [INFO] 	Process 1: Batch 1899/10000, mean_policy_losses: -30.925, mean_net_lifetime: 5987.2112, mean_mc_travel_dist: 6655.5707, mean_rewards: 85.0989, total_rewards: 4656.0970, mean_steps: 75.6100, mean_ecr: 0.0402 mean_entropies: 2.0923, took: 142.1670s
2022-08-01 08:47:42,530 [INFO] 	Process 1: Batch 1999/10000, mean_policy_losses: -48.270, mean_net_lifetime: 6341.7352, mean_mc_travel_dist: 6966.8850, mean_rewards: 86.5697, total_rewards: 4948.8094, mean_steps: 78.8900, mean_ecr: 0.0392 mean_entropies: 2.1710, took: 150.7207s
2022-08-01 08:50:11,032 [INFO] 	Process 1: Batch 2099/10000, mean_policy_losses: -53.868, mean_net_lifetime: 6214.8692, mean_mc_travel_dist: 6817.9991, mean_rewards: 87.0593, total_rewards: 4851.3963, mean_steps: 76.8400, mean_ecr: 0.0395 mean_entropies: 2.1270, took: 148.5043s
2022-08-01 08:52:44,152 [INFO] 	Process 1: Batch 2199/10000, mean_policy_losses: 8.189, mean_net_lifetime: 6431.8296, mean_mc_travel_dist: 6892.4722, mean_rewards: 89.3553, total_rewards: 5053.7487, mean_steps: 76.6000, mean_ecr: 0.0397 mean_entropies: 2.1495, took: 153.1207s
2022-08-01 08:55:09,156 [INFO] 	Process 1: Batch 2299/10000, mean_policy_losses: -62.449, mean_net_lifetime: 6292.3347, mean_mc_travel_dist: 6603.0331, mean_rewards: 93.8190, total_rewards: 4972.4873, mean_steps: 71.8700, mean_ecr: 0.0406 mean_entropies: 2.0773, took: 145.0029s
2022-08-01 08:57:40,926 [INFO] 	Process 1: Batch 2399/10000, mean_policy_losses: -41.943, mean_net_lifetime: 6194.8246, mean_mc_travel_dist: 6682.4263, mean_rewards: 89.6984, total_rewards: 4858.6194, mean_steps: 74.8000, mean_ecr: 0.0398 mean_entropies: 2.0558, took: 151.7698s
2022-08-01 09:00:08,787 [INFO] 	Process 1: Batch 2499/10000, mean_policy_losses: 16.712, mean_net_lifetime: 6110.7881, mean_mc_travel_dist: 6580.0290, mean_rewards: 93.8099, total_rewards: 4795.3942, mean_steps: 73.4900, mean_ecr: 0.0406 mean_entropies: 2.0220, took: 147.8613s
2022-08-01 09:02:26,153 [INFO] 	Process 1: Batch 2599/10000, mean_policy_losses: -60.047, mean_net_lifetime: 6215.5548, mean_mc_travel_dist: 6603.3417, mean_rewards: 94.4901, total_rewards: 4896.9406, mean_steps: 71.8600, mean_ecr: 0.0400 mean_entropies: 2.0385, took: 137.3655s
2022-08-01 09:04:43,720 [INFO] 	Process 1: Batch 2699/10000, mean_policy_losses: -112.040, mean_net_lifetime: 6123.5765, mean_mc_travel_dist: 6524.8260, mean_rewards: 92.9497, total_rewards: 4818.7423, mean_steps: 73.9400, mean_ecr: 0.0403 mean_entropies: 1.9832, took: 137.5682s
2022-08-01 09:06:56,345 [INFO] 	Process 1: Batch 2799/10000, mean_policy_losses: -52.571, mean_net_lifetime: 6328.5874, mean_mc_travel_dist: 6415.7756, mean_rewards: 97.3525, total_rewards: 5045.4322, mean_steps: 71.4300, mean_ecr: 0.0410 mean_entropies: 1.9495, took: 132.6245s
2022-08-01 09:09:03,302 [INFO] 	Process 1: Batch 2899/10000, mean_policy_losses: -96.796, mean_net_lifetime: 6263.5747, mean_mc_travel_dist: 6339.8820, mean_rewards: 99.1605, total_rewards: 4996.0765, mean_steps: 68.0600, mean_ecr: 0.0418 mean_entropies: 1.9616, took: 126.9571s
2022-08-01 09:11:17,798 [INFO] 	Process 1: Batch 2999/10000, mean_policy_losses: -22.871, mean_net_lifetime: 6377.2564, mean_mc_travel_dist: 6449.3618, mean_rewards: 95.5662, total_rewards: 5087.9826, mean_steps: 71.5700, mean_ecr: 0.0408 mean_entropies: 1.9647, took: 134.4967s
2022-08-01 09:13:24,833 [INFO] 	Process 1: Batch 3099/10000, mean_policy_losses: -44.304, mean_net_lifetime: 6458.0612, mean_mc_travel_dist: 6234.2962, mean_rewards: 102.1674, total_rewards: 5211.6735, mean_steps: 68.8200, mean_ecr: 0.0422 mean_entropies: 1.9109, took: 127.0331s
2022-08-01 09:15:47,802 [INFO] 	Process 1: Batch 3199/10000, mean_policy_losses: -59.565, mean_net_lifetime: 6381.5017, mean_mc_travel_dist: 6857.8005, mean_rewards: 90.7649, total_rewards: 5010.4236, mean_steps: 76.5900, mean_ecr: 0.0388 mean_entropies: 1.9929, took: 142.9706s
2022-08-01 09:18:05,270 [INFO] 	Process 1: Batch 3299/10000, mean_policy_losses: -6.317, mean_net_lifetime: 6260.6951, mean_mc_travel_dist: 6651.3113, mean_rewards: 93.1323, total_rewards: 4931.1429, mean_steps: 74.0200, mean_ecr: 0.0394 mean_entropies: 1.9932, took: 137.4673s
2022-08-01 09:20:57,665 [INFO] 	Process 1: Batch 3399/10000, mean_policy_losses: -80.849, mean_net_lifetime: 7472.7075, mean_mc_travel_dist: 7932.2132, mean_rewards: 98.0968, total_rewards: 5886.6670, mean_steps: 88.8800, mean_ecr: 0.0396 mean_entropies: 1.9441, took: 172.3945s
2022-08-01 09:23:15,719 [INFO] 	Process 1: Batch 3499/10000, mean_policy_losses: -77.961, mean_net_lifetime: 6416.0507, mean_mc_travel_dist: 6327.0905, mean_rewards: 102.5905, total_rewards: 5150.8780, mean_steps: 69.3900, mean_ecr: 0.0416 mean_entropies: 1.9403, took: 138.0550s
2022-08-01 09:25:33,469 [INFO] 	Process 1: Batch 3599/10000, mean_policy_losses: -73.950, mean_net_lifetime: 6126.9439, mean_mc_travel_dist: 6421.8345, mean_rewards: 99.5397, total_rewards: 4842.8577, mean_steps: 69.2700, mean_ecr: 0.0409 mean_entropies: 1.8919, took: 137.7483s
2022-08-01 09:27:51,857 [INFO] 	Process 1: Batch 3699/10000, mean_policy_losses: -99.407, mean_net_lifetime: 6448.8660, mean_mc_travel_dist: 6531.6062, mean_rewards: 97.9261, total_rewards: 5142.7878, mean_steps: 71.6800, mean_ecr: 0.0401 mean_entropies: 1.9196, took: 138.3889s
2022-08-01 09:29:57,020 [INFO] 	Process 1: Batch 3799/10000, mean_policy_losses: -12.154, mean_net_lifetime: 6234.6967, mean_mc_travel_dist: 6349.6989, mean_rewards: 100.8465, total_rewards: 4965.0670, mean_steps: 67.1200, mean_ecr: 0.0412 mean_entropies: 1.9130, took: 125.1622s
2022-08-01 09:32:30,491 [INFO] 	Process 1: Batch 3899/10000, mean_policy_losses: -106.068, mean_net_lifetime: 6234.7493, mean_mc_travel_dist: 6624.6588, mean_rewards: 96.6981, total_rewards: 4910.7310, mean_steps: 73.6600, mean_ecr: 0.0396 mean_entropies: 1.8278, took: 153.4695s
2022-08-01 09:35:03,658 [INFO] 	Process 1: Batch 3999/10000, mean_policy_losses: -73.660, mean_net_lifetime: 6764.2630, mean_mc_travel_dist: 6296.7148, mean_rewards: 104.4547, total_rewards: 5506.3924, mean_steps: 69.9000, mean_ecr: 0.0411 mean_entropies: 1.8058, took: 153.1686s
2022-08-01 09:37:38,235 [INFO] 	Process 1: Batch 4099/10000, mean_policy_losses: -70.092, mean_net_lifetime: 6420.5293, mean_mc_travel_dist: 6672.1614, mean_rewards: 95.3906, total_rewards: 5086.4016, mean_steps: 74.0700, mean_ecr: 0.0392 mean_entropies: 1.8500, took: 154.5779s
2022-08-01 09:40:05,311 [INFO] 	Process 1: Batch 4199/10000, mean_policy_losses: -134.554, mean_net_lifetime: 6156.3896, mean_mc_travel_dist: 6181.1328, mean_rewards: 104.4811, total_rewards: 4920.8003, mean_steps: 66.5300, mean_ecr: 0.0416 mean_entropies: 1.7905, took: 147.0755s
2022-08-01 09:42:44,885 [INFO] 	Process 1: Batch 4299/10000, mean_policy_losses: -60.358, mean_net_lifetime: 6468.7978, mean_mc_travel_dist: 6292.9538, mean_rewards: 102.1086, total_rewards: 5211.0063, mean_steps: 69.9200, mean_ecr: 0.0411 mean_entropies: 1.8038, took: 159.5740s
2022-08-01 09:45:25,709 [INFO] 	Process 1: Batch 4399/10000, mean_policy_losses: -105.472, mean_net_lifetime: 6489.6805, mean_mc_travel_dist: 6181.5503, mean_rewards: 105.1392, total_rewards: 5253.3705, mean_steps: 68.4600, mean_ecr: 0.0416 mean_entropies: 1.7455, took: 160.8224s
2022-08-01 09:48:10,086 [INFO] 	Process 1: Batch 4499/10000, mean_policy_losses: -78.749, mean_net_lifetime: 6311.0183, mean_mc_travel_dist: 6551.5238, mean_rewards: 97.1803, total_rewards: 5000.8674, mean_steps: 71.7500, mean_ecr: 0.0398 mean_entropies: 1.7848, took: 164.3782s
2022-08-01 09:50:54,078 [INFO] 	Process 1: Batch 4599/10000, mean_policy_losses: -28.148, mean_net_lifetime: 6018.6633, mean_mc_travel_dist: 6150.2810, mean_rewards: 101.4421, total_rewards: 4790.5799, mean_steps: 68.2400, mean_ecr: 0.0416 mean_entropies: 1.7242, took: 163.9910s
2022-08-01 09:53:34,562 [INFO] 	Process 1: Batch 4699/10000, mean_policy_losses: -26.989, mean_net_lifetime: 6462.5865, mean_mc_travel_dist: 6466.0202, mean_rewards: 99.2398, total_rewards: 5169.6706, mean_steps: 71.1000, mean_ecr: 0.0398 mean_entropies: 1.7462, took: 160.4847s
2022-08-01 09:56:17,795 [INFO] 	Process 1: Batch 4799/10000, mean_policy_losses: -54.942, mean_net_lifetime: 6456.2274, mean_mc_travel_dist: 6445.8028, mean_rewards: 101.0026, total_rewards: 5168.0213, mean_steps: 70.4900, mean_ecr: 0.0404 mean_entropies: 1.7428, took: 163.2350s
2022-08-01 09:58:44,133 [INFO] 	Process 1: Batch 4899/10000, mean_policy_losses: -54.403, mean_net_lifetime: 6275.3268, mean_mc_travel_dist: 6205.9458, mean_rewards: 103.0787, total_rewards: 5034.7851, mean_steps: 67.2500, mean_ecr: 0.0414 mean_entropies: 1.7145, took: 146.3353s
2022-08-01 10:01:21,484 [INFO] 	Process 1: Batch 4999/10000, mean_policy_losses: -101.376, mean_net_lifetime: 6582.7474, mean_mc_travel_dist: 6441.7339, mean_rewards: 102.4283, total_rewards: 5295.0723, mean_steps: 69.4200, mean_ecr: 0.0402 mean_entropies: 1.7409, took: 157.3469s
2022-08-01 10:03:56,536 [INFO] 	Process 1: Batch 5099/10000, mean_policy_losses: -52.916, mean_net_lifetime: 6520.2462, mean_mc_travel_dist: 6421.6563, mean_rewards: 100.9774, total_rewards: 5237.0378, mean_steps: 70.0100, mean_ecr: 0.0404 mean_entropies: 1.6931, took: 155.0572s
2022-08-01 10:06:17,659 [INFO] 	Process 1: Batch 5199/10000, mean_policy_losses: -74.056, mean_net_lifetime: 6274.5191, mean_mc_travel_dist: 6234.4075, mean_rewards: 101.4756, total_rewards: 5028.0875, mean_steps: 67.9400, mean_ecr: 0.0411 mean_entropies: 1.6749, took: 141.1207s
2022-08-01 10:08:52,645 [INFO] 	Process 1: Batch 5299/10000, mean_policy_losses: -50.512, mean_net_lifetime: 6480.8676, mean_mc_travel_dist: 6275.6543, mean_rewards: 101.6736, total_rewards: 5226.9201, mean_steps: 68.9900, mean_ecr: 0.0410 mean_entropies: 1.6794, took: 154.9877s
2022-08-01 10:11:25,771 [INFO] 	Process 1: Batch 5399/10000, mean_policy_losses: -45.873, mean_net_lifetime: 6607.5606, mean_mc_travel_dist: 6221.9069, mean_rewards: 104.4633, total_rewards: 5363.4801, mean_steps: 67.1600, mean_ecr: 0.0411 mean_entropies: 1.6302, took: 153.1257s
2022-08-01 10:14:04,528 [INFO] 	Process 1: Batch 5499/10000, mean_policy_losses: -97.967, mean_net_lifetime: 6416.9172, mean_mc_travel_dist: 6498.1836, mean_rewards: 100.1715, total_rewards: 5117.6647, mean_steps: 70.7200, mean_ecr: 0.0401 mean_entropies: 1.6688, took: 158.7566s
2022-08-01 10:16:25,971 [INFO] 	Process 1: Batch 5599/10000, mean_policy_losses: -56.124, mean_net_lifetime: 6589.2627, mean_mc_travel_dist: 6437.6557, mean_rewards: 99.6468, total_rewards: 5302.0369, mean_steps: 71.1800, mean_ecr: 0.0401 mean_entropies: 1.6337, took: 141.4464s
2022-08-01 10:18:45,421 [INFO] 	Process 1: Batch 5699/10000, mean_policy_losses: -82.399, mean_net_lifetime: 6402.0420, mean_mc_travel_dist: 6488.6905, mean_rewards: 99.6038, total_rewards: 5105.1793, mean_steps: 72.0200, mean_ecr: 0.0404 mean_entropies: 1.6224, took: 139.4478s
2022-08-01 10:21:10,920 [INFO] 	Process 1: Batch 5799/10000, mean_policy_losses: -79.030, mean_net_lifetime: 6471.3704, mean_mc_travel_dist: 6484.8429, mean_rewards: 102.4168, total_rewards: 5175.3676, mean_steps: 69.9600, mean_ecr: 0.0398 mean_entropies: 1.6266, took: 145.4996s
2022-08-01 10:23:35,476 [INFO] 	Process 1: Batch 5899/10000, mean_policy_losses: -70.890, mean_net_lifetime: 6611.5451, mean_mc_travel_dist: 6226.4730, mean_rewards: 106.4411, total_rewards: 5366.8796, mean_steps: 67.2800, mean_ecr: 0.0410 mean_entropies: 1.5608, took: 144.5570s
2022-08-01 10:25:58,705 [INFO] 	Process 1: Batch 5999/10000, mean_policy_losses: -91.144, mean_net_lifetime: 6572.4165, mean_mc_travel_dist: 6149.9298, mean_rewards: 107.2620, total_rewards: 5342.8516, mean_steps: 66.7500, mean_ecr: 0.0414 mean_entropies: 1.5359, took: 143.2283s
2022-08-01 10:28:22,365 [INFO] 	Process 1: Batch 6099/10000, mean_policy_losses: -39.442, mean_net_lifetime: 6658.2935, mean_mc_travel_dist: 6260.8401, mean_rewards: 105.4971, total_rewards: 5406.7852, mean_steps: 67.1600, mean_ecr: 0.0410 mean_entropies: 1.5835, took: 143.6591s
2022-08-01 10:30:53,298 [INFO] 	Process 1: Batch 6199/10000, mean_policy_losses: -79.003, mean_net_lifetime: 6374.5407, mean_mc_travel_dist: 6448.3155, mean_rewards: 101.8767, total_rewards: 5085.5899, mean_steps: 69.8900, mean_ecr: 0.0400 mean_entropies: 1.6062, took: 150.9325s
2022-08-01 10:33:27,553 [INFO] 	Process 1: Batch 6299/10000, mean_policy_losses: -96.288, mean_net_lifetime: 6255.7834, mean_mc_travel_dist: 6294.6967, mean_rewards: 101.1350, total_rewards: 4997.5133, mean_steps: 68.8000, mean_ecr: 0.0410 mean_entropies: 1.5397, took: 154.2529s
2022-08-01 10:36:03,288 [INFO] 	Process 1: Batch 6399/10000, mean_policy_losses: -45.044, mean_net_lifetime: 6567.2482, mean_mc_travel_dist: 6618.3880, mean_rewards: 98.0553, total_rewards: 5244.7174, mean_steps: 73.3700, mean_ecr: 0.0393 mean_entropies: 1.5616, took: 155.7381s
2022-08-01 10:38:35,081 [INFO] 	Process 1: Batch 6499/10000, mean_policy_losses: -98.500, mean_net_lifetime: 6630.6952, mean_mc_travel_dist: 6308.2483, mean_rewards: 106.5071, total_rewards: 5369.1900, mean_steps: 67.9000, mean_ecr: 0.0408 mean_entropies: 1.5332, took: 151.7945s
2022-08-01 10:41:05,687 [INFO] 	Process 1: Batch 6599/10000, mean_policy_losses: -50.309, mean_net_lifetime: 6531.3667, mean_mc_travel_dist: 5902.6557, mean_rewards: 111.1922, total_rewards: 5351.7117, mean_steps: 62.4700, mean_ecr: 0.0426 mean_entropies: 1.4572, took: 150.5986s
2022-08-01 10:43:42,772 [INFO] 	Process 1: Batch 6699/10000, mean_policy_losses: -54.721, mean_net_lifetime: 6577.3746, mean_mc_travel_dist: 6364.1075, mean_rewards: 104.5199, total_rewards: 5305.0939, mean_steps: 68.1700, mean_ecr: 0.0403 mean_entropies: 1.5552, took: 157.0915s
2022-08-01 10:46:18,873 [INFO] 	Process 1: Batch 6799/10000, mean_policy_losses: -55.965, mean_net_lifetime: 6488.5729, mean_mc_travel_dist: 6610.5241, mean_rewards: 100.6534, total_rewards: 5167.6506, mean_steps: 71.3400, mean_ecr: 0.0389 mean_entropies: 1.5466, took: 156.1004s
2022-08-01 10:48:36,018 [INFO] 	Process 1: Batch 6899/10000, mean_policy_losses: -79.402, mean_net_lifetime: 6374.8981, mean_mc_travel_dist: 6134.0790, mean_rewards: 107.0045, total_rewards: 5149.0284, mean_steps: 64.8200, mean_ecr: 0.0416 mean_entropies: 1.4689, took: 137.1450s
2022-08-01 10:51:00,155 [INFO] 	Process 1: Batch 6999/10000, mean_policy_losses: -77.629, mean_net_lifetime: 6482.4254, mean_mc_travel_dist: 6445.7118, mean_rewards: 101.0393, total_rewards: 5193.7139, mean_steps: 70.4400, mean_ecr: 0.0398 mean_entropies: 1.4486, took: 144.1341s
2022-08-01 10:53:16,840 [INFO] 	Process 1: Batch 7099/10000, mean_policy_losses: -58.413, mean_net_lifetime: 6705.2523, mean_mc_travel_dist: 6494.4170, mean_rewards: 102.6935, total_rewards: 5406.3689, mean_steps: 70.1500, mean_ecr: 0.0399 mean_entropies: 1.4642, took: 136.6883s
2022-08-01 10:55:32,931 [INFO] 	Process 1: Batch 7199/10000, mean_policy_losses: -34.819, mean_net_lifetime: 6304.2649, mean_mc_travel_dist: 6430.7893, mean_rewards: 100.2767, total_rewards: 5018.5527, mean_steps: 69.7600, mean_ecr: 0.0403 mean_entropies: 1.4685, took: 136.0912s
2022-08-01 10:57:49,695 [INFO] 	Process 1: Batch 7299/10000, mean_policy_losses: -66.723, mean_net_lifetime: 6440.4433, mean_mc_travel_dist: 6372.5505, mean_rewards: 99.0194, total_rewards: 5166.8133, mean_steps: 71.1600, mean_ecr: 0.0403 mean_entropies: 1.4672, took: 136.7648s
2022-08-01 11:00:07,639 [INFO] 	Process 1: Batch 7399/10000, mean_policy_losses: -50.309, mean_net_lifetime: 6439.1547, mean_mc_travel_dist: 6227.3983, mean_rewards: 104.9762, total_rewards: 5194.3062, mean_steps: 68.3500, mean_ecr: 0.0414 mean_entropies: 1.4520, took: 137.9434s
2022-08-01 11:02:48,630 [INFO] 	Process 1: Batch 7499/10000, mean_policy_losses: -100.457, mean_net_lifetime: 6529.4983, mean_mc_travel_dist: 6703.8222, mean_rewards: 96.7354, total_rewards: 5188.9901, mean_steps: 74.5000, mean_ecr: 0.0388 mean_entropies: 1.4489, took: 160.9880s
2022-08-01 11:05:18,072 [INFO] 	Process 1: Batch 7599/10000, mean_policy_losses: -62.184, mean_net_lifetime: 6411.1337, mean_mc_travel_dist: 6388.9305, mean_rewards: 102.2847, total_rewards: 5133.3476, mean_steps: 70.1300, mean_ecr: 0.0399 mean_entropies: 1.3430, took: 149.4456s
2022-08-01 11:07:46,407 [INFO] 	Process 1: Batch 7699/10000, mean_policy_losses: -65.848, mean_net_lifetime: 6310.5818, mean_mc_travel_dist: 6234.4179, mean_rewards: 105.1656, total_rewards: 5064.1377, mean_steps: 68.5100, mean_ecr: 0.0413 mean_entropies: 1.3340, took: 148.3327s
2022-08-01 11:10:26,722 [INFO] 	Process 1: Batch 7799/10000, mean_policy_losses: -77.253, mean_net_lifetime: 6872.2926, mean_mc_travel_dist: 6179.3059, mean_rewards: 109.5492, total_rewards: 5637.2964, mean_steps: 66.7400, mean_ecr: 0.0412 mean_entropies: 1.3005, took: 160.3145s
2022-08-01 11:13:07,874 [INFO] 	Process 1: Batch 7899/10000, mean_policy_losses: -85.663, mean_net_lifetime: 6563.0743, mean_mc_travel_dist: 6351.4889, mean_rewards: 103.5057, total_rewards: 5293.9596, mean_steps: 70.0500, mean_ecr: 0.0403 mean_entropies: 1.3499, took: 161.1527s
2022-08-01 11:15:18,509 [INFO] 	Process 1: Batch 7999/10000, mean_policy_losses: -41.228, mean_net_lifetime: 6416.1899, mean_mc_travel_dist: 6136.5156, mean_rewards: 105.7332, total_rewards: 5189.9917, mean_steps: 65.3100, mean_ecr: 0.0417 mean_entropies: 1.3283, took: 130.6352s
2022-08-01 11:17:27,811 [INFO] 	Process 1: Batch 8099/10000, mean_policy_losses: -77.129, mean_net_lifetime: 6375.1137, mean_mc_travel_dist: 6453.0450, mean_rewards: 102.0821, total_rewards: 5085.3640, mean_steps: 69.5200, mean_ecr: 0.0397 mean_entropies: 1.4033, took: 129.3021s
2022-08-01 11:19:42,049 [INFO] 	Process 1: Batch 8199/10000, mean_policy_losses: -75.786, mean_net_lifetime: 6575.3585, mean_mc_travel_dist: 6541.6211, mean_rewards: 102.0718, total_rewards: 5267.4635, mean_steps: 70.5100, mean_ecr: 0.0395 mean_entropies: 1.3715, took: 134.2395s
2022-08-01 11:21:45,221 [INFO] 	Process 1: Batch 8299/10000, mean_policy_losses: -56.345, mean_net_lifetime: 6663.2051, mean_mc_travel_dist: 6079.8069, mean_rewards: 108.4189, total_rewards: 5447.2437, mean_steps: 66.9900, mean_ecr: 0.0419 mean_entropies: 1.2426, took: 123.1713s
2022-08-01 11:23:55,496 [INFO] 	Process 1: Batch 8399/10000, mean_policy_losses: -28.759, mean_net_lifetime: 6429.0622, mean_mc_travel_dist: 6460.4863, mean_rewards: 99.0745, total_rewards: 5137.4795, mean_steps: 70.6700, mean_ecr: 0.0400 mean_entropies: 1.2820, took: 130.2760s

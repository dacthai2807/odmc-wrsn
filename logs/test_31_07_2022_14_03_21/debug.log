2022-07-31 14:03:21,153 [INFO] Process 3: Begin training phase
2022-07-31 14:03:27,379 [INFO] Process 3: Start epoch 0
2022-07-31 14:06:32,591 [INFO] 	Process 3: Batch 99/10000, mean_policy_losses: 322.500, mean_net_lifetime: 6904.7708, mean_mc_travel_dist: 10554.7949, mean_rewards: 65.5387, total_rewards: 4800.8888, mean_steps: 97.4200, mean_ecr: 0.0403 mean_entropies: 2.9824, took: 185.2048s
2022-07-31 14:09:00,537 [INFO] 	Process 3: Batch 199/10000, mean_policy_losses: -24.828, mean_net_lifetime: 4785.9897, mean_mc_travel_dist: 7775.1725, mean_rewards: 63.7308, total_rewards: 3234.8633, mean_steps: 75.7100, mean_ecr: 0.0419 mean_entropies: 2.9490, took: 147.9462s
2022-07-31 14:11:35,135 [INFO] 	Process 3: Batch 299/10000, mean_policy_losses: -7.396, mean_net_lifetime: 5150.9179, mean_mc_travel_dist: 8156.0882, mean_rewards: 65.4387, total_rewards: 3524.6660, mean_steps: 79.5600, mean_ecr: 0.0414 mean_entropies: 2.9059, took: 154.5987s
2022-07-31 14:14:56,751 [INFO] 	Process 3: Batch 399/10000, mean_policy_losses: 0.710, mean_net_lifetime: 7698.4701, mean_mc_travel_dist: 10489.9365, mean_rewards: 71.2777, total_rewards: 5605.9825, mean_steps: 103.5300, mean_ecr: 0.0426 mean_entropies: 2.8784, took: 201.6161s
2022-07-31 14:18:05,461 [INFO] 	Process 3: Batch 499/10000, mean_policy_losses: -35.311, mean_net_lifetime: 5912.6461, mean_mc_travel_dist: 8871.9526, mean_rewards: 67.2565, total_rewards: 4140.9597, mean_steps: 93.3700, mean_ecr: 0.0410 mean_entropies: 2.7851, took: 188.7094s
2022-07-31 14:22:20,099 [INFO] 	Process 3: Batch 599/10000, mean_policy_losses: 26.952, mean_net_lifetime: 8341.4694, mean_mc_travel_dist: 12486.7904, mean_rewards: 67.4505, total_rewards: 5849.6212, mean_steps: 130.0900, mean_ecr: 0.0393 mean_entropies: 2.7925, took: 254.6377s
2022-07-31 14:26:58,388 [INFO] 	Process 3: Batch 699/10000, mean_policy_losses: -27.410, mean_net_lifetime: 9065.2074, mean_mc_travel_dist: 13252.4257, mean_rewards: 71.4269, total_rewards: 6418.0968, mean_steps: 139.3600, mean_ecr: 0.0408 mean_entropies: 2.7257, took: 278.2897s
2022-07-31 14:32:07,275 [INFO] 	Process 3: Batch 799/10000, mean_policy_losses: -30.237, mean_net_lifetime: 10295.1466, mean_mc_travel_dist: 14867.3340, mean_rewards: 73.0249, total_rewards: 7324.7972, mean_steps: 163.7300, mean_ecr: 0.0395 mean_entropies: 2.6956, took: 308.8875s
2022-07-31 14:36:29,649 [INFO] 	Process 3: Batch 899/10000, mean_policy_losses: -53.067, mean_net_lifetime: 9694.0199, mean_mc_travel_dist: 12721.7834, mean_rewards: 79.1495, total_rewards: 7151.9997, mean_steps: 134.8200, mean_ecr: 0.0403 mean_entropies: 2.7470, took: 262.3720s
2022-07-31 14:40:36,971 [INFO] 	Process 3: Batch 999/10000, mean_policy_losses: 12.052, mean_net_lifetime: 9002.8282, mean_mc_travel_dist: 11805.2295, mean_rewards: 78.5093, total_rewards: 6643.9992, mean_steps: 128.3000, mean_ecr: 0.0402 mean_entropies: 2.6860, took: 247.3243s
2022-07-31 14:43:38,862 [INFO] 	Process 3: Batch 1099/10000, mean_policy_losses: -31.732, mean_net_lifetime: 6364.9203, mean_mc_travel_dist: 8463.5418, mean_rewards: 75.5678, total_rewards: 4675.2908, mean_steps: 92.5100, mean_ecr: 0.0399 mean_entropies: 2.6558, took: 181.8899s
2022-07-31 14:49:14,071 [INFO] 	Process 3: Batch 1199/10000, mean_policy_losses: -16.699, mean_net_lifetime: 11758.4608, mean_mc_travel_dist: 15111.1783, mean_rewards: 80.9325, total_rewards: 8739.6778, mean_steps: 166.0000, mean_ecr: 0.0383 mean_entropies: 2.6133, took: 335.2090s
2022-07-31 14:52:20,430 [INFO] 	Process 3: Batch 1299/10000, mean_policy_losses: -38.676, mean_net_lifetime: 6854.5108, mean_mc_travel_dist: 8470.2545, mean_rewards: 81.0404, total_rewards: 5162.6592, mean_steps: 93.8600, mean_ecr: 0.0415 mean_entropies: 2.5482, took: 186.3578s
2022-07-31 14:55:56,051 [INFO] 	Process 3: Batch 1399/10000, mean_policy_losses: -29.342, mean_net_lifetime: 8181.9208, mean_mc_travel_dist: 9904.8495, mean_rewards: 79.5569, total_rewards: 6201.5943, mean_steps: 110.8700, mean_ecr: 0.0391 mean_entropies: 2.4725, took: 215.6203s
2022-07-31 14:59:29,803 [INFO] 	Process 3: Batch 1499/10000, mean_policy_losses: -41.313, mean_net_lifetime: 8994.1336, mean_mc_travel_dist: 10844.4762, mean_rewards: 86.5287, total_rewards: 6827.2426, mean_steps: 115.0400, mean_ecr: 0.0406 mean_entropies: 2.3259, took: 213.7537s
2022-07-31 15:01:56,916 [INFO] 	Process 3: Batch 1599/10000, mean_policy_losses: -40.898, mean_net_lifetime: 5828.0440, mean_mc_travel_dist: 6821.4288, mean_rewards: 81.2186, total_rewards: 4464.6107, mean_steps: 75.8900, mean_ecr: 0.0414 mean_entropies: 2.3431, took: 147.1119s
2022-07-31 15:04:43,097 [INFO] 	Process 3: Batch 1699/10000, mean_policy_losses: -49.746, mean_net_lifetime: 6485.7914, mean_mc_travel_dist: 7908.6980, mean_rewards: 81.5376, total_rewards: 4905.0946, mean_steps: 87.3500, mean_ecr: 0.0402 mean_entropies: 2.3200, took: 166.1818s
2022-07-31 15:08:32,538 [INFO] 	Process 3: Batch 1799/10000, mean_policy_losses: -64.733, mean_net_lifetime: 9640.9095, mean_mc_travel_dist: 11353.3777, mean_rewards: 93.4947, total_rewards: 7370.8443, mean_steps: 120.7500, mean_ecr: 0.0414 mean_entropies: 2.2870, took: 229.4416s
2022-07-31 15:13:17,762 [INFO] 	Process 3: Batch 1899/10000, mean_policy_losses: -55.601, mean_net_lifetime: 10523.2256, mean_mc_travel_dist: 12873.1689, mean_rewards: 87.9240, total_rewards: 7949.1072, mean_steps: 142.6600, mean_ecr: 0.0395 mean_entropies: 2.2718, took: 285.2236s
2022-07-31 15:18:50,288 [INFO] 	Process 3: Batch 1999/10000, mean_policy_losses: -46.722, mean_net_lifetime: 14010.6439, mean_mc_travel_dist: 15905.7452, mean_rewards: 93.1445, total_rewards: 10830.2683, mean_steps: 172.4100, mean_ecr: 0.0399 mean_entropies: 2.2272, took: 332.5264s
2022-07-31 15:22:35,142 [INFO] 	Process 3: Batch 2099/10000, mean_policy_losses: -41.478, mean_net_lifetime: 8600.7561, mean_mc_travel_dist: 10645.8180, mean_rewards: 85.1512, total_rewards: 6472.0079, mean_steps: 117.1000, mean_ecr: 0.0400 mean_entropies: 2.1978, took: 224.8539s
2022-07-31 15:25:16,620 [INFO] 	Process 3: Batch 2199/10000, mean_policy_losses: -37.712, mean_net_lifetime: 7119.4326, mean_mc_travel_dist: 7821.6561, mean_rewards: 91.9375, total_rewards: 5555.7473, mean_steps: 84.5400, mean_ecr: 0.0414 mean_entropies: 2.1334, took: 161.4775s
2022-07-31 15:27:38,940 [INFO] 	Process 3: Batch 2299/10000, mean_policy_losses: -25.902, mean_net_lifetime: 6022.2771, mean_mc_travel_dist: 6354.6903, mean_rewards: 88.5971, total_rewards: 4752.0393, mean_steps: 72.4500, mean_ecr: 0.0421 mean_entropies: 2.0710, took: 142.3180s
2022-07-31 15:30:22,357 [INFO] 	Process 3: Batch 2399/10000, mean_policy_losses: -49.466, mean_net_lifetime: 6193.9751, mean_mc_travel_dist: 7631.7853, mean_rewards: 78.4497, total_rewards: 4668.1020, mean_steps: 85.1100, mean_ecr: 0.0377 mean_entropies: 2.1829, took: 163.4198s
2022-07-31 15:32:51,971 [INFO] 	Process 3: Batch 2499/10000, mean_policy_losses: -31.575, mean_net_lifetime: 6172.5374, mean_mc_travel_dist: 6855.0807, mean_rewards: 85.9298, total_rewards: 4801.8002, mean_steps: 77.4400, mean_ecr: 0.0406 mean_entropies: 2.0940, took: 149.6145s
2022-07-31 15:35:26,374 [INFO] 	Process 3: Batch 2599/10000, mean_policy_losses: -38.965, mean_net_lifetime: 6428.6908, mean_mc_travel_dist: 7062.2845, mean_rewards: 88.9015, total_rewards: 5016.9146, mean_steps: 78.8600, mean_ecr: 0.0406 mean_entropies: 2.0166, took: 154.4020s
2022-07-31 15:37:55,609 [INFO] 	Process 3: Batch 2699/10000, mean_policy_losses: -36.924, mean_net_lifetime: 6050.9036, mean_mc_travel_dist: 7009.6760, mean_rewards: 86.8216, total_rewards: 4649.2155, mean_steps: 76.2400, mean_ecr: 0.0397 mean_entropies: 2.1258, took: 149.2337s
2022-07-31 15:40:28,728 [INFO] 	Process 3: Batch 2799/10000, mean_policy_losses: -4.781, mean_net_lifetime: 6309.0658, mean_mc_travel_dist: 6708.5056, mean_rewards: 89.3644, total_rewards: 4967.5326, mean_steps: 75.5300, mean_ecr: 0.0401 mean_entropies: 2.0472, took: 153.1169s
2022-07-31 15:42:57,967 [INFO] 	Process 3: Batch 2899/10000, mean_policy_losses: -65.141, mean_net_lifetime: 6364.9592, mean_mc_travel_dist: 6766.7628, mean_rewards: 91.5498, total_rewards: 5011.8826, mean_steps: 74.4900, mean_ecr: 0.0401 mean_entropies: 2.0726, took: 149.2409s
2022-07-31 15:45:23,509 [INFO] 	Process 3: Batch 2999/10000, mean_policy_losses: -53.225, mean_net_lifetime: 6275.6693, mean_mc_travel_dist: 6588.6243, mean_rewards: 93.6762, total_rewards: 4959.0924, mean_steps: 72.4100, mean_ecr: 0.0406 mean_entropies: 2.1286, took: 145.5411s
2022-07-31 15:48:02,438 [INFO] 	Process 3: Batch 3099/10000, mean_policy_losses: -56.278, mean_net_lifetime: 6269.8212, mean_mc_travel_dist: 7074.4671, mean_rewards: 90.8591, total_rewards: 4855.9124, mean_steps: 76.2700, mean_ecr: 0.0395 mean_entropies: 2.0978, took: 158.9319s
2022-07-31 15:50:25,031 [INFO] 	Process 3: Batch 3199/10000, mean_policy_losses: -41.217, mean_net_lifetime: 6473.2611, mean_mc_travel_dist: 6729.7571, mean_rewards: 95.5127, total_rewards: 5128.0646, mean_steps: 73.9300, mean_ecr: 0.0409 mean_entropies: 2.0831, took: 142.5927s
2022-07-31 15:53:00,239 [INFO] 	Process 3: Batch 3299/10000, mean_policy_losses: -82.854, mean_net_lifetime: 7008.5870, mean_mc_travel_dist: 7290.2737, mean_rewards: 96.1317, total_rewards: 5551.4713, mean_steps: 79.5900, mean_ecr: 0.0397 mean_entropies: 2.0581, took: 155.2077s
2022-07-31 15:55:19,465 [INFO] 	Process 3: Batch 3399/10000, mean_policy_losses: -56.259, mean_net_lifetime: 6321.2499, mean_mc_travel_dist: 6502.7315, mean_rewards: 96.4709, total_rewards: 5021.4767, mean_steps: 71.4900, mean_ecr: 0.0404 mean_entropies: 2.0413, took: 139.2251s
2022-07-31 15:57:44,732 [INFO] 	Process 3: Batch 3499/10000, mean_policy_losses: -105.951, mean_net_lifetime: 6229.0285, mean_mc_travel_dist: 6572.8176, mean_rewards: 93.0979, total_rewards: 4915.1359, mean_steps: 72.7900, mean_ecr: 0.0405 mean_entropies: 2.0323, took: 145.2669s
2022-07-31 16:00:07,282 [INFO] 	Process 3: Batch 3599/10000, mean_policy_losses: -57.440, mean_net_lifetime: 6443.1191, mean_mc_travel_dist: 6601.8768, mean_rewards: 97.4465, total_rewards: 5123.0876, mean_steps: 71.7100, mean_ecr: 0.0400 mean_entropies: 1.9922, took: 142.5517s
2022-07-31 16:02:19,338 [INFO] 	Process 3: Batch 3699/10000, mean_policy_losses: -56.268, mean_net_lifetime: 6655.2261, mean_mc_travel_dist: 5911.5206, mean_rewards: 107.6340, total_rewards: 5473.5949, mean_steps: 65.6300, mean_ecr: 0.0438 mean_entropies: 1.9002, took: 132.0542s
2022-07-31 16:04:57,921 [INFO] 	Process 3: Batch 3799/10000, mean_policy_losses: -49.668, mean_net_lifetime: 6290.9515, mean_mc_travel_dist: 6577.7206, mean_rewards: 94.0403, total_rewards: 4975.8618, mean_steps: 72.9400, mean_ecr: 0.0402 mean_entropies: 2.0389, took: 158.5828s
2022-07-31 16:07:30,589 [INFO] 	Process 3: Batch 3899/10000, mean_policy_losses: -84.028, mean_net_lifetime: 6407.5454, mean_mc_travel_dist: 6487.8833, mean_rewards: 96.9466, total_rewards: 5109.9687, mean_steps: 71.8900, mean_ecr: 0.0404 mean_entropies: 1.9834, took: 152.6684s
2022-07-31 16:09:56,781 [INFO] 	Process 3: Batch 3999/10000, mean_policy_losses: -46.440, mean_net_lifetime: 6253.0880, mean_mc_travel_dist: 6731.2206, mean_rewards: 93.4281, total_rewards: 4907.4674, mean_steps: 74.3400, mean_ecr: 0.0392 mean_entropies: 1.9613, took: 146.1930s
2022-07-31 16:12:16,075 [INFO] 	Process 3: Batch 4099/10000, mean_policy_losses: -98.238, mean_net_lifetime: 6439.9722, mean_mc_travel_dist: 6468.4543, mean_rewards: 99.3560, total_rewards: 5147.2313, mean_steps: 71.4200, mean_ecr: 0.0407 mean_entropies: 1.9676, took: 139.2935s
2022-07-31 16:14:34,084 [INFO] 	Process 3: Batch 4199/10000, mean_policy_losses: -50.362, mean_net_lifetime: 6300.1541, mean_mc_travel_dist: 6105.7191, mean_rewards: 103.5687, total_rewards: 5080.1938, mean_steps: 66.5700, mean_ecr: 0.0422 mean_entropies: 1.8374, took: 138.0096s
2022-07-31 16:17:03,812 [INFO] 	Process 3: Batch 4299/10000, mean_policy_losses: -83.126, mean_net_lifetime: 6264.7979, mean_mc_travel_dist: 6539.0484, mean_rewards: 95.8514, total_rewards: 4958.4203, mean_steps: 71.9700, mean_ecr: 0.0400 mean_entropies: 1.8812, took: 149.7269s
2022-07-31 16:19:25,764 [INFO] 	Process 3: Batch 4399/10000, mean_policy_losses: -96.421, mean_net_lifetime: 6275.1323, mean_mc_travel_dist: 6347.2209, mean_rewards: 98.5303, total_rewards: 5006.0571, mean_steps: 69.7000, mean_ecr: 0.0406 mean_entropies: 1.8845, took: 141.9530s
2022-07-31 16:22:01,961 [INFO] 	Process 3: Batch 4499/10000, mean_policy_losses: -43.420, mean_net_lifetime: 6366.1929, mean_mc_travel_dist: 6726.8606, mean_rewards: 92.8990, total_rewards: 5021.2912, mean_steps: 74.8200, mean_ecr: 0.0390 mean_entropies: 1.9210, took: 156.1966s
2022-07-31 16:24:35,666 [INFO] 	Process 3: Batch 4599/10000, mean_policy_losses: -73.485, mean_net_lifetime: 6313.1723, mean_mc_travel_dist: 6591.0937, mean_rewards: 97.2848, total_rewards: 4995.4106, mean_steps: 72.4600, mean_ecr: 0.0401 mean_entropies: 1.8223, took: 153.7047s
2022-07-31 16:26:55,372 [INFO] 	Process 3: Batch 4699/10000, mean_policy_losses: -92.881, mean_net_lifetime: 6463.3584, mean_mc_travel_dist: 6388.4105, mean_rewards: 99.6710, total_rewards: 5186.4106, mean_steps: 70.6700, mean_ecr: 0.0404 mean_entropies: 1.7999, took: 139.7071s
2022-07-31 16:29:17,678 [INFO] 	Process 3: Batch 4799/10000, mean_policy_losses: -92.186, mean_net_lifetime: 6399.1981, mean_mc_travel_dist: 6721.4927, mean_rewards: 95.4991, total_rewards: 5055.5969, mean_steps: 74.3900, mean_ecr: 0.0392 mean_entropies: 1.8285, took: 142.3062s
2022-07-31 16:31:41,102 [INFO] 	Process 3: Batch 4899/10000, mean_policy_losses: -55.943, mean_net_lifetime: 6198.8579, mean_mc_travel_dist: 6670.1593, mean_rewards: 93.2118, total_rewards: 4865.0369, mean_steps: 74.2700, mean_ecr: 0.0387 mean_entropies: 1.8114, took: 143.4232s
2022-07-31 16:34:05,689 [INFO] 	Process 3: Batch 4999/10000, mean_policy_losses: -50.766, mean_net_lifetime: 6261.7398, mean_mc_travel_dist: 6520.5063, mean_rewards: 96.8571, total_rewards: 4958.2488, mean_steps: 70.5800, mean_ecr: 0.0400 mean_entropies: 1.8345, took: 144.5865s
2022-07-31 16:36:32,710 [INFO] 	Process 3: Batch 5099/10000, mean_policy_losses: -92.003, mean_net_lifetime: 6404.0044, mean_mc_travel_dist: 6611.3110, mean_rewards: 99.1575, total_rewards: 5081.7422, mean_steps: 72.2500, mean_ecr: 0.0399 mean_entropies: 1.8113, took: 147.0203s
2022-07-31 16:38:49,651 [INFO] 	Process 3: Batch 5199/10000, mean_policy_losses: -71.221, mean_net_lifetime: 6440.9122, mean_mc_travel_dist: 6422.5903, mean_rewards: 100.3407, total_rewards: 5156.6570, mean_steps: 69.6300, mean_ecr: 0.0407 mean_entropies: 1.7811, took: 136.9425s
2022-07-31 16:41:13,824 [INFO] 	Process 3: Batch 5299/10000, mean_policy_losses: -88.270, mean_net_lifetime: 6283.8790, mean_mc_travel_dist: 6407.3773, mean_rewards: 100.3971, total_rewards: 5002.6783, mean_steps: 69.6200, mean_ecr: 0.0404 mean_entropies: 1.7017, took: 144.1717s
2022-07-31 16:43:37,288 [INFO] 	Process 3: Batch 5399/10000, mean_policy_losses: -64.398, mean_net_lifetime: 6344.8101, mean_mc_travel_dist: 6298.7995, mean_rewards: 100.2395, total_rewards: 5085.6170, mean_steps: 69.7500, mean_ecr: 0.0407 mean_entropies: 1.6826, took: 143.4649s
2022-07-31 16:45:52,499 [INFO] 	Process 3: Batch 5499/10000, mean_policy_losses: -84.629, mean_net_lifetime: 6448.1657, mean_mc_travel_dist: 6329.1225, mean_rewards: 102.9650, total_rewards: 5182.8841, mean_steps: 67.8300, mean_ecr: 0.0407 mean_entropies: 1.7355, took: 135.2124s
2022-07-31 16:48:11,414 [INFO] 	Process 3: Batch 5599/10000, mean_policy_losses: -75.945, mean_net_lifetime: 6621.8854, mean_mc_travel_dist: 6546.2367, mean_rewards: 100.0300, total_rewards: 5313.2774, mean_steps: 71.1600, mean_ecr: 0.0397 mean_entropies: 1.7332, took: 138.9126s
2022-07-31 16:50:31,076 [INFO] 	Process 3: Batch 5699/10000, mean_policy_losses: -52.329, mean_net_lifetime: 6430.7194, mean_mc_travel_dist: 6515.9688, mean_rewards: 99.9841, total_rewards: 5128.7760, mean_steps: 72.5400, mean_ecr: 0.0400 mean_entropies: 1.6777, took: 139.6625s
2022-07-31 16:52:54,410 [INFO] 	Process 3: Batch 5799/10000, mean_policy_losses: -107.483, mean_net_lifetime: 6504.7655, mean_mc_travel_dist: 6498.6842, mean_rewards: 99.0453, total_rewards: 5205.5912, mean_steps: 72.2500, mean_ecr: 0.0399 mean_entropies: 1.7336, took: 143.3324s
2022-07-31 16:55:23,360 [INFO] 	Process 3: Batch 5899/10000, mean_policy_losses: -20.059, mean_net_lifetime: 6639.4313, mean_mc_travel_dist: 6308.7473, mean_rewards: 102.4884, total_rewards: 5377.7702, mean_steps: 68.7500, mean_ecr: 0.0410 mean_entropies: 1.6775, took: 148.9523s
2022-07-31 16:57:49,039 [INFO] 	Process 3: Batch 5999/10000, mean_policy_losses: -114.041, mean_net_lifetime: 6564.9059, mean_mc_travel_dist: 6556.7846, mean_rewards: 97.2821, total_rewards: 5253.8615, mean_steps: 73.3100, mean_ecr: 0.0397 mean_entropies: 1.7107, took: 145.6788s
2022-07-31 16:59:59,267 [INFO] 	Process 3: Batch 6099/10000, mean_policy_losses: -30.002, mean_net_lifetime: 6325.5688, mean_mc_travel_dist: 6003.9682, mean_rewards: 105.5806, total_rewards: 5125.9382, mean_steps: 64.7000, mean_ecr: 0.0422 mean_entropies: 1.6218, took: 130.2273s
2022-07-31 17:02:24,864 [INFO] 	Process 3: Batch 6199/10000, mean_policy_losses: -44.902, mean_net_lifetime: 6539.2837, mean_mc_travel_dist: 6302.3527, mean_rewards: 102.5482, total_rewards: 5279.4385, mean_steps: 68.9300, mean_ecr: 0.0405 mean_entropies: 1.5999, took: 145.5972s
2022-07-31 17:04:43,323 [INFO] 	Process 3: Batch 6299/10000, mean_policy_losses: -50.031, mean_net_lifetime: 6555.9228, mean_mc_travel_dist: 6322.2232, mean_rewards: 102.7659, total_rewards: 5291.9769, mean_steps: 68.7600, mean_ecr: 0.0408 mean_entropies: 1.5958, took: 138.4591s
2022-07-31 17:06:59,207 [INFO] 	Process 3: Batch 6399/10000, mean_policy_losses: -66.828, mean_net_lifetime: 6557.8660, mean_mc_travel_dist: 6280.0023, mean_rewards: 103.3678, total_rewards: 5302.2685, mean_steps: 68.7300, mean_ecr: 0.0408 mean_entropies: 1.5589, took: 135.8835s
2022-07-31 17:09:19,932 [INFO] 	Process 3: Batch 6499/10000, mean_policy_losses: -78.941, mean_net_lifetime: 6420.6497, mean_mc_travel_dist: 6515.3014, mean_rewards: 100.9252, total_rewards: 5118.1822, mean_steps: 71.6400, mean_ecr: 0.0394 mean_entropies: 1.5989, took: 140.7254s
2022-07-31 17:11:33,474 [INFO] 	Process 3: Batch 6599/10000, mean_policy_losses: -99.161, mean_net_lifetime: 6756.6108, mean_mc_travel_dist: 6295.3545, mean_rewards: 106.6283, total_rewards: 5498.0528, mean_steps: 68.5300, mean_ecr: 0.0406 mean_entropies: 1.6104, took: 133.5429s
2022-07-31 17:14:05,580 [INFO] 	Process 3: Batch 6699/10000, mean_policy_losses: -58.687, mean_net_lifetime: 6420.0028, mean_mc_travel_dist: 6660.8452, mean_rewards: 97.3748, total_rewards: 5088.4739, mean_steps: 73.6200, mean_ecr: 0.0388 mean_entropies: 1.6276, took: 152.1041s
2022-07-31 17:16:37,615 [INFO] 	Process 3: Batch 6799/10000, mean_policy_losses: -54.342, mean_net_lifetime: 6302.7678, mean_mc_travel_dist: 6583.5727, mean_rewards: 96.7009, total_rewards: 4986.9004, mean_steps: 72.4000, mean_ecr: 0.0394 mean_entropies: 1.6104, took: 152.0355s
2022-07-31 17:18:41,742 [INFO] 	Process 3: Batch 6899/10000, mean_policy_losses: -75.241, mean_net_lifetime: 6307.9436, mean_mc_travel_dist: 5590.2388, mean_rewards: 113.7929, total_rewards: 5190.6384, mean_steps: 60.1800, mean_ecr: 0.0447 mean_entropies: 1.4551, took: 124.1284s
2022-07-31 17:20:58,933 [INFO] 	Process 3: Batch 6999/10000, mean_policy_losses: -106.966, mean_net_lifetime: 6477.0750, mean_mc_travel_dist: 6210.7953, mean_rewards: 106.5845, total_rewards: 5235.9578, mean_steps: 67.8900, mean_ecr: 0.0416 mean_entropies: 1.4759, took: 137.1908s
2022-07-31 17:23:17,346 [INFO] 	Process 3: Batch 7099/10000, mean_policy_losses: -81.034, mean_net_lifetime: 6404.4692, mean_mc_travel_dist: 6387.0195, mean_rewards: 99.5357, total_rewards: 5127.4007, mean_steps: 71.5300, mean_ecr: 0.0408 mean_entropies: 1.4531, took: 138.4114s
2022-07-31 17:25:31,627 [INFO] 	Process 3: Batch 7199/10000, mean_policy_losses: -58.334, mean_net_lifetime: 6671.6554, mean_mc_travel_dist: 6299.7263, mean_rewards: 104.1915, total_rewards: 5412.2199, mean_steps: 69.6000, mean_ecr: 0.0408 mean_entropies: 1.4471, took: 134.2834s
2022-07-31 17:27:53,686 [INFO] 	Process 3: Batch 7299/10000, mean_policy_losses: -48.928, mean_net_lifetime: 6173.6941, mean_mc_travel_dist: 6469.0444, mean_rewards: 96.5524, total_rewards: 4880.0335, mean_steps: 72.6900, mean_ecr: 0.0400 mean_entropies: 1.4853, took: 142.0584s
2022-07-31 17:30:19,665 [INFO] 	Process 3: Batch 7399/10000, mean_policy_losses: -41.900, mean_net_lifetime: 6415.8955, mean_mc_travel_dist: 6481.5407, mean_rewards: 97.3599, total_rewards: 5119.7781, mean_steps: 72.3000, mean_ecr: 0.0400 mean_entropies: 1.4970, took: 145.9772s
2022-07-31 17:32:37,975 [INFO] 	Process 3: Batch 7499/10000, mean_policy_losses: -31.668, mean_net_lifetime: 6255.0002, mean_mc_travel_dist: 6384.8533, mean_rewards: 98.9144, total_rewards: 4978.8447, mean_steps: 69.5200, mean_ecr: 0.0402 mean_entropies: 1.4509, took: 138.3121s
2022-07-31 17:35:09,477 [INFO] 	Process 3: Batch 7599/10000, mean_policy_losses: -27.661, mean_net_lifetime: 6309.0203, mean_mc_travel_dist: 6671.9483, mean_rewards: 94.1299, total_rewards: 4975.0525, mean_steps: 74.2100, mean_ecr: 0.0390 mean_entropies: 1.5027, took: 151.5016s
2022-07-31 17:37:40,803 [INFO] 	Process 3: Batch 7699/10000, mean_policy_losses: -77.363, mean_net_lifetime: 6593.7540, mean_mc_travel_dist: 6528.8046, mean_rewards: 99.3167, total_rewards: 5288.0368, mean_steps: 72.4100, mean_ecr: 0.0394 mean_entropies: 1.4753, took: 151.3253s
2022-07-31 17:40:05,497 [INFO] 	Process 3: Batch 7799/10000, mean_policy_losses: -64.138, mean_net_lifetime: 6561.9105, mean_mc_travel_dist: 6325.7492, mean_rewards: 102.8697, total_rewards: 5296.9464, mean_steps: 70.0300, mean_ecr: 0.0402 mean_entropies: 1.3988, took: 144.6953s
2022-07-31 17:42:18,301 [INFO] 	Process 3: Batch 7899/10000, mean_policy_losses: -62.477, mean_net_lifetime: 6528.2473, mean_mc_travel_dist: 6184.5808, mean_rewards: 105.2362, total_rewards: 5292.2223, mean_steps: 68.1300, mean_ecr: 0.0414 mean_entropies: 1.3758, took: 132.8027s
2022-07-31 17:44:41,279 [INFO] 	Process 3: Batch 7999/10000, mean_policy_losses: -55.104, mean_net_lifetime: 6585.2646, mean_mc_travel_dist: 6427.8383, mean_rewards: 99.9247, total_rewards: 5300.5415, mean_steps: 71.4100, mean_ecr: 0.0402 mean_entropies: 1.4277, took: 142.9789s
2022-07-31 17:46:54,331 [INFO] 	Process 3: Batch 8099/10000, mean_policy_losses: -50.596, mean_net_lifetime: 6514.3347, mean_mc_travel_dist: 6220.3434, mean_rewards: 107.9150, total_rewards: 5271.0369, mean_steps: 66.1300, mean_ecr: 0.0413 mean_entropies: 1.4098, took: 133.0505s
2022-07-31 17:49:17,945 [INFO] 	Process 3: Batch 8199/10000, mean_policy_losses: -106.651, mean_net_lifetime: 6436.0150, mean_mc_travel_dist: 6510.0507, mean_rewards: 98.5497, total_rewards: 5134.5308, mean_steps: 71.8200, mean_ecr: 0.0396 mean_entropies: 1.4521, took: 143.6157s
2022-07-31 17:51:34,218 [INFO] 	Process 3: Batch 8299/10000, mean_policy_losses: -52.229, mean_net_lifetime: 6455.6212, mean_mc_travel_dist: 6441.6719, mean_rewards: 101.7123, total_rewards: 5167.2868, mean_steps: 69.3100, mean_ecr: 0.0401 mean_entropies: 1.4115, took: 136.2719s
2022-07-31 17:53:47,184 [INFO] 	Process 3: Batch 8399/10000, mean_policy_losses: -70.375, mean_net_lifetime: 6453.3692, mean_mc_travel_dist: 6341.9781, mean_rewards: 102.6075, total_rewards: 5185.8415, mean_steps: 69.4600, mean_ecr: 0.0403 mean_entropies: 1.5160, took: 132.9668s
2022-07-31 17:55:57,097 [INFO] 	Process 3: Batch 8499/10000, mean_policy_losses: -88.755, mean_net_lifetime: 6458.7613, mean_mc_travel_dist: 6018.6052, mean_rewards: 108.1172, total_rewards: 5256.0274, mean_steps: 65.8800, mean_ecr: 0.0417 mean_entropies: 1.4096, took: 129.9125s
2022-07-31 17:58:17,775 [INFO] 	Process 3: Batch 8599/10000, mean_policy_losses: -79.745, mean_net_lifetime: 6475.8206, mean_mc_travel_dist: 6328.9448, mean_rewards: 102.5207, total_rewards: 5210.7347, mean_steps: 69.8600, mean_ecr: 0.0406 mean_entropies: 1.4167, took: 140.6784s
2022-07-31 18:00:32,202 [INFO] 	Process 3: Batch 8699/10000, mean_policy_losses: -34.753, mean_net_lifetime: 6814.3565, mean_mc_travel_dist: 6370.0350, mean_rewards: 104.7488, total_rewards: 5540.5265, mean_steps: 69.7800, mean_ecr: 0.0402 mean_entropies: 1.4596, took: 134.4251s
2022-07-31 18:02:36,883 [INFO] 	Process 3: Batch 8799/10000, mean_policy_losses: -74.163, mean_net_lifetime: 6575.4904, mean_mc_travel_dist: 6142.8604, mean_rewards: 108.2359, total_rewards: 5347.7267, mean_steps: 65.6200, mean_ecr: 0.0408 mean_entropies: 1.3850, took: 124.6816s
2022-07-31 18:04:43,780 [INFO] 	Process 3: Batch 8899/10000, mean_policy_losses: -72.015, mean_net_lifetime: 6435.1702, mean_mc_travel_dist: 6239.2452, mean_rewards: 106.3382, total_rewards: 5187.9592, mean_steps: 67.1700, mean_ecr: 0.0409 mean_entropies: 1.4232, took: 126.8981s
2022-07-31 18:06:50,034 [INFO] 	Process 3: Batch 8999/10000, mean_policy_losses: -66.494, mean_net_lifetime: 6404.3161, mean_mc_travel_dist: 6077.3385, mean_rewards: 106.8859, total_rewards: 5189.9840, mean_steps: 65.4600, mean_ecr: 0.0418 mean_entropies: 1.4142, took: 126.2540s
2022-07-31 18:09:14,112 [INFO] 	Process 3: Batch 9099/10000, mean_policy_losses: -103.616, mean_net_lifetime: 6750.8915, mean_mc_travel_dist: 6614.9111, mean_rewards: 100.9046, total_rewards: 5428.2579, mean_steps: 73.0000, mean_ecr: 0.0389 mean_entropies: 1.3914, took: 144.0792s
2022-07-31 18:11:36,805 [INFO] 	Process 3: Batch 9199/10000, mean_policy_losses: -18.975, mean_net_lifetime: 6277.3464, mean_mc_travel_dist: 6328.9261, mean_rewards: 100.3751, total_rewards: 5012.3091, mean_steps: 69.7200, mean_ecr: 0.0408 mean_entropies: 1.3911, took: 142.6897s
2022-07-31 18:13:49,474 [INFO] 	Process 3: Batch 9299/10000, mean_policy_losses: -32.588, mean_net_lifetime: 6767.5027, mean_mc_travel_dist: 6347.6977, mean_rewards: 107.5110, total_rewards: 5498.2648, mean_steps: 67.4200, mean_ecr: 0.0405 mean_entropies: 1.3606, took: 132.6708s
2022-07-31 18:16:00,999 [INFO] 	Process 3: Batch 9399/10000, mean_policy_losses: -77.942, mean_net_lifetime: 6601.8347, mean_mc_travel_dist: 6372.4428, mean_rewards: 107.3722, total_rewards: 5327.6990, mean_steps: 67.4800, mean_ecr: 0.0403 mean_entropies: 1.3865, took: 131.5237s
2022-07-31 18:18:16,238 [INFO] 	Process 3: Batch 9499/10000, mean_policy_losses: -70.921, mean_net_lifetime: 6422.9214, mean_mc_travel_dist: 6388.9435, mean_rewards: 101.9855, total_rewards: 5146.0553, mean_steps: 68.3200, mean_ecr: 0.0405 mean_entropies: 1.3907, took: 135.2414s
2022-07-31 18:20:29,931 [INFO] 	Process 3: Batch 9599/10000, mean_policy_losses: -98.237, mean_net_lifetime: 6531.8992, mean_mc_travel_dist: 6402.6035, mean_rewards: 106.5514, total_rewards: 5251.9863, mean_steps: 67.6700, mean_ecr: 0.0403 mean_entropies: 1.3485, took: 133.6904s
2022-07-31 18:22:45,493 [INFO] 	Process 3: Batch 9699/10000, mean_policy_losses: -59.624, mean_net_lifetime: 6380.3296, mean_mc_travel_dist: 6467.8923, mean_rewards: 101.5316, total_rewards: 5087.4046, mean_steps: 68.7400, mean_ecr: 0.0399 mean_entropies: 1.3636, took: 135.5622s
2022-07-31 18:25:00,918 [INFO] 	Process 3: Batch 9799/10000, mean_policy_losses: -86.463, mean_net_lifetime: 6440.9754, mean_mc_travel_dist: 6553.0409, mean_rewards: 101.2333, total_rewards: 5131.2200, mean_steps: 70.8600, mean_ecr: 0.0394 mean_entropies: 1.3605, took: 135.4264s
2022-07-31 18:27:06,947 [INFO] 	Process 3: Batch 9899/10000, mean_policy_losses: -55.901, mean_net_lifetime: 6499.7078, mean_mc_travel_dist: 6408.9721, mean_rewards: 102.2746, total_rewards: 5219.3282, mean_steps: 68.7500, mean_ecr: 0.0398 mean_entropies: 1.3795, took: 126.0265s
2022-07-31 18:29:07,496 [INFO] 	Process 3: Batch 9999/10000, mean_policy_losses: -89.199, mean_net_lifetime: 6459.6828, mean_mc_travel_dist: 6146.4144, mean_rewards: 108.4205, total_rewards: 5231.0322, mean_steps: 65.0400, mean_ecr: 0.0413 mean_entropies: 1.2880, took: 120.5503s
2022-07-31 18:40:22,355 [INFO] Process 3: Epoch 0: mean_policy_losses: -53.632, mean_net_lifetime: 6826.6917, mean_mc_travel_dist: 7417.8664, mean_entropies: 1.8753, m_net_lifetime_valid: 6486.6488, took: 16614.9715s, (157.8229 / 100 batches)

2022-07-31 18:40:22,356 [INFO] Process 3: Start epoch 1
2022-07-31 18:42:33,768 [INFO] 	Process 3: Batch 99/10000, mean_policy_losses: 80.814, mean_net_lifetime: 4083.3409, mean_mc_travel_dist: 7144.8365, mean_rewards: 59.9481, total_rewards: 2659.3830, mean_steps: 68.1600, mean_ecr: 0.0405 mean_entropies: 2.9172, took: 131.4079s
2022-07-31 18:44:58,090 [INFO] 	Process 3: Batch 199/10000, mean_policy_losses: 13.064, mean_net_lifetime: 4263.2786, mean_mc_travel_dist: 6838.4806, mean_rewards: 62.2038, total_rewards: 2899.2841, mean_steps: 69.6300, mean_ecr: 0.0403 mean_entropies: 2.8096, took: 144.3214s
2022-07-31 18:47:18,512 [INFO] 	Process 3: Batch 299/10000, mean_policy_losses: 14.165, mean_net_lifetime: 4300.0512, mean_mc_travel_dist: 6723.7909, mean_rewards: 62.1817, total_rewards: 2957.1084, mean_steps: 70.8500, mean_ecr: 0.0402 mean_entropies: 2.6749, took: 140.4190s
2022-07-31 18:49:42,267 [INFO] 	Process 3: Batch 399/10000, mean_policy_losses: -24.419, mean_net_lifetime: 4714.5561, mean_mc_travel_dist: 6680.9158, mean_rewards: 66.8107, total_rewards: 3379.6219, mean_steps: 73.5000, mean_ecr: 0.0421 mean_entropies: 2.6583, took: 143.7556s
2022-07-31 18:52:18,310 [INFO] 	Process 3: Batch 499/10000, mean_policy_losses: 4.144, mean_net_lifetime: 5070.8063, mean_mc_travel_dist: 7116.7415, mean_rewards: 68.1471, total_rewards: 3649.2482, mean_steps: 79.1800, mean_ecr: 0.0395 mean_entropies: 2.6209, took: 156.0455s
2022-07-31 18:54:46,476 [INFO] 	Process 3: Batch 599/10000, mean_policy_losses: -27.878, mean_net_lifetime: 4958.9910, mean_mc_travel_dist: 6961.9784, mean_rewards: 68.5366, total_rewards: 3568.8084, mean_steps: 77.1600, mean_ecr: 0.0400 mean_entropies: 2.5999, took: 148.1655s
2022-07-31 18:57:20,797 [INFO] 	Process 3: Batch 699/10000, mean_policy_losses: 13.974, mean_net_lifetime: 5417.3486, mean_mc_travel_dist: 7023.0219, mean_rewards: 73.4154, total_rewards: 4013.6536, mean_steps: 79.5300, mean_ecr: 0.0399 mean_entropies: 2.5733, took: 154.3200s
2022-07-31 18:59:47,522 [INFO] 	Process 3: Batch 799/10000, mean_policy_losses: -28.957, mean_net_lifetime: 5607.0510, mean_mc_travel_dist: 6965.1044, mean_rewards: 77.5679, total_rewards: 4214.4934, mean_steps: 76.0400, mean_ecr: 0.0399 mean_entropies: 2.5415, took: 146.7259s
2022-07-31 19:02:25,537 [INFO] 	Process 3: Batch 899/10000, mean_policy_losses: -20.041, mean_net_lifetime: 5671.3341, mean_mc_travel_dist: 6994.1065, mean_rewards: 77.3048, total_rewards: 4273.0874, mean_steps: 77.8600, mean_ecr: 0.0394 mean_entropies: 2.4797, took: 158.0166s
2022-07-31 19:05:01,828 [INFO] 	Process 3: Batch 999/10000, mean_policy_losses: -30.189, mean_net_lifetime: 5915.0867, mean_mc_travel_dist: 6923.6410, mean_rewards: 81.1372, total_rewards: 4531.1193, mean_steps: 77.1200, mean_ecr: 0.0399 mean_entropies: 2.3875, took: 156.2893s
2022-07-31 19:07:29,788 [INFO] 	Process 3: Batch 1099/10000, mean_policy_losses: -53.179, mean_net_lifetime: 5776.4869, mean_mc_travel_dist: 6635.4278, mean_rewards: 83.9307, total_rewards: 4449.8860, mean_steps: 73.8100, mean_ecr: 0.0416 mean_entropies: 2.3070, took: 147.9594s
2022-07-31 19:10:11,079 [INFO] 	Process 3: Batch 1199/10000, mean_policy_losses: -50.160, mean_net_lifetime: 5934.5774, mean_mc_travel_dist: 7084.0390, mean_rewards: 80.6997, total_rewards: 4517.9288, mean_steps: 78.7800, mean_ecr: 0.0393 mean_entropies: 2.3123, took: 161.2902s
2022-07-31 19:12:50,887 [INFO] 	Process 3: Batch 1299/10000, mean_policy_losses: 2.547, mean_net_lifetime: 6113.3319, mean_mc_travel_dist: 6930.1257, mean_rewards: 81.5119, total_rewards: 4728.0134, mean_steps: 79.7200, mean_ecr: 0.0398 mean_entropies: 2.2342, took: 159.8114s
2022-07-31 19:15:18,889 [INFO] 	Process 3: Batch 1399/10000, mean_policy_losses: -35.160, mean_net_lifetime: 5811.9904, mean_mc_travel_dist: 6689.0183, mean_rewards: 82.4927, total_rewards: 4474.2830, mean_steps: 75.2000, mean_ecr: 0.0408 mean_entropies: 2.1560, took: 147.9997s
2022-07-31 19:17:42,930 [INFO] 	Process 3: Batch 1499/10000, mean_policy_losses: -108.726, mean_net_lifetime: 5798.6163, mean_mc_travel_dist: 6775.7429, mean_rewards: 82.6759, total_rewards: 4444.2944, mean_steps: 75.9100, mean_ecr: 0.0402 mean_entropies: 2.1557, took: 144.0409s
2022-07-31 19:20:03,565 [INFO] 	Process 3: Batch 1599/10000, mean_policy_losses: 14.803, mean_net_lifetime: 6111.4062, mean_mc_travel_dist: 6799.0035, mean_rewards: 86.7342, total_rewards: 4751.6055, mean_steps: 74.9800, mean_ecr: 0.0404 mean_entropies: 2.0726, took: 140.6365s
2022-07-31 19:22:38,066 [INFO] 	Process 3: Batch 1699/10000, mean_policy_losses: -7.565, mean_net_lifetime: 6171.7445, mean_mc_travel_dist: 6854.2957, mean_rewards: 86.5205, total_rewards: 4801.3402, mean_steps: 76.4800, mean_ecr: 0.0398 mean_entropies: 2.1305, took: 154.4994s
2022-07-31 19:25:19,718 [INFO] 	Process 3: Batch 1799/10000, mean_policy_losses: -9.436, mean_net_lifetime: 6145.5197, mean_mc_travel_dist: 6882.3519, mean_rewards: 84.5802, total_rewards: 4769.3047, mean_steps: 77.9400, mean_ecr: 0.0395 mean_entropies: 2.1431, took: 161.6528s
2022-07-31 19:27:51,785 [INFO] 	Process 3: Batch 1899/10000, mean_policy_losses: -50.839, mean_net_lifetime: 6122.3874, mean_mc_travel_dist: 6857.9671, mean_rewards: 87.1915, total_rewards: 4750.8983, mean_steps: 75.3500, mean_ecr: 0.0394 mean_entropies: 2.0977, took: 152.0660s
2022-07-31 19:30:27,525 [INFO] 	Process 3: Batch 1999/10000, mean_policy_losses: -36.130, mean_net_lifetime: 6162.0758, mean_mc_travel_dist: 6709.0307, mean_rewards: 87.2251, total_rewards: 4820.9854, mean_steps: 76.0500, mean_ecr: 0.0400 mean_entropies: 2.1344, took: 155.7410s
2022-07-31 19:33:01,319 [INFO] 	Process 3: Batch 2099/10000, mean_policy_losses: 5.682, mean_net_lifetime: 6306.5753, mean_mc_travel_dist: 6809.3217, mean_rewards: 87.5684, total_rewards: 4945.2089, mean_steps: 78.0900, mean_ecr: 0.0392 mean_entropies: 2.1360, took: 153.7941s
2022-07-31 19:35:29,258 [INFO] 	Process 3: Batch 2199/10000, mean_policy_losses: -58.398, mean_net_lifetime: 6336.5502, mean_mc_travel_dist: 6401.2978, mean_rewards: 96.7003, total_rewards: 5057.0303, mean_steps: 70.8900, mean_ecr: 0.0414 mean_entropies: 2.0405, took: 147.9398s
2022-07-31 19:37:54,315 [INFO] 	Process 3: Batch 2299/10000, mean_policy_losses: -47.391, mean_net_lifetime: 6237.1237, mean_mc_travel_dist: 6700.8944, mean_rewards: 91.5892, total_rewards: 4897.2359, mean_steps: 74.9900, mean_ecr: 0.0397 mean_entropies: 2.0523, took: 145.0554s
2022-07-31 19:40:18,038 [INFO] 	Process 3: Batch 2399/10000, mean_policy_losses: -23.053, mean_net_lifetime: 6107.3182, mean_mc_travel_dist: 6630.6907, mean_rewards: 91.1294, total_rewards: 4781.9992, mean_steps: 75.2300, mean_ecr: 0.0405 mean_entropies: 2.0742, took: 143.7250s
2022-07-31 19:42:34,985 [INFO] 	Process 3: Batch 2499/10000, mean_policy_losses: -34.899, mean_net_lifetime: 6078.0180, mean_mc_travel_dist: 6176.2398, mean_rewards: 99.7465, total_rewards: 4844.3585, mean_steps: 68.1300, mean_ecr: 0.0421 mean_entropies: 1.9496, took: 136.9455s
2022-07-31 19:44:49,582 [INFO] 	Process 3: Batch 2599/10000, mean_policy_losses: -75.676, mean_net_lifetime: 6161.2832, mean_mc_travel_dist: 6445.0383, mean_rewards: 97.7625, total_rewards: 4872.7848, mean_steps: 69.1000, mean_ecr: 0.0414 mean_entropies: 1.9685, took: 134.5954s
2022-07-31 19:47:13,485 [INFO] 	Process 3: Batch 2699/10000, mean_policy_losses: -56.683, mean_net_lifetime: 6316.6367, mean_mc_travel_dist: 6568.3093, mean_rewards: 94.2488, total_rewards: 5003.6932, mean_steps: 73.0800, mean_ecr: 0.0403 mean_entropies: 2.0140, took: 143.9053s
2022-07-31 19:49:38,776 [INFO] 	Process 3: Batch 2799/10000, mean_policy_losses: -7.078, mean_net_lifetime: 6190.6423, mean_mc_travel_dist: 6542.8496, mean_rewards: 96.1816, total_rewards: 4882.6891, mean_steps: 70.5500, mean_ecr: 0.0408 mean_entropies: 2.0107, took: 145.2907s
2022-07-31 19:51:57,473 [INFO] 	Process 3: Batch 2899/10000, mean_policy_losses: -81.004, mean_net_lifetime: 6235.1996, mean_mc_travel_dist: 6236.9025, mean_rewards: 100.5896, total_rewards: 4988.9679, mean_steps: 68.6100, mean_ecr: 0.0413 mean_entropies: 1.9496, took: 138.6976s
2022-07-31 19:54:16,804 [INFO] 	Process 3: Batch 2999/10000, mean_policy_losses: -105.163, mean_net_lifetime: 6309.7401, mean_mc_travel_dist: 6373.9270, mean_rewards: 97.7366, total_rewards: 5035.5788, mean_steps: 69.6000, mean_ecr: 0.0412 mean_entropies: 1.9112, took: 139.3294s
2022-07-31 19:56:34,509 [INFO] 	Process 3: Batch 3099/10000, mean_policy_losses: -4.494, mean_net_lifetime: 6334.4969, mean_mc_travel_dist: 6286.4086, mean_rewards: 99.5159, total_rewards: 5077.6327, mean_steps: 69.5500, mean_ecr: 0.0413 mean_entropies: 1.8789, took: 137.7055s
2022-07-31 19:58:45,911 [INFO] 	Process 3: Batch 3199/10000, mean_policy_losses: -92.764, mean_net_lifetime: 6375.3228, mean_mc_travel_dist: 6431.0779, mean_rewards: 101.0375, total_rewards: 5089.3580, mean_steps: 68.6200, mean_ecr: 0.0407 mean_entropies: 1.9195, took: 131.4028s
2022-07-31 20:01:04,520 [INFO] 	Process 3: Batch 3299/10000, mean_policy_losses: -91.209, mean_net_lifetime: 6400.8777, mean_mc_travel_dist: 6293.8427, mean_rewards: 102.8507, total_rewards: 5142.7515, mean_steps: 68.8000, mean_ecr: 0.0419 mean_entropies: 1.8632, took: 138.6077s
2022-07-31 20:03:33,795 [INFO] 	Process 3: Batch 3399/10000, mean_policy_losses: -33.721, mean_net_lifetime: 6674.9574, mean_mc_travel_dist: 6746.7543, mean_rewards: 96.5974, total_rewards: 5326.0211, mean_steps: 73.5600, mean_ecr: 0.0389 mean_entropies: 1.8738, took: 149.2756s
2022-07-31 20:05:58,495 [INFO] 	Process 3: Batch 3499/10000, mean_policy_losses: -88.746, mean_net_lifetime: 6369.1458, mean_mc_travel_dist: 6679.5247, mean_rewards: 95.1758, total_rewards: 5034.1184, mean_steps: 73.7500, mean_ecr: 0.0393 mean_entropies: 1.8452, took: 144.6986s
2022-07-31 20:08:16,804 [INFO] 	Process 3: Batch 3599/10000, mean_policy_losses: -27.445, mean_net_lifetime: 6303.2457, mean_mc_travel_dist: 6329.6743, mean_rewards: 101.1485, total_rewards: 5037.3109, mean_steps: 67.4500, mean_ecr: 0.0411 mean_entropies: 1.9042, took: 138.3088s
2022-07-31 20:10:37,633 [INFO] 	Process 3: Batch 3699/10000, mean_policy_losses: -75.527, mean_net_lifetime: 6331.1879, mean_mc_travel_dist: 6252.9622, mean_rewards: 101.4663, total_rewards: 5081.6122, mean_steps: 68.5800, mean_ecr: 0.0412 mean_entropies: 1.8574, took: 140.8312s
2022-07-31 20:12:55,017 [INFO] 	Process 3: Batch 3799/10000, mean_policy_losses: -64.736, mean_net_lifetime: 6270.3780, mean_mc_travel_dist: 6515.9059, mean_rewards: 99.9040, total_rewards: 4967.1968, mean_steps: 69.9700, mean_ecr: 0.0400 mean_entropies: 1.8540, took: 137.3838s
2022-07-31 20:15:14,816 [INFO] 	Process 3: Batch 3899/10000, mean_policy_losses: -106.220, mean_net_lifetime: 6322.9229, mean_mc_travel_dist: 6356.3047, mean_rewards: 103.2241, total_rewards: 5052.7210, mean_steps: 68.3900, mean_ecr: 0.0411 mean_entropies: 1.8201, took: 139.7996s
2022-07-31 20:17:25,210 [INFO] 	Process 3: Batch 3999/10000, mean_policy_losses: -66.575, mean_net_lifetime: 6327.5093, mean_mc_travel_dist: 6328.8258, mean_rewards: 102.1344, total_rewards: 5062.3634, mean_steps: 68.1000, mean_ecr: 0.0408 mean_entropies: 1.8161, took: 130.3944s
2022-07-31 20:19:36,807 [INFO] 	Process 3: Batch 4099/10000, mean_policy_losses: -57.588, mean_net_lifetime: 6343.6986, mean_mc_travel_dist: 6238.0997, mean_rewards: 102.1463, total_rewards: 5096.2971, mean_steps: 68.2400, mean_ecr: 0.0413 mean_entropies: 1.7937, took: 131.5938s
2022-07-31 20:21:42,713 [INFO] 	Process 3: Batch 4199/10000, mean_policy_losses: -71.656, mean_net_lifetime: 6404.5956, mean_mc_travel_dist: 6007.8837, mean_rewards: 108.5047, total_rewards: 5203.8137, mean_steps: 63.8700, mean_ecr: 0.0427 mean_entropies: 1.7748, took: 125.9073s
2022-07-31 20:23:56,562 [INFO] 	Process 3: Batch 4299/10000, mean_policy_losses: -66.513, mean_net_lifetime: 6581.2945, mean_mc_travel_dist: 6412.6494, mean_rewards: 102.5475, total_rewards: 5298.7646, mean_steps: 69.0500, mean_ecr: 0.0407 mean_entropies: 1.8164, took: 133.8492s
2022-07-31 20:26:04,643 [INFO] 	Process 3: Batch 4399/10000, mean_policy_losses: -54.872, mean_net_lifetime: 6262.9656, mean_mc_travel_dist: 6256.8843, mean_rewards: 104.2990, total_rewards: 5012.8302, mean_steps: 66.5900, mean_ecr: 0.0410 mean_entropies: 1.7157, took: 128.0812s
2022-07-31 20:28:17,065 [INFO] 	Process 3: Batch 4499/10000, mean_policy_losses: -56.087, mean_net_lifetime: 6370.2031, mean_mc_travel_dist: 6185.4560, mean_rewards: 104.5876, total_rewards: 5133.8541, mean_steps: 65.8000, mean_ecr: 0.0414 mean_entropies: 1.7383, took: 132.4219s
2022-07-31 20:30:33,046 [INFO] 	Process 3: Batch 4599/10000, mean_policy_losses: -106.793, mean_net_lifetime: 6304.2772, mean_mc_travel_dist: 6331.4978, mean_rewards: 102.1128, total_rewards: 5038.1865, mean_steps: 68.4200, mean_ecr: 0.0406 mean_entropies: 1.7193, took: 135.9818s
2022-07-31 20:32:47,079 [INFO] 	Process 3: Batch 4699/10000, mean_policy_losses: -36.070, mean_net_lifetime: 6439.1369, mean_mc_travel_dist: 6562.2627, mean_rewards: 101.1644, total_rewards: 5126.8329, mean_steps: 69.7000, mean_ecr: 0.0397 mean_entropies: 1.7372, took: 134.0331s
2022-07-31 20:34:54,664 [INFO] 	Process 3: Batch 4799/10000, mean_policy_losses: -62.856, mean_net_lifetime: 6317.8102, mean_mc_travel_dist: 6386.6503, mean_rewards: 102.9392, total_rewards: 5040.7895, mean_steps: 67.2300, mean_ecr: 0.0402 mean_entropies: 1.7010, took: 127.5839s
2022-07-31 20:37:03,185 [INFO] 	Process 3: Batch 4899/10000, mean_policy_losses: -74.742, mean_net_lifetime: 6632.8109, mean_mc_travel_dist: 6194.4762, mean_rewards: 107.1293, total_rewards: 5394.5351, mean_steps: 66.9500, mean_ecr: 0.0414 mean_entropies: 1.6204, took: 128.5207s
2022-07-31 20:39:17,157 [INFO] 	Process 3: Batch 4999/10000, mean_policy_losses: -68.449, mean_net_lifetime: 6523.7373, mean_mc_travel_dist: 6421.2675, mean_rewards: 101.5160, total_rewards: 5239.9811, mean_steps: 69.9200, mean_ecr: 0.0404 mean_entropies: 1.6887, took: 133.9735s
2022-07-31 20:41:30,332 [INFO] 	Process 3: Batch 5099/10000, mean_policy_losses: -97.847, mean_net_lifetime: 6414.0677, mean_mc_travel_dist: 6333.1958, mean_rewards: 103.8177, total_rewards: 5148.6725, mean_steps: 68.7300, mean_ecr: 0.0407 mean_entropies: 1.6189, took: 133.1742s
2022-07-31 20:43:47,737 [INFO] 	Process 3: Batch 5199/10000, mean_policy_losses: -44.281, mean_net_lifetime: 6326.5507, mean_mc_travel_dist: 6589.2064, mean_rewards: 96.7840, total_rewards: 5009.3827, mean_steps: 71.7700, mean_ecr: 0.0392 mean_entropies: 1.6532, took: 137.4043s
2022-07-31 20:46:07,252 [INFO] 	Process 3: Batch 5299/10000, mean_policy_losses: -17.698, mean_net_lifetime: 6472.9142, mean_mc_travel_dist: 6474.1186, mean_rewards: 100.1445, total_rewards: 5178.3120, mean_steps: 71.2200, mean_ecr: 0.0401 mean_entropies: 1.5678, took: 139.5159s
2022-07-31 20:48:27,230 [INFO] 	Process 3: Batch 5399/10000, mean_policy_losses: -77.016, mean_net_lifetime: 6661.9550, mean_mc_travel_dist: 6356.2343, mean_rewards: 104.1075, total_rewards: 5391.7882, mean_steps: 69.8000, mean_ecr: 0.0405 mean_entropies: 1.5811, took: 139.9781s
2022-07-31 20:50:43,256 [INFO] 	Process 3: Batch 5499/10000, mean_policy_losses: -54.939, mean_net_lifetime: 6647.7851, mean_mc_travel_dist: 6228.6757, mean_rewards: 104.0947, total_rewards: 5402.0500, mean_steps: 67.8600, mean_ecr: 0.0413 mean_entropies: 1.5806, took: 136.0251s
2022-07-31 20:53:07,324 [INFO] 	Process 3: Batch 5599/10000, mean_policy_losses: -55.794, mean_net_lifetime: 6268.1959, mean_mc_travel_dist: 6668.5256, mean_rewards: 96.9472, total_rewards: 4934.6193, mean_steps: 73.7500, mean_ecr: 0.0396 mean_entropies: 1.5858, took: 144.0693s
2022-07-31 20:55:24,524 [INFO] 	Process 3: Batch 5699/10000, mean_policy_losses: -30.475, mean_net_lifetime: 6420.0381, mean_mc_travel_dist: 6360.5260, mean_rewards: 102.1476, total_rewards: 5148.7036, mean_steps: 69.1100, mean_ecr: 0.0403 mean_entropies: 1.6183, took: 137.1994s
2022-07-31 20:57:39,501 [INFO] 	Process 3: Batch 5799/10000, mean_policy_losses: -90.891, mean_net_lifetime: 6382.7381, mean_mc_travel_dist: 6354.7196, mean_rewards: 102.4610, total_rewards: 5112.8237, mean_steps: 68.7800, mean_ecr: 0.0409 mean_entropies: 1.5759, took: 134.9767s
2022-07-31 20:59:44,420 [INFO] 	Process 3: Batch 5899/10000, mean_policy_losses: -90.036, mean_net_lifetime: 6473.2493, mean_mc_travel_dist: 6072.9484, mean_rewards: 109.4458, total_rewards: 5259.1850, mean_steps: 65.5200, mean_ecr: 0.0419 mean_entropies: 1.4922, took: 124.9203s
2022-07-31 21:02:00,208 [INFO] 	Process 3: Batch 5999/10000, mean_policy_losses: -55.712, mean_net_lifetime: 6438.5420, mean_mc_travel_dist: 6602.5159, mean_rewards: 97.5476, total_rewards: 5118.2358, mean_steps: 71.7400, mean_ecr: 0.0391 mean_entropies: 1.5463, took: 135.7882s
2022-07-31 21:04:04,150 [INFO] 	Process 3: Batch 6099/10000, mean_policy_losses: -87.475, mean_net_lifetime: 6554.4790, mean_mc_travel_dist: 6231.6774, mean_rewards: 108.7567, total_rewards: 5309.5561, mean_steps: 66.0600, mean_ecr: 0.0410 mean_entropies: 1.4899, took: 123.9418s
2022-07-31 21:06:12,742 [INFO] 	Process 3: Batch 6199/10000, mean_policy_losses: -74.233, mean_net_lifetime: 6513.7428, mean_mc_travel_dist: 6307.3776, mean_rewards: 104.0496, total_rewards: 5252.8861, mean_steps: 68.3500, mean_ecr: 0.0406 mean_entropies: 1.4792, took: 128.5912s
2022-07-31 21:08:23,335 [INFO] 	Process 3: Batch 6299/10000, mean_policy_losses: -33.950, mean_net_lifetime: 6633.0688, mean_mc_travel_dist: 6444.8502, mean_rewards: 102.5479, total_rewards: 5344.7955, mean_steps: 69.3700, mean_ecr: 0.0402 mean_entropies: 1.4898, took: 130.5932s
2022-07-31 21:10:36,170 [INFO] 	Process 3: Batch 6399/10000, mean_policy_losses: -80.792, mean_net_lifetime: 6385.2903, mean_mc_travel_dist: 6332.8611, mean_rewards: 100.3226, total_rewards: 5118.7181, mean_steps: 69.5700, mean_ecr: 0.0408 mean_entropies: 1.4974, took: 132.8345s
2022-07-31 21:12:46,744 [INFO] 	Process 3: Batch 6499/10000, mean_policy_losses: -21.188, mean_net_lifetime: 6666.1992, mean_mc_travel_dist: 6334.1441, mean_rewards: 104.9187, total_rewards: 5400.1802, mean_steps: 68.3800, mean_ecr: 0.0404 mean_entropies: 1.4909, took: 130.5753s
2022-07-31 21:14:56,309 [INFO] 	Process 3: Batch 6599/10000, mean_policy_losses: -59.029, mean_net_lifetime: 6547.1988, mean_mc_travel_dist: 6349.4016, mean_rewards: 105.3474, total_rewards: 5278.1576, mean_steps: 67.6500, mean_ecr: 0.0411 mean_entropies: 1.4836, took: 129.5643s
2022-07-31 21:17:10,012 [INFO] 	Process 3: Batch 6699/10000, mean_policy_losses: -72.556, mean_net_lifetime: 6557.8480, mean_mc_travel_dist: 6548.9092, mean_rewards: 103.5865, total_rewards: 5248.4157, mean_steps: 68.9700, mean_ecr: 0.0395 mean_entropies: 1.4953, took: 133.7016s
2022-07-31 21:19:22,761 [INFO] 	Process 3: Batch 6799/10000, mean_policy_losses: -55.143, mean_net_lifetime: 6339.0920, mean_mc_travel_dist: 6405.9907, mean_rewards: 102.5471, total_rewards: 5058.0166, mean_steps: 67.7700, mean_ecr: 0.0405 mean_entropies: 1.5024, took: 132.7499s
2022-07-31 21:21:45,843 [INFO] 	Process 3: Batch 6899/10000, mean_policy_losses: -78.123, mean_net_lifetime: 6046.6784, mean_mc_travel_dist: 6552.4995, mean_rewards: 95.9856, total_rewards: 4737.6504, mean_steps: 71.4500, mean_ecr: 0.0395 mean_entropies: 1.4864, took: 143.0806s
2022-07-31 21:24:19,478 [INFO] 	Process 3: Batch 6999/10000, mean_policy_losses: -56.857, mean_net_lifetime: 6479.2338, mean_mc_travel_dist: 6353.8081, mean_rewards: 103.8725, total_rewards: 5208.6497, mean_steps: 68.4400, mean_ecr: 0.0404 mean_entropies: 1.4441, took: 153.6364s
2022-07-31 21:26:40,835 [INFO] 	Process 3: Batch 7099/10000, mean_policy_losses: -51.283, mean_net_lifetime: 6732.0035, mean_mc_travel_dist: 6465.0399, mean_rewards: 102.8343, total_rewards: 5438.9956, mean_steps: 70.6800, mean_ecr: 0.0400 mean_entropies: 1.4147, took: 141.3578s
2022-07-31 21:28:57,981 [INFO] 	Process 3: Batch 7199/10000, mean_policy_losses: -52.758, mean_net_lifetime: 6425.7134, mean_mc_travel_dist: 6565.9139, mean_rewards: 99.3729, total_rewards: 5112.8039, mean_steps: 71.8500, mean_ecr: 0.0396 mean_entropies: 1.4616, took: 137.1465s
2022-07-31 21:31:03,593 [INFO] 	Process 3: Batch 7299/10000, mean_policy_losses: -78.592, mean_net_lifetime: 6741.5659, mean_mc_travel_dist: 6167.6275, mean_rewards: 111.8217, total_rewards: 5508.0404, mean_steps: 65.2400, mean_ecr: 0.0417 mean_entropies: 1.4468, took: 125.6096s
2022-07-31 21:33:11,635 [INFO] 	Process 3: Batch 7399/10000, mean_policy_losses: -82.317, mean_net_lifetime: 6214.5169, mean_mc_travel_dist: 6373.9345, mean_rewards: 101.7770, total_rewards: 4940.4008, mean_steps: 67.4400, mean_ecr: 0.0404 mean_entropies: 1.5050, took: 128.0429s
2022-07-31 21:35:20,842 [INFO] 	Process 3: Batch 7499/10000, mean_policy_losses: -41.626, mean_net_lifetime: 6241.8584, mean_mc_travel_dist: 6397.9681, mean_rewards: 101.2140, total_rewards: 4962.5658, mean_steps: 68.1400, mean_ecr: 0.0401 mean_entropies: 1.4629, took: 129.2062s
2022-07-31 21:37:30,059 [INFO] 	Process 3: Batch 7599/10000, mean_policy_losses: -64.871, mean_net_lifetime: 6290.1937, mean_mc_travel_dist: 6309.0406, mean_rewards: 103.5663, total_rewards: 5028.8069, mean_steps: 67.9300, mean_ecr: 0.0406 mean_entropies: 1.4079, took: 129.2183s
2022-07-31 21:39:41,227 [INFO] 	Process 3: Batch 7699/10000, mean_policy_losses: -58.071, mean_net_lifetime: 6420.2950, mean_mc_travel_dist: 6257.7929, mean_rewards: 105.4968, total_rewards: 5169.1190, mean_steps: 67.9800, mean_ecr: 0.0411 mean_entropies: 1.3180, took: 131.1671s
2022-07-31 21:41:59,915 [INFO] 	Process 3: Batch 7799/10000, mean_policy_losses: -36.890, mean_net_lifetime: 6518.0629, mean_mc_travel_dist: 6718.9227, mean_rewards: 100.9063, total_rewards: 5174.4935, mean_steps: 71.2500, mean_ecr: 0.0388 mean_entropies: 1.4386, took: 138.6895s
2022-07-31 21:44:24,420 [INFO] 	Process 3: Batch 7899/10000, mean_policy_losses: -93.074, mean_net_lifetime: 6479.2156, mean_mc_travel_dist: 6396.3984, mean_rewards: 106.3040, total_rewards: 5200.6731, mean_steps: 67.7400, mean_ecr: 0.0406 mean_entropies: 1.4053, took: 144.5047s
2022-07-31 21:46:40,912 [INFO] 	Process 3: Batch 7999/10000, mean_policy_losses: -81.747, mean_net_lifetime: 6685.5240, mean_mc_travel_dist: 6572.4727, mean_rewards: 106.5297, total_rewards: 5371.3109, mean_steps: 67.0300, mean_ecr: 0.0397 mean_entropies: 1.3769, took: 136.4918s
2022-07-31 21:48:47,474 [INFO] 	Process 3: Batch 8099/10000, mean_policy_losses: -109.416, mean_net_lifetime: 6480.3740, mean_mc_travel_dist: 6224.1357, mean_rewards: 109.0365, total_rewards: 5236.1671, mean_steps: 64.7900, mean_ecr: 0.0415 mean_entropies: 1.3497, took: 126.5603s
2022-07-31 21:51:06,127 [INFO] 	Process 3: Batch 8199/10000, mean_policy_losses: -37.073, mean_net_lifetime: 6301.5785, mean_mc_travel_dist: 6378.0090, mean_rewards: 104.9598, total_rewards: 5027.2881, mean_steps: 66.9500, mean_ecr: 0.0407 mean_entropies: 1.3623, took: 138.6549s
2022-07-31 21:53:18,386 [INFO] 	Process 3: Batch 8299/10000, mean_policy_losses: -98.046, mean_net_lifetime: 6509.8839, mean_mc_travel_dist: 6345.5739, mean_rewards: 106.6345, total_rewards: 5242.1602, mean_steps: 68.0800, mean_ecr: 0.0406 mean_entropies: 1.3810, took: 132.2575s
2022-07-31 21:55:28,690 [INFO] 	Process 3: Batch 8399/10000, mean_policy_losses: -25.377, mean_net_lifetime: 6593.2645, mean_mc_travel_dist: 6458.8904, mean_rewards: 104.7628, total_rewards: 5301.7295, mean_steps: 68.7900, mean_ecr: 0.0401 mean_entropies: 1.3934, took: 130.3056s
2022-07-31 21:57:41,990 [INFO] 	Process 3: Batch 8499/10000, mean_policy_losses: -109.177, mean_net_lifetime: 6545.1933, mean_mc_travel_dist: 6616.1225, mean_rewards: 102.8440, total_rewards: 5223.3004, mean_steps: 69.5800, mean_ecr: 0.0394 mean_entropies: 1.4286, took: 133.2989s
2022-07-31 21:59:51,546 [INFO] 	Process 3: Batch 8599/10000, mean_policy_losses: -89.357, mean_net_lifetime: 6521.2130, mean_mc_travel_dist: 6485.0645, mean_rewards: 104.8369, total_rewards: 5224.4807, mean_steps: 67.9500, mean_ecr: 0.0401 mean_entropies: 1.3719, took: 129.5541s
2022-07-31 22:02:08,688 [INFO] 	Process 3: Batch 8699/10000, mean_policy_losses: -73.703, mean_net_lifetime: 6502.5687, mean_mc_travel_dist: 6729.7612, mean_rewards: 100.5475, total_rewards: 5157.0148, mean_steps: 70.1700, mean_ecr: 0.0389 mean_entropies: 1.4016, took: 137.1437s
2022-07-31 22:04:31,571 [INFO] 	Process 3: Batch 8799/10000, mean_policy_losses: -60.796, mean_net_lifetime: 6669.2219, mean_mc_travel_dist: 6657.7710, mean_rewards: 102.6505, total_rewards: 5338.2081, mean_steps: 70.7400, mean_ecr: 0.0390 mean_entropies: 1.3323, took: 142.8835s
2022-07-31 22:06:47,259 [INFO] 	Process 3: Batch 8899/10000, mean_policy_losses: -84.150, mean_net_lifetime: 6539.2653, mean_mc_travel_dist: 6490.2506, mean_rewards: 103.7051, total_rewards: 5242.0070, mean_steps: 68.4000, mean_ecr: 0.0401 mean_entropies: 1.3146, took: 135.6866s
2022-07-31 22:08:49,303 [INFO] 	Process 3: Batch 8999/10000, mean_policy_losses: -68.628, mean_net_lifetime: 6287.1608, mean_mc_travel_dist: 6269.2065, mean_rewards: 109.6263, total_rewards: 5033.6355, mean_steps: 63.9000, mean_ecr: 0.0413 mean_entropies: 1.2860, took: 122.0460s
2022-07-31 22:10:59,081 [INFO] 	Process 3: Batch 9099/10000, mean_policy_losses: -77.725, mean_net_lifetime: 6572.9764, mean_mc_travel_dist: 6243.6724, mean_rewards: 108.9290, total_rewards: 5324.8514, mean_steps: 66.4000, mean_ecr: 0.0408 mean_entropies: 1.2729, took: 129.7778s
2022-07-31 22:13:11,027 [INFO] 	Process 3: Batch 9199/10000, mean_policy_losses: -71.010, mean_net_lifetime: 6299.2663, mean_mc_travel_dist: 6432.1810, mean_rewards: 103.9266, total_rewards: 5012.8301, mean_steps: 67.6900, mean_ecr: 0.0399 mean_entropies: 1.2859, took: 131.9468s
2022-07-31 22:15:19,582 [INFO] 	Process 3: Batch 9299/10000, mean_policy_losses: -45.378, mean_net_lifetime: 6490.5480, mean_mc_travel_dist: 6480.8454, mean_rewards: 104.3996, total_rewards: 5195.3077, mean_steps: 67.9700, mean_ecr: 0.0400 mean_entropies: 1.2752, took: 128.5535s
2022-07-31 22:17:30,061 [INFO] 	Process 3: Batch 9399/10000, mean_policy_losses: -80.378, mean_net_lifetime: 6652.1402, mean_mc_travel_dist: 6423.4891, mean_rewards: 110.1510, total_rewards: 5367.5623, mean_steps: 66.2500, mean_ecr: 0.0402 mean_entropies: 1.2630, took: 130.4786s
2022-07-31 22:19:34,771 [INFO] 	Process 3: Batch 9499/10000, mean_policy_losses: -57.615, mean_net_lifetime: 6326.7435, mean_mc_travel_dist: 6084.1352, mean_rewards: 110.4139, total_rewards: 5110.6611, mean_steps: 62.5800, mean_ecr: 0.0418 mean_entropies: 1.2492, took: 124.7105s
2022-07-31 22:21:43,542 [INFO] 	Process 3: Batch 9599/10000, mean_policy_losses: -115.210, mean_net_lifetime: 6447.3943, mean_mc_travel_dist: 6542.3149, mean_rewards: 106.1502, total_rewards: 5139.7442, mean_steps: 67.3000, mean_ecr: 0.0394 mean_entropies: 1.2858, took: 128.7718s
2022-07-31 22:23:44,754 [INFO] 	Process 3: Batch 9699/10000, mean_policy_losses: -51.929, mean_net_lifetime: 6479.7133, mean_mc_travel_dist: 6451.7919, mean_rewards: 107.8149, total_rewards: 5189.9788, mean_steps: 63.7900, mean_ecr: 0.0401 mean_entropies: 1.2029, took: 121.2110s
2022-07-31 22:25:41,937 [INFO] 	Process 3: Batch 9799/10000, mean_policy_losses: -59.057, mean_net_lifetime: 6549.6087, mean_mc_travel_dist: 6072.6434, mean_rewards: 117.6020, total_rewards: 5336.0893, mean_steps: 59.7800, mean_ecr: 0.0419 mean_entropies: 1.1652, took: 117.1810s
2022-07-31 22:27:47,143 [INFO] 	Process 3: Batch 9899/10000, mean_policy_losses: -81.001, mean_net_lifetime: 6248.6483, mean_mc_travel_dist: 6484.3028, mean_rewards: 108.0792, total_rewards: 4952.0941, mean_steps: 63.6300, mean_ecr: 0.0402 mean_entropies: 1.2561, took: 125.2085s
2022-07-31 22:29:47,022 [INFO] 	Process 3: Batch 9999/10000, mean_policy_losses: -58.900, mean_net_lifetime: 6654.9122, mean_mc_travel_dist: 6288.3131, mean_rewards: 113.5510, total_rewards: 5397.9272, mean_steps: 62.9600, mean_ecr: 0.0406 mean_entropies: 1.1613, took: 119.8778s
2022-07-31 22:40:03,515 [INFO] Process 3: Epoch 1: mean_policy_losses: -54.591, mean_net_lifetime: 6239.6913, mean_mc_travel_dist: 6499.7927, mean_entropies: 1.7501, m_net_lifetime_valid: 6492.0902, took: 14381.1564s, (136.2838 / 100 batches)

2022-07-31 22:40:03,516 [INFO] Process 3: Start epoch 2
2022-07-31 22:42:15,650 [INFO] 	Process 3: Batch 99/10000, mean_policy_losses: 53.720, mean_net_lifetime: 4517.0233, mean_mc_travel_dist: 7334.6679, mean_rewards: 62.4855, total_rewards: 3053.4784, mean_steps: 72.0200, mean_ecr: 0.0408 mean_entropies: 2.9202, took: 132.1287s
2022-07-31 22:44:37,885 [INFO] 	Process 3: Batch 199/10000, mean_policy_losses: -15.184, mean_net_lifetime: 4408.1871, mean_mc_travel_dist: 6899.9842, mean_rewards: 63.0999, total_rewards: 3029.9736, mean_steps: 70.8700, mean_ecr: 0.0410 mean_entropies: 2.8242, took: 142.2343s
2022-07-31 22:47:11,081 [INFO] 	Process 3: Batch 299/10000, mean_policy_losses: 15.536, mean_net_lifetime: 4462.6782, mean_mc_travel_dist: 7103.0192, mean_rewards: 60.9616, total_rewards: 3046.0789, mean_steps: 75.3500, mean_ecr: 0.0391 mean_entropies: 2.7479, took: 153.1952s
2022-07-31 22:49:34,092 [INFO] 	Process 3: Batch 399/10000, mean_policy_losses: -19.742, mean_net_lifetime: 4576.1563, mean_mc_travel_dist: 6891.9459, mean_rewards: 62.3395, total_rewards: 3199.5410, mean_steps: 74.7100, mean_ecr: 0.0408 mean_entropies: 2.7022, took: 143.0122s
2022-07-31 22:51:58,175 [INFO] 	Process 3: Batch 499/10000, mean_policy_losses: 27.399, mean_net_lifetime: 4738.1178, mean_mc_travel_dist: 6982.0261, mean_rewards: 65.0787, total_rewards: 3344.1238, mean_steps: 77.2700, mean_ecr: 0.0398 mean_entropies: 2.6290, took: 144.0829s
2022-07-31 22:54:36,253 [INFO] 	Process 3: Batch 599/10000, mean_policy_losses: -1.139, mean_net_lifetime: 5089.7725, mean_mc_travel_dist: 7426.2309, mean_rewards: 63.9741, total_rewards: 3607.1329, mean_steps: 83.7800, mean_ecr: 0.0384 mean_entropies: 2.6030, took: 158.0778s
2022-07-31 22:56:53,782 [INFO] 	Process 3: Batch 699/10000, mean_policy_losses: 45.236, mean_net_lifetime: 5072.3530, mean_mc_travel_dist: 6845.4151, mean_rewards: 73.2654, total_rewards: 3704.3899, mean_steps: 72.9000, mean_ecr: 0.0408 mean_entropies: 2.6514, took: 137.5293s
2022-07-31 22:59:16,453 [INFO] 	Process 3: Batch 799/10000, mean_policy_losses: -66.205, mean_net_lifetime: 5165.3121, mean_mc_travel_dist: 6813.2764, mean_rewards: 72.8306, total_rewards: 3804.6578, mean_steps: 75.3300, mean_ecr: 0.0404 mean_entropies: 2.6315, took: 142.6695s
2022-07-31 23:01:50,159 [INFO] 	Process 3: Batch 899/10000, mean_policy_losses: -14.289, mean_net_lifetime: 5729.7821, mean_mc_travel_dist: 6841.0870, mean_rewards: 78.6047, total_rewards: 4361.6756, mean_steps: 77.5200, mean_ecr: 0.0402 mean_entropies: 2.5386, took: 153.7058s
2022-07-31 23:04:29,231 [INFO] 	Process 3: Batch 999/10000, mean_policy_losses: -34.745, mean_net_lifetime: 5846.1420, mean_mc_travel_dist: 6994.2764, mean_rewards: 78.1450, total_rewards: 4448.8031, mean_steps: 79.6700, mean_ecr: 0.0396 mean_entropies: 2.4719, took: 159.0735s
2022-07-31 23:06:48,222 [INFO] 	Process 3: Batch 1099/10000, mean_policy_losses: -22.605, mean_net_lifetime: 5708.9066, mean_mc_travel_dist: 6769.2035, mean_rewards: 81.3512, total_rewards: 4355.2589, mean_steps: 74.0800, mean_ecr: 0.0400 mean_entropies: 2.4374, took: 138.9898s
2022-07-31 23:09:16,544 [INFO] 	Process 3: Batch 1199/10000, mean_policy_losses: -38.743, mean_net_lifetime: 5691.0286, mean_mc_travel_dist: 6971.7299, mean_rewards: 78.3382, total_rewards: 4297.6750, mean_steps: 78.4600, mean_ecr: 0.0390 mean_entropies: 2.3488, took: 148.3222s
2022-07-31 23:11:47,252 [INFO] 	Process 3: Batch 1299/10000, mean_policy_losses: -6.079, mean_net_lifetime: 6382.7962, mean_mc_travel_dist: 6950.5492, mean_rewards: 86.3996, total_rewards: 4993.1033, mean_steps: 79.0300, mean_ecr: 0.0405 mean_entropies: 2.3521, took: 150.7095s
2022-07-31 23:14:47,792 [INFO] 	Process 3: Batch 1399/10000, mean_policy_losses: -36.572, mean_net_lifetime: 7495.8227, mean_mc_travel_dist: 8749.0522, mean_rewards: 87.3219, total_rewards: 5746.6665, mean_steps: 96.0900, mean_ecr: 0.0402 mean_entropies: 2.3029, took: 180.5398s
2022-07-31 23:17:17,924 [INFO] 	Process 3: Batch 1499/10000, mean_policy_losses: -0.954, mean_net_lifetime: 5996.6170, mean_mc_travel_dist: 6991.4188, mean_rewards: 83.7575, total_rewards: 4598.5531, mean_steps: 78.3300, mean_ecr: 0.0395 mean_entropies: 2.2876, took: 150.1323s
2022-07-31 23:19:39,925 [INFO] 	Process 3: Batch 1599/10000, mean_policy_losses: -59.407, mean_net_lifetime: 6311.0675, mean_mc_travel_dist: 6538.5830, mean_rewards: 91.9738, total_rewards: 5003.9267, mean_steps: 72.9200, mean_ecr: 0.0417 mean_entropies: 2.1636, took: 141.9991s
2022-07-31 23:22:17,967 [INFO] 	Process 3: Batch 1699/10000, mean_policy_losses: -59.233, mean_net_lifetime: 5952.9937, mean_mc_travel_dist: 7033.2650, mean_rewards: 82.9289, total_rewards: 4546.9640, mean_steps: 78.8200, mean_ecr: 0.0388 mean_entropies: 2.1566, took: 158.0426s
2022-07-31 23:24:42,757 [INFO] 	Process 3: Batch 1799/10000, mean_policy_losses: -13.656, mean_net_lifetime: 6073.0333, mean_mc_travel_dist: 6697.5792, mean_rewards: 88.6347, total_rewards: 4734.4419, mean_steps: 73.7700, mean_ecr: 0.0398 mean_entropies: 2.1788, took: 144.7902s
2022-07-31 23:27:03,861 [INFO] 	Process 3: Batch 1899/10000, mean_policy_losses: -46.728, mean_net_lifetime: 6138.3000, mean_mc_travel_dist: 6644.3565, mean_rewards: 91.0157, total_rewards: 4810.2914, mean_steps: 73.8100, mean_ecr: 0.0404 mean_entropies: 2.1205, took: 141.1050s
2022-07-31 23:29:24,216 [INFO] 	Process 3: Batch 1999/10000, mean_policy_losses: -60.977, mean_net_lifetime: 6171.3771, mean_mc_travel_dist: 6532.1613, mean_rewards: 92.4561, total_rewards: 4865.5637, mean_steps: 71.8500, mean_ecr: 0.0413 mean_entropies: 2.1523, took: 140.3531s
2022-07-31 23:31:46,213 [INFO] 	Process 3: Batch 2099/10000, mean_policy_losses: -57.582, mean_net_lifetime: 6408.3133, mean_mc_travel_dist: 6810.1109, mean_rewards: 89.4732, total_rewards: 5047.2494, mean_steps: 74.5400, mean_ecr: 0.0390 mean_entropies: 2.1614, took: 141.9974s
2022-07-31 23:34:01,431 [INFO] 	Process 3: Batch 2199/10000, mean_policy_losses: -93.888, mean_net_lifetime: 6270.1026, mean_mc_travel_dist: 6440.7935, mean_rewards: 96.6606, total_rewards: 4982.6607, mean_steps: 70.6200, mean_ecr: 0.0411 mean_entropies: 2.0809, took: 135.2182s
2022-07-31 23:36:28,098 [INFO] 	Process 3: Batch 2299/10000, mean_policy_losses: -32.679, mean_net_lifetime: 6263.7260, mean_mc_travel_dist: 6925.0874, mean_rewards: 89.1764, total_rewards: 4878.8433, mean_steps: 77.6600, mean_ecr: 0.0385 mean_entropies: 2.0351, took: 146.6677s
2022-07-31 23:39:06,690 [INFO] 	Process 3: Batch 2399/10000, mean_policy_losses: -41.506, mean_net_lifetime: 7115.3055, mean_mc_travel_dist: 7767.6057, mean_rewards: 96.4718, total_rewards: 5562.4338, mean_steps: 84.3100, mean_ecr: 0.0408 mean_entropies: 1.9905, took: 158.5923s
2022-07-31 23:41:23,809 [INFO] 	Process 3: Batch 2499/10000, mean_policy_losses: -84.608, mean_net_lifetime: 6255.2613, mean_mc_travel_dist: 6465.9273, mean_rewards: 95.4854, total_rewards: 4962.8918, mean_steps: 72.4400, mean_ecr: 0.0410 mean_entropies: 1.9458, took: 137.1188s
2022-07-31 23:43:51,970 [INFO] 	Process 3: Batch 2599/10000, mean_policy_losses: -97.655, mean_net_lifetime: 6229.1780, mean_mc_travel_dist: 6687.9298, mean_rewards: 92.2665, total_rewards: 4892.0576, mean_steps: 74.3900, mean_ecr: 0.0396 mean_entropies: 2.0019, took: 148.1615s
2022-07-31 23:45:59,246 [INFO] 	Process 3: Batch 2699/10000, mean_policy_losses: -30.783, mean_net_lifetime: 6121.0545, mean_mc_travel_dist: 6328.6074, mean_rewards: 97.7455, total_rewards: 4856.0275, mean_steps: 68.6000, mean_ecr: 0.0414 mean_entropies: 1.9557, took: 127.2750s
2022-07-31 23:48:10,121 [INFO] 	Process 3: Batch 2799/10000, mean_policy_losses: -72.549, mean_net_lifetime: 6180.8748, mean_mc_travel_dist: 6320.0867, mean_rewards: 99.5234, total_rewards: 4917.0849, mean_steps: 68.0300, mean_ecr: 0.0411 mean_entropies: 1.9909, took: 130.8739s
2022-07-31 23:50:27,834 [INFO] 	Process 3: Batch 2899/10000, mean_policy_losses: -59.135, mean_net_lifetime: 6528.0304, mean_mc_travel_dist: 6586.8385, mean_rewards: 97.3361, total_rewards: 5210.9762, mean_steps: 71.6400, mean_ecr: 0.0399 mean_entropies: 2.0131, took: 137.7147s
2022-07-31 23:52:48,945 [INFO] 	Process 3: Batch 2999/10000, mean_policy_losses: -42.677, mean_net_lifetime: 6383.6442, mean_mc_travel_dist: 6858.8994, mean_rewards: 91.7895, total_rewards: 5012.7519, mean_steps: 75.2800, mean_ecr: 0.0382 mean_entropies: 1.9545, took: 141.1107s
2022-07-31 23:55:06,346 [INFO] 	Process 3: Batch 3099/10000, mean_policy_losses: -19.321, mean_net_lifetime: 6318.8268, mean_mc_travel_dist: 6681.2143, mean_rewards: 95.2007, total_rewards: 4983.8481, mean_steps: 72.7800, mean_ecr: 0.0395 mean_entropies: 1.9308, took: 137.4000s
2022-07-31 23:57:22,357 [INFO] 	Process 3: Batch 3199/10000, mean_policy_losses: -10.480, mean_net_lifetime: 6556.6143, mean_mc_travel_dist: 6583.7699, mean_rewards: 97.9737, total_rewards: 5239.8604, mean_steps: 72.1000, mean_ecr: 0.0403 mean_entropies: 1.8491, took: 136.0111s
2022-07-31 23:59:36,835 [INFO] 	Process 3: Batch 3299/10000, mean_policy_losses: -131.312, mean_net_lifetime: 6350.8900, mean_mc_travel_dist: 6510.4159, mean_rewards: 98.3574, total_rewards: 5049.3345, mean_steps: 71.3000, mean_ecr: 0.0402 mean_entropies: 1.8047, took: 134.4798s
2022-08-01 00:01:48,847 [INFO] 	Process 3: Batch 3399/10000, mean_policy_losses: -100.659, mean_net_lifetime: 6546.7563, mean_mc_travel_dist: 6151.7977, mean_rewards: 104.8098, total_rewards: 5316.5289, mean_steps: 68.4200, mean_ecr: 0.0415 mean_entropies: 1.8026, took: 132.0101s
2022-08-01 00:04:04,950 [INFO] 	Process 3: Batch 3499/10000, mean_policy_losses: -44.635, mean_net_lifetime: 6396.4701, mean_mc_travel_dist: 6258.3821, mean_rewards: 98.9449, total_rewards: 5145.9067, mean_steps: 69.2100, mean_ecr: 0.0412 mean_entropies: 1.8556, took: 136.1051s
2022-08-01 00:06:15,238 [INFO] 	Process 3: Batch 3599/10000, mean_policy_losses: -80.915, mean_net_lifetime: 6402.8086, mean_mc_travel_dist: 6270.5620, mean_rewards: 102.5070, total_rewards: 5148.9715, mean_steps: 68.6700, mean_ecr: 0.0414 mean_entropies: 1.7941, took: 130.2865s
2022-08-01 00:08:29,547 [INFO] 	Process 3: Batch 3699/10000, mean_policy_losses: -82.206, mean_net_lifetime: 6287.7838, mean_mc_travel_dist: 6310.4259, mean_rewards: 100.0941, total_rewards: 5026.1207, mean_steps: 69.8300, mean_ecr: 0.0408 mean_entropies: 1.7718, took: 134.3095s
2022-08-01 00:10:46,779 [INFO] 	Process 3: Batch 3799/10000, mean_policy_losses: -60.775, mean_net_lifetime: 6414.5003, mean_mc_travel_dist: 6401.8701, mean_rewards: 100.2836, total_rewards: 5134.7517, mean_steps: 70.8500, mean_ecr: 0.0406 mean_entropies: 1.7632, took: 137.2307s
2022-08-01 00:12:53,604 [INFO] 	Process 3: Batch 3899/10000, mean_policy_losses: -62.672, mean_net_lifetime: 6538.0965, mean_mc_travel_dist: 6190.2084, mean_rewards: 107.9736, total_rewards: 5300.2793, mean_steps: 66.3400, mean_ecr: 0.0417 mean_entropies: 1.7665, took: 126.8278s
2022-08-01 00:15:14,148 [INFO] 	Process 3: Batch 3999/10000, mean_policy_losses: -77.071, mean_net_lifetime: 6533.1225, mean_mc_travel_dist: 6797.1547, mean_rewards: 95.0844, total_rewards: 5173.6915, mean_steps: 73.6200, mean_ecr: 0.0387 mean_entropies: 1.8272, took: 140.5419s
2022-08-01 00:17:25,493 [INFO] 	Process 3: Batch 4099/10000, mean_policy_losses: -34.285, mean_net_lifetime: 6389.0833, mean_mc_travel_dist: 6335.2155, mean_rewards: 102.4189, total_rewards: 5122.5415, mean_steps: 68.9500, mean_ecr: 0.0408 mean_entropies: 1.7216, took: 131.3453s
2022-08-01 00:19:29,027 [INFO] 	Process 3: Batch 4199/10000, mean_policy_losses: -82.745, mean_net_lifetime: 6244.2282, mean_mc_travel_dist: 5962.7161, mean_rewards: 106.8528, total_rewards: 5052.1414, mean_steps: 64.8100, mean_ecr: 0.0425 mean_entropies: 1.7178, took: 123.5340s
2022-08-01 00:21:44,443 [INFO] 	Process 3: Batch 4299/10000, mean_policy_losses: -36.007, mean_net_lifetime: 6456.1406, mean_mc_travel_dist: 6614.6044, mean_rewards: 96.9771, total_rewards: 5133.5720, mean_steps: 71.2500, mean_ecr: 0.0394 mean_entropies: 1.7720, took: 135.4148s
2022-08-01 00:23:53,588 [INFO] 	Process 3: Batch 4399/10000, mean_policy_losses: -92.419, mean_net_lifetime: 6373.2797, mean_mc_travel_dist: 6108.2257, mean_rewards: 106.3144, total_rewards: 5152.4715, mean_steps: 65.5600, mean_ecr: 0.0421 mean_entropies: 1.7020, took: 129.1465s
2022-08-01 00:26:05,780 [INFO] 	Process 3: Batch 4499/10000, mean_policy_losses: -25.251, mean_net_lifetime: 6390.9388, mean_mc_travel_dist: 6322.5899, mean_rewards: 101.9225, total_rewards: 5126.6648, mean_steps: 69.4500, mean_ecr: 0.0410 mean_entropies: 1.6973, took: 132.1926s
2022-08-01 00:28:17,606 [INFO] 	Process 3: Batch 4599/10000, mean_policy_losses: -57.322, mean_net_lifetime: 6521.7504, mean_mc_travel_dist: 6296.9249, mean_rewards: 104.5372, total_rewards: 5262.6029, mean_steps: 67.5900, mean_ecr: 0.0408 mean_entropies: 1.6849, took: 131.8251s
2022-08-01 00:30:29,475 [INFO] 	Process 3: Batch 4699/10000, mean_policy_losses: -78.461, mean_net_lifetime: 6430.3463, mean_mc_travel_dist: 6369.0350, mean_rewards: 101.7094, total_rewards: 5157.5495, mean_steps: 68.8300, mean_ecr: 0.0405 mean_entropies: 1.7002, took: 131.8700s
2022-08-01 00:32:40,145 [INFO] 	Process 3: Batch 4799/10000, mean_policy_losses: -37.562, mean_net_lifetime: 6521.0761, mean_mc_travel_dist: 6306.0368, mean_rewards: 103.2381, total_rewards: 5260.7968, mean_steps: 68.6600, mean_ecr: 0.0400 mean_entropies: 1.6734, took: 130.6691s
2022-08-01 00:34:44,363 [INFO] 	Process 3: Batch 4899/10000, mean_policy_losses: -82.178, mean_net_lifetime: 6517.7403, mean_mc_travel_dist: 6079.4874, mean_rewards: 110.7257, total_rewards: 5302.6226, mean_steps: 64.5100, mean_ecr: 0.0419 mean_entropies: 1.6196, took: 124.2180s
2022-08-01 00:36:53,228 [INFO] 	Process 3: Batch 4999/10000, mean_policy_losses: -57.599, mean_net_lifetime: 6513.5804, mean_mc_travel_dist: 6330.8751, mean_rewards: 103.2261, total_rewards: 5248.1081, mean_steps: 68.0300, mean_ecr: 0.0406 mean_entropies: 1.6563, took: 128.8657s
2022-08-01 00:39:05,638 [INFO] 	Process 3: Batch 5099/10000, mean_policy_losses: -101.601, mean_net_lifetime: 6082.2460, mean_mc_travel_dist: 6515.8853, mean_rewards: 96.7318, total_rewards: 4780.6266, mean_steps: 70.7500, mean_ecr: 0.0399 mean_entropies: 1.6535, took: 132.4082s
2022-08-01 00:41:22,511 [INFO] 	Process 3: Batch 5199/10000, mean_policy_losses: -91.259, mean_net_lifetime: 6560.5413, mean_mc_travel_dist: 6560.2394, mean_rewards: 100.8365, total_rewards: 5248.9318, mean_steps: 71.1500, mean_ecr: 0.0395 mean_entropies: 1.6743, took: 136.8739s
2022-08-01 00:43:36,979 [INFO] 	Process 3: Batch 5299/10000, mean_policy_losses: -49.996, mean_net_lifetime: 6459.6940, mean_mc_travel_dist: 6363.8551, mean_rewards: 102.8239, total_rewards: 5186.9230, mean_steps: 67.9900, mean_ecr: 0.0409 mean_entropies: 1.6367, took: 134.4675s
2022-08-01 00:46:01,501 [INFO] 	Process 3: Batch 5399/10000, mean_policy_losses: -54.722, mean_net_lifetime: 6683.5703, mean_mc_travel_dist: 6454.5174, mean_rewards: 101.6673, total_rewards: 5392.7573, mean_steps: 70.9500, mean_ecr: 0.0401 mean_entropies: 1.6196, took: 144.5216s
2022-08-01 00:48:24,519 [INFO] 	Process 3: Batch 5499/10000, mean_policy_losses: -58.516, mean_net_lifetime: 6571.7204, mean_mc_travel_dist: 6318.8357, mean_rewards: 105.0021, total_rewards: 5308.8486, mean_steps: 67.4800, mean_ecr: 0.0405 mean_entropies: 1.5969, took: 143.0199s
2022-08-01 00:50:46,611 [INFO] 	Process 3: Batch 5599/10000, mean_policy_losses: -60.559, mean_net_lifetime: 6363.3668, mean_mc_travel_dist: 6678.4267, mean_rewards: 100.0559, total_rewards: 5027.6815, mean_steps: 71.3600, mean_ecr: 0.0391 mean_entropies: 1.6121, took: 142.0913s
2022-08-01 00:53:01,506 [INFO] 	Process 3: Batch 5699/10000, mean_policy_losses: -74.410, mean_net_lifetime: 6581.1824, mean_mc_travel_dist: 6457.4370, mean_rewards: 102.6429, total_rewards: 5290.8172, mean_steps: 69.9500, mean_ecr: 0.0398 mean_entropies: 1.5472, took: 134.8953s
2022-08-01 00:55:14,390 [INFO] 	Process 3: Batch 5799/10000, mean_policy_losses: -81.086, mean_net_lifetime: 6510.2438, mean_mc_travel_dist: 6337.8101, mean_rewards: 104.3122, total_rewards: 5243.0444, mean_steps: 68.3600, mean_ecr: 0.0405 mean_entropies: 1.5525, took: 132.8849s
2022-08-01 00:57:33,341 [INFO] 	Process 3: Batch 5899/10000, mean_policy_losses: -63.959, mean_net_lifetime: 6405.3076, mean_mc_travel_dist: 6464.8102, mean_rewards: 101.2165, total_rewards: 5112.6832, mean_steps: 70.2800, mean_ecr: 0.0399 mean_entropies: 1.5341, took: 138.9478s
2022-08-01 00:59:47,970 [INFO] 	Process 3: Batch 5999/10000, mean_policy_losses: -79.022, mean_net_lifetime: 6523.1687, mean_mc_travel_dist: 6330.6154, mean_rewards: 104.9449, total_rewards: 5257.4810, mean_steps: 68.2100, mean_ecr: 0.0405 mean_entropies: 1.5583, took: 134.6304s
2022-08-01 01:01:56,212 [INFO] 	Process 3: Batch 6099/10000, mean_policy_losses: -76.918, mean_net_lifetime: 6644.3841, mean_mc_travel_dist: 6196.9753, mean_rewards: 107.3030, total_rewards: 5405.2549, mean_steps: 66.0300, mean_ecr: 0.0410 mean_entropies: 1.5069, took: 128.2435s
2022-08-01 01:04:07,982 [INFO] 	Process 3: Batch 6199/10000, mean_policy_losses: -53.361, mean_net_lifetime: 6506.0313, mean_mc_travel_dist: 6127.9674, mean_rewards: 105.6439, total_rewards: 5281.2445, mean_steps: 66.8100, mean_ecr: 0.0415 mean_entropies: 1.4863, took: 131.7685s
2022-08-01 01:06:31,209 [INFO] 	Process 3: Batch 6299/10000, mean_policy_losses: -53.033, mean_net_lifetime: 6651.1162, mean_mc_travel_dist: 6404.7590, mean_rewards: 103.6694, total_rewards: 5370.7916, mean_steps: 69.8800, mean_ecr: 0.0402 mean_entropies: 1.4921, took: 143.2269s
2022-08-01 01:08:58,393 [INFO] 	Process 3: Batch 6399/10000, mean_policy_losses: -53.984, mean_net_lifetime: 6449.2171, mean_mc_travel_dist: 6457.7377, mean_rewards: 100.9797, total_rewards: 5157.6696, mean_steps: 69.7200, mean_ecr: 0.0400 mean_entropies: 1.5231, took: 147.1847s
2022-08-01 01:11:11,842 [INFO] 	Process 3: Batch 6499/10000, mean_policy_losses: -103.483, mean_net_lifetime: 6424.2440, mean_mc_travel_dist: 6347.4962, mean_rewards: 106.6385, total_rewards: 5155.6482, mean_steps: 67.5500, mean_ecr: 0.0398 mean_entropies: 1.4545, took: 133.4474s
2022-08-01 01:13:33,982 [INFO] 	Process 3: Batch 6599/10000, mean_policy_losses: -88.663, mean_net_lifetime: 6435.6336, mean_mc_travel_dist: 6581.3676, mean_rewards: 100.8726, total_rewards: 5119.3600, mean_steps: 71.4900, mean_ecr: 0.0395 mean_entropies: 1.4770, took: 142.1402s
2022-08-01 01:15:55,811 [INFO] 	Process 3: Batch 6699/10000, mean_policy_losses: -32.142, mean_net_lifetime: 6493.7586, mean_mc_travel_dist: 6585.1745, mean_rewards: 100.8213, total_rewards: 5177.3026, mean_steps: 70.6700, mean_ecr: 0.0394 mean_entropies: 1.4700, took: 141.8307s
2022-08-01 01:18:20,775 [INFO] 	Process 3: Batch 6799/10000, mean_policy_losses: -81.340, mean_net_lifetime: 6373.9055, mean_mc_travel_dist: 6273.2218, mean_rewards: 104.0486, total_rewards: 5119.6484, mean_steps: 68.0500, mean_ecr: 0.0406 mean_entropies: 1.4225, took: 144.9626s
2022-08-01 01:20:53,262 [INFO] 	Process 3: Batch 6899/10000, mean_policy_losses: -64.822, mean_net_lifetime: 6633.4374, mean_mc_travel_dist: 6211.2691, mean_rewards: 105.4008, total_rewards: 5391.1836, mean_steps: 68.1400, mean_ecr: 0.0414 mean_entropies: 1.3651, took: 152.4870s
2022-08-01 01:23:13,183 [INFO] 	Process 3: Batch 6999/10000, mean_policy_losses: -99.687, mean_net_lifetime: 6208.3712, mean_mc_travel_dist: 5917.3533, mean_rewards: 107.5650, total_rewards: 5025.2924, mean_steps: 65.0600, mean_ecr: 0.0420 mean_entropies: 1.3409, took: 139.9227s
2022-08-01 01:25:56,234 [INFO] 	Process 3: Batch 7099/10000, mean_policy_losses: -34.914, mean_net_lifetime: 6366.0731, mean_mc_travel_dist: 6582.0383, mean_rewards: 98.3390, total_rewards: 5049.9762, mean_steps: 72.7900, mean_ecr: 0.0395 mean_entropies: 1.4441, took: 163.0494s
2022-08-01 01:28:25,173 [INFO] 	Process 3: Batch 7199/10000, mean_policy_losses: -59.996, mean_net_lifetime: 6434.5953, mean_mc_travel_dist: 6168.2528, mean_rewards: 106.5311, total_rewards: 5201.1132, mean_steps: 67.2500, mean_ecr: 0.0416 mean_entropies: 1.3540, took: 148.9402s
2022-08-01 01:31:01,112 [INFO] 	Process 3: Batch 7299/10000, mean_policy_losses: -50.064, mean_net_lifetime: 6674.1662, mean_mc_travel_dist: 6472.4269, mean_rewards: 101.8286, total_rewards: 5380.0649, mean_steps: 71.5900, mean_ecr: 0.0400 mean_entropies: 1.4353, took: 155.9356s
2022-08-01 01:33:33,649 [INFO] 	Process 3: Batch 7399/10000, mean_policy_losses: -72.080, mean_net_lifetime: 6340.8052, mean_mc_travel_dist: 6401.8804, mean_rewards: 100.5917, total_rewards: 5061.0005, mean_steps: 69.2400, mean_ecr: 0.0403 mean_entropies: 1.4086, took: 152.5392s
2022-08-01 01:36:05,009 [INFO] 	Process 3: Batch 7499/10000, mean_policy_losses: -113.203, mean_net_lifetime: 6309.6078, mean_mc_travel_dist: 6544.6060, mean_rewards: 96.2153, total_rewards: 5000.9662, mean_steps: 73.2700, mean_ecr: 0.0395 mean_entropies: 1.4377, took: 151.3610s
2022-08-01 01:38:37,188 [INFO] 	Process 3: Batch 7599/10000, mean_policy_losses: -36.742, mean_net_lifetime: 6373.8911, mean_mc_travel_dist: 6536.0401, mean_rewards: 99.0997, total_rewards: 5067.4112, mean_steps: 71.2200, mean_ecr: 0.0397 mean_entropies: 1.3933, took: 152.1776s
2022-08-01 01:41:02,674 [INFO] 	Process 3: Batch 7699/10000, mean_policy_losses: -29.773, mean_net_lifetime: 6395.5085, mean_mc_travel_dist: 6307.5251, mean_rewards: 102.2041, total_rewards: 5134.5741, mean_steps: 69.3800, mean_ecr: 0.0406 mean_entropies: 1.3862, took: 145.4882s
2022-08-01 01:43:16,689 [INFO] 	Process 3: Batch 7799/10000, mean_policy_losses: -57.716, mean_net_lifetime: 6483.8416, mean_mc_travel_dist: 6339.2418, mean_rewards: 102.8954, total_rewards: 5216.6894, mean_steps: 68.2400, mean_ecr: 0.0402 mean_entropies: 1.3951, took: 134.0151s
2022-08-01 01:45:34,448 [INFO] 	Process 3: Batch 7899/10000, mean_policy_losses: -107.024, mean_net_lifetime: 6469.0146, mean_mc_travel_dist: 6354.0731, mean_rewards: 104.9599, total_rewards: 5199.1982, mean_steps: 68.8200, mean_ecr: 0.0406 mean_entropies: 1.3663, took: 137.7586s
2022-08-01 01:47:51,852 [INFO] 	Process 3: Batch 7999/10000, mean_policy_losses: -47.545, mean_net_lifetime: 6501.7444, mean_mc_travel_dist: 6185.4320, mean_rewards: 106.6967, total_rewards: 5265.8147, mean_steps: 66.2900, mean_ecr: 0.0413 mean_entropies: 1.3686, took: 137.4021s
2022-08-01 01:50:13,280 [INFO] 	Process 3: Batch 8099/10000, mean_policy_losses: -81.145, mean_net_lifetime: 6534.3308, mean_mc_travel_dist: 6198.2718, mean_rewards: 108.0028, total_rewards: 5295.6368, mean_steps: 66.3100, mean_ecr: 0.0414 mean_entropies: 1.3641, took: 141.4282s
2022-08-01 01:52:21,796 [INFO] 	Process 3: Batch 8199/10000, mean_policy_losses: -35.764, mean_net_lifetime: 6297.6805, mean_mc_travel_dist: 6057.7885, mean_rewards: 107.1223, total_rewards: 5087.1848, mean_steps: 65.0000, mean_ecr: 0.0420 mean_entropies: 1.3277, took: 128.5174s
2022-08-01 01:54:40,463 [INFO] 	Process 3: Batch 8299/10000, mean_policy_losses: -92.935, mean_net_lifetime: 6546.8677, mean_mc_travel_dist: 6327.8247, mean_rewards: 103.5758, total_rewards: 5281.7093, mean_steps: 69.0300, mean_ecr: 0.0405 mean_entropies: 1.3963, took: 138.6661s
2022-08-01 01:57:00,999 [INFO] 	Process 3: Batch 8399/10000, mean_policy_losses: -58.323, mean_net_lifetime: 6486.4381, mean_mc_travel_dist: 6266.2851, mean_rewards: 107.2470, total_rewards: 5234.1281, mean_steps: 67.4000, mean_ecr: 0.0409 mean_entropies: 1.3339, took: 140.5365s
2022-08-01 01:59:18,755 [INFO] 	Process 3: Batch 8499/10000, mean_policy_losses: -45.201, mean_net_lifetime: 6316.8935, mean_mc_travel_dist: 6288.2243, mean_rewards: 102.6516, total_rewards: 5060.0319, mean_steps: 67.6800, mean_ecr: 0.0408 mean_entropies: 1.3162, took: 137.7566s
2022-08-01 02:01:37,133 [INFO] 	Process 3: Batch 8599/10000, mean_policy_losses: -87.192, mean_net_lifetime: 6280.6699, mean_mc_travel_dist: 6147.5503, mean_rewards: 103.9758, total_rewards: 5051.4311, mean_steps: 66.7000, mean_ecr: 0.0416 mean_entropies: 1.2716, took: 138.3783s
2022-08-01 02:03:54,702 [INFO] 	Process 3: Batch 8699/10000, mean_policy_losses: -51.881, mean_net_lifetime: 6426.1565, mean_mc_travel_dist: 6336.4611, mean_rewards: 102.0356, total_rewards: 5159.0655, mean_steps: 68.9100, mean_ecr: 0.0406 mean_entropies: 1.2620, took: 137.5689s
2022-08-01 02:06:04,196 [INFO] 	Process 3: Batch 8799/10000, mean_policy_losses: -60.040, mean_net_lifetime: 6427.5305, mean_mc_travel_dist: 6227.0294, mean_rewards: 104.5886, total_rewards: 5183.3063, mean_steps: 68.4800, mean_ecr: 0.0410 mean_entropies: 1.2560, took: 129.4938s
2022-08-01 02:08:17,202 [INFO] 	Process 3: Batch 8899/10000, mean_policy_losses: -66.924, mean_net_lifetime: 6498.0601, mean_mc_travel_dist: 6223.9176, mean_rewards: 104.2325, total_rewards: 5253.8122, mean_steps: 68.6600, mean_ecr: 0.0410 mean_entropies: 1.2687, took: 133.0057s
2022-08-01 02:10:35,573 [INFO] 	Process 3: Batch 8999/10000, mean_policy_losses: -46.752, mean_net_lifetime: 6415.6534, mean_mc_travel_dist: 6555.1918, mean_rewards: 100.2671, total_rewards: 5105.3292, mean_steps: 70.4700, mean_ecr: 0.0397 mean_entropies: 1.3124, took: 138.3714s
2022-08-01 02:13:00,516 [INFO] 	Process 3: Batch 9099/10000, mean_policy_losses: -76.857, mean_net_lifetime: 6530.9764, mean_mc_travel_dist: 6432.7432, mean_rewards: 101.1776, total_rewards: 5245.0618, mean_steps: 72.0200, mean_ecr: 0.0404 mean_entropies: 1.2715, took: 144.9432s
2022-08-01 02:15:09,366 [INFO] 	Process 3: Batch 9199/10000, mean_policy_losses: -64.387, mean_net_lifetime: 6574.9578, mean_mc_travel_dist: 6219.4525, mean_rewards: 105.8626, total_rewards: 5331.5216, mean_steps: 67.0400, mean_ecr: 0.0412 mean_entropies: 1.2417, took: 128.8469s
2022-08-01 02:17:31,565 [INFO] 	Process 3: Batch 9299/10000, mean_policy_losses: -59.967, mean_net_lifetime: 6451.4901, mean_mc_travel_dist: 6523.7760, mean_rewards: 98.1705, total_rewards: 5147.8223, mean_steps: 72.0100, mean_ecr: 0.0396 mean_entropies: 1.2757, took: 142.2013s
2022-08-01 02:20:03,566 [INFO] 	Process 3: Batch 9399/10000, mean_policy_losses: -80.163, mean_net_lifetime: 6481.7299, mean_mc_travel_dist: 6416.9017, mean_rewards: 100.9883, total_rewards: 5199.3629, mean_steps: 71.1600, mean_ecr: 0.0401 mean_entropies: 1.1949, took: 151.9999s
2022-08-01 02:22:33,635 [INFO] 	Process 3: Batch 9499/10000, mean_policy_losses: -65.242, mean_net_lifetime: 6332.3580, mean_mc_travel_dist: 6569.0027, mean_rewards: 97.2424, total_rewards: 5018.7434, mean_steps: 72.3600, mean_ecr: 0.0393 mean_entropies: 1.2146, took: 150.0708s
2022-08-01 02:24:55,111 [INFO] 	Process 3: Batch 9599/10000, mean_policy_losses: -47.756, mean_net_lifetime: 6433.8550, mean_mc_travel_dist: 6595.2425, mean_rewards: 97.6015, total_rewards: 5115.2839, mean_steps: 73.4500, mean_ecr: 0.0395 mean_entropies: 1.2579, took: 141.4761s
2022-08-01 02:26:58,528 [INFO] 	Process 3: Batch 9699/10000, mean_policy_losses: -59.848, mean_net_lifetime: 6355.8255, mean_mc_travel_dist: 6065.1876, mean_rewards: 107.1782, total_rewards: 5143.2342, mean_steps: 65.2400, mean_ecr: 0.0420 mean_entropies: 1.1492, took: 123.4168s
2022-08-01 02:29:19,240 [INFO] 	Process 3: Batch 9799/10000, mean_policy_losses: -52.356, mean_net_lifetime: 6306.6709, mean_mc_travel_dist: 6570.4908, mean_rewards: 96.1131, total_rewards: 4993.3541, mean_steps: 73.5500, mean_ecr: 0.0396 mean_entropies: 1.2063, took: 140.7121s
2022-08-01 02:31:40,649 [INFO] 	Process 3: Batch 9899/10000, mean_policy_losses: -96.660, mean_net_lifetime: 6430.6761, mean_mc_travel_dist: 6145.5836, mean_rewards: 105.8475, total_rewards: 5201.8560, mean_steps: 67.5700, mean_ecr: 0.0416 mean_entropies: 1.1483, took: 141.4082s
2022-08-01 02:33:48,475 [INFO] 	Process 3: Batch 9999/10000, mean_policy_losses: -85.815, mean_net_lifetime: 6642.0589, mean_mc_travel_dist: 6187.4264, mean_rewards: 108.6051, total_rewards: 5405.1282, mean_steps: 66.8100, mean_ecr: 0.0412 mean_entropies: 1.1326, took: 127.8252s
2022-08-01 02:46:32,056 [INFO] Process 3: Epoch 2: mean_policy_losses: -55.681, mean_net_lifetime: 6266.6826, mean_mc_travel_dist: 6519.1485, mean_entropies: 1.7418, m_net_lifetime_valid: 6548.5558, took: 14788.5361s, (138.8609 / 100 batches)

2022-08-01 02:46:32,057 [INFO] Process 3: Start epoch 3
2022-08-01 02:48:07,043 [INFO] 	Process 3: Batch 99/10000, mean_policy_losses: 66.788, mean_net_lifetime: 4162.1604, mean_mc_travel_dist: 7058.5600, mean_rewards: 90.8904, total_rewards: 2764.6636, mean_steps: 49.4600, mean_ecr: 0.0391 mean_entropies: 1.6657, took: 94.9783s
2022-08-01 02:49:14,442 [INFO] 	Process 3: Batch 199/10000, mean_policy_losses: -58.661, mean_net_lifetime: 3467.8173, mean_mc_travel_dist: 5504.9882, mean_rewards: 105.9061, total_rewards: 2384.3197, mean_steps: 34.9600, mean_ecr: 0.0408 mean_entropies: 1.3841, took: 67.3999s
2022-08-01 02:50:50,445 [INFO] 	Process 3: Batch 299/10000, mean_policy_losses: -52.209, mean_net_lifetime: 4277.7618, mean_mc_travel_dist: 6699.3187, mean_rewards: 103.1465, total_rewards: 2952.1077, mean_steps: 46.0800, mean_ecr: 0.0404 mean_entropies: 1.3575, took: 96.0022s
2022-08-01 02:52:13,279 [INFO] 	Process 3: Batch 399/10000, mean_policy_losses: -45.102, mean_net_lifetime: 3897.2785, mean_mc_travel_dist: 6484.7960, mean_rewards: 100.7155, total_rewards: 2612.7451, mean_steps: 42.5700, mean_ecr: 0.0402 mean_entropies: 1.3193, took: 82.8343s
2022-08-01 02:53:55,309 [INFO] 	Process 3: Batch 499/10000, mean_policy_losses: -64.045, mean_net_lifetime: 4932.0270, mean_mc_travel_dist: 8014.3351, mean_rewards: 103.5940, total_rewards: 3342.7473, mean_steps: 53.1600, mean_ecr: 0.0401 mean_entropies: 1.3131, took: 102.0302s
2022-08-01 02:56:02,547 [INFO] 	Process 3: Batch 599/10000, mean_policy_losses: -80.832, mean_net_lifetime: 5737.9332, mean_mc_travel_dist: 9484.9462, mean_rewards: 104.6820, total_rewards: 3855.2270, mean_steps: 65.8400, mean_ecr: 0.0391 mean_entropies: 1.3033, took: 127.2380s
2022-08-01 02:57:34,020 [INFO] 	Process 3: Batch 699/10000, mean_policy_losses: -74.187, mean_net_lifetime: 4768.5519, mean_mc_travel_dist: 6754.6499, mean_rewards: 115.3225, total_rewards: 3428.5426, mean_steps: 45.2300, mean_ecr: 0.0417 mean_entropies: 1.2973, took: 91.4717s
2022-08-01 03:00:03,155 [INFO] 	Process 3: Batch 799/10000, mean_policy_losses: -46.556, mean_net_lifetime: 6486.2354, mean_mc_travel_dist: 10333.1012, mean_rewards: 106.5869, total_rewards: 4429.1026, mean_steps: 72.8400, mean_ecr: 0.0388 mean_entropies: 1.2486, took: 149.1355s
2022-08-01 03:02:34,963 [INFO] 	Process 3: Batch 899/10000, mean_policy_losses: -74.397, mean_net_lifetime: 7602.0179, mean_mc_travel_dist: 11091.2394, mean_rewards: 118.9167, total_rewards: 5391.9181, mean_steps: 76.1100, mean_ecr: 0.0410 mean_entropies: 1.2183, took: 151.8076s
2022-08-01 03:05:12,487 [INFO] 	Process 3: Batch 999/10000, mean_policy_losses: -81.459, mean_net_lifetime: 8508.4730, mean_mc_travel_dist: 12198.9016, mean_rewards: 117.3081, total_rewards: 6079.9550, mean_steps: 82.9900, mean_ecr: 0.0394 mean_entropies: 1.1066, took: 157.5248s
2022-08-01 03:07:40,038 [INFO] 	Process 3: Batch 1099/10000, mean_policy_losses: -59.239, mean_net_lifetime: 8734.3394, mean_mc_travel_dist: 11423.7778, mean_rewards: 132.7756, total_rewards: 6461.0240, mean_steps: 78.5900, mean_ecr: 0.0421 mean_entropies: 1.0264, took: 147.5505s
2022-08-01 03:12:21,422 [INFO] 	Process 3: Batch 1199/10000, mean_policy_losses: -79.490, mean_net_lifetime: 14275.8837, mean_mc_travel_dist: 21899.0243, mean_rewards: 128.3215, total_rewards: 9905.1979, mean_steps: 143.8300, mean_ecr: 0.0382 mean_entropies: 1.0039, took: 281.3844s
2022-08-01 03:16:56,835 [INFO] 	Process 3: Batch 1299/10000, mean_policy_losses: -52.729, mean_net_lifetime: 15684.5048, mean_mc_travel_dist: 22429.0428, mean_rewards: 132.7980, total_rewards: 11207.2304, mean_steps: 145.1100, mean_ecr: 0.0391 mean_entropies: 0.9534, took: 275.4060s
2022-08-01 03:21:14,356 [INFO] 	Process 3: Batch 1399/10000, mean_policy_losses: -52.331, mean_net_lifetime: 13240.1725, mean_mc_travel_dist: 18731.9157, mean_rewards: 134.8998, total_rewards: 9504.1616, mean_steps: 126.9500, mean_ecr: 0.0402 mean_entropies: 0.8861, took: 257.5287s
2022-08-01 03:26:16,074 [INFO] 	Process 3: Batch 1499/10000, mean_policy_losses: -53.553, mean_net_lifetime: 17516.0888, mean_mc_travel_dist: 23848.0551, mean_rewards: 136.7687, total_rewards: 12754.0809, mean_steps: 163.3200, mean_ecr: 0.0403 mean_entropies: 0.8553, took: 301.7173s
2022-08-01 03:31:31,816 [INFO] 	Process 3: Batch 1599/10000, mean_policy_losses: -42.527, mean_net_lifetime: 18520.8374, mean_mc_travel_dist: 24679.3095, mean_rewards: 134.3168, total_rewards: 13594.2847, mean_steps: 167.5100, mean_ecr: 0.0398 mean_entropies: 0.8026, took: 315.7422s
2022-08-01 03:38:01,191 [INFO] 	Process 3: Batch 1699/10000, mean_policy_losses: -45.117, mean_net_lifetime: 20780.9857, mean_mc_travel_dist: 29059.6621, mean_rewards: 139.9638, total_rewards: 14976.0670, mean_steps: 198.3800, mean_ecr: 0.0412 mean_entropies: 0.7338, took: 389.3748s
2022-08-01 03:45:27,878 [INFO] 	Process 3: Batch 1799/10000, mean_policy_losses: -48.788, mean_net_lifetime: 24888.5835, mean_mc_travel_dist: 33876.1624, mean_rewards: 138.5467, total_rewards: 18119.3771, mean_steps: 235.0000, mean_ecr: 0.0378 mean_entropies: 0.7673, took: 446.6864s
2022-08-01 03:51:13,524 [INFO] 	Process 3: Batch 1899/10000, mean_policy_losses: -41.165, mean_net_lifetime: 20780.1188, mean_mc_travel_dist: 27937.9352, mean_rewards: 140.9924, total_rewards: 15198.6658, mean_steps: 183.7900, mean_ecr: 0.0402 mean_entropies: 0.7070, took: 345.6472s
2022-08-01 03:55:48,296 [INFO] 	Process 3: Batch 1999/10000, mean_policy_losses: -45.277, mean_net_lifetime: 16261.3576, mean_mc_travel_dist: 20763.2846, mean_rewards: 141.0748, total_rewards: 12115.8598, mean_steps: 147.5800, mean_ecr: 0.0405 mean_entropies: 0.6830, took: 274.7723s
2022-08-01 04:01:41,716 [INFO] 	Process 3: Batch 2099/10000, mean_policy_losses: -55.746, mean_net_lifetime: 21421.8511, mean_mc_travel_dist: 26722.0297, mean_rewards: 142.1405, total_rewards: 16082.3880, mean_steps: 182.5400, mean_ecr: 0.0398 mean_entropies: 0.6606, took: 353.4185s
2022-08-01 04:06:53,698 [INFO] 	Process 3: Batch 2199/10000, mean_policy_losses: -34.917, mean_net_lifetime: 17700.2172, mean_mc_travel_dist: 24505.5955, mean_rewards: 141.4126, total_rewards: 12809.3773, mean_steps: 165.3700, mean_ecr: 0.0398 mean_entropies: 0.6236, took: 311.9830s
2022-08-01 04:11:55,989 [INFO] 	Process 3: Batch 2299/10000, mean_policy_losses: -38.256, mean_net_lifetime: 16437.1890, mean_mc_travel_dist: 22691.9940, mean_rewards: 144.7195, total_rewards: 11906.3652, mean_steps: 157.0600, mean_ecr: 0.0414 mean_entropies: 0.6102, took: 302.2895s
2022-08-01 04:16:32,993 [INFO] 	Process 3: Batch 2399/10000, mean_policy_losses: -43.324, mean_net_lifetime: 16027.8629, mean_mc_travel_dist: 20402.5130, mean_rewards: 143.5376, total_rewards: 11954.3333, mean_steps: 145.1100, mean_ecr: 0.0397 mean_entropies: 0.6008, took: 277.0050s
2022-08-01 04:22:29,890 [INFO] 	Process 3: Batch 2499/10000, mean_policy_losses: -56.773, mean_net_lifetime: 20705.6840, mean_mc_travel_dist: 27023.1999, mean_rewards: 141.0416, total_rewards: 15309.4941, mean_steps: 188.1500, mean_ecr: 0.0401 mean_entropies: 0.5962, took: 356.8968s
2022-08-01 04:26:15,517 [INFO] 	Process 3: Batch 2599/10000, mean_policy_losses: -37.381, mean_net_lifetime: 14690.1591, mean_mc_travel_dist: 18822.2551, mean_rewards: 147.4463, total_rewards: 10935.0404, mean_steps: 120.8800, mean_ecr: 0.0418 mean_entropies: 0.5838, took: 225.6276s
2022-08-01 04:33:00,720 [INFO] 	Process 3: Batch 2699/10000, mean_policy_losses: -48.589, mean_net_lifetime: 23764.0870, mean_mc_travel_dist: 32286.0640, mean_rewards: 143.3507, total_rewards: 17314.3389, mean_steps: 216.1900, mean_ecr: 0.0406 mean_entropies: 0.5795, took: 405.2026s
2022-08-01 04:39:21,994 [INFO] 	Process 3: Batch 2799/10000, mean_policy_losses: -45.771, mean_net_lifetime: 22344.4838, mean_mc_travel_dist: 29441.0641, mean_rewards: 144.7236, total_rewards: 16463.9236, mean_steps: 195.7700, mean_ecr: 0.0392 mean_entropies: 0.5525, took: 381.2702s
2022-08-01 04:45:35,935 [INFO] 	Process 3: Batch 2899/10000, mean_policy_losses: -38.601, mean_net_lifetime: 22349.1270, mean_mc_travel_dist: 28777.3861, mean_rewards: 141.1984, total_rewards: 16600.6621, mean_steps: 199.1500, mean_ecr: 0.0388 mean_entropies: 0.5571, took: 373.9444s
2022-08-01 04:50:45,868 [INFO] 	Process 3: Batch 2999/10000, mean_policy_losses: -39.968, mean_net_lifetime: 19762.9766, mean_mc_travel_dist: 24668.3010, mean_rewards: 146.1421, total_rewards: 14838.2164, mean_steps: 166.6600, mean_ecr: 0.0405 mean_entropies: 0.5262, took: 309.9340s
2022-08-01 04:56:46,200 [INFO] 	Process 3: Batch 3099/10000, mean_policy_losses: -39.601, mean_net_lifetime: 20363.1012, mean_mc_travel_dist: 27725.3082, mean_rewards: 143.7779, total_rewards: 14828.5311, mean_steps: 191.4400, mean_ecr: 0.0401 mean_entropies: 0.5189, took: 360.3311s
2022-08-01 05:04:50,123 [INFO] 	Process 3: Batch 3199/10000, mean_policy_losses: -49.551, mean_net_lifetime: 27957.2104, mean_mc_travel_dist: 36762.5357, mean_rewards: 144.7977, total_rewards: 20610.4311, mean_steps: 251.9300, mean_ecr: 0.0402 mean_entropies: 0.5079, took: 483.9226s
2022-08-01 05:11:54,545 [INFO] 	Process 3: Batch 3299/10000, mean_policy_losses: -40.269, mean_net_lifetime: 24733.3097, mean_mc_travel_dist: 33257.0042, mean_rewards: 142.3900, total_rewards: 18089.5320, mean_steps: 232.1100, mean_ecr: 0.0387 mean_entropies: 0.5141, took: 424.4234s
2022-08-01 05:18:05,946 [INFO] 	Process 3: Batch 3399/10000, mean_policy_losses: -38.644, mean_net_lifetime: 22712.8881, mean_mc_travel_dist: 29224.9960, mean_rewards: 144.4382, total_rewards: 16875.7296, mean_steps: 198.9900, mean_ecr: 0.0397 mean_entropies: 0.4752, took: 371.4005s
2022-08-01 05:26:37,423 [INFO] 	Process 3: Batch 3499/10000, mean_policy_losses: -40.052, mean_net_lifetime: 30675.1132, mean_mc_travel_dist: 41858.5668, mean_rewards: 141.8755, total_rewards: 22310.3073, mean_steps: 271.8500, mean_ecr: 0.0379 mean_entropies: 0.4961, took: 511.4774s
2022-08-01 05:32:53,749 [INFO] 	Process 3: Batch 3599/10000, mean_policy_losses: -47.521, mean_net_lifetime: 22995.1862, mean_mc_travel_dist: 29511.7271, mean_rewards: 145.9152, total_rewards: 17097.4445, mean_steps: 207.4400, mean_ecr: 0.0404 mean_entropies: 0.4617, took: 376.3259s
2022-08-01 05:39:16,504 [INFO] 	Process 3: Batch 3699/10000, mean_policy_losses: -37.478, mean_net_lifetime: 23393.2674, mean_mc_travel_dist: 29773.2291, mean_rewards: 147.7121, total_rewards: 17444.2536, mean_steps: 199.7500, mean_ecr: 0.0410 mean_entropies: 0.4525, took: 382.7541s
2022-08-01 05:47:10,850 [INFO] 	Process 3: Batch 3799/10000, mean_policy_losses: -29.344, mean_net_lifetime: 27403.6049, mean_mc_travel_dist: 36675.7673, mean_rewards: 139.5049, total_rewards: 20076.4540, mean_steps: 247.7900, mean_ecr: 0.0376 mean_entropies: 0.4876, took: 474.3411s
2022-08-01 05:54:44,309 [INFO] 	Process 3: Batch 3899/10000, mean_policy_losses: -33.425, mean_net_lifetime: 24295.3294, mean_mc_travel_dist: 34030.9336, mean_rewards: 144.4268, total_rewards: 17496.4905, mean_steps: 218.8600, mean_ecr: 0.0389 mean_entropies: 0.4625, took: 453.4639s
2022-08-01 05:59:57,319 [INFO] 	Process 3: Batch 3999/10000, mean_policy_losses: -38.922, mean_net_lifetime: 16848.4891, mean_mc_travel_dist: 22277.6792, mean_rewards: 149.8283, total_rewards: 12400.2316, mean_steps: 149.8300, mean_ecr: 0.0423 mean_entropies: 0.4315, took: 313.0104s
2022-08-01 06:07:42,960 [INFO] 	Process 3: Batch 4099/10000, mean_policy_losses: -42.521, mean_net_lifetime: 24974.6775, mean_mc_travel_dist: 33891.1292, mean_rewards: 142.1007, total_rewards: 18204.4209, mean_steps: 230.5200, mean_ecr: 0.0386 mean_entropies: 0.4618, took: 465.6413s
2022-08-01 06:15:44,382 [INFO] 	Process 3: Batch 4199/10000, mean_policy_losses: -31.101, mean_net_lifetime: 28557.3622, mean_mc_travel_dist: 37685.3977, mean_rewards: 143.5740, total_rewards: 21024.5725, mean_steps: 248.2700, mean_ecr: 0.0396 mean_entropies: 0.4437, took: 481.4213s
2022-08-01 06:21:20,173 [INFO] 	Process 3: Batch 4299/10000, mean_policy_losses: -47.225, mean_net_lifetime: 19955.3922, mean_mc_travel_dist: 24928.8860, mean_rewards: 149.6419, total_rewards: 14974.3208, mean_steps: 171.4700, mean_ecr: 0.0420 mean_entropies: 0.4149, took: 335.7915s
2022-08-01 06:27:07,190 [INFO] 	Process 3: Batch 4399/10000, mean_policy_losses: -45.531, mean_net_lifetime: 19944.1310, mean_mc_travel_dist: 26303.2153, mean_rewards: 154.6500, total_rewards: 14687.9058, mean_steps: 178.7600, mean_ecr: 0.0420 mean_entropies: 0.4160, took: 347.0121s
2022-08-01 06:33:23,158 [INFO] 	Process 3: Batch 4499/10000, mean_policy_losses: -27.652, mean_net_lifetime: 22994.6153, mean_mc_travel_dist: 28384.8025, mean_rewards: 142.2387, total_rewards: 17325.8544, mean_steps: 196.6300, mean_ecr: 0.0391 mean_entropies: 0.4237, took: 375.9730s
2022-08-01 06:39:24,739 [INFO] 	Process 3: Batch 4599/10000, mean_policy_losses: -32.705, mean_net_lifetime: 21633.8477, mean_mc_travel_dist: 28017.5626, mean_rewards: 146.1211, total_rewards: 16037.4851, mean_steps: 186.9100, mean_ecr: 0.0400 mean_entropies: 0.4167, took: 361.5766s
2022-08-01 06:46:31,574 [INFO] 	Process 3: Batch 4699/10000, mean_policy_losses: -29.001, mean_net_lifetime: 24124.0693, mean_mc_travel_dist: 31618.0515, mean_rewards: 143.9232, total_rewards: 17807.1592, mean_steps: 210.9900, mean_ecr: 0.0386 mean_entropies: 0.4172, took: 426.8395s
2022-08-01 06:51:35,449 [INFO] 	Process 3: Batch 4799/10000, mean_policy_losses: -28.931, mean_net_lifetime: 19734.0162, mean_mc_travel_dist: 22974.9624, mean_rewards: 149.2774, total_rewards: 15148.9391, mean_steps: 149.8500, mean_ecr: 0.0401 mean_entropies: 0.4125, took: 303.8735s
2022-08-01 06:55:20,771 [INFO] 	Process 3: Batch 4899/10000, mean_policy_losses: -30.856, mean_net_lifetime: 14317.2282, mean_mc_travel_dist: 17213.3859, mean_rewards: 151.2732, total_rewards: 10883.0276, mean_steps: 111.5500, mean_ecr: 0.0412 mean_entropies: 0.3976, took: 225.3228s
2022-08-01 07:00:33,268 [INFO] 	Process 3: Batch 4999/10000, mean_policy_losses: -29.940, mean_net_lifetime: 19354.5586, mean_mc_travel_dist: 24676.5750, mean_rewards: 147.2909, total_rewards: 14429.0242, mean_steps: 163.6000, mean_ecr: 0.0400 mean_entropies: 0.4159, took: 312.4979s
2022-08-01 07:08:20,548 [INFO] 	Process 3: Batch 5099/10000, mean_policy_losses: -30.405, mean_net_lifetime: 26446.3443, mean_mc_travel_dist: 34420.3055, mean_rewards: 144.1143, total_rewards: 19570.2763, mean_steps: 245.5800, mean_ecr: 0.0386 mean_entropies: 0.4051, took: 467.2786s
2022-08-01 07:15:31,518 [INFO] 	Process 3: Batch 5199/10000, mean_policy_losses: -37.017, mean_net_lifetime: 25077.5665, mean_mc_travel_dist: 33432.8800, mean_rewards: 142.8278, total_rewards: 18398.7252, mean_steps: 226.6700, mean_ecr: 0.0399 mean_entropies: 0.3791, took: 430.9695s
2022-08-01 07:22:30,403 [INFO] 	Process 3: Batch 5299/10000, mean_policy_losses: -44.617, mean_net_lifetime: 24222.0688, mean_mc_travel_dist: 33051.2391, mean_rewards: 144.0048, total_rewards: 17619.5343, mean_steps: 227.2700, mean_ecr: 0.0393 mean_entropies: 0.3920, took: 418.8872s
2022-08-01 07:28:43,446 [INFO] 	Process 3: Batch 5399/10000, mean_policy_losses: -30.235, mean_net_lifetime: 22342.1617, mean_mc_travel_dist: 27528.9646, mean_rewards: 148.9497, total_rewards: 16842.6838, mean_steps: 187.8500, mean_ecr: 0.0402 mean_entropies: 0.3704, took: 373.0423s
2022-08-01 07:33:19,604 [INFO] 	Process 3: Batch 5499/10000, mean_policy_losses: -28.456, mean_net_lifetime: 16582.7508, mean_mc_travel_dist: 19820.0128, mean_rewards: 151.5535, total_rewards: 12628.4164, mean_steps: 140.9200, mean_ecr: 0.0418 mean_entropies: 0.3406, took: 276.1573s
2022-08-01 07:38:40,342 [INFO] 	Process 3: Batch 5599/10000, mean_policy_losses: -36.102, mean_net_lifetime: 18738.7526, mean_mc_travel_dist: 24570.7745, mean_rewards: 146.9694, total_rewards: 13832.6221, mean_steps: 169.0000, mean_ecr: 0.0404 mean_entropies: 0.3654, took: 320.7391s
2022-08-01 07:44:59,904 [INFO] 	Process 3: Batch 5699/10000, mean_policy_losses: -39.386, mean_net_lifetime: 24490.8114, mean_mc_travel_dist: 30972.0636, mean_rewards: 147.0523, total_rewards: 18302.5076, mean_steps: 212.5300, mean_ecr: 0.0396 mean_entropies: 0.3691, took: 379.5619s
2022-08-01 07:52:13,052 [INFO] 	Process 3: Batch 5799/10000, mean_policy_losses: -37.209, mean_net_lifetime: 24608.6735, mean_mc_travel_dist: 35163.6139, mean_rewards: 144.0663, total_rewards: 17585.5398, mean_steps: 233.7400, mean_ecr: 0.0394 mean_entropies: 0.3552, took: 433.1437s
2022-08-01 07:58:40,179 [INFO] 	Process 3: Batch 5899/10000, mean_policy_losses: -25.280, mean_net_lifetime: 22053.2071, mean_mc_travel_dist: 28321.6751, mean_rewards: 147.5750, total_rewards: 16395.9406, mean_steps: 189.7000, mean_ecr: 0.0405 mean_entropies: 0.3560, took: 387.1313s
2022-08-01 08:05:28,340 [INFO] 	Process 3: Batch 5999/10000, mean_policy_losses: -25.527, mean_net_lifetime: 24878.0953, mean_mc_travel_dist: 30822.9959, mean_rewards: 148.6115, total_rewards: 18721.8856, mean_steps: 204.6000, mean_ecr: 0.0413 mean_entropies: 0.3529, took: 408.1620s
2022-08-01 08:09:18,967 [INFO] 	Process 3: Batch 6099/10000, mean_policy_losses: -26.835, mean_net_lifetime: 14716.9963, mean_mc_travel_dist: 17994.8025, mean_rewards: 150.5696, total_rewards: 11129.7872, mean_steps: 119.7700, mean_ecr: 0.0406 mean_entropies: 0.3438, took: 230.6253s
2022-08-01 08:16:21,426 [INFO] 	Process 3: Batch 6199/10000, mean_policy_losses: -37.363, mean_net_lifetime: 24764.6773, mean_mc_travel_dist: 35543.5690, mean_rewards: 144.3849, total_rewards: 17663.0004, mean_steps: 227.7900, mean_ecr: 0.0393 mean_entropies: 0.3479, took: 422.4598s
2022-08-01 08:22:32,503 [INFO] 	Process 3: Batch 6299/10000, mean_policy_losses: -27.020, mean_net_lifetime: 23274.9374, mean_mc_travel_dist: 28647.8594, mean_rewards: 150.2663, total_rewards: 17552.7736, mean_steps: 190.5900, mean_ecr: 0.0401 mean_entropies: 0.3498, took: 371.0702s
2022-08-01 08:29:25,814 [INFO] 	Process 3: Batch 6399/10000, mean_policy_losses: -34.190, mean_net_lifetime: 23771.5778, mean_mc_travel_dist: 30060.5155, mean_rewards: 149.1365, total_rewards: 17769.0398, mean_steps: 206.5900, mean_ecr: 0.0400 mean_entropies: 0.3524, took: 413.3167s
2022-08-01 08:34:16,661 [INFO] 	Process 3: Batch 6499/10000, mean_policy_losses: -24.893, mean_net_lifetime: 17997.5793, mean_mc_travel_dist: 22488.4287, mean_rewards: 150.1876, total_rewards: 13506.4740, mean_steps: 152.6000, mean_ecr: 0.0406 mean_entropies: 0.3528, took: 290.8474s
2022-08-01 08:39:48,835 [INFO] 	Process 3: Batch 6599/10000, mean_policy_losses: -29.341, mean_net_lifetime: 21485.9013, mean_mc_travel_dist: 25892.9866, mean_rewards: 148.6881, total_rewards: 16315.6322, mean_steps: 176.4300, mean_ecr: 0.0405 mean_entropies: 0.3593, took: 332.1733s
2022-08-01 08:47:49,096 [INFO] 	Process 3: Batch 6699/10000, mean_policy_losses: -29.417, mean_net_lifetime: 30356.1671, mean_mc_travel_dist: 36837.5638, mean_rewards: 145.4858, total_rewards: 22996.7212, mean_steps: 256.4400, mean_ecr: 0.0390 mean_entropies: 0.3450, took: 480.2619s
2022-08-01 08:54:18,719 [INFO] 	Process 3: Batch 6799/10000, mean_policy_losses: -27.254, mean_net_lifetime: 23903.9500, mean_mc_travel_dist: 30871.3545, mean_rewards: 149.0642, total_rewards: 17737.7257, mean_steps: 201.9900, mean_ecr: 0.0397 mean_entropies: 0.3425, took: 389.6217s
2022-08-01 08:59:43,030 [INFO] 	Process 3: Batch 6899/10000, mean_policy_losses: -32.227, mean_net_lifetime: 19555.1532, mean_mc_travel_dist: 25242.7570, mean_rewards: 150.9661, total_rewards: 14516.7019, mean_steps: 163.9300, mean_ecr: 0.0394 mean_entropies: 0.3436, took: 324.3084s
2022-08-01 09:05:17,986 [INFO] 	Process 3: Batch 6999/10000, mean_policy_losses: -27.705, mean_net_lifetime: 21629.4518, mean_mc_travel_dist: 26526.6745, mean_rewards: 149.3049, total_rewards: 16332.8310, mean_steps: 179.2900, mean_ecr: 0.0395 mean_entropies: 0.3414, took: 334.9596s
2022-08-01 09:11:05,101 [INFO] 	Process 3: Batch 7099/10000, mean_policy_losses: -21.482, mean_net_lifetime: 21640.7482, mean_mc_travel_dist: 27291.5187, mean_rewards: 146.7348, total_rewards: 16190.6642, mean_steps: 185.8300, mean_ecr: 0.0409 mean_entropies: 0.3236, took: 347.1154s
2022-08-01 09:17:49,158 [INFO] 	Process 3: Batch 7199/10000, mean_policy_losses: -19.069, mean_net_lifetime: 26388.6983, mean_mc_travel_dist: 30704.5750, mean_rewards: 144.6295, total_rewards: 20254.0839, mean_steps: 219.3100, mean_ecr: 0.0392 mean_entropies: 0.3280, took: 404.0487s
2022-08-01 09:23:42,824 [INFO] 	Process 3: Batch 7299/10000, mean_policy_losses: -24.832, mean_net_lifetime: 22045.1096, mean_mc_travel_dist: 27337.7587, mean_rewards: 149.1899, total_rewards: 16584.5028, mean_steps: 184.3200, mean_ecr: 0.0408 mean_entropies: 0.3224, took: 353.6738s
2022-08-01 09:29:01,419 [INFO] 	Process 3: Batch 7399/10000, mean_policy_losses: -28.464, mean_net_lifetime: 19487.1272, mean_mc_travel_dist: 23955.2704, mean_rewards: 148.9670, total_rewards: 14703.5863, mean_steps: 166.2700, mean_ecr: 0.0417 mean_entropies: 0.3272, took: 318.5851s
2022-08-01 09:34:53,826 [INFO] 	Process 3: Batch 7499/10000, mean_policy_losses: -12.265, mean_net_lifetime: 20821.5135, mean_mc_travel_dist: 25656.6993, mean_rewards: 150.9338, total_rewards: 15695.7188, mean_steps: 173.3400, mean_ecr: 0.0409 mean_entropies: 0.3186, took: 352.4175s
2022-08-01 09:41:05,763 [INFO] 	Process 3: Batch 7599/10000, mean_policy_losses: -31.539, mean_net_lifetime: 20724.6343, mean_mc_travel_dist: 25606.9131, mean_rewards: 150.4524, total_rewards: 15611.6649, mean_steps: 173.4500, mean_ecr: 0.0401 mean_entropies: 0.3352, took: 371.9354s
2022-08-01 09:48:51,201 [INFO] 	Process 3: Batch 7699/10000, mean_policy_losses: -35.985, mean_net_lifetime: 23762.9041, mean_mc_travel_dist: 30756.9332, mean_rewards: 149.6424, total_rewards: 17619.2807, mean_steps: 208.6800, mean_ecr: 0.0396 mean_entropies: 0.3065, took: 465.4388s
2022-08-01 09:55:52,097 [INFO] 	Process 3: Batch 7799/10000, mean_policy_losses: -20.000, mean_net_lifetime: 21473.0163, mean_mc_travel_dist: 28432.6657, mean_rewards: 148.9902, total_rewards: 15794.6600, mean_steps: 182.6200, mean_ecr: 0.0413 mean_entropies: 0.3180, took: 420.8968s
2022-08-01 10:02:55,663 [INFO] 	Process 3: Batch 7899/10000, mean_policy_losses: -21.096, mean_net_lifetime: 23105.1387, mean_mc_travel_dist: 31121.2962, mean_rewards: 146.6589, total_rewards: 16891.4357, mean_steps: 200.0300, mean_ecr: 0.0399 mean_entropies: 0.3061, took: 423.5650s
2022-08-01 10:10:42,462 [INFO] 	Process 3: Batch 7999/10000, mean_policy_losses: -20.902, mean_net_lifetime: 24742.5953, mean_mc_travel_dist: 31936.0393, mean_rewards: 144.9300, total_rewards: 18363.1307, mean_steps: 216.9000, mean_ecr: 0.0396 mean_entropies: 0.3328, took: 466.7997s
2022-08-01 10:19:21,439 [INFO] 	Process 3: Batch 8099/10000, mean_policy_losses: -23.892, mean_net_lifetime: 27375.6948, mean_mc_travel_dist: 37250.3383, mean_rewards: 142.9059, total_rewards: 19934.4944, mean_steps: 256.3300, mean_ecr: 0.0394 mean_entropies: 0.3177, took: 518.9776s
2022-08-01 10:26:05,513 [INFO] 	Process 3: Batch 8199/10000, mean_policy_losses: -34.598, mean_net_lifetime: 21463.5981, mean_mc_travel_dist: 27711.3757, mean_rewards: 145.3021, total_rewards: 15927.1637, mean_steps: 194.2700, mean_ecr: 0.0387 mean_entropies: 0.3396, took: 404.0728s
2022-08-01 10:32:50,739 [INFO] 	Process 3: Batch 8299/10000, mean_policy_losses: -31.526, mean_net_lifetime: 19806.8317, mean_mc_travel_dist: 28634.2534, mean_rewards: 144.1618, total_rewards: 14088.8956, mean_steps: 196.9600, mean_ecr: 0.0390 mean_entropies: 0.3319, took: 405.2245s
2022-08-01 10:41:08,159 [INFO] 	Process 3: Batch 8399/10000, mean_policy_losses: -24.469, mean_net_lifetime: 24309.8114, mean_mc_travel_dist: 33086.5769, mean_rewards: 143.5162, total_rewards: 17697.5257, mean_steps: 228.3900, mean_ecr: 0.0392 mean_entropies: 0.3237, took: 497.4055s
2022-08-01 10:50:10,861 [INFO] 	Process 3: Batch 8499/10000, mean_policy_losses: -21.877, mean_net_lifetime: 29994.6892, mean_mc_travel_dist: 38468.4438, mean_rewards: 145.0461, total_rewards: 22307.3719, mean_steps: 256.8400, mean_ecr: 0.0386 mean_entropies: 0.3206, took: 542.7183s
2022-08-01 10:54:46,219 [INFO] 	Process 3: Batch 8599/10000, mean_policy_losses: -11.532, mean_net_lifetime: 17344.1099, mean_mc_travel_dist: 20841.2825, mean_rewards: 149.9379, total_rewards: 13182.2086, mean_steps: 141.5600, mean_ecr: 0.0411 mean_entropies: 0.3054, took: 275.3457s
2022-08-01 11:00:13,003 [INFO] 	Process 3: Batch 8699/10000, mean_policy_losses: -22.204, mean_net_lifetime: 19424.1534, mean_mc_travel_dist: 24969.8140, mean_rewards: 149.7406, total_rewards: 14437.7192, mean_steps: 169.9800, mean_ecr: 0.0401 mean_entropies: 0.3230, took: 326.7955s
2022-08-01 11:06:05,323 [INFO] 	Process 3: Batch 8799/10000, mean_policy_losses: -25.898, mean_net_lifetime: 19220.0825, mean_mc_travel_dist: 25677.1751, mean_rewards: 151.4596, total_rewards: 14090.9909, mean_steps: 167.8600, mean_ecr: 0.0420 mean_entropies: 0.2980, took: 352.3199s
2022-08-01 11:12:10,479 [INFO] 	Process 3: Batch 8899/10000, mean_policy_losses: -15.512, mean_net_lifetime: 20684.8504, mean_mc_travel_dist: 23769.0648, mean_rewards: 147.9992, total_rewards: 15939.6748, mean_steps: 161.5500, mean_ecr: 0.0405 mean_entropies: 0.3044, took: 365.1560s
2022-08-01 11:16:27,014 [INFO] 	Process 3: Batch 8999/10000, mean_policy_losses: -120.750, mean_net_lifetime: 13397.9348, mean_mc_travel_dist: 13508.9500, mean_rewards: 110.9309, total_rewards: 10697.4048, mean_steps: 127.1200, mean_ecr: 0.0413 mean_entropies: 1.0745, took: 256.5363s
2022-08-01 11:18:52,612 [INFO] 	Process 3: Batch 9099/10000, mean_policy_losses: -106.256, mean_net_lifetime: 6398.2143, mean_mc_travel_dist: 6665.8216, mean_rewards: 93.6977, total_rewards: 5065.4446, mean_steps: 76.4700, mean_ecr: 0.0398 mean_entropies: 1.1889, took: 145.5984s
2022-08-01 11:21:15,582 [INFO] 	Process 3: Batch 9199/10000, mean_policy_losses: -132.760, mean_net_lifetime: 6497.8737, mean_mc_travel_dist: 6761.2701, mean_rewards: 93.5866, total_rewards: 5146.1430, mean_steps: 77.7000, mean_ecr: 0.0391 mean_entropies: 1.2085, took: 142.9696s
2022-08-01 11:24:07,761 [INFO] 	Process 3: Batch 9299/10000, mean_policy_losses: -140.105, mean_net_lifetime: 9162.1248, mean_mc_travel_dist: 8842.7792, mean_rewards: 120.1895, total_rewards: 7394.2930, mean_steps: 92.4800, mean_ecr: 0.0414 mean_entropies: 1.1181, took: 172.1781s

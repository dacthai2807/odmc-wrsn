2022-07-31 14:03:18,428 [INFO] Process 2: Begin training phase
2022-07-31 14:03:24,051 [INFO] Process 2: Start epoch 0
2022-07-31 14:06:34,417 [INFO] 	Process 2: Batch 99/10000, mean_policy_losses: 283.455, mean_net_lifetime: 6719.9519, mean_mc_travel_dist: 11947.7257, mean_rewards: 62.1146, total_rewards: 4335.9679, mean_steps: 109.7200, mean_ecr: 0.0401 mean_entropies: 2.9847, took: 190.3546s
2022-07-31 14:09:12,657 [INFO] 	Process 2: Batch 199/10000, mean_policy_losses: -4.178, mean_net_lifetime: 5990.7746, mean_mc_travel_dist: 9416.5047, mean_rewards: 65.1232, total_rewards: 4115.2128, mean_steps: 89.8700, mean_ecr: 0.0407 mean_entropies: 2.9671, took: 158.2419s
2022-07-31 14:12:30,090 [INFO] 	Process 2: Batch 299/10000, mean_policy_losses: 14.509, mean_net_lifetime: 7163.6214, mean_mc_travel_dist: 11370.9235, mean_rewards: 68.6688, total_rewards: 4894.1288, mean_steps: 112.9400, mean_ecr: 0.0387 mean_entropies: 2.8735, took: 197.4326s
2022-07-31 14:15:35,993 [INFO] 	Process 2: Batch 399/10000, mean_policy_losses: -13.998, mean_net_lifetime: 6357.6687, mean_mc_travel_dist: 10103.7141, mean_rewards: 64.6026, total_rewards: 4340.6208, mean_steps: 102.4600, mean_ecr: 0.0393 mean_entropies: 2.8261, took: 185.9028s
2022-07-31 14:19:02,603 [INFO] 	Process 2: Batch 499/10000, mean_policy_losses: -33.281, mean_net_lifetime: 7969.3954, mean_mc_travel_dist: 11469.8875, mean_rewards: 70.3609, total_rewards: 5681.0240, mean_steps: 116.4800, mean_ecr: 0.0411 mean_entropies: 2.8307, took: 206.6102s
2022-07-31 14:22:04,084 [INFO] 	Process 2: Batch 599/10000, mean_policy_losses: -2.888, mean_net_lifetime: 6781.1981, mean_mc_travel_dist: 10034.6060, mean_rewards: 69.6142, total_rewards: 4778.0543, mean_steps: 101.6600, mean_ecr: 0.0422 mean_entropies: 2.7699, took: 181.4814s
2022-07-31 14:24:42,362 [INFO] 	Process 2: Batch 699/10000, mean_policy_losses: -1.867, mean_net_lifetime: 5902.0277, mean_mc_travel_dist: 8277.0325, mean_rewards: 69.8314, total_rewards: 4249.3530, mean_steps: 87.6200, mean_ecr: 0.0404 mean_entropies: 2.7780, took: 158.2777s
2022-07-31 14:27:42,603 [INFO] 	Process 2: Batch 799/10000, mean_policy_losses: -77.556, mean_net_lifetime: 7005.5980, mean_mc_travel_dist: 9738.4760, mean_rewards: 75.1545, total_rewards: 5061.8537, mean_steps: 99.6100, mean_ecr: 0.0404 mean_entropies: 2.7858, took: 180.2405s
2022-07-31 14:30:32,557 [INFO] 	Process 2: Batch 899/10000, mean_policy_losses: 13.528, mean_net_lifetime: 5935.1394, mean_mc_travel_dist: 8820.4456, mean_rewards: 67.5425, total_rewards: 4174.4087, mean_steps: 94.2800, mean_ecr: 0.0404 mean_entropies: 2.6933, took: 169.9552s
2022-07-31 14:32:51,064 [INFO] 	Process 2: Batch 999/10000, mean_policy_losses: -48.582, mean_net_lifetime: 5552.5088, mean_mc_travel_dist: 7189.9290, mean_rewards: 74.1468, total_rewards: 4115.4064, mean_steps: 76.7700, mean_ecr: 0.0417 mean_entropies: 2.6625, took: 138.5062s
2022-07-31 14:35:36,870 [INFO] 	Process 2: Batch 1099/10000, mean_policy_losses: -14.542, mean_net_lifetime: 6124.6154, mean_mc_travel_dist: 8188.6154, mean_rewards: 71.0705, total_rewards: 4487.9790, mean_steps: 92.1200, mean_ecr: 0.0390 mean_entropies: 2.6251, took: 165.8050s
2022-07-31 14:39:39,275 [INFO] 	Process 2: Batch 1199/10000, mean_policy_losses: -50.191, mean_net_lifetime: 11277.5146, mean_mc_travel_dist: 13040.5413, mean_rewards: 89.0720, total_rewards: 8673.8401, mean_steps: 135.4700, mean_ecr: 0.0426 mean_entropies: 2.6331, took: 242.4031s
2022-07-31 14:44:19,484 [INFO] 	Process 2: Batch 1299/10000, mean_policy_losses: -62.251, mean_net_lifetime: 10817.9589, mean_mc_travel_dist: 13619.3744, mean_rewards: 81.2463, total_rewards: 8096.2377, mean_steps: 153.9000, mean_ecr: 0.0392 mean_entropies: 2.4787, took: 280.2113s
2022-07-31 14:46:50,784 [INFO] 	Process 2: Batch 1399/10000, mean_policy_losses: -48.282, mean_net_lifetime: 6268.8713, mean_mc_travel_dist: 7445.8227, mean_rewards: 79.5481, total_rewards: 4780.4001, mean_steps: 83.3900, mean_ecr: 0.0406 mean_entropies: 2.4027, took: 151.3007s
2022-07-31 14:50:16,978 [INFO] 	Process 2: Batch 1499/10000, mean_policy_losses: -43.702, mean_net_lifetime: 8522.9381, mean_mc_travel_dist: 10357.1563, mean_rewards: 82.7986, total_rewards: 6452.2233, mean_steps: 115.6400, mean_ecr: 0.0402 mean_entropies: 2.4306, took: 206.1937s
2022-07-31 14:54:25,270 [INFO] 	Process 2: Batch 1599/10000, mean_policy_losses: -39.540, mean_net_lifetime: 9810.2505, mean_mc_travel_dist: 12623.8104, mean_rewards: 83.9766, total_rewards: 7286.8343, mean_steps: 140.4500, mean_ecr: 0.0396 mean_entropies: 2.4291, took: 248.2910s
2022-07-31 14:59:42,521 [INFO] 	Process 2: Batch 1699/10000, mean_policy_losses: -62.147, mean_net_lifetime: 13043.5599, mean_mc_travel_dist: 15884.1232, mean_rewards: 89.3792, total_rewards: 9868.3197, mean_steps: 180.2900, mean_ecr: 0.0387 mean_entropies: 2.3709, took: 317.2526s
2022-07-31 15:03:01,547 [INFO] 	Process 2: Batch 1799/10000, mean_policy_losses: -35.295, mean_net_lifetime: 8626.2629, mean_mc_travel_dist: 10337.1197, mean_rewards: 85.3003, total_rewards: 6559.9777, mean_steps: 114.7800, mean_ecr: 0.0402 mean_entropies: 2.2658, took: 199.0256s
2022-07-31 15:07:47,091 [INFO] 	Process 2: Batch 1899/10000, mean_policy_losses: -37.954, mean_net_lifetime: 12673.0706, mean_mc_travel_dist: 14871.6190, mean_rewards: 89.7333, total_rewards: 9700.2179, mean_steps: 163.6900, mean_ecr: 0.0397 mean_entropies: 2.2278, took: 285.5444s
2022-07-31 15:11:37,368 [INFO] 	Process 2: Batch 1999/10000, mean_policy_losses: -81.214, mean_net_lifetime: 9539.0534, mean_mc_travel_dist: 10964.7823, mean_rewards: 86.4621, total_rewards: 7346.6981, mean_steps: 124.7000, mean_ecr: 0.0398 mean_entropies: 2.1822, took: 230.2759s
2022-07-31 15:15:54,553 [INFO] 	Process 2: Batch 2099/10000, mean_policy_losses: -92.984, mean_net_lifetime: 11951.5979, mean_mc_travel_dist: 13144.7187, mean_rewards: 99.3866, total_rewards: 9323.0410, mean_steps: 143.1600, mean_ecr: 0.0423 mean_entropies: 2.1068, took: 257.1852s
2022-07-31 15:18:14,632 [INFO] 	Process 2: Batch 2199/10000, mean_policy_losses: -50.611, mean_net_lifetime: 5820.4059, mean_mc_travel_dist: 6776.4289, mean_rewards: 84.1760, total_rewards: 4466.2584, mean_steps: 76.4900, mean_ecr: 0.0409 mean_entropies: 2.0825, took: 140.0803s
2022-07-31 15:20:38,115 [INFO] 	Process 2: Batch 2299/10000, mean_policy_losses: -74.617, mean_net_lifetime: 5966.4643, mean_mc_travel_dist: 6876.8889, mean_rewards: 83.8214, total_rewards: 4591.8083, mean_steps: 77.2700, mean_ecr: 0.0401 mean_entropies: 2.1782, took: 143.4820s
2022-07-31 15:23:14,425 [INFO] 	Process 2: Batch 2399/10000, mean_policy_losses: -43.380, mean_net_lifetime: 6461.6712, mean_mc_travel_dist: 7256.0957, mean_rewards: 85.0703, total_rewards: 5011.4247, mean_steps: 81.8900, mean_ecr: 0.0398 mean_entropies: 2.0974, took: 156.3107s
2022-07-31 15:25:59,923 [INFO] 	Process 2: Batch 2499/10000, mean_policy_losses: -25.890, mean_net_lifetime: 6662.6567, mean_mc_travel_dist: 7734.7963, mean_rewards: 83.5927, total_rewards: 5116.4726, mean_steps: 89.4600, mean_ecr: 0.0394 mean_entropies: 2.0862, took: 165.4962s
2022-07-31 15:28:17,761 [INFO] 	Process 2: Batch 2599/10000, mean_policy_losses: -41.882, mean_net_lifetime: 6062.4803, mean_mc_travel_dist: 6726.8821, mean_rewards: 86.2430, total_rewards: 4718.3864, mean_steps: 75.3900, mean_ecr: 0.0405 mean_entropies: 2.0437, took: 137.8401s
2022-07-31 15:30:38,690 [INFO] 	Process 2: Batch 2699/10000, mean_policy_losses: -30.977, mean_net_lifetime: 6136.1910, mean_mc_travel_dist: 6803.4395, mean_rewards: 85.6204, total_rewards: 4775.6899, mean_steps: 76.9800, mean_ecr: 0.0400 mean_entropies: 2.0499, took: 140.9278s
2022-07-31 15:32:56,694 [INFO] 	Process 2: Batch 2799/10000, mean_policy_losses: -53.098, mean_net_lifetime: 6080.0964, mean_mc_travel_dist: 6739.1034, mean_rewards: 87.8713, total_rewards: 4732.5093, mean_steps: 75.5700, mean_ecr: 0.0403 mean_entropies: 2.0867, took: 138.0038s
2022-07-31 15:35:12,124 [INFO] 	Process 2: Batch 2899/10000, mean_policy_losses: -24.238, mean_net_lifetime: 6392.4444, mean_mc_travel_dist: 6632.1431, mean_rewards: 94.9209, total_rewards: 5067.0219, mean_steps: 72.6400, mean_ecr: 0.0411 mean_entropies: 2.0714, took: 135.4307s
2022-07-31 15:37:39,893 [INFO] 	Process 2: Batch 2999/10000, mean_policy_losses: -79.339, mean_net_lifetime: 6334.2548, mean_mc_travel_dist: 6725.9016, mean_rewards: 90.9286, total_rewards: 4989.4771, mean_steps: 75.6700, mean_ecr: 0.0401 mean_entropies: 2.0536, took: 147.7663s
2022-07-31 15:40:10,146 [INFO] 	Process 2: Batch 3099/10000, mean_policy_losses: -31.207, mean_net_lifetime: 6661.4701, mean_mc_travel_dist: 7197.5505, mean_rewards: 92.2810, total_rewards: 5221.9600, mean_steps: 79.9800, mean_ecr: 0.0394 mean_entropies: 2.0822, took: 150.2559s
2022-07-31 15:42:27,626 [INFO] 	Process 2: Batch 3199/10000, mean_policy_losses: -60.053, mean_net_lifetime: 6249.7416, mean_mc_travel_dist: 6646.2955, mean_rewards: 93.8741, total_rewards: 4920.6371, mean_steps: 72.4800, mean_ecr: 0.0405 mean_entropies: 2.0386, took: 137.4793s
2022-07-31 15:44:43,751 [INFO] 	Process 2: Batch 3299/10000, mean_policy_losses: -59.506, mean_net_lifetime: 6246.7068, mean_mc_travel_dist: 6393.8717, mean_rewards: 95.2658, total_rewards: 4968.5649, mean_steps: 71.2500, mean_ecr: 0.0414 mean_entropies: 2.0157, took: 136.1239s
2022-07-31 15:46:58,807 [INFO] 	Process 2: Batch 3399/10000, mean_policy_losses: -72.365, mean_net_lifetime: 6208.2466, mean_mc_travel_dist: 6444.9304, mean_rewards: 95.5552, total_rewards: 4919.8624, mean_steps: 71.3200, mean_ecr: 0.0413 mean_entropies: 1.9638, took: 135.0582s
2022-07-31 15:49:21,977 [INFO] 	Process 2: Batch 3499/10000, mean_policy_losses: -75.822, mean_net_lifetime: 6380.8643, mean_mc_travel_dist: 6564.7997, mean_rewards: 95.2601, total_rewards: 5067.9044, mean_steps: 73.0700, mean_ecr: 0.0408 mean_entropies: 2.0004, took: 143.1678s
2022-07-31 15:51:47,888 [INFO] 	Process 2: Batch 3599/10000, mean_policy_losses: -73.933, mean_net_lifetime: 6309.8126, mean_mc_travel_dist: 6693.1156, mean_rewards: 94.3836, total_rewards: 4971.1895, mean_steps: 75.1700, mean_ecr: 0.0397 mean_entropies: 2.0118, took: 145.9125s
2022-07-31 15:54:02,067 [INFO] 	Process 2: Batch 3699/10000, mean_policy_losses: -114.730, mean_net_lifetime: 6191.3458, mean_mc_travel_dist: 6436.1289, mean_rewards: 97.2198, total_rewards: 4904.1201, mean_steps: 70.1500, mean_ecr: 0.0407 mean_entropies: 2.0098, took: 134.1771s
2022-07-31 15:56:21,471 [INFO] 	Process 2: Batch 3799/10000, mean_policy_losses: -44.010, mean_net_lifetime: 6614.8789, mean_mc_travel_dist: 6698.3475, mean_rewards: 95.8650, total_rewards: 5275.4342, mean_steps: 74.1200, mean_ecr: 0.0398 mean_entropies: 1.9960, took: 139.4062s
2022-07-31 15:58:29,820 [INFO] 	Process 2: Batch 3899/10000, mean_policy_losses: -99.837, mean_net_lifetime: 6232.1939, mean_mc_travel_dist: 6458.2099, mean_rewards: 96.6456, total_rewards: 4941.6506, mean_steps: 70.1200, mean_ecr: 0.0405 mean_entropies: 1.9814, took: 128.3491s
2022-07-31 16:00:38,230 [INFO] 	Process 2: Batch 3999/10000, mean_policy_losses: -67.574, mean_net_lifetime: 6241.0871, mean_mc_travel_dist: 6401.4605, mean_rewards: 98.4025, total_rewards: 4961.9025, mean_steps: 69.5500, mean_ecr: 0.0407 mean_entropies: 1.9881, took: 128.4096s
2022-07-31 16:02:47,657 [INFO] 	Process 2: Batch 4099/10000, mean_policy_losses: -97.004, mean_net_lifetime: 6285.3855, mean_mc_travel_dist: 6459.3504, mean_rewards: 95.9069, total_rewards: 4993.8244, mean_steps: 70.5400, mean_ecr: 0.0403 mean_entropies: 1.9271, took: 129.4264s
2022-07-31 16:05:05,163 [INFO] 	Process 2: Batch 4199/10000, mean_policy_losses: -92.538, mean_net_lifetime: 6362.7279, mean_mc_travel_dist: 6638.1523, mean_rewards: 98.4113, total_rewards: 5036.1949, mean_steps: 72.1700, mean_ecr: 0.0395 mean_entropies: 1.8920, took: 137.5059s
2022-07-31 16:07:09,877 [INFO] 	Process 2: Batch 4299/10000, mean_policy_losses: -75.568, mean_net_lifetime: 6271.4358, mean_mc_travel_dist: 6009.6821, mean_rewards: 103.6019, total_rewards: 5069.8398, mean_steps: 66.1400, mean_ecr: 0.0429 mean_entropies: 1.8327, took: 124.7142s
2022-07-31 16:09:24,187 [INFO] 	Process 2: Batch 4399/10000, mean_policy_losses: -50.412, mean_net_lifetime: 6313.2502, mean_mc_travel_dist: 6545.2238, mean_rewards: 99.2048, total_rewards: 5004.6332, mean_steps: 72.1600, mean_ecr: 0.0399 mean_entropies: 1.8420, took: 134.3114s
2022-07-31 16:11:45,033 [INFO] 	Process 2: Batch 4499/10000, mean_policy_losses: -119.759, mean_net_lifetime: 6212.1299, mean_mc_travel_dist: 6844.6653, mean_rewards: 91.9813, total_rewards: 4843.4801, mean_steps: 75.2400, mean_ecr: 0.0385 mean_entropies: 1.8938, took: 140.8448s
2022-07-31 16:13:57,539 [INFO] 	Process 2: Batch 4599/10000, mean_policy_losses: -39.263, mean_net_lifetime: 6256.7767, mean_mc_travel_dist: 6159.3053, mean_rewards: 100.7401, total_rewards: 5025.4417, mean_steps: 69.6400, mean_ecr: 0.0420 mean_entropies: 1.7498, took: 132.5069s
2022-07-31 16:16:23,561 [INFO] 	Process 2: Batch 4699/10000, mean_policy_losses: -67.488, mean_net_lifetime: 6313.5103, mean_mc_travel_dist: 6663.5727, mean_rewards: 95.0505, total_rewards: 4981.5816, mean_steps: 76.0300, mean_ecr: 0.0395 mean_entropies: 1.8499, took: 146.0213s
2022-07-31 16:18:52,775 [INFO] 	Process 2: Batch 4799/10000, mean_policy_losses: -62.595, mean_net_lifetime: 6371.1222, mean_mc_travel_dist: 6784.4693, mean_rewards: 95.5154, total_rewards: 5015.7450, mean_steps: 75.5900, mean_ecr: 0.0391 mean_entropies: 1.8507, took: 149.2145s
2022-07-31 16:21:06,944 [INFO] 	Process 2: Batch 4899/10000, mean_policy_losses: -74.940, mean_net_lifetime: 6293.6269, mean_mc_travel_dist: 6401.3425, mean_rewards: 102.1145, total_rewards: 5014.3492, mean_steps: 69.2800, mean_ecr: 0.0405 mean_entropies: 1.7851, took: 134.1654s
2022-07-31 16:23:22,434 [INFO] 	Process 2: Batch 4999/10000, mean_policy_losses: -84.009, mean_net_lifetime: 6560.9157, mean_mc_travel_dist: 6590.6937, mean_rewards: 98.7313, total_rewards: 5243.3295, mean_steps: 71.6000, mean_ecr: 0.0397 mean_entropies: 1.8316, took: 135.4930s
2022-07-31 16:25:40,163 [INFO] 	Process 2: Batch 5099/10000, mean_policy_losses: -70.056, mean_net_lifetime: 6484.9329, mean_mc_travel_dist: 6549.4878, mean_rewards: 97.9707, total_rewards: 5175.3837, mean_steps: 72.1000, mean_ecr: 0.0399 mean_entropies: 1.8520, took: 137.7293s
2022-07-31 16:27:52,142 [INFO] 	Process 2: Batch 5199/10000, mean_policy_losses: -97.882, mean_net_lifetime: 6229.1908, mean_mc_travel_dist: 6385.9248, mean_rewards: 100.2369, total_rewards: 4952.5864, mean_steps: 67.9400, mean_ecr: 0.0405 mean_entropies: 1.7907, took: 131.9789s
2022-07-31 16:30:09,969 [INFO] 	Process 2: Batch 5299/10000, mean_policy_losses: -86.654, mean_net_lifetime: 6608.1699, mean_mc_travel_dist: 6404.5552, mean_rewards: 102.5381, total_rewards: 5328.0104, mean_steps: 69.7400, mean_ecr: 0.0404 mean_entropies: 1.8178, took: 137.8270s
2022-07-31 16:32:40,525 [INFO] 	Process 2: Batch 5399/10000, mean_policy_losses: -33.845, mean_net_lifetime: 6399.4337, mean_mc_travel_dist: 6865.7725, mean_rewards: 93.1533, total_rewards: 5026.2792, mean_steps: 74.5300, mean_ecr: 0.0382 mean_entropies: 1.8520, took: 150.5558s
2022-07-31 16:34:56,851 [INFO] 	Process 2: Batch 5499/10000, mean_policy_losses: -91.386, mean_net_lifetime: 6230.3194, mean_mc_travel_dist: 6536.0470, mean_rewards: 97.1812, total_rewards: 4923.1100, mean_steps: 72.3200, mean_ecr: 0.0396 mean_entropies: 1.7877, took: 136.3264s
2022-07-31 16:37:11,714 [INFO] 	Process 2: Batch 5599/10000, mean_policy_losses: -74.789, mean_net_lifetime: 6401.7433, mean_mc_travel_dist: 6401.5870, mean_rewards: 100.9163, total_rewards: 5121.5694, mean_steps: 70.7800, mean_ecr: 0.0409 mean_entropies: 1.8059, took: 134.8627s
2022-07-31 16:39:18,381 [INFO] 	Process 2: Batch 5699/10000, mean_policy_losses: -81.762, mean_net_lifetime: 6442.2311, mean_mc_travel_dist: 6109.1716, mean_rewards: 106.6338, total_rewards: 5221.3616, mean_steps: 66.5100, mean_ecr: 0.0417 mean_entropies: 1.6971, took: 126.6674s
2022-07-31 16:41:25,837 [INFO] 	Process 2: Batch 5799/10000, mean_policy_losses: -67.550, mean_net_lifetime: 6417.1209, mean_mc_travel_dist: 6267.8711, mean_rewards: 105.3580, total_rewards: 5164.9146, mean_steps: 66.8500, mean_ecr: 0.0412 mean_entropies: 1.7197, took: 127.4552s
2022-07-31 16:43:39,824 [INFO] 	Process 2: Batch 5899/10000, mean_policy_losses: -73.631, mean_net_lifetime: 6396.1867, mean_mc_travel_dist: 6376.1841, mean_rewards: 103.9086, total_rewards: 5121.6654, mean_steps: 68.8300, mean_ecr: 0.0403 mean_entropies: 1.7099, took: 133.9881s
2022-07-31 16:45:50,225 [INFO] 	Process 2: Batch 5999/10000, mean_policy_losses: -82.002, mean_net_lifetime: 6555.4019, mean_mc_travel_dist: 6179.6873, mean_rewards: 105.2108, total_rewards: 5319.5393, mean_steps: 66.8800, mean_ecr: 0.0411 mean_entropies: 1.6788, took: 130.3993s
2022-07-31 16:48:02,404 [INFO] 	Process 2: Batch 6099/10000, mean_policy_losses: -94.495, mean_net_lifetime: 6439.6965, mean_mc_travel_dist: 6352.6027, mean_rewards: 103.4187, total_rewards: 5170.3669, mean_steps: 68.4000, mean_ecr: 0.0406 mean_entropies: 1.7049, took: 132.1809s
2022-07-31 16:50:16,641 [INFO] 	Process 2: Batch 6199/10000, mean_policy_losses: -25.741, mean_net_lifetime: 6577.4019, mean_mc_travel_dist: 6171.3750, mean_rewards: 104.4381, total_rewards: 5344.3632, mean_steps: 66.6400, mean_ecr: 0.0413 mean_entropies: 1.6588, took: 134.2357s
2022-07-31 16:52:32,745 [INFO] 	Process 2: Batch 6299/10000, mean_policy_losses: -89.422, mean_net_lifetime: 6433.7379, mean_mc_travel_dist: 6167.5950, mean_rewards: 103.9646, total_rewards: 5200.6365, mean_steps: 67.9000, mean_ecr: 0.0413 mean_entropies: 1.6378, took: 136.1024s
2022-07-31 16:54:41,918 [INFO] 	Process 2: Batch 6399/10000, mean_policy_losses: -84.421, mean_net_lifetime: 6393.2954, mean_mc_travel_dist: 6386.1851, mean_rewards: 100.7602, total_rewards: 5116.5132, mean_steps: 69.0000, mean_ecr: 0.0405 mean_entropies: 1.6502, took: 129.1740s
2022-07-31 16:56:52,800 [INFO] 	Process 2: Batch 6499/10000, mean_policy_losses: -96.490, mean_net_lifetime: 6259.3505, mean_mc_travel_dist: 6578.9834, mean_rewards: 98.7534, total_rewards: 4945.3416, mean_steps: 70.4700, mean_ecr: 0.0397 mean_entropies: 1.6995, took: 130.8822s
2022-07-31 16:59:05,066 [INFO] 	Process 2: Batch 6599/10000, mean_policy_losses: -87.456, mean_net_lifetime: 6665.0879, mean_mc_travel_dist: 6355.5165, mean_rewards: 103.0874, total_rewards: 5394.8891, mean_steps: 69.7800, mean_ecr: 0.0405 mean_entropies: 1.6104, took: 132.2670s
2022-07-31 17:01:11,063 [INFO] 	Process 2: Batch 6699/10000, mean_policy_losses: -23.970, mean_net_lifetime: 6624.1324, mean_mc_travel_dist: 6210.4615, mean_rewards: 107.3414, total_rewards: 5382.6541, mean_steps: 66.7600, mean_ecr: 0.0415 mean_entropies: 1.5842, took: 125.9970s
2022-07-31 17:03:21,255 [INFO] 	Process 2: Batch 6799/10000, mean_policy_losses: -99.785, mean_net_lifetime: 6403.4292, mean_mc_travel_dist: 6122.7403, mean_rewards: 106.2057, total_rewards: 5179.1083, mean_steps: 66.6800, mean_ecr: 0.0415 mean_entropies: 1.5988, took: 130.1919s
2022-07-31 17:05:35,567 [INFO] 	Process 2: Batch 6899/10000, mean_policy_losses: -27.512, mean_net_lifetime: 6516.7119, mean_mc_travel_dist: 6338.3564, mean_rewards: 102.8276, total_rewards: 5249.2790, mean_steps: 68.8700, mean_ecr: 0.0407 mean_entropies: 1.5850, took: 134.3102s
2022-07-31 17:07:52,252 [INFO] 	Process 2: Batch 6999/10000, mean_policy_losses: -79.806, mean_net_lifetime: 6429.4472, mean_mc_travel_dist: 6500.9988, mean_rewards: 100.5457, total_rewards: 5129.3939, mean_steps: 70.7100, mean_ecr: 0.0400 mean_entropies: 1.5584, took: 136.6868s
2022-07-31 17:10:18,024 [INFO] 	Process 2: Batch 7099/10000, mean_policy_losses: -77.977, mean_net_lifetime: 6335.1678, mean_mc_travel_dist: 6611.5337, mean_rewards: 96.4771, total_rewards: 5012.9878, mean_steps: 72.7900, mean_ecr: 0.0393 mean_entropies: 1.5551, took: 145.7701s
2022-07-31 17:12:21,587 [INFO] 	Process 2: Batch 7199/10000, mean_policy_losses: -81.893, mean_net_lifetime: 6812.6770, mean_mc_travel_dist: 6023.1805, mean_rewards: 112.7075, total_rewards: 5608.0409, mean_steps: 63.2900, mean_ecr: 0.0421 mean_entropies: 1.4514, took: 123.5634s
2022-07-31 17:14:24,523 [INFO] 	Process 2: Batch 7299/10000, mean_policy_losses: -58.709, mean_net_lifetime: 6507.1172, mean_mc_travel_dist: 5929.2010, mean_rewards: 110.4447, total_rewards: 5322.1086, mean_steps: 63.1100, mean_ecr: 0.0430 mean_entropies: 1.4787, took: 122.9369s
2022-07-31 17:16:23,472 [INFO] 	Process 2: Batch 7399/10000, mean_policy_losses: -86.385, mean_net_lifetime: 6650.5868, mean_mc_travel_dist: 6036.3565, mean_rewards: 113.4944, total_rewards: 5444.2526, mean_steps: 63.3600, mean_ecr: 0.0417 mean_entropies: 1.4224, took: 118.9488s
2022-07-31 17:20:17,032 [INFO] 	Process 2: Batch 7499/10000, mean_policy_losses: -99.472, mean_net_lifetime: 12836.1772, mean_mc_travel_dist: 13695.6192, mean_rewards: 127.9072, total_rewards: 10098.6864, mean_steps: 124.7800, mean_ecr: 0.0419 mean_entropies: 1.3473, took: 233.5599s
2022-07-31 17:22:33,191 [INFO] 	Process 2: Batch 7599/10000, mean_policy_losses: -50.726, mean_net_lifetime: 6460.6935, mean_mc_travel_dist: 6607.8480, mean_rewards: 97.9606, total_rewards: 5139.9380, mean_steps: 72.5000, mean_ecr: 0.0392 mean_entropies: 1.5069, took: 136.1592s
2022-07-31 17:24:51,778 [INFO] 	Process 2: Batch 7699/10000, mean_policy_losses: -47.726, mean_net_lifetime: 6421.2778, mean_mc_travel_dist: 6535.1295, mean_rewards: 97.9426, total_rewards: 5115.0023, mean_steps: 71.6600, mean_ecr: 0.0399 mean_entropies: 1.5109, took: 138.5867s
2022-07-31 17:27:07,345 [INFO] 	Process 2: Batch 7799/10000, mean_policy_losses: -97.517, mean_net_lifetime: 6472.9721, mean_mc_travel_dist: 6361.3275, mean_rewards: 102.2143, total_rewards: 5201.3009, mean_steps: 69.0600, mean_ecr: 0.0403 mean_entropies: 1.4440, took: 135.5660s
2022-07-31 17:29:31,897 [INFO] 	Process 2: Batch 7899/10000, mean_policy_losses: -79.581, mean_net_lifetime: 6433.2533, mean_mc_travel_dist: 6713.4510, mean_rewards: 97.0092, total_rewards: 5092.7382, mean_steps: 72.9400, mean_ecr: 0.0388 mean_entropies: 1.5061, took: 144.5534s
2022-07-31 17:31:49,351 [INFO] 	Process 2: Batch 7999/10000, mean_policy_losses: -17.026, mean_net_lifetime: 6346.4471, mean_mc_travel_dist: 6652.0919, mean_rewards: 98.9161, total_rewards: 5016.2218, mean_steps: 70.9900, mean_ecr: 0.0395 mean_entropies: 1.4685, took: 137.4547s
2022-07-31 17:34:02,649 [INFO] 	Process 2: Batch 8099/10000, mean_policy_losses: -100.600, mean_net_lifetime: 6535.2111, mean_mc_travel_dist: 6372.2616, mean_rewards: 105.3758, total_rewards: 5261.6708, mean_steps: 68.5700, mean_ecr: 0.0402 mean_entropies: 1.4046, took: 133.2977s
2022-07-31 17:36:13,487 [INFO] 	Process 2: Batch 8199/10000, mean_policy_losses: -65.783, mean_net_lifetime: 6606.4765, mean_mc_travel_dist: 6445.0289, mean_rewards: 103.1511, total_rewards: 5318.5006, mean_steps: 68.8900, mean_ecr: 0.0399 mean_entropies: 1.4541, took: 130.8381s
2022-07-31 17:38:20,627 [INFO] 	Process 2: Batch 8299/10000, mean_policy_losses: -56.617, mean_net_lifetime: 6464.7953, mean_mc_travel_dist: 6284.8792, mean_rewards: 103.4768, total_rewards: 5209.6224, mean_steps: 67.7100, mean_ecr: 0.0409 mean_entropies: 1.4280, took: 127.1401s
2022-07-31 17:40:30,486 [INFO] 	Process 2: Batch 8399/10000, mean_policy_losses: -114.521, mean_net_lifetime: 6492.3604, mean_mc_travel_dist: 6290.1620, mean_rewards: 104.3405, total_rewards: 5235.6706, mean_steps: 69.0000, mean_ecr: 0.0406 mean_entropies: 1.3924, took: 129.8580s
2022-07-31 17:42:44,668 [INFO] 	Process 2: Batch 8499/10000, mean_policy_losses: -49.627, mean_net_lifetime: 6617.7417, mean_mc_travel_dist: 6406.6623, mean_rewards: 103.5248, total_rewards: 5337.4027, mean_steps: 68.5500, mean_ecr: 0.0399 mean_entropies: 1.4092, took: 134.1826s
2022-07-31 17:44:52,951 [INFO] 	Process 2: Batch 8599/10000, mean_policy_losses: -78.086, mean_net_lifetime: 6338.1756, mean_mc_travel_dist: 6079.6281, mean_rewards: 107.0214, total_rewards: 5123.1333, mean_steps: 65.8300, mean_ecr: 0.0420 mean_entropies: 1.3833, took: 128.2819s
2022-07-31 17:47:07,323 [INFO] 	Process 2: Batch 8699/10000, mean_policy_losses: -60.881, mean_net_lifetime: 6515.7446, mean_mc_travel_dist: 6355.3964, mean_rewards: 105.4352, total_rewards: 5245.0104, mean_steps: 67.6400, mean_ecr: 0.0405 mean_entropies: 1.4018, took: 134.3732s
2022-07-31 17:49:19,844 [INFO] 	Process 2: Batch 8799/10000, mean_policy_losses: -83.390, mean_net_lifetime: 6486.8112, mean_mc_travel_dist: 6412.4565, mean_rewards: 103.3028, total_rewards: 5205.3080, mean_steps: 69.0400, mean_ecr: 0.0401 mean_entropies: 1.3694, took: 132.5201s
2022-07-31 17:51:33,729 [INFO] 	Process 2: Batch 8899/10000, mean_policy_losses: -27.825, mean_net_lifetime: 6670.4845, mean_mc_travel_dist: 6024.7828, mean_rewards: 110.2629, total_rewards: 5465.8101, mean_steps: 66.4200, mean_ecr: 0.0421 mean_entropies: 1.3387, took: 133.8855s
2022-07-31 17:53:51,269 [INFO] 	Process 2: Batch 8999/10000, mean_policy_losses: -44.559, mean_net_lifetime: 6511.2081, mean_mc_travel_dist: 6432.3904, mean_rewards: 104.2961, total_rewards: 5225.5135, mean_steps: 68.7500, mean_ecr: 0.0400 mean_entropies: 1.3861, took: 137.5406s
2022-07-31 17:56:12,439 [INFO] 	Process 2: Batch 9099/10000, mean_policy_losses: -95.415, mean_net_lifetime: 6408.6180, mean_mc_travel_dist: 6517.9510, mean_rewards: 100.3883, total_rewards: 5105.8307, mean_steps: 71.2700, mean_ecr: 0.0395 mean_entropies: 1.3893, took: 141.1686s
2022-07-31 17:58:19,881 [INFO] 	Process 2: Batch 9199/10000, mean_policy_losses: -63.952, mean_net_lifetime: 6510.8612, mean_mc_travel_dist: 6120.3226, mean_rewards: 108.6157, total_rewards: 5287.0106, mean_steps: 66.1500, mean_ecr: 0.0415 mean_entropies: 1.3007, took: 127.4420s
2022-07-31 18:00:36,510 [INFO] 	Process 2: Batch 9299/10000, mean_policy_losses: -79.466, mean_net_lifetime: 6408.1355, mean_mc_travel_dist: 6620.9800, mean_rewards: 102.2770, total_rewards: 5084.7186, mean_steps: 72.0200, mean_ecr: 0.0392 mean_entropies: 1.3689, took: 136.6299s
2022-07-31 18:02:47,663 [INFO] 	Process 2: Batch 9399/10000, mean_policy_losses: -81.335, mean_net_lifetime: 6354.2118, mean_mc_travel_dist: 6418.5623, mean_rewards: 101.7855, total_rewards: 5071.2697, mean_steps: 68.7100, mean_ecr: 0.0405 mean_entropies: 1.3309, took: 131.1525s
2022-07-31 18:05:02,997 [INFO] 	Process 2: Batch 9499/10000, mean_policy_losses: -44.985, mean_net_lifetime: 6385.5354, mean_mc_travel_dist: 6541.1801, mean_rewards: 100.6728, total_rewards: 5077.8542, mean_steps: 70.9400, mean_ecr: 0.0397 mean_entropies: 1.3620, took: 135.3327s
2022-07-31 18:07:18,298 [INFO] 	Process 2: Batch 9599/10000, mean_policy_losses: -59.106, mean_net_lifetime: 6429.6104, mean_mc_travel_dist: 6579.4109, mean_rewards: 101.7470, total_rewards: 5113.7282, mean_steps: 68.7700, mean_ecr: 0.0391 mean_entropies: 1.3688, took: 135.3038s
2022-07-31 18:09:31,035 [INFO] 	Process 2: Batch 9699/10000, mean_policy_losses: -43.882, mean_net_lifetime: 6498.9784, mean_mc_travel_dist: 6352.5915, mean_rewards: 103.8315, total_rewards: 5228.7953, mean_steps: 67.4900, mean_ecr: 0.0405 mean_entropies: 1.3397, took: 132.7366s
2022-07-31 18:11:37,217 [INFO] 	Process 2: Batch 9799/10000, mean_policy_losses: -52.518, mean_net_lifetime: 6505.2150, mean_mc_travel_dist: 6280.9653, mean_rewards: 108.7020, total_rewards: 5249.1825, mean_steps: 64.5800, mean_ecr: 0.0409 mean_entropies: 1.2828, took: 126.1815s
2022-07-31 18:13:57,105 [INFO] 	Process 2: Batch 9899/10000, mean_policy_losses: -37.642, mean_net_lifetime: 6630.6966, mean_mc_travel_dist: 6654.7708, mean_rewards: 100.2306, total_rewards: 5299.7425, mean_steps: 72.2100, mean_ecr: 0.0390 mean_entropies: 1.3243, took: 139.8884s
2022-07-31 18:16:18,487 [INFO] 	Process 2: Batch 9999/10000, mean_policy_losses: -86.246, mean_net_lifetime: 6466.4730, mean_mc_travel_dist: 6438.0885, mean_rewards: 103.8085, total_rewards: 5179.3400, mean_steps: 69.3500, mean_ecr: 0.0397 mean_entropies: 1.2891, took: 141.3823s
2022-07-31 18:27:22,958 [INFO] Process 2: Epoch 0: mean_policy_losses: -58.177, mean_net_lifetime: 6865.4821, mean_mc_travel_dist: 7482.0509, mean_entropies: 1.8763, m_net_lifetime_valid: 6507.5193, took: 15838.8984s, (150.2418 / 100 batches)

2022-07-31 18:27:22,958 [INFO] Process 2: Start epoch 1
2022-07-31 18:29:24,707 [INFO] 	Process 2: Batch 99/10000, mean_policy_losses: 120.875, mean_net_lifetime: 3976.4213, mean_mc_travel_dist: 7126.7246, mean_rewards: 57.6816, total_rewards: 2555.4844, mean_steps: 69.7600, mean_ecr: 0.0394 mean_entropies: 2.8934, took: 121.7447s
2022-07-31 18:31:26,965 [INFO] 	Process 2: Batch 199/10000, mean_policy_losses: -38.109, mean_net_lifetime: 4294.6598, mean_mc_travel_dist: 6862.9735, mean_rewards: 62.0734, total_rewards: 2924.1375, mean_steps: 69.4400, mean_ecr: 0.0416 mean_entropies: 2.7898, took: 122.2569s
2022-07-31 18:33:45,281 [INFO] 	Process 2: Batch 299/10000, mean_policy_losses: -30.583, mean_net_lifetime: 4334.9305, mean_mc_travel_dist: 7022.7291, mean_rewards: 59.1655, total_rewards: 2932.6776, mean_steps: 73.9900, mean_ecr: 0.0392 mean_entropies: 2.7541, took: 138.3161s
2022-07-31 18:36:01,232 [INFO] 	Process 2: Batch 399/10000, mean_policy_losses: -29.716, mean_net_lifetime: 4731.3519, mean_mc_travel_dist: 6975.8496, mean_rewards: 64.9001, total_rewards: 3338.3450, mean_steps: 74.5600, mean_ecr: 0.0400 mean_entropies: 2.7568, took: 135.9508s
2022-07-31 18:38:17,135 [INFO] 	Process 2: Batch 499/10000, mean_policy_losses: -9.428, mean_net_lifetime: 4820.6683, mean_mc_travel_dist: 6945.0687, mean_rewards: 66.4451, total_rewards: 3432.5351, mean_steps: 75.0700, mean_ecr: 0.0406 mean_entropies: 2.7053, took: 135.9029s
2022-07-31 18:40:32,542 [INFO] 	Process 2: Batch 599/10000, mean_policy_losses: 21.578, mean_net_lifetime: 4781.7370, mean_mc_travel_dist: 6686.8062, mean_rewards: 68.7987, total_rewards: 3446.2011, mean_steps: 73.0200, mean_ecr: 0.0408 mean_entropies: 2.6625, took: 135.4060s
2022-07-31 18:43:01,152 [INFO] 	Process 2: Batch 699/10000, mean_policy_losses: -23.612, mean_net_lifetime: 5157.6068, mean_mc_travel_dist: 6831.1022, mean_rewards: 71.1177, total_rewards: 3793.8737, mean_steps: 77.1100, mean_ecr: 0.0404 mean_entropies: 2.6049, took: 148.6108s
2022-07-31 18:45:24,153 [INFO] 	Process 2: Batch 799/10000, mean_policy_losses: -27.833, mean_net_lifetime: 5324.4153, mean_mc_travel_dist: 6735.1878, mean_rewards: 75.6762, total_rewards: 3978.2098, mean_steps: 74.8700, mean_ecr: 0.0405 mean_entropies: 2.5911, took: 143.0021s
2022-07-31 18:47:54,739 [INFO] 	Process 2: Batch 899/10000, mean_policy_losses: -51.535, mean_net_lifetime: 5311.1538, mean_mc_travel_dist: 7058.4656, mean_rewards: 72.2851, total_rewards: 3900.9953, mean_steps: 79.6400, mean_ecr: 0.0389 mean_entropies: 2.5409, took: 150.5867s
2022-07-31 18:50:19,716 [INFO] 	Process 2: Batch 999/10000, mean_policy_losses: -8.199, mean_net_lifetime: 5860.7394, mean_mc_travel_dist: 6824.6485, mean_rewards: 81.3889, total_rewards: 4496.4548, mean_steps: 77.4800, mean_ecr: 0.0401 mean_entropies: 2.3939, took: 144.9768s
2022-07-31 18:52:41,181 [INFO] 	Process 2: Batch 1099/10000, mean_policy_losses: -96.321, mean_net_lifetime: 5733.0324, mean_mc_travel_dist: 6645.9800, mean_rewards: 82.3829, total_rewards: 4405.0288, mean_steps: 74.6300, mean_ecr: 0.0412 mean_entropies: 2.3791, took: 141.4627s
2022-07-31 18:55:13,979 [INFO] 	Process 2: Batch 1199/10000, mean_policy_losses: -77.050, mean_net_lifetime: 5836.5933, mean_mc_travel_dist: 7083.0479, mean_rewards: 79.2123, total_rewards: 4419.9837, mean_steps: 79.9100, mean_ecr: 0.0389 mean_entropies: 2.3547, took: 152.7992s
2022-07-31 18:57:37,834 [INFO] 	Process 2: Batch 1299/10000, mean_policy_losses: -39.537, mean_net_lifetime: 6018.5884, mean_mc_travel_dist: 6767.8837, mean_rewards: 84.3063, total_rewards: 4666.7112, mean_steps: 74.7600, mean_ecr: 0.0405 mean_entropies: 2.3888, took: 143.8563s
2022-07-31 19:00:04,967 [INFO] 	Process 2: Batch 1399/10000, mean_policy_losses: -42.393, mean_net_lifetime: 5815.4725, mean_mc_travel_dist: 6870.0228, mean_rewards: 83.5515, total_rewards: 4442.1156, mean_steps: 76.0600, mean_ecr: 0.0400 mean_entropies: 2.3300, took: 147.1314s
2022-07-31 19:02:29,881 [INFO] 	Process 2: Batch 1499/10000, mean_policy_losses: 6.438, mean_net_lifetime: 5881.3277, mean_mc_travel_dist: 6790.8962, mean_rewards: 83.3878, total_rewards: 4523.3900, mean_steps: 76.0600, mean_ecr: 0.0401 mean_entropies: 2.2597, took: 144.9156s
2022-07-31 19:04:54,558 [INFO] 	Process 2: Batch 1599/10000, mean_policy_losses: 0.919, mean_net_lifetime: 5818.3440, mean_mc_travel_dist: 6648.5124, mean_rewards: 83.6623, total_rewards: 4490.6872, mean_steps: 74.4700, mean_ecr: 0.0406 mean_entropies: 2.1686, took: 144.6766s
2022-07-31 19:07:21,835 [INFO] 	Process 2: Batch 1699/10000, mean_policy_losses: -76.585, mean_net_lifetime: 5829.8285, mean_mc_travel_dist: 6815.7816, mean_rewards: 82.9575, total_rewards: 4467.8875, mean_steps: 76.2200, mean_ecr: 0.0399 mean_entropies: 2.2156, took: 147.2772s
2022-07-31 19:09:42,440 [INFO] 	Process 2: Batch 1799/10000, mean_policy_losses: -71.940, mean_net_lifetime: 6125.4207, mean_mc_travel_dist: 6730.6503, mean_rewards: 88.5968, total_rewards: 4779.6166, mean_steps: 73.9200, mean_ecr: 0.0410 mean_entropies: 2.1625, took: 140.6035s
2022-07-31 19:12:07,095 [INFO] 	Process 2: Batch 1899/10000, mean_policy_losses: -41.977, mean_net_lifetime: 5871.1566, mean_mc_travel_dist: 6705.8856, mean_rewards: 87.1473, total_rewards: 4531.8420, mean_steps: 74.8900, mean_ecr: 0.0406 mean_entropies: 2.1471, took: 144.6542s
2022-07-31 19:14:39,284 [INFO] 	Process 2: Batch 1999/10000, mean_policy_losses: -65.161, mean_net_lifetime: 6076.3888, mean_mc_travel_dist: 7019.4277, mean_rewards: 83.5794, total_rewards: 4672.6729, mean_steps: 79.0300, mean_ecr: 0.0389 mean_entropies: 2.1470, took: 152.1921s
2022-07-31 19:16:50,528 [INFO] 	Process 2: Batch 2099/10000, mean_policy_losses: -68.077, mean_net_lifetime: 5973.2932, mean_mc_travel_dist: 6098.7309, mean_rewards: 94.2584, total_rewards: 4754.9334, mean_steps: 69.2700, mean_ecr: 0.0432 mean_entropies: 1.9535, took: 131.2430s
2022-07-31 19:19:12,127 [INFO] 	Process 2: Batch 2199/10000, mean_policy_losses: -76.452, mean_net_lifetime: 5859.6626, mean_mc_travel_dist: 6729.3265, mean_rewards: 85.5425, total_rewards: 4514.1499, mean_steps: 75.2300, mean_ecr: 0.0398 mean_entropies: 2.0298, took: 141.5996s
2022-07-31 19:21:26,262 [INFO] 	Process 2: Batch 2299/10000, mean_policy_losses: -22.863, mean_net_lifetime: 6228.4276, mean_mc_travel_dist: 6345.7131, mean_rewards: 96.2406, total_rewards: 4960.3733, mean_steps: 69.8200, mean_ecr: 0.0426 mean_entropies: 2.0531, took: 134.1340s
2022-07-31 19:23:52,285 [INFO] 	Process 2: Batch 2399/10000, mean_policy_losses: -53.360, mean_net_lifetime: 6129.0124, mean_mc_travel_dist: 6785.8137, mean_rewards: 88.1943, total_rewards: 4772.2350, mean_steps: 75.2900, mean_ecr: 0.0398 mean_entropies: 2.0450, took: 146.0227s
2022-07-31 19:26:09,184 [INFO] 	Process 2: Batch 2499/10000, mean_policy_losses: 0.442, mean_net_lifetime: 6069.7867, mean_mc_travel_dist: 6443.6785, mean_rewards: 92.3133, total_rewards: 4781.3540, mean_steps: 71.6200, mean_ecr: 0.0416 mean_entropies: 1.9991, took: 136.8992s
2022-07-31 19:28:25,966 [INFO] 	Process 2: Batch 2599/10000, mean_policy_losses: -40.177, mean_net_lifetime: 6254.2547, mean_mc_travel_dist: 6260.8229, mean_rewards: 95.4093, total_rewards: 5002.5959, mean_steps: 70.8300, mean_ecr: 0.0419 mean_entropies: 2.0187, took: 136.7820s
2022-07-31 19:30:36,624 [INFO] 	Process 2: Batch 2699/10000, mean_policy_losses: -83.315, mean_net_lifetime: 6140.6197, mean_mc_travel_dist: 6206.7811, mean_rewards: 99.9988, total_rewards: 4900.4503, mean_steps: 66.7800, mean_ecr: 0.0422 mean_entropies: 2.0113, took: 130.6577s
2022-07-31 19:33:00,308 [INFO] 	Process 2: Batch 2799/10000, mean_policy_losses: 11.789, mean_net_lifetime: 6420.2821, mean_mc_travel_dist: 6550.0179, mean_rewards: 94.5338, total_rewards: 5110.4984, mean_steps: 72.7400, mean_ecr: 0.0406 mean_entropies: 2.0395, took: 143.6854s
2022-07-31 19:35:20,595 [INFO] 	Process 2: Batch 2899/10000, mean_policy_losses: -114.323, mean_net_lifetime: 6126.9923, mean_mc_travel_dist: 6705.9995, mean_rewards: 91.6367, total_rewards: 4786.0997, mean_steps: 73.7000, mean_ecr: 0.0394 mean_entropies: 2.0300, took: 140.2857s
2022-07-31 19:37:40,146 [INFO] 	Process 2: Batch 2999/10000, mean_policy_losses: -6.588, mean_net_lifetime: 6356.2095, mean_mc_travel_dist: 6698.2915, mean_rewards: 93.1726, total_rewards: 5017.2877, mean_steps: 73.7100, mean_ecr: 0.0399 mean_entropies: 1.9595, took: 139.5523s
2022-07-31 19:39:58,135 [INFO] 	Process 2: Batch 3099/10000, mean_policy_losses: -57.538, mean_net_lifetime: 6123.7627, mean_mc_travel_dist: 6602.4818, mean_rewards: 91.1909, total_rewards: 4803.8768, mean_steps: 73.0700, mean_ecr: 0.0401 mean_entropies: 1.9766, took: 137.9886s
2022-07-31 19:42:13,071 [INFO] 	Process 2: Batch 3199/10000, mean_policy_losses: -57.434, mean_net_lifetime: 6451.0374, mean_mc_travel_dist: 6526.0573, mean_rewards: 98.5837, total_rewards: 5146.4468, mean_steps: 71.0700, mean_ecr: 0.0405 mean_entropies: 1.9558, took: 134.9367s
2022-07-31 19:44:26,812 [INFO] 	Process 2: Batch 3299/10000, mean_policy_losses: -50.501, mean_net_lifetime: 6218.9208, mean_mc_travel_dist: 6445.0613, mean_rewards: 98.1181, total_rewards: 4930.0750, mean_steps: 70.1500, mean_ecr: 0.0406 mean_entropies: 1.9054, took: 133.7403s
2022-07-31 19:46:45,843 [INFO] 	Process 2: Batch 3399/10000, mean_policy_losses: -65.054, mean_net_lifetime: 6385.3446, mean_mc_travel_dist: 6699.5865, mean_rewards: 94.1172, total_rewards: 5045.7831, mean_steps: 73.0200, mean_ecr: 0.0397 mean_entropies: 1.9734, took: 139.0301s
2022-07-31 19:49:02,508 [INFO] 	Process 2: Batch 3499/10000, mean_policy_losses: -67.726, mean_net_lifetime: 6369.5340, mean_mc_travel_dist: 6529.0289, mean_rewards: 96.2419, total_rewards: 5064.1636, mean_steps: 71.6500, mean_ecr: 0.0402 mean_entropies: 1.9265, took: 136.6643s
2022-07-31 19:51:19,245 [INFO] 	Process 2: Batch 3599/10000, mean_policy_losses: -49.980, mean_net_lifetime: 6360.2836, mean_mc_travel_dist: 6554.2797, mean_rewards: 96.9443, total_rewards: 5049.7451, mean_steps: 71.5600, mean_ecr: 0.0401 mean_entropies: 1.9382, took: 136.7383s
2022-07-31 19:53:35,070 [INFO] 	Process 2: Batch 3699/10000, mean_policy_losses: -20.537, mean_net_lifetime: 6452.6593, mean_mc_travel_dist: 6528.5811, mean_rewards: 100.1534, total_rewards: 5147.1598, mean_steps: 69.9200, mean_ecr: 0.0399 mean_entropies: 1.8698, took: 135.8241s
2022-07-31 19:55:49,064 [INFO] 	Process 2: Batch 3799/10000, mean_policy_losses: -56.305, mean_net_lifetime: 6291.6309, mean_mc_travel_dist: 6457.3949, mean_rewards: 98.0008, total_rewards: 5000.5322, mean_steps: 71.1400, mean_ecr: 0.0402 mean_entropies: 1.8670, took: 133.9952s
2022-07-31 19:58:06,244 [INFO] 	Process 2: Batch 3899/10000, mean_policy_losses: -128.488, mean_net_lifetime: 6351.9241, mean_mc_travel_dist: 6522.6158, mean_rewards: 98.7862, total_rewards: 5048.6989, mean_steps: 72.4000, mean_ecr: 0.0404 mean_entropies: 1.8284, took: 137.1803s
2022-07-31 20:00:22,363 [INFO] 	Process 2: Batch 3999/10000, mean_policy_losses: -29.102, mean_net_lifetime: 6421.4134, mean_mc_travel_dist: 6533.5467, mean_rewards: 96.5405, total_rewards: 5114.8870, mean_steps: 72.6300, mean_ecr: 0.0398 mean_entropies: 1.7975, took: 136.1166s
2022-07-31 20:02:41,311 [INFO] 	Process 2: Batch 4099/10000, mean_policy_losses: -21.037, mean_net_lifetime: 6342.3230, mean_mc_travel_dist: 6549.1669, mean_rewards: 96.8000, total_rewards: 5032.4896, mean_steps: 72.8400, mean_ecr: 0.0397 mean_entropies: 1.7618, took: 138.9497s
2022-07-31 20:05:01,571 [INFO] 	Process 2: Batch 4199/10000, mean_policy_losses: -31.633, mean_net_lifetime: 6435.0071, mean_mc_travel_dist: 6708.0961, mean_rewards: 95.6734, total_rewards: 5093.4806, mean_steps: 73.0500, mean_ecr: 0.0391 mean_entropies: 1.7774, took: 140.2608s
2022-07-31 20:07:16,634 [INFO] 	Process 2: Batch 4299/10000, mean_policy_losses: -36.470, mean_net_lifetime: 6314.0702, mean_mc_travel_dist: 6487.5140, mean_rewards: 97.5111, total_rewards: 5017.0651, mean_steps: 70.6700, mean_ecr: 0.0403 mean_entropies: 1.7881, took: 135.0626s
2022-07-31 20:09:35,113 [INFO] 	Process 2: Batch 4399/10000, mean_policy_losses: -75.453, mean_net_lifetime: 6401.2724, mean_mc_travel_dist: 6601.7489, mean_rewards: 96.5081, total_rewards: 5082.0452, mean_steps: 72.1700, mean_ecr: 0.0396 mean_entropies: 1.8030, took: 138.4790s
2022-07-31 20:11:55,188 [INFO] 	Process 2: Batch 4499/10000, mean_policy_losses: -108.697, mean_net_lifetime: 6475.0520, mean_mc_travel_dist: 6449.2271, mean_rewards: 100.5188, total_rewards: 5185.7619, mean_steps: 71.8100, mean_ecr: 0.0403 mean_entropies: 1.7881, took: 140.0747s
2022-07-31 20:14:11,170 [INFO] 	Process 2: Batch 4599/10000, mean_policy_losses: -35.963, mean_net_lifetime: 6466.0146, mean_mc_travel_dist: 6521.4592, mean_rewards: 98.6970, total_rewards: 5161.7228, mean_steps: 71.4600, mean_ecr: 0.0397 mean_entropies: 1.8013, took: 135.9830s
2022-07-31 20:16:29,590 [INFO] 	Process 2: Batch 4699/10000, mean_policy_losses: -61.063, mean_net_lifetime: 6456.1437, mean_mc_travel_dist: 6446.8799, mean_rewards: 102.3660, total_rewards: 5167.2226, mean_steps: 69.5100, mean_ecr: 0.0400 mean_entropies: 1.7522, took: 138.4193s
2022-07-31 20:18:47,772 [INFO] 	Process 2: Batch 4799/10000, mean_policy_losses: -90.456, mean_net_lifetime: 6631.6789, mean_mc_travel_dist: 6175.3902, mean_rewards: 105.5412, total_rewards: 5396.9446, mean_steps: 68.3000, mean_ecr: 0.0413 mean_entropies: 1.6717, took: 138.1821s
2022-07-31 20:21:07,144 [INFO] 	Process 2: Batch 4899/10000, mean_policy_losses: -102.426, mean_net_lifetime: 6559.4627, mean_mc_travel_dist: 6643.5745, mean_rewards: 100.0019, total_rewards: 5230.9794, mean_steps: 71.6900, mean_ecr: 0.0393 mean_entropies: 1.7270, took: 139.3708s
2022-07-31 20:23:32,073 [INFO] 	Process 2: Batch 4999/10000, mean_policy_losses: 1.564, mean_net_lifetime: 6458.3084, mean_mc_travel_dist: 6726.2686, mean_rewards: 96.0330, total_rewards: 5113.8374, mean_steps: 74.3400, mean_ecr: 0.0386 mean_entropies: 1.7495, took: 144.9301s
2022-07-31 20:25:43,425 [INFO] 	Process 2: Batch 5099/10000, mean_policy_losses: -137.319, mean_net_lifetime: 6584.0451, mean_mc_travel_dist: 6163.9211, mean_rewards: 107.4491, total_rewards: 5351.9135, mean_steps: 67.3300, mean_ecr: 0.0415 mean_entropies: 1.6382, took: 131.3515s
2022-07-31 20:27:58,235 [INFO] 	Process 2: Batch 5199/10000, mean_policy_losses: -25.240, mean_net_lifetime: 6514.9932, mean_mc_travel_dist: 6323.0120, mean_rewards: 102.8351, total_rewards: 5250.9543, mean_steps: 69.5100, mean_ecr: 0.0408 mean_entropies: 1.6584, took: 134.8109s
2022-07-31 20:30:06,026 [INFO] 	Process 2: Batch 5299/10000, mean_policy_losses: -69.760, mean_net_lifetime: 6340.6788, mean_mc_travel_dist: 6084.2340, mean_rewards: 106.1911, total_rewards: 5123.9657, mean_steps: 66.0800, mean_ecr: 0.0417 mean_entropies: 1.5596, took: 127.7892s
2022-07-31 20:32:17,735 [INFO] 	Process 2: Batch 5399/10000, mean_policy_losses: -46.433, mean_net_lifetime: 6686.7057, mean_mc_travel_dist: 6428.2432, mean_rewards: 104.6116, total_rewards: 5401.5497, mean_steps: 68.3700, mean_ecr: 0.0401 mean_entropies: 1.5991, took: 131.7108s
2022-07-31 20:34:27,821 [INFO] 	Process 2: Batch 5499/10000, mean_policy_losses: -85.403, mean_net_lifetime: 6354.2021, mean_mc_travel_dist: 6416.2688, mean_rewards: 101.9172, total_rewards: 5071.6874, mean_steps: 68.3500, mean_ecr: 0.0400 mean_entropies: 1.5466, took: 130.0860s
2022-07-31 20:36:39,211 [INFO] 	Process 2: Batch 5599/10000, mean_policy_losses: -66.287, mean_net_lifetime: 6691.3178, mean_mc_travel_dist: 6298.7197, mean_rewards: 104.4518, total_rewards: 5432.0512, mean_steps: 69.2000, mean_ecr: 0.0409 mean_entropies: 1.5937, took: 131.3899s
2022-07-31 20:38:55,202 [INFO] 	Process 2: Batch 5699/10000, mean_policy_losses: -90.076, mean_net_lifetime: 6419.9264, mean_mc_travel_dist: 6609.1217, mean_rewards: 99.7967, total_rewards: 5098.3482, mean_steps: 71.6500, mean_ecr: 0.0393 mean_entropies: 1.6435, took: 135.9849s
2022-07-31 20:41:14,202 [INFO] 	Process 2: Batch 5799/10000, mean_policy_losses: -68.524, mean_net_lifetime: 6319.9457, mean_mc_travel_dist: 6732.6736, mean_rewards: 95.9960, total_rewards: 4974.3204, mean_steps: 73.4600, mean_ecr: 0.0387 mean_entropies: 1.6222, took: 139.0063s
2022-07-31 20:43:22,893 [INFO] 	Process 2: Batch 5899/10000, mean_policy_losses: -81.611, mean_net_lifetime: 6472.3222, mean_mc_travel_dist: 6337.9433, mean_rewards: 105.2935, total_rewards: 5205.6933, mean_steps: 67.8800, mean_ecr: 0.0408 mean_entropies: 1.6163, took: 128.6896s
2022-07-31 20:45:25,132 [INFO] 	Process 2: Batch 5999/10000, mean_policy_losses: -85.009, mean_net_lifetime: 6571.8558, mean_mc_travel_dist: 5724.5797, mean_rewards: 114.3409, total_rewards: 5427.4621, mean_steps: 61.5800, mean_ecr: 0.0435 mean_entropies: 1.5193, took: 122.2388s
2022-07-31 20:47:42,875 [INFO] 	Process 2: Batch 6099/10000, mean_policy_losses: -75.184, mean_net_lifetime: 6391.9760, mean_mc_travel_dist: 6531.6998, mean_rewards: 99.3348, total_rewards: 5086.1677, mean_steps: 71.0400, mean_ecr: 0.0400 mean_entropies: 1.6024, took: 137.7441s
2022-07-31 20:49:56,157 [INFO] 	Process 2: Batch 6199/10000, mean_policy_losses: -33.217, mean_net_lifetime: 6651.3376, mean_mc_travel_dist: 6486.2511, mean_rewards: 101.7007, total_rewards: 5354.2769, mean_steps: 70.8100, mean_ecr: 0.0397 mean_entropies: 1.5915, took: 133.2805s
2022-07-31 20:51:55,303 [INFO] 	Process 2: Batch 6299/10000, mean_policy_losses: -46.088, mean_net_lifetime: 6356.0896, mean_mc_travel_dist: 5948.8088, mean_rewards: 110.2939, total_rewards: 5167.0700, mean_steps: 63.4300, mean_ecr: 0.0426 mean_entropies: 1.5268, took: 119.1459s
2022-07-31 20:54:05,702 [INFO] 	Process 2: Batch 6399/10000, mean_policy_losses: -68.137, mean_net_lifetime: 6462.0565, mean_mc_travel_dist: 6160.2631, mean_rewards: 104.4249, total_rewards: 5230.5224, mean_steps: 68.6500, mean_ecr: 0.0416 mean_entropies: 1.4988, took: 130.3999s
2022-07-31 20:56:12,084 [INFO] 	Process 2: Batch 6499/10000, mean_policy_losses: -84.658, mean_net_lifetime: 6402.9413, mean_mc_travel_dist: 6218.1631, mean_rewards: 104.2732, total_rewards: 5159.7289, mean_steps: 67.5100, mean_ecr: 0.0413 mean_entropies: 1.5015, took: 126.3827s
2022-07-31 20:58:21,111 [INFO] 	Process 2: Batch 6599/10000, mean_policy_losses: -42.734, mean_net_lifetime: 6519.2403, mean_mc_travel_dist: 6269.9813, mean_rewards: 104.8210, total_rewards: 5266.4473, mean_steps: 68.3100, mean_ecr: 0.0413 mean_entropies: 1.5120, took: 129.0270s
2022-07-31 21:00:26,320 [INFO] 	Process 2: Batch 6699/10000, mean_policy_losses: -50.935, mean_net_lifetime: 6559.7164, mean_mc_travel_dist: 6201.5052, mean_rewards: 107.1427, total_rewards: 5320.5613, mean_steps: 67.8900, mean_ecr: 0.0413 mean_entropies: 1.4532, took: 125.2088s
2022-07-31 21:02:32,585 [INFO] 	Process 2: Batch 6799/10000, mean_policy_losses: -77.579, mean_net_lifetime: 6514.1796, mean_mc_travel_dist: 6333.1653, mean_rewards: 102.7137, total_rewards: 5248.6350, mean_steps: 68.8600, mean_ecr: 0.0409 mean_entropies: 1.4646, took: 126.2634s
2022-07-31 21:04:36,815 [INFO] 	Process 2: Batch 6899/10000, mean_policy_losses: -76.843, mean_net_lifetime: 6377.4759, mean_mc_travel_dist: 6126.6204, mean_rewards: 105.2905, total_rewards: 5153.1979, mean_steps: 67.4100, mean_ecr: 0.0413 mean_entropies: 1.4340, took: 124.2320s
2022-07-31 21:06:39,178 [INFO] 	Process 2: Batch 6999/10000, mean_policy_losses: -93.723, mean_net_lifetime: 6258.2898, mean_mc_travel_dist: 6169.9804, mean_rewards: 104.8962, total_rewards: 5024.8162, mean_steps: 66.7900, mean_ecr: 0.0414 mean_entropies: 1.4482, took: 122.3632s
2022-07-31 21:08:46,662 [INFO] 	Process 2: Batch 7099/10000, mean_policy_losses: -57.890, mean_net_lifetime: 6542.3020, mean_mc_travel_dist: 6087.3696, mean_rewards: 104.7587, total_rewards: 5325.1127, mean_steps: 67.2200, mean_ecr: 0.0420 mean_entropies: 1.4186, took: 127.4835s
2022-07-31 21:11:00,396 [INFO] 	Process 2: Batch 7199/10000, mean_policy_losses: -43.373, mean_net_lifetime: 6264.6281, mean_mc_travel_dist: 6368.7803, mean_rewards: 100.8730, total_rewards: 4991.1272, mean_steps: 69.4700, mean_ecr: 0.0405 mean_entropies: 1.5068, took: 133.7346s
2022-07-31 21:13:07,898 [INFO] 	Process 2: Batch 7299/10000, mean_policy_losses: -86.185, mean_net_lifetime: 6596.3559, mean_mc_travel_dist: 6093.0493, mean_rewards: 109.5443, total_rewards: 5378.0664, mean_steps: 65.0500, mean_ecr: 0.0417 mean_entropies: 1.4178, took: 127.5020s
2022-07-31 21:15:22,356 [INFO] 	Process 2: Batch 7399/10000, mean_policy_losses: -72.873, mean_net_lifetime: 6482.0685, mean_mc_travel_dist: 6522.7757, mean_rewards: 99.8729, total_rewards: 5177.5133, mean_steps: 71.4100, mean_ecr: 0.0394 mean_entropies: 1.4468, took: 134.4576s
2022-07-31 21:17:35,685 [INFO] 	Process 2: Batch 7499/10000, mean_policy_losses: -80.097, mean_net_lifetime: 6339.5909, mean_mc_travel_dist: 6584.8869, mean_rewards: 97.3382, total_rewards: 5023.3414, mean_steps: 71.9800, mean_ecr: 0.0393 mean_entropies: 1.4373, took: 133.3293s
2022-07-31 21:19:48,845 [INFO] 	Process 2: Batch 7599/10000, mean_policy_losses: -61.659, mean_net_lifetime: 6547.3844, mean_mc_travel_dist: 6486.5975, mean_rewards: 99.4491, total_rewards: 5250.6878, mean_steps: 71.2700, mean_ecr: 0.0399 mean_entropies: 1.4127, took: 133.1577s
2022-07-31 21:21:54,011 [INFO] 	Process 2: Batch 7699/10000, mean_policy_losses: -34.426, mean_net_lifetime: 6444.7144, mean_mc_travel_dist: 6263.9065, mean_rewards: 103.7401, total_rewards: 5192.3708, mean_steps: 68.1300, mean_ecr: 0.0407 mean_entropies: 1.3519, took: 125.1687s
2022-07-31 21:24:02,673 [INFO] 	Process 2: Batch 7799/10000, mean_policy_losses: -57.770, mean_net_lifetime: 6593.3474, mean_mc_travel_dist: 6541.5412, mean_rewards: 100.9009, total_rewards: 5285.0391, mean_steps: 70.4800, mean_ecr: 0.0398 mean_entropies: 1.3702, took: 128.6615s
2022-07-31 21:26:13,080 [INFO] 	Process 2: Batch 7899/10000, mean_policy_losses: -36.802, mean_net_lifetime: 6679.1548, mean_mc_travel_dist: 6493.7355, mean_rewards: 100.2883, total_rewards: 5380.6782, mean_steps: 70.4600, mean_ecr: 0.0397 mean_entropies: 1.4004, took: 130.4053s
2022-07-31 21:28:22,458 [INFO] 	Process 2: Batch 7999/10000, mean_policy_losses: -85.909, mean_net_lifetime: 6609.1573, mean_mc_travel_dist: 6548.7421, mean_rewards: 102.5787, total_rewards: 5299.8634, mean_steps: 70.4900, mean_ecr: 0.0393 mean_entropies: 1.4124, took: 129.3795s
2022-07-31 21:30:28,883 [INFO] 	Process 2: Batch 8099/10000, mean_policy_losses: -63.991, mean_net_lifetime: 6534.6389, mean_mc_travel_dist: 6565.4534, mean_rewards: 102.7810, total_rewards: 5222.2859, mean_steps: 69.3000, mean_ecr: 0.0396 mean_entropies: 1.4537, took: 126.4254s
2022-07-31 21:32:38,487 [INFO] 	Process 2: Batch 8199/10000, mean_policy_losses: -88.396, mean_net_lifetime: 6624.7661, mean_mc_travel_dist: 6351.8585, mean_rewards: 105.4517, total_rewards: 5354.9656, mean_steps: 70.2900, mean_ecr: 0.0403 mean_entropies: 1.3953, took: 129.6033s
2022-07-31 21:34:56,024 [INFO] 	Process 2: Batch 8299/10000, mean_policy_losses: -48.670, mean_net_lifetime: 6408.6857, mean_mc_travel_dist: 6531.0485, mean_rewards: 100.1578, total_rewards: 5103.3666, mean_steps: 70.3000, mean_ecr: 0.0397 mean_entropies: 1.4092, took: 137.5375s
2022-07-31 21:37:03,994 [INFO] 	Process 2: Batch 8399/10000, mean_policy_losses: -82.809, mean_net_lifetime: 6293.8139, mean_mc_travel_dist: 6233.4398, mean_rewards: 103.2086, total_rewards: 5048.3398, mean_steps: 67.6900, mean_ecr: 0.0412 mean_entropies: 1.3322, took: 127.9691s
2022-07-31 21:39:19,679 [INFO] 	Process 2: Batch 8499/10000, mean_policy_losses: -22.179, mean_net_lifetime: 6607.7960, mean_mc_travel_dist: 6383.1970, mean_rewards: 103.1130, total_rewards: 5332.1367, mean_steps: 69.4300, mean_ecr: 0.0401 mean_entropies: 1.3225, took: 135.6857s
2022-07-31 21:41:21,028 [INFO] 	Process 2: Batch 8599/10000, mean_policy_losses: -43.845, mean_net_lifetime: 6515.4119, mean_mc_travel_dist: 5956.9044, mean_rewards: 111.2867, total_rewards: 5324.2550, mean_steps: 63.4800, mean_ecr: 0.0424 mean_entropies: 1.2889, took: 121.3494s
2022-07-31 21:43:35,066 [INFO] 	Process 2: Batch 8699/10000, mean_policy_losses: -135.682, mean_net_lifetime: 6492.9371, mean_mc_travel_dist: 6708.9608, mean_rewards: 98.4999, total_rewards: 5151.2323, mean_steps: 72.5900, mean_ecr: 0.0387 mean_entropies: 1.4032, took: 134.0369s
2022-07-31 21:45:40,580 [INFO] 	Process 2: Batch 8799/10000, mean_policy_losses: -35.019, mean_net_lifetime: 6446.0371, mean_mc_travel_dist: 6292.9187, mean_rewards: 103.2390, total_rewards: 5187.8474, mean_steps: 67.4800, mean_ecr: 0.0411 mean_entropies: 1.3698, took: 125.5142s
2022-07-31 21:47:40,861 [INFO] 	Process 2: Batch 8899/10000, mean_policy_losses: -62.266, mean_net_lifetime: 6556.3267, mean_mc_travel_dist: 6152.5372, mean_rewards: 108.2867, total_rewards: 5326.5418, mean_steps: 65.0400, mean_ecr: 0.0411 mean_entropies: 1.2509, took: 120.2818s
2022-07-31 21:49:50,571 [INFO] 	Process 2: Batch 8999/10000, mean_policy_losses: -64.080, mean_net_lifetime: 6418.2684, mean_mc_travel_dist: 6651.3110, mean_rewards: 99.4699, total_rewards: 5088.7318, mean_steps: 71.6000, mean_ecr: 0.0389 mean_entropies: 1.2635, took: 129.7095s
2022-07-31 21:51:54,426 [INFO] 	Process 2: Batch 9099/10000, mean_policy_losses: -54.061, mean_net_lifetime: 6635.5052, mean_mc_travel_dist: 6364.0807, mean_rewards: 105.5420, total_rewards: 5363.0074, mean_steps: 68.1700, mean_ecr: 0.0399 mean_entropies: 1.2012, took: 123.8551s
2022-07-31 21:54:10,603 [INFO] 	Process 2: Batch 9199/10000, mean_policy_losses: -16.377, mean_net_lifetime: 6469.2329, mean_mc_travel_dist: 6466.5051, mean_rewards: 101.2499, total_rewards: 5176.3282, mean_steps: 70.1800, mean_ecr: 0.0398 mean_entropies: 1.2425, took: 136.1775s
2022-07-31 21:56:19,827 [INFO] 	Process 2: Batch 9299/10000, mean_policy_losses: -68.649, mean_net_lifetime: 6584.9326, mean_mc_travel_dist: 6181.2546, mean_rewards: 107.7469, total_rewards: 5349.1320, mean_steps: 66.9500, mean_ecr: 0.0411 mean_entropies: 1.2182, took: 129.2241s
2022-07-31 21:58:18,327 [INFO] 	Process 2: Batch 9399/10000, mean_policy_losses: -50.541, mean_net_lifetime: 6665.2724, mean_mc_travel_dist: 5986.0743, mean_rewards: 113.4966, total_rewards: 5468.5276, mean_steps: 62.7300, mean_ecr: 0.0423 mean_entropies: 1.2095, took: 118.4986s
2022-07-31 22:00:22,317 [INFO] 	Process 2: Batch 9499/10000, mean_policy_losses: -46.686, mean_net_lifetime: 6238.8382, mean_mc_travel_dist: 6515.4512, mean_rewards: 102.2817, total_rewards: 4936.7648, mean_steps: 67.1600, mean_ecr: 0.0399 mean_entropies: 1.2797, took: 123.9897s
2022-07-31 22:02:26,883 [INFO] 	Process 2: Batch 9599/10000, mean_policy_losses: -63.196, mean_net_lifetime: 6406.8798, mean_mc_travel_dist: 6577.7543, mean_rewards: 103.2298, total_rewards: 5091.6937, mean_steps: 68.1800, mean_ecr: 0.0395 mean_entropies: 1.3235, took: 124.5673s
2022-07-31 22:04:24,192 [INFO] 	Process 2: Batch 9699/10000, mean_policy_losses: -59.967, mean_net_lifetime: 6365.3470, mean_mc_travel_dist: 6261.6421, mean_rewards: 108.5135, total_rewards: 5113.1489, mean_steps: 63.9300, mean_ecr: 0.0410 mean_entropies: 1.2550, took: 117.3079s
2022-07-31 22:06:24,780 [INFO] 	Process 2: Batch 9799/10000, mean_policy_losses: -51.911, mean_net_lifetime: 6485.7677, mean_mc_travel_dist: 6169.1754, mean_rewards: 111.3542, total_rewards: 5252.7671, mean_steps: 63.1300, mean_ecr: 0.0414 mean_entropies: 1.2338, took: 120.5892s
2022-07-31 22:08:32,020 [INFO] 	Process 2: Batch 9899/10000, mean_policy_losses: -75.148, mean_net_lifetime: 6214.5642, mean_mc_travel_dist: 6510.9427, mean_rewards: 102.7609, total_rewards: 4912.8801, mean_steps: 66.7800, mean_ecr: 0.0397 mean_entropies: 1.2706, took: 127.2383s
2022-07-31 22:10:34,094 [INFO] 	Process 2: Batch 9999/10000, mean_policy_losses: -46.883, mean_net_lifetime: 6416.3421, mean_mc_travel_dist: 6412.8036, mean_rewards: 105.9022, total_rewards: 5134.1093, mean_steps: 65.4300, mean_ecr: 0.0403 mean_entropies: 1.2255, took: 122.0748s
2022-07-31 22:21:25,423 [INFO] Process 2: Epoch 1: mean_policy_losses: -53.795, mean_net_lifetime: 6210.5358, mean_mc_travel_dist: 6495.1063, mean_entropies: 1.7720, m_net_lifetime_valid: 6474.6687, took: 14042.4628s, (132.5855 / 100 batches)

2022-07-31 22:21:25,424 [INFO] Process 2: Start epoch 2
2022-07-31 22:22:33,191 [INFO] 	Process 2: Batch 99/10000, mean_policy_losses: 17.492, mean_net_lifetime: 3416.3844, mean_mc_travel_dist: 5944.5850, mean_rewards: 94.3814, total_rewards: 2243.1473, mean_steps: 38.3300, mean_ecr: 0.0404 mean_entropies: 1.5849, took: 67.7614s
2022-07-31 22:24:06,996 [INFO] 	Process 2: Batch 199/10000, mean_policy_losses: -56.662, mean_net_lifetime: 4696.5504, mean_mc_travel_dist: 7843.9110, mean_rewards: 98.6001, total_rewards: 3143.7762, mean_steps: 53.1100, mean_ecr: 0.0403 mean_entropies: 1.4299, took: 93.8065s
2022-07-31 22:26:11,685 [INFO] 	Process 2: Batch 299/10000, mean_policy_losses: -38.959, mean_net_lifetime: 6081.7369, mean_mc_travel_dist: 10314.7915, mean_rewards: 101.4853, total_rewards: 4032.2837, mean_steps: 70.8200, mean_ecr: 0.0384 mean_entropies: 1.3989, took: 124.6894s
2022-07-31 22:27:27,440 [INFO] 	Process 2: Batch 399/10000, mean_policy_losses: -66.767, mean_net_lifetime: 4041.8978, mean_mc_travel_dist: 6301.5185, mean_rewards: 103.8404, total_rewards: 2791.9347, mean_steps: 41.6200, mean_ecr: 0.0401 mean_entropies: 1.3616, took: 75.7554s
2022-07-31 22:28:32,959 [INFO] 	Process 2: Batch 499/10000, mean_policy_losses: -68.279, mean_net_lifetime: 3635.4419, mean_mc_travel_dist: 5490.5732, mean_rewards: 104.6168, total_rewards: 2553.9847, mean_steps: 36.6400, mean_ecr: 0.0409 mean_entropies: 1.3236, took: 65.5190s
2022-07-31 22:30:01,053 [INFO] 	Process 2: Batch 599/10000, mean_policy_losses: -67.910, mean_net_lifetime: 4734.8123, mean_mc_travel_dist: 7251.8805, mean_rewards: 102.5363, total_rewards: 3298.1617, mean_steps: 51.0500, mean_ecr: 0.0397 mean_entropies: 1.3093, took: 88.0890s
2022-07-31 22:32:22,374 [INFO] 	Process 2: Batch 699/10000, mean_policy_losses: -55.777, mean_net_lifetime: 7386.6240, mean_mc_travel_dist: 11088.1975, mean_rewards: 108.6905, total_rewards: 5179.6251, mean_steps: 82.1500, mean_ecr: 0.0397 mean_entropies: 1.2896, took: 141.3255s
2022-07-31 22:34:19,436 [INFO] 	Process 2: Batch 799/10000, mean_policy_losses: -66.784, mean_net_lifetime: 6388.0367, mean_mc_travel_dist: 9133.4060, mean_rewards: 114.5658, total_rewards: 4571.6775, mean_steps: 61.1400, mean_ecr: 0.0400 mean_entropies: 1.2454, took: 117.0604s
2022-07-31 22:36:42,086 [INFO] 	Process 2: Batch 899/10000, mean_policy_losses: -56.952, mean_net_lifetime: 7553.7659, mean_mc_travel_dist: 11089.5805, mean_rewards: 120.2256, total_rewards: 5346.5364, mean_steps: 72.6300, mean_ecr: 0.0401 mean_entropies: 1.1851, took: 142.6519s
2022-07-31 22:39:21,430 [INFO] 	Process 2: Batch 999/10000, mean_policy_losses: -50.420, mean_net_lifetime: 8765.3032, mean_mc_travel_dist: 12918.8203, mean_rewards: 123.3584, total_rewards: 6191.9448, mean_steps: 90.2700, mean_ecr: 0.0398 mean_entropies: 1.1019, took: 159.3444s
2022-07-31 22:42:23,726 [INFO] 	Process 2: Batch 1099/10000, mean_policy_losses: -63.254, mean_net_lifetime: 10464.2989, mean_mc_travel_dist: 15616.9918, mean_rewards: 124.9659, total_rewards: 7350.4299, mean_steps: 104.4100, mean_ecr: 0.0391 mean_entropies: 1.0507, took: 182.2951s
2022-07-31 22:45:48,469 [INFO] 	Process 2: Batch 1199/10000, mean_policy_losses: -70.209, mean_net_lifetime: 11240.6182, mean_mc_travel_dist: 17263.2622, mean_rewards: 130.2957, total_rewards: 7795.0651, mean_steps: 117.8300, mean_ecr: 0.0405 mean_entropies: 0.9529, took: 204.7429s
2022-07-31 22:50:10,787 [INFO] 	Process 2: Batch 1299/10000, mean_policy_losses: -49.969, mean_net_lifetime: 13308.4553, mean_mc_travel_dist: 20242.4220, mean_rewards: 132.6065, total_rewards: 9269.1721, mean_steps: 139.5300, mean_ecr: 0.0389 mean_entropies: 0.9458, took: 262.3183s
2022-07-31 22:55:32,351 [INFO] 	Process 2: Batch 1399/10000, mean_policy_losses: -72.039, mean_net_lifetime: 17706.9681, mean_mc_travel_dist: 24626.6484, mean_rewards: 132.2333, total_rewards: 12788.4934, mean_steps: 170.4500, mean_ecr: 0.0389 mean_entropies: 0.9070, took: 321.5641s
2022-07-31 23:00:33,350 [INFO] 	Process 2: Batch 1499/10000, mean_policy_losses: -53.706, mean_net_lifetime: 17681.5572, mean_mc_travel_dist: 22706.8898, mean_rewards: 139.3890, total_rewards: 13150.1599, mean_steps: 159.1700, mean_ecr: 0.0389 mean_entropies: 0.8347, took: 300.9991s
2022-07-31 23:04:22,025 [INFO] 	Process 2: Batch 1599/10000, mean_policy_losses: -55.239, mean_net_lifetime: 13219.9669, mean_mc_travel_dist: 18363.8996, mean_rewards: 138.6914, total_rewards: 9553.5511, mean_steps: 124.8500, mean_ecr: 0.0399 mean_entropies: 0.8005, took: 228.6748s
2022-07-31 23:08:39,397 [INFO] 	Process 2: Batch 1699/10000, mean_policy_losses: -61.475, mean_net_lifetime: 15313.1826, mean_mc_travel_dist: 20469.4871, mean_rewards: 142.0766, total_rewards: 11227.5799, mean_steps: 139.6000, mean_ecr: 0.0403 mean_entropies: 0.7759, took: 257.3721s
2022-07-31 23:13:39,578 [INFO] 	Process 2: Batch 1799/10000, mean_policy_losses: -48.812, mean_net_lifetime: 17771.2820, mean_mc_travel_dist: 22468.2769, mean_rewards: 138.5114, total_rewards: 13284.9084, mean_steps: 158.8800, mean_ecr: 0.0407 mean_entropies: 0.7210, took: 300.1814s
2022-07-31 23:18:24,456 [INFO] 	Process 2: Batch 1899/10000, mean_policy_losses: -44.453, mean_net_lifetime: 16826.1285, mean_mc_travel_dist: 23050.4773, mean_rewards: 139.1513, total_rewards: 12221.9740, mean_steps: 152.0100, mean_ecr: 0.0394 mean_entropies: 0.7169, took: 284.8775s
2022-07-31 23:24:59,662 [INFO] 	Process 2: Batch 1999/10000, mean_policy_losses: -50.615, mean_net_lifetime: 23537.3395, mean_mc_travel_dist: 31145.9778, mean_rewards: 138.1353, total_rewards: 17316.3408, mean_steps: 211.0300, mean_ecr: 0.0381 mean_entropies: 0.6965, took: 395.2057s
2022-07-31 23:31:52,769 [INFO] 	Process 2: Batch 2099/10000, mean_policy_losses: -53.810, mean_net_lifetime: 23149.6744, mean_mc_travel_dist: 32916.8828, mean_rewards: 135.8893, total_rewards: 16572.2672, mean_steps: 222.3100, mean_ecr: 0.0394 mean_entropies: 0.6256, took: 413.1076s
2022-07-31 23:37:42,118 [INFO] 	Process 2: Batch 2199/10000, mean_policy_losses: -43.315, mean_net_lifetime: 20512.4089, mean_mc_travel_dist: 26495.6899, mean_rewards: 144.0609, total_rewards: 15222.5427, mean_steps: 176.5100, mean_ecr: 0.0400 mean_entropies: 0.6162, took: 349.3485s
2022-07-31 23:43:54,335 [INFO] 	Process 2: Batch 2299/10000, mean_policy_losses: -38.560, mean_net_lifetime: 20414.8567, mean_mc_travel_dist: 30585.1732, mean_rewards: 142.7728, total_rewards: 14305.3187, mean_steps: 199.0900, mean_ecr: 0.0389 mean_entropies: 0.6178, took: 372.2103s
2022-07-31 23:48:42,330 [INFO] 	Process 2: Batch 2399/10000, mean_policy_losses: -48.334, mean_net_lifetime: 18092.1102, mean_mc_travel_dist: 22012.6181, mean_rewards: 146.7409, total_rewards: 13696.5947, mean_steps: 152.4500, mean_ecr: 0.0405 mean_entropies: 0.5598, took: 288.0016s
2022-07-31 23:53:46,530 [INFO] 	Process 2: Batch 2499/10000, mean_policy_losses: -39.271, mean_net_lifetime: 18158.8510, mean_mc_travel_dist: 22681.0012, mean_rewards: 145.2453, total_rewards: 13628.6665, mean_steps: 156.6100, mean_ecr: 0.0410 mean_entropies: 0.5697, took: 304.1993s
2022-07-31 23:59:00,232 [INFO] 	Process 2: Batch 2599/10000, mean_policy_losses: -46.337, mean_net_lifetime: 17957.1272, mean_mc_travel_dist: 23900.2372, mean_rewards: 145.4622, total_rewards: 13183.3183, mean_steps: 158.8800, mean_ecr: 0.0417 mean_entropies: 0.5646, took: 313.7035s
2022-08-01 00:03:54,423 [INFO] 	Process 2: Batch 2699/10000, mean_policy_losses: -50.891, mean_net_lifetime: 17484.7071, mean_mc_travel_dist: 23516.4665, mean_rewards: 145.9379, total_rewards: 12787.3154, mean_steps: 158.1200, mean_ecr: 0.0402 mean_entropies: 0.5464, took: 294.1875s
2022-08-01 00:09:39,864 [INFO] 	Process 2: Batch 2799/10000, mean_policy_losses: -39.996, mean_net_lifetime: 20406.6809, mean_mc_travel_dist: 26490.5224, mean_rewards: 143.6571, total_rewards: 15113.8039, mean_steps: 180.6700, mean_ecr: 0.0403 mean_entropies: 0.5551, took: 345.4441s
2022-08-01 00:15:35,702 [INFO] 	Process 2: Batch 2899/10000, mean_policy_losses: -26.246, mean_net_lifetime: 21799.5680, mean_mc_travel_dist: 26166.4018, mean_rewards: 143.8585, total_rewards: 16575.6233, mean_steps: 183.6900, mean_ecr: 0.0392 mean_entropies: 0.5325, took: 355.8383s
2022-08-01 00:22:20,549 [INFO] 	Process 2: Batch 2999/10000, mean_policy_losses: -41.720, mean_net_lifetime: 21506.8785, mean_mc_travel_dist: 30815.7670, mean_rewards: 140.0604, total_rewards: 15349.8240, mean_steps: 211.1600, mean_ecr: 0.0389 mean_entropies: 0.5232, took: 404.8447s
2022-08-01 00:27:36,627 [INFO] 	Process 2: Batch 3099/10000, mean_policy_losses: -35.605, mean_net_lifetime: 19460.3483, mean_mc_travel_dist: 24594.5686, mean_rewards: 147.2922, total_rewards: 14550.1648, mean_steps: 167.0200, mean_ecr: 0.0412 mean_entropies: 0.4832, took: 316.0795s
2022-08-01 00:33:18,326 [INFO] 	Process 2: Batch 3199/10000, mean_policy_losses: -41.065, mean_net_lifetime: 20615.9889, mean_mc_travel_dist: 26158.2184, mean_rewards: 147.4216, total_rewards: 15390.0994, mean_steps: 179.1700, mean_ecr: 0.0409 mean_entropies: 0.4990, took: 341.6993s
2022-08-01 00:39:14,840 [INFO] 	Process 2: Batch 3299/10000, mean_policy_losses: -26.616, mean_net_lifetime: 20834.1897, mean_mc_travel_dist: 25407.7451, mean_rewards: 142.0462, total_rewards: 15761.0136, mean_steps: 182.7000, mean_ecr: 0.0404 mean_entropies: 0.4981, took: 356.5136s
2022-08-01 00:42:35,784 [INFO] 	Process 2: Batch 3399/10000, mean_policy_losses: -29.441, mean_net_lifetime: 12646.4732, mean_mc_travel_dist: 15549.6589, mean_rewards: 145.4415, total_rewards: 9542.9643, mean_steps: 106.6900, mean_ecr: 0.0408 mean_entropies: 0.5047, took: 200.9438s
2022-08-01 00:49:27,624 [INFO] 	Process 2: Batch 3499/10000, mean_policy_losses: -37.412, mean_net_lifetime: 23878.1637, mean_mc_travel_dist: 31440.7869, mean_rewards: 143.6115, total_rewards: 17597.4164, mean_steps: 216.5200, mean_ecr: 0.0392 mean_entropies: 0.5205, took: 411.8405s
2022-08-01 00:55:56,313 [INFO] 	Process 2: Batch 3599/10000, mean_policy_losses: -36.750, mean_net_lifetime: 22528.3742, mean_mc_travel_dist: 30341.5174, mean_rewards: 143.4352, total_rewards: 16468.9981, mean_steps: 203.1900, mean_ecr: 0.0385 mean_entropies: 0.4899, took: 388.6899s
2022-08-01 01:01:42,006 [INFO] 	Process 2: Batch 3699/10000, mean_policy_losses: -37.717, mean_net_lifetime: 21312.1510, mean_mc_travel_dist: 27562.4034, mean_rewards: 144.6634, total_rewards: 15807.5502, mean_steps: 185.0200, mean_ecr: 0.0406 mean_entropies: 0.4697, took: 345.6925s
2022-08-01 01:06:21,300 [INFO] 	Process 2: Batch 3799/10000, mean_policy_losses: -48.532, mean_net_lifetime: 17267.3301, mean_mc_travel_dist: 22285.8414, mean_rewards: 147.0693, total_rewards: 12817.6843, mean_steps: 144.6500, mean_ecr: 0.0414 mean_entropies: 0.4627, took: 279.2885s
2022-08-01 01:12:25,599 [INFO] 	Process 2: Batch 3899/10000, mean_policy_losses: -55.676, mean_net_lifetime: 21586.6244, mean_mc_travel_dist: 28447.2812, mean_rewards: 142.9600, total_rewards: 15903.8161, mean_steps: 192.6900, mean_ecr: 0.0400 mean_entropies: 0.4744, took: 364.3039s
2022-08-01 01:18:59,424 [INFO] 	Process 2: Batch 3999/10000, mean_policy_losses: -38.968, mean_net_lifetime: 23356.4969, mean_mc_travel_dist: 31247.8458, mean_rewards: 146.8872, total_rewards: 17114.3586, mean_steps: 206.9400, mean_ecr: 0.0409 mean_entropies: 0.4205, took: 393.8250s
2022-08-01 01:24:46,015 [INFO] 	Process 2: Batch 4099/10000, mean_policy_losses: -42.356, mean_net_lifetime: 20772.3369, mean_mc_travel_dist: 28995.8954, mean_rewards: 146.5761, total_rewards: 14982.1153, mean_steps: 187.9700, mean_ecr: 0.0400 mean_entropies: 0.4601, took: 346.5913s
2022-08-01 01:32:07,226 [INFO] 	Process 2: Batch 4199/10000, mean_policy_losses: -45.939, mean_net_lifetime: 24698.8771, mean_mc_travel_dist: 35005.3298, mean_rewards: 143.3666, total_rewards: 17704.4758, mean_steps: 236.1300, mean_ecr: 0.0395 mean_entropies: 0.4486, took: 441.2010s
2022-08-01 01:39:07,050 [INFO] 	Process 2: Batch 4299/10000, mean_policy_losses: -37.299, mean_net_lifetime: 23436.4258, mean_mc_travel_dist: 32956.6833, mean_rewards: 147.3955, total_rewards: 16855.9285, mean_steps: 221.3300, mean_ecr: 0.0408 mean_entropies: 0.4279, took: 419.8339s
2022-08-01 01:45:56,857 [INFO] 	Process 2: Batch 4399/10000, mean_policy_losses: -33.396, mean_net_lifetime: 25533.3433, mean_mc_travel_dist: 32756.4135, mean_rewards: 145.6839, total_rewards: 18988.3689, mean_steps: 210.8700, mean_ecr: 0.0390 mean_entropies: 0.4470, took: 409.8075s
2022-08-01 01:50:56,204 [INFO] 	Process 2: Batch 4499/10000, mean_policy_losses: -34.906, mean_net_lifetime: 18468.7605, mean_mc_travel_dist: 22637.7527, mean_rewards: 149.8078, total_rewards: 13948.8235, mean_steps: 158.1800, mean_ecr: 0.0410 mean_entropies: 0.4188, took: 299.3467s
2022-08-01 01:57:50,275 [INFO] 	Process 2: Batch 4599/10000, mean_policy_losses: -37.495, mean_net_lifetime: 23840.1643, mean_mc_travel_dist: 31500.7852, mean_rewards: 140.5410, total_rewards: 17546.5371, mean_steps: 220.5100, mean_ecr: 0.0390 mean_entropies: 0.4384, took: 414.0711s
2022-08-01 02:04:02,175 [INFO] 	Process 2: Batch 4699/10000, mean_policy_losses: -42.910, mean_net_lifetime: 24194.9268, mean_mc_travel_dist: 31373.2798, mean_rewards: 149.4865, total_rewards: 17929.6575, mean_steps: 202.8600, mean_ecr: 0.0400 mean_entropies: 0.4143, took: 371.8998s
2022-08-01 02:10:20,218 [INFO] 	Process 2: Batch 4799/10000, mean_policy_losses: -40.473, mean_net_lifetime: 22498.0354, mean_mc_travel_dist: 29181.9820, mean_rewards: 148.4296, total_rewards: 16670.7302, mean_steps: 197.3800, mean_ecr: 0.0407 mean_entropies: 0.4184, took: 378.0434s
2022-08-01 02:15:47,045 [INFO] 	Process 2: Batch 4899/10000, mean_policy_losses: -30.977, mean_net_lifetime: 21961.6475, mean_mc_travel_dist: 27319.0165, mean_rewards: 147.9612, total_rewards: 16506.7816, mean_steps: 178.7600, mean_ecr: 0.0397 mean_entropies: 0.4056, took: 326.8255s
2022-08-01 02:24:17,828 [INFO] 	Process 2: Batch 4999/10000, mean_policy_losses: -40.258, mean_net_lifetime: 30324.7404, mean_mc_travel_dist: 40843.1629, mean_rewards: 143.0855, total_rewards: 22163.0481, mean_steps: 273.7900, mean_ecr: 0.0387 mean_entropies: 0.3992, took: 510.7789s
2022-08-01 02:31:15,440 [INFO] 	Process 2: Batch 5099/10000, mean_policy_losses: -35.165, mean_net_lifetime: 25716.4683, mean_mc_travel_dist: 32364.5600, mean_rewards: 144.0968, total_rewards: 19251.1840, mean_steps: 219.9200, mean_ecr: 0.0393 mean_entropies: 0.3953, took: 417.6110s
2022-08-01 02:36:38,118 [INFO] 	Process 2: Batch 5199/10000, mean_policy_losses: -40.866, mean_net_lifetime: 19240.8676, mean_mc_travel_dist: 26310.7982, mean_rewards: 144.7897, total_rewards: 13984.7517, mean_steps: 179.3000, mean_ecr: 0.0395 mean_entropies: 0.3945, took: 322.6846s
2022-08-01 02:42:45,879 [INFO] 	Process 2: Batch 5299/10000, mean_policy_losses: -26.153, mean_net_lifetime: 24496.0004, mean_mc_travel_dist: 30626.7530, mean_rewards: 147.1605, total_rewards: 18377.7161, mean_steps: 206.7100, mean_ecr: 0.0402 mean_entropies: 0.3769, took: 367.7599s
2022-08-01 02:48:56,470 [INFO] 	Process 2: Batch 5399/10000, mean_policy_losses: -31.425, mean_net_lifetime: 21200.7427, mean_mc_travel_dist: 28538.8833, mean_rewards: 145.2470, total_rewards: 15501.0907, mean_steps: 185.2500, mean_ecr: 0.0402 mean_entropies: 0.3886, took: 370.5924s
2022-08-01 02:54:01,708 [INFO] 	Process 2: Batch 5499/10000, mean_policy_losses: -35.588, mean_net_lifetime: 20186.2205, mean_mc_travel_dist: 25008.6736, mean_rewards: 149.4065, total_rewards: 15193.3993, mean_steps: 168.0900, mean_ecr: 0.0402 mean_entropies: 0.3662, took: 305.2374s
2022-08-01 03:02:04,069 [INFO] 	Process 2: Batch 5599/10000, mean_policy_losses: -30.403, mean_net_lifetime: 31225.7092, mean_mc_travel_dist: 39880.4964, mean_rewards: 148.2216, total_rewards: 23255.3501, mean_steps: 259.4500, mean_ecr: 0.0387 mean_entropies: 0.3654, took: 482.3609s
2022-08-01 03:07:43,970 [INFO] 	Process 2: Batch 5699/10000, mean_policy_losses: -33.012, mean_net_lifetime: 19859.4319, mean_mc_travel_dist: 24628.8406, mean_rewards: 152.4108, total_rewards: 14939.4286, mean_steps: 171.7900, mean_ecr: 0.0413 mean_entropies: 0.3645, took: 339.9004s
2022-08-01 03:14:10,682 [INFO] 	Process 2: Batch 5799/10000, mean_policy_losses: -31.627, mean_net_lifetime: 23906.6252, mean_mc_travel_dist: 31344.0148, mean_rewards: 146.1145, total_rewards: 17645.8349, mean_steps: 213.5500, mean_ecr: 0.0399 mean_entropies: 0.3689, took: 386.7134s
2022-08-01 03:21:53,661 [INFO] 	Process 2: Batch 5899/10000, mean_policy_losses: -34.629, mean_net_lifetime: 29076.7050, mean_mc_travel_dist: 37149.9270, mean_rewards: 142.2902, total_rewards: 21652.3211, mean_steps: 253.4500, mean_ecr: 0.0395 mean_entropies: 0.3620, took: 462.9789s
2022-08-01 03:29:15,231 [INFO] 	Process 2: Batch 5999/10000, mean_policy_losses: -34.144, mean_net_lifetime: 26879.8958, mean_mc_travel_dist: 35449.5729, mean_rewards: 145.1368, total_rewards: 19798.3947, mean_steps: 231.3600, mean_ecr: 0.0394 mean_entropies: 0.3627, took: 441.5698s
2022-08-01 03:33:47,801 [INFO] 	Process 2: Batch 6099/10000, mean_policy_losses: -33.143, mean_net_lifetime: 16346.9397, mean_mc_travel_dist: 21529.9394, mean_rewards: 147.8203, total_rewards: 12049.3566, mean_steps: 146.8500, mean_ecr: 0.0406 mean_entropies: 0.3741, took: 272.5626s
2022-08-01 03:40:33,107 [INFO] 	Process 2: Batch 6199/10000, mean_policy_losses: -26.555, mean_net_lifetime: 25434.1026, mean_mc_travel_dist: 33382.3614, mean_rewards: 145.4306, total_rewards: 18767.0915, mean_steps: 221.4800, mean_ecr: 0.0402 mean_entropies: 0.3447, took: 405.3106s
2022-08-01 03:47:30,053 [INFO] 	Process 2: Batch 6299/10000, mean_policy_losses: -26.589, mean_net_lifetime: 23610.1973, mean_mc_travel_dist: 31585.4711, mean_rewards: 144.0804, total_rewards: 17300.9597, mean_steps: 218.3000, mean_ecr: 0.0401 mean_entropies: 0.3747, took: 416.9484s
2022-08-01 03:51:19,792 [INFO] 	Process 2: Batch 6399/10000, mean_policy_losses: -37.221, mean_net_lifetime: 14562.0007, mean_mc_travel_dist: 18364.3053, mean_rewards: 148.4059, total_rewards: 10899.2219, mean_steps: 124.4900, mean_ecr: 0.0404 mean_entropies: 0.3734, took: 229.7391s
2022-08-01 03:57:26,158 [INFO] 	Process 2: Batch 6499/10000, mean_policy_losses: -37.241, mean_net_lifetime: 22259.5468, mean_mc_travel_dist: 29354.3025, mean_rewards: 143.4667, total_rewards: 16397.5514, mean_steps: 203.8100, mean_ecr: 0.0390 mean_entropies: 0.3544, took: 366.3665s
2022-08-01 04:04:23,898 [INFO] 	Process 2: Batch 6599/10000, mean_policy_losses: -29.412, mean_net_lifetime: 25770.7279, mean_mc_travel_dist: 32533.9502, mean_rewards: 145.4508, total_rewards: 19272.0929, mean_steps: 221.6900, mean_ecr: 0.0385 mean_entropies: 0.3515, took: 417.7393s
2022-08-01 04:10:22,714 [INFO] 	Process 2: Batch 6699/10000, mean_policy_losses: -23.205, mean_net_lifetime: 21705.0362, mean_mc_travel_dist: 27064.7073, mean_rewards: 146.3601, total_rewards: 16302.2498, mean_steps: 189.5500, mean_ecr: 0.0402 mean_entropies: 0.3323, took: 358.8149s
2022-08-01 04:17:34,984 [INFO] 	Process 2: Batch 6799/10000, mean_policy_losses: -23.526, mean_net_lifetime: 27575.1431, mean_mc_travel_dist: 36187.0268, mean_rewards: 144.3074, total_rewards: 20344.2351, mean_steps: 240.1000, mean_ecr: 0.0385 mean_entropies: 0.3377, took: 432.2677s
2022-08-01 04:22:52,352 [INFO] 	Process 2: Batch 6899/10000, mean_policy_losses: -32.533, mean_net_lifetime: 20793.8601, mean_mc_travel_dist: 26055.9994, mean_rewards: 151.4620, total_rewards: 15589.4946, mean_steps: 171.7800, mean_ecr: 0.0410 mean_entropies: 0.3055, took: 317.3718s
2022-08-01 04:28:05,332 [INFO] 	Process 2: Batch 6999/10000, mean_policy_losses: -29.237, mean_net_lifetime: 19864.9504, mean_mc_travel_dist: 26260.5914, mean_rewards: 149.7446, total_rewards: 14621.0455, mean_steps: 170.6400, mean_ecr: 0.0410 mean_entropies: 0.3308, took: 312.9803s
2022-08-01 04:34:40,991 [INFO] 	Process 2: Batch 7099/10000, mean_policy_losses: -25.825, mean_net_lifetime: 24749.2677, mean_mc_travel_dist: 30920.7075, mean_rewards: 148.6196, total_rewards: 18572.7532, mean_steps: 208.4600, mean_ecr: 0.0402 mean_entropies: 0.3306, took: 395.6499s
2022-08-01 04:39:39,065 [INFO] 	Process 2: Batch 7199/10000, mean_policy_losses: -31.366, mean_net_lifetime: 19425.2463, mean_mc_travel_dist: 24980.8515, mean_rewards: 149.5861, total_rewards: 14436.7249, mean_steps: 164.2500, mean_ecr: 0.0401 mean_entropies: 0.3381, took: 298.0762s
2022-08-01 04:47:21,242 [INFO] 	Process 2: Batch 7299/10000, mean_policy_losses: -19.125, mean_net_lifetime: 29879.1795, mean_mc_travel_dist: 38261.3829, mean_rewards: 143.7155, total_rewards: 22233.0654, mean_steps: 253.6600, mean_ecr: 0.0388 mean_entropies: 0.3405, took: 462.1835s
2022-08-01 04:53:17,334 [INFO] 	Process 2: Batch 7399/10000, mean_policy_losses: -20.001, mean_net_lifetime: 21951.0578, mean_mc_travel_dist: 27965.8965, mean_rewards: 149.9756, total_rewards: 16364.1380, mean_steps: 191.3800, mean_ecr: 0.0409 mean_entropies: 0.3137, took: 356.0920s
2022-08-01 04:59:29,507 [INFO] 	Process 2: Batch 7499/10000, mean_policy_losses: -24.917, mean_net_lifetime: 23895.2950, mean_mc_travel_dist: 28734.2805, mean_rewards: 146.9378, total_rewards: 18154.5849, mean_steps: 198.8000, mean_ecr: 0.0401 mean_entropies: 0.3187, took: 372.1724s
2022-08-01 05:04:54,853 [INFO] 	Process 2: Batch 7599/10000, mean_policy_losses: -21.176, mean_net_lifetime: 21857.4850, mean_mc_travel_dist: 27415.7799, mean_rewards: 150.8994, total_rewards: 16381.0901, mean_steps: 179.0600, mean_ecr: 0.0412 mean_entropies: 0.3077, took: 325.3466s
2022-08-01 05:10:25,050 [INFO] 	Process 2: Batch 7699/10000, mean_policy_losses: -25.592, mean_net_lifetime: 22272.1793, mean_mc_travel_dist: 26549.7253, mean_rewards: 148.2196, total_rewards: 16971.8891, mean_steps: 180.4400, mean_ecr: 0.0409 mean_entropies: 0.3316, took: 330.1963s
2022-08-01 05:15:55,566 [INFO] 	Process 2: Batch 7799/10000, mean_policy_losses: -20.596, mean_net_lifetime: 20205.7530, mean_mc_travel_dist: 25493.5078, mean_rewards: 146.2071, total_rewards: 15114.6563, mean_steps: 174.3000, mean_ecr: 0.0395 mean_entropies: 0.3322, took: 330.5170s
2022-08-01 05:24:03,512 [INFO] 	Process 2: Batch 7899/10000, mean_policy_losses: -24.922, mean_net_lifetime: 28371.5977, mean_mc_travel_dist: 38568.0589, mean_rewards: 142.8236, total_rewards: 20666.1177, mean_steps: 262.2700, mean_ecr: 0.0386 mean_entropies: 0.3448, took: 487.9458s
2022-08-01 05:30:46,068 [INFO] 	Process 2: Batch 7999/10000, mean_policy_losses: -21.997, mean_net_lifetime: 26573.8968, mean_mc_travel_dist: 32798.9878, mean_rewards: 146.3061, total_rewards: 20021.4401, mean_steps: 221.3100, mean_ecr: 0.0397 mean_entropies: 0.3276, took: 402.5553s
2022-08-01 05:37:25,407 [INFO] 	Process 2: Batch 8099/10000, mean_policy_losses: -24.380, mean_net_lifetime: 23307.8029, mean_mc_travel_dist: 29317.9140, mean_rewards: 147.4467, total_rewards: 17452.7363, mean_steps: 208.0400, mean_ecr: 0.0399 mean_entropies: 0.3363, took: 399.3397s
2022-08-01 05:42:40,822 [INFO] 	Process 2: Batch 8199/10000, mean_policy_losses: -15.670, mean_net_lifetime: 20353.9703, mean_mc_travel_dist: 25177.3357, mean_rewards: 147.1497, total_rewards: 15325.9024, mean_steps: 170.4400, mean_ecr: 0.0401 mean_entropies: 0.3088, took: 315.4132s
2022-08-01 05:46:24,554 [INFO] 	Process 2: Batch 8299/10000, mean_policy_losses: -5.650, mean_net_lifetime: 14138.9508, mean_mc_travel_dist: 17345.9355, mean_rewards: 149.1037, total_rewards: 10676.4192, mean_steps: 118.5300, mean_ecr: 0.0413 mean_entropies: 0.3084, took: 223.7341s
2022-08-01 05:51:47,349 [INFO] 	Process 2: Batch 8399/10000, mean_policy_losses: -23.367, mean_net_lifetime: 19867.9114, mean_mc_travel_dist: 24647.0290, mean_rewards: 146.5054, total_rewards: 14949.2097, mean_steps: 178.4800, mean_ecr: 0.0400 mean_entropies: 0.3215, took: 322.7950s
2022-08-01 05:56:42,259 [INFO] 	Process 2: Batch 8499/10000, mean_policy_losses: -23.777, mean_net_lifetime: 19000.1026, mean_mc_travel_dist: 24347.5122, mean_rewards: 147.7379, total_rewards: 14139.3536, mean_steps: 162.1800, mean_ecr: 0.0400 mean_entropies: 0.2903, took: 294.9012s
2022-08-01 06:01:46,203 [INFO] 	Process 2: Batch 8599/10000, mean_policy_losses: -12.228, mean_net_lifetime: 20963.8283, mean_mc_travel_dist: 25529.5979, mean_rewards: 151.4996, total_rewards: 15866.8040, mean_steps: 167.4000, mean_ecr: 0.0402 mean_entropies: 0.2899, took: 303.9514s
2022-08-01 06:07:41,202 [INFO] 	Process 2: Batch 8699/10000, mean_policy_losses: -31.477, mean_net_lifetime: 20588.2925, mean_mc_travel_dist: 28564.8435, mean_rewards: 142.7833, total_rewards: 14882.1983, mean_steps: 195.0200, mean_ecr: 0.0392 mean_entropies: 0.3093, took: 354.9992s
2022-08-01 06:15:24,084 [INFO] 	Process 2: Batch 8799/10000, mean_policy_losses: -19.836, mean_net_lifetime: 27693.0320, mean_mc_travel_dist: 38480.4936, mean_rewards: 148.6115, total_rewards: 20004.1847, mean_steps: 252.4900, mean_ecr: 0.0402 mean_entropies: 0.2881, took: 462.8800s
2022-08-01 06:21:26,475 [INFO] 	Process 2: Batch 8899/10000, mean_policy_losses: -16.653, mean_net_lifetime: 23382.2985, mean_mc_travel_dist: 28406.1737, mean_rewards: 145.8106, total_rewards: 17708.5312, mean_steps: 197.7900, mean_ecr: 0.0405 mean_entropies: 0.2888, took: 362.3937s
2022-08-01 06:27:46,261 [INFO] 	Process 2: Batch 8999/10000, mean_policy_losses: -17.126, mean_net_lifetime: 26125.8603, mean_mc_travel_dist: 31507.7962, mean_rewards: 148.8742, total_rewards: 19830.9025, mean_steps: 214.1900, mean_ecr: 0.0406 mean_entropies: 0.2917, took: 379.7851s
2022-08-01 06:34:04,453 [INFO] 	Process 2: Batch 9099/10000, mean_policy_losses: -18.737, mean_net_lifetime: 23497.6455, mean_mc_travel_dist: 29305.6644, mean_rewards: 149.1237, total_rewards: 17643.1891, mean_steps: 204.4000, mean_ecr: 0.0404 mean_entropies: 0.2894, took: 378.1888s
2022-08-01 06:41:36,182 [INFO] 	Process 2: Batch 9199/10000, mean_policy_losses: -20.501, mean_net_lifetime: 26894.2006, mean_mc_travel_dist: 34922.4055, mean_rewards: 145.9171, total_rewards: 19919.0053, mean_steps: 242.5800, mean_ecr: 0.0391 mean_entropies: 0.2975, took: 451.7233s
2022-08-01 06:46:59,640 [INFO] 	Process 2: Batch 9299/10000, mean_policy_losses: -25.468, mean_net_lifetime: 20133.0223, mean_mc_travel_dist: 24185.9825, mean_rewards: 146.9033, total_rewards: 15305.7351, mean_steps: 173.4500, mean_ecr: 0.0411 mean_entropies: 0.2831, took: 323.4674s
2022-08-01 06:53:12,607 [INFO] 	Process 2: Batch 9399/10000, mean_policy_losses: -21.776, mean_net_lifetime: 21253.7539, mean_mc_travel_dist: 27364.8141, mean_rewards: 149.3016, total_rewards: 15790.3959, mean_steps: 182.5300, mean_ecr: 0.0407 mean_entropies: 0.2918, took: 372.9672s
2022-08-01 06:59:33,640 [INFO] 	Process 2: Batch 9499/10000, mean_policy_losses: -25.356, mean_net_lifetime: 22541.6578, mean_mc_travel_dist: 29211.0471, mean_rewards: 147.4226, total_rewards: 16707.7522, mean_steps: 205.5500, mean_ecr: 0.0408 mean_entropies: 0.2931, took: 381.0331s
2022-08-01 07:05:25,435 [INFO] 	Process 2: Batch 9599/10000, mean_policy_losses: -17.169, mean_net_lifetime: 21908.8016, mean_mc_travel_dist: 27990.2524, mean_rewards: 148.0752, total_rewards: 16316.6157, mean_steps: 191.7800, mean_ecr: 0.0393 mean_entropies: 0.2987, took: 351.7945s
2022-08-01 07:11:43,562 [INFO] 	Process 2: Batch 9699/10000, mean_policy_losses: -14.776, mean_net_lifetime: 25158.6811, mean_mc_travel_dist: 30761.1764, mean_rewards: 150.8818, total_rewards: 19012.8737, mean_steps: 208.4000, mean_ecr: 0.0413 mean_entropies: 0.2865, took: 378.1271s
2022-08-01 07:17:35,996 [INFO] 	Process 2: Batch 9799/10000, mean_policy_losses: -21.337, mean_net_lifetime: 21758.2580, mean_mc_travel_dist: 30264.2019, mean_rewards: 148.6648, total_rewards: 15715.8081, mean_steps: 192.2000, mean_ecr: 0.0396 mean_entropies: 0.2737, took: 352.4348s
2022-08-01 07:24:11,920 [INFO] 	Process 2: Batch 9899/10000, mean_policy_losses: -16.713, mean_net_lifetime: 25332.3625, mean_mc_travel_dist: 32567.7969, mean_rewards: 142.6186, total_rewards: 18825.3919, mean_steps: 217.2600, mean_ecr: 0.0385 mean_entropies: 0.2875, took: 395.9240s
2022-08-01 07:29:42,978 [INFO] 	Process 2: Batch 9999/10000, mean_policy_losses: -14.718, mean_net_lifetime: 22087.2618, mean_mc_travel_dist: 27432.6227, mean_rewards: 147.9131, total_rewards: 16607.6148, mean_steps: 187.5200, mean_ecr: 0.0395 mean_entropies: 0.2706, took: 331.0581s
2022-08-01 07:58:50,359 [INFO] Process 2: Epoch 2: mean_policy_losses: -35.370, mean_net_lifetime: 19973.4844, mean_mc_travel_dist: 26071.5947, mean_entropies: 0.5286, m_net_lifetime_valid: 21660.4709, took: 34644.9324s, (325.7183 / 100 batches)

2022-08-01 07:58:50,360 [INFO] Process 2: Start epoch 3
2022-08-01 08:01:12,777 [INFO] 	Process 2: Batch 99/10000, mean_policy_losses: 109.447, mean_net_lifetime: 4606.7103, mean_mc_travel_dist: 8337.0971, mean_rewards: 58.9493, total_rewards: 2943.6075, mean_steps: 80.9500, mean_ecr: 0.0394 mean_entropies: 2.8904, took: 142.4118s
2022-08-01 08:03:23,403 [INFO] 	Process 2: Batch 199/10000, mean_policy_losses: 35.427, mean_net_lifetime: 4129.6703, mean_mc_travel_dist: 6775.8206, mean_rewards: 59.2737, total_rewards: 2778.1389, mean_steps: 71.1300, mean_ecr: 0.0406 mean_entropies: 2.7774, took: 130.6256s
2022-08-01 08:05:32,319 [INFO] 	Process 2: Batch 299/10000, mean_policy_losses: 2.442, mean_net_lifetime: 4338.1091, mean_mc_travel_dist: 7001.9338, mean_rewards: 60.3106, total_rewards: 2941.4556, mean_steps: 72.5800, mean_ecr: 0.0395 mean_entropies: 2.7558, took: 128.9145s
2022-08-01 08:07:55,346 [INFO] 	Process 2: Batch 399/10000, mean_policy_losses: -36.326, mean_net_lifetime: 4652.0176, mean_mc_travel_dist: 7171.4170, mean_rewards: 61.7511, total_rewards: 3219.3904, mean_steps: 78.7800, mean_ecr: 0.0395 mean_entropies: 2.7024, took: 143.0276s
2022-08-01 08:10:07,922 [INFO] 	Process 2: Batch 499/10000, mean_policy_losses: -25.277, mean_net_lifetime: 4561.7854, mean_mc_travel_dist: 6572.4008, mean_rewards: 64.8769, total_rewards: 3249.4692, mean_steps: 72.8700, mean_ecr: 0.0416 mean_entropies: 2.6833, took: 132.5766s
2022-08-01 08:12:30,761 [INFO] 	Process 2: Batch 599/10000, mean_policy_losses: -2.034, mean_net_lifetime: 4942.1037, mean_mc_travel_dist: 7069.0869, mean_rewards: 67.2755, total_rewards: 3530.3340, mean_steps: 78.4700, mean_ecr: 0.0401 mean_entropies: 2.6575, took: 142.8402s
2022-08-01 08:14:43,526 [INFO] 	Process 2: Batch 699/10000, mean_policy_losses: 33.107, mean_net_lifetime: 4937.7260, mean_mc_travel_dist: 6678.2633, mean_rewards: 71.7751, total_rewards: 3603.1584, mean_steps: 73.6600, mean_ecr: 0.0407 mean_entropies: 2.6211, took: 132.7635s
2022-08-01 08:17:00,496 [INFO] 	Process 2: Batch 799/10000, mean_policy_losses: 10.439, mean_net_lifetime: 5257.2736, mean_mc_travel_dist: 6700.8109, mean_rewards: 74.9267, total_rewards: 3918.7396, mean_steps: 74.0100, mean_ecr: 0.0412 mean_entropies: 2.5615, took: 136.9710s
2022-08-01 08:19:25,344 [INFO] 	Process 2: Batch 899/10000, mean_policy_losses: -18.329, mean_net_lifetime: 5514.9522, mean_mc_travel_dist: 6915.7646, mean_rewards: 76.6721, total_rewards: 4132.9909, mean_steps: 77.6000, mean_ecr: 0.0398 mean_entropies: 2.4844, took: 144.8475s
2022-08-01 08:21:39,083 [INFO] 	Process 2: Batch 999/10000, mean_policy_losses: -44.793, mean_net_lifetime: 5619.9782, mean_mc_travel_dist: 6622.1080, mean_rewards: 81.7296, total_rewards: 4297.2402, mean_steps: 72.4300, mean_ecr: 0.0409 mean_entropies: 2.4262, took: 133.7386s
2022-08-01 08:23:57,835 [INFO] 	Process 2: Batch 1099/10000, mean_policy_losses: -75.167, mean_net_lifetime: 5715.4780, mean_mc_travel_dist: 6579.9720, mean_rewards: 82.6557, total_rewards: 4399.7090, mean_steps: 74.8800, mean_ecr: 0.0414 mean_entropies: 2.3114, took: 138.7527s
2022-08-01 08:26:16,483 [INFO] 	Process 2: Batch 1199/10000, mean_policy_losses: -49.512, mean_net_lifetime: 5702.1143, mean_mc_travel_dist: 6856.3298, mean_rewards: 81.3624, total_rewards: 4331.9460, mean_steps: 75.8300, mean_ecr: 0.0400 mean_entropies: 2.2894, took: 138.6482s
2022-08-01 08:28:41,192 [INFO] 	Process 2: Batch 1299/10000, mean_policy_losses: -82.813, mean_net_lifetime: 5931.5441, mean_mc_travel_dist: 6955.6974, mean_rewards: 82.1135, total_rewards: 4540.8105, mean_steps: 77.8200, mean_ecr: 0.0400 mean_entropies: 2.2785, took: 144.7069s
2022-08-01 08:30:56,663 [INFO] 	Process 2: Batch 1399/10000, mean_policy_losses: -49.361, mean_net_lifetime: 6062.8733, mean_mc_travel_dist: 6689.2789, mean_rewards: 87.2906, total_rewards: 4725.4187, mean_steps: 73.8700, mean_ecr: 0.0408 mean_entropies: 2.2176, took: 135.4739s
2022-08-01 08:33:17,603 [INFO] 	Process 2: Batch 1499/10000, mean_policy_losses: -60.648, mean_net_lifetime: 5808.2115, mean_mc_travel_dist: 6832.4866, mean_rewards: 82.4074, total_rewards: 4442.2433, mean_steps: 76.8500, mean_ecr: 0.0396 mean_entropies: 2.2347, took: 140.9394s
2022-08-01 08:35:29,959 [INFO] 	Process 2: Batch 1599/10000, mean_policy_losses: -86.988, mean_net_lifetime: 6029.3451, mean_mc_travel_dist: 6667.5577, mean_rewards: 88.2757, total_rewards: 4696.4166, mean_steps: 73.6100, mean_ecr: 0.0406 mean_entropies: 2.1679, took: 132.3560s
2022-08-01 08:37:46,957 [INFO] 	Process 2: Batch 1699/10000, mean_policy_losses: -14.451, mean_net_lifetime: 6198.8292, mean_mc_travel_dist: 6784.5791, mean_rewards: 87.7287, total_rewards: 4842.1274, mean_steps: 75.4500, mean_ecr: 0.0403 mean_entropies: 2.2078, took: 136.9965s
2022-08-01 08:39:58,191 [INFO] 	Process 2: Batch 1799/10000, mean_policy_losses: -44.772, mean_net_lifetime: 6141.1343, mean_mc_travel_dist: 6502.1068, mean_rewards: 90.4888, total_rewards: 4841.1433, mean_steps: 72.2500, mean_ecr: 0.0417 mean_entropies: 2.1053, took: 131.2351s
2022-08-01 08:42:17,431 [INFO] 	Process 2: Batch 1899/10000, mean_policy_losses: -34.339, mean_net_lifetime: 5892.5491, mean_mc_travel_dist: 6935.8491, mean_rewards: 82.5782, total_rewards: 4506.2726, mean_steps: 77.2900, mean_ecr: 0.0395 mean_entropies: 2.1259, took: 139.2306s
2022-08-01 08:44:22,929 [INFO] 	Process 2: Batch 1999/10000, mean_policy_losses: -35.792, mean_net_lifetime: 5983.8666, mean_mc_travel_dist: 6363.4376, mean_rewards: 92.7326, total_rewards: 4711.6300, mean_steps: 69.0100, mean_ecr: 0.0416 mean_entropies: 2.1107, took: 125.5073s
2022-08-01 08:46:51,503 [INFO] 	Process 2: Batch 2099/10000, mean_policy_losses: -66.994, mean_net_lifetime: 6149.7344, mean_mc_travel_dist: 7081.8023, mean_rewards: 86.4350, total_rewards: 4734.3844, mean_steps: 77.9700, mean_ecr: 0.0382 mean_entropies: 2.1648, took: 148.5746s
2022-08-01 08:49:05,912 [INFO] 	Process 2: Batch 2199/10000, mean_policy_losses: -69.873, mean_net_lifetime: 6340.2713, mean_mc_travel_dist: 6586.8464, mean_rewards: 95.3805, total_rewards: 5023.5022, mean_steps: 72.5900, mean_ecr: 0.0409 mean_entropies: 2.1252, took: 134.4083s
2022-08-01 08:51:22,941 [INFO] 	Process 2: Batch 2299/10000, mean_policy_losses: -21.509, mean_net_lifetime: 6258.7446, mean_mc_travel_dist: 6780.1057, mean_rewards: 90.3106, total_rewards: 4903.2353, mean_steps: 75.2800, mean_ecr: 0.0394 mean_entropies: 2.1132, took: 137.0296s
2022-08-01 08:53:29,518 [INFO] 	Process 2: Batch 2399/10000, mean_policy_losses: -60.939, mean_net_lifetime: 6303.2987, mean_mc_travel_dist: 6343.3648, mean_rewards: 96.4961, total_rewards: 5035.2020, mean_steps: 69.8100, mean_ecr: 0.0415 mean_entropies: 2.0859, took: 126.5776s
2022-08-01 08:55:44,963 [INFO] 	Process 2: Batch 2499/10000, mean_policy_losses: -43.812, mean_net_lifetime: 6341.3404, mean_mc_travel_dist: 6841.7367, mean_rewards: 90.8942, total_rewards: 4973.4095, mean_steps: 75.1800, mean_ecr: 0.0391 mean_entropies: 2.1052, took: 135.4435s
2022-08-01 08:57:53,757 [INFO] 	Process 2: Batch 2599/10000, mean_policy_losses: -85.892, mean_net_lifetime: 6228.3536, mean_mc_travel_dist: 6466.3886, mean_rewards: 95.7099, total_rewards: 4935.7156, mean_steps: 71.4300, mean_ecr: 0.0411 mean_entropies: 2.0657, took: 128.7943s
2022-08-01 09:00:09,632 [INFO] 	Process 2: Batch 2699/10000, mean_policy_losses: -16.151, mean_net_lifetime: 6208.4682, mean_mc_travel_dist: 6645.2603, mean_rewards: 93.1760, total_rewards: 4879.4162, mean_steps: 73.4800, mean_ecr: 0.0398 mean_entropies: 2.0496, took: 135.8751s
2022-08-01 09:02:24,440 [INFO] 	Process 2: Batch 2799/10000, mean_policy_losses: -52.418, mean_net_lifetime: 6177.8492, mean_mc_travel_dist: 6468.3342, mean_rewards: 93.4563, total_rewards: 4884.7257, mean_steps: 71.9400, mean_ecr: 0.0408 mean_entropies: 1.9391, took: 134.8078s
2022-08-01 09:04:35,087 [INFO] 	Process 2: Batch 2899/10000, mean_policy_losses: -40.100, mean_net_lifetime: 6317.8898, mean_mc_travel_dist: 6261.9912, mean_rewards: 99.8079, total_rewards: 5066.7683, mean_steps: 68.8500, mean_ecr: 0.0414 mean_entropies: 1.9182, took: 130.6475s
2022-08-01 09:06:47,093 [INFO] 	Process 2: Batch 2999/10000, mean_policy_losses: -85.715, mean_net_lifetime: 6105.3979, mean_mc_travel_dist: 6499.9178, mean_rewards: 94.4829, total_rewards: 4806.1803, mean_steps: 71.1900, mean_ecr: 0.0406 mean_entropies: 1.9944, took: 132.0052s
2022-08-01 09:09:06,046 [INFO] 	Process 2: Batch 3099/10000, mean_policy_losses: -65.071, mean_net_lifetime: 6403.3967, mean_mc_travel_dist: 6800.0782, mean_rewards: 91.0581, total_rewards: 5043.9262, mean_steps: 75.5800, mean_ecr: 0.0386 mean_entropies: 1.9995, took: 138.9539s
2022-08-01 09:11:14,083 [INFO] 	Process 2: Batch 3199/10000, mean_policy_losses: -48.160, mean_net_lifetime: 6468.8624, mean_mc_travel_dist: 6437.1459, mean_rewards: 99.9403, total_rewards: 5181.7546, mean_steps: 69.8900, mean_ecr: 0.0408 mean_entropies: 1.9841, took: 128.0367s
2022-08-01 09:13:26,947 [INFO] 	Process 2: Batch 3299/10000, mean_policy_losses: -55.401, mean_net_lifetime: 6308.6823, mean_mc_travel_dist: 6331.2819, mean_rewards: 99.9474, total_rewards: 5043.6415, mean_steps: 69.2300, mean_ecr: 0.0408 mean_entropies: 1.9096, took: 132.8633s
2022-08-01 09:15:35,411 [INFO] 	Process 2: Batch 3399/10000, mean_policy_losses: -95.741, mean_net_lifetime: 6343.4529, mean_mc_travel_dist: 6207.4643, mean_rewards: 103.3208, total_rewards: 5102.4495, mean_steps: 67.0000, mean_ecr: 0.0416 mean_entropies: 1.9380, took: 128.4650s
2022-08-01 09:17:47,392 [INFO] 	Process 2: Batch 3499/10000, mean_policy_losses: -84.269, mean_net_lifetime: 6505.3459, mean_mc_travel_dist: 6580.1087, mean_rewards: 98.4449, total_rewards: 5189.4768, mean_steps: 71.5900, mean_ecr: 0.0399 mean_entropies: 1.8969, took: 131.9818s
2022-08-01 09:19:53,246 [INFO] 	Process 2: Batch 3599/10000, mean_policy_losses: -73.641, mean_net_lifetime: 6333.2644, mean_mc_travel_dist: 6362.0350, mean_rewards: 102.4495, total_rewards: 5061.8917, mean_steps: 68.2900, mean_ecr: 0.0408 mean_entropies: 1.8585, took: 125.8537s
2022-08-01 09:21:57,044 [INFO] 	Process 2: Batch 3699/10000, mean_policy_losses: -74.699, mean_net_lifetime: 6504.1141, mean_mc_travel_dist: 6254.3091, mean_rewards: 104.6767, total_rewards: 5253.5483, mean_steps: 66.3400, mean_ecr: 0.0416 mean_entropies: 1.8419, took: 123.7968s
2022-08-01 09:24:02,736 [INFO] 	Process 2: Batch 3799/10000, mean_policy_losses: -52.478, mean_net_lifetime: 6242.9799, mean_mc_travel_dist: 6139.8892, mean_rewards: 101.9964, total_rewards: 5015.4138, mean_steps: 67.8000, mean_ecr: 0.0419 mean_entropies: 1.7629, took: 125.6923s
2022-08-01 09:26:13,116 [INFO] 	Process 2: Batch 3899/10000, mean_policy_losses: -62.352, mean_net_lifetime: 6574.9359, mean_mc_travel_dist: 6416.6655, mean_rewards: 101.6282, total_rewards: 5291.7405, mean_steps: 70.2600, mean_ecr: 0.0405 mean_entropies: 1.7813, took: 130.3811s
2022-08-01 09:28:22,623 [INFO] 	Process 2: Batch 3999/10000, mean_policy_losses: -127.736, mean_net_lifetime: 6379.4315, mean_mc_travel_dist: 6261.0086, mean_rewards: 102.2783, total_rewards: 5127.8132, mean_steps: 69.2600, mean_ecr: 0.0413 mean_entropies: 1.7556, took: 129.5054s
2022-08-01 09:30:34,643 [INFO] 	Process 2: Batch 4099/10000, mean_policy_losses: -4.598, mean_net_lifetime: 6376.8793, mean_mc_travel_dist: 6505.1537, mean_rewards: 98.1049, total_rewards: 5076.6927, mean_steps: 70.8900, mean_ecr: 0.0401 mean_entropies: 1.7934, took: 132.0208s
2022-08-01 09:32:44,332 [INFO] 	Process 2: Batch 4199/10000, mean_policy_losses: -57.104, mean_net_lifetime: 6281.9643, mean_mc_travel_dist: 6168.0261, mean_rewards: 102.6640, total_rewards: 5049.7350, mean_steps: 66.6900, mean_ecr: 0.0418 mean_entropies: 1.7783, took: 129.6890s
2022-08-01 09:34:57,926 [INFO] 	Process 2: Batch 4299/10000, mean_policy_losses: -47.149, mean_net_lifetime: 6850.8553, mean_mc_travel_dist: 6286.9241, mean_rewards: 105.1622, total_rewards: 5593.7506, mean_steps: 68.9600, mean_ecr: 0.0411 mean_entropies: 1.7754, took: 133.5922s
2022-08-01 09:37:10,372 [INFO] 	Process 2: Batch 4399/10000, mean_policy_losses: -66.681, mean_net_lifetime: 6527.3216, mean_mc_travel_dist: 6446.9568, mean_rewards: 101.0488, total_rewards: 5238.3021, mean_steps: 69.7900, mean_ecr: 0.0400 mean_entropies: 1.7551, took: 132.4473s
2022-08-01 09:39:27,022 [INFO] 	Process 2: Batch 4499/10000, mean_policy_losses: -106.942, mean_net_lifetime: 6446.9310, mean_mc_travel_dist: 6547.2082, mean_rewards: 98.3339, total_rewards: 5137.9861, mean_steps: 72.3800, mean_ecr: 0.0398 mean_entropies: 1.7655, took: 136.6494s
2022-08-01 09:41:53,406 [INFO] 	Process 2: Batch 4599/10000, mean_policy_losses: -57.073, mean_net_lifetime: 6290.1326, mean_mc_travel_dist: 6606.8187, mean_rewards: 96.8024, total_rewards: 4968.7689, mean_steps: 72.8700, mean_ecr: 0.0394 mean_entropies: 1.7950, took: 146.3843s
2022-08-01 09:44:10,778 [INFO] 	Process 2: Batch 4699/10000, mean_policy_losses: -64.433, mean_net_lifetime: 6337.9992, mean_mc_travel_dist: 6535.4315, mean_rewards: 98.7508, total_rewards: 5031.3938, mean_steps: 70.7500, mean_ecr: 0.0399 mean_entropies: 1.7231, took: 137.3718s
2022-08-01 09:46:31,303 [INFO] 	Process 2: Batch 4799/10000, mean_policy_losses: -11.525, mean_net_lifetime: 6566.6484, mean_mc_travel_dist: 6595.4761, mean_rewards: 98.5846, total_rewards: 5247.8014, mean_steps: 72.3400, mean_ecr: 0.0395 mean_entropies: 1.7227, took: 140.5246s
2022-08-01 09:48:38,275 [INFO] 	Process 2: Batch 4899/10000, mean_policy_losses: -77.372, mean_net_lifetime: 6638.5659, mean_mc_travel_dist: 6163.4675, mean_rewards: 106.9392, total_rewards: 5405.8724, mean_steps: 66.5800, mean_ecr: 0.0414 mean_entropies: 1.6956, took: 126.9731s
2022-08-01 09:50:51,939 [INFO] 	Process 2: Batch 4999/10000, mean_policy_losses: -61.128, mean_net_lifetime: 6336.5069, mean_mc_travel_dist: 6420.2764, mean_rewards: 100.6966, total_rewards: 5053.2813, mean_steps: 69.8500, mean_ecr: 0.0403 mean_entropies: 1.7179, took: 133.6632s
2022-08-01 09:53:04,327 [INFO] 	Process 2: Batch 5099/10000, mean_policy_losses: -89.043, mean_net_lifetime: 6635.1395, mean_mc_travel_dist: 6133.3763, mean_rewards: 108.4819, total_rewards: 5408.4643, mean_steps: 67.6800, mean_ecr: 0.0415 mean_entropies: 1.6241, took: 132.3887s
2022-08-01 09:55:18,481 [INFO] 	Process 2: Batch 5199/10000, mean_policy_losses: -49.642, mean_net_lifetime: 6438.5740, mean_mc_travel_dist: 6376.7003, mean_rewards: 100.3201, total_rewards: 5163.8936, mean_steps: 69.9400, mean_ecr: 0.0402 mean_entropies: 1.6935, took: 134.1537s
2022-08-01 09:57:23,877 [INFO] 	Process 2: Batch 5299/10000, mean_policy_losses: -112.741, mean_net_lifetime: 6429.4804, mean_mc_travel_dist: 6213.2645, mean_rewards: 105.3642, total_rewards: 5187.8521, mean_steps: 66.6500, mean_ecr: 0.0415 mean_entropies: 1.6325, took: 125.3971s
2022-08-01 09:59:40,289 [INFO] 	Process 2: Batch 5399/10000, mean_policy_losses: -79.545, mean_net_lifetime: 6555.1117, mean_mc_travel_dist: 6296.0162, mean_rewards: 102.1271, total_rewards: 5296.4092, mean_steps: 70.7200, mean_ecr: 0.0410 mean_entropies: 1.5858, took: 136.4109s
2022-08-01 10:01:59,966 [INFO] 	Process 2: Batch 5499/10000, mean_policy_losses: -50.600, mean_net_lifetime: 6445.8839, mean_mc_travel_dist: 6192.3076, mean_rewards: 102.7148, total_rewards: 5207.4224, mean_steps: 67.9800, mean_ecr: 0.0410 mean_entropies: 1.5879, took: 139.6762s
2022-08-01 10:04:19,535 [INFO] 	Process 2: Batch 5599/10000, mean_policy_losses: -81.609, mean_net_lifetime: 6487.6211, mean_mc_travel_dist: 6376.3106, mean_rewards: 103.9399, total_rewards: 5212.8692, mean_steps: 69.0500, mean_ecr: 0.0405 mean_entropies: 1.5789, took: 139.5691s
2022-08-01 10:06:37,959 [INFO] 	Process 2: Batch 5699/10000, mean_policy_losses: -53.997, mean_net_lifetime: 6384.8462, mean_mc_travel_dist: 6885.6278, mean_rewards: 94.7855, total_rewards: 5007.9696, mean_steps: 73.1200, mean_ecr: 0.0380 mean_entropies: 1.6600, took: 138.4242s
2022-08-01 10:08:48,936 [INFO] 	Process 2: Batch 5799/10000, mean_policy_losses: -77.395, mean_net_lifetime: 6488.5222, mean_mc_travel_dist: 6128.2701, mean_rewards: 106.8174, total_rewards: 5264.1535, mean_steps: 66.6600, mean_ecr: 0.0418 mean_entropies: 1.5751, took: 130.9764s
2022-08-01 10:11:03,237 [INFO] 	Process 2: Batch 5899/10000, mean_policy_losses: -73.938, mean_net_lifetime: 6554.7618, mean_mc_travel_dist: 6269.7671, mean_rewards: 106.6460, total_rewards: 5301.8415, mean_steps: 67.3700, mean_ecr: 0.0411 mean_entropies: 1.5324, took: 134.3035s
2022-08-01 10:13:17,900 [INFO] 	Process 2: Batch 5999/10000, mean_policy_losses: -95.192, mean_net_lifetime: 6693.2298, mean_mc_travel_dist: 6511.6946, mean_rewards: 102.2988, total_rewards: 5390.9891, mean_steps: 69.8200, mean_ecr: 0.0396 mean_entropies: 1.5952, took: 134.6609s
2022-08-01 10:15:39,331 [INFO] 	Process 2: Batch 6099/10000, mean_policy_losses: -80.585, mean_net_lifetime: 6515.4298, mean_mc_travel_dist: 6204.8977, mean_rewards: 107.4387, total_rewards: 5274.9181, mean_steps: 66.4200, mean_ecr: 0.0412 mean_entropies: 1.5320, took: 141.4309s
2022-08-01 10:18:01,136 [INFO] 	Process 2: Batch 6199/10000, mean_policy_losses: -110.876, mean_net_lifetime: 6399.3740, mean_mc_travel_dist: 6277.3280, mean_rewards: 103.8376, total_rewards: 5144.3283, mean_steps: 67.6400, mean_ecr: 0.0408 mean_entropies: 1.5188, took: 141.8061s
2022-08-01 10:20:12,546 [INFO] 	Process 2: Batch 6299/10000, mean_policy_losses: -65.236, mean_net_lifetime: 6497.9155, mean_mc_travel_dist: 6068.6825, mean_rewards: 109.8008, total_rewards: 5284.5565, mean_steps: 64.7800, mean_ecr: 0.0419 mean_entropies: 1.4660, took: 131.4102s
2022-08-01 10:22:25,276 [INFO] 	Process 2: Batch 6399/10000, mean_policy_losses: -52.047, mean_net_lifetime: 6459.3651, mean_mc_travel_dist: 6288.5353, mean_rewards: 105.7054, total_rewards: 5202.2030, mean_steps: 67.6400, mean_ecr: 0.0410 mean_entropies: 1.4988, took: 132.7285s
2022-08-01 10:24:39,810 [INFO] 	Process 2: Batch 6499/10000, mean_policy_losses: -38.948, mean_net_lifetime: 6459.2079, mean_mc_travel_dist: 6430.1202, mean_rewards: 100.8275, total_rewards: 5173.7169, mean_steps: 68.9300, mean_ecr: 0.0400 mean_entropies: 1.5099, took: 134.5344s
2022-08-01 10:26:54,572 [INFO] 	Process 2: Batch 6599/10000, mean_policy_losses: -81.175, mean_net_lifetime: 6466.2248, mean_mc_travel_dist: 6289.8004, mean_rewards: 103.8648, total_rewards: 5208.9433, mean_steps: 68.1200, mean_ecr: 0.0409 mean_entropies: 1.4882, took: 134.7615s
2022-08-01 10:29:21,476 [INFO] 	Process 2: Batch 6699/10000, mean_policy_losses: -61.746, mean_net_lifetime: 6316.7304, mean_mc_travel_dist: 6592.6632, mean_rewards: 99.2994, total_rewards: 4998.6877, mean_steps: 71.8000, mean_ecr: 0.0393 mean_entropies: 1.5206, took: 146.9052s
2022-08-01 10:31:40,716 [INFO] 	Process 2: Batch 6799/10000, mean_policy_losses: -94.580, mean_net_lifetime: 6568.5029, mean_mc_travel_dist: 6396.2657, mean_rewards: 102.8279, total_rewards: 5290.3672, mean_steps: 69.9500, mean_ecr: 0.0403 mean_entropies: 1.4893, took: 139.2399s
2022-08-01 10:33:40,558 [INFO] 	Process 2: Batch 6899/10000, mean_policy_losses: -57.019, mean_net_lifetime: 6419.5067, mean_mc_travel_dist: 6099.7312, mean_rewards: 108.0723, total_rewards: 5200.7131, mean_steps: 64.3700, mean_ecr: 0.0416 mean_entropies: 1.4101, took: 119.8428s
2022-08-01 10:35:54,820 [INFO] 	Process 2: Batch 6999/10000, mean_policy_losses: -55.248, mean_net_lifetime: 6665.7091, mean_mc_travel_dist: 6544.5470, mean_rewards: 101.9267, total_rewards: 5358.1613, mean_steps: 70.2700, mean_ecr: 0.0398 mean_entropies: 1.5000, took: 134.2600s
2022-08-01 10:38:03,818 [INFO] 	Process 2: Batch 7099/10000, mean_policy_losses: -71.236, mean_net_lifetime: 6270.3587, mean_mc_travel_dist: 6428.7452, mean_rewards: 100.1356, total_rewards: 4985.4601, mean_steps: 68.8900, mean_ecr: 0.0403 mean_entropies: 1.4559, took: 128.9980s
2022-08-01 10:40:15,537 [INFO] 	Process 2: Batch 7199/10000, mean_policy_losses: -91.548, mean_net_lifetime: 6395.5108, mean_mc_travel_dist: 6416.9553, mean_rewards: 102.0925, total_rewards: 5112.7489, mean_steps: 69.9700, mean_ecr: 0.0399 mean_entropies: 1.3920, took: 131.7197s
2022-08-01 10:42:19,102 [INFO] 	Process 2: Batch 7299/10000, mean_policy_losses: -82.204, mean_net_lifetime: 6620.5879, mean_mc_travel_dist: 6082.2813, mean_rewards: 108.8611, total_rewards: 5405.0448, mean_steps: 66.0400, mean_ecr: 0.0418 mean_entropies: 1.3376, took: 123.5665s
2022-08-01 10:44:25,945 [INFO] 	Process 2: Batch 7399/10000, mean_policy_losses: -36.322, mean_net_lifetime: 6500.2022, mean_mc_travel_dist: 6282.4921, mean_rewards: 105.3927, total_rewards: 5244.1430, mean_steps: 66.9200, mean_ecr: 0.0411 mean_entropies: 1.3485, took: 126.8430s
2022-08-01 10:46:37,842 [INFO] 	Process 2: Batch 7499/10000, mean_policy_losses: -63.026, mean_net_lifetime: 6539.7369, mean_mc_travel_dist: 6356.6417, mean_rewards: 104.4590, total_rewards: 5269.4592, mean_steps: 68.8300, mean_ecr: 0.0404 mean_entropies: 1.3751, took: 131.8964s
2022-08-01 10:48:42,247 [INFO] 	Process 2: Batch 7599/10000, mean_policy_losses: -49.061, mean_net_lifetime: 6460.5584, mean_mc_travel_dist: 6216.8399, mean_rewards: 105.7948, total_rewards: 5217.9110, mean_steps: 66.9000, mean_ecr: 0.0413 mean_entropies: 1.3794, took: 124.4033s
2022-08-01 10:50:52,590 [INFO] 	Process 2: Batch 7699/10000, mean_policy_losses: -55.827, mean_net_lifetime: 6588.7585, mean_mc_travel_dist: 6611.4301, mean_rewards: 101.0410, total_rewards: 5266.6025, mean_steps: 70.0800, mean_ecr: 0.0392 mean_entropies: 1.4562, took: 130.3447s
2022-08-01 10:53:09,155 [INFO] 	Process 2: Batch 7799/10000, mean_policy_losses: -56.862, mean_net_lifetime: 6347.0870, mean_mc_travel_dist: 6449.3899, mean_rewards: 100.8221, total_rewards: 5057.2090, mean_steps: 69.8600, mean_ecr: 0.0401 mean_entropies: 1.4202, took: 136.5625s
2022-08-01 10:55:32,251 [INFO] 	Process 2: Batch 7899/10000, mean_policy_losses: -105.370, mean_net_lifetime: 6431.2356, mean_mc_travel_dist: 6704.5889, mean_rewards: 98.2249, total_rewards: 5090.3948, mean_steps: 72.5300, mean_ecr: 0.0387 mean_entropies: 1.4177, took: 143.0992s
2022-08-01 10:57:51,239 [INFO] 	Process 2: Batch 7999/10000, mean_policy_losses: -60.970, mean_net_lifetime: 6334.7978, mean_mc_travel_dist: 6382.8981, mean_rewards: 103.1401, total_rewards: 5058.9216, mean_steps: 68.3200, mean_ecr: 0.0405 mean_entropies: 1.3257, took: 138.9852s
2022-08-01 11:00:05,455 [INFO] 	Process 2: Batch 8099/10000, mean_policy_losses: -65.444, mean_net_lifetime: 6475.1677, mean_mc_travel_dist: 6446.8830, mean_rewards: 102.3614, total_rewards: 5186.0755, mean_steps: 69.8100, mean_ecr: 0.0399 mean_entropies: 1.3627, took: 134.2173s
2022-08-01 11:02:15,672 [INFO] 	Process 2: Batch 8199/10000, mean_policy_losses: -50.265, mean_net_lifetime: 6532.6832, mean_mc_travel_dist: 6557.3588, mean_rewards: 98.4681, total_rewards: 5221.6008, mean_steps: 72.7700, mean_ecr: 0.0396 mean_entropies: 1.3243, took: 130.2188s
2022-08-01 11:04:29,246 [INFO] 	Process 2: Batch 8299/10000, mean_policy_losses: -34.862, mean_net_lifetime: 6653.6352, mean_mc_travel_dist: 6269.1770, mean_rewards: 102.6651, total_rewards: 5400.9209, mean_steps: 70.2300, mean_ecr: 0.0410 mean_entropies: 1.2997, took: 133.5727s
2022-08-01 11:06:39,668 [INFO] 	Process 2: Batch 8399/10000, mean_policy_losses: -95.079, mean_net_lifetime: 6632.4159, mean_mc_travel_dist: 6456.2996, mean_rewards: 102.2843, total_rewards: 5341.3853, mean_steps: 70.4300, mean_ecr: 0.0400 mean_entropies: 1.3255, took: 130.4212s
2022-08-01 11:08:42,915 [INFO] 	Process 2: Batch 8499/10000, mean_policy_losses: -44.959, mean_net_lifetime: 6404.2688, mean_mc_travel_dist: 6200.1695, mean_rewards: 103.8469, total_rewards: 5165.1920, mean_steps: 67.6200, mean_ecr: 0.0416 mean_entropies: 1.2917, took: 123.2483s
2022-08-01 11:10:47,912 [INFO] 	Process 2: Batch 8599/10000, mean_policy_losses: -52.304, mean_net_lifetime: 6336.0574, mean_mc_travel_dist: 6147.0095, mean_rewards: 103.9031, total_rewards: 5107.4346, mean_steps: 67.4400, mean_ecr: 0.0411 mean_entropies: 1.2295, took: 124.9968s
2022-08-01 11:13:02,033 [INFO] 	Process 2: Batch 8699/10000, mean_policy_losses: -77.906, mean_net_lifetime: 6748.1408, mean_mc_travel_dist: 6434.0085, mean_rewards: 104.1645, total_rewards: 5462.2336, mean_steps: 69.3500, mean_ecr: 0.0402 mean_entropies: 1.3073, took: 134.1184s
2022-08-01 11:15:15,242 [INFO] 	Process 2: Batch 8799/10000, mean_policy_losses: -47.498, mean_net_lifetime: 6228.8121, mean_mc_travel_dist: 6259.8026, mean_rewards: 101.9155, total_rewards: 4977.5382, mean_steps: 68.4900, mean_ecr: 0.0408 mean_entropies: 1.3609, took: 133.2097s
2022-08-01 11:17:33,800 [INFO] 	Process 2: Batch 8899/10000, mean_policy_losses: -83.113, mean_net_lifetime: 6328.6736, mean_mc_travel_dist: 6659.7962, mean_rewards: 97.5794, total_rewards: 4997.3481, mean_steps: 72.0400, mean_ecr: 0.0389 mean_entropies: 1.3944, took: 138.5586s
2022-08-01 11:19:58,371 [INFO] 	Process 2: Batch 8999/10000, mean_policy_losses: -72.209, mean_net_lifetime: 6417.9184, mean_mc_travel_dist: 6712.4457, mean_rewards: 98.2544, total_rewards: 5076.1349, mean_steps: 73.7600, mean_ecr: 0.0386 mean_entropies: 1.4191, took: 144.5715s
2022-08-01 11:22:24,167 [INFO] 	Process 2: Batch 9099/10000, mean_policy_losses: -79.900, mean_net_lifetime: 6319.0096, mean_mc_travel_dist: 6613.9473, mean_rewards: 98.0371, total_rewards: 4996.4115, mean_steps: 70.8500, mean_ecr: 0.0392 mean_entropies: 1.3871, took: 145.7974s
2022-08-01 11:25:02,918 [INFO] 	Process 2: Batch 9199/10000, mean_policy_losses: -77.751, mean_net_lifetime: 6306.0289, mean_mc_travel_dist: 6340.3342, mean_rewards: 102.2629, total_rewards: 5038.5600, mean_steps: 69.2000, mean_ecr: 0.0404 mean_entropies: 1.3736, took: 158.7487s
